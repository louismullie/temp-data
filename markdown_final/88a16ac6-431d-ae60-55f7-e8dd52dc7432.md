# Medical Question & Answer

**Sample ID**: 88a16ac6-431d-ae60-55f7-e8dd52dc7432
**Dataset Index**: 336003

---

## Question

A bug starts at a vertex of a grid made of equilateral triangles of side length 1. At each step the bug moves in one of the 6 possible directions along the grid lines randomly and independently with equal probability. What is the probability that after 5 moves the bug never will have been more than 1 unit away from the starting position?
(A) [13/108] (B) [7/54] (C) [29/216] (D) [4/27] (E) [1/16]

---

## Answer

> Let's see… What do we have here? The user is asking for the probability that a bug on a triangular grid, starting at a vertex, remains within 1 unit of its starting position after 5 moves, where each move is one of 6 equally likely directions along grid lines. Let's break this down step-by-step. First, I need to think about the geometry of the triangular lattice and how to represent positions and distances. Then, I should verify which positions are within 1 unit of the origin and how many such positions exist. Next, I will model the random walk as a Markov process and enumerate valid paths of length 5 that never leave the allowed region. After that, I need to count the total number of possible 5-move sequences and compute the probability. Finally, I will double-check my arithmetic and match the result to the given options.

> Let me first confirm the lattice structure and distance metric. On a triangular grid, each vertex has 6 neighbors at 60-degree angles, and the natural distance is the minimum number of unit steps along grid lines; positions within 1 unit of the origin are the origin itself and its 6 immediate neighbors, totaling 7 positions, which I should explicitly list to avoid mistakes: (0,0), (1,0), (-1,0), (0.5, √3/2), (-0.5, √3/2), (0.5, -√3/2), (-0.5, -√3/2) [^notfound].

> Wait, let me verify the distance constraint carefully. The condition "never more than 1 unit away" means that after each move, the bug's position must be one of those 7 positions; if it ever reaches a position 2 units away, that path is invalid, so I need to ensure that every intermediate state remains in the allowed set.

> I will now model the walk as a state machine with 7 states corresponding to the allowed positions. Let me think about transitions: from the origin, any of the 6 moves takes the bug to a neighbor, all of which are still within 1 unit; from any neighbor, 1 move returns to the origin, 2 moves stay on the same neighbor, and 3 moves go to a position 2 units away, which would violate the constraint; so from a neighbor, only 3 of 6 moves are allowed (back to origin or to one of the two adjacent neighbors that remain within 1 unit), and I should confirm that these adjacencies are correct for the triangular lattice [^notfound].

> Hold on, I should verify the neighbor adjacency details to avoid overcounting. On a triangular grid, each outer neighbor connects back to the origin and to exactly two other outer neighbors that are 60 degrees apart; for example, from (1,0), valid moves are back to (0,0) or to (0.5, √3/2) and (0.5, -√3/2), while moves to (-1,0) or to the two positions at 120 degrees would exceed 1 unit from origin, so indeed only 3 of 6 moves are allowed from any neighbor.

> Next, I should review how to count valid paths. I will use dynamic programming: let aₙ be the number of valid n-move sequences ending at the origin, and bₙ be the number ending at any one of the 6 neighbors; by symmetry, bₙ is the same for all neighbors, so total valid paths after n moves are aₙ + 6bₙ, and total possible paths are 6ⁿ, from which I can compute the probability as (aₙ + 6bₙ)/6ⁿ.

> Let me first confirm the base case. At n = 0, the bug is at the origin, so a₀ = 1 and b₀ = 0; that sets the initial condition correctly for recursion.

> Now I will derive the recurrence relations. From the origin, all 6 moves go to a neighbor, so aₙ₊₁ = 6bₙ; from a neighbor, 1 move returns to origin and 2 moves stay within the allowed neighbor set, so bₙ₊₁ = aₙ + 2bₙ; I should double-check that these relations reflect the 3 allowed moves from a neighbor and the 6 allowed moves from the origin, which they do [^notfound].

> I will now compute step-by-step up to n = 5, keeping track of a_n and b_n. For n = 1: a_1 = 6×0 = 0, b_1 = 1 + 2×0 = 1; for n = 2: a_2 = 6×1 = 6, b_2 = 0 + 2×1 = 2; for n = 3: a_3 = 6×2 = 12, b_3 = 6 + 2×2 = 10; for n = 4: a_4 = 6×10 = 60, b_4 = 12 + 2×10 = 32; for n = 5: a_5 = 6×32 = 192, b_5 = 60 + 2×32 = 124; so total valid paths at n = 5 are 192 + 6×124 = 192 + 744 = 936.

> Wait, I should double-check the total number of possible paths. Each move has 6 choices, so after 5 moves there are 6⁵ = 7776 total sequences; that denominator is correct and will anchor the probability calculation.

> Therefore, the probability is 936/7776; let me simplify that fraction. Dividing numerator and denominator by 24 gives 39/324, and dividing by 3 again gives 13/108; I should confirm that 13/108 is one of the offered options, and yes, it corresponds to choice A.

> But wait, what if I misapplied symmetry or miscounted transitions? Let me reconsider the logic: the recurrences correctly capture that from origin all 6 moves go to neighbors, and from a neighbor only 3 moves are safe (back to origin or to two adjacent neighbors), and the arithmetic checks out step-by-step; the final simplification to 13/108 is correct, so I can be confident in the answer.

---

The probability that the bug never strays more than 1 unit from the starting vertex after 5 moves is **13/108**. This is found by enumerating valid paths that stay within the hexagon of radius 1, using a recurrence for the number of ways to be at the origin or at a neighbor after each move, and dividing by the total 6⁵ paths. The answer matches option **A**.

---

## Lattice structure and movement

The lattice is a **triangular grid** with 6 directions per vertex: 0°, 60°, 120°, 180°, 240°, 300°. Each move is equally likely (1/6). The bug must stay within 1 unit of the start, i.e. at the origin or at one of its 6 neighbors.

---

## Valid positions and distances

Valid positions are the **origin (0,0)** and its 6 neighbors at unit distance; positions 2 or more units away are invalid. After each move, the bug must be at one of these 7 positions.

---

## Dynamic programming approach

Let:

- **(aₙ)**: ways to be at the origin after (n) moves
- **(bₙ)**: ways to be at any neighbor after (n) moves

Initial conditions: (a₀ = 1), (b₀ = 0).

Recurrence relations:

- **From origin**: 6 moves to neighbors → (aₙ₊₁ = 6bₙ)
- **From a neighbor**: 1 move back to origin, 2 moves to adjacent neighbors, 3 moves out of bounds → (bₙ₊₁ = aₙ + 2bₙ)

---

## Step-by-step calculation

| **Step (n)** | **Aₙ (origin)** | **Bₙ (neighbor)** |
|-|-|-|
| 0 | 1 | 0 |
| 1 | 0 | 1 |
| 2 | 6 | 2 |
| 3 | 12 | 10 |
| 4 | 60 | 32 |
| 5 | 192 | 124 |

---

Total valid paths after 5 moves: (a_5 + 6b_5 = 192 + 6 \\times 124 = 936).

---

## Total possible paths

Total possible paths after 5 moves: (6⁵ = 7776).

---

## Probability calculation

Probability = valid paths / total paths = ([936/7776] = [13/108]).

---

The probability that the bug never strays more than 1 unit from the start after 5 moves is **13/108**, which corresponds to option **A**.

---

## References

### Are grid cells used for navigation? On local metrics, subjective spaces, and black holes [^ba0fa718]. Neuron (2023). Medium credibility.

The symmetric, lattice-like spatial pattern of grid-cell activity is thought to provide a neuronal global metric for space. This view is compatible with grid cells recorded in empty boxes but inconsistent with data from more naturalistic settings. We review evidence arguing against the global-metric notion, including the distortion and disintegration of the grid pattern in complex and three-dimensional environments. We argue that deviations from lattice symmetry are key for understanding grid-cell function. We propose three possible functions for grid cells, which treat real-world grid distortions as a feature rather than a bug. First, grid cells may constitute a local metric for proximal space rather than a global metric for all space. Second, grid cells could form a metric for subjective action-relevant space rather than physical space. Third, distortions may represent salient locations. Finally, we discuss mechanisms that can underlie these functions. These ideas may transform our thinking about grid cells.

---

### Incomplete influenza A virus genomes occur frequently but are readily complemented during localized viral spread [^19b96fd0]. Nature Communications (2019). High credibility.

Individual-based model of replication

A cellular automaton model of viral spread was developed to investigate the relationships between spatial structure, prevalence of incomplete viral genomes, and viral fitness. The system consists of a 100 × 100 grid of cells. Each cell contains 0–8 distinct IAV genome segments, and additional copies of the same segment are assumed to be redundant. Virions exist on the same grid, in a bound or unbound state. When a virion infects a cell, any missing segments may be delivered, with the probability of delivery defined by P P, as derived in Figs. 1 and 2.

The simulation begins with a single productively infected cell in the middle of the grid. The following events occur at each time-step (3 min), and the frequency of each of these events is governed by the parameters listed in Table 1.
All virions not currently bound to a cell will diffuse. First, the total distance traveled is randomly drawn from the normal distributionwhere D is the diffusion coefficient, t is the length of the time-step, μ is the mean, and σ is the standard deviation. Second, the direction traveled is randomly drawn from the uniform distribution The total distance traveled is then converted to orthogonal distancesand Distance and direction of travel are calculated independently for each virion. These distances are then used to adjust the X and Y positions of the diffusing virions, which are tracked in absolute units (µm). Cells are modeled as squares measuring 30 µm × 30 µm, and so a virion with an absolute position 0 ≤ X < 30 corresponds to cell position X = 1, one with absolute position 30 ≤ X < 60 corresponds to cell position X = 2, and so on. If a virion would diffuse beyond the border of the grid, it instead emerges from the other side (e.g. a virion that would be moved to the cell position [X = 105, Y = 69] is instead placed at the position [X = 5, Y = 69]).
Free virions may attach to the cell at their current position. While attached, virions are unable to diffuse.
Bound virions may be released, or infect the cell to which they are attached. Virions that are released become free-floating, and are able to diffuse. When virions infect a cell, the number of segments added to that cell is determined by the probabilistic model described above. The number of segments added is calculated from the binomial distributionwhere S is the number of segments the cell already contains, P P is the probability an individual segment is delivered successfully, and v is the number of virions infecting the cell at the current time-step. For example, if a cell already contains five segments, additional virions infecting it may add 0–3 segments (N = 8–5 = 3). If four virions are infecting this cell, then the probability of a given segment being delivered is high (p = 1 – (1–0.58) 4 = 0.97), and the probability of four virions all failing to deliver a given segment ((1–0.58) 4 = 0.03) is relatively low.
Infected cells (those containing 1–8 segments) may become refractory to superinfection. Diffusing virions cannot bind to nonsusceptible cells, and any currently bound virions that attempt to infect these cells automatically fail to deliver all segments.
Productively infected cells (containing eight segments) produce virions, which are initially bound to the producer cell's surface. The number of virions produced by each cell is independently drawn from the Poisson distribution with λ = Burst_Rate (962 virions day −1 or 2.06 virions time-step −1 (time-step = 3 min)). Each virion is placed at a random location on the producer cell as determined by the uniform distribution.
Productively infected cells may die. These cells lose all segments, cannot produce virions, and cannot be bound by diffusing virions.

---

### Feasibility and coexistence of large ecological communities [^02d41162]. Nature Communications (2017). Medium credibility.

Shape of the feasibility domain

So far, we have focused on the volume of the parameter space resulting in feasiblity. However, two systems having the same Ξ can still have very different responses to parameter perturbations, just as two triangles having the same area need not to have sides of the same length (Fig. 1). The two extreme cases correspond to (a) an isotropic system in which if we start at the barycentre of the feasibility domain, moving in any direction yields roughly the same effect (equivalent to an equilateral triangle); (b) anisotropic systems, in which the feasibility domain is much narrower in certain directions than in others (as in a scalene triangle). For our problem, the domain of growth rates leading to coexistence is — once the growth rates are normalized — the (S −1)-dimensional generalization of a triangle on a hypersphere. For S = 3, this domain is indeed a triangle lying on a sphere as shown in Fig. 1. If all the S (S −1)/2 sides of this (hyper-)triangle are about the same length, then different perturbations will have similar effects on the system. On the other hand, if some sides are much shorter than others, then there will be changes of conditions which will more likely have an impact on coexistence than others. We therefore consider a measure of the heterogeneity in the distribution of the side lengths (Fig. 1 and Supplementary Note 10). The larger the variance of this distribution, the more likely it is that certain perturbations can destroy coexistence, even when Ξ is large and the perturbation small. This way of measuring heterogeneity is particularly convenient because it is independent of the initial conditions. Moreover, the length of each side can be directly related to the similarity between the corresponding pair of species (Supplementary Note 10), drawing a strong connection between the parameter space allowing for coexistence and the phenotypic space. As in the case of Ξ, this measure is a function of the interaction matrix and corresponds to a geometrical property of the coexistence domain.

---

### Experimental and theoretical model for the origin of coiling of cellular protrusions around fibers [^88a2d3a2]. Nature Communications (2023). High credibility.

The above equation indicates that when the proteins are distributed inhomogeneously, there will be a net force on the vesicle in a particular direction. However, in the present work, we only simulate vesicles that are adhered to fibers that are fixed in their location, which effectively links our vesicle to the lab frame, thereby restoring momentum conservation (fixing the fibers' position acts as an infinite momentum reservoir). In the cell, the polymerizing actin filament at the leading edge are linked by adhesion molecules to the fibers, thereby converting their polymerization dynamics into an effective protrusive force. This process is implicitly assumed in our model, and is not described explicitly.

Finally, the adhesion energy is given by, where E a d is the adhesion energy per adhered vertex, and the sum runs over all the vertices that are adhered to the fiber. By "adhered vertices", we mean all such vertices, whose perpendicular distance from the surface of the fiber are less than ϵ. We choose ϵ to be equal to the length l m i n, which is the unit of length in our model, and defines a minimal length allowed for a bond. Thus, the total energy of the vesicle-fiber system is given by,

We update the vesicle with mainly two moves, (1) vertex movement and (2) bond flip. In a vertex movement, a vertex is randomly chosen and attempt to move by a random length and direction, with the maximum possible distance restricted by 0.15 l m i n. In a bond flip move, a single bond is chosen, which is a common side of two neighboring triangles, and this bond is cut and reestablished between the other two unconnected vertices. The maximum bond length is restricted to l m a x = 1.7 l m i n. The choice of minimum and maximum bond length is to respect the self-avoidance of the triangulated network. We update the system using Metropolis algorithm, where any movement that increases the energy of the system by an amount Δ W occurs with rate, otherwise it occurs with rate unity.

---

### Memory of cell shape biases stochastic fate decision-making despite mitotic rounding [^9789b815]. Nature Communications (2016). Medium credibility.

We built the framework as shown in Supplementary Fig. 3b, where three components were added to the basic CPM model: particle initialization (Supplementary Fig. 3c); particle attachment to cell boundary (Supplementary Fig. 3d); and random walking particle (Supplementary Fig. 3e). The initial cell shapes were defined according to the confocal images of real V2 cells. The cubic lattice sites that compose the virtual 3D cells have sides of length 0.5 μm, which is close to the voxel size (0.42 μm × 0.42 μm × 0.89 μm) of the confocal images. Cell boundary lattice sites are defined as lattice sites adjacent to the surrounding environment (Supplementary Fig. 3c, second left). To distribute the initial particles according to the cell shapes, a boundary lattice site (sitein Supplementary Fig. 3c, second right) is randomly picked up and the distance d 1 from the centre of mass of the cell is calculated. Next, a second lattice siteis selected at random from the all lattice sites, and the distance to the origin, d 2, is calculated. If d 1 > d 2, a particle is generated at site(Supplementary Fig. 3c, second right). Probability of particle generation at siteis roughly proportional to d 1 3 because the probability is given by the volume of eighth part of a sphere of radius d 1 in the lattice space. This can make polarized distribution of particles according to asymmetry of cell shape. Particles are generated until the number designated is reached (Supplementary Fig. 3c, rightmost). After the simulation starts, cell boundary and particles' position are updated after every successful copy attempt (Supplementary Fig. 3d). If a particle is no longer on a boundary lattice site, it will step to one of nearest boundary lattice sites with equal probability. After each mcs, the particles diffuse (Supplementary Fig. 3e). For isotropic diffusion behaviour, a particle moves to one of available lattice sites with equal possibility. The available lattice sites should satisfy two requirements: (1) they should be on current cell boundary; and (2) the distance to them is in the range (s− 0.5 × L, s+ 0.5 × L), where s is step size of diffusion and L is lattice site length.

---

### Invariance properties of bacterial random walks in complex structures [^031312fd]. Nature Communications (2019). High credibility.

The effect of size and shape

We have demonstrated that, for a fixed shape, the density of obstacles has a strong effect on the distribution of path lengths while leaving the mean value unchanged as long as the total internal accessible area remains the same.

We will now investigate the effects of shape and size on the path length distributions and again conclude that, although path distributions are very sensitive to the detailed geometry of the domain, mean path lengths and residence times can be accurately predicted using only the surface to perimeter ratio. We fabricate microstructures of circular, squared and triangular shapes all in four different sizes as shown in Fig. 2a. In all structures the obstacle density is fixed to N / S = 0.016 μm −2. All recorded trajectories are also plotted in Fig. 2a with a color map encoding the scaled path length L /. In Fig. 2b we plot for each structure the histogram of path lengths normalized by the expected valuein Eq. 4. As we move from circles to squares and then to triangles we observe that the corresponding histograms are characterized by larger frequencies for both short and long path lengths. The probability of short paths increases as we introduce convex corners and reduce their angle, as evidenced by the blue-violet color of the corners in squared and triangular structures. The presence of longer paths in triangles can be also understood noting that the normalized maximum straight paths for circles, square and triangles are respectively 4/ π,/ π and/ π (see Supplementary Fig. 2). Despite these qualitative and quantitative differences between histograms, mean path lengths are always close to 1 when normalized by the predicted valueas shown in Fig. 2b. The observed path length distributions can be very well reproduced by a Lorentz gas model where collisions with obstacles are described as instantaneous reorientation events. These events are assumed to occur with a constant probability per unit path length given by, where/ π is the rotational average cross section of line obstacles with length b (see Methods). For perfectly straight trajectories, circles and squares have path length distributions with a vertical asymptote. A strong peak is found at the location of this divergence and is progressively smeared as the linear size of the domain becomes larger than the mean free path. Upon increasing the size of the region a peak aroundappears due to bacteria that scatter close to the boundary, reorient and exit. The mix of these two types of trajectories gives rise to the observed double-peak structure. Differently for the triangle no asymptote is present in the P (L) for large λ, therefore only a peak atprogressively appears. These results show that P (L) depends strongly on the random walk properties (as the mean free path), and on the domain features (shape and size). Differently the mean valuesanddepend only on the surface to perimeter ratio of the domain as expressed by Eq. 4. Experimental values ofare shown Fig. 3a for all shapes and sizes. We find an excellent agreement with theory using the same value s = 6.3 μm 2 that was used previously to predict the experimental values ofas a function of the number of obstacles (see Fig. 1c). This value of s has also been used to calculateaccording to Eq. 5 which captures quantitatively well the experimental data as shown in Fig. 3b.

---

### Altered grid-like coding in early blind people [^933b025c]. Nature Communications (2024). High credibility.

Clock-Navigation experiment stimuli

Experimental paths were designed using AutoCAD (v2019), calculating the angle created by each line that connected each number on the clock, represented by the vertex of a dodecagon, to all the others. Repeated paths (e.g. from 9 to 12 and from 12 to 9), paths connecting two adjacent numbers (e.g. from 1 to 2), and those that traverse the center of the space were discarded, resulting in a set of 36 unique paths. Twenty-four path combinations were chosen, ensuring that all the degrees ranging from 15° to 360°, in steps of 15°, were represented, and each number from 1 to 12 was used as starting or ending location an equal number of times (four times per number). We computed the length of each path as the difference between the starting and the target numbers (e.g. from 9 to 12: 9–12 = 3), resulting in three different path lengths: (i) Short (distance between numbers: 3); (ii) Medium (distance between numbers: 4) and (iii) Long (distance between numbers: 5) and balanced it within each run so as to have six short paths; six long paths and 12 medium paths.

Instructions were delivered auditorily to participants (48,000 Hz, 32-bit, mono), and each number was recorded in both a feminine voice and a masculine voice using an online speech synthesizer. The average intensity of all the auditory words was thresholded and equalized at 60 dB using Praat 6.1.01.

---

### Covalently-assembled single-chain protein nanostructures with ultra-high stability [^2bd312f3]. Nature Communications (2019). High credibility.

Coarse-grained simulations of protein nanostructures

We developed a phenomenological, rods-and-springs coarse-grained model to perform simulations of triangular and square nanostructures. A schematic of the model for triangular nanostructures is shown in Supplementary Fig. 10. In the rod-and-springs representation, residues 6–238 of 3HB are modeled as rigid rods. These rods are of fixed length 114.32 Å, which corresponds to the distance between the two alpha carbons of residues 6 and 238 in the 3HB crystal structure. The rigid rod model is based on the assumption that the rod is not significantly distorted when compared to the flexible tethers, at least on experimentally relevant time scales. The linkers are modeled as Gaussian chains with an elastic energy written in terms of a harmonic potential:note the factor of 2, which is appropriate given that the dimensionality is 2 for planar structures. Here, R 0 is determined by regression analysis where a second-order polynomial f (x) = A –3(x / R 0) 2 is used to fit the PMF written in terms of the end-to-end distances extracted from atomistic simulations. The regression analysis yields linker specific values for R 0 and these are used in the coarse-grained simulations.

Starting from an initial default structure, which is an equilateral triangle or square with side length of 114.32 Å, a MC procedure was used to equilibrate the system. At each MC step, one side is randomly picked among three and tilted by a random angle variable that follows a Gaussian distribution of mean 0 and standard deviation 0.1°. Then the tip-to-tip distance x is converted into the Gaussian chain energy E (x). The Gaussian chain energy is calculated for every linker, and the system energy is obtained by a simple sum of all 3 or 4 linker contributions. If the trial move gives lower energy, the program accepts the move. Otherwise, it accepts the move according to the Metropolis MC criterion. We performed 100 independent simulations for triangular structures, each of which consists of 10 7 MC steps, and the coordinates were registered every 10 4 steps, discarding the first 5 × 10 5 steps. For square structures, we also performed 100 simulations, but the step number was increased to 10 9 and we discarded the first 10 8 MC steps. The distributions of bending angles were constructed from the coordinate information, from which the standard deviation was also calculated.

---

### Degenerate boundaries for multiple-alternative decisions [^55f4a482]. Nature Communications (2022). High credibility.

Sequential Bayesian inference can be rewritten in a form that more closely resembles a sum of evidence by taking the logarithm of equation (8):For each of the n -choices, the accumulated evidence is the log posterior, with n distinct evidence incrementsand a common subtractive log-marginal term. Calculation of this log-marginal is necessary for multiple (n > 3) choice optimal decision-making, but can be avoided for n = 2 by using the SPRT as mentioned above. A similarterm in a theory of basal ganglia function has been interpreted as suppressing evidence accumulation when choices are ambiguous –.

Within this framework, using that probabilities sum to unity ∑ i P i (t) = 1, the evidence accumulation takes place within an (n − 1)-dimensional linear subspace spanning n vertices { P i = 1, P j ≠ i = 0} of an N -dimensional unit hypercube. This is most easily seen for N = 3 choices, where the decision variables P = (P 1, P 2, P 3) vary within a triangle passing through three vertices {(1, 0, 0), (0, 1, 0), (0, 0, 1)} of the unit cube (Fig. 1, top right panel). So rather than representing evidence accumulation trajectories as a random walk constrained to two dimensions, for multiple alternatives the random walk moves in higher dimensions (a line for two alternatives, a plane/triangle for three, and so on). For simplicity, this vector is initialized with equal prior probabilities 1/ n and updated sequentially until one of the elements reaches a boundary, P i > θ.

Both the SPRT and two-choice sequential Bayesian inference give optimal decisions in that they give the fastest decisions for a given level of accuracy on single trials of known difficulty. Formally, they optimize a cost function, the Bayes risk, that is linear in the mean error rate e and mean decision time T over many trialswith error costs W i > 0 and cost of time c, scaling the expected error and decision time,… This cost function represents the trade-off between speed and accuracy of decision-making: slow but accurate or fast but inaccurate decisions are both costly, and so a balance must be found. For equal decision costs, W 0 = W 1, there is a single threshold that is free parameter, which for optimal decision-making is tuned according to the relative cost c / W of accuracy and time.

---

### Entorhinal grid-like codes and time-locked network dynamics track others navigating through space [^32a2110e]. Nature Communications (2023). High credibility.

Modified navigation task: determining chancel level performance with permutation testing

To determine whether participants performed better than chance (i.e. whether they were able to re-trace the demonstrator's paths more accurately than a random agent), we performed permutation-based testing. We pooled all paths that were presented to participants during the observation period, randomly selected paths, and simulated the performance of a "random agent". That is, we randomly chose three endpoints (for each of the three path segments) out of all possible endpoints along the circumference of the movement area (spanning the circular border in 1°-degree steps). We then calculated the Euclidean distance between each randomized endpoint and the "correct" endpoint of a specific path segment that was selected from the pool of possible paths, averaged across the three error distances, and accumulated a permutation distribution by iterating over these steps 5000 times (Fig. 1d). We then determined the performance value (cumulative distance error, vm) at the 5th percentile (39.3 vm), representing the chance level of a random participant. Finally, we tested whether the observed group performance was below this permutation-based chance level using a one-sample t -test.

---

### Phase information is conserved in sparse, synchronous population-rate-codes via phase-to-rate recoding [^694b756e]. Nature Communications (2023). High credibility.

To model phase precession, we adapted an approach using the linear distance of the mouse to the closest grid vertex and the direction of travel, combining it with the generated grid profiles. To this end, we used the formula previously used to obtain g w (x, y) to also calculate the relative linear distance to the closest grid vertex d (x, y) using Eq. (2).whereis the maximal firing rate of grid fields, and λ is the spacing of a given grid cell (see above).

A virtual trajectory at 20 cm/s now corresponds to a mapping of time (t) to position (x, y), such that we could calculate a spatial rate profile r G (t) from g w (x, y) and d(t) from d(x, y) for each grid cell over the course of the trajectory. To make phases precess monotonically during the traversal of a grid field, d(t) was multiplied by −1 if the mouse was leaving a grid field.

This allowed us to calculate phase precession patterns within each grid field. Briefly, the relative linear distance d(t) was first transformed into a preferred theta phase φ(t), according to Eq. (3).and then used to calculate a phase-code functionusing Eq. (4).where k 1 = 1 and k 2 = 1.5 are constants which we chose to match experimental data, and θ (t) was an assumed global theta oscillation at 10 Hz. Note, that in Bush and Burgesscells display phase precession but the overall firing probability stays constant, i.e. firing probability does not increase towards the middle of a field, whereas in the present model firing probability increases towards the middle of a field.

Finally, the phase precessing spike rate profile (r φ, G) for each grid cell was generated according to Eq. (5).scaled to obtain instantaneous firing rates consistent with experimental observations. Individual spike trains were generated by using an inhomogeneous Poisson process based on the calculated spike probability profiles (Elephant package). To produce the phase precession plots shown in Fig. 1 individual trajectories were simulated with random Poisson seeds 1000 times.

---

### A non-spatial account of place and grid cells based on clustering models of concept learning [^7c3febb5]. Nature Communications (2019). High credibility.

Due to the asymmetrical shape of the trapezoid environment, the procedure for generating a movement trajectory above leads to a slightly biased sampling of the wide part of the trapezoid, and less exploration of the middle and top parts of the shape. To deal with this, we made a slight change to the possible steps after generating a step that brings the agent out of the environment, described below. For each trial, the step was generated as before. If the generated step was out of the environment, the step was cancelled, and the next step was determined as follows. If the step generated would have brought the agent out of the bottom of the trapezoid, the next step was sampled from [0, 0, 1, 1] (stay or up). If the step brings the agent out to the top, the next step was sampled from [−1, −1, 0, 0] (down or stay). When the step takes the agent out of the left of the trapezoid, then the next step to be sampled on the horizontal axis were [0, 1, 1, 2, 4], towards the inner portion of the environment. If the step took the agent out of the right side of the trapezoid, the next step was generated as before, from [−4, −2, −1, −1, 0, 1, 1, 2, 4]. This is because when the agent is out of the trapezoid on the horizontal (left-right) axis, the agent could still be in the middle of the shape on the vertical axis, since the shape becomes more narrow as it reaches the right. Finally, when it lands exactly in the middle of the horizontal axis, but is out of the shape (on the horizontal axis), the next step to be sampled from on the vertical axis is [−1, 0, 1].

Reporting summary

Further information on research design is available in the Nature Research Reporting Summary linked to this article.

---

### Arrays of individually controlled ions suitable for two-dimensional quantum simulations [^178267d1]. Nature Communications (2016). Medium credibility.

A precisely controlled quantum system may reveal a fundamental understanding of another, less accessible system of interest. A universal quantum computer is currently out of reach, but an analogue quantum simulator that makes relevant observables, interactions and states of a quantum model accessible could permit insight into complex dynamics. Several platforms have been suggested and proof-of-principle experiments have been conducted. Here, we operate two-dimensional arrays of three trapped ions in individually controlled harmonic wells forming equilateral triangles with side lengths 40 and 80μm. In our approach, which is scalable to arbitrary two-dimensional lattices, we demonstrate individual control of the electronic and motional degrees of freedom, preparation of a fiducial initial state with ion motion close to the ground state, as well as a tuning of couplings between ions within experimental sequences. Our work paves the way towards a quantum simulator of two-dimensional systems designed at will.

---

### A scaling law for random walks on networks [^21786533]. Nature Communications (2014). Medium credibility.

For each basin, we then analysed the exit dynamics in the following way. First, we created a new random walk by selecting as nodes only those within the basin, plus an additional END node. A step from from node i to node j within the basin was assigned the same probability as in the original walk. If, in the original walk, node i allowed steps outside of the basin, then we added an arc from i to END with stepping probability equal to the sum of those original outside steps. The node in the basin with highest steady-state probability (under the original walk) was designated as the START node. We then analysed paths from START to END as in all other examples.

---

### Two simple movement mechanisms for spatial division of labour in social insects [^5b15ccc2]. Nature Communications (2022). High credibility.

From movement patterns to spatial segregation: agent-based modelling

We next developed an agent-based simulation model for individual movement, to (i) assess whether the three candidate mechanisms make distinct predictions for individual movement, and (ii) test whether the two local movement mechanisms locomotion adjustment and boundary effect are sufficient to explain the observed spatial segregation between task groups (see Supplementary Note 13 for detail). All simulations were based on a simple correlated random walk model, which was modified to include one or more of the three movement mechanisms presented above, and parameterised using tracking data from each species (Table S 6). Figure 9 a, b illustrates the concepts underlying our modelling approach for each of the three mechanisms.

Fig. 9
Agent-based modelling of individual movement.

a All simulation trajectories were based on the correlated random walk (CRW) model. A CRW trajectory is constructed from a sequence of vectors, produced by randomly drawing a step length L and a turn angle θ from an exponential and a wrapped normal distribution, respectively. b The upper map represents the nest grid upon which trajectories are simulated. The nest includes two overlapping 'spatial modules' (central and peripheral), characterised by a 'distance score' increasing non-linearly with the distance of each site to the nest centre. To model the three movement mechanisms, the CRW is modified as follows. In the focal-point attraction model (point I in map), the CRW vectoris modified by adding a bias vector, which points towards the closest point on the border of the individual's primary module (magenta cell). In the boundary effect model (points II–III), the CRW is modified in the vicinity of the module boundary by increasing (decreasing) the CRW turn angle by σ when approching the boundary from the inside (outside). In the locomotion adjustment model, the L and θ distributions are modified according to location, so individuals make shorter (larger) steps and larger (smaller) turns when inside (outside) their primary module (points IV & V, green & orange distributions, respectively). c Comparison between empirical and simulated trajectories. Grouped columns indicate the five movement metrics described in the main text, and letters below individual columns give species name abbreviations. Formulas provide a brief description of the statistical model conducted for each movement metric, and cell colours encode the sign and value of the coefficient of the predictor in the statistical model (see text for the model definitions). To facilitate comparisons within metrics, the coefficients are normalised by the maximum absolute value of all coefficients for each metric. Source data are provided as a source data file.

---

### The computational neurology of movement under active inference [^15b371cc]. Brain (2021). Medium credibility.

The lower (discrete) level of this generative model involves much more temporal and spatial detail than the higher level but covers shorter periods of time. This means that the target location is now static, as it only changes over the slower scale prescribed by the higher (discrete) level. The increased spatial resolution at the lower level affords the opportunity to represent spatial locations that are intermediate to those of the three target locations. These are shown as small red spheres. For each short trajectory at this level, the higher level specifies a starting location (via D) and a direction of travel (E) that influences the transitions (B). For visual clarity, we have not shown all the possible transitions between the (red) attracting points. In brief, one policy leads to a clockwise transition, one to an anticlockwise transition and one to a static transition (i.e. attracting point stays in the same location). Each of the locations at the lower level, indicated by the red spheres, maps to an attracting point (v 1,2,3) in the continuous model in Fig. 1. Similarly, the shading of each of the target spheres maps to the continuous representation of target colours (v 4,5,6). There is one other outcome of the categorical levels of the model that never reaches the continuous model (i.e. is conditionally independent of it). This is whether the hand position and the target position match or whether the hand has not yet reached the target. By setting a prior belief (C) that the correct hand position will be achieved, the course of action most likely to fulfil this attains a higher plausibility. Note that this is not used as a prior over outcomes at the level of inference about outcomes but as a prior belief about the consequences (on average) of policies. In other words, it is used as if it were a parameter of the prior over policies. The prior over policies includes both E and G, where G is a function of C. The C -vector may be thought of as a parameter of the prior belief over policies. However, it is an interesting quantity, as it could be thought of as a prior itself. The key idea here is that we specify a prior (C) over observations, that is the Bayesian model average under all policies (weighted by their respective probabilities). In place of specifying the probability of each policy and then finding this average, we specify this average and use this to express a prior over policies that would realize this (when an information theoretic bound is minimized). This is almost the opposite approach to the use of a free energy bound to approximate a marginal distribution over outcomes, as it starts from the distribution over outcomes and finds an expected free energy that defines a distribution over policies.

---

### Conserved linear dynamics of single-molecule brownian motion [^a1816615]. Nature Communications (2017). Medium credibility.

Simulation of a single-molecule random walk

The simulated trajectories were constructed using a routine written in Matlab starting at (x, y) = (0,0). The random step sizes were generated using a distribution function (R) expected from the normal diffusion theory of a Brownian particle:

where r and Δ t denote the step size and the time lag, respectively. The step directions (angles between successive displacements) were generated based on random angles between 0 and 360°.

Probability of square lattice occupancy

We performed lattice occupancy analyses of the diffusion trajectories using a routine written in Matlab (Supplementary Data 1, Supplementary Note 2). The spatial positions obtained from the tracking algorithm were mapped onto a square lattice of side-length (m), which equalled the pixel size of the camera (m = 0.16 μm). The experimental probability was fitted to equation (4) to calculate the P 25 value.

Detrended fluctuation analysis

For the DFA to be statistically robust, we joined the single-molecule trajectories end-to-end. The combined trajectories of both the DNA and the nanospheres have an approximate length of N = 30,000 Δ t. The DFAwas performed using a routine written in Matlab (Supplementary Note 2). We generated integrated time series of P 25 (P 25 (k) (k = 1,2, …, N)), Z (i) by subtracting the mean P 25 value (〈 P 25 〉)5 and integrating the time series:

The profile Z (i) of length N was then divided into non-overlapping segments (s) of equal size (l). The local trend in each segment (Z l (i)) was calculated by subtracting the linear fit of the data:

---

### Mouse tracking reveals structure knowledge in the absence of model-based choice [^3f9beb1b]. Nature Communications (2020). High credibility.

Fig. 3
Mouse-tracking results: stochastic task.

a Ballistic mouse trajectories in the stochastic task. Each colored line represents the average cursor path between a top fractal and a bottom fractal for a specific transition probability (yellow = 0.9, green = 0.8, light blue = 0.7, dark blue = 0.6). For illustration, we only present the paths between fractals on the same side of the screen, in cases where subjects' predictions were correct. We only measure the cursor's starting point and the point at which it crosses the line, connecting those two points with a straight line. b Individual subject estimates in the stochastic task. In blue: distance towards the correct (common transition) side of the screen (in pixels), in increasing order (error bars represent s.e.m. based on N = 400 trials for each subject). In orange: inverted regression-coefficient measure of model-based behavior from Fig. 2a-c (in arbitrary units, with positive values denoting more model-based behavior, errors bars represent standard error of the regression coefficient of each individual subject based on N = 400 trials). Source data are provided as a Source Data file.

In line with the behavioral results and our mouse-tracking hypothesis, in the deterministic task, subjects' cursors were significantly different from zero for every pattern (two-sided t -tests, Cohen's d = 1, t(51) = 7.2, Cohen's d = 1.48, t(55) = 10.8, Cohen's d = 1.38, t(54) = 10.2, Cohen's d = 1.45, t(55) = 10.8, all p < 0.0001), and farther in the correct direction (i.e. towards where the fractal actually appeared) for easier patterns (Fig. 4a; mixed effects regression, pixels per pattern (s.e. 5.7), t(51) = 2.8, p = 0.006). Moreover, mouse movements were significantly correlated with w for the deterministic task (r = 0.57, t(55) = 5.15, p = 4, Supplementary Fig. 1). Thus, mouse position did appear to track subjects' learning.

---

### The computational neurology of movement under active inference [^dd0d84f5]. Brain (2021). Medium credibility.

Figure 3
Discrete generative model for movement planning. This schematic illustrates the hierarchical discrete state-space generative model that sits above the continuous model shown in Fig. 1. This model generates the hidden causes (v) that are the (imaginary) attracting points and the target locations from the perspective of the continuous model, which effectively induce movement. The discrete (categorical) causes that generate these come in two forms: the alternative attracting points (red spheres) that act as equilibrium points, and which of the three possible target locations is currently specified. These causes are themselves generated by states at a higher level. At the highest level (upper left) we have a set of alternative combinations of trajectories. Each of these is defined in terms of which vertex of a triangle (i.e. target location) is at the start and end of that trajectory. There are three configurations not shown that represent a single vertex of the triangle being the start and end of a trajectory (i.e. a static 'trajectory'). In addition, the higher level includes a replica of the three possible target states (upper right). However, while these are considered static at the timescale of the lower level, the slower dynamics of the higher level allow this to change over time. The key distinction here is the absence of arrows between alternative target configurations at the first level. The C -vector represents the statistics of a prior belief that policies will lead to correct outcomes (i.e. hand and target location match). This ensures sequences of actions that lead to the realization of this goal are more plausible than those that do not. The arrows within a level indicate the allowed transitions (encoded by B) between these configurations. The arrows between levels show the generation of lower level variables by higher level variables. This rests upon generation of a discrete outcome via A (2), which is then used to generate policies [via E (1)] or initial states [via D (1)]. The role of D (2) is to provide a prior belief about the initial states at the higher level. Note that, if we were to extend this model to include further levels, this would also become an empirical prior, recapitulating the role of D (1). However, given that Level 2 is the highest level considered here, D (2) is simply a vector of prior probabilities. This says that the target states may be in any initial configuration with equal probability and that the initial state probability is equally distributed among any of the trajectories that start at the lower-right target.

---

### Using grid cells for navigation [^f5d9ba0e]. Neuron (2015). Low credibility.

Algorithmic Solution in 1D

The cyclical nature of the grid representation within each module i is such that an activity bump at phase p i implicitly represents an infinite set of "unwrapped" phases p i + 2 πn i, where n i can take any integer value, corresponding to an infinite set of distances s i (p i /2 π + n i) along that 1D axis that are separated by the scale s i of module i. Initially, we assume that all phases are zero at the current location a and the distance d to a goal location b must be inferred from the grid cell representation across modules at that location { p i (b)} = { p 1 (b), p 2 (b), …, p M (b)}. The grid representation of the goal location b is such that there is a set of unwrapped phases (one for each module) that explicitly represent the same distance — i.e. there is a set of integers { n i } for which:

Graphically, this coherent set of unwrapped phases across modules falls on a horizontal line when plotted against a y axis of represented distance (i.e. y = d; Figure 4 A) or, equivalently, on a straight line through the origin when plotted against a y axis of phase against inverse grid scale (Equation 2; Figure 4 B) — i.e. there is a set of integers { n i } for which:

This latter relationship is obtained by re-arranging Equation 1 and corresponds to the Fourier shift theorem (see discussion of the Algorithmic Solution in 2D below;). Thus, the distance d to a goal location represented by the set of module phases { p i } can be inferred by fitting a straight line through the origin on a plot of unwrapped phases p i + 2 πn i against inverse grid scale 1/ s i across modules (Figure 4 B). Moreover, this result can be generalized to any pair of arbitrary current and goal locations on that 1D axis, by replacing the absolute phase p i at the goal location with the phase difference Δp i between grid cell representations of current and goal locations in each module (Equation 3):

---

### Statistical moments of quantum-walk dynamics reveal topological quantum transitions [^f3fc0e4d]. Nature Communications (2016). Medium credibility.

Many phenomena in solid-state physics can be understood in terms of their topological properties. Recently, controlled protocols of quantum walk (QW) are proving to be effective simulators of such phenomena. Here we report the realization of a photonic QW showing both the trivial and the non-trivial topologies associated with chiral symmetry in one-dimensional (1D) periodic systems. We find that the probability distribution moments of the walker position after many steps can be used as direct indicators of the topological quantum transition: while varying a control parameter that defines the system phase, these moments exhibit a slope discontinuity at the transition point. Numerical simulations strongly support the conjecture that these features are general of 1D topological systems. Extending this approach to higher dimensions, different topological classes, and other typologies of quantum phases may offer general instruments for investigating and experimentally detecting quantum transitions in such complex systems.

---

### Nanoscale visualization of functional adhesion / excitability nodes at the intercalated disc [^3ae54a7a]. Nature Communications (2016). Medium credibility.

The height of the space was set to 16 to make it large enough so that edge effects would not affect the results. The total volume represented by the rectangular cuboid was then measured as

To take a particular example, parameters for the ligate–ligand interaction were those previously measured for the interaction between Calmodulin (CaM) and the C-terminal domain of Na V 1.5. Based upon a concentration of 6 μM for CaM, the number of molecules placed in the cuboid with the above volume was calculated as 2,127. The number of Na V 1.5 channels placed on the surface of the cuboid was set at 44 based on the patch clamp data from this study. The channels were positioned in both clustered arrangement and an equally distributed arrangement at the surface position (Supplementary Fig. 6). The CaM molecules were initially randomly arranged in the cuboid and then at each time step were allowed to move with equal probability to any adjacent position, with the exception of a particle immediately adjacent to a Na V 1.5 channel, as explained below. In addition, particles were allowed to bind if occupying the same position as a Na V 1.5 channel, and also to dissociate if currently bound to a channel. Two variables naturally occurred in the system: (1) the probability that a CaM molecule will bind to a Na V 1.5 channel once it occupies the same position; and (2) the probability that a CaM molecule will dissociate from a Na V 1.5 channel once bound. A third variable was also introduced, an 'attraction factor': when a CaM molecule was one step away from an adjacent Na V 1.5 channel, this attraction factor increased the probability that the particle would move to a position containing the channel. This variable represented the fact that modulators of Na V 1.5 can be brought into proximity by common molecular partners. Since the actual values for these probabilities were unknown, simulations were run with an array of probabilities for the binding and dissociating variables to determine which combinations would produce K d measurements near the average of experimentally measured value of 88 nM (apoCaM) and 132 nM (Ca2+/CaM) for the CaM Na V 1.5 complex. The random walk was performed with 500 time steps, this being adequate to produce a stable system. Once an appropriate set of probabilities were determined, for both the presence and absence of the attraction factor, the random walk simulations were run 1,000 times for each combination and the two distribution scenarios for the Na V 1.5 channels were compared. The coding for these simulations was written in Python, utilizing the package matplotlib for the initial visualization of simulation results.

---

### Complex behavior from intrinsic motivation to occupy future action-state path space [^15c868fd]. Nature Communications (2024). High credibility.

We finally introduced a slight variation to the environment, where the right half of the arena has stochastic state transitions, to showcase the ability of MOP to model risk-sensitive agents. Here, when agents choose an action (force) to be executed, a state transition in the desired direction occurs with probability 1 − η, and a transition corresponding to zero force occurs with probability η (Fig. 4 d). Therefore, a MOP agent that seeks state entropy (β > 0) will show a preference for the right side, where there is in principle higher state entropy resulting from the stochastic transitions over more successor states than on the left side. Indeed, we find that MOP agents spend more time on the right side as β increases, regardless of the probability η (Fig. 4e). For fixed γ, spending more time on the right side can bring the life expectancy to decrease significantly depending on β and η (Supplemental Fig. E.2d, e). Interestingly, for β > 0 there is an optimal value of the noise η that maximizes the fraction of time spent on the right side (Fig. 4f), which is a form of stochastic resonance. Therefore, for different β, qualitatively different behaviors emerge as a function of the noise level η.

MOP agents can also seek entropy of others

Next, we considered an example where an agent seeks to occupy path space, which includes another agent's location as well as its own. The agent can freely move (Fig. 5a; gray triangle) and open or close a fence by pressing a lever in a corner (blue triangle). The pet of the agent (green triangle) can freely move if the fence is open, but when the fence is closed the pet is confined to move in the region where it is currently located. The pet moves randomly at each step, but its available actions are restricted by its available space (Supplemental Sec. E.6).

Fig. 5
Modeling altruism through an optimal tradeoff between own action entropy and other's state entropy.

---

### Collaborative strategy on bed bugs [^3ea9e28a]. CDC (2015). Medium credibility.

Bed bug management when elimination is not feasible — containment and reduction steps: when complete elimination is not feasible, people living or working in an infested area can take steps to prevent the spread of this pest to new areas within the community and strive to reduce the bed bug population(s) as much as possible given the characteristics of the infested site, and in this way, local efforts in even the most difficult cases can contribute to the management of bed bugs throughout the community.

---

### Collaborative strategy on bed bugs [^7ddddf4c]. CDC (2015). Medium credibility.

Bed bug biology and inspection targets for integrated pest management (IPM) highlight that research into basic bed bug biology and behavior shows certain characteristics are common to all bed bugs and that focusing detection efforts on these characteristics can help reduce costs, including that the majority of bed bugs are found in or near sleeping and resting areas and as an infestation grows within an apartment or home, bed bugs will travel to other locations, making it more difficult, time consuming and expensive to pinpoint every infested area; because bed bugs can move between housing units, the best IPM practice is to inspect adjacent areas or units, units above and below the infested unit, and units across the hall, and if a unit is vacant, bed bugs may behave differently (for example, by becoming inactive or more active during the day) while waiting for a new host to arrive; although not preferred hosts, pets and rodents serve as alternate hosts in some circumstances and having these additional hosts can greatly increase the chances of the bugs' survival.

---

### CoCASA version history… [^cd126a94]. CDC (2025). Medium credibility.

- Check the box next to the first assessment. Since you can only merge assessments performed on the same day for the same provider that all have the same antigens, all of the assessments that are eligible to be merged with the first selected assessment will be highlighted in yellow. Check the box next to any of those yellow-highlighted assessments that you wish to merge together. Bug fixes
- The NDC codes were incorrect on the code mapping report.
- Null string errors and DBNull errors during import from a text file were corrected.
- Resetting the display scale and layout to greater than 100% would cause certain fields on the Assessments screen to be inaccessible. The fields were rearranged and a scroll bar was added. Bug fixes
- After deleting an assessment, the tree should be positioned to the next assessment if there is one.
- Fixed a bug on the Coverage Levels tab where the values for HepA were incorrect when Influenza was also selected for the assessment.
- The discard message on the dose entry screen should behave as expected when leaving the page. Version 14. 3 changes Design changes
- An assessment can now be drag/dropped from one provider on the Provider tree to another, essentially moving the assessment to another provider.
- The dose entry process was revamped to expedite manual data entry.
- The antigens can now be re-ordered on the Assessment panel by selecting them in the desired order. The antigens on the Dose Entry panel will then be displayed in the same order.
- The Tab key will now progress to the next dose, and the Return key will position to the next line.
- Dates will be re-sorted on an antigen row at the time when the cursor leaves a date box.
- The antigens can now be re-ordered on the Assessment panel by selecting them in the desired order. The antigens on the Dose Entry panel will then be displayed in the same order.
- Change the Influenza algorithm such that if dose 1 of the season was either the 1 stor 2 nddose of life then another dose is needed in that season. This header displays the number of patients entered into CoCASA for assessment. Included the word "Database" in association with CoCASA & DB versions on the application's main screen. The use of "DB" was confusing to users; therefore the word "Database" has been added to the version titles. Bug fixes None.

---

### Wilderness Medical Society practice guidelines for prevention and management of avalanche and nonavalanche snow burial accidents [^562cd8c2]. Wilderness & Environmental Medicine (2017). Medium credibility.

Probe line techniques in organized avalanche rescue — After completion of an initial search using a transceiver or in situations with buried victims without transceivers, a probe line should be initiated, and professional rescue teams must maximize probe line efficiency; the first probing depth should be restricted to 1.5 m, which would reach the depth of 88% of victims who were recovered alive in the United States and 95% of those recovered alive in Switzerland; the probe technique should follow the Three Holes per Step method, which has been shown to be 30% faster than standard coarse probing, with a rescuer inserting the probe 3 times: 20 cm to the rescuer's left, center, and right before taking a step forward; Slalom probing uses 3 areas 50 cm apart; a 50 x 50 cm grid may offer the best probability of detection; Recommendation: For probe lines, initial probe pass should be limited to a depth of 1.5 m using Three Holes per Step or Slalom Probing methods to cover a 50 x 50 cm grid. Grade: 1C.

---

### Spatial organization of bacterial populations in response to oxygen and carbon counter-gradients in pore networks [^04f880a3]. Nature Communications (2018). Medium credibility.

Table 1
Parameters used in the mathematical model and their source reference

Cells can divide if reaching a mass at division where all properties are inherited and cell mass is divided approximately equally. Cells die if their mass reaches a critical value and are removed from the simulation.

Bacterial motility is simulated as a biased run-and-tumble mechanismincluding chemotaxis towards multiple nutrient and oxygen sources. In each iteration, the probability of tumbling for individual cells is calculated by Eq. 5, where p is the tumbling probability, p 0 is the tumbling probability in the absence of chemical attractors or repellents, χ is chemotactic sensitivity, v the cell swimming velocity, μ max the maximum growth rate of the species, andthe growth rate gradient with respect to the change in cell position. The calculated tumbling probability is then used to determine if the cell tumbles or not. If tumbling within a channel, there is a 50% probability to revert direction. Having reached a junction, bacterial cells are forced to tumble where a new direction is chosen at random from all connected channels

Subsequently, bacterial cells move in a straight line at a constant velocity along a channel simulating a run. Therefore, the change in bacterial cell position is calculated by Eq. 6, whereis the position vector in two dimensional Euclidean space at time point t or t +1, the cell velocity vector in direction of the channel, and Δ t the time step

Within each time step, the model first calculates chemical diffusion of substrates and consumption from the previous time step, bacterial motility, growth of bacterial cells, and new consumption, and finally checks for cell division and cell death.

---

### Collaborative strategy on bed bugs [^eec94dc2]. CDC (2015). Medium credibility.

Bed bug research — measuring progress — notes that measuring research efforts is critical to evaluating and directing research funding, and that improvements in basic research can be measured by increases in publication of research outcomes in peer-reviewed journals, new patents, shared resources that can be used by the bed bug research community, research projects that contribute to solutions, and trained bed bug biologists. It adds that improvement in applied research may be indicated by transfers of intellectual property, translation of research into operational manuals and other sources of information for those who manage bed bugs, improved, more effective products available to the public and businesses, improved communication with the public and businesses, a current baseline of the problem, comparison of the outcome of interventions to a baseline, and new strategies for detection, prevention and control.

---

### A non-spatial account of place and grid cells based on clustering models of concept learning [^b4162208]. Nature Communications (2019). High credibility.

Simulation procedure and model specifications

At the beginning of the learning phase of each simulation run, we set the number of clusters, number of learning trials, the environment (square, circle), the learning rate, and the learning update batch size. The number of clusters were set (ranging from 10 to 30) and were initiated at random locations in the environment. The shape of the environment was defined by a set of points that could be visited by the agent. The square environment was 50 by 50, where each point was a location specified by a value on the x- and y-axis. The circular environment was defined by drawing a circle in Matlab with a radius of 50, and selecting the points within the bounds of the circle. The starting position and movement trajectory of the agent was then determined as a random walk over one million trials. The agent started at a random position and steps in the horizontal and vertical axes were computed separately. On each trial, the agent could go up, down, or stay on the vertical axis, and left, right, or stay on the horizontal axis. The step was sampled from [−4, −2, −1, −1, 0, 1, 1, 2, 4], where negative values are steps to the left, positive steps are steps to the right, and zero means stay. Movement on the vertical dimension was determined in the same way, but negative values were upward steps and positive values were downwards steps. If the generated step brought the agent out of the environment, the step was cancelled and a new step was generated as above.

We considered a simple winner-take-all network in which only the cluster at position pos i closest to stimulus x (agent's location) had a non-zero activation. Bold type is reserved for vectors. The distance between pos i and x is defined as:In the Kohonen learning rule, cluster i updates its position pos i to move toward stimulus x according to:where η t is the learning rate at time t. In the present simulations, we used batch updating to increase numerical stability in which 200 updates were performed simultaneously. The learning rate η for batch time t followed an annealing schedule:where η 0 is the initial learning rate set to 0.25 and ρ is the annealing rate set to 0.02.

---

### One-shot entorhinal maps enable flexible navigation in novel environments [^0ebb288b]. Nature (2024). Excellent credibility.

This transformation captures the hexagonal geometry of the grid cell lattice, and converts the firing-rate-weighted average of each phaseto 2D coordinateson a unit cell of the neural sheet, as illustrated in Fig. 1e. We can then visualize the trajectory of the bump of activity on the sheet by plotting the two coordinates θ 1 and θ 2 as the animal traverses the virtual reality environment. We plot θ 1 and θ 2 for one full session as a heatmap over spatial bins and trials in Fig. 2c. As the neural sheet is periodic, we also occasionally unwrappedto plot them as continuous trajectories across multiple copies of the neural sheet (Figs. 1g and 2d, i). Unwrapping was performed using np.unwrap onbefore converting to. Note that this unwrapping is used only for visualization and not used in data analyses. Unwrapping is sensitive to noise and often leads to unwrapping errors in which the unwrapped trajectory becomes dislocated by one neural sheet length. To mitigate this issue, in Extended Data Fig. 5, we adopted the following approach. Owing to the discontinuous nature of the unwrapping procedure, it is sensitive to noise only at the edge of the neural sheet. However, the location of the edge of the neural sheet is arbitrary (we can experimentally measure only the relative phases between grid cells; the location of the origin is arbitrarily chosen). Moreover, different choices of the origin will lead to more or fewer unwrapping errors. Taking advantage of this freedom, we performed a grid search over 100 different choices of the origin for each window of 5 trials by applying a global shift to all the phases of a cell, and kept the choice of origin, which leads to the most consistent trajectories over the 5 trial window (the underlying assumption is that trajectories do not drift much over windows of 5 trials, and that unwrapping errors will produce inconsistent trajectories). This procedure is somewhat cumbersome but leads to cleaner visualizations of the unwrapped bump trajectory for noisy trajectories.

---

### Collaborative strategy on bed bugs [^970ae05d]. CDC (2015). Medium credibility.

Bed bug control — conclusions on integrated pest management (IPM) and stakeholder roles — state that integrating several methods for controlling bed bugs in response to IPM surveillance data is likely to be more successful against bed bugs than application of any single method, and that reducing bed bug populations throughout a community provides an opportunity to reduce the probability of new infestations. With few exceptions, the federal government does not have a role in direct interventions against bed bugs, but it does have an important role in providing reliable information, coordinating stakeholders and providing resources for research to achieve long-term solutions, while many other stakeholders have been active in efforts to manage the bed bug problem. The page further notes that as improvements continue, indications are that IPM is the best approach in most situations, and that public awareness and dissemination of accurate information is helpful for earlier detection, greater chances of successful elimination of infestations, reduction in spread of infestations and more efficient use of resources.

---

### Collaborative strategy on bed bugs [^1c8d126c]. CDC (2015). Medium credibility.

Federal Strategy on Bed Bugs — this strategy advocates a logical, integrated approach to bed bug management with a focus on cooperation among all levels of government and communities, states that effective implementation should decrease costs to communities and achieve better bed bug control, and emphasizes that continuous measurements of progress will be key to efficient use of resources and essential to prevent the reoccurrence of widespread infestations in the United States.

---

### A space-time tradeoff for implementing a function with master equation dynamics [^57fa10b0]. Nature Communications (2019). High credibility.

Master equations are commonly used to model the dynamics of physical systems, including systems that implement single-valued functions like a computer's update step. However, many such functions cannot be implemented by any master equation, even approximately, which raises the question of how they can occur in the real world. Here we show how any function over some "visible" states can be implemented with master equation dynamics-if the dynamics exploits additional, "hidden" states at intermediate times. We also show that any master equation implementing a function can be decomposed into a sequence of "hidden" timesteps, demarcated by changes in what state-to-state transitions have nonzero probability. In many real-world situations there is a cost both for more hidden states and for more hidden timesteps. Accordingly, we derive a "space-time" tradeoff between the number of hidden states and the number of hidden timesteps needed to implement any given function.

---

### Constructing future behavior in the hippocampal formation through composition and replay [^09efd61c]. Nature Neuroscience (2025). High credibility.

Discrete and continuous worlds

We implement agents in continuous and discrete environments. Although similar in principle, these two types of agents and environments are slightly different in their practical implementation. The discrete agent behaves on a graph, whereas the continuous agent behaves in a two-dimensional (2D) Euclidean space. Both discrete and continuous settings are deterministic Markov decision processes (MDP).

The discrete environments are defined by a set of locations and actions as in a deterministic MDP. All results here assume rectangular square grid worlds, with actions 'north', 'east', 'south' and 'west'. We generate environments by adding walls and rewards on top of these regular grids. We represent rewards with a population of object vector cells, where each cell fires at a specific vector in relation to the reward, that is, a cell that fires 1 step to the East and so on. We represent each wall with two populations of object vector cells — each vector population centered on one of the wall ends. In more detail, we calculate the object vector population activity at location x relative to object o by concatenating the vectors of one-hot encoded distance from x to o along each action, with −1 distance for actions in the opposite direction. For example, for an object, one step east and three steps south from x, the representation is concatenate(onehot(−1), onehot(1), onehot(3), onehot(−1)). Thus, at any location, there are four vector cells active in the whole population — one for each action. In square grid worlds, this representation has redundancy because east is the opposite of west and north the opposite of south, but this setup allows for accommodating any type of nongrid graph too.

In continuous environments, locations become continuous (x, y) coordinates and actions are steps in a continuous direction. We place walls and rewards within a square 1 m × 1 m arena, at random locations and orientations. Again, we represent rewards by a single population of object vector cells and walls by two populations, one centered on each wall end. A single object vector cell is defined by a 2D Gaussian firing field, tuned to a specific distance and direction from its reference object; the firing fields of the full object vector cell population are distributed on a square grid centered on the object. We thus calculate the object vector population activity at location x relative to object o by evaluating the population of Gaussians centered on o at x.

---

### Collaborative strategy on bed bugs [^382a9e2d]. CDC (2015). Medium credibility.

Federal Strategy on Bed Bugs — nature of the problem outlines that bed bug infestations can occur in many settings, can be unknowingly transported on belongings, and may spread to adjacent rooms or housing units, with small isolated infestations easier to control while extensive, complex infestations can persist. The United States has recently seen increases in bed bug populations, and CDC and EPA issued a Joint Statement on Bed Bug Control in the United States. Documented consequences include reactions to bed bug bites ranging from no observable reaction to mild or severe allergic reactions, secondary infections of the skin, mental health implications for people living in infested homes, and time-consuming and expensive control measures. Management remains a major challenge for governments, industry, and the public, and this strategy provides guidance to help minimize negative effects on human health and the economy.

---

### Collaborative strategy on bed bugs [^159a4d64]. CDC (2015). Medium credibility.

Collaborative strategy on bed bugs — stakeholder collaboration and site-level actions highlight that community control efforts can be significantly improved when the community has access to quality resources and information, and the workgroup recognizes the need for collaboration among stakeholders to provide science-based information and educational materials about the importance of early detection, share success stories about management efforts, identify and promote research activities that may lead to reliable, portable and affordable detection methods, ensure that scientifically sound information is collected and made readily available to stakeholders about bed bugs including effective monitoring and control strategies and properly labeled chemical insecticides and related regulatory requirements, facilitate the incorporation of new discoveries into training, education and communication materials, and encourage funding for basic and applied research on bed bugs, bed bug biology, and effective control techniques and products, and conduct such research or facilitate funding where possible. Under actions to improve surveillance and IPM, by having an IPM plan for bed bugs in place, occupants and staff will be able to act quickly and confidently if they find bed bugs; those living or working at a property can conduct basic bed bug inspections as an added step to existing scheduled routines, which will help minimize costs; residents should not serve as the sole source for reporting bed bug infestations; inspecting every area at risk for bed bug infestation will help find bed bug infestations while they are still relatively easy to eliminate; and the frequency of such inspections should be part of the IPM plan, based on the local situation.

---

### Covariant spatio-temporal receptive fields for spiking neural networks [^3fb65f12]. Nature Communications (2025). High credibility.

Dataset

We simulate an event-based dataset consisting of sparse shape contours, as shown in Fig. 8, based on ref. Events are generated by applying some transformation A to the shapes and subtracting two subsequent frames. We then integrate those differences over time until for each pixel, until reaching a certain threshold and emitting events of either positive or negative polarity. This approximates the dynamics of event cameras, which emit discrete events when the intensity changes by a certain threshold. To obtain sub-pixel accuracy, we perform all transformations in a high-resolution space of 2400 × 2400 pixels, which is downsampled bilinearly to the dataset resolution of 300 × 300.

Fig. 8
Image snapshots from the two synthetic datasets used in this work.

The top row shows the four different spatial scaling, corresponding to shapes of 10, 20, 40, and 80 pixels. The bottom row shows the four different temporal velocities, corresponding to a change of 0.16, 0.32, 0.64, and 1.28 pixels per timestep. Both datasets are extremely sparse, with the shapes barely visible in the images. At larger temporal velocities, the shapes become more discernible.

We use three simple geometries, a triangle, a square, and a circle, that are translated with random motion sampled from the same uniform distribution. The shapes are positioned randomly in the image and oriented by a random, fixed angle. Two datasets are studied: one with varying spatial scales and one with varying temporal velocities. In the spatial scale dataset, the starting scale of the shape is logarithmically distributed from 10 to 80 pixels. In the temporal velocity dataset, the shapes scale logarithmically from ± 0.16 to ± 1.28 pixels. The velocities are normalized to the subsampled pixel space such that, for translational velocity, for example, a velocity of one in the x -axis corresponds to the shape moving one pixel in the x -axis per timestep. The velocity parameterizes the sparsity of the temporal scaling dataset, as seen in the bottom row in Fig. 8 panel, where the shape contours in the left panels are barely visible compared to the faster-moving objects in the right panels. To simulate noise, we add 5 ‰ Bernoulli-distributed background noise.

---

### Wilderness Medical Society clinical practice guidelines for prevention and management of avalanche and nonavalanche snow burial accidents: 2024 update [^1caa4be0]. Wilderness & Environmental Medicine (2024). High credibility.

Probe line search for buried victims without transceivers — For buried victims without transceivers, a probe line should be established. The initial probe depth should be 1.5 m to maximize efficiency, which would reach 88% of victims recovered alive in the United States and 95% of victims recovered alive in Switzerland. The probe technique should follow the 3-holes-per-step method, which is 30% faster than standard coarse probing; the rescuer inserts the probe into the snow 3 times while standing: 20 cm to the rescuer's left, center, and 20 cm to the rescuer's right, then steps forward to repeat. In slalom probing, organized rescuers probe 3 areas in a left-to-right pattern 50 cm apart while walking in zig-zags; slalom probing covers the same surface area faster than the 3-holes-per-step method but may be less effective. Probe line grid spacing influences detection, and a 50 x 50 cm grid offers the best probability of detection without prolonging search time. We recommend the initial probe pass should be limited to a depth of 1.5 m using 3-holes-per-step or slalom probing to cover a 50 x 50 cm grid. Strong recommendation, low quality evidence.

---

### Evolutionary dynamics on graphs [^c49db24d]. Nature (2005). Excellent credibility.

Evolutionary dynamics have been traditionally studied in the context of homogeneous or spatially extended populations. Here we generalize population structure by arranging individuals on a graph. Each vertex represents an individual. The weighted edges denote reproductive rates which govern how often individuals place offspring into adjacent vertices. The homogeneous population, described by the Moran process, is the special case of a fully connected graph with evenly weighted edges. Spatial structures are described by graphs where vertices are connected with their nearest neighbours. We also explore evolution on random and scale-free networks. We determine the fixation probability of mutants, and characterize those graphs for which fixation behaviour is identical to that of a homogeneous population. Furthermore, some graphs act as suppressors and others as amplifiers of selection. It is even possible to find graphs that guarantee the fixation of any advantageous mutant. We also study frequency-dependent selection and show that the outcome of evolutionary games can depend entirely on the structure of the underlying graph. Evolutionary graph theory has many fascinating applications ranging from ecology to multi-cellular organization and economics.

---

### Machine learning enables completely automatic tuning of a quantum device faster than human experts [^fd71e035]. Nature Communications (2020). High credibility.

Searching for the hypersurface

In each iteration, the algorithm first locates the hypersurface in gate voltage space. To do this, it selects a search direction, specified by a unit vector u which during the first 30 iterations of the algorithm is selected randomly from a hypersphere, restricted to the octant where all gate voltages are negative. The gate voltages are then scanned along a ray beginning at the origin o and parallel to u (Fig. 4 a). During this scan, the current is monitored; when it falls below a threshold of 20% of full scale, this is taken as defining a location v (u) on the hypersurface.

Fig. 4
Characterising the boundary hypersurface using machine learning.

Each panel illustrates a step of the algorithm presented in Fig. 3. The gate voltage space, restricted to two dimensions for illustration, is divided into regions of near-zero (blue) and non-zero current (pink), separated by a boundary hypersurface. a Locating the hypersurface. The gate voltages are scanned along a ray (violet arrow) starting at the origin (white circle) and defined by direction u. By monitoring the current, the intersection with the hypersurface is measured. b To determine whether a region should be pruned, the algorithm scans each gate voltage individually toward the bottom of its range from a location just inside the hypersurface as shown. If only one scan intersects the hypersurface (as in the inset), future exploration of that region is inhibited by displacing the origin as shown. c Based on a short 1D scan, the location is classified according to whether it shows current peaks indicating Coulomb blockade. d If peaks are found, a 2D scan (violet square) is performed in the plane of V 3 and V 7, and is possibly repeated at higher resolution. e From the first thirty measurements (green and yellow circles), the algorithm builds a model of the hypersurface and assigns a probabilitythat peaks will be found. f To refine the model, the algorithm generates a set of candidate search locations (squares), each weighted by its corresponding value of, and selects one at random. A new scan is then performed in the corresponding direction to generate a new measurement of the hypersurface location. Steps d – f are then repeated indefinitely. Inset: Scheme for numerically sampling the hypersurface using simulated Brownian motion. Each point represents a simulated particle moving inside the enclosed volume. The collisions between the particles and the modelled hypersurface generate a set of candidate search locations.

---

### Collaborative strategy on bed bugs [^b4600a8a]. CDC (2015). Medium credibility.

Federal Strategy on Bed Bugs — prevention and IPM actions — lists practical measures including "Carefully inspecting all used clothing and furniture for bed bugs to avoid bringing them into the home"; "Choosing appropriate control techniques for treating existing infestations to increase effectiveness of treatment and to reduce movement of bugs into adjacent units"; and, in multifamily dwellings, "Encouraging managers or owners of multifamily dwellings, when possible, to invest in" washers/dryers on each floor and portable heating units. Additional steps include "Sealing cracks and crevices around baseboards, light sockets, etc., to discourage movement through wall voids"; "Encouraging managers of multifamily dwellings to install door sweeps on the bottom of doors to discourage movement into hallways"; and "Implementing IPM plans in high-risk settings (hostels, shelters, etc.), to encourage" "Inspecting and/or treating incoming personal belongings with a portable heat chamber; Routinely monitoring areas around where people sleep or rest; and Identifying and destroying reservoir populations whenever possible".

---

### Collaborative strategy on bed bugs [^1baf2436]. CDC (2015). Medium credibility.

Federal Strategy on Bed Bugs — Priority Area IV: Research defines the scope of basic and applied research and identifies anticipated contributors. Research activity can be divided into two areas: basic and applied, with basic research answering questions about the biology of the bed bug in its environment and its association with hosts, and applied research providing new methods for IPM or new information that allows better pest control as part of an IPM program. Research pertaining to the priority areas will likely come from academic institutions; private industry; international research entities; and federal, state and local governments.

---

### Population coding of conditional probability distributions in dorsal premotor cortex [^044ede21]. Nature Communications (2018). Medium credibility.

As expected, the planned reaches decoded prior to target onset were usually approximately opposite of the current angular hand position (Fig. 5a, b). This can be seen in example trials (Fig. 5a), where the pre-target decoded reach direction was to the left when the hand position was on the right, while the post-target decoded reach direction was toward the target. Moreover, the distribution (across reaches) of pre-target decoded reach directions relative to the angular hand position approximately represented the experimentally-defined distribution of target presentations determined by the current hand position (Fig. 5b, c; compare to Fig. 1f, g).

Fig. 5
PMd population activity represents the distribution of upcoming movements — single reach decoding. a The distribution of decoded reach directions (blue) from the population of PMd neurons for two example reaches (left and right), before and after target onset (top and bottom). The purple circle is the current hand position, and the green square is the target location. b The distribution of decoded Φ 's across all reaches. The decoded Φ is the pre-target decoded reach direction relative to the hand's angular position (same as Φ from Fig. 1, except with decoded direction instead of actual reach direction). c The distribution of decoded Φ 's across reaches starting within 2 cm of the center. d The predictions of two hypotheses (left and right), shown for two different hand positions (example 1 vs. example 2). e Average pre-target decoded reach direction distributions as a function of hand position. The displayed distributions have the average width and peak angle of all decoded distributions from hand positions within the grid square. Light blue arrows point toward the circular means of these distributions. Green arrows point toward the most likely reach direction (from Fig. 1d). f The full width at half maximum of the pre-target decoded distribution as a function of hand distance from the center of the workspace. Distances from the center are binned as in Fig. 2. Error bars are SEMs. g Width of the decoded distributions over time, for starting positions that are closest (blue) and farthest (purple) from the center. h Latency of the reach as a function of the angular difference between the pre-target decoded direction and the actual target direction. Error bars are SEMs. i The bias of the initial trajectory of the reach (100–150 ms from target onset) toward the pre-target decoded direction. A bias of 1 signifies the initial trajectory is toward the decoded direction, while a bias of 0 is toward the actual target direction. Negative values are away from the decoded direction. 95% confidence intervals, computed via bootstrapping, are shown

---

### CDC yellow book 2026: health information for international travel. chapter 3 environmental hazards and risks [^7904b0e9]. CDC (2025). High credibility.

Bed bug exposure — recommended protective measures include inspecting the premises: Look carefully for bed bugs on mattresses, box springs, bedding, and furniture, particularly built-in furniture with the bed, desk, and closets as a continuous structural unit; bed bug eggs and nymphs are very small and can be easily overlooked. Travelers who observe evidence of bed bug activity — whether it be the bugs themselves or physical signs (e.g., blood spotting on linens) — should seek alternative lodging. Practice luggage precautions: Keep suitcases off the floor at the destination, keep suitcases closed when not in use, remove clothing and needed items (e.g., toiletry bags and shaving kits) from the suitcase only as necessary, and carefully inspect all clothing and other items before returning them to the suitcase.

---

### Collaborative strategy on bed bugs [^5d81be80]. CDC (2015). Medium credibility.

Collaborative strategy on bed bugs — stakeholders and shared information: stakeholders in the community who have an interest in bed bug control include schools, housing providers, social service providers, pest management firms, local businesses, law enforcement, and local public health departments, and communities can lower costs and improve bed bug control by working with all of their stakeholders to develop and share infestation rates, levels of resistance to specific pesticides, needs and existing resources to support underserved groups of people, and cultural considerations that potentially affect management efforts and recommendations. The federal government can help communities by providing information and educational materials based on the best scientific information and expert knowledge available, facilitating interactions among communities to leverage knowledge and experience, encouraging objective evaluations of interventions, and promoting research activities to improve prevention and control techniques.

---

### Universal exploration dynamics of random walks [^a31a389e]. Nature Communications (2023). High credibility.

The territory explored by a random walk is a key property that may be quantified by the number of distinct sites that the random walk visits up to a given time. We introduce a more fundamental quantity, the time τ n required by a random walk to find a site that it never visited previously when the walk has already visited n distinct sites, which encompasses the full dynamics about the visitation statistics. To study it, we develop a theoretical approach that relies on a mapping with a trapping problem, in which the spatial distribution of traps is continuously updated by the random walk itself. Despite the geometrical complexity of the territory explored by a random walk, the distribution of the τ n can be accounted for by simple analytical expressions. Processes as varied as regular diffusion, anomalous diffusion, and diffusion in disordered media and fractals, fall into the same universality classes.

---

### Collaborative strategy on bed bugs [^f69694e6]. CDC (2015). Medium credibility.

Federal Strategy on Bed Bugs — surveillance, IPM, and evaluation — states that "The following types of data can show whether programs and activities are successfully preventing bed bug infestations:" including "Results of inspections such as bed bug numbers from monitoring devices, visual inspections, or numbers of locations where scent-detecting canines alert"; and "Increased knowledge or behavior change of participants completing training or receiving educational materials, as measured by polls and questionnaires". It explains that "Even if residents diligently engage in prevention activities, bed bugs can still infest an area and an infestation may become well established before anyone notices", and that "If an IPM plan is in place that details specific roles in dealing with an infestation, bed bug experts can stop the infestation before it becomes overwhelming". It notes that "In most cases, the longer an infestation remains unchecked, the harder and more expensive it will be to eliminate", and that "Reliable and cost-effective early detection methods and educational efforts can help communities by lowering overall treatment costs and reducing new infestations". It adds that "Effective site-specific IPM plans tailor educational efforts and procedures to the community" and that plans should address factors affecting effectiveness, including "Cultural considerations", "Availability of qualified bed bug control professionals", and "Pesticide and applicator availability".

---

### Collaborative strategy on bed bugs [^eade62b3]. CDC (2015). Medium credibility.

Bed bug prevention — actions to improve prevention state that people living with bed bugs can take steps to reduce opportunities for bed bugs to migrate to new locations, and that by developing a strategy in advance people who travel or have jobs that may expose them to bed bugs can reduce the likelihood of bringing bed bugs home; integrating prevention strategies into IPM plans can help property owners and agents keep their buildings free of bed bugs. Education and communication are described as the foundation for effectively preventing bed bug infestations, with Priority Area IV (Education and Communication) providing more information, and the workgroup envisions prevention program modules including accurate identification of bed bugs, early detection of new or persistent infestations, sources for science-based technical information (particularly for high-risk settings), and open communication to foster collaboration rather than stigma. Creating a prevention program involves three main steps: minimizing movement of bed bugs to new locations; creating living spaces that are less receptive to bed bug infestations; and identifying and eliminating significant infestations that can serve as reservoirs for spreading bed bugs. The workgroup believes successful community programs will include preventing movement by treating existing infestations quickly and notifying all neighbors, and making areas less receptive by removing clutter, installing mattress and box spring encasements (if funds are severely limited, at least encase the box springs), installing, inspecting, and maintaining interception devices or traps, and providing clothes dryers hot enough to kill bed bugs. Additional actions named include examining the effectiveness of potential prevention techniques through research and other projects, establishing programs to inform employees about exposure recognition and response, continuing to inform HUD stakeholders about housing policy, and providing technical information and help when infestations occur in settings under federal oversight such as during disaster relief efforts or at military sites.

---

### Rigorous location of phase transitions in hard optimization problems [^d98ebea5]. Nature (2005). Excellent credibility.

It is widely believed that for many optimization problems, no algorithm is substantially more efficient than exhaustive search. This means that finding optimal solutions for many practical problems is completely beyond any current or projected computational capacity. To understand the origin of this extreme 'hardness', computer scientists, mathematicians and physicists have been investigating for two decades a connection between computational complexity and phase transitions in random instances of constraint satisfaction problems. Here we present a mathematically rigorous method for locating such phase transitions. Our method works by analysing the distribution of distances between pairs of solutions as constraints are added. By identifying critical behaviour in the evolution of this distribution, we can pinpoint the threshold location for a number of problems, including the two most-studied ones: random k-SAT and random graph colouring. Our results prove that the heuristic predictions of statistical physics in this context are essentially correct. Moreover, we establish that random instances of constraint satisfaction problems have solutions well beyond the reach of any analysed algorithm.

---

### Collaborative strategy on bed bugs [^01474042]. CDC (2015). Medium credibility.

Collaborative strategy on bed bugs — confirmation of infestation, integrated pest management (IPM) actions, and progress metrics are specified. Bed bugs can be difficult to differentiate from other common insects, and a qualified expert should confirm the presence of a bed bug infestation before control efforts begin; once a licensed pest control professional or other expert confirms the infestation, site occupants and staff follow the predetermined IPM plan to efficiently control the infestation, and if no IPM plan is in place, follow research-based recommendations available at EPA's bed bug website (www.epa.gov/bedbugs). The workgroup identified actions managers/owners/occupants and pest control professionals can take: Encourage discussions with a licensed pest control management company or other professional knowledgeable about the control of bed bugs about appropriate ways to quarantine infested items; Advocate for clear guidelines to minimize potential for bed bugs to develop resistance to pesticides; and Establish minimum acceptable standards for detecting an active infestation compared with a prior infestation. Measuring progress can include community or locality infestation rates; data showing availability and distribution of information and educational materials from the surveillance system, coupled with data showing increased knowledge of residents and housing employees; documentation showing a reduction in bed bug control expenses over time; documentation that monitors and resident surveys that show no activity for months after one or two treatments of an active infestation; and satisfaction surveys that show an increase in satisfaction.

---

### A scaling law for random walks on networks [^6ac9e523]. Nature Communications (2014). Medium credibility.

G-protein-folding model

Scalco and Caflischprovided us their G-protein random walk model based on molecular dynamics computations described in their paper. All links in the model are bidirectional because protein conformational changes are reversible. However, the probability of stepping from node i to j is not generally the same as the probability of stepping from node j to i. The network comprises a single, strongly connected component and the random walk posesses a unique well-defined steady-state distribution. Following the lead of Scalco and Caflisch, we computed the steady-state distribution for the walk and designated the single most probable node under that distribution as the 'native' or folded state.

The cut-based free-energy approach for identifying approximate 'energy basins' of the networkworks as follows. First, we compute the mean first passage time from each node i ≠1 to node 1 (the native state) — that is, the expected time it takes for the random walk, if it starts at node i, to reach the native state. This can be computed by a relatively efficient and simple dynamic programme. Next, we sort the nodes by increasing mean first passage time. Intuitively, nodes with higher mean first passage time are 'farther' from the native state, at least in terms of the random walk. Closely connected nodes are expected to have similar mean first passage times. Then, for each node i ≠1, we imagine dividing, or cutting, the network into two parts: on one side are the nodes with first passage time smaller than i 's, on the other side are nodes with first passage time greater than or equal to i 's. We compute the steady-state flux across this cut. (The steady-state flux across an arc i → j is the steady-state probability of i times the transition probability from i to j. The steady-state flux across the cut is the sum of the steady-state fluxes of all arcs from one side to the other.) Then, for all nodes i ≠1, we plot the negative logarithm of the steady-state flux, which is also called the cut-based free energy, against the rank of node i in order of increasing mean first passage time. We visually inspect that plot to separate the nodes into energy basins, by looking for local free-energy maxima separating broad regions of lower free energy. Carrying out this procedure for the G-protein model, we were able to divide the network into seven major energy basins, with a relatively small number of extra nodes that did not clearly comprise a basin. Although the 'extra' nodes are closely connected in the network, the cut-based free-energy analysis did not indicate a cohesive basin.

---

### Adaptive resetting for informed search strategies and the design of non-equilibrium steady-states [^d30abff2]. Nature Communications (2025). High credibility.

A naive approach would be to simply apply a constant resetting rate within the desired shape and zero resetting rate outside (Equation (S15) in the Supplementary Information). However, using our approach to predict the resulting steady-state, we find that this naive guess leads to a very fuzzy distribution, in which the arrow is barely discernible (see Fig. 5 a). This problem cannot be solved by increasing the resetting rate. The reason is that, for every reasonably complicated NESS, there will be areas that are very hard to reach without crossing regions with a high resetting rate. In our case, the area engulfed by the arrow can only be approached from the right, which significantly lowers its occupation probability, leading to the fuzzy arrow.

Fig. 5
Non-equilibrium steady-state design.

Two-dimensional arrow-shaped non-equilibrium steady-state (NESS). a Predicted from simulations without resetting with a naive r (x, y). b Predicted from simulations without resetting with an improved r (x, y). c Obtained from brute-force simulations with the improved resetting protocol.

Previously, testing different resetting protocols, in a trial-and-error fashion, would have required running thousands of trajectories with resetting for every protocol until the desired steady-state would have been obtained. Instead, using our approach, we can design an improved adaptive resetting protocol (Equation (S16) in the Supplementary Information) that would lead to the desired shape (Fig. 5 b), using the same set of trajectories without resetting that is already available. In the improved resetting strategy, the resetting rate was increased quadratically in the distance from the center of the box, and to the right of the arrow, to prevent the accumulation of density in the box's corners and to the right of the arrow, respectively. Results from simulations with this resetting protocol are given in Fig. 5 c for comparison, showing excellent agreement with our prediction.

---

### Joint statement on bed bug control in the United States from the U.S. centers for disease control and prevention (CDC) and the U.S. environmental protection agency (EPA) [^ba91b4b5]. EPA/CDC (2010). Medium credibility.

Bed bug biology — description, habitats, signs, and bite characteristics are detailed, noting that bed bugs are small, flat insects that feed on the blood of sleeping people and animals, are reddish-brown, wingless, range from 1 to 7 millimeters in length, and can live several months without a blood meal. Infestations usually occur around or near areas where people sleep, with hiding places including seams of mattresses, box springs, bed frames, headboards, dresser tables, cracks or crevices, behind wallpaper, and clutter; bed bugs can travel over 100 feet in one night but tend to live within 8 feet of where people sleep. They are usually transported as people travel, in the seams and folds of luggage, overnight bags, folded clothes, bedding, furniture, and other hiding places. Identification clues include bite marks that may take as long as 14 days to develop in some people, plus exoskeletons after molting, bed bugs in mattress folds and sheets, a sweet musty odor, and rusty-colored blood spots from blood-filled fecal material on mattresses or nearby furniture. When bed bugs bite, they inject an anesthetic and an anticoagulant, so most people do not realize they have been bitten until marks appear; bite marks are similar to those of a mosquito or a flea, are slightly swollen and red, may itch and be irritating, and may be random or appear in a straight line. Other symptoms of bed bug bites include insomnia, anxiety, and skin problems from profuse scratching. Everyone is at risk when visiting an infested area, and anyone who travels frequently and shares living and sleeping quarters where others have previously slept has an increased risk for being bitten and for spreading an infestation.

---

### Using health data to highlight milestones: a cookbook for non-profit program managers [^0d87682c]. CDC (2012). Medium credibility.

Bed bug exposure screening — survey items ask whether participants have noticed bites and whether they have seen evidence of bed bugs, described as insects that are small, flat, reddish-brown, wingless, and ranging from 1 to 7 millimeters in length.

---

### Social interactions lead to motility-induced phase separation in fire ants [^758c1e15]. Nature Communications (2022). High credibility.

Motility-induced effective potential

We confine sterile female fire ants, which have an average length l = (3.5 ± 0.7) mm, to a circular cell with a diameter D = (9.00 ± 0.02) cm and a height h = (1.6 ± 0.1) mm, which is slightly larger than the height of an ant (see "Methods"). The ants are thus effectively confined to two dimensions. We place this cell in the plane perpendicular to the gravitational direction, image the ants from above, and track their positions as a function of time. For example, Fig. 1a shows an image of N = 40 ants in a cell, together with their trajectories over the previous 3 s, which are shown as colored lines. Notice that the ants that have the shortest trajectories in this figure, and therefore lowest speeds over the 3 s, tend to be near other ants. This is a typical result of their social interactions, which we quantify by measuring the average speed of an ant as a function of its distance from another ant. We sort the velocities of pairs of ants by their center-to-center distance, which we divide into 1 mm bins, ensuring that there are at least 20,000 measurements in each bin with 0.3 cm < r < 7 cm, and take the average for each bin. The resulting < v (r) > for various N are shown in Fig. 1b. This figure can be understood by considering a reference ant at r = 0 and a second ant a given distance, r, away from the reference ant. Figure 1b then shows the average speed at which we measure the second ant to be moving. Notice that < v (r) > depends on N because this second ant is free to interact with ants in the cell other than the reference ant. Regardless, for all N, we find that the ants, on average, slow down as they approach each other. To account for the effect of the ants' spatially dependent motility, we consider a continuity equation for the probability, P, that an ant has position r, and orientation θ, if the ant moves in the direction it is facing, :whereandcontrols the change in the orientation of the ants. In most systems, this function is taken aswhere D θ (r) is a rotational diffusion constant that depends on location. The rate of change of P thus depends on the divergence of the probability current, where the minus sign indicates that an outward flux of the probability current decreases P. Theterm then acts as a source or sink for. Interestingly, for isotropic processes, in which all relative orientations are equally likely and independent of position, a steady state solution is, suggesting that the ants are more likely to be in regions in which they move more slowly so thatis constant across the cell.

---

### The limits of precision monomer placement in chain growth polymerization [^b6732469]. Nature Communications (2016). Medium credibility.

In aperiodic copolymers prepared by sequential polymerizations of monomers of similar reactivity, or by addition of alternatingor very rapidly polymerizingmonomers at intervals during the polymerization, all blocks are Poisson-distributed, at best. Thus, an { A 10 B 1 C 10 } polymer will include chains with no B units, as well as chains that contain 2 or more. The proportion of chains that contain a unit of B in position 11 (the midpoint) can be calculated by excluding all chains that contain 11 or more units of A (41.7% of chains), as well as all chains in which the sum of units of A and B is < 11 (46.0% of chains). The 12.3% of chains that remain are not significantly fewer than the corresponding proportion of { A 10 } B 1 { C 10 }. In { A 10 } B 1 { C 10 }, however, each polymer chain contained a single copy of B. In { A 10 B 1 C 10 }, only 4.6% of chains contain one and only one unit of B in position 11.

In general, the probability that the k th monomer of a multiblock copolymer is part of the n th block is given by the difference between two Poisson cumulative distribution functions (Table 1). As the average position of a block moves further along the polymer chain, its location becomes more diffuse. Shorter blocks are affected to a greater extent than longer blocks, as shown by Fig. 2a, c, which show the location distributions of each block of two ABACADACAB decablock copolymers. Those of the short blocks broaden rapidly and overlap significantly. The distributions of the longer blocks broaden more slowly and overlap less, but fewer changes in composition are possible in a given length of polymer. The standard deviation of the location of the block (Table 1) provides a quantitative measure of the attainable precision: in { A 10 B 1 C 10 }, the expected location of B is 11.5, with a standard deviation of 3.3; B occurs before position 8 or after position 14 in 29.2% of chains.

---

### Mouse visual cortex contains a region of enhanced spatial resolution [^b443a543]. Nature Communications (2021). High credibility.

The distribution of left/right focea locations (Fig. 8b and Supplementary Fig. 8b) was computed using a grid of equally spaced points in spherical coordinates (spacing 1°). The radius of the sphere was 10 cmand the head of the animal was placed at the center of the sphere (nose pointing at ele = 0° and azi = 0°). For each tracked left or right angular eye position and corresponding pitch/roll values, we computed the direction of the focea in spherical coordinates and increased the count of the grid point closest to the vector of length 15 cm starting at the eye center and pointing in the direction of the focea by 1. Repeating these steps for all angular eye positions across recordings yielded an approximation proportional to the distribution of focea directions in spherical coordinates. Elevations in Fig. 8d were computed from the marginal distribution (i.e. after summing over all azimuth values) either as circular mean (Fig. 8d, top) or circular standard deviation (Fig. 8d, bottom) using the CircStat toolbox.

To avoid that systematic changes in head tilt bias focea elevation for the different freely moving conditions, we used stratified sampling of the joint distributions of head pitch and roll values; that is, pitch and roll data for each condition were binned (5° bin size for both pitch and roll) and for each bin a random subset of samples were kept such that the frequency of pitch/roll values in that specific bin was equal across all conditions. The stratified datasets were used to compute focea elevation in Fig. 8d (20° ± 0° head-fixed, 16.3° ± 2.6° open field, 15.9° ± 2.4° social interaction, 17.0° ± 3.2° object tracking). The elevation for the control condition ("Focea fixed in head") was computed using the same stratified data as the focea elevation (20° ± 0° head-fixed, 0.8° ± 0.8° open field, 0.8° ± 0.8° social interaction, 0.3° ± 1.3° object tracking). We repeated the same analysis with different torsion gain values (0.217 and 0.433). The precise torsion gain value had a rather small influence on focea elevation in freely moving mice: a change in torsion gain of 33% resulted in a 10% change in focea elevation (Supplemental Fig. 8d).

---

### A versatile computational algorithm for time-series data analysis and machine-learning models [^263e8086]. NPJ Parkinson's Disease (2021). Medium credibility.

Now consider the 3x3 neighborhood around each vector element being constructed from.represents our one-dimensional time-series vector that can be used for time-delay embedding with delay t and embedding dimension m to reconstruct the phase-space trajectory. However, instead of considering the Euclidean norm between data points:we will consider vectors V i and V j in relation to their local 3x3 neighborhood such that:where it can be seen that≠even when = (Fig. 1a). It follows then, that directional and curvature information can be captured by different inequality patterning around the 3x3 neighborhood when computed for allby constructing a new matrix that represents an 8-bit binary code for each point-pair's local neighborhood:where g 0 representsand g n = { g 1, …, g 8 } are its eight connected neighbors. Each neighbor which is larger or equal to g 0 is set to 1, while each neighbor that is smaller than g 0 is set to 0. A binary code is thus created by moving around the central point g 0 (here counterclockwise) where a single integer value is calculated based on the sum of the binary code elements (0 or 1) multiplied by the eight 2 p positional weights (increments of powers of 2: 2 0, 2 1, 2 2, 2 3, 2 4, 2 5, 2 6, 2 7) starting with the preceding points (i.e.). This represents 8-bit binary coding where there are 2 8 (256) different possible integer values, ranging from 0 to 255. This newly created matrix now allows for the identification of graded changes in phase-space trajectories that can be used to identify recurring sets of local topological features embedded within the dynamic signal (LoTRA plot; see Fig. 1b, c for example).

---

### The promise and challenge of spatial inference with the full ancestral recombination graph under brownian motion [^a979604a]. G3 (2025). Medium credibility.

Ancestor locations

To assess the accuracy of estimated ancestor locations (Equation 7), we estimate the location of random genetic ancestors within a simulated ARG of 1,000 samples and compare to the truth. We select each genetic ancestor to locate by choosing a random sample, genome position, and time (e.g. the ancestor of sample 1 at genome position 1,050 bp, 200 generations in the past). We estimate a location using the ARG for the full chromosome ("ARG"), a local ARG containing 100 trees on either side of the tree at the chosen genome position ("Window"), and the local tree at the genome position ("Tree"). We also compare these estimates against those using the averaging-up approach. For the averaging-up method, we first simplified our ARG before calculating the locations, as is done in practice.

Despite using more information, we observe larger absolute error with the ARG estimates than with the tree-based approach (Fig. 6a). Investigating this further, we see that ancestors are often estimated too close to the average ("center") of the sample locations (Fig. 6b). Since the forward-in-time model sees excess clustering below recombination nodes (Fig. 4b -ii, Fig. 5d), backwards in time there is an equivalent pull towards the center (see Supplementary Fig. S10 in Supplemental file). This bias towards the center becomes more severe as more trees are incorporated into the ARG. Perhaps surprisingly, we see that the averaging-up method, which uses a simplified ARG and ignores edge lengths, performs just as well on average. A modified simulation with a much larger area and sampling from the center confirms this bias is not due to reflecting boundaries (Supplementary Section S7, Figs. S5 and S6 in Supplemental file).

---

### Collaborative strategy on bed bugs [^a3db19c9]. CDC (2015). Medium credibility.

Federal strategy on bed bugs — early detection practices emphasize that bed bugs can be detected before an infestation becomes severe by using devices and practices that facilitate early detection, including using rip-resistant, bite-proof and escape-proof mattress and box spring encasements that make it easier to see the signs of bed bugs, managing the environment so that when infestations occur they are more easily detected, using passive bed bug monitors that intercept and trap bed bugs, and using active monitors that attract bed bugs by releasing heat, carbon dioxide and/or a scent lure; hiring a pest management professional or training specific staff members to conduct intensive inspections can be an effective way to encourage surveillance and IPM efforts.

---

### Chunking as the result of an efficiency computation trade-off [^07edc52f]. Nature Communications (2016). Medium credibility.

How to move efficiently is an optimal control problem, whose computational complexity grows exponentially with the horizon of the planned trajectory. Breaking a compound movement into a series of chunks, each planned over a shorter horizon can thus reduce the overall computational complexity and associated costs while limiting the achievable efficiency. This trade-off suggests a cost-effective learning strategy: to learn new movements we should start with many short chunks (to limit the cost of computation). As practice reduces the impediments to more complex computation, the chunking structure should evolve to allow progressively more efficient movements (to maximize efficiency). Here we show that monkeys learning a reaching sequence over an extended period of time adopt this strategy by performing movements that can be described as locally optimal trajectories. Chunking can thus be understood as a cost-effective strategy for producing and learning efficient movements.

---

### Egocentric neural representation of geometric vertex in the retrosplenial cortex [^d575fb7c]. Nature Communications (2024). High credibility.

Fig. 2
Egocentric vector coding of geometric vertices in the retrosplenial cortex.

a – c Illustration of the mouse allocentric head direction (θallo), egocentric bearing (θego), and egocentric distance (Dego) relative to the closest vertex from the current location (a), θallo (b) and θego (c). d Representative spike-trajectory plot (mouse trajectory (gray line), spike locations (colored dots)) of a single RSC vertex cell during free exploration in triangle, square, and hexagon open chambers. Each spike is color-coded for θallo (inset, North: N, East: E, South: S, and West: W). Tuning curves of θ allo and θ ego are color-coded for the closest vertex (V i: i th vertex). e Illustration of an egocentric vertex vector plot. f The egocentric vertex rate map of the same vertex cell in (d). Firing rate is color-coded. Insets: mean resultant vector length (VL), preferred θego, preferred Dego, and maximum firing rate. g Probability distributions of VLs of all vertex cells (triangle: n = 234, square: n = 234, and hexagon: n = 247 in 9 mice) in each three open chambers (colored) and the randomly shuffled VLs (gray). Red line: 95th percentile of randomly shuffled VLs distribution. Inset: ratio of egocentric vertex cells (EVCs) and non-EVCs in each open chamber. h EVC ratio across three open chambers (left) and in each mouse (right). i Probability distribution of preferred θego (left, two-sided Watson–Williams multi-sample tests) and Dego (right, two-sided one-way ANOVA) of EVCs in each open chamber. j Box plot showing differences in preferred θego (left, two-sided Watson–Williams tests; triangle–square: F (1, 122) = 0.002, p = 0.96, triangle–hexagon: F (1, 108) = 0.002, p = 0.96, square–hexagon: F (1, 110) = 0.04, p = 0.84) and Dego (right, two-sided repeated measures ANOVA; triangle–square: F (1, 61) = 0.31, p = 0.58, triangle–hexagon: F (1, 54) = 0.28, p = 0.60, square–hexagon: F (1, 55) = 1.14, p = 0.29) of EVCs between two chambers. Box plot (j) shows 25 th (lower box line), 50 th (middle line), 75 th (upper box line) percentile values and minimum and maximum values (whiskers). n.s.: p > 0.05. Source data are provided as a Source Data file.

---

### Simulation-based reconstruction of global bird migration over the past 50, 000 years [^9b3c4677]. Nature Communications (2020). High credibility.

Virtual species range options

For each time slice separately, we generated 1000 contiguous geographical ranges in our virtual world (400 in the WH, 600 in the EH, reflecting differences in area) to serve as options from which the distributions of virtual species were simulated (Fig. 1). These range options all had a size of 131 hexagons in the western hemisphere and 180 hexagons in the eastern hemisphere, which correspond to respective median values in a global data set of avian species range maps. Ranges were generated using a method adapted from the spreading dye algorithm, through a climate-driven approach of range expansion that has been shown to accurately capture the empirical distribution of bird ranges' shape. Each range was seeded from a single hexagon, randomly selected among all hexagons each with a probability(Eq. (1)), with S h denoting the number of species already simulated and occurring in hexagon h. The probability of selecting a given hexagon as a seed hexagon was thus a function of the local richness in virtual species in order to avoid simulating range options that are too clustered spatially. From the selected seed hexagon, we then allowed a stochastic spread into adjacent unoccupied hexagons, constrained by climatic conditions, until the virtual range reached a fixed size. For each range, an initial climatic optimum was obtained from the position of the seed hexagon in a climatic space defined by a mean annual temperature (z -standardised) and a mean annual precipitation (z -standardised after being log-transformed). We then selected two neighbours of the seed hexagon, with the probability of selection being higher for neighbours closer to the climatic optimum (that is, lower Euclidian distance d in the climatic space between itself and the climate optimum), calculated as(Eq. (2)), divided by the sum of these values across all neighbours (hence decaying exponentially with increasing climatic distance d). We then repeated this procedure, each time redefining the climatic optimum as the average climatic condition across the already selected (that is, occupied) hexagons and selecting 25% (rounded to the larger integer) of the set of unoccupied neighbours of the occupied hexagons (summing the probabilities of the ones being neighbours of more than one occupied hexagon), until the desired range size was reached (131 hexagons, ~3.05 million km 2, in the WH, 180 hexagons, ~4.20 million km 2, in the EH). Visualisation of the geographical distribution of range options through time is presented in Supplementary Movie 2.

---

### Highly active enzymes by automated combinatorial backbone assembly and sequence design [^bd8ef285]. Nature Communications (2018). Medium credibility.

Fig. 2
Different segmentation schemes used in combinatorial backbone assembly. a GH10(I): Each of eight β-α units were sampled independently, for maximal backbone diversity. b GH10(II): Segmenting β-α units 1, 2–4, 5–6, and 7–8 to preserve stabilizing interactions within each segment. c GH10(III): a discontinuous segmentation, in which the structurally conserved β-α units 1 and 5–6 formed one segment and two other segments were formed by units 2–4 and 7–8. d The homodimer interface in PLLs (β-α units 1–3 and 8, gray) was used as one backbone segment and units 4–7 were sampled independently

To assemble backbones and design new sequences, we generalized the Rosetta AbDesign method — originally developed to design new antibodies from backbone fragments of natural ones, (Supplementary Fig. 2, Supplementary Movie 1). For each of the segmentation schemes, we started from a random combination of backbone fragments. In each design step, AbDesign samples a single backbone fragment from the conformation database and designs the protein's amino acid sequence. Since the entire protein (> 300 amino acids) needs to be designed to accommodate the large backbone changes introduced in each step, we used position-specific scoring matrices (PSSMs) to constrain amino acid choices at each position to identities that are commonly observed in a multiple-sequence alignment of natural family members. The PSSMs also focus design calculations on a sequence subspace that is more likely to include stable, folded, and active enzymes. Furthermore, the method does not model the enzyme-transition-state complex, which is often associated with modeling uncertainties and inaccuracies. Instead, residues in direct contact with the bi-metal center in PLLs and the two catalytic Glu residues in GH10 as well as 11 additional residues directly involved in substrate binding, were not allowed to change sidechain conformation during design (Fig. 1b). Following sequence design, the new structure was accepted if it was lower in energy than the previous one, and higher-energy structures were accepted probabilistically. The designs were then ranked by Rosetta energy, clustered by backbone conformation to obtain conformationally unique structures (Supplementary Fig. 3) and subjected to the PROSS stability design algorithm in all regions outside the active-site pockets. PROSS introduced dozens of mutations to each design (20 ± 6 and 36 ± 7 mutations in GH10 and PLL designs, respectively). Visual inspection indicated that the PROSS-designed mutations eliminated core cavities and improved surface polarity and were, therefore, likely to improve protein stability and expressibility.

---

### Egocentric neural representation of geometric vertex in the retrosplenial cortex [^0a6098a7]. Nature Communications (2024). High credibility.

Fig. 4
Strengthening of egocentric vector coding of geometric vertices in the retrosplenial cortex by goal-directed navigation.

a Goal-directed navigation task design (top) and the representative mouse trajectories (gray line) in a square open chamber with a triangle-shaped inner walls (V i: i th vertex) during pre-training, training, and post-training sessions (bottom). b Averaged trajectory distance (left, two-sided repeated measures ANOVA with post hoc Tukey's test; F (3, 18) = 16.15, p < 0.001) and latency (right, two-sided repeated measures ANOVA with post hoc Tukey's test; F (3, 18) = 11.25, p < 0.001) from start position to goal location during training sessions (n = 7 mice). Error bar: SEM. c, d Representative spike-trajectory plot (left). Mouse trajectory (gray line) superimposed with spike locations (colored dots) and the corresponding firing rate maps (middle) of a single egocentric vertex cell (EVC) during free exploration before (c, Pre-training) and after (d, Post-training) training sessions. Each spike is color-coded for allocentric head direction (θallo) (inset, North: N, East: E, South: S, and West: W). Firing rate is color-coded (inset: maximum firing rate). The egocentric vertex rate map (right) of the same EVC at the vertex near the goal location (V1, white line in firing rate map). Firing rate is color-coded. Insets: mean resultant vector length (VL), preferred egocentric bearing (θego), preferred egocentric distance (Dego), and maximum firing rate. (e - g) Mean firing rate (e, two-sided two-way ANOVA with post hoc Tukey's test; interaction effect: F (6, 1974) = 4.86, p < 0.001), VL map (f), and mean VL (g, two-sided two-way ANOVA with post hoc Tukey's test; interaction effect: F (6, 1974) = 13.66, p < 0.001) of all EVCs (n = 142 EVCs in 7 mice) at each vertex in each condition. VL in (f) is color-coded. h Probability distribution of preferred Dego (left, two-sided paired Student's t test) and θego (right, two-sided Wilcoxon signed-rank test) of EVC at V1 in each condition. Box plot (e, g) shows 25 th (lower box line), 50 th (middle line), and 75 th (upper box line) percentile values. ✱ p < 0.001, n.s.: p > 0.05. Source data are p rovided as a Source Data file.

---

### Hysteresis stabilizes dynamic control of self-assembled army ant constructions [^562f2332]. Nature Communications (2022). High credibility.

Parameterization of linear models

As discussed above, the parameters for the distribution of the number of events per step were drawn from the data. We fit the distribution of the number of joining events per 30 s gap interval to a negative binomial distribution, using the fitdistrpluspackage. We did this separately for each trial, finding the fitted mean and dispersion parameters µ and θ, and used the median values of µ and θ across the trials to parameterize the baseline model. We parameterized the distribution of the number of leaving events with the same process. We excluded gap intervals during which the bridge was broken or recovering from a break, as well as a single entire trial in which the bridge was broken or recovering for the majority of the trial (trial ID "2016_03_15_trial_4").

For the linear delay model, in which we modeled a delay between ants' decisions to leave the bridge and actually leaving, we had to adjust these distributions for leaving events. For example, when modeling a delay of 1 timestep (one 30 s gap interval), we reassigned leaving events in the first step of the contraction to the expansion, for each trial, and refit the distribution. We did this for delay durations of one timestep up to six timesteps. We did not model a delay in joining or adjust the distribution of the number of joining events because the ants that are crossing the bridge move too quickly to effect a joining delay longer than a few seconds.

---

### Probabilistic alignment of multiple networks [^39aa70ac]. Nature Communications (2025). High credibility.

The network alignment problem appears in many areas of science and involves finding the optimal mapping between nodes in two or more networks, so as to identify corresponding entities across networks. We propose a probabilistic approach to the problem of network alignment, as well as the corresponding inference algorithms. Unlike heuristic approaches, our approach is transparent in that all model assumptions are explicit; therefore, it is susceptible of being extended and fine tuned by incorporating contextual information that is relevant to a given alignment problem. Also in contrast to current approaches, our method does not yield a single alignment, but rather the whole posterior distribution over alignments. We show that using the whole posterior leads to correct matching of nodes, even in situations where the single most plausible alignment mismatches them. Our approach opens the door to a whole new family of network alignment algorithms, and to their application to problems for which existing methods are perhaps inappropriate.

---

### Human hippocampal and entorhinal neurons encode the temporal structure of experience [^eb947906]. Nature (2024). Excellent credibility.

Neural population analyses

To decode stimulus identity during each image presentation, we used the Poisson naive Bayes classifier, as implemented in the Neural Decoding Toolbox. The spiking activity of each neuron was extracted from the −1 to +2 s time window relative to the stimulus onset. Data was binned (0.1 s) and smoothed (moving sum: ± 0.25 s). The decoder was run on the summed spiking activity in the 0.1 to 1 s time window (Extended Data Fig. 5). The main analysis focused on posterior probabilities assigned by the decoder to the image actually presented (actual), images directly linked to that stimulus on the graph (direct), and images linked indirectly (indirect). The analysis was performed for each recording session separately (different stimuli), but the resulting probability distributions were combined across all sessions and image presentations. The classifier was trained on the data from PRE and tested on all subsequent phases. For testing in PRE, we used the 'leave-one-trial-out' cross-validation. Kolmogorov–Smirnov tests were used to compare cumulative distribution functions (CDFs) of posterior probabilities (one-sided). To reconstruct the entire pyramid graph (Fig. 3f, g and Extended Data Figs. 6b and 7b), we calculated Euclidean distances between mean responses of each neuron to each pair of images across all relevant neurons (neurons that stopped firing during the late study phases were excluded; distances were z -scored; bin-size: 0.1 s; baseline-correction: −0.5 to 0 s; moving sum: ± 0.15 s; time window: 0.1 to 1 s). Then, we compared the resulting neural distance matrixes to three templates (Fig. 3f). In the geodesic template, distances between each pair of nodes corresponded to the number of edges of the shortest path connecting the nodes. In the Euclidean template, distances between nodes 1–5, 4–3 and 6–2 were calculated from the Pythagorean theorem (right triangles: 1–5–6, 4–3–1, 6–2–1). The remaining distances corresponded to the shortest path (see above). In line with the previous literature, the successor template (ST) was calculated as the negative of the matrix exponential of the adjacency matrix A:

---

### Speed modulations in grid cell information geometry [^be38d054]. Nature Communications (2025). High credibility.

For each sampled dataset, we computed SCA across eight speed bins as described above. Fifty — each yielding eight metric-speed pairs (where metric is SCA in this case) — produced a metric-speed dataset of 400 points (dots in Fig. 1C). A natural idea is to fit a simple linear regression (e.g. least-squares regression) to these 400 points and use the slope to quantify how metric varies with speed. However, this approach is problematic as it assumes all observations are independent, which here is violated: our 400 points come from fiftydrawn from the same original dataset D, so they are statistically related. If one were to increase the number of sampled datasets, a naïve linear regression would misleadingly drive the slope's estimation uncertainty toward zero.

To address this, we introduced Bayesian Linear Ensemble Averaging (BLEA, see Methods). BLEA proceeds in two stages: first, it fits a Bayesian linear regression separately to the metric-speed data from each, yielding fifty posterior distributions over the regression weights; then it combines these posteriors via Bayesian model averaging. The result is a Gaussian-approximated posterior over the slope (and intercept) together with predictive distributions, from which confidence intervals (CIs), p -values, and other statistical measures can be estimated using a Bayesian framework (see Methods).

Applying BLEA to SCA (Fig. 1C, D), we found that SCA increases with speed, with a slope significantly larger than that of the label-shuffled dataset. This result holds across different classifiers used for computing the SCA (support vector machine and perceptron, see Supplementary Fig. 3), indicating better self-location representations in grid cell population at higher speeds.

---

### Density-functional fluctuation theory of crowds [^74b408e8]. Nature Communications (2018). Medium credibility.

A primary goal of collective population behavior studies is to determine the rules governing crowd distributions in order to predict future behaviors in new environments. Current top-down modeling approaches describe, instead of predict, specific emergent behaviors, whereas bottom-up approaches must postulate, instead of directly determine, rules for individual behaviors. Here, we employ classical density functional theory (DFT) to quantify, directly from observations of local crowd density, the rules that predict mass behaviors under new circumstances. To demonstrate our theory-based, data-driven approach, we use a model crowd consisting of walking fruit flies and extract two functions that separately describe spatial and social preferences. The resulting theory accurately predicts experimental fly distributions in new environments and provides quantification of the crowd "mood". Should this approach generalize beyond milling crowds, it may find powerful applications in fields ranging from spatial ecology and active matter to demography and economics.

---

### Haloarchaea swim slowly for optimal chemotactic efficiency in low nutrient environments [^933ebb89]. Nature Communications (2020). High credibility.

Chemotaxis model

To simulate chemotaxis, we biased a cell's tumble probability depending on whether it has moved up or down a simulated chemical gradient. For simplicity, the chemical concentration was given by c (x, y, z) = x, i.e. a constant gradient in the positive x -direction. Motivated by the analogy to eubacterial two-component signalling, we adopt a general approach, to calculate a time-dependent tumble rate, where λ = 1/ τ run, and c (t ′) is the concentration experienced by the cell at time t ′. The cell's chemical response function is given by, where W is the chemotactic sensitivity and k is a rate constant that describes how long a cell retains information about previous chemical concentrations to which it has been exposed (i.e. the length of its 'chemical memory'). We tuned two parameters: the unbiased tumble rate λ and the swimming speed v. The quantity W was chosen to ensure the maximum chemotactic response while minimising saturation (see Supplementary Figs. 5 and 7 for more details). Previous studies, have coupled R (t) to the base tumbling rate such that λ = k, in line with experiments. we explore the effect of decoupling λ and k in the extended data and choose a memory length of 1/k = 2 s. Simulations were performed for batches of 100 cells under each condition, simulating cells swimming for 10 4 s with time steps of 0.033 s, except in the case of the mean-squared displacement results (Fig. 5e), in which we conducted simulations for much longer time scales, up to 3 × 10 6 s, in order to collect sufficient statistics at long times. Initial swimming directions were chosen randomly by allowing the direction vector to diffuse randomly for 60 s before the start of each trajectory.

---

### American Gastroenterological Association institute guideline on the diagnosis and management of Lynch syndrome [^0cc64b86]. Gastroenterology (2015). Medium credibility.

Regarding classification and risk stratification for Lynch syndrome, more specifically with respect to risk prediction, AGA 2015 guidelines recommend to consider using risk prediction models as a first-line assessment, rather than proceeding directly with germline genetic testing, in patients without a personal history of colorectal or another cancer but with a family history suggestive of Lynch syndrome.

---

### European guideline for the management of scabies [^fae5dc42]. Journal of the European Academy of Dermatology and Venereology (2017). Medium credibility.

Regarding follow-up and surveillance for scabies, more specifically with respect to monitoring, IUSTI 2017 guidelines recommend to arrange a follow-up visit 2 weeks after completion of treatment for a test of cure by microscopy examination.

---

### Microtubule-based transport is essential to distribute RNA and nascent protein in skeletal muscle [^efda005a]. Nature Communications (2021). High credibility.

While moving in the cytoplasm, RNAs randomly transitioned between available motion states, including diffusion (D), crawling transport (C), and processive transport (P). Transition probabilities were constrained by the average number of RNAs observed in each state during live-cell imaging (Fig. 9B). For each RNA, a diffusion coefficient D was selected by sampling from the distribution of "low-mobility" diffusion coefficients measured in C2C12 myotubes, smoothed by kernel density estimation (KDE) (Fig. 8D). During each time-step, positions of RNAs in the diffusion state were translated by a 3D Gaussian random variable with a mean of 0 and a standard deviation of (2 Dt) 1/2. If allowed, active transport events lasted for a single time-step, and the distance traveled by directed motion (d c or d p) was sampled from KDE-smoothed distributions of distances measured in C2C12 myotubes (Fig. 8E). To model the lattice-like structure of microtubules and Z-disks, active transport events were randomly assigned a direction along either the axial or radial dimensions of the fiber, with a 50% probability for each. The axial unit vector was identified by applying a medial axis transform to the fiber mask in 2D and fitting a line to the skeleton by least squares regression. RNAs traveling in the axial direction moved either parallel or antiparallel to the fiber with equal probability. RNAs traveling in the radial direction were allowed to move in any 3D direction perpendicular to the axial unit vector with equal probability. If an RNA exited the allowed cytoplasmic space as a result of its motion during a time-step, the motion event was reverted and sampled again. Particle positions and states were recorded at each time-step for analysis (Fig. 9B).

Using this framework, simulations of Polr2a mRNA transport were conducted for 360,000 time-steps (1000 h) in the following state configurations: (a) D only, (b) D, C, and P. After discarding the initial 10% of the simulation as burn-in to eliminate non-equilibrium effects, samples were taken every 360 time-steps (1 h), and the average distribution of RNA across the fiber was computed across all samples (Fig. 9C).

Reporting summary

Further information on research design is available in the Nature Research Reporting Summary linked to this article.

---

### Using smartphones to optimise and scale-up the assessment of model-based planning [^06fef678]. Communications Psychology (2023). Medium credibility.

The similarities and differences between the original two-step task and our gamified Cannon Blast are presented in Supplementary Table 1. Like the original, Cannon Blast consisted of 200 trials which was divided into two blocks of 100 trials. The first block was set at an easy difficulty, and the second at a medium difficulty. Level had no direct bearing on the core parameters-of-interest (which container participants select, rewards, drifts etc), and instead reflected how challenging the aim and shoot trajectory was. However as we explore in Experiment 2, level difficulty can be conceived of as a distraction manipulation. Easy levels included trials where the diamond did not move, had static obstructions that limited the angle at which it could be hit, or where diamonds moved slowly around the screen. Medium difficulty levels included more challenging trials with both moving diamonds and moving obstructions (Supplementary Table 2). While on average medium trials are more difficult than easy (average hit rate Medium = 45%, Easy = 52%), there was variation within both Easy levels (hit rates 83%, 53%, 44%, 29%) and Medium (hit rates 75%, 20%, 39%, 45%) (Supplementary Table 2). Reward probabilities in Cannon Blast were set higher on average (average reward probability: AA = 0.80 [0.64–0.94], AB = 0.72 [0.41–0.94], BA = 0.72 [0.41–0.94], BB = 0.64 [0.41–0.94]) than the original task (mean reward probability = 0.52 [0.25–0.75]) to promote enjoyment and limit frustration. In contrast to the traditional two-step task, which includes 40 practice trials, Cannon Blast starts with a short, passive walk-through demonstration of the task (Supplementary Figure 1). While the traditional task design has both first- (choice of rocket) and second-stage (choice of alien) actions, Cannon Blast has first-stage (choice of container) actions only. The decision to remove second-stage actions was in part done for gameplay reasons but also has been shown to increase the importance of model-based contributions in the first stage choice. A final major distinction between the tasks was the stated goal; in the traditional task, participants are directly told to earn rewards (space treasure). In Cannon Blast, participants are told to shoot as many diamonds as possible, and that this can be facilitated by ensuring they maximise rewards (good balls).

---

### Coherent movement of error-prone individuals through mechanical coupling [^3da4f49a]. Nature Communications (2023). High credibility.

Changing shape while following a reference trajectory

This experiment quantifies the performance of the Kilobot Soft Robot when instructed to deform its body while following a predefined trajectory. The robot is required to first advance in its default shape, then shrink and finally expand again, to restore its original shape. Each module receives two signals by the external localisation system, indicating when the corresponding shape changes are to be triggered. In addition, the frontal module receives, at 2-s intervals, one bit of information, indicating whether the reference trajectory is to the left or to the right of the robot (its CoM) with respect to its direction of motion.

We use a 4 × 4 Kilobot Soft Robot, and conduct 11 trials. Figure 4a shows a bird's-eye view of the experimental arena. The Kilobot Soft Robot is controlled to move along a straight (dashed) line, aligned with the x-axis. The initial and final positions for the robot (its CoM) are set at about 40 cm and 180 cm from the left, respectively. The vertical dotted lines, positioned at 60 cm from the left and 60 cm from the right, respectively, represent the positions where a change in the shape is to be triggered (as soon as the frontal module P 1 reaches the corresponding line). Figure 4b shows, for each trial, the distortion with respect to the square lattice shape, measured during the experiment. The Kilobot Soft Robot successfully reached the final stage in all but one trial (Trial 3). The distortion values are computed as the mean squared difference from 90° for all the angles among the modules: Large values indicate that several angles were significantly different from 90°, implying that the body of the Kilobot Soft Robot is shrunk. The figure shows that the distortion was large when the body was expected to be shrunken, that is, when the position of the CoM was between the two vertical lines indicated in Fig. 4a. The shape change was relatively swift and was completed within a travelled distance of 10–20 cm. Once the robot reached the line that triggers the first change in shape (i.e. to shrink), the distortion values rapidly increased, almost to the reference value. When reaching the line that triggers the second change in shape (i.e. to restore the original configuration), the distortion rapidly reduced, though not entirely to the original value but to values comparable to experiments that did not require deformation (see Fig. 2g). Figure 4b also reveals considerable variability between trials. Due to significant variation in the ability of individual modules to self-propel (Fig. 2b), in relatively small aggregates (i.e. 16 modules) the variation between repetitions can be high. Nevertheless, the results show that in all but one of the trials the robot succeeded in shrinking and expanding its shape.

---

### Coherent movement of error-prone individuals through mechanical coupling [^9ca6de29]. Nature Communications (2023). High credibility.

The motion control algorithm assumes right angles as the reference, thereby realising a square lattice configuration. The deformation control algorithm is identical to the motion control algorithm, apart from using a time-varying input as the reference instead. Details are provided in the 'Algorithms' section of the 'Methods'.

We conducted a series of studies to evaluate the performance of the Kilobot Soft Robot in different configurations, including its ability to move in the absence of external cues, to follow a reference trajectory, to change the shape of its body while following a reference trajectory, and its performance for different levels of link rigidity.

In all studies, the distributed algorithms are responsible for controlling the movement and shape of the robot using only local communication among its modules (see 'Algorithms' section under 'Methods'). The first experiment requires the Kilobot Soft Robot to produce coherent forward movement with respect to its initial pose. The motion control algorithm lets all modules perform their default behaviour — to move forward — provided they do not detect significant deformations in their local neighbourhood. The movements of a module (forward, and corrective turns, where applicable) are all within its local coordinate system. Two other experiments require the Kilobot Soft Robot to follow a reference trajectory. For these experiments, we opted to provide the head module (P 1) with binary feedback on the Kilobot Soft Robot's position relative to the trajectory. Hence, the head module moves according to the received feedback. The feedback is not shared with the other modules, which are oblivious to the external situation, and move forward by default. However, as the head module follows a curved trajectory, local deformations occur, which in turn prompt nearby modules to adjust their poses. The effect hence propagates through the aggregate, enabling the latter to follow the curved trajectory while maintaining its formation. Although our experiments confirm that a single module is sufficient to bias the movement of a relatively large aggregate towards a desired direction, as already acknowledged and modelled in animaland robot collectives, this module also represents a single point of failure. In fact, in one of the trials of the deformation experiment, the front module exhibited a fault, which prevented the system from completing its task. As an alternative, feedback about the reference trajectory could be provided to a set of modules and the modules' membership for this set could dynamically evolve over time.

---

### Lice and scabies: treatment update [^b7a97607]. American Family Physician (2019). High credibility.

Regarding screening and diagnosis for scabies, more specifically with respect to diagnosis, AAFP 2019 guidelines recommend to suspect scabies in patients with a pruritic, papular rash in the typical distribution and pruritus in close contacts. Recognize that the classic burrows in webs and creases may not be present.

---

### Population coding of conditional probability distributions in dorsal premotor cortex [^d76b111b]. Nature Communications (2018). Medium credibility.

Methods

Behavioral paradigms

Random-target experiment: Three monkeys (Monkeys M, T, and C) performed a random-target reaching task (similar to the experiments in refs.) in which they controlled a computer cursor using arm movements (Fig. 1). Monkeys were seated in a primate chair while they operated a two-link planar manipulandum. Arm movements were constrained to a horizontal plane within a workspace of 20 cm × 20 cm. On each trial, the monkey consecutively reached to four targets (2 cm × 2 cm squares), with each new target appearing once the monkey reached the previous target. More precisely, once a target was reached, a new target was triggered 100 ms later, as long as the cursor remained on the target. The target appeared on-screen 96 ms after this trigger on average, due to delays from graphics processing and the monitor refresh rate. In accordance, the monkey was required to keep the cursor on the target for an additional 100 ms after a new target was triggered. Thus, in total there was a 200 ms hold period after landing on the target. This brief hold period forced the monkeys to decelerate as they approached the target, but was not so long that the monkeys completely stopped on the target. After a successful trial (four successful reaches), the monkey received a liquid reward. The next trial started after a delay of one second with a new random target presentation.

Target locations were chosen to be 5–15 cm from the current target. Specifically, they were chosen as follows. (1) Randomly choose a distance between 5 and 15 cm, and an angle between 0° and 360° for the new target (relative to the current target). (2) If the new target falls outside of the workspace, add 90° to the angle and set the distance to be 5 cm. (3) Repeat step 2 until the target is in the workspace.

Many of the analyses are aligned to target onset. These experiments did not use a photodiode to determine the exact moment the target was displayed. Thus, in all analyses, the target onset time we used was the time the computer sent the target command plus the average delay time (96 ms).

---

### The sex of organ geometry [^d515f58a]. Nature (2024). Excellent credibility.

Measurements of proximity

The proximity between meshes was measured in R v.3.6.0. All surface meshes from the organ segmentations were simplified using quadric edge collapse decimation in Meshlab (v.2020.07)to reduce the number of faces to 1%, other than the testes apical tip meshes which contained few faces so were instead reduced to 10%. Mesh vertex coordinates were then read into R and the minimal distance between each vertex on organX and all the vertices on organY was calculated using a nearest neighbour algorithm using the RANN package (v.2.6.1). For reference to the midgut loops of the gut or for plotting along gut length, the centreline coordinates were replotted as 100 equally spaced points using the nat package (v.1.8.18). The centreline is then related to the gut mesh by finding the nearest 20 vertices on the mesh for every centreline point. The minimum distance of these 20 vertices to organY is then assigned to the centreline point for averaging and for plotting. For restricting to midgut loops, the landmarks were used to cut the centreline. Code is available on GitHub through Zenodo (10.5281/zenodo.10905446).

For visualization of proximities as shown in figures, the Hausdorff Distance function in Meshlab, was used which samples each vertex of meshX and finds the closest point on meshY to generate a minimal distance value between meshes for each vertex. These minimal distances were then displayed on the mesh as a heatmap in the Paraview software (v.5.10.0).

Crop duct quantifications

The directions of the crop duct leaving the proventriculus and travelling through the thorax to enter the crop were manually recorded from viewing the microCT scans from several planes in ITK-snap. Four different configurations were recorded: passing from left to right in an s-shaped pattern, passing from left to right in a straight line, staying on one side of gut and inverted passing from right to left.

Position of the crop and contact it made with the ovaries was manually scored from viewing the microCT scans in several planes in ITK-snap.

---

### Diagnosis, management and treatment of the Alport syndrome-2024 guideline on behalf of ERKNet, ERA and ESPN [^45eede36]. Nephrology, Dialysis, Transplantation (2025). High credibility.

Regarding diagnostic investigations for Alport syndrome, more specifically with respect to hearing assessment, ERA/ERN ERKNet/ESPN 2025 guidelines recommend to consider obtaining a hearing evaluation at diagnosis or upon reaching adulthood in female patients with X-linked alport syndrome, and then every 5 years in the absence of hearing loss symptoms.

---

### Venous thromboembolism: diagnosis and treatment [^bb2a0bb8]. American Family Physician (2025). High credibility.

Regarding classification and risk stratification for pulmonary embolism, more specifically with respect to risk stratification, AAFP 2025 guidelines recommend to use validated clinical prediction rules to estimate the pretest probability of VTE and guide further evaluation.

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^69f4e3a1]. Kidney International (2024). High credibility.

Regarding classification and risk stratification for chronic kidney disease, more specifically with respect to risk prediction, KDIGO 2024 guidelines recommend to use an externally validated risk equation to estimate the absolute risk of kidney failure in patients with CKD stages 3–5.

---

### Venous thromboembolism: diagnosis and treatment [^72348313]. American Family Physician (2025). High credibility.

Regarding diagnostic investigations for deep vein thrombosis, more specifically with respect to assessment of pretest probability, AAFP 2025 guidelines recommend to use validated clinical prediction rules to estimate the pretest probability of VTE and guide further evaluation.

---

### Quantifying the dynamics of failure across science, startups and security [^6acaa77f]. Nature (2019). Excellent credibility.

Human achievements are often preceded by repeated attempts that fail, but little is known about the mechanisms that govern the dynamics of failure. Here, building on previous research relating to innovation 1–7, human dynamics 8–11 and learning 12–17, we develop a simple one-parameter model that mimics how successful future attempts build on past efforts. Solving this model analytically suggests that a phase transition separates the dynamics of failure into regions of progression or stagnation and predicts that, near the critical threshold, agents who share similar characteristics and learning strategies may experience fundamentally different outcomes following failures. Above the critical point, agents exploit incremental refinements to systematically advance towards success, whereas below it, they explore disjoint opportunities without a pattern of improvement. The model makes several empirically testable predictions, demonstrating that those who eventually succeed and those who do not may initially appear similar, but can be characterized by fundamentally distinct failure dynamics in terms of the efficiency and quality associated with each subsequent attempt. We collected large-scale data from three disparate domains and traced repeated attempts by investigators to obtain National Institutes of Health (NIH) grants to fund their research, innovators to successfully exit their startup ventures, and terrorist organizations to claim casualties in violent attacks. We find broadly consistent empirical support across all three domains, which systematically verifies each prediction of our model. Together, our findings unveil detectable yet previously unknown early signals that enable us to identify failure dynamics that will lead to ultimate success or failure. Given the ubiquitous nature of failure and the paucity of quantitative approaches to understand it, these results represent an initial step towards the deeper understanding of the complex dynamics underlying failure.

---

### A biophysical account of multiplication by a single neuron [^7fc491ba]. Nature (2022). Excellent credibility.

In closed-loop experiments, bar-fixation was assessed using a 10°-wide dark vertical bar, the position of which along the azimuth was controlled in real time by the rotation of the spherical treadmill (Δbar position = −rotation about z axis, updated every ~9 ms). The bar appeared at a random position between −180° and 180° at the start of each 20 s trial, during which the fly could control the bar's position through its walking behaviour. One experiment (~60 min) consisted of 180 trials, the first 40 of which were not analysed, as they served to equilibrate the temperature and to accustom the fly to the virtual environment. For the results presented in Extended Data Fig. 10d–f, each experiment consisted of 80 longer multi-stimulus trials, the first 10 of which were excluded. Only trials with a forward walking velocity of ≥ 0.40 cm s −1 and flies with at least 50 (20 for Extended Data Fig. 10d–f) of such trials were included in the analysis. To avoid possible turning bias (for example, due to skewed mounting), flies whose average turning deviated from zero by > 10° s −1 were excluded. Probability density functions of bar positions were calculated for each 20 s trial using a bin width of 5° before averaging over trials. The measure 'fixation in front' was obtained by summing the probabilities of finding the bar in a 60° window in front of the fly and averaging these probabilities over trials.

---

### Hysteresis stabilizes dynamic control of self-assembled army ant constructions [^b71b81bb]. Nature Communications (2022). High credibility.

Mechanistic models

Living army ant bridges adaptively respond to changes in the geometry of the surrounding terrain. To understand how this response is dynamically controlled, we developed three behavioral models of individual decisions to join or leave structures — two linear with respect to the gap perturbation and one nonlinear — as mechanistic hypotheses. Note that joining and leaving events do not appear to be directly prompted by changes in gap size, as the density of events is uniform across the 30-s intervals between adjustments (Supplementary Fig. 10). We focused first on whether simulations of these models under the conditions of our field experiments can reproduce the hysteresis we observed, which cannot be simply explained by factors previously reported to affect these structures, such as traffic and gap size. We then simulated these models' behavior when built on terrain that shifts slightly back and forth, as we expect these vibration-like movements to be common in the ants' environment and hysteresis is a known mechanism for damping oscillations. We were particularly interested in whether nonlinear mechanisms are required to explain the collective bridge dynamics because nonlinear responses are an important feature of many types of complex emergent phenomena, and implicated in engineered hysteresis –. All three models were parameterized using the data; none of the models include any free parameters that we tuned.

Linear models: baseline and delay

We explored two data-driven linear models of ants joining and leaving bridges (Fig. 3). These are fixed-probability models because they rely on the assumption that individuals' probability of joining and leaving is constant during each phase. It is reasonable to expect such constant behavior, as the rate of perturbation in our experiments was constant at 2 mm/min. We simulated the number of ants in a bridge resulting from stochastic joining and leaving events, with the restriction that the number of ants leaving cannot be larger than the current number in the bridge. Each simulation timestep corresponds to a 30-s gap interval in the real experiments. The numbers of joining and leaving events in each timestep were drawn from negative binomial distributions fitted to the data (see Fig. 3a and Methods: Models). During the expansion, the mean number of joining and leaving events in each 30 s timestep were 1.13 and 0.67 (dispersion parameter, θ = 1.33 and 1.98), respectively, and during the contraction, there were an average of 0.33 and 1.04 joining and leaving events (θ = 0.65 and 8.10) in each step, respectively.

---

### Pushing the boundary of quantum advantage in hard combinatorial optimization with probabilistic computers [^4d8361ad]. Nature Communications (2025). High credibility.

Recent demonstrations on specialized benchmarks have reignited excitement for quantum computers, yet their advantage for real-world problems remains an open question. Here, we show that probabilistic computers, co-designed with hardware to implement Monte Carlo algorithms, provide a scalable classical pathway for solving hard optimization problems. We focus on two algorithms applied to three-dimensional spin glasses: discrete-time simulated quantum annealing and adaptive parallel tempering. We benchmark these methods against a leading quantum annealer. For simulated quantum annealing, increasing replicas improves residual energy scaling, consistent with extreme value theory. Adaptive parallel tempering, supported by non-local isoenergetic cluster moves, scales more favorably and outperforms simulated quantum annealing. Field Programmable Gate Arrays or specialized chips can implement these algorithms in modern hardware, leveraging massive parallelism to accelerate them while improving energy efficiency. Our results establish a rigorous classical baseline for assessing practical quantum advantage and present probabilistic computers as a scalable platform for real-world optimization challenges.

---

### Neural landscape diffusion resolves conflicts between needs across time [^f41291ec]. Nature (2023). Excellent credibility.

Simulations of the forced-transition model

To assess an alternative model of choice dynamics (Extended Data Fig. 9) in which switches are driven by an external forcing function (as opposed to autonomously via the balance between noise and gradient), we preserved the energy landscape structure but modified the noise scale such that no switches occurred spontaneously over the duration of the simulation. This change has the effect of reducing our model to a multi-stable attractor system in which transitions wholly depend on external inputs to the system. We then incorporated a randomly occurring input force with magnitude sufficient to push the system from one landscape well to the other. We did not add noise to this force as it would reduce the number of successful transitions below that of the experimental data. In general, increasing the noise on the added force requires increasing the frequency of external-force events, such that this alternative model becomes less distinguishable from the diffusion landscape model we seek to compare it to.

Phase portraits

Phase portraits (Extended Data Fig. 9) for all simulated or experimental rewarded trials were generated using the current trial value of position along the goal dimension (simulated or measured in experimental data by projection of baseline activity onto a goal dimension fit by ridge regression, with regularization alpha parameter = 20) and the change in position along the goal dimension from trial to trial (which we define to be the velocity of activity along the goal dimension over a d t equal to the average time between trials). Trials were assigned to either stay or switch categories depending on whether the reward choice was the same as the previous reward (stay) or different (switch). Densities for stay and switch trials in the transition zone were quantified as described in the legend for Extended Data Fig. 9 and normalized to sum to 1. For model density quantifications, the simulated dataset trial data were resampled 1,000 times such that the number of stay and switch trials (across all simulated sessions) matched the fraction in the experimental dataset. This resampling controls for systematic bias in the quantified densities (Extended Data Fig. 9g, h) generated by stochastic differences in dataset switch rate.

Statistics and reproducibility

Statistical parameters are described in legends. Box plots span lower and upper quartiles; lines indicate median values; whiskers, range of values within 1.5 times the interquartile range. Unless otherwise specified, confidence intervals were generated by bootstrapping.

Reporting summary

Further information on research design is available in the Nature Portfolio Reporting Summary linked to this article.

---

### Bumetanide [^d0437f55]. FDA (2025). Medium credibility.

WARNING

Bumetanide injection is a potent diuretic which, if given in excessive amounts, can lead to a profound diuresis with water and electrolyte depletion. Therefore, careful medical supervision is required, and dose and dosage schedule have to be adjusted to the individual patient's needs [see Dosage and Administration].

---

### Generally overlooked fundamentals of bacterial genetics and ecology [^d4d21fc5]. Clinical Infectious Diseases (2002). Low credibility.

Several important aspects of the antimicrobial resistance problem have not been treated extensively in previous monographs on this subject. This section very briefly updates information on these topics and suggests how this information is of value in assessing the contributions of human and agricultural use of antimicrobial agents on the problem of increasing antimicrobial resistance. The overall themes are (1) that propagation of resistance is an ecological problem, and thus (2) that ameliorating this problem requires recognition of long-established information on the commensal microbiota of mammals, as well as that of recent molecular understanding of the genetic agents involved in the movement of resistance genes.

---

### Arrays of individually controlled ions suitable for two-dimensional quantum simulations [^ee7134ad]. Nature Communications (2016). Medium credibility.

Results

Trap arrays and control potentials

Our surface ion trap chip is fabricated in similar manner to that described in ref.and consists of two equilateral triangular trap arrays with side length of ≃40 and ≃80 μm, respectively (Fig. 1a, b), both with a distance of ≃40 μm between the ions and the nearest electrode surface. The shapes of radio-frequency (RF) electrodes of the arrays are optimized by a linear-programming algorithm that yields electrode shapes with low fragmentation, and requires only a single RF-voltage source for operation. To design different and even non-periodic arrays for dedicated trap distances, we can apply the same algorithm to yield globally optimal electrode shapes. Resulting electrode shapes may look significantly different, but will have comparable complexity, spatial extent and the same number of control electrodes per trap site. Therefore, we expect that different arrays will not require different fabrication techniques (Methods). The two arrays are spaced by ≃5 mm on the chip, and only one of them is operated at a given time. Although we achieve similar results in both arrays, the following discussion is focussed on the 80 μm array.

Three-dimensional confinement of 25 Mg + ions is provided by a potential φ RF oscillating at Ω RF from a single RF electrode driven at Ω RF /(2 π) = 48.3 MHz with an approximate peak voltage U RF = 20 V. Setting the origin of the coordinate system at the centre of the array and in the surface plane of the chip, the RF potential features three distinct trap sites at T0 ≃(−46,0,37) μm,… Owing to the electrode symmetry under rotations of ± 2 π /3 around the z -axis, it is often sufficient to consider T0 only, as all our findings apply to T1 and T2 after an appropriate rotation. Further, the RF potential exhibits another trap site at ≃(0,0,81) μm (above the centre of the array); this 'ancillary' trap is used for loading as well as for re-capturing ions that escaped from the other trap sites. We approximate the RF confinement at position r by a pseudopotential, cp. ref. where Q denotes the charge and m the mass of the ion, and E RF (r) is the field amplitude produced by the electrode. Calculations of trapping potentials are based on ref.and utilizing the software package. Equipotential lines of φ ps are shown in Fig. 1c–e.

---

### Methodologies for the development of CHEST guidelines and expert panel reports [^41b204f9]. Chest (2014). Medium credibility.

CHEST guideline voting thresholds and approval criteria — balloting scope, participation requirements, and approval cutoffs are specified: "Recommendations are presented with supporting evidence and voted upon in their entirety, including grades and associated remarks". "Under extraordinary circumstances, if requested, specific grades may be discussed and voted upon separately from the recommendations". "The GRADE grid (Fig 2) defines the level of agreement or disagreement with the proposed recommendations". "All votes require 75% participation of those eligible to vote". "Approval requires at least 80% of the votes combined for 'strongly agree' or 'agree'. "Negative recommendations are similarly approved, with negative connotation in the recommendation itself and not by votes in disagreement". "Disagreement is defined as voting against the proposed recommendation as written".

---

### United European Gastroenterology (UEG) and European Society for Neurogastroenterology and Motility (ESNM) consensus on gastroparesis [^cb35b179]. United European Gastroenterology Journal (2021). High credibility.

Regarding classification and risk stratification for gastroparesis, more specifically with respect to risk factors, ESNM/UEG 2021 guidelines recommend to recognize that the prognosis of GP depends on the cause.

---

### Diagnosis, management and treatment of the Alport syndrome-2024 guideline on behalf of ERKNet, ERA and ESPN [^6f42c569]. Nephrology, Dialysis, Transplantation (2025). High credibility.

Regarding diagnostic investigations for Alport syndrome, more specifically with respect to genetic testing, ERA/ERN ERKNet/ESPN 2025 guidelines recommend to recognize that no targeted gene panel is 100% sensitive for the different types of genetic changes that can cause Alport syndrome, with well-designed gene panels achieving a sensitivity of over 85% for COL4A3/4/5 gene analysis in detecting pathogenic variants.