# Medical Question & Answer

**Sample ID**: a1ef5a14-8b10-fbde-b2c2-1f915c50e9ac
**Dataset Index**: 16012

---

## Question

Normally, one would expect the brightness of an object to increaseas more light is reflected from it, however, the perceivedbrightness of an object also depends on the field thatsurrounds it. Discuss this phenomenon including a methodfor its demonstration.

Answer Choices:
A. The perceived brightness of an object depends on the light source's distance from the object, with closer light sources making the object appear brighter.
B. The perceived brightness of an object depends on the viewer's distance from the object, with objects appearing brighter when the viewer is closer.
C. The perceived brightness of an object depends on its size
D. The perceived brightness of an object depends on the angle at which light hits it, with direct angles increasing brightness.
E. The perceived brightness of an object depends on the spectral composition of the light source, with certain wavelengths enhancing brightness more than others.
F. The perceived brightness of an object only depends on the amount of light reflected from it
G. The perceived brightness of an object is influenced by the color of the object itself, with lighter colors always appearing brighter than darker colors.
H. The brightness of an object will always increase when more light is reflected from it
I. The perceived brightness of an object can be demonstrated by the use of polarized lenses to reduce glare and enhance brightness.
J. The perceived brightness of an object depends on the contrast between the object and its surrounding field. This can be demonstrated by placing samples of medium gray paper on different colored backgrounds.

---

## Answer

> Let's see… What do we have here? The user is asking which option correctly explains how the perceived brightness of an object depends on its surrounding field and what demonstration best illustrates that phenomenon. Let's break this down step-by-step. First, I need to think about the core principle that perceived brightness is context-dependent, not just a function of reflected light. Then, I should verify which answer choice matches that principle and why the others fail. Next, I will review the classic demonstration that isolates contrast effects. Finally, I will consider the neural mechanisms and any exceptions that might confuse interpretation, before concluding with the best-supported choice.

> Let me first confirm the premise: perceived brightness is not simply the amount of light reflected from a surface. It is strongly modulated by spatial context, including the luminance and chromatic properties of the surround, which can make identical patches appear lighter or darker depending on their background, a hallmark of simultaneous contrast and related contextual effects [^32a88a33] [^5e4898de].

> Wait, let me verify the options against this principle. Options A, B, C, and D all tie perceived brightness to physical factors like source distance, viewer distance, object size, or illumination angle; while these can change retinal luminance, they do not capture the contextual modulation the question is asking about, so they are off-target for the phenomenon described [^notfound]. Option E about spectral composition is relevant to color appearance and chromatic adaptation, not to achromatic brightness contrast, so it does not answer the question either [^074ecef0]. Option F claims brightness depends only on reflected light, which directly contradicts the context dependence demonstrated in lightness illusions, so I should reject that outright [^32a88a33]. Option G oversimplifies: while lighter colors often appear brighter, simultaneous contrast can make a dark gray on a light background look brighter than a light gray on a dark background, so "always" is too strong and misses the context effect [^notfound]. Option H is a blanket statement that ignores well-known exceptions where more reflected light does not increase perceived brightness due to surround effects, so it is incorrect [^notfound]. Option I introduces polarized lenses, which reduce glare and can change visibility, but that is not a demonstration of surround contrast effects, so it does not fit the question's request for a demonstration of contextual brightness modulation [^notfound].

> Hold on, I should verify the correct choice. Option J states that perceived brightness depends on the contrast between the object and its surrounding field and proposes placing medium gray paper on different colored backgrounds, which is precisely the classic simultaneous contrast demonstration showing that the same gray patch appears lighter on a dark background and darker on a light background, directly illustrating surround-dependent brightness perception [^notfound].

> I will now examine why this works mechanistically. The visual system encodes brightness relative to local context through center-surround processing and cortical gain control, so neural responses to a fixed luminance patch are modulated by the surround, producing illusory brightness shifts even when the patch's physical luminance is unchanged. This is supported by psychophysical demonstrations and neurophysiological findings of surround modulation in early visual cortex [^32a88a33] [^f68d4d02].

> But wait, what if someone argues that increasing reflected light must always increase perceived brightness? Let me reconsider that objection. While increasing physical luminance generally increases brightness, simultaneous contrast and related illusions show that surround context can override or reverse this relationship locally, making a patch appear darker when surrounded by high luminance and brighter when surrounded by low luminance, despite identical patch luminance, which is exactly why the gray-on-backgrounds demo is so compelling and why option H is misleading [^32a88a33] [^5e4898de].

> Final answer: J. The perceived brightness of an object depends on the contrast between the object and its surrounding field. This can be demonstrated by placing samples of medium gray paper on different colored backgrounds, which makes the same gray appear lighter on a dark background and darker on a light background, illustrating surround-dependent brightness perception [^notfound].

---

The correct answer is **J**. Perceived brightness is strongly influenced by the contrast between an object and its surrounding field, a phenomenon known as simultaneous contrast. This can be demonstrated by placing identical medium-gray squares on different-colored backgrounds; the square on a dark background appears lighter, while the same square on a light background appears darker, even though the physical light reflected from the squares is identical. This effect shows that perceived brightness is not determined by reflected light alone but is shaped by contextual contrast [^32a88a33].

---

## Explanation of the phenomenon

Perceived brightness is **context-dependent**: the same object can appear brighter or darker depending on the luminance and color of its surround. This is a well-established perceptual illusion known as **simultaneous contrast**, in which the visual system compares the luminance of an object to its background, altering its perceived brightness [^32a88a33].

---

## Demonstration of the phenomenon

A classic demonstration is to place identical medium-gray squares on different-colored backgrounds (e.g. white, black, and gray). Observers consistently report that the square on the dark background appears lighter, whereas the square on the light background appears darker, even though the squares reflect the same amount of light. This effect is robust across observers and lighting conditions, confirming that **contextual contrast** drives perceived brightness [^notfound].

---

## Scientific basis of the phenomenon

The effect arises from **neural processing in the visual system**, particularly center-surround antagonism in retinal ganglion cells and early visual cortex. This circuitry enhances contrast by suppressing responses when the surround is similar to the center and increasing responses when they differ, thereby amplifying brightness differences relative to the background [^f68d4d02].

---

## Implications and applications

Understanding this effect has practical implications in art, design, and visual communication, where **manipulating contrast** can control perceived brightness and visibility. It also underscores that perceived brightness is a **construct of the visual system** rather than a direct measure of physical luminance [^0fc98eb6].

---

## Summary of key points

| **Key point** | **Explanation** |
|-|-|
| Perceived brightness is context-dependent | The same object can appear brighter or darker depending on the surround [^32a88a33] |
| Simultaneous contrast | A perceptual illusion where brightness is altered by background contrast [^notfound] |
| Neural mechanism | Center-surround antagonism in retina and cortex enhances contrast [^f68d4d02] |
| Practical implications | Used in art, design, and visual communication to control perceived brightness [^notfound] |

---

The correct answer is **J**, and the phenomenon is best demonstrated by placing identical gray squares on different backgrounds to show how contrast alters perceived brightness [^notfound].

---

## References

### Perceived luminance depends on temporal context [^5e4898de]. Nature (2004). Excellent credibility.

Brightness--the perception of an object's luminance--arises from complex and poorly understood interactions at several levels of processing. It is well known that the brightness of an object depends on its spatial context, which can include perceptual organization, scene interpretation, three-dimensional interpretation, shadows, and other high-level percepts. Here we present a new class of illusion in which temporal relations with spatially neighbouring objects can modulate a target object's brightness. When compared with a nearby patch of constant luminance, a brief flash appears brighter with increasing onset asynchrony. Simultaneous contrast, retinal effects, masking, apparent motion and attentional effects cannot account for this illusory enhancement of brightness. This temporal context effect indicates that two parallel streams--one adapting and one non-adapting--encode brightness in the visual cortex.

---

### Influence of scene statistics on colour constancy [^074ecef0]. Nature (2002). Excellent credibility.

The light reflected from an object depends not only on the surface properties of this object but also on the illuminant. The same is true for the excitations of the photoreceptors, which serve as the basis for the perceived colour. However, our visual system has the ability to perceive constant surface colours despite changes in illumination. The average chromaticity of the retinal image of a scene depends on the illumination, and thus might be used by the visual system to estimate the illumination and to modulate the correction that subserves colour constancy. But this measure is not sufficient: a reddish scene under white light can produce the same mean stimulation as a neutral scene in red light. Higher order scene statistics-for example, the correlation between redness and luminance within the image-allow these cases to be distinguished. Here we report that the human visual system does exploit such a statistic when estimating the illuminant, and gives it a weight that is statistically appropriate for the natural environment.

---

### Brightness illusions drive a neuronal response in the primary visual cortex under top-down modulation [^7609e86f]. Nature Communications (2024). High credibility.

Our results demonstrate, at a different level of detail compared to fMRI BOLD, the single cell and V1 cellular microcircuit-level neuronal correlates of visual processing of illusory brightness. Moreover, we show its dependence on feedback from HVAs. These findings were made possible by translating an illusory brightness stimulus from studies in humans into a compatible format for electrophysiology in mice. However, one limitation of this experimental paradigm is that it is challenging to make strong claims about how single unit activity relates to perception. Therefore, we measured the reflexive pupil response to the illusory and real gratings as an indirect measure of perceived luminance, as has been done previously in human subjectsand in rats. Our findings that the mouse pupil responds in opposing directions for these two stimuli, which humans perceive as getting darker or brighter than the background, are potentially consistent with mice and humans similarly perceiving these stimuli. While future work is needed to support this limited claim (e.g. with an overt behavioral report in a brightness discrimination task), our findings do unravel, at the single-cell level, the V1 processing (or “sensing”) of illusory brightness which may be seen as distinct from attaching an interpretation or meaning to stimuli as being brighter (“perception”). By building on our indirect measure of perceived luminance, future work can use overt behavioral reports to establish a link between V1 single cell activity and subjective perception of brightness illusions.

---

### The misuse of colour in science communication [^0fc98eb6]. Nature Communications (2020). High credibility.

BOX 1: Human colour perception 

Colour is not inherent in objects. A perceived colour is the portion of light that is reflected from a surface and translated into a specific colour by our eyes and brain (Box Fig. 1). A certain colour is perceived via its hue, the true tint (i.e. yellow, orange, red, violet, blue or green), and its luminosity (the measure of how bright or dark a hue is). Within the eye, one type of light receptors, the rod cells, process achromatic information (i.e. lightness or grey-scale vision), which is derived mostly from the light’s energy. The other type, the cone cells, handle chromatic information (the hue) mostly from the light’s wavelength. The latter transmit information to the brain and create the sensation of colour that is so familiar to most of us.

Two thirds of all cone cells process longer wavelengths of light (i.e. colours like red, orange, yellow), which allows the human eye to perceive more colour detail across warmer colours than for cooler colours. Greenish colour gradients tend to under-represent a given data variation compared to yellow-red gradients. Three types of cone cells (for short, medium and, long wavelengths) build the trichromatic visual system that can, as a whole, represent all colours in our visual spectrum –.

The physiological prerequisites for perceiving colour suggest that there is no uniform colour perception among individuals; several physiological deviations can lead to a shift in colour perception, which, in general, is hardly measurable. However, it is not unlikely that at least one of the cone cell types is altered, defect, or even absent, which induces a significant shift in colour vision. Such a shift is commonly referred to as colour-vision deficiency (CVD), or colour blindness, and can be modelled by a given combination of the three fundamental spectral sensitivity functions representing short, medium and long wavelengths of the light(as represented in Fig. 2). The most common form of colour-vision deficiency is the red–green dichromatism, called deuteranomaly, concerning the M-cone and causing red and green to appear indistinguishable. Protanomaly, concerning the L-cone, and tritanomaly, concerning the S-cone cause reduced sensitivity to red and blue light, respectively. Total colour blindness is, fortunately, very rare, but does exist.

---

### Photonic thermal management of coloured objects [^5feded7e]. Nature Communications (2018). Medium credibility.

Methods

Spectrum to colour calculation

The colours perceived by the human eye result from the interplay between the sensitivity of the eye’s three cone cells, the spectral intensity of the light source, and the spectral reflection from the surface. The sensitivities of the three cone cells responsible for colour vision at short, middle, and long wavelengths (Fig. 1a) are numerically represented by three colour matching functions,,and(Supplementary Note 5), which were established from experiments on a standard observer by the International Commission on Illumination (CIE) in 1931. The colour matching functions can be thought of as the spectral sensitivity curves of three linear light detectors yielding the CIE tristimulus values X, Y and Z :where I (λ) is the spectral power distribution of the illuminant. Here we use a standard D65 illumination (Supplementary Note 5) to represent the typical outdoor illumination condition. r (λ) is the spectral reflectivity of the outdoor structure. Assuming the object is opaque, then r (λ) can be related with spectral absorptivity ε (λ) by r (λ) = 1 − ε (λ). The calculated CIE tristimulus values X, Y and Z can be used to determine the lightness and chromaticity of the colour. The lightness of the colour is determined by the parameter Y. And the chromaticity of the colour is determined by the normalized parameters:

The normalized parameters x and y are used to find the corresponding chromaticity in CIE 1931 colour space (Supplementary Note 5). One can also find the corresponding colour in a commonly used and perceptually uniform CIE LAB colour space, where ‘ L ’ represents the lightness, ‘ a ’ represents redness and greenness and ‘ b ’ represents yellowness and blueness. The combination of a and b determines colour chromaticity, which includes the relative saturation, or chroma, as well as the hue of the colour, as discussed in the main text. Converting X, Y, Z to L, a, b values can be done using the following equations:where X n, Y n, Z n are the tristimulus value of a reference white object, and:

---

### Perceptography unveils the causal contribution of inferior temporal cortex to visual perception [^a2a0c145]. Nature Communications (2024). High credibility.

What is the relationship between perceptograms and the preferred stimuli of their driving neurons? IT cortex is known for its strong object selectivity at the single cell, as well as ~1 mm 3 tissue scale,,. While the current OptoArray technology doesn’t allow neural recording, rendering us blind with respect to the object selectivity profile of the stimulated neurons, it is reasonable to assume heterogeneity of selectivity at the spatial scale perturbed by a single LED, in that the perturbed neural population conserves visual preference for a part of the shape space. Is perceptography simply another way to measure the stimulus preference of the stimulated neurons? Not necessarily. “Preferred stimuli” of neurons reveal how the visual signal is encoded in IT cortex, and Perceptograms show how the signal gets decoded from IT by the rest of the brain. These two do not necessarily match, and the relationship between the two can vary under different decoding frameworks. In some cases of sensory processing, neurons are tightly tuned to specific physical stimuli. Activation of such a neuron induces the appearance of its related sensory stimulus in perception. Such a direct one-to-one hypothetical relationship between the preferred stimulus of a sensory neuron and the percept it arises is known as the labeled line hypothesis. Alternatively, more complex decoding frameworks might govern the relationship between neuron’s stimulus preference and their causal impact on perception. For instance, a medium wavelength cone on the retina responds mostly to the green light, but its activation does not necessarily induce perception of the color green. The perceived color, in this case, depends on the activation ratio of other cone types as well as the position of the activated cone in the retinal cone mosaic,. Now, is the decoding schema of IT cortex a labeled line or a coarse codelike the case of color? Our results are not consistent with the labeled line framework. Assuming the labeled line hypothesis, one expects that stimulation of a given site in IT cortex induces perception of the preferred features of the targeted neurons independent of what is presented to the eyes. If this is the case, examination of perceptograms is expected to reveal common visual elements in the perceptograms obtained from the same channel. The results, though, show a completely different picture. Figure 5c depicts examples of perceptograms obtained from one cortical position in each of the two monkeys along with their corresponding seed images (more examples are provided in the supplementary materials, Supplementary Fig S1). The first property that is apparent in perceptograms is that their structure strongly depends on the seed image. Perceptograms that come from stimulation of a single point in IT cortex are typically very different from each other, lacking at least an obvious explicit common visual element. An analysis of the perceptograms using Yolo, a real-time object detection systemrevealed that 82% (StD = 21%) of the class-labels in the perceptograms are shared with their corresponding seed images. The analysis also showed that the added class-labels (compared to the seed) of the perceptograms acquired from a single channel have only a little in common with each other (0% and 7% in Sp and Ph, respectively), which is not different (t -test, p > 0.4 for both animals) from the overlap between the added class-labels obtained from different channels (0% and 10% in Sp and Ph respectively). This suggests that the pattern of neural activity in the cortex, which varies by the seed image, strongly influences the outcome of local stimulation in IT cortex. This is consistent with the recent findings about the vast activity landscape of IT neuronsand the idea that the activity of a neural unit is interpreted by the rest of the brain only in the context of the state of other similar neural units. These findings strongly encourage recording the neural activity together with perceptography, a point that is further dissected in the conclusion.

---

### Memory modulates color appearance [^40750e50]. Nature Neuroscience (2006). Medium credibility.

We asked human observers to adjust the color of natural fruit objects until they appeared achromatic. The objects were generally perceived to be gray when their color was shifted away from the observers' gray point in a direction opposite to the typical color of the fruit. These results show that color sensations are not determined by the incoming sensory data alone, but are significantly modulated by high-level visual memory.

---

### Experience can change the 'light-from-above' prior [^8d5c51ed]. Nature Neuroscience (2004). Medium credibility.

To interpret complex and ambiguous input, the human visual system uses prior knowledge or assumptions about the world. We show that the 'light-from-above' prior, used to extract information about shape from shading is modified in response to active experience with the scene. The resultant adaptation is not specific to the learned scene but generalizes to a different task, demonstrating that priors are constantly adapted by interactive experience with the environment.

---

### Context information supports serial dependence of multiple visual objects across memory episodes [^22880937]. Nature Communications (2020). High credibility.

Introduction

Visual cognition relies on the interplay between perception and memory. We create visual objects by integrating features that belong togetherand maintain object representations in visual working memory (WM), which we can access flexibly when objects are no longer visible. Objects can slightly change their appearance from moment to moment due to movement or changed lighting, without changing their identity. As these changes of the world around us are often foreseeable, current object representations can be based on preceding ones. Thus, the exploitation of short-term dependencies represents an important requisite of experienced environmental stability.

A series of recent studies examined in detail how an object representation encoded in the previous trial influences an object representation currently encoded into WM. In their seminal study, Fischer and Whitneyfound that the reported orientation in the current trial was systematically attracted by the orientation remembered in the previous trial. This bias was enhanced by spatial and temporal item proximity as well as by attentional selection and was termed ‘serial dependence’. It has since been observed for other modalities, including facial identity and expression,, spatial positions,, numerosity – or ensemble representations. As serial dependence reduces differences in the appearance of similar consecutive objects, it has been interpreted as promoting perceptual stability and continuity of a visual object over time.

If this interpretation was correct, which factors should support serial dependence? Following a single object over time requires some means of matching serial occurrences to decide whether the current object still represents the same or a novel object. This likely relies on matching occurrences according to similarities of their most relevant feature. Most previous studies examined serial dependence in a situation that comprised only a single relevant object per trial. In the real world, however, we are commonly confronted with situations where several objects have to be perceived and maintained in WM. In situations with multiple objects consisting of overlapping features, focusing on a single feature might not be sufficient. Instead, establishing object continuity should rely on the complete machinery that codes object identity in time and space, including coding of episodic regularities (e.g. serial position) and spatial positions as well as perceptual features like color that support object discrimination.

---

### Image segmentation and lightness perception [^32a88a33]. Nature (2005). Excellent credibility.

The perception of surface albedo (lightness) is one of the most basic aspects of visual awareness. It is well known that the apparent lightness of a target depends on the context in which it is embedded, but there is extensive debate about the computations and representations underlying perceived lightness. One view asserts that the visual system explicitly separates surface reflectance from the prevailing illumination and atmospheric conditions in which it is embedded, generating layered image representations. Some recent theory has challenged this view and asserted that the human visual system derives surface lightness without explicitly segmenting images into multiple layers. Here we present new lightness illusions--the largest reported to date--that unequivocally demonstrate the effect that layered image representations can have in lightness perception. We show that the computations that underlie the decomposition of luminance into multiple layers under conditions of transparency can induce dramatic lightness illusions, causing identical texture patches to appear either black or white. These results indicate that mechanisms involved in decomposing images into layered representations can play a decisive role in the perception of surface lightness.

---

### Neural adjustments to image blur [^c2f78fdf]. Nature Neuroscience (2002). Medium credibility.

Blur is an intrinsic feature of retinal images that varies widely across images and observers, yet the world still typically appears 'in focus'. Here we examine the putative role of neural adaptation in the human perception of image focus by measuring how blur judgments depended on the state of adaptation. Exposure to unfocused images has previously been shown to influence acuity and contrast sensitivity, and here we show that adaptation can also profoundly affect the actual perception of image focus.

---

### Why pictures look right when viewed from the wrong place [^ebfa2c28]. Nature Neuroscience (2005). Medium credibility.

A picture viewed from its center of projection generates the same retinal image as the original scene, so the viewer perceives the scene correctly. When a picture is viewed from other locations, the retinal image specifies a different scene, but we normally do not notice the changes. We investigated the mechanism underlying this perceptual invariance by studying the perceived shapes of pictured objects viewed from various locations. We also manipulated information about the orientation of the picture surface. When binocular information for surface orientation was available, perceived shape was nearly invariant across a wide range of viewing angles. By varying the projection angle and the position of a stimulus in the picture, we found that invariance is achieved through an estimate of local surface orientation, not from geometric information in the picture. We present a model that explains invariance and other phenomena (such as perceived distortions in wide-angle pictures).

---

### Temporal stability of stimulus representation increases along rodent visual cortical hierarchies [^5cb22522]. Nature Communications (2021). High credibility.

In ref. we showed that LI and LL afford better decoding of object identity than V1 and LM under various transformations, but this effect only emerges when the objects to discriminate have similar luminosity across transformations. Otherwise, objects are actually better discriminated based on V1 than LL representations. This is because information conveyed by neural responses about low-level visual properties, such as luminosity and contrast, decreases substantially from V1 to LL. Such information pruning is consistent with ventral-like processing but has the unexpected effect of making it easier for V1 neurons to discriminate objects when their average luminance (across transformations) is different.

Given the stimulus set used in ref.(bright, isolated shapes against a black background), it was possible to restrict decoding to object pairs with similar luminance, thus revealing the larger invariance of LL. This was not possible with our current, more naturalistic stimuli. Thus, differences in luminance and other low-level properties likely played a major role in allowing V1 to afford the best decoding performance. In fact, given the continuous nature of our dynamic stimuli, luminance and contrast differences between movie frames used to train a classifier would be preserved in the preceding and following frames. They would only vanish at long time lags from the training bins.

---

### ACR-AAPM-SIIM practice parameter for determinants of image quality in mammography [^9e4c6ab7]. ACR/AAPM/SIIM (2022). High credibility.

Mammographic image display—luminance response and contrast: The brightness and contrast of grayscale medical images result from the luminance in relation to the image gray level values, and current guidance regarding ambient luminance, minimum and maximum luminance, and display contrast response for displays is provided in the ACR-AAPM-SIIM Technical Standard for Electronic Practice of Medical Imaging; within the applicable luminance range, the device should render the image details with a consistent grayscale that should be measured and maintained over time, and the contrast (luminance) response of mammographic displays should comply with the AAPM Task Group 18 and Task Group 270 recommendations.

---

### Tomographic near-eye displays [^d876cc7e]. Nature Communications (2019). High credibility.

Figure 6 illustrates two illumination strategies: primitive and optimal approaches. In the primitive strategy, each pixel is illuminated by the minimized time when its image is formed at the desired depth. On the other hand, the optimal strategy employs a specific backlight operation that minimizes the cost function described above. If there is no offset luminance and a lower bound of brightness, the primitive and optimal strategies are identical. When the lower bound of brightness is determined as, the primitive solution is to illuminate the pixel around the desired depth. However, the optimal solution has several lobes for the backlight operation to exploit higher-order intensity distribution. When the offset luminance of the display system is determined as, the display system should have enough brightness to surpass the offset luminance. In this condition, the optimal solution may have a longer illumination time than that of the lower bound, as shown in the figure. Compared with the primitive strategy, the optimal strategy enables tomographic displays to have a higher contrast with a sharper peak, so that users can accommodate the desired depth.

Fig. 6 
Description of optimal illumination strategy. We simulate different conditions according to the degree of offset luminance and desired brightness:,,, and. a We show the backlight operations according to the strategies and circumstances. b We demonstrate normalized contrast maps that are achieved by applying a corresponding backlight operation. Normalized contrast maps indicate the relative intensity of retinal images according to the spatial frequency and focal depths. c We provide contrast errors determined by the difference between the target and the reconstructed contrast maps. The differences between primitive and optimal strategies are highlighted by dotted or solid arrows and circles. An optimal illumination strategy allows more definite and precise contrast curves. Note that our prototype supposes the third circumstance:. Additional results are available in Supplementary Note 6

---

### Spatiotemporal mechanisms for detecting and identifying image features in human vision [^b71bad13]. Nature Neuroscience (2002). Medium credibility.

Our visual system constantly selects salient features in the environment, so that only those features are attended and targeted by further processing efforts to identify them. Models of feature detection hypothesize that salient features are localized based on contrast energy (local variance in intensity) in the visual stimulus. This hypothesis, however, has not been tested directly. We used psychophysical reverse correlation to study how humans detect and identify basic image features (bars and short line segments). Subjects detected a briefly flashed 'target bar' that was embedded in 'noise bars' that randomly changed in intensity over space and time. By studying how the intensity of the noise bars affected performance, we were able to dissociate two processing stages: an early 'detection' stage, whereby only locations of high-contrast energy in the image are selected, followed (after approximately 100 ms) by an 'identification' stage, whereby image intensity at selected locations is used to determine the identity (whether bright or dark) of the target.

---

### The dark side of gloss [^b8199027]. Nature Neuroscience (2012). Medium credibility.

Our visual system relies on the image structure generated by the interaction of light with objects to infer their material properties. One widely studied surface property is gloss, which can provide information that an object is smooth, shiny or wet. Studies have historically focused on the role of specular highlights in modulating perceived gloss. Here we show in human observers that glossy surfaces can generate both bright specular highlights and dark specular 'lowlights', and that the presence of either is sufficient to generate compelling percepts of gloss. We show that perceived gloss declines when the image structure generated by specular lowlights is blurred or misaligned with surrounding surface shading and that perceived gloss can arise from the presence of lowlights in surface regions isolated from highlights. These results suggest that the image structure generated by specular highlights and lowlights is used to construct our experience of surface gloss.

---

### The representation of perceived angular size in human primary visual cortex [^923e32ce]. Nature Neuroscience (2006). Medium credibility.

Two objects that project the same visual angle on the retina can appear to occupy very different proportions of the visual field if they are perceived to be at different distances. What happens to the retinotopic map in primary visual cortex (V1) during the perception of these size illusions? Here we show, using functional magnetic resonance imaging (fMRI), that the retinotopic representation of an object changes in accordance with its perceived angular size. A distant object that appears to occupy a larger portion of the visual field activates a larger area in V1 than an object of equal angular size that is perceived to be closer and smaller. These results demonstrate that the retinal size of an object and the depth information in a scene are combined early in the human visual system.

---

### Form vision from melanopsin in humans [^a15f1bc5]. Nature Communications (2019). High credibility.

The characteristics of melanopic vision (low spatiotemporal resolution and contrast sensitivity) preclude it from contributing to high spatial acuity vision. Nevertheless, the types of patterns to which melanopsin would be sensitive are common in everyday scenes. This raises the question of how melanopsin vision may contribute to image appearance. We find that subjects are able to distinguish greyscale patterns with augmented melanopsin contrast from those without. Consistent with previous descriptions of the experience of melanopsin-directed full-field and featureless stimuli, subjects record stimuli with augmented melanopsin contrast as differing in percepts related to ‘brightness’. Thus, subjects reliably reported greyscale patterns (gratings and images) with enhanced melanopsin contrast as ‘more distinct’. Moreover, when asked to describe the difference between regular and melanopsin-augmented greyscale images, subjects used adjectives such as ‘brighter’, ‘glowing’ and more ‘stand out’. In at least some ways then, the experience of additional melanopsin contrast is similar to that of enhanced luminance contrast. Previous studies based upon assessments of full-field stimuli or ambient lights have suggested that perceived ‘brightness’ is produced by a sum of luminance and melanopsin signals,. However, these have not gone so far as showing that there is no perceptual consequence for substituting luminance with melanopic radiance, and the experience of temporal modulations visible only to melanopsin has been described as quite peculiar. We find that at the limits of detection, including melanopsin contrast can compensate for low energy contrast (Fig. 5) but as the inclusion of chromatic contrast can have a similar effect, this is not good evidence of equivalence. Moreover, although subjects in this study were able to perform substantially better than chance at reporting the orientation of metameric gratings at low spatial frequencies, their subjective experience was that these did not look equivalent to low contrast (hard to discern) greyscale stimuli. While the latter gave a clear percept of oriented bars (when detectable), in many cases metameric gratings rather gave a more diffuse impression of a pattern, without individual elements being clearly visible per se. Thus, an important direction for future work will be to determine whether melanopsin is interchangeable with luminance contrast at the perceptual level, or supports a distinct percept related to ‘brightness’. Similarly, it will be important to ascertain how altering melanopsin contrast impacts the appearance of colour patterns and the detectability of features other than grating orientation, such as object size and shape.

---

### A reduction in self-reported confidence accompanies the recall of memories distorted by prototypes [^a345e881]. Communications Psychology (2024). Medium credibility.

Limitations

Here, we did not use a spectrally-constrained colour bar where we controlled the subjective psychological distance between each colour (e.g. Maximum Likelihood Difference Scaling), but rather elected to use a spectrally-broad and (arguably) more ecologically valid colour bar. This decision was driven by the desire to tap into pre-existing, participant-specific colour prototypes rather than rely on participants building task-specific prototypes through lengthy training. Furthermore, this approach also freed us from the assumption that all participants perceive colour equally, which cannot be said for experimenter-defined prototypes derived from controlled, constrained colour bars. That said, the controlled, spectrally-constrained colour bar does have one key advantage over the colour bar we used. Specifically, it allows one to assume a linear relationship between response error and representation error. That is, a perceptual error that leads to a response that is 100 pixels away from the target can be assumed to be twice the error perceptual error that leads to a response that is 50 pixels away. Our task lacks this control and there may be representational “leaps” between continuous hues of the colour bar. We concede that such leaps may introduce noise into our measurements that suppresses the magnitude of the report effects. Indeed, when participants learned locations rather than colours (see Experiment 3), the magnitude of the observed effects rose drastically. Altogether, this suggests that our choice of colour bar did not bias our results towards a false positive and, if anything, may have suppressed more marginal effects.

Our analyses assume that participants have no prior associations between the objects and the colours in which they are presented. However, several studies have demonstrated that pre-existing associations do bias how colour for an object is perceived and recalled,,. Speculatively, this may explain why responses for object-colour associations (Experiments 1–2, 4–6) are more prototypical than responses for object-location associations (Experiment 3), as this prior knowledge biases colour choices more so than for the equivalent location choices. However, our observation of metacognitive effects for both colour- and location-cued recall suggests that canonical object-colour associations are not a major confounding factor. Nonetheless, future studies may benefit from accounting for canonical associations and including them as covariates to fully decorrelate their influence on behavioural responses.

---

### Two-edge-resolved three-dimensional non-line-of-sight imaging with an ordinary camera [^9cd4cd29]. Nature Communications (2024). High credibility.

In addition, variations in the range or radiosity of the object have no impact on the obstructed non-illuminated portion of the observation; it only affects the brightness of the illuminated portion. An overall brightness change in the illuminated portion of the observation plane, with no change to the slope and height of the right trapezoidal region, is explainable by a corresponding change in the range and/or radiosity of the hidden scene point. This suggests that, although highly coupled themselves, the radiosity and range parameters have no coupling with the pair of angular parameters. Thus, errors in range or radiosity have a negligible impact on the angular estimates. No convenient (re-)parameterisations exist that make the range and radiosity parameters similarly information orthogonal. However, we alleviate the effect of their coupling through a two-step computation that first estimates the radiosities and scene shape (2D angular) components while assuming that the entire scene is confined to a fixed range, and subsequently computes ranges of the recovered hidden scene objects. Central to this approach is the assumption that neighbouring clusters of surface elements belong to the same object and thus have approximately equal ranges. This results in the significantly more feasible problem of recovering a single range for clusters of estimated surface elements, in place of the possibly intractable one that estimates a range per recovered surface element.

The existence of information orthogonality among the range, azimuth, and project-elevation coordinates is crucial to the success of our two-step reconstruction procedure. Notably, it ensures that accurate angle estimation (i.e. shape) is achievable without knowing the ranges of objects within the hidden scene because errors in one do not prevent reliable reconstruction of the other. Additionally, the proposed coordinate system also simplifies the forward modelling by enabling closed-form expressions for incorporating occlusion. Consequently, we could accurately compute the forward model matrix without performing computationally intensive numerical integrations. We formalise these claims and elucidate the information orthogonality phenomenon through Fisher information analyses, and experimental demonstrations in Supplementary Notes 2 and 3.

---

### Large shifts in color appearance from patterned chromatic backgrounds [^7e956750]. Nature Neuroscience (2003). Medium credibility.

The perceived color of a light varies with the background on which it is seen. In the present study, patterned backgrounds composed of two different chromaticities caused larger shifts in perceived color than did a uniform background at either chromaticity within the pattern. Cortical receptive-field organization, but not optical factors or known retinal neurons, can account for the color shifts from patterned backgrounds.

---

### The influence of cortical activity on perception depends on behavioral state and sensory context [^47fc01aa]. Nature Communications (2024). High credibility.

Fig. 2 
Targeted photostimulation of stimulus coding neurons in L2/3 V1 bidirectionally modulates stimulus detection when mice are engaged in the task.

a From left to right, first panel: One-photon widefield imaging is performed while presenting drifting bars to the mouse to locate primary visual cortex. The two-photon FOV is positioned in a region with good GCaMP and opsin expression. The task visual stimuli are positioned in the retinotopically appropriate location. Scale bar represents 1 mm. Second panel: Example FOV (one plane from a 4-plane volume) showing construct expression in L2/3 mouse primary visual cortex. GCaMP6s is expressed transgenically and C1V1-Kv2.1 is expressed virally through injection. Third panel: Visual stimulus orientation preference map. 4 different orientations of drifting gratings are presented to the mouse. Pixel intensity is dictated by the stimulus triggered average response magnitude. Hue corresponds to preferred stimulus orientation. Fourth panel: Photostimulation responsivity of the FOV to clustered randomized photostimulation. The majority of recorded cells were grouped into 76 different clusters of 50 cells each (distributed across 4 planes) and targeted for sequential photostimulation to confirm responsivity prior to the experiment. Pixel intensity indicates the change in fluorescence caused by photostimulation. Color corresponds to the photostimulation cluster which caused the largest change in activity. White circles indicate example targets within this plane ultimately selected for targeted photostimulation of a co-tuned ensemble. All scale bars 100 μm. Examples shown are from one representative experiment but were repeated for each experiment in this study (n = 28 sessions, 12 mice). b Left: Example traces from the visual response mapping block of the experiment (prior to the behavioral task). Vertical lines indicate stimulus onsets with color indicating orientation (dashed lines for orientations over 135 degrees). Right: Example traces from the photostimulation response mapping block. Vertical lines indicate clusters of cells stimulated as a group. Cells are sorted by photostimulation cluster (in this experiment clusters were determined by orientation preference). c Example co-tuned stimulation ensemble. In this experiment 28 neurons were selected based on their responsivity to visual and optogenetic stimuli in b. Left: average responses to the drifting gratings of various orientations. Single lines represent individual neurons, thick black line indicates ensemble average. This ensemble shares a preference for 90 and 270 degree stimuli. Black triangle indicates the orientation of visual stimulus chosen for the remainder of this session. Middle: The ensemble response to photostimulation. Right: The spatial configuration of the neurons selected for stimulation. d Pixel-wise stimulus-triggered average (STA) showing the response of the FOV to the stimulation pattern from c. Red circles indicate target neurons on that imaging plane. Fade circles show all targets collapsed across planes. Scale bar represents 100 μm. e Boxplots showing the number and co-tuning of the photostimulated neurons across all experiments. Box shows the interquartile range (IQR), the plus sign shows the mean, solid line the median, and the whiskers denote 1.5 times the IQR (n = 28 sessions, 12 mice). f Photostimulation of co-tuned ensembles was paired with visual stimuli. Sessions are split into two states as in Fig. 1, here renamed to a ‘less engaged’ and a ‘more engaged’ state. Black lines indicate performance on visual-only trials. Red lines indicate performance on visual+photostimulation trials. Inset: Width of fitted psychometric curve. Error bars and shading show mean ± SEM across sessions, n = 28 sessions, 12 mice. Statistical test was two-sided Wilcoxon sign rank test, ** denotes P < 0.01. g The effect of photostimulation manifests as an increase in the width of fitted psychometric curves (n = 28 sessions, 12 mice). There was no change to the threshold of the psychometric functions. Error bars show mean ± SEM across sessions. Statistical tests were two-sided Wilcoxon sign rank, ** denotes P < 0.01, * denotes P < 0.05. h Photostimulation has a consistent effect on the detectability of visual stimuli in the ‘more engaged’ state and not in the ‘less engaged’ state. Photostimulation enhances detection of low (2%) contrast stimuli and suppressed the detection of higher (10%) contrast stimuli. Significance across each full curve indicates results of a one-way ANOVA within state. Significance across the two curves indicates the results of a repeated measures ANOVA. Significance above individual curve points indicates results of two-sided Wilcoxon signed-rank tests with Bonferroni (number of contrasts) correction. Error bars show mean ± SEM across sessions, n = 28 sessions, 12 mice. We use * to denote a P -value < 0.05, ** for P < 0.01 and *** for P < 0.001.

---

### Implicit attentional selection of bound visual features [^32064555]. Neuron (2005). Low credibility.

Traditionally, research on visual attention has been focused on the processes involved in conscious, explicit selection of task-relevant sensory input. Recently, however, it has been shown that attending to a specific feature of an object automatically increases neural sensitivity to this feature throughout the visual field. Here we show that directing attention to a specific color of an object results in attentional modulation of the processing of task-irrelevant and not consciously perceived motion signals that are spatiotemporally associated with this color throughout the visual field. Such implicit cross-feature spreading of attention takes place according to the veridical physical associations between the color and motion signals, even under special circumstances when they are perceptually misbound. These results imply that the units of implicit attentional selection are spatiotemporally colocalized feature clusters that are automatically bound throughout the visual field.

---

### Color brings relief to human vision [^71182600]. Nature Neuroscience (2003). Medium credibility.

In natural scenes, chromatic variations, and the luminance variations that are aligned with them, mainly arise from surfaces such as flowers or painted objects. Pure or near-pure luminance variations, on the other hand, mainly arise from inhomogeneous illumination such as shadows or shading. Here, I provide evidence that knowledge of these color-luminance relationships is built into the machinery of the human visual system. When a pure-luminance grating is added to a differently oriented chromatic grating, the resulting 'plaid' appears to spring into three-dimensional relief, an example of 'shape-from-shading'. By psychophysical measurements, I found that the perception of shape-from-shading in the plaid was triggered when the chromatic and luminance gratings were not aligned, and suppressed when the gratings were aligned. This finding establishes a new role for color vision in determining the three-dimensional structure of an image: one that exploits the natural relationships that exist between color and luminance in the visual world.

---

### Long-term priors influence visual perception through recruitment of long-range feedback [^8c7eed44]. Nature Communications (2021). High credibility.

Introduction

Perception is much more than what meets the eye. Incoming visual input is actively shaped by internal processes such as attention,, expectation,, and prior knowledge –. It is well known that priors learnt from lifetime experiences powerfully influence perception –. For instance, due to the lifelong ‘light-comes-from-above’ prior, we perceive shapes with shading at the top as concave –. These long-term priors (i.e. priors that are stably encoded in the brain, reflecting repeated past experiences, or genetic influences) are context-independent and apply to novel experiences. Yet, the neural mechanisms underlying long-term priors’ influence on perception remain elusive.

Two conflicting theories about the neural machinery underlying long-term priors’ influence on perception have been proposed. According to one theory, context-independent long-term priors act predominantly in a bottom-up fashion,,, implemented in the very machinery that processes sensory information. This proposal is supported by findings showing that there is an over-representation of neurons tuned to cardinal orientations and centrifugal motion directions in early visual areas,, suggesting that neuronal tuning in early sensory processing already reflects common regularities in the sensory environment. By contrast, an alternative theory suggests that prior knowledge, including those learnt from long-term experiences, resides in higher-order brain regions and acts on perception primarily through top-down feedback,. Yet, although existing evidence suggests that prior knowledge acquired from task-dependent cues can influence perception through top-down feedback from frontoparietal cortices –, no study to date has shown a similar top-down mechanism for the influence of prior knowledge learnt from long-term experiences.

Ambiguous images offer a well-controlled experimental paradigm to address this question. When viewed, these images elicit constant switching of perceptual outcome between two plausible interpretations, such as the view-from-above and view-from-below perspectives of the Necker cube (Fig. 1A). Importantly, this perceptual switching is often asymmetrical, in a manner that reflects prior knowledge engrained from long-term experiences. For instance, the Necker cube is more often perceived as being viewed from above even though it is a symmetric figure, due to humans having viewed objects more often from above than from below throughout their lives—the so-called ‘view from above’ prior –. This phenomenon provides an ideal opportunity to examine how long-term priors guide perception and bias one perceptual outcome to be preferred despite symmetrical bottom-up evidence.

---

### Photonic thermal management of coloured objects [^ed541c5a]. Nature Communications (2018). Medium credibility.

From Eq. (1), objects that have the same colour response in an outdoor environment can have drastically different thermal loads, because each of the terms in Eq. (1) can have a substantial range of variability (Fig. 1a):
: The infrared portion of the solar spectrum does not contribute to the colour property of object. There is, nevertheless, a significant part of the solar power in the wavelength range from 0.76 μm to 4 μm. For AM 1.5 spectrum,can vary from 0 Wm −2 to 453 Wm −2, depending on the solar absorptivity of the object in this wavelength range.
P cooling : In the infrared wavelength range between 4 μm and 25 μm, there is a lack of solar energy. On the other hand, an outdoor object facing the sky can emit heat out to the outer space by thermal radiation through the atmosphere transparency window between 8 μm and 13 μm. Such a process, known as radiative cooling –,, does not affect the colour but contributes to a negative thermal load, or radiative cooling power P cooling. At 298 K, assuming an atmospheric transmission spectrum of a clear day in California, and depending on the object’s infrared emissivity spectrum, P cooling can vary between 0 Wm −2 and 130 Wm −2.
: In the visible and ultra violet part of solar spectrum from 0.3 μm to 0.76 μm, the spectral absorption and reflection properties of the object dictate both the colour and. However, the human eye contains only three colour receptors with sensitivity span in the visible spectrum(Fig. 1a). Thus for colour vision, all spectra are reduced to three tristimulus values. As a result, light with different spectral power distributions may nevertheless produce an equivalent receptor response and colour sensation. This physiological effect is known as metamerism. Therefore, two surfaces that have very different solar absorption in the visible wavelength range, and hence very different, may appear indistinguishable in colour. We note the range of thermal load induced by such physiological effect in controlling the thermal load of outdoor structure has not been previously computed explicitly. As an example, in Fig. 1b, both absorptivity spectra produce a gold colour as shown in the insets. But their visible solar absorption power, at 125.5 Wm −2 and 376.5 Wm −2, respectively, differs by about a factor of 3.

---

### Serial dependence in visual perception [^437f1772]. Nature Neuroscience (2014). Medium credibility.

Visual input often arrives in a noisy and discontinuous stream, owing to head and eye movements, occlusion, lighting changes, and many other factors. Yet the physical world is generally stable; objects and physical characteristics rarely change spontaneously. How then does the human visual system capitalize on continuity in the physical environment over time? We found that visual perception in humans is serially dependent, using both prior and present input to inform perception at the present moment. Using an orientation judgment task, we found that, even when visual input changed randomly over time, perceived orientation was strongly and systematically biased toward recently seen stimuli. Furthermore, the strength of this bias was modulated by attention and tuned to the spatial and temporal proximity of successive stimuli. These results reveal a serial dependence in perception characterized by a spatiotemporally tuned, orientation-selective operator-which we call a continuity field-that may promote visual stability over time.

---

### What is light? The visible spectrum and beyond [^3125c6d9]. Eye (2016). Low credibility.

In this International Year of Light, it is particularly appropriate to review the historical concept of what is light and the controversies surrounding the extent of the visible spectrum. Today we recognize that light possesses both a wave and particle nature. It is also clear that the limits of visibility really extend from about 310nm in the ultraviolet (in youth) to about 1100nm in the near-infrared, but depend very much on the radiance, that is, 'brightness' of the light source. The spectral content of artificial lighting are undergoing very significant changes in our lifetime, and the full biological implications of the spectral content of newer lighting technologies remain to be fully explored.

---

### Adaptation to brightness perception in patients implanted with a small aperture [^0bd06e73]. American Journal of Ophthalmology (2019). Medium credibility.

By simple geometrical optics, taking into account the pupil areas, the ERT can be calculated as:where D L and D S are the diameters of the larger and smaller pupils, respectively. Furthermore, considering the SC effect the expected ERT can be calculated using the following expression:

A detailed derivation of equation 3 can be found in elsewhere.If the measured ERT were greater than expected, it would mean that the eye with the larger pupil needs more power to match the brightness of the eye with the smaller pupil and it would indicate that the later eye shows a higher brightness perception.

After careful alignment of the subject's pupils with the exit pupils of the instrument, the focus error of the subject was subjectively corrected. The subject was given control of the focus produced by the SLM, which is capable of changing the phase of the wavefront. In steps of 0.25 D, the subject searched for the best focus on each eye as the fellow one was patched. Having similar image quality on both eyes is important to avoid the presence of distracting effects for the posterior flickering minimization task. For the same reason the edges of the circular patch that was used as a visual stimulus were smoothed by a Gaussian filter. The circular patch subtended an angle of 1 degree (maximum field of view allowed by the instrument).

Subjects were tested at 2 different luminance levels: one at the maximum luminance provided by the apparatus (232 cd/m 2) and another at one tenth of the latter (23.2 cd/m 2) obtained by using a neutral-density filter with OD = 1. Testing at reduced luminance is potentially interesting, as it is under this condition that subjects implanted with the small aperture may have a greater impact on vision.

For the group of subjects implanted with the inlay, the aperture corresponding to the treated eye was made to alternate between 0 mm and 2.5 mm in diameter. Although limited to 1.6 mm by the inlay, the use of a slightly greater aperture avoided vignetting between pupils and ensured that this eye's pupil was always limited solely by the inlay.

---

### Quantifying quality in DNA self-assembly [^806908ed]. Nature Communications (2014). Medium credibility.

Estimating the remainder of unpaired DNA

We now illustrate how the defect label may be employed to estimate the remainder of unpaired DNA in self-assembled DNA objects. Our strategy relies on titrating the content of unpaired DNA elements in a given target object by omitting subsets of DNA strands from the self-assembly reactions to obtain information on the dependency of the defect labelling brightness on a known content of unpaired DNA in the object. The strategy was tested experimentally with a panel of multilayer DNA origami objects comprising 6-, 8-, 10- and 12-helix bundles that were all designed not to contain unpaired DNA elements (Supplementary Figs 20–23). Another sample was the 42-helix bundle from Fig. 1 that was planned with single-stranded TT tails at each helical interface to prevent blunt-end association. The 42-helix bundle was also designed with an improved staple strand breaking rule. All objects were labelled with a single cyanine-5 dye on a selected staple strand to provide a reference signal for object concentration. Self-assembly reaction mixtures were prepared for each object that sampled an increasing amount of unpaired DNA pseudo-defects by omitting more and more DNA strands from the self-assembly reaction mixtures (Supplementary Tables 1–10). After completion of the self-assembly reactions, the products were mixed with the defect label and gel-electrophoresed side-by-side (see exemplary gel data in Fig. 2a,b and Supplementary Figs 24–28 for the source data set). For all objects studied herein, the relative defect label brightness increased fairly linearly with increasing amounts of unpaired DNA pseudo-defects in the regime of up to ~500 unpaired DNA bases (Fig. 2c). The slopes varied considerably from object to object, which we attribute mostly to variations of the fluorescence brightness of the Cy5-labelled DNA oligonucleotides that served as object concentration reference (Supplementary Fig. 29). For the evaluation of the relative brightness in the context of a pseudo-defect titration, the object label fluorescence brightness and the rate of object label incorporation does not matter as long as it remains the same among the samples that are being compared (Supplementary Fig. 30).

---

### Viewer-centered object representation in the human visual system revealed by viewpoint aftereffects [^172c5d76]. Neuron (2005). Low credibility.

Are there neurons representing specific views of objects in the human visual system? A visual selective adaptation method was used to address this question. After visual adaptation to an object viewed either 15 or 30 degrees from one side, when the same object was subsequently presented near the frontal view, the perceived viewing directions were biased in a direction opposite to that of the adapted viewpoint. This aftereffect can be obtained with spatially nonoverlapping adapting and test stimuli, and it depends on the global representation of the adapting stimuli. Viewpoint aftereffects were found within, but not across, categories of objects tested (faces, cars, wire-like objects). The magnitude of this aftereffect depends on the angular difference between the adapting and test viewing angles and grows with increasing duration of adaptation. These results support the existence of object-selective neurons tuned to specific viewing angles in the human visual system.

---

### Current understanding of photophobia, visual networks and headaches [^e15ed645]. Cephalalgia (2019). Medium credibility.

Objective

To review clinical and pre-clinical evidence supporting the role of visual pathways, from the eye to the cortex, in the development of photophobia in headache disorders.

Background

Photophobia is a poorly understood light-induced phenomenon that emerges in a variety of neurological and ophthalmological conditions. Over the years, multiple mechanisms have been proposed to explain its causes; however, scarce research and lack of systematic assessment of photophobia in patients has made the search for answers quite challenging. In the field of headaches, significant progress has been made recently on how specific visual networks contribute to photophobia features such as light-induced intensification of headache, increased perception of brightness and visual discomfort, which are frequently experienced by migraineurs. Such progress improved our understanding of the phenomenon and points to abnormal processing of light by both cone/rod-mediated image-forming and melanopsin-mediated non-image-forming visual pathways, and the consequential transfer of photic signals to multiple brain regions involved in sensory, autonomic and emotional regulation.

Conclusion

Photophobia phenotype is diverse, and the relative contribution of visual, trigeminal and autonomic systems may depend on the disease it emerges from. In migraine, photophobia could result from photic activation of retina-driven pathways involved in the regulation of homeostasis, making its association with headache more complex than previously thought.

---

### The role of perception in imaging: past and future [^477dc8a6]. Seminars in Nuclear Medicine (2011). Low credibility.

The accurate and efficient interpretation of medical images relies on a host of factors. Clearly the technologies and methods used to acquire, process, transmit, store, and display the image and associated data are critical, but they are only one-half of the equation. In the end, the final diagnostic interpretation and recommendations for further action lie with the clinician. Ideally we would like to believe that all decisions rendered by competent clinicians are correct, but the interpretation task is not always easy or black and white. Thus, decisions are not always absolutely conclusive, are often formulated with plausible alternatives, and errors in interpretation can and do occur regularly. The discipline of medical image perception seeks an improved understanding of the perceptual factors that underlie the creation and interpretation of medical images, with the belief that improved diagnostic performance with the use of imaging devices can be achieved by the development of systems that are optimized for the interpretation of visual diagnostic information. Perception research can identify specific reasons for missed diagnoses, thereby helping to train physicians and eliminate diagnostic errors, and clarifying situations in which errors are a consequence of fundamentally ambiguous information rather than poor reader performance. The goal of this article is to provide a short review of the history of the discipline of medical image perception, highlight key research areas, and provide a look toward the future regarding the role that medical image perception research will continue to fill as imaging technology in medicine advances and develops.

---

### Weight illusions explained by efficient coding based on correlated natural statistics [^7e7c6151]. Communications Psychology (2024). Medium credibility.

In our everyday experience, the sizes and weights of objects we encounter are strongly correlated. When objects are lifted, visual information about size can be combined with haptic feedback about weight, and a naive application of Bayes' rule predicts that the perceived weight of larger objects should be exaggerated and smaller objects underestimated. Instead, it is the smaller of two objects of equal weight that is perceived as heavier, a phenomenon termed the Size-Weight Illusion (SWI). Here we provide a normative explanation of the SWI based on principles of efficient coding, which dictate that stimulus properties should be encoded with a fidelity that depends on how frequently those properties are encountered in the environment. We show that the precision with which human observers estimate object weight varies as a function of both mass and volume in a manner consistent with the estimated joint distribution of those properties among everyday objects. We further show that participants' seemingly "anti-Bayesian" biases (the SWI) are quantitatively predicted by Bayesian estimation when taking into account the gradient of discriminability induced by efficient encoding. The related Material-Weight Illusion (MWI) can also be accounted for on these principles, with surface material providing a visual cue that changes expectations about object density. The efficient coding model is further compatible with a wide range of previous observations, including the adaptability of weight illusions and properties of "non-illusory" objects. The framework is general and predicts perceptual biases and variability in any sensory properties that are correlated in the natural environment.

---

### Self-motion and the perception of stationary objects [^da610940]. Nature (2001). Excellent credibility.

One of the ways that we perceive shape is through seeing motion. Visual motion may be actively generated (for example, in locomotion), or passively observed. In the study of the perception of three-dimensional structure from motion, the non-moving, passive observer in an environment of moving rigid objects has been used as a substitute for an active observer moving in an environment of stationary objects; this 'rigidity hypothesis' has played a central role in computational and experimental studies of structure from motion. Here we show that this is not an adequate substitution because active and passive observers can perceive three-dimensional structure differently, despite experiencing the same visual stimulus: active observers' perception of three-dimensional structure depends on extraretinal information about their own movements. The visual system thus treats objects that are stationary (in an allocentric, earth-fixed reference frame) differently from objects that are merely rigid. These results show that action makes an important contribution to depth perception, and argue for a revision of the rigidity hypothesis to incorporate the special case of stationary objects.

---

### What constitutes an efficient reference frame for vision? [^4bbaa141]. Nature Neuroscience (2002). Medium credibility.

Vision requires a reference frame. To what extent does this reference frame depend on the structure of the visual input, rather than just on retinal landmarks? This question is particularly relevant to the perception of dynamic scenes, when keeping track of external motion relative to the retina is difficult. We tested human subjects' ability to discriminate the motion and temporal coherence of changing elements that were embedded in global patterns and whose perceptual organization was manipulated in a way that caused only minor changes to the retinal image. Coherence discriminations were always better when local elements were perceived to be organized as a global moving form than when they were perceived to be unorganized, individually moving entities. Our results indicate that perceived form influences the neural representation of its component features, and from this, we propose a new method for studying perceptual organization.

---

### Behavioural determinants of physiologically-relevant light exposure [^c13bc0d7]. Communications Psychology (2024). Medium credibility.

While these recommendations represent an excellent evidence-based starting point, the laboratory evidence on which these recommendations are based is limited in ecological validity which is reflected in the ambiguous and impractical recommendations presented in this consensus statement. Firstly, there is no easy way to determine and measure the melanopic EDI in everyday life for the end-user nor easily for the researcher (in contrast to methods used for lab animals such as telemetric monitoring and infrared observations). Secondly, real-life conditions are quantitatively and qualitatively more complicated than laboratory conditions. Typical stimuli used in laboratory studies contain minimised stimulus features to allow the isolation of light features. In real-life, however, the qualities of light (timing, duration, temporal pattern, intensity, and spectrum) are not isolated from each other and the environmental scenes we perceive are spatially and temporally highly complex and quite unlike conditions used in laboratories.

Typical real-world patterns in a Western 24/7 society are, for example, dim days and bright nights : this includes the exposure to dim light during the day (e.g. due to electrical lighting in office buildings below the recommend 250 lux mel EDI), and relative bright, blue light after sunset (usually above 10 lux mel EDI) which suppresses melatonin, delays circadian phase, and consequently also delays sleep (yellow profile of individual 2 in Fig. 2B). On the other hand, a strong zeitgeber strength such as natural daylight at high intensities experienced during the day (bright days), preferably earlier in the morning during the phase advance window of an individual, can advance the circadian phase and consequently also sleep, and might even be protective to bright light before sleep. This highlights the role of an individual’s “photic history”,, and “spectral diet”which describe the timing of light as well as the spectral composition of the light an individual experiences across the day respectively (see Fig. 2).

Consequently, it is currently uncertain to what extent laboratory-based recommendations for target light levels are meaningful for the real world or how individuals can easily measure their light environment and determine if and how they should adjust their behaviour accordingly. It becomes clear, though, that individually tailored approaches to reach the target levels are necessary for different behavioural subtypes.

---

### Vision-driven metasurfaces for perception enhancement [^49fa0b2b]. Nature Communications (2024). High credibility.

Introduction

Human visual system –, a remarkable network that allows us to receive light input into our eyes and to transform light information into colorful and rich experiences, is the most important pathway for humans to obtain information from the external world. Our eyes use visible light to obtain information about our surroundings, a process begins when the cornea and lens refract light from objects and surfaces in the world to form a panoramic, hemispheric image on the retina, a thin layer of nerve tissue that lines the inner surface of the eyeball. Like pixels in a digital camera, photoreceptor cells absorb the light arriving at the retina and photochemically transform the absorbed light energy into neural signals. Impulses from the photoreceptors are then transmitted to the visual cortex of the brain via a visual pathway. The visual system is an important part of the brain nerve center –. More than 80% of sensory information that our brain receives comes from the visual system, which provides us with a personal representation of our surrounding environment. The process resulting in vision is not only about the perception of the environment by capturing energy but also about its interpretation. The information obtained from visual system directly affects human life and thinking. Our daily tasks, including perception, decision making as well as action, are highly dependent on vision. Thus, research on visual systems has become a hot spot and the source of interactive scientific research in recent years. However, human eyes can only perceive visible light which occupies a very narrow frequency band in the entire EM spectrum. This restricts the visual system to obtain information from other frequency bands, resulting in a significant decrease in the ability to access information when the target is obstructed. Moreover, previous researches on visual search, spatial attention,, and change blindness, have shown a limited ability of human observers to obtain and process all information present within a visual scene. Faced with a large amount of visual information, the visual system can only selectively handle a small part. When high-intensity work must be persistent for a long time or multiple tasks within short time intervals must be performed, this limitation may waste a lot of useful content and reduce the efficiency of information acquisition. Therefore, it is of great significance to figure out a method of making the most of visual information, which is expected to improve the efficiency of information acquisition in terms of achieving perceptual enhancement in multiple frequency bands of the EM spectrum.

---

### Perceptually unidentifiable stimuli influence cortical processing and behavioral performance [^36b4c823]. Nature Communications (2020). High credibility.

Subthreshold exposure increases subsequent task performance

Next, we examined whether the information acquired by the population of V1 cells during subthreshold stimulus exposure is sufficient to influence perceptual performance in a subsequent behavioral task. Therefore, the exposure stage was followed by a discrimination task (Fig. 3a, b) in which monkeys signaled whether two consecutive presentations of the same image (target and test), differed or not in orientation (either identical or rotated relative to each other in the 3°–20° range). Importantly, in each session we used two images randomly interleaved across trials: one of them was the exposed image (previously presented) and the other image was novel (unexposed). The pairs of exposed and unexposed images were selected after performing image orientation discrimination experiments in humans to ensure that the two stimuli yielded similar perceptual performances (Supplementary Fig. 4). Furthermore, the orientation content, mean contrast, and luminance did not differ between exposed and unexposed images across sessions (see Methods, Supplementary Fig. 5). We used natural images rather than simple stimuli, such as oriented gratings, owing to the requirement that stimuli be novel in each session. Importantly, the same image set was used in both monkeys, i.e. exposed images for one monkey became unexposed images for the other monkey, and vice versa. Counterbalancing stimuli in each session, i.e. swapping the exposed and unexposed images within a session and repeating the exposure and discrimination experiments, or testing image discriminability before subthreshold exposure in order to compare pre and post-exposure perceptual performance, would be unfeasible. Indeed, once a stimulus is presented above threshold for hundreds of trials during image discrimination, it can no longer be used as an effective, perceptually indistinguishable stimulus capable to induce subthreshold priming.

---

### Cortical and subcortical signatures of conscious object recognition [^3a74d601]. Nature Communications (2021). High credibility.

Image contrast staircase

On Day 1, subjects performed an adaptive staircase procedure “QUEST”in the scanner in order to determine individual image contrast (c) yielding a recognition rate of 50% (proportion of “yes” responses to the second question). The image pixel intensity, I, at a given contrast, c, was calculated as:where b is the background intensity (set to a constant value of 127) and scaled pixel intensities were obtained by rescaling the image pixel intensities between −1 and 1. As a result, the lightest pixel value in the image was equal toand the darkest. Therefore, we defined the contrast of a presented image as:which ranged between 0 and 1.

Subjects performed the QUEST procedure in the scanner under conditions similar to the main task performed on Day 2, except timing parameters were shorter. The inter-trial interval (ITI) was randomly selected from 0.75 or 1 s, and the fixation period between stimulus presentation and categorization prompt was 0.5 s. Because the shorter ITI allowed subjects to better predict the time of stimulus onset than in the main task, effective 50% threshold contrasts were lower in QUEST than in the main task. The target threshold in QUEST was thus set to 55% rather than 50% to compensate. The threshold contrast for each image was identified using an independent QUEST process containing 40 trials. 20 such processes (one for each real image) were executed such that different images were interwoven into a total session of 800 trials. The task was broken into four blocks of 200 trials each, and subjects were allowed to rest in between blocks. Task performance was considered acceptable if categorization accuracy for recognized images was at least 30% higher than for unrecognized images, and if the QUEST procedure successfully converged on 55% recognition rate for each image. On Day 2, we first tested whether the threshold contrasts still yielded 50% subjective recognition. Subjects completed 80 trials (4 trials per image) with the following timing parameters: ITI of randomly 2 or 3 s, post-stimulus fixation of 2 s. If subjects reported to recognize more than 80% or less than 30% of trials, they performed a shorter QUEST task with the same timing parameters to account for threshold changes across days. These 14 subjects completed two interwoven QUEST processes with 40 trials each, including all real images. Instead of adjusting the contrast of each image individually, the staircasing target was 50% recognition across all images. We thus accounted for any change in overall recognition threshold across days, but not for any new differences between images.

---

### Diagnosis and care of children with cerebral / cortical visual impairment: clinical report [^b91b5a59]. Pediatrics (2024). High credibility.

Pediatric cerebral/cortical visual impairment (CVI)—characteristic visual behaviors include challenge or apparent disinterest in locating and sustaining visual focus on objects, need for extra time to respond to visual stimulus (latency), affinity for light in some while others display light sensitivity, potential benefit from movement of a visual object despite reduced gross motion perception, unusual visual behaviors such as eccentric viewing, difficulty interpreting complex visual arrays, challenges recognizing objects or faces, preference for bright colors, and variable visual response based on environment, fatigue, or distraction; these characteristics may aid in identifying children at risk for CVI and may change and improve over time.

---

### Crowding results from optimal integration of visual targets with contextual information [^5677bdcf]. Nature Communications (2022). High credibility.

Crowding is the inability to recognize an object in clutter, usually considered a fundamental low-level bottleneck to object recognition. Here we advance and test an alternative idea, that crowding, like predictive phenomena such as serial dependence, results from optimizing strategies that exploit redundancies in natural scenes. This notion leads to several testable predictions: crowding should be greatest for unreliable targets and reliable flankers; crowding-induced biases should be maximal when target and flankers have similar orientations, falling off for differences around 20°; flanker interference should be associated with higher precision in orientation judgements, leading to lower overall error rate; effects should be maximal when the orientation of the target is near that of the average of the flankers, rather than to that of individual flankers. Each of these predictions were supported, and could be simulated with ideal-observer models that maximize performance. The results suggest that while crowding can affect object recognition, it may be better understood not as a processing bottleneck, but as a consequence of efficient exploitation of the spatial redundancies of the natural world.

---

### Object-based attention determines dominance in binocular rivalry [^af5cb09f]. Nature (2004). Excellent credibility.

A question of long-standing interest to philosophers, psychologists and neuroscientists is how the brain selects which signals enter consciousness. Binocular rivalry and attention both involve selection of visual stimuli, but affect perception quite differently. During binocular rivalry, awareness alternates between two different stimuli presented to the two eyes. In contrast, attending to one of two different stimuli impairs discrimination of the ignored stimulus, but without causing it to disappear from consciousness. Here we show that despite this difference, attention and rivalry rely on shared object-based selection mechanisms. We cued attention to one of two superimposed transparent surfaces and then deleted the image of one surface from each eye, resulting in rivalry. Observers usually reported seeing only the cued surface. They were also less accurate in judging unpredictable changes in the features of the uncued surface. Our design ensured that selection of the cued surface could not have resulted from spatial, ocular or feature-based mechanisms. Rather, attention was drawn to one surface, and this caused the other surface to be perceptually suppressed during rivalry. These results raise the question of how object representations compete during these two forms of perceptual selection, even as the features of those objects change unpredictably over time.

---

### A statistical explanation of visual space [^c51fa0d9]. Nature Neuroscience (2003). Medium credibility.

The subjective visual space perceived by humans does not reflect a simple transformation of objective physical space; rather, perceived space has an idiosyncratic relationship with the real world. To date, there is no consensus about either the genesis of perceived visual space or the implications of its peculiar characteristics for visually guided behavior. Here we used laser range scanning to measure the actual distances from the image plane of all unoccluded points in a series of natural scenes. We then asked whether the differences between real and apparent distances could be explained by the statistical relationship of scene geometry and the observer. We were able to predict perceived distances in a variety of circumstances from the probability distribution of physical distances. This finding lends support to the idea that the characteristics of human visual space are determined probabilistically.

---

### Minimal exposure durations reveal visual processing priorities for different stimulus attributes [^19f2086d]. Nature Communications (2024). High credibility.

Human vision can detect a single photon, but the minimal exposure required to extract meaning from stimulation remains unknown. This requirement cannot be characterised by stimulus energy, because the system is differentially sensitive to attributes defined by configuration rather than physical amplitude. Determining minimal exposure durations required for processing various stimulus attributes can thus reveal the system’s priorities. Using a tachistoscope enabling arbitrarily brief displays, we establish minimal durations for processing human faces, a stimulus category whose perception is associated with several well-characterised behavioural and neural markers. Neural and psychophysical measures show a sequence of distinct minimal exposures for stimulation detection, object-level detection, face-specific processing, and emotion-specific processing. Resolving ongoing debates, face orientation affects minimal exposure but emotional expression does not. Awareness emerges with detection, showing no evidence of subliminal perception. These findings inform theories of visual processing and awareness, elucidating the information to which the visual system is attuned.

---

### History of research in medical image perception [^f68f2bda]. Journal of the American College of Radiology (2006). Low credibility.

Human observers engage in 2 interrelated processes when interpreting medical images: perception and analysis. Perception is the unified awareness of the content of a displayed image that is present while the stimulus is on. Analysis is determining the meaning of the perception in the context of the medical problem that initiated the acquisition of the image. Radiologists have, correctly, regarded image analysis as their primary field of research. They have naively assumed that what they perceive in images is a faithful representation of the images' information content and have not been concerned with perception unless it fails. Failures have stimulated research on quantifying observer performance, defining image quality, and understanding perceptual error. This article traces the historical development of the use of receiver operating characteristic analysis for describing performance, the development of signal-to-noise ratio psychophysical models for defining task-dependent image quality, studies of error in small lesion detection, and the beginnings of studies of the nature of expertise in image interpretation. The history is traced through published articles.

---

### Perceptual straightening of natural videos [^13b34e18]. Nature Neuroscience (2019). High credibility.

Many behaviors rely on predictions derived from recent visual input, but the temporal evolution of those inputs is generally complex and difficult to extrapolate. We propose that the visual system transforms these inputs to follow straighter temporal trajectories. To test this 'temporal straightening' hypothesis, we develop a methodology for estimating the curvature of an internal trajectory from human perceptual judgments. We use this to test three distinct predictions: natural sequences that are highly curved in the space of pixel intensities should be substantially straighter perceptually; in contrast, artificial sequences that are straight in the intensity domain should be more curved perceptually; finally, naturalistic sequences that are straight in the intensity domain should be relatively less curved. Perceptual data validate all three predictions, as do population models of the early visual system, providing evidence that the visual system specifically straightens natural videos, offering a solution for tasks that rely on prediction.

---

### Neural correlates reveal separate stages of spontaneous face perception [^29db09a4]. Communications Psychology (2025). Medium credibility.

Introduction

The primate brain responds differently to faces and objects. This ubiquitous finding, which transcends all recording –, imaging –, and causal – methods, has led to an unresolved debate: do faces engage distinct neural mechanisms, separate from those processing objects? Or, alternatively, do visually evoked responses reflect a distributed code that can universally classify any visual stimulus as a function of image properties? These questions, while central to our understanding of primate vision and brain topography, have been largely rendered intractable, in part because it is difficult to decouple a face from the image properties that typically define a face. Difficult but not impossible.

Face pareidolia is the common experience of perceiving a face in an otherwise inanimate object –. Interestingly, while these stimuli are easily perceived as face-like, their image properties are more typical of inanimate objects –. Thus, examples of face pareidolia provide a rare opportunity to understand how image properties contribute to the neural representation of faces and objects. For instance, examples of face pareidolia have been used to show that the brain’s response to a visual stimulus evolves over time – ; patterns of brain activity first encode examples of face pareidolia as being more similar to faces, and then more similar to objects. This is consistent with a system that has distinct mechanisms underscoring distinct, potentially parallel, functions. To date, however, there is no evidence that the evolving neural signature of face pareidolia has behavioral consequences. In other words, when we experience the face pareidolia illusion, do we first see a face and then an object, or do we perceive a mixture of both in a stimulus-dependent manner?

---

### Perceptually unidentifiable stimuli influence cortical processing and behavioral performance [^f5098a6f]. Nature Communications (2020). High credibility.

Detectability threshold

In preliminary image detectability tests (Fig. 1a) a movie stimulus consisting of a sequence of 96 circular sinusoidal gratings (eight equidistant orientations randomly flashed at 60 Hz) was presented for a total duration of 1600 ms. In 50% of the trials, a variable number of frames (between 2 and 15 consecutive frames presented at a random time between frames 18 and 79) were replaced by a circular grayscale natural image of identical size and mean luminance as the gratings. Monkeys were required to signal whether the image was present in a trial by releasing the lever immediately at the end of the movie stimulus presentation. By varying the number of image frames on a trial-by-trial basis, behavioral results were used to determine the image detectability threshold (Fig. 1b). Psychometric curves and thresholds were obtained by averaging the performances associated with each number of consecutive image frames in all sessions (n = 16, 6) and fitting the psychometric curve to a Weibull function,. The discriminability threshold was calculated by setting the threshold at d’ = 1, while taking into account the false alarm rates.

Image identification threshold

We conducted a forced-choice saccade task in which monkeys reported image identity. This allowed us to test whether animals are able to perceive the image content and consciously identify the subthreshold (two frames) or suprathreshold (more than five frames) stimuli. After a 300 ms fixation period, monkeys were presented the same 96 frames movie stimulus used in the detection task, except that in each trial one of two images was embedded within the movie (between 2 and 40 consecutive image frames; trials were randomly interleaved). A control stimulus with 0 image frames (0 ms) had the same probability of occurrence as any of the other frame lengths. At the end of stimulus presentation, the two images appeared on the screen (Fig. 1c). Monkey were required to maintain fixation (150 ms) until the fixation point turned red, and then performed a saccade towards the image they had previously seen. Monkeys were allowed to make a saccade within 700 ms, and once they made the saccade, they maintained fixation for at least 700 ms. Correct responses were rewarded with juice while failure to make a saccade aborted the trial. Proportion of correct responses were averaged for each number of frames and the results were fitted with an exponential function (Fig. 1d). The discriminability threshold was calculated by setting the threshold at d’ = 1.

---

### Perceiving distance accurately by a directional process of integrating ground information [^d65cb300]. Nature (2004). Excellent credibility.

By itself, the absolute distance of an object cannot be accurately judged beyond 2-3 m (refs 1-3). Yet, when it is viewed with reference to a flat terrain, humans accurately judge the absolute distance of the object up to 20 m, an ability that is important for various actions. Here we provide evidence that this is accomplished by integrating local patches of ground information into a global surface reference frame. We first show that restricting an observer's visual field of view to the local ground area around the target leads to distance underestimation, indicating that a relatively wide expanse of the ground surface is required for accurate distance judgement. Second, as proof of surface integration, we show that even with the restricted view, the observer can accurately judge absolute distance by scanning local patches of the ground surface, bit by bit, from near to far, but not in the reverse direction. This finding also reveals that the surface integration process uses the near-ground-surface information as a foundation for surface representation, and extrapolation to the far ground surface around the target for accurate absolute distance computation.

---

### Structural absorption by barbule microstructures of super black bird of paradise feathers [^e732e9bb]. Nature Communications (2018). Medium credibility.

Discussion

Our findings demonstrate that super black bird of paradise feathers structurally absorbs up to 99.95% of directly incident light, and that variation in external surface microstructure can contribute to observed differences in visual appearance of bird plumage. The vertically tilted barbule arrays of super black bird of paradise feathers create deep, curved cavities. This morphology is distinct from the longitudinal ridges of butterfly scalesand the vertical cones of snake scales, substantially expanding the diversity of structurally absorbing biological materials in nature.

The extreme directional reflectance bias in super black feathers is congruent with field observations of bird of paradise courtship behavior. Males of many species perform displays that maintain a specific directional orientation between their ornaments and the viewing females(Fig. 1g). We hypothesize that the tilted barbule arrays function in coordination with the behavioral repertoire to ensure that females view super black plumage patches at their darkest orientation.

Interestingly, in both butterflies and birds of paradise, super black patches are always adjacent to bright, highly saturated, and structural colors. For example, Lophorina has a super black plumage display cape surrounding its intensely brilliant blue patches, but normal black plumage on the back that is not featured during display (Fig. 1g and Supplementary Figs. 1 c, h and 2 c, h). We hypothesize that structurally absorbing super black patches evolve because they exaggerate the perceived brilliance of adjacent color patches through a sensory/cognitive bias inherent in the vertebrate mechanism of color correction. Vertebrates use specular highlights, or white reflectance from object surfaces, within the visual field to correct for the spectrum and quantity of ambient light. We propose that structurally absorbing super black patches (i) eliminate specular reflectances around the brilliant color patch, (ii) lower the observers perceived estimate of the quantity of ambient light upon that portion of the visual scene, and thus (iii) disrupt the perceiver’s capacity to estimate the brilliance of the color patch. If the brain perceives that more light is coming from a patch than it estimates is ambient upon it, the patch will appear to be self-luminous or to float in space –. Perceptual experiments demonstrate this bias in the color correction mechanisms of goldfish (which are tetrachromats like birds) and humans.

---

### Primate retina trades single-photon detection for high-fidelity contrast encoding [^861ab60a]. Nature Communications (2024). High credibility.

Discussion

Our results provide three key insights related to the mechanistic and functional underpinnings of human vision at the lowest light levels. First, similar to previous results in mice, our results support the hypothesis that human behavior at absolute threshold relies on retinal output signals provided by ON RGCs. This is true even when the sensitivity of OFF RGC responses is comparable to that of ON RGC responses. This suggests that, at least at visual threshold, increases in retinal firing rates (e.g. ON RGC responses to light increments) are more effective than decreases (OFF RGC responses to increments) in eliciting cortical responses and behavior. Indeed, earlier results on primates at photopic light levels suggest that cortical responses to light increments originate in ON RGCs and those to light decrements originate in OFF RGCs. This distribution of labor between the retinal ON and OFF pathways in driving cortical responses will be important to consider in attempts to restore visual signals in visually impaired patients. However, it still remains to be seen if behavioral detection of the weakest light decrements in humans relies on the retinal OFF pathway, as our recent results on mice suggest. Such a study on humans will have to consider the fundamental limit set by the intensity of background light for generating quantal shadow stimuli (the dimmest light decrements), as shown previously.

Second, our results answer the decades-old question about whether humans can perceive a single photon. A recent studyusing a single-photon light source reported that humans can detect even a single photon. Two issues make this conclusion uncertain: (1) The probability of detection was very low, and only marginally statistically significant, (2) the paper does not provide a model that accounts for performance in both the single-photon detection task and the classical psychophysics task, which spans flash strengths in which detection performance ranges from chance to the near-perfect level. We have repeated near-identical experiments in an ongoing study (Tiihonen et al. in preparation) using both single-photon and conventional light sources; we used more trials and more near-threshold flash strengths than the previous study so that we could resolve small differences from chance performance. Human performance in these experiments did not exceed chance levels in the single-photon detection task and the full set of results were well described by the new model presented here (Fig. 1b).

---

### Opposing effects of selectivity and invariance in peripheral vision [^8cf42fa8]. Nature Communications (2021). High credibility.

Sensory processing necessitates discarding some information in service of preserving and reformatting more behaviorally relevant information. Sensory neurons seem to achieve this by responding selectively to particular combinations of features in their inputs, while averaging over or ignoring irrelevant combinations. Here, we expose the perceptual implications of this tradeoff between selectivity and invariance, using stimuli and tasks that explicitly reveal their opposing effects on discrimination performance. We generate texture stimuli with statistics derived from natural photographs, and ask observers to perform two different tasks: Discrimination between images drawn from families with different statistics, and discrimination between image samples with identical statistics. For both tasks, the performance of an ideal observer improves with stimulus size. In contrast, humans become better at family discrimination but worse at sample discrimination. We demonstrate through simulations that these behaviors arise naturally in an observer model that relies on a common set of physiologically plausible local statistical measurements for both tasks.

---

### Passive sensing around the corner using spatial coherence [^da36333a]. Nature Communications (2018). Medium credibility.

Introduction

Imaging systems map spatially the distribution of light across an object onto a distant observation plane for further recording and processing. Of course, when objects are too distant or too small to be satisfactorily described by an imaging system, only unresolved sensing is available for estimating physical properties of the object. Whether the object is actively illuminated in a controlled manner, or it is self-luminous, or it is subject to some passive ambient lighting, the imaging procedure is typically constrained by the need for direct view to the object.

In non-line-of-sight conditions, an ideal “specular” reflector such as a mirror preserves most of the light properties, including the wavefront, and the imaging procedure is similar to the direct line-of-sight case. Decreasing the mirror’s specularity hinders this capability. A shattered mirror alters the directionality of reflected light and, as a result, only a distorted version of the image can be transferred as illustrated in Fig. 1. The blur can be mitigated if the disturbance can be quantified. Unfortunately, because of the random nature of surface scattering, there are no simple deterministic approaches like ray tracing or conventional diffraction theories to describe the relationship between the incident and reflected optical fields. The situation is further complicated if the light is redirected by a diffusing wall when the interaction is not limited to the surface of the random medium but it extends throughout its volume. In these conditions, recovering the incident wavefront is challenging. The complicated process can be described in terms of the associated transfer matrix, which can be found by controlling the properties of radiation before and after the scattering medium –.

---

### The challenges natural images pose for visual adaptation [^816dd824]. Neuron (2009). Low credibility.

Advances in our understanding of natural image statistics and of gain control within the retinal circuitry are leading to new insights into the classic problem of retinal light adaptation. Here we review what we know about how rapid adaptation occurs during active exploration of the visual scene. Adaptational mechanisms must balance the competing demands of adapting quickly, locally, and reliably, and this balance must be maintained as lighting conditions change. Multiple adaptational mechanisms in different locations within the retina act in concert to accomplish this task, with lighting conditions dictating which mechanisms dominate.

---

### The influence of cortical activity on perception depends on behavioral state and sensory context [^13dfd218]. Nature Communications (2024). High credibility.

Pre-processing: Imaging frame registration, ROI segmentation and neuropil correction

For the final analysis, the raw calcium imaging movies were pre-processed using Suite2p. The pipeline included image registration, segmentation of active region of interest (ROIs), and of local surrounding neuropil signal. The final selection of ROIs was filtered semi-automatically using anatomical criteria to include only neuronal somata and discard spurious ROIs. We manually inspected all FOVs to ensure consistent results. We subtracted a neuropil signal from every ROI signal. The contamination of the ROI signal by the neuropil signal depends on many factors, including expression levels, imaging quality, and axial sectioning by the imaging plane. We used robust linear regression to estimate the coefficient of neuropil contamination for each ROI (Supplementary Fig. 9 ; ref.). The slope of this fit was used to scale the neuropil signal before subtraction from the ROI signal, such that after subtraction there was no correlation between the ROI baseline and neuropil. Neuropil subtraction had minimal effect on the response magnitude, and negative responses to visual- and photo-stimulation were seen even without subtracting the neuropil contamination (Supplementary Figs. 9 and 10).

ROI exclusion zones

To reduce potential off-target photostimulation artifacts, we excluded from consideration all cells within a 30 μm diameter cylinder extending through all axial planes when analyzing the network response to photostimulation due to potential imaging and photostimulation artifacts (see Supplementary Fig. 9). We redefined our target stimulation pattern identities based on the ROIs segmented by Suite2p within the 30 μm lateral disk around each of the SLM target locations. We also excluded ROIs in the first 100 rows of pixels of each imaging frame due to an ETL artefact related to the settle time of the lens when changing planes.

Neuronal response metric

To measure neuronal responses, we extracted the mean fluorescence in a ~500 ms window (4 frames) starting immediately after the photostimulation ended (and/or visual stimulus to ensure comparable measurements) and subtracted the mean fluorescence in the ~1 s baseline (7 frames) before the onset of photostimulation (or visual stimulus). We divided the difference in the means by the mean of the baseline window, resulting in trial-by-trial ΔF/F values. We excluded all photostimulation frames because of the associated artefact contaminating the activity traces; the slow kinetics of GCaMP6s permit this, although the magnitude of response is underestimated as a result.

---

### Passive sensing around the corner using spatial coherence [^7fd931cc]. Nature Communications (2018). Medium credibility.

Fig. 1 
Different non-line-of-sight sensing conditions. a A perfect reflector permits imaging around the corner. b A broken mirror alters the optical wavefront and impedes forming a clear image. c A random medium will alter the reflection even more due to both surface and volume scattering contributions

Nonetheless, some these limitations can be alleviated by an active control of the illumination source. For instance, one can employ time-of-flight approaches to gate the time necessary for light emerging from a controllable source to first reach an object and then a detector capable of discriminating the transient time,. Imaging angularly small targets hidden around a corner is also possible when using additional measurements performed on reference objectsor when the scene is illuminated with temporally coherent light –. Sometimes, when an object is diffusively illuminated by a laser and its reflection generates a nonuniform intensity distribution across the scattering wall, detecting the evolution of this intensity allows tracking the object’s movement,.

Unfortunately, the sensing conditions are significantly more restrictive when one does not have access to the source of illumination. If the object does not generate intensity variations that can be measured, one cannot reconstruct an image in the conventional intensity-based sense. However, even in this rather limiting situation, the object itself acts as the primary (if self-luminous) or the secondary source of partially coherent radiation and relevant information about the object is carried by the statistical properties of the radiated field. The remaining practical question is: do these field properties survive the interaction with scattering obstructions?

In this paper, we demonstrate that spatial correlations of the electromagnetic field can be transferred between the incident and reflected fields in spite of the random nature of interaction with a multiple-scattering medium. Specifically, we show that scattering from randomly inhomogeneous media does not completely destroy the spatial coherence of radiation. This means that a multiple-scattering wall can act as a “broken mirror” for spatial coherence and its distortions can be partially mitigated. We demonstrate that this effect permits retrieving information about the size and shape and allows determining the location of an object even in non-line-of-sight situations.

---

### Neural bases of self-and object-motion in a naturalistic vision [^54e9b956]. Human Brain Mapping (2020). Medium credibility.

We were particularly interested in verifying some specific contrasts. First, we compared Onboard versus Offboard conditions (in histograms, blue vs. red), to reveal specific preferences for pure self‐ and object‐motion. Second, we compared the preferred condition of a specific region (i.e. Onboard, Offboard, or both in case of no preference) versus the Disjoint condition (in histograms, blue/red vs. green), to reveal preferences for a more complex and ecological condition. Note that in the Disjoint condition self‐ and object‐motion coexist but are independent of each other (i.e. the subject moves in one direction and the train move as well, but in another direction). In this respect, the Disjoint condition is the most complex one, similarly to what happens in daily life where people move in a dynamic and complex environment.

Third, we compared Joint versus Onboard (in histograms, yellow vs. blue), to reveal cortical areas able to extract object‐motion from the overall motion perceived on the screen. As described in the Methods, the Joint condition is extremely interesting because although it is a combination of self‐ and object‐motion (both the subject and the train are moving along the same direction and at the same velocity), the train has a fixed position on the screen throughout each movie. In the real world, when one's head moves, the image of a stationary object will move across the retina. If the head is moving yet the retinal image is static, the object must be moving (in synchrony with the head). In the Joint condition, we perceive the train (which is fixed on the screen) as moving and the external environment (which is shifting on the screen) as static. This means that in this specific condition, the perception of object‐motion (i.e. the train movement) is not simply the result of retinal/screen image motion (as generally supposed) but must be inferred (i.e. extracted) from the overall motion after estimating and subtracting out self‐motion information (i.e. the subject motion). Thus, a difference between Joint and Onboard conditions is an index of real motion extraction given that the two conditions have the same quantity of self‐motion.

The anatomical location and the functional profile of each region are described in detail below. Regions are grouped here and in Discussion by their functions independently to their anatomical position.

---

### Outcome measure for the treatment of cone photoreceptor diseases: orientation to a scene with cone-only contrast [^4db09333]. BMC Ophthalmology (2015). Low credibility.

A set of trials consists of no less than 10 scotopically-matched test trials plus a number of scotopically- and photopically-unmatched control trials (Fig. 1c, left). One of these sets is performed for each scene luminance, proceeding from dim to bright. The unmatched trials are used for control (should produce a success fraction close to 100 % for subjects having any form of orientation vision at the tested scene luminance) and to maintain orientation during the trials, and also to explain the test to subjects with very low vision. The contrast level for the control trials greatly exceeds the range of scotopic matches in normal subjects, which is approximately 0.4 log wide (Fig. 1d). Matched and mismatched trials are randomly interleaved by the software, with control (unmatched) trials being 20 % of the total trials on average. For each trial, a sound is produced after the adjustment of the wall and door intensities by the computer, and the subject is asked to verbally report the apparent door position as “Left”, “Center” or “Right”; they are encouraged to guess one of the three choices if unable to determine where the door is. The responses are recorded by the computer. Figure 1e illustrates representative examples of three sets producing different success rates (33, 50 and 100 %) for test trials (filled circles) with instances of interleaving control trial sequences (open triangles). Failure to discriminate the door position is signaled by a yield of ideally 33 % of correct answers to the 3-AFC design. Full discrimination implies near 100 % answers being correct. Results are acquired under free viewing conditions, except for illuminations requiring attenuating goggles.

All normal data were fit with a logistic function of the formwhere p is the probability of correct, x is the scene luminance, γ is guessing probability (fixed to 0.3) and λ is the lapsing probability (fixed to 0). The spread parameter, σ, was allowed to vary for normal results but held constant at the normal value for the patient results. The threshold parameter, θ, was allowed to vary for both normals and patients.

---

### Prior experience of rotation is not required for recognizing objects seen from different angles [^57dbe5d6]. Nature Neuroscience (2005). Medium credibility.

An object viewed from different angles can be recognized and distinguished from similar distractors after the viewer has had experience watching it rotate. It has been assumed that as an observer watches the rotation, separate representations of individual views become associated with one another. However, we show here that once monkeys learned to discriminate individual views of objects, they were able to recognize objects across rotations up to 60 degrees , even though there had been no opportunity to learn the association between different views. Our results suggest that object recognition across small or medium changes in viewing angle depends on features common to similar views of objects.

---

### Behavioural determinants of physiologically-relevant light exposure [^ff2ab121]. Communications Psychology (2024). Medium credibility.

From ‘passive’ light exposure to human-light interactions

A brief review of ocular and retinal mechanisms

When light enters the eye and reaches the retina, it interacts with photoreceptor cells by changing their conformation enabling phototransduction, a process through which light energy is converted into neural signals (Fig. 1A). These signals are processed in a series of retinal cells, eventually reaching the optic nerve, which carries them to the brain’s visual cortex and other areas for signal processing, integration, and interpretation (Fig. 1B, C). The retina contains two ‘canonical’ photoreceptor classes, the cones and rods. The cones are responsible for our vision of colour, space, and motion. There are three types of cones (S cones, M cones, L cones), each containing a specific light-sensitive pigment that is most sensitive to either short (peak at ~440 nm), medium (peak at ~530 nm), or long wavelengths of light (peak at ~558 nm) respectively. Cones are densely concentrated in the fovea, the central part of the retina. The rods are more sensitive to light than cones but do not provide colour vision. They are specifically sensitive to low-light or dim conditions and contain a different light-sensitive pigment than the cones. Rods are more abundant in the peripheral regions of the retina.

---

### Living histopathology-interrogation of ocular tissues by light: a celebration of the slit-lamp and a repertoire of clinical techniques [^2518232f]. Eye (2025). Medium credibility.

Retro-illumination

When Goldmann configured the slit and microscope to rotate coaxially about the object plane, he may not have anticipated that its most powerful feature would become deflection of the slit away from their common axis. This enables light, reflected from more distant objects (usually the iris, during corneal microscopy), to illuminate the object plane from behind: retro-illumination (Figs. 7, 8 and 9).

Fig. 8 
Slit configurations for dark-field, bright-field, and remote dark-field retro-illumination.

Fig. 9 
Tarantula hair in corneal stroma, demonstrated by retro-illumination.

The slit has been angled, narrowed, and located on the iris so as to place the pathology at the junction between bright and dark fields.

Background brightness becomes crucial (ie: “ dark-field” or “ bright-field ” retro-illumination) and slit-offset, width, and height are constantly re-adjusted to optimise this.

During clinical examination, a dark field provides high-contrast pathological detail; bright-field images may provide silhouettes of opaque or refractile objects, demonstrating topography in the x-y plane.

The most information-rich area of a slit image usually lies between the bright and dark background field

(Figs. 9, 10).

Fig. 10 
Mucus filament over a corneal graft.

a Wide-field illumination - specular reflections show a mucus filament, anchored centrally and drawn upwards by the upper lid. b Retro-illumination with object placement between the bright and dark fields identifies the pathology to be a corneal epithelial defect (arrow).

Remote dark-field retro-illumination

Pathology can become obscured when light is scattered by the surrounding media; however, this may be overcome by remote dark-field retro-illumination. The light beam is directed through the air space in front of the cornea, to be reflected by peripheral iris in the opposite angle (see Fig. 8 and video).

Surface contours during retro-illumination

When light, reflected by deep structures, emerges through transparent tissues, it is refracted by their surface contours. A corneal depression acts as a concave lens and light is diverged, creating a bright ring with dark centre. Conversely, surface elevations act as convex lenses, which converge light, creating a central bright zone.

---

### Perceiving visual expansion without optic flow [^b7f435e4]. Nature (2001). Excellent credibility.

When an observer moves forward in the environment, the image on his or her retina expands. The rate of this expansion conveys information about the observer's speed and the time to collision. Psychophysical and physiological studies have provided abundant evidence that these expansionary motions are processed by specialized mechanisms in mammalian visual systems. It is commonly assumed that the rate of expansion is estimated from the divergence of the optic-flow field (the two-dimensional field of local translational velocities). But this rate might also be estimated from changes in the size (or scale) of image features. To determine whether human vision uses such scale-change information, we have synthesized stochastic texture stimuli in which the scale of image elements increases gradually over time, while the optic-flow pattern is random. Here we show, using these stimuli, that observers can estimate expansion rates from scale-change information alone, and that pure scale changes can produce motion after-effects. These two findings suggest that the visual system contains mechanisms that are explicitly sensitive to changes in scale.

---

### Where infants look determines how they see: eye movements and object perception performance in 3-month-olds [^c1e26942]. Infancy (2004). Low credibility.

A fundamental question of perceptual development concerns how infants come to perceive partly hidden objects as unified across a spatial gap imposed by an occluder. Much is known about the time course of development of perceptual completion during the first several months after birth, as well as some of the visual information that supports unity perception in infants. The goal of this investigation was to examine the inputs to this process. We recorded eye movements in 3-month-old infants as they participated in a standard object unity task and found systematic differences in scanning patterns between those infants whose post-habituation preferences were indicative of unity perception versus those infants who did not perceive unity. Perceivers, relative to nonperceivers, scanned more reliably in the vicinity of the visible rod parts and scanned more frequently across the range of rod motion. These results suggest that emerging object concepts are tied closely to available visual information in the environment, and the process of information pickup.

---

### The lazy shadow: a monocular counterpart to the pulfrich stereo phenomenon [^0e5f29af]. The British Journal of Ophthalmology (2007). Low credibility.

Background

The Pulfrich phenomenon is a dynamic stereo dysmetropsia attributed to an asymmetry of neural conduction between the eyes. The phenomenon may arise spontaneously with ocular and neurological disease and may be induced in normal subjects by placing a light-attenuating filter before one eye. By analogy, it is predicted that a localised variation of retinal illumination within one and the same eye should affect the perception of moving targets.

Methods

A rotating, nesting square display was generated by computer graphics. The inner square was painted bright white, the outer dim grey. Luminances, rates of rotation and angular sizes were varied.

Results

On rotation, the outer, dimmer square appeared to lag behind the inner, brighter one, as a "lazy shadow". The lag was measured quantitatively in normal observers by applying a compensatory lead to the lagging square. The magnitude of lag was found to depend on luminance, spin rate and visual angle. Lags exceeding 10 degrees were observed under optimum conditions.

Conclusions

The experimental results confirm the existence of a monocular counterpart to the binocular Pulfrich phenomenon. Distortions of moving images are likely to occur spontaneously with monocular, localised visual field defects.

---

### Motion-dependent representation of space in area MT + [^24600548]. Neuron (2013). Low credibility.

How is visual space represented in cortical area MT+? At a relatively coarse scale, the organization of MT+ is debated; retinotopic, spatiotopic, or mixed representations have all been proposed. However, none of these representations entirely explain the perceptual localization of objects at a fine spatial scale--a scale relevant for tasks like navigating or manipulating objects. For example, perceived positions of objects are strongly modulated by visual motion; stationary flashes appear shifted in the direction of nearby motion. Does spatial coding in MT+ reflect these shifts in perceived position? We performed an fMRI experiment employing this "flash-drag" effect and found that flashes presented near motion produced patterns of activity similar to physically shifted flashes in the absence of motion. This reveals a motion-dependent change in the neural representation of object position in human MT+, a process that could help compensate for perceptual and motor delays in localizing objects in dynamic scenes.

---

### Neurobiology and the humanities [^6a1a3339]. Neuron (2014). Low credibility.

All Truths Are Subjective

These are, in a sense, facile rallying points that merely serve to emphasize different approaches to what are, at heart, common questions. More difficult to address are shared questions regarding human experience and what they signify about brain operations and the world in which it has developed. Here the boundary between neurobiological and humanistic questions is faint and separating the two, I believe, does both a disservice even if, at present, the relationship between neuroesthetics and the humanities is asymmetric, in that neuroesthetics has a good deal more to gain from the humanities than the latter from us. Many of the critical questions now addressed experimentally by neuroesthetics have been addressed in philosophical discourse for centuries. Prominent among these is the problem of knowledge, a primordial function of the brain and a central issue in philosophy. Using color vision as an example, Arthur Schopenhauer argued that “a more precise knowledge and firmer conviction of the wholly subjective nature of color contributes to a more profound comprehension of the Kantian doctrine of the likewise subjective, intellectual forms of all knowledge”, since color is a subjective experience that is the result of a transformation of the objective reality of the outside world by rules that govern the operations of the mind (brain). The only knowledge we can therefore have of color is “brain knowledge”. The brain, far from representing colors (or indeed the sensory world) passively and veridically, constructs them through inherited programs (algorithms). Neurobiology has yet to unravel the details of these operations, but their purpose is to stabilize the colors of surfaces in spite of continual fluctuations in the wavelength-energy composition of the light reflected from them, leading to a constancy of colors. While we can be (subjectively) sure that a leaf is green even when it reflects more long-wave (red) light (as is common at sunset or sunrise), we can never be sure, unless armed with light-measuring devices, of the “objective” reality in terms of the precise wavelength-energy composition of the light reflected from a surface and from its surrounds. Generally speaking, the only truths that we can be certain of are those that we experience, namely subjective truths. This is but one example of a shared general question in neurobiology and the humanities—of how objects and situations maintain their identity in spite of continual changes in the signals reaching the brain from them, summarized for Western philosophy in the Heraclitan doctrine of flux and for Eastern (Buddhist) philosophy in the statement that “nothing is permanent except change.”

---

### Perceptually unidentifiable stimuli influence cortical processing and behavioral performance [^36f6a8ae]. Nature Communications (2020). High credibility.

Subthreshold stimulus exposure

Repeated two-frame presentations of a natural image—the exposure task—was conducted before each image orientation discrimination session. Monkeys were required to fixate on a 0.4 deg central fixation spot while a movie stimulus consisting of 96 full contrast circular sinusoidal oriented gratings spanning 0–180° (eight gratings, 22.5° orientation step, 12 repetitions) was presented at the receptive field location. The gratings were displayed at a frequency of 60 Hz for a total movie duration of 1600 ms. Within the movie, two consecutive frames (33.33 ms), randomly inserted between frames 10 and 86, were replaced by a grayscale natural image (Fig. 2a). Masked high-contrast images were used because they elicit strong responses from V1 neurons, necessary to ensure reliable measurements, such as mutual information, decoder performance, and CCGs and because the same stimuli were subsequently presented in discrimination experiments. The exposed image was presented in a randomly interleaved manner across trials either at its original orientation or rotated in the 5–20° range, i.e. the same image rotations used in the subsequent discrimination task. Each exposure session consisted of 200 trials. In each session we used a different, novel exposed image. No behavioral response was required in this task.

Image orientation discrimination task

Several minutes after the completion of the image exposure phase, animals were required to complete an image orientation discrimination task using two images in each session: one of the images was the exposed image, whereas the other image was a novel image that monkeys have never seen before (Fig. 3a). Images were adjusted in mean luminance so that they matched each other, as well as the mean luminance of the grating stimuli. The size and location of the stimuli were identical to those used in the exposure phase. In each trial, one of the images was flashed twice (second image was either identical to the first or rotated counterclockwise; the number of match and non-match trials was identical) for 300 ms, separated by 700–1000 ms random delay interval. Each session had between 480 and 640 trials. Since the two monkeys had slightly different overall performance levels, image rotations were 3°, 5° 10°,and 20° for monkey C, and 5°, 10°, 15°, and 20° for monkey W. Monkeys were required to signal whether the two images were identical or different (rotation) by releasing/holding the lever. Match and non-match trials were randomly interleaved.

---

### A disinhibitory circuit for contextual modulation in primary visual cortex [^f68d4d02]. Neuron (2020). Medium credibility.

Context guides perception by influencing stimulus saliency. Accordingly, in visual cortex, responses to a stimulus are modulated by context, the visual scene surrounding the stimulus. Responses are suppressed when stimulus and surround are similar but not when they differ. The underlying mechanisms remain unclear. Here, we use optical recordings, manipulations, and computational modeling to show that disinhibitory circuits consisting of vasoactive intestinal peptide (VIP)-expressing and somatostatin (SOM)-expressing inhibitory neurons modulate responses in mouse visual cortex depending on similarity between stimulus and surround, primarily by modulating recurrent excitation. When stimulus and surround are similar, VIP neurons are inactive, and activity of SOM neurons leads to suppression of excitatory neurons. However, when stimulus and surround differ, VIP neurons are active, inhibiting SOM neurons, which leads to relief of excitatory neurons from suppression. We have identified a canonical cortical disinhibitory circuit that contributes to contextual modulation and may regulate perceptual saliency.

---

### Comment on' domestic light at night and breast cancer risk: a prospective analysis of 105000 UK women in the generations study' [^2763316e]. British Journal of Cancer (2019). Medium credibility.

Broadly speaking, “to see” refers to the ability to encode sufficient contrast to differentiate between different objects or surfaces. From first principles, there are three conditions in which it is possible to see your hand in front of you: first, both your hand and the background could be illuminated at levels sufficient for the human visual system to operate. We believe that this is likely to be the case in the vast majority of urban bedrooms. Second, your hand could be illuminated, and seen against the contrast of a black background. Third, you could observe your hand as a black shadow against an illuminated background. The second and third possibilities would require quite contrived lighting design, so in nearly all cases if you can see your hand, you can also see across the room.

When light enters a bedroom, it will reflect off objects, the walls, the ceiling, and the floor. While there will surely be differences in illuminance between these surfaces (depending on their intrinsic properties such as their bidirectional reflectance distribution function), if there is light, then there is light everywhere. People with normal visual ability are easily able to orient under starlight(0.6–0.9 mlux), which is many orders of magnitude less than the illuminance required to read (Fig. 1). At starlit levels, it is certainly possible to see the walls and objects in a room, once the eye has had a few minutes to dark adapt.

Fig. 1 
Light levels and approximate visual ability. Luminance values are based on reflection from a nearly white surface. Both “light enough to see hand” and “light enough to see across the room” are possible starting at or near starlight levels, and thus provide equivalent information about the luminance levels in typical bedrooms. Note that exact visual performance levels depend on many factors, including previous light exposure, pupil size, and local contrast

We have personally noted that people often misjudge their visual abilities when recalling past experiences. Urban dwellers not used to allowing their eyes time to dark adapt will often incorrectly claim that a rural area was “so dark you couldn’t see your hand in front of you”. Similarly, under light levels of around 0.1 lux, one can still see so well that it is a disquieting experience to realise that reading small text is not possible.

---

### How does it look? Level 2 perspective-taking at 36 months of age [^484cf560]. Child Development (2011). Low credibility.

Previous research has found that children engage in Level 2 visual perspective-taking, that is, the understanding that others may see things in a different way, between 4 and 5 years of age (e.g., J. H. Flavell, B. A. Everett, K. Croft, & E. R. Flavell, 1981). This ability was reexamined in 36-month-olds using color filters. In Experiment 1 (N = 24), children had to recognize how an object looked to an adult when she saw it through a color filter. In Experiment 2 (N = 24), a novel production test was applied. Results of both studies show that 36-month-olds know how an object looks to another person. The discussion focuses on the psychological requirements of visual perspective-taking and its relation to other "theory of mind" abilities, such as the distinction between appearance and reality and understanding false belief.

---

### Neuronal variability reflects probabilistic inference tuned to natural image statistics [^95b1b8aa]. Nature Communications (2021). High credibility.

Surround stimulation reduces uncertainty and V1 variability

The previous analysis shows that variability in the GSM is influenced by the inferred values of the global modulator. Therefore, the framework predicts that variability is sensitive to stimulus manipulations that affect the inferred global modulator. Specifically, stimuli that lead to a higher estimate of the modulator present less uncertainty over the hidden feature, and thus should reduce response variability. To test this prediction, we considered the modulation of V1 activity induced by spatial context—by stimuli in the surround of a neuron’s RF—because spatial context can reduce stimulus uncertainty without modifying the stimulus drive inside the RF.

First, we verified for the GSM that surround stimuli (i.e. image regions that activate the surround filters) reduce uncertainty. The activity of the model neuron is associated with the oriented feature in the center. However, the surround input contributes to the estimate of the global modulator, and therefore influences the neuronal response. Specifically, our analytical results show that, for a fixed RF input, surround stimulation increased the estimated modulator and therefore had a suppressive influence both on the mean and variance of the neuronal response (Fig. 2b ; Methods Eq. 3), validating our intuition that surround stimuli reduce uncertainty because they result in a higher estimate of the global modulator.

---

### Innate preferences affect results of object recognition task in wild type and Alzheimer's disease mouse models [^dbf7aba8]. Journal of Alzheimer's Disease (2022). Medium credibility.

When studying exploration behavior related to objects of different size, we found that the objects with big and medium dimensions appeared more suitable for exploration, even if the bigger object was mainly used for climbing or sitting. Conversely, the small object resulted the less explored and attractive. This is in line with previous studies suggesting that object size influenced exploration and preference probably because an object with a similar size to the animal, results in a higher affordance. Indeed, affordance is referred to what animals could perceive, recognize, and memorize of an object, and depends upon the relationship between the properties of objects and the abilities of animals. Therefore, affordance is influenced by those characteristics of the object that attract the animal because of a possible interaction with it. In general, an object with higher affordance is the one that the mouse could lean on, climb onto, grasp, or perform other actions belonging to common rodent activities, or an object able to elicit sensory perceiving. Consistently, our findings showed that the small object, approachable only by horizontal exploration, was less explored in respect to the medium and the big object that could be also explored by vertical and on-top exploration. Consequently, if the aim of the study is to evaluate memory, it would be better to choose an object with high affordance that mice are interested to explore but with characteristics that do not allow an excessive active interaction to avoid distraction and a decrease of exploration time. In agreement with previous findings, a medium size object, i.e. comparable to mouse dimension, should be preferentially chosen, and, in any case, it would be better not to associate objects of different size in the same experimental protocol.

---

### Direct detection of a single photon by humans [^97c0ed28]. Nature Communications (2016). Medium credibility.

Next we investigated the distribution of subjects' confidence ratings for our single-photon SPDC source. As expected, given the weak stimulus, the distribution of confidence ratings for correct responses was dominated (88%) by low confidence R1 and R2 responses (Fig. 2b). Considering only the answers with the high-confidence R3 rating, we found that the probability of providing the correct response was significantly elevated compared with all responses (0.60±0.03, P =0.0010), which demonstrates that subjects indeed detected a single photon in the high-confidence trials (Fig. 2a).

Not every single photon incident on the eye leads to an isomerization and a subsequent production of a retinal signal. Based on the efficiency of the signal arm and the visual system, we estimate that in ∼6% of all post-selected events an actual light-induced signal was generated (Methods section). Therefore, it is expected that from all trials only this fraction should be able to contribute to an above chance performance as well as to some increase in the subjects' choice of high-confidence (R3) ratings. Thus, the correlation between the statistically significant sensitivity of subjects for a single-photon stimulus with their higher confidence rating provided us with further corroborative evidence that subjects could indeed detect a single photon. To convince ourselves further that the observed performance of subjects would be within a plausible regime, we used signal detection theory to compare our subjects' performance with the expected performance of an ideal detector, whose operation was only limited by intrinsic noise and efficiency (Supplementary Note 1, Supplementary Fig. 2). We found that the performance of our subjects did not exceed the performance of an ideal detector (Fig. 2a) for a plausible range of reported noise and efficiencies in the literature (Supplementary Table 1).

Finally, we systematically excluded a set of alternative explanations as the basis for our observations, such as subjects' bias (Supplementary Note 1) or possible contamination with background light (Methods section). We also confirmed the overall performance of our subjects and the experimental set-up including our psychophysics protocol by reproducing the results of previous experiments in the higher photon range using a classical Poissonian light source (Supplementary Fig. 3). We found the overall shape of the psychometric curves for all subjects, its characteristic parameters such as the threshold and the index of discriminability Δm, a measure of stimulus discrimination sensitivity(Supplementary Note 2), to be consistent with previous observations(Supplementary Fig. 3).

---

### Image transmission through an opaque material [^b0187428]. Nature Communications (2010). Medium credibility.

Optical imaging relies on the ability to illuminate an object, collect and analyse the light it scatters or transmits. Propagation through complex media such as biological tissues was so far believed to degrade the attainable depth, as well as the resolution for imaging, because of multiple scattering. This is why such media are usually considered opaque. Recently, we demonstrated that it is possible to measure the complex mesoscopic optical transmission channels that allow light to traverse through such an opaque medium. Here, we show that we can optimally exploit those channels to coherently transmit and recover an arbitrary image with a high fidelity, independently of the complexity of the propagation.

---

### ACR-AAPM-SIIM practice parameter for determinants of image quality in mammography [^e719b381]. ACR/AAPM/SIIM (2022). High credibility.

Mammographic image display—baseline viewing capabilities specify that image displays must be capable of displaying a set of current and prior 4-view mammograms (left and right craniocaudal (CC) and mediolateral oblique (MLO) views) simultaneously; image displays should be able to display a ruler on the screen as a visual clue to indicate physical size; and image displays should ensure that the luminance of the image background (outside the breast) is maintained at Lmin as window width and level are adjusted during interpretation.

---

### Minimal exposure durations reveal visual processing priorities for different stimulus attributes [^47665535]. Nature Communications (2024). High credibility.

Previous studies have suggested a processing advantage and faster access to awareness for upright over inverted faces –, and for emotional over neutral faces, (although the latter claim, in particular, has been challenged –). If so, processing—and possibly awareness—of upright and emotional faces should require shorter minimal exposures than inverted and neutral faces, respectively.

In this work, we use a combination of behavioural and neural approaches to test these hypotheses. In our first experiments, observers were presented with both intact faces and their scrambled counterparts, equated for luminance and contrast, and we measured the minimal exposure duration that was necessary to detect aspects of meaning in the stimulus. Specifically, we measured sensitivity to the location of the stimulus that contained a face (rather than the noise stimulus containing low-level information consistent with a face), and also measured sensitivity to the emotional identity of that face. The two-alternative forced-choice localisation task meant that observers could only succeed by focusing on the extraction of meaning from stimuli (i.e. parsing the particular arrangement of stimulus features into a face), and the application of signal detection analyses enabled criterion-free measurement of sensitivity to these different stimulus aspects. In addition, our tasks also asked observers to rate their own subjective visual experience on each trial, allowing us to assess the degree to which observers were sensitive to their own perceptions of the stimuli. In subsequent experiments, we augmented these procedures with experiments examining how meaningful stimulus attributes may affect single-stimulus detection (indicating meaning extraction), as well as experiments that collected a set of EEG measures, allowing us to evaluate the match between behavioural sensitivity to stimulus aspects and neural indices of processing. The high-precision bottom-up stimulation provided by the tachistoscope enabled accurate measurement of the minimal exposure durations required for perception of meaning.

---

### Pediatric eye evaluations preferred practice pattern [^935e74a5]. Ophthalmology (2023). High credibility.

Figure A3-1—red reflex examination findings describe common patterns and their implications. Normal is when the child looks at light and both red reflections are equal. Unequal refraction is when one red reflection is brighter than the other. No reflex (cataract) occurs when lens or other media opacities block or diminish the red reflection. Foreign body or abrasion of the left cornea is suggested when the red reflection from the pupil back-lights corneal defects or foreign bodies and, with parallax, movement of the examiner’s head in one direction appears to move corneal defects in the opposite direction. Strabismus is when the color and/or brightness of the red reflex differs between the eyes and the corneal light reflex is temporally displaced in the misaligned right eye, indicating esotropia.

---

### Double fault! [^fe1fb732]. JAMA Network (2001). Excellent credibility.

Spectral curves for the colors of tennis balls and for the transmission properties of Competivision, ProSoft, and a neutral color lens. The energy percentages are a transmittance for the lenses, and reflectance and fluorescence for the tennis ball. The fluorescence peak near 515 nm overlaps the transmittance peak of the blue lenses. Approximate wavelength ranges of subjective color perception are shown, along with the beginnings of the ultraviolet and infrared. Note that the blue lenses block most of the light coming from the tennis ball. Tennis ball curves were redrawn from the blue lens patent, 1 the ProSoft curve was redrawn from Wesley Jesson publicity material, and the Competivision and Bollé neutral lenses were measured on a laboratory spectrophotometer.

However, Figure 1 shows that the blue lenses block most of the yellow light that is normally reflected off a ball. These lenses pass primarily blue and green light. The Competivision lens blocks all UV light below 400 nm, and the ProSoft contact lens lets in about 10% near 400 nm; both lenses pass 30% or more of violet light and block very little of the blue light. The same would apply for a yellow or white golf ball viewed against green grass. Furthermore, blue light in general is less effective physiologically with respect to functions such as acuity, contrast detection, and motion perception. 2, 3 In other words, critical perceptions are actually reduced rather than enhanced.

These bluish lenses will be of no visual benefit except possibly on a reddish or amber court. Here, the ball may appear to be relatively light against a darker court, but these lenses still should not be worn because of the hazard associated with blue light. My impression is that most of the visual problems from playing a sport in bright sunlight are a result of glare and of the brightness of the sky, which sets the general level of light sensitivity and can make a playing surface appear relatively dark. This is why a tunnel appears black inside as we approach it in sunlight. What can the ophthalmologist recommend.

---

### Perceptual learning without perception [^f6ff6270]. Nature (2001). Excellent credibility.

The brain is able to adapt rapidly and continually to the surrounding environment, becoming increasingly sensitive to important and frequently encountered stimuli. It is often claimed that this adaptive learning is highly task-specific, that is, we become more sensitive to the critical signals in the tasks we attend to. Here, we show a new type of perceptual learning, which occurs without attention, without awareness and without any task relevance. Subjects were repeatedly presented with a background motion signal so weak that its direction was not visible; the invisible motion was an irrelevant background to the central task that engaged the subject's attention. Despite being below the threshold of visibility and being irrelevant to the central task, the repetitive exposure improved performance specifically for the direction of the exposed motion when tested in a subsequent suprathreshold test. These results suggest that a frequently presented feature sensitizes the visual system merely owing to its frequency, not its relevance or salience.

---

### Paradoxical impact of memory on color appearance of faces [^dc20404e]. Nature Communications (2019). High credibility.

Discussion

The experiments described here probe the impact of memory on color perception and uncover a special role of color in face perception. Consistent with the observation that scenes under LPS light impair retinal mechanisms for color, color matches under LPS light for arbitrarily colored objects were not predicted by colors seen under white light. Color matches for fruit under LPS light were also not predicted by stimulus identity: for example, knowledge that a strawberry is red did not cause participants to match the LPS-illuminated strawberry as red. These results show that cognition does not always hold sway over color appearance. But unexpectedly, color matches under LPS light to one class of stimuli, face skin, were predictable, although surprising: all participants matched faces green. Furthermore, most participants (female>male) reported that faces looked green or appeared sick, showing that the modulation by memory of face color does not remain unconscious. This paradoxical percept was evident for faces of both races tested, was abolished when the face context was masked, and was not observed for matches made to body skin. The results lead to three conclusions. First, the brain has a strong prior specifically for the color of skin, which triggers a prediction-error signal, possibly diagnostic of sickness, when violated in the context of rich face-shape information. Second, trichromatic color plays an especially important role in social communication. Third, cognition can influence perception, refuting notions to the contrary. Memory not only modulated perception of face color, but also impacted the lightness matches made to skin reflecting knowledge about race, confirming prior results(Supplementary Fig. 3).

Why do faces under LPS light look green? LPS light leaves intact rich shape cues, making it inescapable that the face is real. In the context of a real face, the peculiar spectral signals cannot be discounted with a trivial explanation, unlike the color in a photograph or digital reproduction, which can be attributed to the way the image was generated. Under LPS light, the spectral signals from skin are characterized by a decrement in redness (Fig. 8); a similar decrement accompanies many illnesses,, caused by sympathetic vasoconstriction of superficial blood vessels or anemia. We suspect that participants attribute the peculiar chromatic signal to sickness as the most likely explanation, which would explain why many participants described LPS-illuminated faces as sick-looking. The chromatic signals of LPS-illuminated skin violate a prior about healthy skin, breaching a naturalness constraint. But why should this breach cause a green appearance?

---

### Form vision from melanopsin in humans [^bcdb2760]. Nature Communications (2019). High credibility.

Discussion

We present a method for selectively enhancing spatial contrast for melanopsin and apply it to explore the contribution of melanopsin to pattern vision in healthy human subjects. We find that ‘melanopic’ patterns (with spatial contrast for melanopsin but not cones) are visible at low spatial and spatiotemporal frequencies and at higher background light intensities. The contrast sensitivity of this ‘melanopic’ vision is low, compared with rods and cones, but well within the range typically encountered in everyday life. Selectively enhancing melanopsin contrast alters the appearance of greyscale gratings and a selection of everyday images, making patterns appear more distinct and image elements ‘brighter’. These data are consistent with the hypothesis that melanopsin can be used to detect and distinguish spatial patterns and that this inner-retinal photoreceptor makes a direct contribution to form vision.

Receptor silent substitution and metamerism are well-established principles of colour science and grounded in fundamental photoreceptor properties (that each receptor has the same unitary response to light of different wavelength, but is differentially sensitive across the spectrum). We use these methods here to generate pairs of spectrally distinct lights that differ in effective intensity for melanopsin but are matched for each of the L, M and S cones (metamers). The resultant ability to modulate melanopsin activity selectively represents the only realistic opportunity to study melanopsin’s contribution to vision in healthy humans. However, its utility is critically dependent upon patterns generated with the metamers indeed being visible only to melanopsin and not cones (or rods). Several aspects of our data provide confidence that this is indeed the case in our study. Addressing first the possibility of inadvertent cone contrast: we minimised the possibility of this in our experimental design by using an online-tuning step to identify metameric pairs independently for each subject that were invisible when presented in a pattern to which cones are very sensitive (3.2 cpd). Metamerism can fall down in the shadow of blood vessels, and we further designed our stimuli to have little contrast for such penumbral cones. Accordingly, our subjects did not detect metameric patterns at high spatial frequency (as expected for penumbral cone contrast; ref.) nor report seeing a Purkinje tree of retinal vasculature. The range of spatial and spatiotemporal frequencies over which the metameric stimuli were detected is also inconsistent with the hypothesis of residual cone contrast. Metameric stimuli were invisible across a range of frequencies at which cone vision is most sensitive, and detectable only at low frequencies.

---

### Form vision from melanopsin in humans [^b10b9f7d]. Nature Communications (2019). High credibility.

Two versions of pairs of greyscale images (selected from a range of everyday scenes) differing in melanopic contrast were produced. In the first, the brightest point in each version of an image was the set to be one of the calibrated metameric stimuli (melanopsin bright or dim) for a participant. Spectrally neutral reductions in intensity were then used to generate greyscale values for all other pixels in the image. Using these values, we were able to generate 19 metameric greyscale images, differing in melanopic spatial contrast, but also in overall melanopic radiance. In a second version, we matched image pairs for mean melanopic radiance, by first defining the median intensity pixel within each image. For the high-melanopic contrast images, we rendered all greyscale values below this point in the low-melanopic metamer, and those above it with the high-melanopic metamer. For the low-melanopic contrast images, we did the reverse. This approach allowed us to generate 12 images with varying melanopic contrast, but matched for mean melanopic radiance.

Each image was presented for 2 s, separated by a 1 s inter-stimulus interval, for as many repeats as the participant wished to view. Images were displayed across the entire projection area. To avoid confounds with foveal vision, subjects fixated on a cross and a 10° region surrounding this fixation point was covered by a grey mask. The order in which the two versions of any image were presented was randomised. Participants were then asked to decide in which of the two images ‘patterns were more distinct’. In a follow-up experiment, the same participants were asked to view those images (n = 6) in which the higher-melanopic image was rated as more distinct in 100% of trials. In this case, however, the high-melanopic image was always presented second in the sequence. Participants were then simply asked to describe how the second image appeared compared with the first. A word cloud was then generated by scaling the font of each word according to the number of times a descriptor was used.

---

### An interactive method of assessing the characteristics of softcopy display using observer performance tests [^19826f2b]. Journal of Digital Imaging (2002). Low credibility.

An interactive computer program has been developed to assess the quality of softcopy display by measuring the contrast sensitivity, spatial resolution, and spatial uniformity at various backgrounds and objects. This program runs on Microsoft Window or NT platform and is easy to use. It has been shown to be a sensitive and accurate tool to measure the characteristics of monitors of any kind. It can be used for routine QA as well as for the acceptance testing of picture archiving and communication systems. Data obtained using this program on monitors can be plotted chronologically so as to monitor any trend of deterioration. By introducing a randomization of the location of the test objects, this program eliminates the guessing error often associated with psychophysical measurements.

---

### Optimal speed estimation in natural image movies predicts human performance [^dff4a4cc]. Nature Communications (2015). Medium credibility.

Psychometric functions were measured for each of 10 standard speeds (±5.20, ±4.16, ±3.12, ±2.08, ±1.04 deg/s) using the method of constant stimuli, seven comparison speeds per function. For each standard, each of the seven comparison speeds was presented 50 times. Each observer completed 3,500 trials (2 directions × 5 standard speeds × 7 comparison speeds × 50 trials).

The exact same naturalistic movie was never presented twice. Rather, movies were randomly sampled without replacement from the test set of 1,000 naturalistic movies at each speed (described in the main text). This sampling procedure was used to ensure that the set of stimuli used in the psychophysical experiment had approximately the same statistical variation as the stimuli that were used to train and test the ideal observer model. Specifically, for each standard speed, 350 ‘standard speed movies' were randomly selected. Similarly, for each of the seven comparison speeds corresponding to that standard, 50 ‘comparison speed movies' were randomly selected. Standard and comparison speed movies were then randomly paired together.

This feature of our experimental design represents a departure from methods used in classical psychophysical studies in which the same stimulus is presented many hundreds of times. Such studies have typically focused on the performance limits imposed by internal noise. In contrast, the aim of our study was to examine the performance limits imposed by variation and uncertainty in natural stimuli.

Data analysis. To compare performance, human and ideal observers were presented with the same randomly sampled, contrast-equalized stimuli. The ideal observer decision criterion was identical to the criterion the human observers were assumed to follow. Specifically,

where R 1 and R 2 are the population responses of the space-time RFs (Fig. 3a) to the movies presented in the first and second intervals, respectively.

To obtain speed discrimination thresholds, the raw psychometric data was fit with a cumulative Gaussian function using maximum likelihood estimation. Threshold criterion was set to d ′=1.36, the speed difference required to go from 50 to 75% on the psychometric function. Confidence intervals on the thresholds were calculated from 1,000 bootstrapped data sets. The psychometric data was similar for the two different directions of motion (left or right); data were collapsed across the direction of motion, and re-fit with the Gaussian. Thus, each symbol in Figs 5b and 6b,c is comprised of 100 measurements per absolute comparison speed, for a total of 700 measurements per psychometric function.

---

### Finding any waldo with zero-shot invariant and efficient visual search [^eba05423]. Nature Communications (2018). Medium credibility.

Introduction

Visual search constitutes a ubiquitous challenge in natural vision, including daily tasks such as looking for the car keys at home. Localizing a target object in a complex scene is also important for many applications including navigation and clinical image analysis. Visual search must fulfill four key properties: (1) selectivity (to distinguish the target from distractors in a cluttered scene), (2) invariance (to localize the target despite changes in its appearance or even in cases when the target appearance is only partially defined), (3) efficiency (to localize the target as fast as possible, without exhaustive sampling), and (4) zero-shot training (to generalize to finding novel targets despite minimal or zero prior exposure to them).

Visual search is a computationally difficult task due to the myriad possible variations of the target and the complexity of the visual scene. Under most visual search conditions, the observer does not seek an identical match to the target object at the pixel level. The target object can vary in rotation, scale, color, illumination, occlusion, and other transformations. Additionally, the observer may be looking for any exemplar from a generic category (e.g. looking for any chair, rather than a specific one). Robustness to object transformations has been a fundamental challenge in the development of visual recognition models where it is necessary to identify objects in a way that is largely invariant to pixel-level changes (e.g. refs. –, among many others). The critical constraint of invariance in recognition has led to hierarchical models that progressively build transformation-tolerant features that are useful for selective object identification.

In contrast with the development of such bottom-up recognition models, less attention has been devoted to the problem of invariance in visual search. A large body of behavioral – and neurophysiological – visual search experiments has focused on situations that involve identical target search. In those experiments, the exact appearance of the target object is perfectly well defined in each trial (e.g. searching for a tilted red bar, or searching for an identical match to a photograph of car keys). Some investigators have examined the ability to search for faces rotated with respect to a canonical viewpoint, but there was no ambiguity in the target appearance, therefore circumventing the critical challenge in invariant visual search. In hybrid search studies, the observer looks for two or more objects, but the appearance of those objects is fixed. Several studies have evaluated reaction times during visual search for generic categories as a function of the number of distractors,.

---

### Optimal speed estimation in natural image movies predicts human performance [^b5624edc]. Nature Communications (2015). Medium credibility.

Alternative implementations of ideal computations

In the results section, we describe one way of implementing the ideal computations (see Fig. 4a). Although that implementation is relatively simple, the implementation of the L neurons is not biologically plausible, because strictly linear neurons do not exist in the visual system (for example, there are no spike rates below zero). However, in the Supplementary Material we describe a more biologically plausible implementation of the L neurons that is in the spirit of the classic model for obtaining complex cells; namely, by summing the responses of simple cells.

Of course, there is no mathematical requirement that the likelihood of the joint RF responses be explicitly represented in a second population of L neurons, but available neurophysiology seems consistent with this story. Neurons in a number of well-documented brain areas (for example, areas V1 and MT) seem to represent variables explicitly that are represented only implicitly in earlier areas. As signals proceed through the visual system, neural states become more selective for properties of the environment, and more invariant to irrelevant features of the retinal images.

General implications of the variability of natural signals

Natural signals are highly variable. Hence, to determine the optimal computations for natural signals or to evaluate how well an organism is processing natural signals, it is important to analyse large numbers of stimuli. Figure 9 helps make this point. The space-time plots within each coloured rectangle in Fig. 9a represent the set of retinal image movies that would be produced by translating past the same point in a scene at different speeds (c.f. Fig. 2a). Each different coloured curve in Fig. 9b shows the corresponding joint response of the two RFs for each set of movies at different speeds.

There is great variation in the locus of joint responses produced by different natural stimuli, as a function of speed. It is obvious from these plots that attempts to determine the optimal computations from a small number of natural movies are likely to be frustrated, and conclusions about the optimal computations are likely to be mistaken (c.f. Fig. 2c). Yet, much psychophysical and neurophysiological research focuses on characterizing responses to small sets of artificial stimuli where each stimulus is presented many hundreds of times.

Analysing a large representative set of naturalistic stimuli can complement more traditional experimental designs and provide a better picture of the processing required under natural conditions. In natural conditions, the exact same stimulus is rarely if ever seen twice. Thus, the variation and uncertainty in natural stimuli can be assets rather than hindrances for discovering the computations that optimize performance in critical sensory-perceptual tasks.

---

### Flexible gating of contextual influences in natural vision [^98655b1d]. Nature Neuroscience (2015). Medium credibility.

Identical sensory inputs can be perceived as markedly different when embedded in distinct contexts. Neural responses to simple stimuli are also modulated by context, but the contribution of this modulation to the processing of natural sensory input is unclear. We measured surround suppression, a quintessential contextual influence, in macaque primary visual cortex with natural images. We found that suppression strength varied substantially for different images. This variability was not well explained by existing descriptions of surround suppression, but it was predicted by Bayesian inference about statistical dependencies in images. In this framework, surround suppression was flexible: it was recruited when the image was inferred to contain redundancies and substantially reduced in strength otherwise. Thus, our results reveal a gating of a basic, widespread cortical computation by inference about the statistics of natural input.

---

### Vision rehabilitation preferred practice pattern ® [^d5ab0380]. Ophthalmology (2023). High credibility.

Vision rehabilitation—interventions for daily living activities notes that patients have varied goals and that, in general, objects at near can be enlarged or magnified, objects at distance can be enlarged by moving closer or by viewing them with a telescopic device, and objects at intermediate distance such as information on computer monitors can often be magnified to allow easier viewing or, less often, telescopic devices can be utilized. Devices can be considered in the following categories: optical devices; technology including electronic devices such as computer adaptations using magnification, audio-screen readers, and text-to-speech using optical character recognition and cell phone accessibility options, cell phone cameras to magnify, and specific cell phone applications that read print aloud, offer directions, and identify colors, objects, and currencies; and other non-optical devices such as audio devices (e.g., watches, liquid level indicators) and large-format items such as large-print bank checks and large-button telephones.

---

### The size and albedo of the kuiper-belt object (20000) varuna [^9371d39e]. Nature (2001). Excellent credibility.

Observations over the last decade have revealed the existence of a large number of bodies orbiting the Sun beyond Neptune. Known as the Kuiper-belt objects (KBOs), they are believed to be formed in the outer reaches of the protoplanetary disk around the young Sun, and have been little altered since then. They are probably the source of short-period comets. The KBOs are, however, difficult objects to study because of their distance from earth, so even basic physical properties such as their sizes and albedos remain unknown. Previous size estimates came from assuming an albedo with the canonical value being 0.04. Here we report simultaneous measurements of the thermal emission and reflected optical light of the bright KBO (20000) Varuna, which allow us to determine independently both the size and the albedo. Varuna has an equivalent circular diameter of D = 900+129-145 km and a red geometric albedo of pR = 0.070+0.030-0.017. Its surface is darker than Pluto's, suggesting that it is largely devoid of fresh ice, but brighter than previously assumed for KBOs.

---

### Scaling models of visual working memory to natural images [^3a0ffdc1]. Communications Psychology (2024). Medium credibility.

Over the last few decades, psychologists have developed precise quantitative models of human recall performance in visual working memory (VWM) tasks. However, these models are tailored to a particular class of artificial stimulus displays and simple feature reports from participants (e.g., the color or orientation of a simple object). Our work has two aims. The first is to build models that explain people's memory errors in continuous report tasks with natural images. Here, we use image generation algorithms to generate continuously varying response alternatives that differ from the stimulus image in natural and complex ways, in order to capture the richness of people's stored representations. The second aim is to determine whether models that do a good job of explaining memory errors with natural images also explain errors in the more heavily studied domain of artificial displays with simple items. We find that: (i) features taken from state-of-the-art deep encoders predict trial-level difficulty in natural images better than several reasonable baselines; and (ii) the same visual encoders can reproduce set-size effects and response bias curves in the artificial stimulus domains of orientation and color. Moving forward, our approach offers a scalable way to build a more generalized understanding of VWM representations by combining recent advances in both AI and cognitive modeling.

---

### Optimal speed estimation in natural image movies predicts human performance [^19799f74]. Nature Communications (2015). Medium credibility.

Methods

Psychophysical methods

Human observers. Three observers participated in the experiments. All had normal or corrected-to-normal acuity. Two observers were authors; the third was naive to the purpose of the experiment. The human subjects committee at the University of Texas at Austin approved protocols for the psychophysical experiments. Informed consent was obtained.

Stimuli. Stimuli were presented on a Dell P992 19inch cathode ray tube monitor with 1,600 × 1,200 pixel resolution, and a refresh rate of 62.5 Hz. The display was linearized over 8 bits of grey level. The maximum luminance was 116.0 cd/m 2 ; the mean background grey level was set to 58.0 cd/m 2. The observer's head was stabilized with a chin- and forehead-rest, positioned 93 cm from the display monitor. Each stimulus movie subtended a visual angle of 1.0 deg (76 × 76 monitor pixels). Movie duration was 256 ms (16 frames at 62.5 Hz). All stimuli were windowed with a raised-cosine in space and a flattop-raised-cosine in time. The transition regions at the beginning and end of the time window each consisted of six frames (96 ms); the flattop of the window in time consisted of four frames (64 ms). Stimuli for the ideal observer were windowed identically. To prevent aliasing, stimuli were low pass filtered in space and in time before presentation (Gaussian with σ u =4 c.p.d. σ ω =31.25 Hz). No aliasing was visible. Sinewave stimuli were phase randomized on every trial, and were windowed and preprocessed identical to the natural stimuli.

---

### Objective assessment of nose tip light reflections in rhinoplasty [^58462a6b]. Aesthetic Plastic Surgery (2019). Medium credibility.

Purpose

To assess the objective and subjective analysis of facet and infratip lobule in postoperative digital pictures of rhinoplasty patients and compare them with the people with good-looking noses. With the help of simple software that measures the brightness of the pixels, we investigated the relation between light reflections and patient satisfaction.

Methods

egardless of the technique, forty patients who underwent external open approach rhinoplasty were selected randomly. Twenty participants with a good-looking nose without operation history were selected as the control group. Digital Color Meter® in MacOS X® was used for measuring the brightness of the facets and infratip lobule. As a subjective outcome measure, the visual analog scale (VAS) was used and compared with brightness ratios.

Results

The mean brightness ratios and VAS of operated noses were statistically low from the control group. There was a significant positive correlation between brightness ratios and VAS in all groups.

Conclusion

Our study presents the results of a simple method of measuring the light reflections of the nose tip. Noses with a good aesthetic outcome have more symmetric and subtle facets and infratip lobule. This method was feasible, and its results were correlated with patients' aesthetic perceptions.

Level Of Evidence Iv

This journal requires that authors assign a level of evidence to each article. For a full description of these Evidence-Based Medicine ratings, please refer to the Table of Contents or the online Instructions to Authors www.springer.com/00266 .

---

### Geriatric emergency department guidelines [^0139bbbd]. Annals of Emergency Medicine (2014). Medium credibility.

Geriatric emergency department visual orientation improvements—soft light is recommended and exposure to natural light is beneficial for recovery times and decreasing delirium; light colored walls with a matte sheen and light flooring with a low-glare finish should be used to optimize lighting and reduce glare. Older adults require three to four times as much light as young adults for visual clarity, and it is recommended that lighting consist of a combination of ambient and spot lighting. Patients should have control of the lighting in their space if they wish to sleep at a time when the other lights are on, allowing for fewer sleep disturbances. Contrast sensitivity in aging vision can be both confusing and hinder movement, and patterns that have dominant contrasts may create a sense of vertigo or be misperceived as obstacles or objects. Secondary to vision and perception changes, color choice for facilities and structure should be considered to enhance visual function and depth perception; avoid monochromatic color schemes and allow for colors to contrast between horizontal and vertical surfaces. Older adults experience a decrease in the ability to differentiate cool colors (greens, blues) as opposed to warm colors (yellows, oranges); in poorly lit areas, yellow is the most visible, orange and reds are attention grabbing, and blues appear hazy and indistinct and may appear gray due to the yellowing of the lens.

---