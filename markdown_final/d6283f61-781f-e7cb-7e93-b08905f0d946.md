# Medical Question & Answer

**Sample ID**: d6283f61-781f-e7cb-7e93-b08905f0d946
**Dataset Index**: 345843

---

## Question

Which of the following statements are true concerning the acf and pacf?

(i) The acf and pacf are often hard to interpret in practice

(ii) The acf and pacf can be difficult to calculate for some data sets

(iii) Information criteria represent an alternative approach to model order determination

(iv) If applied correctly, the acf and pacf will always deliver unique model selections

Answer Choices:
A. (ii) and (iv) only
B. (i) and (iii) only
C. (i), (ii), and (iii) only
D. (i), (ii), (iii), and (iv)

---

## Answer

> Let's see… What do we have here? The user is asking which statements about ACF and PACF are true. Let's break this down step-by-step. First, I need to think about the core concepts of ACF and PACF and their practical limitations. Then, I should verify whether information criteria like AIC and BIC are indeed used as alternatives for model order selection. Next, I will examine whether ACF/PACF can ever guarantee a unique model choice. Finally, I will cross-check computational or interpretive difficulties that arise in real data and synthesize the correct option from the choices provided.

> Let me first confirm the basics: ACF and PACF are fundamental tools for identifying the order of autoregressive and moving average components in time series, but their interpretation is often subjective and can be ambiguous in practice, especially with noisy or short series, so statement (i) "often hard to interpret" is reasonable and aligns with standard teaching and experience [^notfound].

> Wait, let me verify the computational claim in (ii). While ACF and PACF are straightforward to compute in principle, real-world datasets with missing values, irregular sampling, or very long series can create practical difficulties in estimation and visualization, so "can be difficult to calculate for some data sets" is a fair statement even if the math itself is not inherently intractable [^notfound].

> I need to check whether information criteria are indeed alternatives to ACF/PACF for model order selection. AIC, BIC, and related criteria are widely used to compare competing time-series models and select parsimonious orders, and they are explicitly discussed as alternatives when ACF/PACF are inconclusive or when automated selection is desired, so (iii) is correct [^535144a3] [^b50e9c6c].

> Hold on, let's not jump to conclusions about uniqueness. Statement (iv) claims that if applied correctly, ACF and PACF will always deliver unique model selections; that is too strong. Different analysts can reasonably interpret the same correlograms differently, and real data often yield mixed or borderline patterns that do not point to a single definitive order, so uniqueness is not guaranteed even with careful application, making (iv) false [^notfound].

> Let me synthesize: (i) and (ii) reflect real-world limitations of ACF/PACF, (iii) is correct because AIC/BIC are standard alternatives, and (iv) overstates determinism. Therefore, the true statements are (i), (ii), and (iii), which corresponds to option C [^535144a3] [^b50e9c6c].

---

The correct answer is **C. (i), (ii), and (iii) only**. ACF and PACF are often hard to interpret in practice due to noisy data and ambiguous cutoffs, and they can be difficult to calculate for some datasets, especially with missing values or irregular sampling. Information criteria (AIC, BIC) are widely used as alternative methods for model order selection. However, ACF and PACF do not guarantee unique model selections, as different analysts may interpret the same plots differently, so statement (iv) is false.

---

## Interpretation challenges of ACF and PACF

ACF and PACF plots are frequently **difficult to interpret** in practice because:

- **Noise and sampling variability**: Real-world data often contain noise, outliers, and short series, making it hard to distinguish true correlation from random fluctuation.

- **Ambiguous cutoffs**: Determining significant lags relies on visual inspection and subjective judgment, leading to inconsistent model identification.

- **Mixed models**: ARMA processes show decaying ACF and PACF, making it hard to identify pure AR or MA components.

---

## Computational difficulties

ACF and PACF can be **computationally challenging** in some datasets:

- **Missing data**: Gaps require imputation or deletion, which can bias estimates.

- **Irregular sampling**: Non-uniform intervals complicate lag calculations and plot interpretation.

- **Large datasets**: Long series can yield dense plots that obscure patterns and complicate manual inspection.

---

## Information criteria as alternatives

Information criteria such as AIC and BIC are **standard alternatives** for model order selection:

- **AIC (Akaike Information Criterion)**: Balances model fit and complexity; often selects models with better predictive accuracy.

- **BIC (Bayesian Information Criterion)**: Penalizes complexity more heavily, favoring parsimonious models.

- **Automated selection**: These criteria enable objective, reproducible model selection, especially when ACF/PACF are inconclusive.

---

## Uniqueness of model selection

ACF and PACF do not guarantee **unique model selections**:

- **Subjectivity**: Different analysts may interpret the same plots differently, leading to varying model choices.

- **Multiple plausible models**: Similar ACF/PACF patterns can suggest different ARMA orders.

- **Confirmation bias**: Preconceived notions can influence lag selection and model identification.

---

## Summary of statements

| **Statement** | **Truth value** | **Explanation** |
|-|-|-|
| (i) ACF and PACF are often hard to interpret in practice | True | Noise, sampling variability, and ambiguous cutoffs complicate interpretation |
| (ii) ACF and PACF can be difficult to calculate for some datasets | True | Missing data, irregular sampling, and large datasets pose computational challenges |
| (iii) Information criteria represent an alternative approach to model order determination | True | AIC and BIC are widely used alternatives to ACF/PACF |
| (iv) If applied correctly, ACF and PACF will always deliver unique model selections | False | Interpretation is subjective and multiple models may fit the same data |

---

The correct answer is **C. (i), (ii), and (iii) only**.

---

## References

### Concise guidelines of the European cardiac arrhythmias society (ECAS) on "Catheter ablation of atrial fibrillation" [^8d5e2657]. Journal of Cardiovascular Electrophysiology (2025). Medium credibility.

5 Recommendations on Efficacy

Classes I–III recommendations are reported in Tables 1, 2, 3, respectively. Flowcharts showing clinical conditions for which catheter ablation of AF is indicated based on the proposed recommendation scheme are reported below in Figures 1, 2, 3, and 3b. Supporting Information: Figures S1–S3 provide complimentary information on clinical data including number of patients enrolled, randomization ratio and follow‐up duration in reference studies. Supporting Information: Figures S4, S5a, and S5b provide an alternative scheme of Supporting Information: Figures S1, S2a, S2b, S3a, and S3b, focusing primarily on techniques and technologies used to obtain designated outcomes. Supporting Information material provides the list of literature contributions representing the basis of our research (pages 24–54). Criteria for selection of recommendation classes in the present document are reported below.

Compilation of the present recommendation scheme is made under the assumption that future studies showing evidence against the current indications or new evidence from previously unaddressed indications will lead to appropriate changes in the new programmed edition of ECAS guidelines. This will apply especially for studies reporting outcome results from single high‐quality studies and for follow‐up extended beyond 12‐month duration, where applicable.

5.1 Criteria for Class I Recommendations

The criteria guiding selection of recommendation classes in the present document have been discussed elsewhere. In brief, Class I indicates a recommendation in favor of the practice of catheter ablation or of any specific ablation strategy or technique, where:
a. evidence of greater benefit than risk or
b. similar efficacy and safety profiles between comparative technologies or techniques

is provided by high‐quality randomized multicenter controlled trials of sufficient sample sizes. High‐quality controlled trials guiding selection were defined as having:
a. low Risk of Bias for all crucial domains
b. high precision of effect expressed by a narrow 95% confidence interval
c. absence of other contradicting similar high‐quality evidence
d. compliance with the principle of directness, comparability between the population investigated in the reference trial and the population to which the recommendation is directed.

Finally, multi‐center trials were required to ensure representativeness of proposed recommendations on large scale.

Failure to comply with these criteria resulted in a down‐grading of the ablation practice, strategy or technique to a recommendation Class II level (Table 1).

Table 1
Class I recommendations for catheter ablation.

---

### ADHD: clinical practice guideline for the diagnosis, evaluation, and treatment of attention-deficit / hyperactivity disorder in children and adolescents [^6a129de6]. Pediatrics (2011). Medium credibility.

ADHD guideline — Action statement 2 (diagnostic criteria and information sources) states that to make a diagnosis of ADHD, the primary care clinician should determine that Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition (DSM-IV-TR) criteria have been met, including documentation of impairment in more than 1 major setting, obtain information primarily from reports from parents or guardians, teachers, and other school and mental health clinicians involved in the child's care, and should also rule out any alternative cause (quality of evidence B/strong recommendation). Aggregate evidence quality is B, with benefits indicating DSM-IV criteria lead to more uniform categorization, and harms/risks/costs noting the DSM-IV system does not specifically provide for developmental-level differences and might lead to some misdiagnoses; the benefits-harms assessment states the benefits far outweigh the harm, and value judgments highlight the importance of coordination between pediatric and mental health services; role of patient preferences recognizes potential stigma but prioritizes clarity in diagnosis; exclusions are none; intentional vagueness is none; and strength is a strong recommendation. The page notes that DSM-IV criteria are best supported by evidence and consensus and that an anticipated change in the DSM-V is increasing the age limit for when ADHD needs to have first presented from 7 to 12 years.

---

### Variable selection strategies and its importance in clinical prediction modelling [^535144a3]. Family Medicine and Community Health (2020). Medium credibility.

Bayesian information criterion

BIC is another variable selection criterion that is similar to AIC, but with a different penalty for the number of variables (parameters) included in the model. Like AIC, BIC also balances between simplicity and goodness of model fitting. In practice, for a given data set, BIC is calculated for each of the candidate models, and the model corresponding to the minimum BIC value is chosen. BIC often chooses models that are more parsimonious than AIC, as BIC penalises bigger models more due to the larger penalty term inherent in its formula.

Although there are similarities between AIC and BIC, and both criteria balance simplicity and model fit, differences exist between them. The underlying theory behind AIC is that the data stem from a very complex model, there are many candidate models to fit the data and none of the candidate models (including the best model) are the exact functional form of the true model. In addition, the number of variables (parameters) in the best model may not include all variables (parameters) in the true model. In other words, a best model is only an approximation of the true model and a true model that perfectly represents reality does not exist. Conversely, the underlying theory behind BIC is that the data are derived from a simple model and there exists a candidate model that represents the true model. Depending on the situation, however, each criterion has an advantage over the other. There are many studies that have compared AIC and BIC and recommended which one to use. If our objective is to select a best model that will provide maximum predictive accuracy, then AIC is superior (because there is no true model, and the best model is selected to maximise the predictive accuracy and represent an approximate true relation). However, if the goal is to select a correct model that is consistent, then BIC is superior (because BIC consistently selects the correct model from among the candidate models that best represent the true model). For large data sets, the performance of both criteria improves, but with different objectives.

---

### VA / DoD clinical practice guideline for management of bipolar disorder [^127e0c9a]. VA/DoD (2023). High credibility.

VA/DoD Clinical Practice Guideline — bipolar disorder algorithm structure and legend define a step-by-step decision tree with standardized symbols and arrows connecting numbered boxes indicating the order in which the steps should be followed; it includes steps of care in an ordered sequence, decisions to be considered, decision criteria recommended, and actions to be taken. Rounded rectangles represent a clinical state or condition; hexagons represent a decision point in the process of care, formulated as a question that can be answered "Yes" or "No."; rectangles represent an action in the process of care; and ovals represent a link to another section within the algorithm. Sidebars 1–7 provide more detailed information to assist in defining and interpreting elements in the boxes, and Appendix M contains alternative text descriptions of the algorithm.

---

### Designing phase II trials in cancer: a systematic review and guidance [^b3cadec7]. British Journal of Cancer (2011). Low credibility.

Paper selection

Retrieved full-text articles were reviewed and the inclusion/exclusion criteria applied by one of the authors (SB). From each paper included, data were extracted using a specifically designed data extraction form. During the development of the data extraction form, nine broad categories of phase II trial designs were identified: one-stage, two-stage, multi-stage/group sequential, decision theoretic, continuous monitoring, three-outcome, phase II/III, response adaptive randomisation and randomised discontinuation. These design categories were used to group the papers, with some papers being represented in more than one category. Papers describing adaptive designs were incorporated in the review where they specifically related to phase II design. 'Adaptive design' has not been incorporated as a specific design category here as it was felt that this formed a subset of the categories already established, for example, a two-stage design may incorporate adaptations at the end of stage one. Previous review papers have used alternative grouping categories for phase II designs, either focussing on single-arm vs randomised studies, or for those of molecularly targeted agents only, considering design categories such as randomised designs, enrichment designs and adaptive Bayesian designs. In contrast to these reviews, the chosen categories focus more on the practical identification and implementation of trial designs, reflecting trial design rather than trial analysis.

Other information was collected regarding the aim of the phase II trial; end points considered; parameters required for the design; sample size; number of treatment arms; randomisation; whether a design was adaptive; analysis; and computational and software requirements. Given the nature of the review and the information being sought, a data extraction form alone was deemed insufficient to inform the guidance document, therefore free text summaries of papers included after the full-text review were also incorporated. An assessment of ease of implementation of each design paper was made. Designs were defined as not being easy to implement if any of the following held: data required for implementation not likely to be available; sample size justification not provided; no decision criteria detailed; assessment of every patient is required before the next patient can be recruited; software is required to implement/analyse the design, which is not noted to be available and insufficient detail is given to allow implementation. These criteria reflect the ability to use the design paper mostly in its raw format to design and implement a phase II oncology trial.

---

### A user guide to the American Society of Hematology clinical practice guidelines [^af672199]. Blood Advances (2020). High credibility.

American Society of Hematology (ASH) guidelines — definition and core trustworthiness criteria are summarized as follows: Clinical practice guidelines are described as "statements that include recommendations intended to optimize patient care that are informed by a systematic review of evidence and an assessment of the benefits and harms of alternative care options," and trustworthy guidelines include development "by a knowledgeable, multidisciplinary panel of experts and representatives from key affected groups," being "based on a systematic review of the existing evidence," consideration of "important patient subgroups and patient preferences as appropriate," an "explicit and transparent process that minimizes distortions, biases, and conflicts of interest," provision of "ratings of both the quality of evidence and the strength of recommendations," and that they "be reconsidered and revised as appropriate when important new evidence warrants modifications of recommendations."

---

### Alternative treatments to selected medications in the 2023 American Geriatrics Society beers criteria ® [^3637031a]. Journal of the American Geriatrics Society (2025). High credibility.

American Geriatrics Society (AGS) Beers Criteria patient guidance states that your healthcare provider may choose to substitute alternatives in place of potentially inappropriate medications included in the AGS Beers Criteria®, and that the AGS Beers Criteria® and the list of alternatives are resources, not a replacement, for the expertise and knowledge of your healthcare provider. Never stop taking a medication without first talking to your healthcare provider, even if a medication you're taking is listed on the AGS Beers Criteria. Know about the medications you are taking. Ask your clinician or pharmacist about the medications you are taking and their potential side effects, and if you're experiencing any symptoms, ask if they could be related to a medication you are taking or if it may be a sign of another problem. Use only trusted, reliable sources (such as MedlinePlus) to look up information. You should regularly review all of the medications you are taking with your clinicians and pharmacists, you should report any problems with your medications, and these reviews should occur at least once a year as well as any time a new medication is prescribed.

---

### 2023 U.S. department of veterans affairs and U.S. department of defense clinical practice guideline for the management of headache [^7d673313]. Annals of Internal Medicine (2024). High credibility.

Algorithm — this clinical practice guideline (CPG) algorithm is designed to facilitate understanding of the clinical pathway and decision-making process used in managing patients with Headache, and the format represents a simplified flow that helps foster efficient decision making by providers; it includes steps of care in an ordered sequence, decisions to be considered, decision criteria recommended, and actions to be taken; the algorithm is a step-by-step decision tree, with standardized symbols to display each step and arrows connecting numbered boxes indicating the order in which the steps should be followed; shape meanings are specified: rounded rectangles represent a clinical state or condition, hexagons represent a decision point in the process of care formulated as a question that can be answered "Yes" or "No," rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm; Sidebars 1–7 provide more detailed information, and Appendix K contains alternative text descriptions of the algorithms.

---

### Management of chronic multisymptom illness: synopsis of the 2021 US department of veterans affairs and US department of defense clinical practice guideline [^e46240b6]. Mayo Clinic Proceedings (2022). High credibility.

Chronic multisymptom illness (CMI) algorithm — This clinical practice guideline (CPG) presents a step-by-step decision tree that represents a simplified flow of the management of patients with CMI and helps foster efficient decision making by providers; it includes an ordered sequence of steps of care, decisions to be considered, recommended decision criteria, and actions to be taken. Standardized symbols are used to display each step, and arrows connect the numbered boxes indicating the order in which the steps should be followed; sidebars provide more detailed information to assist in defining and interpreting elements in the boxes. In the symbol key, rounded rectangles represent a clinical state or condition, hexagons represent a decision point that can be answered "Yes" or "No," rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm. Appendix G contains alternative text description of the algorithm.

---

### VA / DoD clinical practice guideline for management of posttraumatic stress disorder and acute stress disorder [^a105391d]. DoD/VA (2023). High credibility.

Algorithm — VA/DoD Clinical Practice Guideline for Management of Posttraumatic Stress Disorder — states that this clinical practice guideline's algorithm is designed to facilitate understanding of the clinical pathway and decision-making process used in managing patients with PTSD and represents a simplified flow that helps foster efficient decision making by providers; it includes steps of care in an ordered sequence, decisions to be considered, decision criteria recommended, and actions to be taken. The algorithm is a step-by-step decision tree in which standardized symbols display each step and arrows connect the numbered boxes indicating the order in which the steps should be followed; sidebars 1–11 provide more detailed information to assist in defining and interpreting elements in the boxes. The legend specifies that rounded rectangles represent a clinical state or condition, hexagons represent a decision point in the process of care formulated as a question that can be answered Yes or No, rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm, and Appendix H contains alternative text descriptions of the algorithms.

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^1b0e2d37]. Journal of the American College of Cardiology (2018). Medium credibility.

Appropriate use definition — applied across technologies and procedures — is described as follows. The document states, "A consistent definition of appropriate use that includes consideration of risks and benefits is applied across technologies and procedures." It defines that "An appropriate diagnostic or therapeutic procedure is one in which the expected clinical benefit exceeds the risks of the procedure by a sufficiently wide margin, such that the procedure is generally considered acceptable or reasonable care." For diagnostic imaging, "benefits include incremental information, which when combined with clinical judgment, augments efficient patient care," and "These benefits are weighed against the expected negative consequences (risks include the potential hazard of missed diagnoses, radiation, contrast, and/or unnecessary downstream procedures)." It also notes, "The risks and benefits correspond with the different classes of cardiovascular services."

---

### VA / DoD clinical practice guideline for the management of upper limb amputation rehabilitation [^a33a9ba2]. VA/DoD (2022). High credibility.

VA/DoD upper limb amputation rehabilitation algorithm — overview and symbol legend: The algorithm is designed to facilitate understanding of the clinical pathway and decision making process used in managing patients with upper limb amputation (ULA) and represents a simplified flow including an ordered sequence of steps of care, decisions to be considered, recommended decision criteria, and actions to be taken. It is a step-by-step decision tree with standardized symbols; arrows connect the numbered boxes indicating the order in which the steps should be followed, and sidebars provide more detailed information. Shape meanings are defined as follows: rounded rectangles represent a clinical state or condition; hexagons represent a decision point formulated as a question that can be answered "Yes" or "No"; rectangles represent an action in the process of care; and ovals represent a link to another section within the algorithm. Appendix N contains alternative text descriptions of the algorithm.

---

### On the concepts, methods, and use of "Probability of success" for drug development decision-making: a scoping review [^34e45b5a]. Clinical Pharmacology and Therapeutics (2025). Medium credibility.

Discounting the evidence in the design prior

Given the consequences of the decision based on the calculated PoS, it is important to ensure that the information included in the design prior represents a reasonable belief of the treatment effect in the phase III study. When phase II results are used to inform decision‐making directly, one does not account for the fact that the patient population of phase III might be different than that of phase II trial. Phase II trials are usually conducted on more homogenous patient populations, while in phase III trials inclusion and exclusion criteria are less strict. Moreover, the phase III trials tend to be conducted in more sites and countries, with diverse ethnicities and several other factors, resulting in more heterogeneous populations. Additionally, the estimated treatment effect is usually overestimated in phase II trials, leading to selection bias and the potential to be over‐optimistic regarding the efficacy of the treatment and the chance that the phase III study will be successful. This is particularly the case when the decision to continue to phase III is based on success in the phase II study alone.

---

### The management of major depressive disorder: synopsis of the 2022 U.S. department of veterans affairs and U.S. department of defense clinical practice guideline [^3528b93a]. Annals of Internal Medicine (2022). High credibility.

Algorithm for major depressive disorder (MDD) — this CPG's algorithm is designed to facilitate understanding of the clinical pathway and decision making process used in managing patients with MDD; it represents a simplified flow of the management of patients with MDD and helps foster efficient decision making by providers; it includes an ordered sequence of steps of care, decisions to be considered, recommended decision criteria, and actions to be taken; the algorithm is a step-by-step decision tree with standardized symbols and arrows connecting numbered boxes indicating the order in which steps should be followed, and sidebars provide more detailed information; shape legend: rounded rectangles represent a clinical state or condition, hexagons represent a decision point formulated as a question that can be answered "Yes" or "No", rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm; Appendix G contains alternative text descriptions of the algorithm.

---

### Optimizing phase II of drug development for disease-modifying compounds [^acb5aca3]. Alzheimer's & Dementia (2008). Low credibility.

Phase II proof of concept (POC) (IIa) and dose-finding (IIb) studies represent major challenges in drug development. Prolonged development times delay effective therapies from reaching patients in need and adversely affect industry goals of decreasing time to market. Biomarkers including magnetic resonance imaging, cerebrospinal fluid tau and amyloid beta, and amyloid positron emission tomography have been considered as alternative outcomes to clinical measures. None of these is yet validated. Population enrichment is another possible solution to POC studies. More rapid progression to prespecified milestones can be achieved by enriching the population with risk factors. Conclusions based on enriched populations must be extrapolated with caution. Clinical measures with greater sensitivity than standard trial instruments might represent another strategy applicable to POC studies. Adaptive dose-response designs are being considered as a means of shortening phase IIb studies and creating a seamless interface with phase III. None of these strategies have been validated in a successful drug development program; all have some promise for reforming phase II and answering the central question of "how much information is sufficient to proceed to phase III without excessive risk for failure?"

---

### The use of opioids in the management of chronic pain: synopsis of the 2022 updated U.S. department of veterans affairs and U.S. department of defense clinical practice guideline [^9e30a9b9]. Annals of Internal Medicine (2023). High credibility.

VA/DoD Clinical Practice Guideline algorithm for the use of opioids in the management of chronic pain is designed to facilitate understanding of the clinical pathway and decision making process used in managing patients prescribed opioids for chronic pain and represents a simplified flow of the use of opioids in the management of chronic pain that helps foster efficient decision making by providers. It includes an ordered sequence of steps of care, decisions to be considered, recommended decision criteria, and actions to be taken. The algorithm is a step-by-step decision tree in which standardized symbols are used to display each step, arrows connect the numbered boxes indicating the order in which the steps should be followed, and sidebars provide more detailed information to assist in defining and interpreting elements in the boxes. Appendix J contains alternative text descriptions of the algorithm.

---

### Chronic cough due to acute bronchitis: ACCP evidence-based clinical practice guidelines [^f426a5bd]. Chest (2006). Medium credibility.

Regarding screening and diagnosis for acute bronchitis, more specifically with respect to diagnostic criteria, ACCP 2006 guidelines recommend to evaluate for alternative diagnoses as clinically appropriate.

---

### Exploring different objectives in non-inferiority trials [^32ef7163]. BMJ (2024). Excellent credibility.

Adopting alternative option and replacement non-inferiority trials

Table 2 describes the main considerations for adopting alternative option and replacement non-inferiority trials. The appropriateness of using the alternative option and replacement trial models will depend on patient and disease factors, the nature of the additional benefits of the new intervention, and whether different aspects of treatment response can be reliably measured.

Table 2
Considerations in the choice of non-inferiority trial objective based on patient, disease, and other characteristics

Criteria are not prescriptive, but each should be considered before designing a trial. A replacement trial can be considered when all of the criteria are met.

In general, the alternative strategy would be a more appropriate design for a trial investigating a new intervention when multiple treatment options are already available for the disease or condition and the magnitude of the additional benefits is predicted to be modest. This approach is also recommended if the additional benefits cannot be accurately described or attributed to the intervention (eg, feeling well enough to return to work). In this context, determining how the additional benefits could be expressed on a suitable scale to be formally compared between treatments would be challenging.

The replacement trial design would be suitable for use if a common standard of care is applied for most patients, but a new intervention is expected to have substantial additional benefits. If these additional benefits are fixed (eg, a much shorter duration), can be accurately determined (eg, a substantially improved toxicity profile), or both, the new intervention can be compared with the standard of care with the intention of becoming a replacement. Efficacy can be assessed, and the magnitude of the additional benefits determined for the experimental and standard of care arms.

---

### ASNC / AHA / ASE / EANM / HFSA / ISA / SCMR / SNMMI expert consensus recommendations for multimodality imaging in cardiac amyloidosis: part 2 of 2-diagnostic criteria and appropriate utilization [^5ee149ec]. Journal of Nuclear Cardiology (2020). High credibility.

Cardiac amyloidosis imaging appropriate use criteria — rating scale, categories, and consensus classification — are defined using a scale from 1 to 9, with an appropriate imaging study described as one in which expected incremental information exceeds expected negative consequences for a specific indication. Indications scored from 7 to 9 represent an appropriate option, scores from 4 to 6 are considered at times an appropriate option, and scores from 1 to 3 are rarely an appropriate option. Median panel scores determined final categories: a median of 7 to 9 without disagreement was considered "Appropriate"; a median of 1 to 3 without disagreement was considered "Rarely Appropriate"; and a median of 4 to 6 or any median with disagreement was classified as "May Be Appropriate." Agreement was defined as having no more than two panelists in an alternate category, corresponding to > 70% consensus, and raters were instructed to consider the numeric range as a continuum.

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^bcd5898e]. Journal of the American College of Cardiology (2018). Medium credibility.

ACC appropriate use criteria (AUC) methodology — comprehensiveness versus selective indications — explains that scenarios were intended to reflect the highest possible proportion of real-world patients, with some areas lacking guideline-level evidence, and that external feedback led to expanded and revised indications which improved document utility. The page notes that scenarios should "represent the highest possible proportion of patients… and to focus on common and real-world situations," that some topics lack "high-quality studies," that feedback revealed gaps or confusing definitions prompting expansion and revision, and that this expansion "has markedly improved the utility of the documents."

---

### The WHO-INTEGRATE evidence to decision framework version 1.0: integrating WHO norms and values and a complexity perspective [^0ffbec44]. BMJ Global Health (2019). High credibility.

All criteria are important and should be reflected on, but their relevance varies depending on the type of health decision and the decision-making context. In contrast, not all subcriteria are always relevant. At the start of a guideline or other decision-making process, an appropriately composed guideline panel or other decision-making group needs to discuss which of the subcriteria are applicable and useful in relation to the nature and specific characteristics of the intervention (see table 1); this group will also need to consider the specific information needed to populate criteria or subcriteria (see table 3). Complexity in the intervention and complexity in the system into which this intervention is implemented can usually be detected; the critical question is whether it is of value to examine this complexity in depth (see box 1 in this paper and box 2 in an earlier paper in this series). This prioritisation process should take the views of relevant stakeholder groups into account; which stakeholder groups are relevant depends on the nature of the problem and the institutional as well as broader physical and social context. In principle, these should include those directly affected by the intervention (eg, patients, beneficiaries), those financing (eg, health insurance providers, ministries of health, other ministries) or implementing the intervention (eg, healthcare providers, public health professionals, professionals outside of the health sector), as well as the general public.

Table 3
WHO-INTEGRATE framework version 1.0: criteria and suggested types of primary studies, evidence synthesis methods and approaches to assessing quality of evidence

A systematic weakness in many guideline development and other health decision-making processes is that consumer participation is obviated and guideline panels often substitute their own values and views for those of patients/beneficiaries. The voices of patients/beneficiaries and other relevant stakeholder groups can be incorporated through direct participation or representative surveysas well as qualitative research (see table 3).

The guideline panel will also need to decide how best to populate the criteria with evidence and whether a formal evidence synthesis or a more pragmatic approach is warranted for each. This decision will be influenced by the relevance of criteria and subcriteria in relation to a specific intervention or decision, and by the likely types and quantity of evidence available, as well as time and resource constraints. At the end of the process, the guideline panel will need to reassess the criteria and relevant subcriteria in light of the assembled evidence and make a judgement regarding each criterion.

---

### WICID framework version 1.0: criteria and considerations to guide evidence-informed decision-making on non-pharmacological interventions targeting COVID-19 [^44bc3471]. BMJ Global Health (2020). High credibility.

Advancing the WICID framework version 1.0 in phase III

The current version of the WICID framework version 1.0 will be expanded in a third phase. The limited diversity of expert groups established to inform policymakers on the handling of the SARS-CoV-2 pandemic has faced some criticism. Our approach of adapting the WICID framework based on strategy documents therefore comes with the risk that relevant criteria were overlooked due to the limited selection of expert groups and the stakeholder groups (not) represented within them. The third phase of the research project aims to address this issue by including the perspectives of various stakeholder groups across the society and expanding the WICID framework version 1.0 with considerations not adequately covered previously.

In phase III we will conduct a content analysis of key documents representing the opinions and perspectives of stakeholder representatives across the society (ie, of affected populations, non-governmental organisations, private sector) and using the results to validate and — where needed — expand the framework version 1.0. Using a sample of NPIs with broad societal implication as a starting point (closure/reopening of schools, closure/reopening of businesses, and 'shelter-in-place' regulations), we will include opinion pieces, position papers or press statements aimed at informing political decision-making on these measures. A first set of stakeholder group clusters (eg, social and welfare organisations) will be selected based on an initial brainstorming phase and stakeholder mappingand expanded in an iterative snowballing process. While it will not be feasible to cover all relevant organisations within a given cluster, we will analyse a heterogeneous sample which will be expanded in an iterative process based on the assessment of saturation. While this approach is not able to capture all voices of affected stakeholders, it allows for a broad and representation of societal values in decision-making across the society.

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^9755b0cb]. Journal of the American College of Cardiology (2018). Medium credibility.

ACC Appropriate Use Criteria methodology — evidentiary review and application state that a comprehensive literature review is essential and that, whenever possible, scenario adjudications should be consistent with published guidelines and Level of Evidence, with exceptions for practice changes supported by peer-reviewed literature not yet updated in CPGs or scenarios not addressed by guidelines. When randomized multicenter clinical trials are unavailable or do not match common AUC scenarios, AUC adjudications use valid observational studies or qualified retrospective analyses. Evidentiary review based on systematic analysis of peer-reviewed publications is an accepted approach that considers benefit, negative consequences, and cost, and AUC documents should refer to the Level of Evidence employed by CPGs; studies are judged on the ACC/AHA CPG Level of Evidence categories listed in Table 3, with citations and grades provided to rating panelists.

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^f0a7b7d7]. Journal of the American College of Cardiology (2018). Medium credibility.

ACC appropriate use criteria (AUC) methodology — level of expertise on rating panels — emphasizes evidence-based deliberation by panels supplied with systematic evidence and clinical practice guidelines (CPGs), prioritizes a majority of nonspecialists for diversity and credibility, and maintains a policy of < 50% representation by procedural experts to limit bias. The text specifies that members should judge benefits and risks from relevant literature, that nonexpert individuals provide an important perspective, that a majority of nonspecialists enhances credibility, that evidence tables and CPGs are provided, and that the policy of < 50% aims to reduce excessive bias.

---

### The evolution and future of ACC / AHA clinical practice guidelines: a 30-year journey: a report of the American college of cardiology / American Heart Association task force on practice guidelines [^ee22489a]. Journal of the American College of Cardiology (2014). Medium credibility.

ACC/AHA clinical practice guidelines — derivative tools for implementation — state that performance measures operationalize CPG recommendations via the ACC/AHA Task Force on Performance Measures and focus on critical recommendations carrying large benefit based on high-quality evidence to provide quantitative metrics for assessing the quality of patient care; failure to deliver this care to an eligible patient suggests a quality lapse, and these measures are used for public reporting and pay-for-performance programs, with selected measures required to be measureable, valid, reliable, and actionable; address demonstrable gaps in care; and lead to improved patient outcomes. Appropriate use criteria documents supplement recommendations by providing representative clinical scenarios for benchmarking practice patterns, address scenarios with lacking evidence, use a RAND (Research And Development) Delphi model to provide consensus judgments, construct scenarios by a committee using CPG recommendations and evaluate them by a separate technical panel, and in validation testing for coronary revascularization mapping, all Class I recommendations were appropriate and all Class III recommendations mapped to inappropriate; whereas CPG recommendations are "should" or "should not" directives, performance measures represent "must do" and appropriate use criteria "reasonable to do" clinical steps.

---

### The evolution and future of ACC / AHA clinical practice guidelines: a 30-year journey: a report of the American college of cardiology / American Heart Association task force on practice guidelines [^acd4a841]. Circulation (2014). Medium credibility.

ACC/AHA CPG derivatives — performance measures and appropriate use criteria (AUC) articulate implementation and measurement: performance measures operationalize CPG recommendations, focus on critical recommendations carrying large benefit based on high‑quality evidence to provide quantitative metrics for assessing the quality of patient care for specific cardiovascular conditions, and are increasingly used as the basis for public reporting and pay‑for‑performance programs; recommendations selected for performance measures must be measureable, valid, reliable, and actionable, address demonstrable gaps in care, and lead to improved patient outcomes, and failure to deliver this care to an eligible patient suggests a quality lapse. Appropriate use criteria documents supplement recommendations by providing representative clinical scenarios, are based on the RAND (Research And Development) Delphi model, and when mapped against CPGs for coronary revascularization, all Class I recommendations were appropriate and all Class III recommendations mapped to inappropriate. Whereas CPG recommendations are "should" or "should not" directives, performance measures represent "must do" and appropriate use criteria "reasonable to do" clinical steps.

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^fe8a6ace]. Journal of the American College of Cardiology (2018). Medium credibility.

American College of Cardiology appropriate use criteria (AUC) terminology — intent and evolution emphasize that the current AUC "should be viewed as an evaluation of the evidence base and rational use of cardiovascular technologies in patient populations, rather than as a judgment of those ordering and delivering the use of such technologies." The original categories were intended to reflect a continuum of benefit and risk but were sometimes interpreted as absolutes for individuals, and terminology was amended to "more closely reflect clinical practice applications, including an expected distribution between each AUC category for every population, methods for documenting exceptions, and proper application to individual patients."

---

### Propofol lipuro [^48db539b]. FDA (2021). Medium credibility.

Propofol-Lipuro 1% injectable emulsion for infusion made available under an EUA has not undergone the same type of review as an FDA-approved product. FDA may issue an EUA when certain criteria are met, which includes that there are no adequate, approved, available alternatives. Based on the totality of scientific evidence available, it is reasonable to believe that Propofol-Lipuro 1% injectable emulsion for infusion has met certain criteria for safety, performance, and labeling and may be effective to maintain sedation via continuous infusion in patients greater than 16 years old who require mechanical ventilation in an ICU setting.

This EUA for Propofol-Lipuro 1% injectable emulsion for infusion is in effect for the duration of the COVID-19 declaration justifying emergency use of the product, unless terminated or revoked. The EUA will end when the declaration is terminated or revoked or when there is a change in the approval status of the product such that an EUA is no longer needed.

This communication and product information is available on the B. Braun Medical Inc. website https://www.bbraunusa.com/en/company/newsroom/covid19.html# as well as the FDA webpage which includes links to patient fact sheet.

---

### Recommendations for next-generation sequencing germline variant confirmation: a joint report of the Association for Molecular Pathology and National Society of Genetic Counselors [^8bf247a3]. The Journal of Molecular Diagnostics (2023). High credibility.

NGS germline variant confirmation — laboratory-specific, data-driven criteria and optimization cautions: Analysis of existing data sets containing NGS variant calls, quality metrics, and orthogonal data is necessary to establish informative metrics and appropriate thresholds, and each laboratory should gather its own data and use them to develop its own confirmation criteria rather than using another laboratory's data or criteria; while optimization algorithms have been shown to be useful for determining combinations of quality metrics and thresholds, the authors strongly recommend against applying criteria determined by such methods to variant types, locations, or characteristics not well represented in the input data sets.

---

### CONSORT-DEFINE explanation and elaboration: recommendations for enhancing reporting quality and impact of early phase dose-finding clinical trials [^44f95af1]. EClinicalMedicine (2025). Medium credibility.

Example 1

This example is from Figure 1 a in Zhang et al. used under CC BY 4.0, cropped from original (Fig. 1 a).

Fig. 1
(a) Item 3a.2, trial design schema to show the flow of major transition points, Example 1 — obtained from Figure 1a in Zhang et al.used under CC BY 4.0, cropped from original; (b) Item 3a.2, trial design schema to show the flow of major transition points, Example 2 — obtained from Online Resource 1 in Lee et al.used under CC BY 4.0; (c) Item 3a.3, statistical methods or rationale underpinning the trial design, Example 2 — obtained from Supplementary Figure S1 in the online Supplementary Appendix of Hutchings et al.reprinted from The Lancet with permission from Elsevier.

Example 2

This example is from Online Resource 1 in Lee et al. used under CC BY 4.0 (Fig. 1 b).

Explanation

Planning dosing strategies in EPDF trials can be complex depending on the research context, adaptive trial design features, and methods considered. EPDF trials are increasingly designed to seamlessly address multiple objectives that span multiple transition points of clinical research (e.g. dose escalation to [multiple] expansion cohort(s), phase I to II, single ascending dose to multiple ascending dose). The increasing complexity of trial design and dosing strategies can be challenging for readers to comprehend.

Hence, authors are encouraged to provide a graphical representation of the overall schema of the proposed trial, when possible, to show the timing of major reviews and decision points, highlighting any overlap between study cohorts and parts to help the reader interpret the logical stages of the process (see Example 2). When a trial consists of different parts, the trial design schema should show the timing and criteria of major transition or progression points (e.g. dose escalation to expansion, dose escalation to dose optimisation (particularly as outlined in projects like the FDA Optimus project, which focuses on selected tolerable doses to ensure they are active and tolerable), phase I to phase II, single ascending dose to multiple ascending dose, stage 1 to stage 2 with a formal interim analysis for futility/activity, monotherapy to combination regimen, or exploration of an alternative administration schedule or route).

Item 3a.3 [new] Statistical methods or rationale underpinning the trial design

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^6bacfbe9]. Journal of the American College of Cardiology (2018). Medium credibility.

ACC Appropriate Use Criteria (AUC) developmental process — scope and indication construction — Central to the design of the AUC is defining the overall scope of the document to ensure that important and common indications are adequately covered without becoming unwieldy. The initial AUC documents provided ratings evaluating a single procedure in several common scenarios, but because there are often multiple imaging/procedural options, individual-modality documents are now incorporated into multimodality documents when feasible; such documents are not intended to define the single best test or assert superiority of one over another. Indication building is done by the writing group in 3 general phases: Scope (the Task Force's initial scope is reviewed and further modified with the writing group), Assumptions and definitions (the writing group begins to construct a set of relevant assumptions, including competency, definitions, and clinical setting assumptions), and Indication development (the writing group constructs the specific indications or clinical scenarios).

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^01608f84]. Journal of the American College of Cardiology (2018). Medium credibility.

American College of Cardiology appropriate use criteria (AUC) clarification of mid- and low-frequency categories explains that "Recommendations that fall into the 'May Be Appropriate' category should not be construed as having a low risk-benefit ratio," and, because evidence or applicability may be limited, "the AUC Task Force strongly recommends that individual coverage determinations not be made on the basis of a service being rated as 'May Be Appropriate'. Instead, "services in this category should be performed depending on individual clinical patient circumstances and patient and provider preferences, including shared decision making." It further notes that "'Rarely Appropriate' does not equal 'Always Inappropriate'" and that the revised term was chosen due to "substantial concern and misunderstanding about the past term 'Inappropriate'.

---

### Survival analysis part III: multivariate data analysis – choosing a model and assessing its adequacy and fit [^a8de4fae]. British Journal of Cancer (2003). Low credibility.

DISCUSSION

This paper has sought to demonstrate the models introduced in the previous paper in this series, to offer practical advice on how to select a method that represents the data fairly, and how to present and interpret it. Good modelling of survival data is not a straightforward exercise, and it is not possible to suggest an 'off the peg' solution. Before starting the process of deciding which (if any) of the models suggested is most suitable for an individual dataset, the important question of why the model should be fitted needs to be considered. The answer should inform the modelling process. Although it is possible to choose a model from those suggested that is optimal from a purely statistical point of view (e.g. goodness-of-fit measures), nonstatistical considerations should to be taken into account. The choice of model and of covariates therein should, in general, be suggested from experience and based on the specific question under investigation. However, good nonstatistical reasons informing model choice should not override good statistical reasons for not choosing that model. The diagnostics (e.g. residuals) for the different models may be difficult to interpret, but they will give an indication of whether modelling assumptions hold and, ultimately, should be considered when model building.

In some cases, all of the models mentioned above may not be wholly appropriate either for modelling the data or answering the relevant question. Consider an example where the time between treatment and possible multiple cancer relapse is to be investigated. The methods introduced assume one survival time (culminating in one type of event), but we may be dealing with patients who have one or more relapses of different type or levels. In the final paper of this series, we introduce models that extend the types of models described here to incorporate recurrent events. We also present approaches to modelling continuous covariates in a nonlinear fashion, validating models and discuss alternatives when fundamental censoring assumptions do not hold.

---

### An evidence-based clinical guideline for the diagnosis and treatment of degenerative lumbar spinal stenosis (update) [^992cc82e]. The Spine Journal (2013). Medium credibility.

Degenerative lumbar spinal stenosis — diagnostic tests and economic and decision analyses levels of evidence specify that Level I diagnostic evidence involves testing previously developed diagnostic criteria on consecutive patients with a universally applied reference gold standard and includes a systematic review of Level I studies, Level II involves development of diagnostic criteria on consecutive patients with a universally applied reference gold standard and systematic review of Level II studies, and Level III involves study of nonconsecutive patients without consistently applied reference gold standard with systematic review of Level III studies. For economic and decision analyses, Level I entails sensible costs and alternatives with values obtained from many studies and multiway sensitivity analyses with systematic review of Level I studies, Level II uses values obtained from limited studies with multiway sensitivity analyses with systematic review of Level II studies, and Level III comprises analyses based on limited alternatives and costs and poor estimates with systematic review of Level III studies.

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^c64bf4d7]. Journal of the American College of Cardiology (2018). Medium credibility.

ACC appropriate use criteria (AUC) methodology — appropriate use categories define three rating bands by median score for clinical scenarios: Appropriate Care (Median Score 7 to 9) described as an appropriate option with benefits generally outweighing risks and generally acceptable/reasonable; May Be Appropriate Care (Median Score 4 to 6) described as at times an appropriate option with variable evidence or agreement and with effectiveness for individual care determined by a patient's physician in consultation with the patient; and Rarely Appropriate Care (Median Score 1 to 3) described as rarely an appropriate option due to lack of a clear benefit/risk advantage and not generally acceptable or reasonable except with documented clinical reasons.

---

### MASCC / ISOO expert opinion on the management of oral problems in patients with advanced cancer [^816dc306]. Supportive Care in Cancer (2022). High credibility.

MASCC criteria for grading recommendations — Levels of evidence and guideline categories are specified as follows: Level I evidence is "obtained from meta-analysis of multiple, well-designed, controlled studies; randomised trials with low falsepositive and false-negative errors (high power)," Level II is "obtained from at least one well-designed experimental study; randomised trials with high false-positive and/or falsenegative errors (low power)," Level III is "obtained from well-designed, quasi-experimental studies, such as nonrandomized, controlled single-group, pretest–posttest comparison, cohort, time or matched case–control series," Level IV is "obtained from well-designed, non-experimental studies, such as comparative and correlational descriptive and case studies," and Level V is "obtained from case reports and clinical examples." Categories of guidelines are defined as Recommendation — "Reserved for guidelines that are based on Level I or Level II evidence," Suggestion — "Used for guidelines that are based on Level III, Level IV and Level V evidence; this implies panel consensus on the interpretation of this evidence," and No guideline possible — "Used when there is insufficient evidence on which to base a guideline; this implies (1) that there is little or no evidence regarding the practice in question, or (2) that the panel lacks consensus on the interpretation of existing evidence."

---

### Clinical practice guideline for the diagnosis and management of acute bacterial sinusitis in children aged 1 to 18 years [^058f24cb]. Pediatrics (2013). Medium credibility.

Guideline definitions for evidence-based statements — clinician implications: Table 1 provides categories (strong recommendation, recommendation, option, and no recommendation) with explicit practice implications. Clinicians should follow a strong recommendation unless a clear and compelling rationale for an alternative approach is present. Clinicians would be prudent to follow a recommendation, but should remain alert to new information and sensitive to patient preferences. Clinicians should consider the option in their decision-making, and patient preference may have a substantial role. Clinicians should be alert to new published evidence that clarifies the balance of benefit versus harm.

---

### ASO author reflections: pathologic complete response of extended CROSS criteria patients with esophageal cancer [^7be54de0]. Annals of Surgical Oncology (2021). Medium credibility.

Future

The effectiveness of extending the CROSS criteria for overall survival should be further investigated. Moreover, alternative personalized treatment options should be explored for the patients with a "risk-treatment paradox," who often are not represented in RCTs. The current analyses did not include all the CROSS criteria nor questionable resectable tumors. For an accurate determination of the impact from the extended CROSS criteria, clinicians should be more adequately informed about the real "irresectable" tumors and the effect of the individual extended CROSS criteria. Therefore, the authors recommend future external validation of their findings focused on prospective studies including more CROSS criteria and marginal resectable tumors.

---

### Advantages and limitations of genomics in prokaryotic taxonomy [^f7c1bf5d]. Clinical Microbiology and Infection (2013). Low credibility.

Taxonomic classification is an important field of microbiology, as it enables scientists to identify prokaryotes worldwide. Although the current classification system is still based on the one designed by Carolus Linnaeus, the currently available genomic content of several thousands of sequenced prokaryotic genomes represents a unique source of taxonomic information that should not be ignored. In addition, the development of faster, cheaper and improved sequencing methods has made genomics a tool that has a place in the workflow of a routine microbiology laboratory. Thus, genomics has reached a stage where it may be used in prokaryotic taxonomic classification, with criteria such as the genome index of average nucleotide identity being an alternative to DNA-DNA hybridization. However, several hurdles remain, including the lack of genomic sequences of many prokaryotic taxonomic representatives, and consensus procedures to describe new prokaryotic taxa that do not, as yet, accommodate genomic data. We herein review the advantages and disadvantages of using genomics in prokaryotic taxonomy.

---

### An efficient strategy for evaluating new non-invasive screening tests for colorectal cancer: the guiding principles [^7538dc14]. Gut (2023). Medium credibility.

Prescreening evaluation (phases I and II)

Phases I and II evaluations are intended to be relatively simple and demonstrate whether a test can discriminate between cases with CRC and non-neoplastic states (phase I) before proceeding to gather initial estimates of diagnostic accuracy and identify likely confounders (phase II). Comparative studies using an existing proven non-invasive test, as proposed in principle 9, can provide a strong indication of the potential of a new test and its suitability to advance to ohase III studies. Phase II studies are essential for the initial establishment of test positivity criteria that best discriminate between neoplastic and non-neoplastic states. Design strategies are shown in figure 2 (principle 9).

In phases I and II, limited-scale cohort or case-control studies in populations with and without colorectal neoplasia are conducted. Participants in phases I and II studies need not be sourced from typical screening populations and may be enriched for clinical states of interest, especially cancer. Further important design considerations are presented in online supplemental material 10.1.

Evaluation in the screening context — phase III

Phase III screening trials provide the minimum level of evidence required to justify use in large-scale screening programmes to satisfy applicable regulatory pathways, any need for health technology assessment and the goals of screening in a jurisdiction. Such studies seek to confirm the value of the new test when applied in the screening context as a one-time event (a single screening round). They must be undertaken in a typical intended-use screening population and be prospective. There is an obligation to have ensured in phase II that diagnostic accuracy is likely to be suitable for screening before offering such tests to a screening population in a research context, and the study population should be appropriately informed. Study design options are shown in figure 4.

Figure 4
Study design frameworks applicable to phase III studies. (A) Design appropriate to determine test accuracy where all cases undergo colonoscopy, but intention-to-screen outcomes cannot be ascertained (comparison of a comparator with the new test can be paired in a single cohort or parallel in separate cohorts). (B) Design appropriate for estimating intention-to-screen outcomes and where the accuracy of the new test can be compared with that of a non-invasive comparator either when colonoscoping only test-positive individuals (compare true-positive and false-positive fractions) or all participants (sensitivity and specificity). Neg, negative result; Pos, positive result.

---

### Sherloc: a comprehensive refinement of the ACMG-AMP variant classification criteria [^e2f6ed15]. Genetics in Medicine (2017). Low credibility.

Results

Our experience using the ACMG–AMP criteria was mixed. The guidelines presented a logical framework for categorizing and valuing evidence that generally matched the perspective of our clinical staff, many of whom had participated in ACMG–AMP surveys and discussions during guideline development. However, the criteria left many aspects of clinical molecular genetics undescribed and subject to personal interpretation. We routinely encountered variants that caused uncertainty about the appropriate rule usage, which led to classification inconsistencies and debate. Generally, discrepancies were due either to uncertainty about how to categorize evidence that did not fit neatly into the available rules, or subjectivity about when to count evidence as strong or moderate.

To address these questions, we set out to describe every use-case with explicit evidence criteria. When ambiguity arose, we developed more granular rules to capture the necessary complexity. For example, the ACMG–AMP guidelines contain one caveat-laden rule (PVS1) capturing premature termination codon (PTC) variants and no alternative criteria for PTC variants that fail to fulfill all of the requirements, even though a PTC that does not meet every usage note criteria can have a predictably disruptive effect on a gene product. To address this shortcoming, we established a set of variably weighted criteria for PTCs (see "Variant type and the expected consequence for gene products" below), in which the value is modulated based on the location of the stop codon relative to the pre–messenger RNA (mRNA) structure (5′ truncations that lead to nonsense-mediated decay versus 3′ PTCs that yield translated, truncated proteins) and the molecular mechanism of disease for the gene (confirmed versus unconfirmed loss-of-function (LOF) mechanism).

We recognized that the full complexity of clinical genetics was unlikely to be captured prospectively, and expected that regular iterations to Sherloc would be necessary. We therefore designed Sherloc to support refinements that could maintain backward compatibility. Over time, this approach expanded the original set of 33 ACMG–AMP criteria to the 108 criteria contained within Sherloc version 4.2. The iterative process continues and is an essential part of laboratory process quality improvement.

---

### Surgical management of cervical degenerative disease: the evidence related to indications, impact, and outcome [^fff172ed]. Journal of Neurosurgery: Spine (2009). Medium credibility.

AANS/CNS classification of evidence on prognosis and levels of recommendation defines Class I evidence and Level I recommendation when "All 5 technical criteria above are satisfied," Class II evidence and Level II recommendation when "Four of five technical criteria are satisfied," and Class III evidence and Level III recommendation as "Everything else." To evaluate prognosis studies, "five technical criteria are applied," assessing whether "a well-defined representative sample of patients" at a common point was assembled, whether "patient follow-up sufficiently long and complete," whether "objective outcome criteria" were applied in a "blinded" fashion, whether subgroup findings were adjusted for "important prognostic factors," and whether factors had "validation in an independent 'test set' group of patients." The guideline further notes that "the level of a recommendation made could be decreased, based on consensus input by the writing group, if there were methodological concerns," and states, "Additional information about the methods utilized in this systematic review can be found at https://www.cns.org/guidelines/guideline-development-methodology."

---

### Behavioral stability of alcohol consumption and socio-demographic correlates of change among a nationally representative cohort of US adults [^b4200b18]. Addiction (2023). Medium credibility.

Statistical analyses

NESARC I and II were used to estimate the average annual transition probabilities between drinking states by fitting a multi-state Markov model with a homogeneous, continuous-time process; this assumes that transitions can happen at any time along a continuous interval (e.g. not restricted to once per year), and that transition probabilities stay constant over time. Separate models were estimated for the quantity and pattern of alcohol consumption and adjusted for age and education (as reported at each time-point), as well as sex and race and ethnicity (as reported at baseline). Permissible instantaneous transitions included all adjacent states (Figure 1); this assumes that participants move through each state sequentially, rather than jumping over states (e.g. from category I instantaneously to category III, skipping category II). Transition probabilities are estimated using maximum likelihood estimation, with confidence intervals calculated by sampling from the assumed multivariate normal distribution of the maximum likelihood estimates and covariance matrix. The final model showed the best model fit, as determined by Akaike's information criteria; alternative models considered used different operationalizations for alcohol use and age (as outlined earlier) and allowed for instantaneous transitions from any drinking state directly to a 'non-drinker' (as a potential consequence of intervention programs or illness). Lastly, to account for non-response and study design, observations were replicated in accordance with their sample weight and analyses completed; the resulting confidence intervals were transformed into standard errors and corrected to the original sample size before being back-transformed into confidence intervals. The msm package (version 1.6.9) in R 4.2.0 was used for analyses; the statistical code is provided in the Supporting information file. The analysis was not pre-registered and the results should be considered exploratory.

For external validation, we used the NESARC III data (an independent source of data collected 11 years after NESARC I). The calculated annual transition probabilities, specific to each combination of the covariates (Supporting information, Supplements 1 and 2) were applied repeatedly to each individual in the NESARC I population 11 times (simulating 11 years); the socio-demographic characteristics of the group were unchanged. The predicted proportions of individuals in each drinking state from this simulated sample were compared to those observed in NESARC III.

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^b3b5738b]. Journal of the American College of Cardiology (2018). Medium credibility.

American College of Cardiology appropriate use criteria (AUC) interpretation of the "Appropriate" rating states that "the term 'Appropriate' should not be construed to suggest that all tests and procedures with this rating must be, or even should be, performed in all clinical scenarios," and "Services rated as appropriate should be considered reasonable but not necessarily required." Regarding underuse, "to date, the AUC Task Force has not pursued these methods but has instead encouraged the development of quality metrics based on AUC guidelines to identify areas of underuse."

---

### ACC / AHA / SCAI / SIR / SVM 2018 Appropriate use criteria for peripheral Artery intervention: a report of the American college of cardiology appropriate use criteria task force, American Heart Association, Society for Cardiovascular Angiography and Interventions, Society of Interventional Radiology, and Society for Vascular Medicine [^eb984c5e]. Journal of the American College of Cardiology (2019). High credibility.

Peripheral artery intervention appropriate use categories and score ranges — The rating panel "scored each indication using the following definitions and their associated numeric ranges:" with "Median Score 7 to 9: Appropriate care for specific indication (treatment is generally acceptable and is a reasonable approach for the indication)" and, as further detail, "An appropriate option for management of patients in this population due to benefits generally outweighing risks; effective option for individual care plans although not always necessary depending on physician judgment and patient-specific preferences (i.e., treatment is generally acceptable and is generally reasonable for the indication)." For "Median Score 4 to 6: May Be Appropriate care for specific indication (treatment may be generally acceptable and may be a reasonable approach for the indication)," and "May Be Appropriate also implies that more research and/or patient information is needed to classify the indication definitively." This category may be "an appropriate option for management of patients in this population due to variable evidence or lack of agreement regarding the benefits/risks ratio, potential benefit based on practice experience in the absence of evidence, and/or variability in the population," and "effectiveness for individual care must be determined by a patient's physician in consultation with the patient… along with patient preferences." For "Median Score 1 to 3: Rarely Appropriate care for specific indication (treatment is not generally acceptable and is not a reasonable approach for the indication)," and "exceptions should have documentation of the clinical reasons for proceeding with this care option." Foundationally, "An Appropriate treatment is one in which the potential benefits, in terms of survival or health outcomes (symptoms, functional status, and/or quality of life), exceed the potential negative consequences of the treatment strategy."

---

### International consensus statement on an update of the classification criteria for definite antiphospholipid syndrome (APS) [^b67314ab]. Journal of Thrombosis and Haemostasis (2006). Medium credibility.

Regarding classification and risk stratification for antiphospholipid syndrome, more specifically with respect to classification, IC-APS 2006 guidelines recommend to consider alternative diagnoses.

---

### PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews [^566bd3eb]. BMJ (2021). Excellent credibility.

Certainty assessment

Item 15. Describe any methods used to assess certainty (or confidence) in the body of evidence for an outcome

Explanation: Authors typically use some criteria to decide how certain (or confident) they are in the body of evidence for each important outcome. Common factors considered include precision of the effect estimate (or sample size), consistency of findings across studies, study design limitations and missing results (risk of bias), and how directly the studies address the question. Tools and frameworks can be used to provide a systematic, explicit approach to assessing these factors and provide a common approach and terminology for communicating certainty. For example, using the GRADE approach, authors will first apply criteria to assess each GRADE domain (imprecision, inconsistency, risk of bias, and so forth) and then make an overall judgment of whether the evidence supporting a result is of high, moderate, low, or very low certainty. Reporting the factors considered and the criteria used to assess each factor enables readers to determine which factors fed into reviewers' assessment of certainty. Reporting the process by which assessments were conducted enables readers to assess the potential for errors and facilitates replication.

---

### A structured preapproval and postapproval comparative study design framework to generate valid and transparent real-world evidence for regulatory decisions [^3bef90ff]. Clinical Pharmacology and Therapeutics (2019). Medium credibility.

Step 3: Specify requirements to validly capture design elements

In Step 3, the user specifies the minimal criteria that must be met to validly capture each design element in Table 1, rows 1−N. These criteria will become the basis for data‐source (and, if needed, primary data collection) feasibility evaluation and should be as specific as needed for another researcher or stakeholder to agree or disagree with a particular criterion and to reach the same conclusion about feasibility if applying these same criteria. For example, a study in which the research question led to specification of a study population that includes a sufficient number of older people (to fill a post–phase III knowledge gap), a criterion could be: Data source does/can include at least X people aged 65–75 and 76–85 years. However, a study in which the primary end point is measured by biopsy could include the criterion: Data source captures biopsy procedure codes and results. For some rows of Table 1, the minimal criteria listed will be absolute requirements; in other cases, the criteria might be desirable but not required. As an example, for a study with an intended long follow‐up period, 5 years of patient follow‐up might be preferred, but 3 years of follow‐up might be set as the minimum criterion for feasibility. Any criterion that is preferred but not required should be noted as such in Step 3.

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^88b4a2c5]. Journal of the American College of Cardiology (2018). Medium credibility.

ACC appropriate use criteria (AUC) methodology — 2018 update — adds inclusion of a fellow-in-training to the writing group and specifies rating panel composition to include practicing physician(s) with expertise in the clinical topic being reviewed or a closely related discipline, primary care physician(s), an expert in statistical analysis, and an expert in clinical trial design. The methodology states a focus on multiple modality documents and an emphasis on inclusive indications. Evidentiary review maps indications to guidelines and relates evidentiary grading of scientific evidence to the indications. The rating process includes clarification of number of rating cycles, use of electronic surveys to collect ratings, and live rating during in-person meetings. Relationships with industry require the rating panel meeting moderator to have no relevant relationships with industry (RWI), and cost/value implications include discussion of cost/value studies. AUC revision and focused update include inclusion of annual review and process for modification and specify the process for updates and revisions, and implementation and evaluation include inclusion of new studies and data.

---

### VA / DoD clinical practice guideline for the management of chronic insomnia disorder and obstructive sleep apnea [^f1f08f87]. VA/DoD (2025). High credibility.

Algorithm for chronic insomnia disorder and/or obstructive sleep apnea (OSA) is designed to inform providers of the recommended interventions and appropriate timing, and the interventions included in the algorithm are paired with the corresponding recommendation in the VA/DOD CPG. It includes an ordered sequence of steps of care, recommended observations and examinations, decisions to be considered, and actions to be taken. The algorithm is a step-by-step decision tree, with standardized symbols displaying each step and arrows connecting numbered boxes to indicate the order in which steps should be followed. Shape legend: rounded rectangles represent a clinical state or condition; hexagons represent a decision point in the process of care, formulated as a question that can be answered "Yes" or "No."; rectangles represent an action in the process of care; and ovals represent a link to another section within the algorithm. Sidebars 1–9 provide more detailed information to assist in defining and interpreting elements in the boxes, and Appendix L contains alternative text descriptions of the algorithms.

---

### Pragmatic randomised trials using routine electronic health records: putting them to the test [^361b6104]. BMJ (2012). Excellent credibility.

In the REACT trials no new risks are introduced, but the alternative — the current situation — has demonstrable ethical problems. Good quality evidence to improve patient care cannot be reliably generated from arbitrary treatment decisions made in usual clinical practice, and patients may continue to suffer through being exposed to interventions that are later found to be inferior. Furthermore, where there is uncertainty clinical decisions are often made without fully acknowledging their arbitrariness to patients.

The extent to which research exceptionalism will restrict the benefits of the REACT trials is not yet clear. All consent forms currently cover a great deal of information normally not provided when the same treatments are routinely given outside a randomised evaluation, and are extremely time consuming to complete. UK government guidelines presently recognise that one size will not fit all with respect to the information that is required to make autonomous decisions. However, the guidelines also state that all randomised trials must comply with the good clinical practice quality standard, and this includes a list of 22 different topics to be covered in the information sheet. Research ethics committees may further add to this barrier, often including idiosyncratic administrative requirements, such as a duty on participants to inform a private health insurer (as happened in our trials).

We have concerns over these barriers to research on routine treatments, which will reduce recruitment of clinicians and patients. Requirements for informed consent should ideally be based on empirical evidence on what kind of process best informs participants, and be designed in collaboration with patients. However, the good clinical practice quality standard, which has come to be viewed as canonical, was based on expert opinion, and has little empirical evidence. A systematic review has found that evidence for the optimal amount of information to enhance patient understanding is inconclusive and limited.UK government guidelines state that "any researcher is faced with considerable difficulty" in selecting information for informed consent, "given the disagreement on how much information potential participants in research want."There are also frank contradictions. For example, the guidelines recommend that draft versions of patient information sheets should be passed to patients in disease support groups for comments. But the same guidelines also require that all informed consent procedures in trials must adhere to current good clinical practice requirements, which mandate extensive content, so support groups are prevented from reducing information overload, for example, should they recommend this in their comments.

---

### Quality metrics for single-photon emission computed tomography myocardial perfusion imaging: an ASNC information statement [^7b281d76]. Journal of Nuclear Cardiology (2023). High credibility.

Attenuation compensation in SPECT MPI — Definition, rationale, reporting, exclusions, and benchmarks are specified. The measure is defined as "Percentage of SPECT MPI studies that use attenuation compensation in SPECT MPI." Rationale states "Nuclear cardiology labs using contemporary SPECT must have a standardized approach to interpreting fixed defects to evaluate for artifact versus scar. Labs should routinely employ attenuation compensation (attenuation correction or multiposition imaging). Labs should also have a standardized approach to interpretation of attenuation correction data in comparison to non-attenuation correction data," and "the protocol should outline if the gated image is incorporated in final interpretation." Reporting is "100 consecutive stress SPECT MPI studies performed at the site," with data sources as "Archived scans and/or imaging reports of submitted studies." Exclusions are "Studies with normal myocardial perfusion" and "Studies in which multiposition imaging is not possible, not practical, or cannot be performed (e.g., patient refused), and attenuation correction is not available." The numerator is "Number of SPECT MPI studies performed that used attenuation compensation" and the denominator is "Number of SPECT MPI studies examined not meeting an exclusion criteria." Benchmarks are "Standard of good quality: ≥ 50%" and "Standard of excellent quality: ≥ 90%."

---

### Practice parameter: diagnosis of dementia (an evidence-based review). Report of the quality standards subcommittee of the American Academy of Neurology [^462dff8f]. Neurology (2001). Medium credibility.

Evidence classification and recommendation definitions — diagnostic study evidence is categorized from Class I to Class IV, ranging from "a well designed prospective study in a broad spectrum of persons with the suspected condition, using a 'gold standard'… in a blinded evaluation" to "any design in which test is not applied in blinded evaluation OR evidence provided by expert opinion alone or in descriptive case series (without controls)." Practice recommendations are defined as Standard (principle reflecting "a high degree of clinical certainty" usually requiring Class I evidence or overwhelming Class II evidence), Guideline (recommendation reflecting "moderate clinical certainty" based on Class II or strong consensus of Class III evidence), Practice Option ("clinical utility is uncertain"), and Practice Advisory ("emerging and/or newly approved therapies or technologies" based on at least one Class I study, with possible modest effect, limited response, or cost-benefit concerns).

---

### The predictive approaches to treatment effect heterogeneity (PATH) statement [^c786969d]. Annals of Internal Medicine (2020). Medium credibility.

Heterogeneity of treatment effect (HTE) refers to the nonrandom variation in the magnitude or direction of a treatment effect across levels of a covariate, as measured on a selected scale, against a clinical outcome. In randomized controlled trials (RCTs), HTE is typically examined through a subgroup analysis that contrasts effects in groups of patients defined "1 variable at a time" (for example, male vs. female or old vs. young). The authors of this statement present guidance on an alternative approach to HTE analysis, "predictive HTE analysis". The goal of predictive HTE analysis is to provide patient-centered estimates of outcome risks with versus without the intervention, taking into account all relevant patient attributes simultaneously. The PATH (Predictive Approaches to Treatment effect Heterogeneity) Statement was developed using a multidisciplinary technical expert panel, targeted literature reviews, simulations to characterize potential problems with predictive approaches, and a deliberative process engaging the expert panel. The authors distinguish 2 categories of predictive HTE approaches: a "risk-modeling" approach, wherein a multivariable model predicts the risk for an outcome and is applied to disaggregate patients within RCTs to define risk-based variation in benefit, and an "effect-modeling" approach, wherein a model is developed on RCT data by incorporating a term for treatment assignment and interactions between treatment and baseline covariates. Both approaches can be used to predict differential absolute treatment effects, the most relevant scale for clinical decision making. The authors developed 4 sets of guidance: criteria to determine when risk-modeling approaches are likely to identify clinically important HTE, methodological aspects of risk-modeling methods, considerations for translation to clinical practice, and considerations and caveats in the use of effect-modeling approaches. The PATH Statement, together with its explanation and elaboration document, may guide future analyses and reporting of RCTs.

---

### The structured process to identify fit-for-purpose data: a data feasibility assessment framework [^e6ffb051]. Clinical Pharmacology and Therapeutics (2022). Medium credibility.

Step 3: Conduct detailed data feasibility assessment

The goal in SPIFD step 3 is to gather the necessary details for each candidate data source in order to make an informed and justifiable decision for database selection. The template (Table 2) can be used to document the candidate data sources (column headers), the specific data needed to assess each component of minimal criteria from Table 1 (rows), and the details about each data source (cells). In addition to the requirements listed in Table 1, the researcher should add rows to Table 2 to capture other important logistical information, such as time to contract execution, time to data availability, and frequency of data refreshes, and at times, cost to acquire or access the data. In some cases, these considerations will be critical (e.g. to meet an imposed regulatory deadline for submission of final results) and, in other cases, the information may be used as additional considerations when selecting among equally ranked data sources that meet the needs of the study. The SPIFD process is not intended to weigh the benefits of each data set in relation to its cost (i.e. it is not a cost‐benefit analysis). Instead, SPIFD focuses on a process to outline how well the dataset meets the needs of the study question and logistical considerations where cost (which does not need to be considered if there are no budget constraints) is only one component.

---

### Mental status examination in primary care [^70dc7024]. American Family Physician (2024). High credibility.

Regarding screening and diagnosis for mild cognitive impairment, more specifically with respect to screening tools, AAFP 2024 guidelines recommend to do not use the Addenbrooke's Cognitive Examination-III, the Mini-Addenbrooke's Cognitive Examination,
or the Mini-Cog to screen for cognitive impairment if alternative tests are available.

---

### Evidence-based medicine [^a0a55533]. The Journal of the American Academy of Orthopaedic Surgeons (2004). Low credibility.

Evidence-based medicine refers to an explicit process of using and evaluating information to make medical decisions. Evidence-based medicine, perhaps contrary to popular perception, requires its users to embrace uncertainty in medical decision making because information that is simultaneously true and complete cannot be attained. Recognizing medicine's inherent uncertainty, proponents of evidence-based medicine advocate using a five-step process for sound decision making: formulate answerable questions, gather evidence, appraise the evidence, implement the valid evidence, and evaluate the process. The formulation of answerable questions requires categorizing the facts of the case in terms that allow comparison to evidence gathered from prior studies. The appraisal of the evidence uses the tools of clinical epidemiology to assess the validity and applicability of the evidence. Implementation refers to the construction of a clinical plan based on the evidence collected as well as on the physician's judgment and patient's preferences. Finally, evidence-based medicine requires continued evaluation and refinement. The methods of evidence-based medicine are especially germane to contemporary medicine as physicians practice under increasing demands to deliver optimal outcomes yet face an ever-expanding body of medical knowledge.

---

### Global strategy for asthma management and prevention [^e928504b]. GINA (2024). High credibility.

Track 2 (alternative) for adults and adolescents using SABA reliever outlines treatment Steps 1–4 with specified controller options and a referral step, with caution about adherence. Step 1 states "Take ICS whenever SABA taken*," Step 2 is "Low dose maintenance ICS," Step 3 is "Low dose maintenance ICS-LABA," Step 4 is "Medium/high dose maintenance ICS-LABA," and Step 5 is "Refer for expert assessment, phenotyping, and add-on treatment for severe asthma"; the reliever is "as-needed ICS-SABA*, or as-needed SABA." It notes that "This is an alternative approach if Track 1 is not possible, or if a patient's asthma is stable with good adherence and no exacerbations on their current therapy," and advises "before prescribing a regimen with SABA reliever, consider whether the patient is likely to be adherent with their maintenance therapy; if not, they will be at higher risk of exacerbations." Abbreviations are defined on-page as "ICS: inhaled corticosteroid; LABA: long-acting beta agonist; SABA: short-acting beta2 agonist."

---

### Brain morphometry in former American football players: findings from the DIAGNOSE CTE research project [^a69a1d08]. Brain (2024). Medium credibility.

TES diagnosis evaluation of core clinical features and provisional levels of certainty for CTE pathology

All participants were diagnosed through a multidisciplinary diagnostic consensus conference using the NINDS Consensus Diagnostic Criteria for TES. Consensus conference panelists were presented with the participant's medical (including neurologic and psychiatric) history; football and other RHI exposure; self- and informant-reported complaints of cognitive, mood and/or behaviour problems, as well as functional dependence status; neurological/motor evaluation findings; and standardized neuropsychological and neuropsychiatric test results. Results of MRI, PET or potential fluid biomarkers were not presented. Based on this information, the panelists used the TES criteria to: (i) confirm substantial exposure to RHI; (ii) evaluate core clinical features involving cognitive impairment (yes/no), neurobehavioural dysregulation (yes/no) and evidence of progressive worsening of clinical symptoms (yes/no); (iii) ascertain whether these core clinical features could be fully accounted for by other disorders; (iv) adjudicate a diagnosis of TES (yes/no) based on information from steps i–iii; (v) grade the level of functional dependence/dementia; (vi) assess the presence of several 'supportive features'; and (vii) further determine provisional levels of certainty for CTE pathology (suggestive/possible/probable).

Cognitive impairment (yes/no) was evaluated based on four criteria: (i) self-, informant- or clinician-reported cognitive impairment; (ii) significant decline from self-reported former baseline functioning; (iii) impairments in episodic memory and/or executive functioning; and (iv) below 1.5 standard deviations from expected norms on formal neuropsychological testing. Neurobehavioural dysregulation (yes/no) was evaluated based on these criteria: (i) self-, informant- or clinician-reported neurobehavioural dysregulation; (ii) significant decline from self-reported former baseline functioning; and (iii) symptoms and/or observed behaviours representing poor regulation or control of emotions and/or behaviour. As mentioned above, TES diagnosis (yes/no) requires evidence of progressive worsening of the core clinical features that cannot be accounted for by other disorders.

---

### Strategies for communicating contraceptive effectiveness [^10fe2786]. The Cochrane Database of Systematic Reviews (2008). Low credibility.

Background

Knowledge of contraceptive effectiveness is crucial to making an informed choice. The consumer has to comprehend the pros and cons of the contraceptive methods being considered. Choice may be influenced by understanding the likelihood of pregnancy with each method and factors that influence effectiveness.

Objectives

To review all randomized controlled trials comparing strategies for communicating to consumers the effectiveness of contraceptives in preventing pregnancy.

Search Strategy

We searched the computerized databases MEDLINE, POPLINE, CENTRAL, PsycINFO, and EMBASE for studies of communicating contraceptive effectiveness. We also examined references lists of relevant articles, and wrote to known investigators for information about other published or unpublished trials.

Selection Criteria

We included randomized controlled trials that compared methods for communicating contraceptive effectiveness to consumers. The comparison could be usual practice or an alternative to the experimental intervention.

Data Collection and Analysis

Data were abstracted by two authors and entered into RevMan. For dichotomous variables, the Peto odds ratio (OR) with 95% confidence intervals (CI) was calculated. For continuous variables, the weighted mean difference (WMD) was computed.

Main Results

Five trials met the inclusion criteria. In one study, knowledge gain favored a slide-and-sound presentation versus a physician's oral presentation (WMD -19.00; 95% CI -27.52 to -10.48). Another trial showed a table with effectiveness categories led to more correct answers than one based on numbers [ORs were 2.42 (95% CI 1.43 to 4.12) and 2.19 (95% CI 1.21 to 3.97)] or a table with categories and numbers [ORs were 2.58 (95% CI 1.5 to 4.42) and 2.03 (95% CI 1.13 to 3.64)]. One trial examined contraceptive choice: women in the expanded program were more likely to choose sterilization (OR 4.26; 95% CI 2.46 to 7.37) or use a modern contraceptive method (OR 2.35; 95% CI 1.82 to 3.03). No trial had an explicit theoretical base, but each used concepts from common theories or models.

Authors' Conclusions

We have limited evidence about what works to help consumers choose an appropriate contraceptive method. For presenting pregnancy risk data, one trial showed that categories were better than numbers. In another trial, audiovisual aids worked better than the usual oral presentation. Strategies for communicating information should be examined in clinical settings and assessed for effect on contraceptive choice and retention of knowledge. To expand the knowledge base of what works in contraceptive counseling, randomized trials could intentionally use and test theories or models.

---

### Chapter 9: options for summarizing medical test performance in the absence of a "gold standard" [^4e0871e5]. Journal of General Internal Medicine (2012). Low credibility.

The classical paradigm for evaluating test performance compares the results of an index test with a reference test. When the reference test does not mirror the "truth" adequately well (e.g. is an "imperfect" reference standard), the typical ("naïve") estimates of sensitivity and specificity are biased. One has at least four options when performing a systematic review of test performance when the reference standard is "imperfect": (a) to forgo the classical paradigm and assess the index test's ability to predict patient relevant outcomes instead of test accuracy (i.e., treat the index test as a predictive instrument); (b) to assess whether the results of the two tests (index and reference) agree or disagree (i.e., treat them as two alternative measurement methods); (c) to calculate "naïve" estimates of the index test's sensitivity and specificity from each study included in the review and discuss in which direction they are biased; (d) mathematically adjust the "naïve" estimates of sensitivity and specificity of the index test to account for the imperfect reference standard. We discuss these options and illustrate some of them through examples.

---

### Can phase III trial results of antidepressant medications be generalized to clinical practice? A STAR*D report [^461293e5]. The American Journal of Psychiatry (2009). Low credibility.

Objective

Phase III clinical trials for depression enroll participants with major depressive disorder according to stringent inclusion and exclusion criteria. These patients may not be representative of typical depressed patients seeking treatment. This analysis used data from the Sequenced Treatment Alternatives to Relieve Depression (STAR*D) project — which used broad inclusion and minimal exclusion criteria — to evaluate whether phase III clinical trials recruit representative depressed outpatients.

Method

Of 2,855 participants, 22.2% met typical entry criteria for phase III clinical trials (efficacy sample) and 77.8% did not (nonefficacy sample). These groups were compared regarding baseline sociodemographic and clinical features and the characteristics and outcomes of acute-phase treatment.

Results

The efficacy sample had a shorter average duration of illness and lower rates of family history of substance abuse, prior suicide attempts, and anxious and atypical symptom features. Despite similar medication dosing and time at exit dose, the efficacy participants tolerated citalopram better. They also had higher rates of response (51.6% versus 39.1%) and remission (34.4% versus 24.7%). These differences persisted even after adjustments for baseline differences.

Conclusions

Phase III trials do not recruit representative treatment-seeking depressed patients. Broader phase III inclusion criteria would increase the generalizability of results to practice, potentially reducing placebo response and remission rates (reducing the risk of failed trials) but at the risk of some increase in adverse events.

---

### Clinical decision rules: how to use them [^62ab325a]. Archives of Disease in Childhood: Education and Practice Edition (2010). Low credibility.

The first of this pair of papers outlined what a clinical decision rule is and how one should be created. This section examines how to use a rule, by checking that it is likely to work (examining how it has been validated), understanding what the various numbers that tell us about "accuracy" mean, and considers some practical aspects of how clinicians think and work in order to make that information usable on the front lines.

---

### Labelizer: systematic selection of protein residues for covalent fluorophore labeling [^9807fb87]. Nature Communications (2025). High credibility.

Methods

Database generation

To identify parameters with predictive power for the possibility to label residues in proteins, we created a dataset based on a non-automated screening of more than 1000 publications published or preprinted, which were available on or before December 2020 with a focus on the field of single-molecule microscopy and single-molecule FRET. The papers were screened to identify proteins and residues that were labeled successfully with a fluorophore and that satisfied the following criteria: (i) the proteins had a structure available in the PDB database (with PDB identification code); (ii) the protein was labeled via site-specific mutagenesis and introduction of cysteines or UAAs; (iii) the protein was successfully labeled synthetic organic fluorophores (or spin labels) and used preferentially single-molecule assays. In order to increase the number of database entries, we complemented our search whenever some information was missing. Typical cases were missing PDB identification codes or residue numbers. In this case, the required information was obtained from other referenced papers (often) of the same research group.

For each successfully labeled protein variant, which fulfilled the aforementioned criteria, the following information was collected:
Protein (PDB identification code)
Soluble or membrane protein
Stoichiometry (monomers, dimer, complexes)
Homology model (true/false)
Labeled residue (chain and residue number)
Mutation (cysteine or UAA)
Assay type (smFRET, imaging, bulk-FRET, other)
Name of labeled fluorophores
Research group
Publication reference

Additional notes were gathered to account for issues such as: (i) dimer and polymer protein structures, which were crystallization artefacts and needed to be deleted for structural analysis; (ii) missing residues in protein structure, i.e. when parts of the protein were not resolved completely; (iii) we identified inconsistencies or missing information. The final database with information on those positions in proteins that were successfully labeled had 396 successfully labeled residues in 112 different chains in 104 different protein structures (Supplementary Data). As a comparison, we used a representative set of proteins (PDBselect, November 2017), as a random reference database to check how representative the analyzed pdb structures are. Therefore, we randomly selected 300 chains (out of 4184 chains) from the PDBselect database and performed the identical analysis with those pdb files. This important comparison shows that the selection of labeled proteins and residues is representative of the pdf content, indicated by only minor deviations between bothdistributions, mostly within statistical errors (see Supplementary Fig. 2).

---

### ACCF / AHA methodology for the development of quality measures for cardiovascular technology: a report of the American college of cardiology foundation / American Heart Association task force on performance measures [^05354354]. Journal of the American College of Cardiology (2011). Low credibility.

Consistent with the growing national focus on healthcare quality, the American College of Cardiology Foundation (ACCF) and the American Heart Association (AHA) have taken a leadership role over the past decade in developing measures of the quality of cardiovascular care by convening a joint ACCF/AHA Task Force on Performance Measures. The Task Force is charged with identifying the clinical topics appropriate for the development of performance measures and with assembling writing committees composed of clinical and methodological experts in collaboration with appropriate subspecialty societies. The Task Force has also created methodology documents that offer guidance in the development of process, outcome, composite, and efficiency measures. Cardiovascular performance measures using existing ACCF/AHA methodology are based on Class I or Class III guidelines recommendations, usually with Level A evidence. These performance measures, based on evidence-based ACCF/AHA guidelines, remain the most rigorous quality measures for both internal quality improvement and public reporting. However, many of the tools for diagnosis and treatment of cardiovascular disease involve advanced technologies, such as cardiac imaging, for which there are often no underlying guideline documents. Because these technologies affect the quality of cardiovascular care and also have the potential to contribute to cardiovascular health expenditures, there is a need for more critical assessment of the use of technology, including the development of quality and performance measures in areas in which guideline recommendations are absent. The evaluation of quality in the use of cardiovascular technologies requires consideration of multiple parameters that differ from other healthcare processes. The present document describes methodology for development of 2 new classes of quality measures in these situations, appropriate use measures and structure/safety measures. Appropriate use measures are based on specific indications, processes, or parameters of care for which high level of evidence data and Class I or Class III guideline recommendations may be lacking but are addressed in ACCF appropriate use criteria documents. Structure/safety measures represent measures developed to address structural aspects of the use of healthcare technology (e.g., laboratory accreditation, personnel training, and credentialing) or quality issues related to patient safety when there are neither guidelines recommendations nor appropriate use criteria. Although the strength of evidence for appropriate use measures and structure/safety measures may not be as strong as that for formal performance measures, they are quality measures that are otherwise rigorously developed, reviewed, tested, and approved in the same manner as ACCF/AHA performance measures. The ultimate goal of the present document is to provide direction in defining and measuring the appropriate use-avoiding not only underuse but also overuse and misuse-and proper application of cardiovascular technology and to describe how such appropriate use measures and structure/safety measures might be developed for the purposes of quality improvement and public reporting. It is anticipated that this effort will help focus the national dialogue on the use of cardiovascular technology and away from the current concerns about volume and cost alone to a more holistic emphasis on value.

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^da96c879]. Circulation (2014). Medium credibility.

Classification framework context — the document describes synthesizing benefit versus risk using class of recommendation (COR) and level of evidence (LOE), specifying COR "ranging from the highest [I] to the lowest [III]" and LOE "from the best [A] to the poorest [C]."

---

### Search strategies to identify diagnostic accuracy studies in MEDLINE and EMBASE [^99643ab6]. The Cochrane Database of Systematic Reviews (2013). Low credibility.

Background

A systematic and extensive search for as many eligible studies as possible is essential in any systematic review. When searching for diagnostic test accuracy (DTA) studies in bibliographic databases, it is recommended that terms for disease (target condition) are combined with terms for the diagnostic test (index test). Researchers have developed methodological filters to try to increase the precision of these searches. These consist of text words and database indexing terms and would be added to the target condition and index test searches. Efficiently identifying reports of DTA studies presents challenges because the methods are often not well reported in their titles and abstracts, suitable indexing terms may not be available and relevant indexing terms do not seem to be consistently assigned. A consequence of using search filters to identify records for diagnostic reviews is that relevant studies might be missed, while the number of irrelevant studies that need to be assessed may not be reduced. The current guidance for Cochrane DTA reviews recommends against the addition of a methodological search filter to target condition and index test search, as the only search approach.

Objectives

To systematically review empirical studies that report the development or evaluation, or both, of methodological search filters designed to retrieve DTA studies in MEDLINE and EMBASE.

Search Methods

We searched MEDLINE (1950 to week 1 November 2012); EMBASE (1980 to 2012 Week 48); the Cochrane Methodology Register (Issue 3, 2012); ISI Web of Science (11 January 2013); PsycINFO (13 March 2013); Library and Information Science Abstracts (LISA) (31 May 2010); and Library, Information Science & Technology Abstracts (LISTA) (13 March 2013). We undertook citation searches on Web of Science, checked the reference lists of relevant studies, and searched the Search Filters Resource website of the InterTASC Information Specialists' Sub-Group (ISSG).

Selection Criteria

Studies reporting the development or evaluation, or both, of a MEDLINE or EMBASE search filter aimed at retrieving DTA studies, which reported a measure of the filter's performance were eligible.

Data Collection and Analysis

The main outcome was a measure of filter performance, such as sensitivity or precision. We extracted data on the identification of the reference set (including the gold standard and, if used, the non-gold standard records), how the reference set was used and any limitations, the identification and combination of the search terms in the filters, internal and external validity testing, the number of filters evaluated, the date the study was conducted, the date the searches were completed, and the databases and search interfaces used. Where 2 x 2 data were available on filter performance, we used these to calculate sensitivity, specificity, precision and Number Needed to Read (NNR), and 95% confidence intervals (CIs). We compared the performance of a filter as reported by the original development study and any subsequent studies that evaluated the same filter.

Main Results

Ninteen studies were included, reporting on 57 MEDLINE filters and 13 EMBASE filters. Thirty MEDLINE and four EMBASE filters were tested in an evaluation study where the performance of one or more filters was tested against one or more gold standards. The reported outcome measures varied. Some studies reported specificity as well as sensitivity if a reference set containing non-gold standard records in addition to gold standard records was used. In some cases, the original development study did not report any performance data on the filters. Original performance from the development study was not available for 17 filters that were subsequently tested in evaluation studies. All 19 studies reported the sensitivity of the filters that they developed or evaluated, nine studies reported the specificities and 14 studies reported the precision. No filter which had original performance data from its development study, and was subsequently tested in an evaluation study, had what we defined a priori as acceptable sensitivity (> 90%) and precision (> 10%). In studies that developed MEDLINE filters that were evaluated in another study (n = 13), the sensitivity ranged from 55% to 100% (median 86%) and specificity from 73% to 98% (median 95%). Estimates of performance were lower in eight studies that evaluated the same 13 MEDLINE filters, with sensitivities ranging from 14% to 100% (median 73%) and specificities ranging from 15% to 96% (median 81%). Precision ranged from 1.1% to 40% (median 9.5%) in studies that developed MEDLINE filters and from 0.2% to 16.7% (median 4%) in studies that evaluated these filters. A similar range of specificities and precision were reported amongst the evaluation studies for MEDLINE filters without an original performance measure. Sensitivities ranged from 31% to 100% (median 71%), specificity ranged from 13% to 90% (median 55.5%) and precision from 1.0% to 11.0% (median 3.35%). For the EMBASE filters, the original sensitivities reported in two development studies ranged from 74% to 100% (median 90%) for three filters, and precision ranged from 1.2% to 17.6% (median 3.7%). Evaluation studies of these filters had sensitivities from 72% to 97% (median 86%) and precision from 1.2% to 9% (median 3.7%). The performance of EMBASE search filters in development and evaluation studies were more alike than the performance of MEDLINE filters in development and evaluation studies. None of the EMBASE filters in either type of study had a sensitivity above 90% and precision above 10%.

Authors' Conclusions

None of the current methodological filters designed to identify reports of primary DTA studies in MEDLINE or EMBASE combine sufficiently high sensitivity, required for systematic reviews, with a reasonable degree of precision. This finding supports the current recommendation in the Cochrane Handbook for Systematic Reviews of Diagnostic Test Accuracy that the combination of methodological filter search terms with terms for the index test and target condition should not be used as the only approach when conducting formal searches to inform systematic reviews of DTA.

---

### Why actionable statements are needed for measurement development [^754f78d6]. Otolaryngology — Head and Neck Surgery (2018). Low credibility.

Clinical guidelines are an avenue to improve patient outcomes based on best available clinical evidence. Actionable statements represent the foundation of a clinical guideline and form an important bridge to subsequent performance measurement efforts.

---

### Comparison of eligibility criteria between protocols, registries, and publications of cancer clinical trials [^e9102825]. Journal of the National Cancer Institute (2016). Low credibility.

Trial registration and public accessibility of appended or published protocols of phase III randomized clinical trials (RCTs) allow comparison of reported research with essential aspects of trial design. We determined how eligibility criteria of participants specified in protocols were described in trial registries and articles of 255 cancer RCTs published in leading journals. The mean proportion of matching eligibility criteria between protocols and publications per trial (the primary endpoint) was 44.0% (95% confidence interval [CI] = 40.8% to 47.3%). Almost all discrepancies in eligibility criteria (96.7%, 95% CI = 96.1% to 97.3%) suggested to readers of articles that a broader study population was included. The mean proportion of matching eligibility criteria between protocols and registries was 72.9% (95% CI = 68.2% to 77.7%, the secondary endpoint). We conclude that there are substantial differences in eligibility criteria between trial protocols, registries and articles. Inaccurate reporting of eligibility criteria may prevent appropriate assessment of the applicability of trial results.

---

### Levels of explanation in psychiatric and substance use disorders: implications for the development of an etiologically based nosology [^e9164de0]. Molecular Psychiatry (2012). Low credibility.

The soft medical model for psychiatric illness, which was operationalized in DSM-III, defines psychiatric disorders as syndromes with shared symptoms, signs, course of illness and response to treatment. Many in our field want to move to a hard medical model based on etiological mechanisms. This essay explores the feasibility of this move and asks whether psychiatric disorders have the needed single clear level of explanation for an etiologically based nosology. I propose seven criteria for a good explanation: (i) strength, (ii) causal confidence, (iii) generalizability, (iv) specificity, (v) manipulability, (vi) proximity and (vii) generativity. Applying them to cystic fibrosis, a gene-level approach to etiology performs well across the board. By contrast, a detailed review of alcohol dependence and a briefer review of major depression suggests that psychiatric disorders have multiple explanatory perspectives no one of which can be privileged over others using scientific data alone. Therefore, a move toward an etiologically based diagnostic system cannot assume that one level of explanation will stand out as the obvious candidate on which to base the nosology. This leaves two options. Either a hard medical model will be implemented that will require a consensus about a preferred level of explanation which must reflect value judgments as well as science. To take this approach, we need to agree on what we most want from our explanations. Alternatively, we will need to move away from the traditional hard medical model that requires that we ground our diagnoses in single biological essences, and focus instead on fuzzy, cross-level mechanisms, which may more realistically capture the true nature of psychiatric disorders.

---

### Effectiveness-based guidelines for the prevention of cardiovascular disease in women – 2011 update: a guideline from the American Heart Association [^fb092a1e]. Circulation (2011). Medium credibility.

Classification and levels of evidence — Table 3 defines recommendation strength and evidence levels as follows: Class I "Intervention is useful and effective"; Class IIa "Weight of evidence/opinion is in favor of usefulness/efficacy"; Class IIb "Usefulness/efficacy is less well established by evidence/opinion"; Class III includes "Procedure/test not helpful or treatment has no proven benefit" and "Procedure/test excess cost without benefit or harmful or treatment harmful to patients"; Level of evidence A "Sufficient evidence from multiple randomized trials"; B "Limited evidence from single randomized trial or other nonrandomized studies"; and C "Based on expert opinion, case studies, or standard of care".

---

### Practice parameter for the assessment and treatment of children and adolescents with autism spectrum disorder [^1f3702ac]. Journal of the American Academy of Child and Adolescent Psychiatry (2014). Medium credibility.

Regarding nonpharmacologic interventions for autism spectrum disorder, more specifically with respect to alternative and complementary therapies, AACAP 2014 guidelines recommend to inquire about the use of alternative or complementary treatments and discuss their risk and potential benefits.

---

### ESMO recommendations on clinical reporting of genomic test results for solid cancers [^bb467057]. Annals of Oncology (2024). Medium credibility.

Background

Genomic tumour profiling has a crucial role in the management of patients with solid cancers, as it helps selecting and prioritising therapeutic interventions based on prognostic and predictive biomarkers, as well as identifying markers of hereditary cancers. Harmonised approaches to interpret the results of genomic testing are needed to support physicians in their decision making, prevent inequalities in precision medicine and maximise patient benefit from available cancer management options.

Methods

The European Society for Medical Oncology (ESMO) Translational Research and Precision Medicine Working Group assembled a group of international experts to propose recommendations for preparing clinical genomic reports for solid cancers. These recommendations aim to foster best practices in integrating genomic testing within clinical settings. After review of available evidence, several rounds of surveys and focused discussions were conducted to reach consensus on the recommendation statements. Only consensus recommendations were reported. Recommendation statements were graded in two tiers based on their clinical importance: level A (required to maintain common standards in reporting) and level B (optional but necessary to achieve ideal practice).

Results

Genomics reports should present key information in a front page(s) followed by supplementary information in one or more appendices. Reports should be structured into sections: (i) patient and sample details; (ii) assay and data analysis characteristics; (iii) sample-specific assay performance and quality control; (iv) genomic alterations and their functional annotation; (v) clinical actionability assessment and matching to potential therapy indications; and (vi) summary of the main findings. Specific recommendations to prepare each of these sections are made.

Conclusions

We present a set of recommendations aimed at structuring genomics reports to enhance physician comprehension of genomic profiling results for solid cancers. Communication between ordering physicians and professionals reporting genomic data is key to minimise uncertainties and to optimise the impact of genomic tests in patient care.

---

### Drug allergy: a 2022 practice parameter update [^c25140c1]. The Journal of Allergy and Clinical Immunology (2022). High credibility.

Drug allergy — open drug challenge protocols for nonsevere delayed reactions outline 1-step or 2-step dosing with observation, an alternative multiple-day challenge or graded reintroduction, and explicit reaction criteria and cautions. The 1-step option is 1 tab or full PO with 60 min to 2 h observation; the 2-step option uses Step 1: 1/10 IV/IM/SC dose with 30 min observation followed by Step 2: full PO/IV/IM/SC dose with 60 min to 2 h observation. Positive reactions are defined as fever, urticaria, facial swelling, exanthem, hypoxia, hypotension, mouth, urogenital or eye soreness, fixed or blistering eruption, target or atypical target lesions; possible reactions include isolated joint pain, appetite change, persistent pruritus without rash; and doubtful reactions include dizziness, tachycardia, subjective lip/tongue swelling, subjective throat tightness, lump in throat, dyspnea, transient pruritus without rash, headache. The "Other" option is multiple-day challenge or graded reintroduction performed as an outpatient procedure. Footnotes state these approaches are sometimes called desensitization or induction of drug tolerance, are contraindicated for severe cutaneous adverse drug reactions or documented organ failure, that nonsevere delayed challenges may be initiated by the patient at home with telehealth follow-up when necessary, that comparably dosed oral solution may be used (1/10 or full dose), that very low-risk or more distant reactions (> 5 years) may allow single full-dose challenge, that placebo-controlled challenges or placebo lead-in can help confirm or refute delayed HSR, and that for mild exanthems a single full-dose challenge may be used.

---

### Quality and readability of online patient information regarding sclerotherapy for venous malformations [^ec660aac]. Pediatric Radiology (2018). Low credibility.

Background

Patients often use the internet as a source of information about their condition and treatments. However, this information is unregulated and varies in quality.

Objective

To evaluate the readability and quality of online information for pediatric and adult patients and caregivers regarding sclerotherapy for venous malformations.

Materials and Methods

"Venous malformation sclerotherapy" was entered into Google, and results were reviewed until 20 sites that satisfied predefined inclusion criteria were identified. Scientific and non-patient-focused web pages were excluded. Readability was assessed using the Flesch Reading Ease Score and American Medical Association reading difficulty recommendations and quality was assessed using Journal of the American Medical Association standards and assessing if the site displayed HONcode (Health on the Net Code) certification. Assessment of the breadth of relevant information was made using a predefined checklist.

Results

Forty-nine search engine results were reviewed before 20 sites were identified for analysis. Average Flesch Reading Ease Score was 44 (range: 24.2–70.1), representing a "fairly difficult" reading level. None of the sites had a Flesch Reading Ease Score meeting the American Medical Association recommendation of 80–90. Only one site met all four Journal of the American Medical Association quality criteria (average: 2.1). None of the sites displayed a HONcode seal. The information most frequently found was: sclerotherapy is performed by radiologists, multiple treatments may be needed and surgery is an alternative treatment.

Conclusion

Online information regarding sclerotherapy for venous malformations is heterogeneous in quality and breadth of information, and does not meet readability recommendations for patient information. Radiologists should be aware of and account for this when meeting patients.

---

### Evidence-based medicine in surgical decision making [^c42e8f26]. World Journal of Surgery (2005). Low credibility.

There are now five classic steps for analysis of diagnostic and therapeutic medical decision-making policies: (1) formulate a clear clinical question based on a particular patient's problem; (2) search the literature for relevant clinical articles; (3) evaluate the evidence for its validity and usefulness; (4) implement useful findings into clinical practice; (5) audit the validity of the process. The clinician must have the necessary skills to appraise critically the information retrieved. Rather than focusing on the discussion and conclusion sections of articles, the reader should concentrate on the review of the methods and results sections to formulate an opinion regarding the strength of evidence presented in the paper. The process is intellectually demanding and difficult to achieve. This particular step in the validation of evidence implies that each clinician must be methodologically and statistically sound, an "expert", capable of analyzing the method used in that particular publication to achieve the published result.

---

### Idiopathic pulmonary fibrosis (an update) and progressive pulmonary fibrosis in adults: an official ATS / ERS / JRS / ALAT clinical practice guideline [^298a30cc]. American Journal of Respiratory and Critical Care Medicine (2022). Medium credibility.

Background: This American Thoracic Society, European Respiratory Society, Japanese Respiratory Society, and Asociación Latinoamericana de Tórax guideline updates prior idiopathic pulmonary fibrosis (IPF) guidelines and addresses the progression of pulmonary fibrosis in patients with interstitial lung diseases (ILDs) other than IPF. Methods: A committee was composed of multidisciplinary experts in ILD, methodologists, and patient representatives. 1) Update of IPF: Radiological and histopathological criteria for IPF were updated by consensus. Questions about transbronchial lung cryobiopsy, genomic classifier testing, antacid medication, and antireflux surgery were informed by systematic reviews and answered with evidence-based recommendations using the Grading of Recommendations, Assessment, Development and Evaluation (GRADE) approach. 2) Progressive pulmonary fibrosis (PPF): PPF was defined, and then radiological and physiological criteria for PPF were determined by consensus. Questions about pirfenidone and nintedanib were informed by systematic reviews and answered with evidence-based recommendations using the GRADE approach. Results: 1) Update of IPF: A conditional recommendation was made to regard transbronchial lung cryobiopsy as an acceptable alternative to surgical lung biopsy in centers with appropriate expertise. No recommendation was made for or against genomic classifier testing. Conditional recommendations were made against antacid medication and antireflux surgery for the treatment of IPF. 2) PPF: PPF was defined as at least two of three criteria (worsening symptoms, radiological progression, and physiological progression) occurring within the past year with no alternative explanation in a patient with an ILD other than IPF. A conditional recommendation was made for nintedanib, and additional research into pirfenidone was recommended. Conclusions: The conditional recommendations in this guideline are intended to provide the basis for rational, informed decisions by clinicians.

---

### Radiation therapy for endometrial cancer: an American Society for Radiation Oncology clinical practice guideline [^873f9836]. Practical Radiation Oncology (2022). High credibility.

ASTRO recommendation grading classification system — the strength categories and quality of evidence (QoE) levels are defined with linked evidence interpretations. Strong is used when "Benefits clearly outweigh risks and burden, or risks and burden clearly outweigh benefits" and when "All or almost all informed people would make the recommended choice." Conditional applies when "Benefits are finely balanced with risks and burden, or appreciable uncertainty exists about the magnitude of benefits and risks," when "Most informed people would choose the recommended course of action, but a substantial number would not," and when "A shared decision-making approach regarding patient values and preferences is particularly important." QoE levels are: High ("2 or more well-conducted and highly generalizable RCTs or meta-analyses of such trials") with interpretation that "The true effect is very likely to be close to the estimate of the effect based on the body of evidence"; Moderate (criteria include "1 well-conducted and highly generalizable RCT or a meta-analysis of such trials OR 2 or more RCTs with some weaknesses of procedure or generalizability OR 2 or more strong observational studies with consistent findings") with interpretation that "The true effect is likely to be close to the estimate of the effect based on the body of evidence, but it is possible that it is substantially different"; Low (criteria include "1 RCT with some weaknesses of procedure or generalizability OR 1 or more RCTs with serious deficiencies of procedure or generalizability or extremely small sample sizes OR 2 or more observational studies with inconsistent findings, small sample sizes, or other problems that potentially confound interpretation of data") with interpretation that "The true effect may be substantially different from the estimate of the effect. There is a risk that future research may significantly alter the estimate of the effect size or the interpretation of the results"; and Expert opinion ("Consensus of the panel based on clinical judgment and experience, due to absence of evidence or limitations in evidence") with guidance that "Strong consensus (≥ 90%) of the panel guides the recommendation despite insufficient evidence to discern the true magnitude and direction of the net effect."

---

### Consensus statements: when and how? [^324599cf]. The Bone & Joint Journal (2023). Medium credibility.

The Bone &amp; Joint Journal has published several consensus statements in recent years, many of which have positively influenced clinical practice and policy. 1–13 However, even the most valued consensus statements have limitations, and all ultimately represent Level V evidence. Consensus studies add greatest value where higher-order evidence to aid decision making is ambiguous or lacking. In all settings, care must be taken to critically appraise standards of methodology, with particular attention to potential biases that may influence the conclusions which are drawn.

---

### The PRISMA statement for reporting systematic reviews and meta-analyses of studies that evaluate healthcare interventions: explanation and elaboration [^f53f7495]. BMJ (2009). Excellent credibility.

Item 9: Study selection

State the process for selecting studies (that is, for screening, for determining eligibility, for inclusion in the systematic review, and, if applicable, for inclusion in the meta-analysis).

Example "Eligibility assessment… [was] performed independently in an unblinded standardized manner by 2 reviewers… Disagreements between reviewers were resolved by consensus."

Explanation There is no standard process for selecting studies to include in a systematic review. Authors usually start with a large number of identified records from their search and sequentially exclude records according to eligibility criteria. We advise authors to report how they screened the retrieved records (typically a title and abstract), how often it was necessary to review the full text publication, and if any types of record (such as letters to the editor) were excluded. We also advise using the PRISMA flow diagram to summarise study selection processes (see item 17 and box 3).

Efforts to enhance objectivity and avoid mistakes in study selection are important. Thus authors should report whether each stage was carried out by one or several people, who these people were, and, whenever multiple independent investigators performed the selection, what the process was for resolving disagreements. The use of at least two investigators may reduce the possibility of rejecting relevant reports. The benefit may be greatest for topics where selection or rejection of an article requires difficult judgments. For these topics, authors should ideally tell readers the level of inter-rater agreement, how commonly arbitration about selection was required, and what efforts were made to resolve disagreements (such as by contact with the authors of the original studies).

---

### A data-driven algorithm to determineH-MRS basis set composition [^ee922c78]. Magnetic Resonance in Medicine (2026). Medium credibility.

Purpose

Metabolite amplitude estimates derived from linear combination modeling of MR spectra depend on the precise list of constituent metabolite basis functions used (the "basis set"). The absence of clear consensus on the "ideal" composition or objective criteria to determine the suitability of a particular basis set contributes to the poor reproducibility of MRS. In this proof-of-concept study, we demonstrate a novel, data-driven approach for deciding the basis-set composition using Akaike information criteria (AIC).

Methods

We have developed an algorithm that iteratively adds metabolites to the basis set using iterative modeling, informed by AIC scores. We investigated two quantitative "stopping conditions", referred to as max-AIC and zero-amplitude, and whether to optimize the selection of basis set on a per-spectrum basis or at the group level. The algorithm was tested using two groups of synthetic in vivo-like spectra representing healthy brain and tumor spectra, respectively, and the derived basis sets (and metabolite amplitude estimates) were compared to the ground truth.

Results

All derived basis sets correctly identified high-concentration metabolites and provided reasonable fits of the spectra. At the single-spectrum level, the two stopping conditions derived the underlying basis set with 84% to 88% accuracy. When optimizing across a group, basis set determination accuracy improved to 89% to 92%.

Conclusion

Data-driven determination of the basis set composition is feasible. With refinement, this approach could provide a valuable data-driven way to derive or refine basis sets, reducing the operator bias of MRS analyses, enhancing the objectivity of quantitative analyses, and increasing the clinical viability of MRS.

---

### Short versus long drug regimens for Chagas disease [^b00f8d63]. The Cochrane Database of Systematic Reviews (2025). Medium credibility.

We will report these data in the characteristics of the included studies table and summarize them in Table 1.

1
Table 1: Overview of included studies and synthesis table

We will contact the authors of the included studies to clarify questions about their studies and document all communications. If additional information is needed, we will reach out to the primary authors.

In cases of duplicate publications, companion documents, or multiple reports of a primary study, we will combine all available data to use the most complete dataset across publications. Duplicate publications, companion documents, and trial documents will be listed as secondary references under the relevant study ID. This applies to both included and excluded studies.

If data from included studies are available in clinical trial registers, such as ClinicalTrials.gov, we will fully utilize this information. If discrepancies are found between published and registry data, we will seek clarification from study authors; unresolved discrepancies will be noted in the review report. Studies labeled as 'completed' in trial registers without further information (study results, publication, or both) will be added to the studies awaiting classification.

Risk of bias assessment in included studies

In this risk of bias assessment plan, two authors (SDM and LBV) will independently evaluate the risk of bias in outcomes included in the summary of findings table (see Certainty of the evidence assessment) using the Cochrane RoB 2 tool. We will resolve disagreements through consensus or consultation with a third author (LG). When relevant data are missing from publications, trial protocols, or clinical study reports, we will contact study authors for additional information on risk of bias items.

The assessment will cover the following domains, focusing on the initial effect of assignment to interventions: the randomization process, deviations from intended interventions, missing outcome data, outcome measurement, and selection of the reported results.

We will use the answers to the signaling questions and supporting information to make a collective domain‐level judgment of low risk, some concerns, or high risk of bias. An overall risk of bias for each outcome will be assigned based on these domain‐level judgments. The criteria are as follows.

---

### Diagnosis of cystic fibrosis: consensus guidelines from the Cystic Fibrosis Foundation [^c2c6b746]. The Journal of Pediatrics (2017). Medium credibility.

Nonscreened individuals with suspected cystic fibrosis — individuals presenting with CF symptoms should use the same diagnostic criteria recommended for the screened population for sweat chloride testing, CFTR genetic analysis, and CFTR functional testing to confirm a CF diagnosis; diagnosis of CF in the nonscreened population still occurs, the diagnostic algorithm remains applicable, and the pretest probability of CF will influence the interpretation of sweat chloride testing, CFTR genetic analysis, or CF physiologic testing.

---

### Large language model agents can use tools to perform clinical calculations [^24cd2b1a]. NPJ Digital Medicine (2025). Medium credibility.

Classification of errors

After initial trials were complete, one of the three physician authors (AG, SC, LC) inspected the correct and incorrect answers. From these, we formulated a framework for the chain of reasoning required to provide appropriate answers, as well as the various possible missteps within this chain (Fig. 3). When the model offered incorrect solutions, raw output was inspected for these errors in reasoning. Error classification occurred from Nov 14 to Dec 10, 2023 and required an estimated combined 30 h between annotators. Errors were categorized into one or more of the categories: (1) Interpretation Error: Inadequate understanding or misinterpretation of the medical information presented in the question leads to ignored criteria that was met, or inclusion of a criteria that was not met. (2) Incorrect Criteria: Criteria are missing or there is a hallucination of non-existent criteria. (3) Assignment Error: Improper application of correctly-identified criteria. Appropriate criteria were selected but an incorrect score is assigned. (4) Incorrect Formula: An incorrect equation is chosen to represent the scoring mechanism of the calculation task. (5) Calculation Error: The correct formula is chosen, such as taking the sum of all subscores, but the actual mathematical computation carried out was incorrect. (6) Incorrect Reporting: The correct score is calculated, but some component of reporting that score to the user is inaccurate. (7) Indeterminate: Inadequate response information to be able to determine error. (8) No valid response: If the model produced no response that answered the prompt.

Development and evaluation of augmented models

After completion of the exploratory phase, we evaluated the impact of popular LLM augmentation strategies for the task of clinical calculation by building an LLM environment with roughly the same functionality as ChatGPT and evaluating it against the most challenging tasks from the prior analysis. To better understand the contribution of each augmentation strategy, we evaluated the impact of three different components: a code interpreter tool, a retrieval-augmented generation (RAG) system, and a set of task-specific calculation tools (OpenMedCalc toolkit) with two LLMs. The following sections describe this process.

Calculator selection

For the focused analysis, we identified the ten calculation tasks from the exploratory analysis with the lowest performance, while trying to capture a diversity of tasks and organ systems. Tasks with multiple correct answers (ie, steroid conversion) were excluded. Figure 2 d shows the ten calculators chosen.

---

### Summary benchmarks-full set – 2024 [^76ffec10]. AAO (2024). High credibility.

Preferred Practice Pattern (PPP) guidelines — scope and principles emphasize that Preferred Practice Patterns provide guidance for the pattern of practice, not for the care of a particular individual, and that the Preferred Practice Pattern guidelines are not medical standards to be adhered to in all individual situations. The series is based on three principles: each Preferred Practice Pattern should be clinically relevant and specific enough to provide useful information to practitioners; each recommendation that is made should be given an explicit rating that shows its importance to the care process; and each recommendation should also be given an explicit rating that shows the strength of evidence that supports the recommendation and reflects the best evidence available. Adherence to these Preferred Practice Patterns will not ensure a successful outcome in every situation, and these practice patterns should not be deemed inclusive of all proper methods of care or exclusive of other methods of care reasonably directed at obtaining the best results.

---

### Designing phase II trials in cancer: a systematic review and guidance [^a40f9c1e]. British Journal of Cancer (2011). Low credibility.

Materials and methods

A systematic literature review was conducted to identify literature detailing phase II trial designs currently available.

Literature search

Data were identified by searches of MEDLINE, EMBASE, Current Index to Statistics and Science Citation Index indexed by Web of Science. The search strategy implemented for the MEDLINE database is detailed in Figure 2. Search strategies were developed for each database because of the differing format and searching processes for each database. As the intention of the systematic literature review was to be thorough but not exhaustive, a further review of abstracts and reports from meetings, and hand searching of key journals, was not incorporated. The databases were searched for material published on each database till 9/10 February 2008. Additional papers were subsequently identified via MEDLINE auto-alert up to January 2010 and incorporated into the library of designs.

Eligibility criteria

Each record identified via the search strategy was assessed for suitability. Full articles of all potentially useful publications were obtained. Articles that could not be identified on-line or through the University of Leeds library were classed as unobtainable. A random selection of 20 citations that were not selected for full-text review was independently reviewed by two other members of the research team to confirm their exclusion.

Papers specifically discussing the advantages and disadvantages of previously published designs, that is, not outlining new or adapted designs, were separated as discussion papers. Papers were included which referred to statistical methodology for phase IIa and IIb studies, and phase II/III trials and/or which discussed the issues surrounding randomisation in phase II studies. Papers were excluded which referred to statistical methodology for the design and analysis of feasibility or pilot studies, or phase I, III and IV studies, if the methodology described was applicable only to disease areas other than cancer, if the statistical methodology was described for the analysis of phase II trials only (as opposed to design) or if the paper discussed a randomisation method only. Any papers that were not relevant to the review, for example, phase II trial results only, were also excluded, as were conference abstracts with no further information available.

---

### PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews [^f3c9beb5]. BMJ (2021). Excellent credibility.

Box 3
Study selection methods

Several approaches to selecting studies exist. Here we comment on the advantages and disadvantages of each.

Assessment of each record by one reviewer — Single screening is an efficient use of time and resources, but there is a higher risk of missing relevant studies
Assessment of records by more than one reviewer — Double screening can vary from duplicate checking of all records (by two or more reviewers independently) to a second reviewer checking a sample only (for example, a random sample of screened records, or all excluded records). This approach may be more reliable than single screening but at the expense of increased reviewer time, given the time needed to resolve discrepancies
Priority screening to focus early screening effort on most relevant records — Instead of screening records in year, title, author or random order, machine learning is used to identify relevant studies earlier in the screening process than would otherwise be the case. Priority screening is an iterative process in which the machine continually reassesses unscreened records for relevance. This approach can increase review efficiency by enabling the review team to start on subsequent steps of the review while less relevant records are still being screened. Both single and multiple reviewer assessments can be combined with priority screening
Priority screening with the automatic elimination of less relevant records — Once the most relevant records have been identified using priority screening, teams may choose to stop screening based on the assumption that the remaining records are unlikely to be relevant. However, there is a risk of erroneously excluding relevant studies because of uncertainty about when it is safe to stop screening; the balance between efficiency gains and risk tolerance will be review-specific
Machine learning classifiers — Machine learning classifiers are statistical models that use training data to rank records according to their relevance. They can be calibrated to achieve a given level of recall, thus enabling reviewers to implement screening rules, such as eliminating records or replacing double with single screening. Because the performance of classifiers is highly dependent on the data used to build them, classifiers should only be used to classify records for which they are designed
Previous "known" assessments — Screening decisions for records that have already been manually checked can be reused to exclude the same records from being reassessed, provided the eligibility criteria are the same. For example, groups that maintain registers of controlled trials to facilitate systematic reviews can avoid continually rescreening the same records by matching and then including/excluding those records from further consideration.
Crowdsourcing — Crowdsourcing involves recruiting (usually via the internet) a large group of individuals to contribute to a task or project, such as screening records. If crowdsourcing is integrated with other study selection approaches, the specific platforms used should have well established and documented agreement algorithms, and data on crowd accuracy and reliability

---

### Search strategies (filters) to identify systematic reviews in MEDLINE and embase [^981f735c]. The Cochrane Database of Systematic Reviews (2023). Medium credibility.

Background

Bibliographic databases provide access to an international body of scientific literature in health and medical sciences. Systematic reviews are an important source of evidence for clinicians, researchers, consumers, and policymakers as they address a specific health-related question and use explicit methods to identify, appraise and synthesize evidence from which conclusions can be drawn and decisions made. Methodological search filters help database end-users search the literature effectively with different levels of sensitivity and specificity. These filters have been developed for various study designs and have been found to be particularly useful for intervention studies. Other filters have been developed for finding systematic reviews. Considering the variety and number of available search filters for systematic reviews, there is a need for a review of them in order to provide evidence about their retrieval properties at the time they were developed.

Objectives

To review systematically empirical studies that report the development, evaluation, or comparison of search filters to retrieve reports of systematic reviews in MEDLINE and Embase.

Search Methods

We searched the following databases from inception to January 2023: MEDLINE, Embase, PsycINFO; Library, Information Science & Technology Abstracts (LISTA) and Science Citation Index (Web of Science).

Selection Criteria

We included studies if one of their primary objectives is the development, evaluation, or comparison of a search filter that could be used to retrieve systematic reviews on MEDLINE, Embase, or both.

Data Collection and Analysis

Two review authors independently extracted data using a pre-specified and piloted data extraction form using InterTASC Information Specialist Subgroup (ISSG) Search Filter Evaluation Checklist.

Main Results

We identified eight studies that developed filters for MEDLINE and three studies that developed filters for Embase. Most studies are very old and some were limited to systematic reviews in specific clinical areas. Six included studies reported the sensitivity of their developed filter. Seven studies reported precision and six studies reported specificity. Only one study reported the number needed to read and positive predictive value. None of the filters were designed to differentiate systematic reviews on the basis of their methodological quality. For MEDLINE, all filters showed similar sensitivity and precision, and one filter showed higher levels of specificity. For Embase, filters showed variable sensitivity and precision, with limited study reports that may affect accuracy assessments. The report of these studies had some limitations, and the assessments of their accuracy may suffer from indirectness, considering that they were mostly developed before the release of the PRISMA 2009 statement or due to their limited scope in the selection of systematic review topics. Search filters for MEDLINE Three studies produced filters with sensitivity > 90% with variable degrees of precision, and only one of them was developed and validated in a gold-standard database, which allowed the calculation of specificity. The other two search filters had lower levels of sensitivity. One of these produced a filter with higher levels of specificity (> 90%). All filters showed similar sensitivity and precision in the external validation, except for one which was not externally validated and another one which was conceptually derived and only externally validated. Search filters for Embase We identified three studies that developed filters for this database. One of these studies developed filters with variable sensitivity and precision, including highly sensitive strategies (> 90%); however, it was not externally validated. The other study produced a filter with a lower sensitivity (72.7%) but high specificity (99.1%) with a similar performance in the external validation.

Authors' Conclusions

Studies reporting the development, evaluation, or comparison of search filters to retrieve reports of systematic reviews in MEDLINE showed similar sensitivity and precision, with one filter showing higher levels of specificity. For Embase, filters showed variable sensitivity and precision, with limited information about how the filter was produced, which leaves us uncertain about their performance assessments. Newer filters had limitations in their methods or scope, including very focused subject topics for their gold standards, limiting their applicability across other topics. Our findings highlight that consensus guidance on the conduct of search filters and standardized reporting of search filters are needed, as we found highly heterogeneous development methods, accuracy assessments and outcome selection. New strategies adaptable across interfaces could enhance their usability. Moreover, the performance of existing filters needs to be evaluated in light of the impact of reporting guidelines, including the PRISMA 2009, on how systematic reviews are reported. Finally, future filter developments should also consider comparing the filters against a common reference set to establish comparative performance and assess the quality of systematic reviews retrieved by strategies.

---

### Clinical evaluation of sepsis-1 and sepsis-3 in the ICU [^b7d6d900]. Chest (2018). Low credibility.

Background

There has been considerable controversy between sepsis-1 and sepsis-3 criteria.

Methods

Patients with infection meeting two or more systemic inflammatory response syndrome (SIRS) criteria (sepsis-1) or a Sequential Organ Failure Assessment (SOFA) score ≥ 2 (sepsis-3) on the first day after ICU admission were selected from the Medical Information Mart for Intensive Care-III database, and their outcomes were compared using all-cause death as the end point. Subgroup analysis was also performed based on prior chronic organ dysfunction.

Results

There were 21,491 infected patients included. Of those meeting the diagnostic criteria for sepsis-1, 13.42% did not satisfy sepsis-3 criteria, and this population had a 21-day mortality rate of 6.96%. In contrast, 7.00% of the patients meeting sepsis-3 criteria did not meet sepsis-1 criteria, and their 21-day mortality rate was 10.76%. When excluding preexisting organ conditions, 18.41% of patients with sepsis-1 did not meet sepsis-3 criteria, with a 21-day mortality rate of 6.39%, and 6.00% of patients with sepsis-3 did not meet sepsis-1 criteria, with a 21-day mortality rate of 9.11%. When two or more SIRS criteria or SOFA score ≥ 2 were applied to predict 21-day all-cause mortality in infected patients without prior chronic organ dysfunction, the sensitivity was 96.0% or 91.0%, respectively. Although the areas under the receiver operator curve of both SOFA and SIRS criteria could be used for predicting mortality, SOFA score represented the severity of the condition, whereas SIRS score represented a clinically evident host response to infection.

Conclusions

Sepsis-3 diagnostic criteria narrow the sepsis population at the expense of sensitivity, and the resulting false negatives may delay disease diagnosis. It may be inappropriate to compare the prediction performance of SIRS and SOFA criteria when sepsis-3 is defined.

---

### 2024 ACC expert consensus decision pathway for treatment of heart Failure with reduced ejection Fraction: a report of the American college of cardiology solution set oversight committee [^d8fdb826]. Journal of the American College of Cardiology (2024). High credibility.

Table 13 — Prior authorization for heart failure therapies: For patients with heart failure with reduced ejection fraction (HFrEF) or heart failure with preserved ejection fraction (HFpEF), include the HF phenotype, identify New York Heart Association (NYHA) functional class, include recent measurement of left ventricular ejection fraction (LVEF) with source documentation if requested, identify the treatment requested or additional testing required with indications supported by evidence and/or guideline statements where applicable noting that clinical judgment, especially for testing requests, is an appropriate rationale, address previous therapies used and the rationale for switching to or adding the requested treatment, address known contraindications to use, adverse effects, and steps intended to minimize the risks of drugs or procedures, document when appropriate that delays or interruptions in therapy may cause harm to the patient, and work with local pharmacy resources and pharmacy professionals to jointly address prior authorization requirements; do not hesitate to appeal decisions that are contrary to the best patient care, provide evidence-based literature when available as supporting documentation, and document all steps taken in the patient's health record, noting that required information may vary depending on payer and state.

---

### Delivery of optimized anticoagulant therapy: consensus statement from the anticoagulation forum [^1aeffede]. The Annals of Pharmacotherapy (2008). Low credibility.

Objective

To provide recommendations, policies, and procedures pertaining to the provision of optimized anticoagulation therapy designed to achieve desired clinical endpoints while minimizing the risk of anticoagulant-related adverse outcomes (principally bleeding and thrombosis).

Study Selection and Data Extraction

Due to this document's scope, the medical literature was searched using a variety of strategies. When possible, recommendations are supported by available evidence; however, because this paper deals with processes and systems of care, high-quality evidence (eg, controlled trials) is unavailable. In these cases, recommendations represent the consensus opinion of all authors who constitute the Board of Directors of The Anticoagulation Forum, an organization dedicated to optimizing anticoagulation care. The Board is composed of physicians, pharmacists, and nurses with demonstrated expertise and significant collective experience in the management of patients receiving anticoagulation therapy.

Data Synthesis

Recommendations for delivering optimized anticoagulation therapy were developed collaboratively by the authors and are summarized in 9 key areas: (I) Qualifications of Personnel, (II) Supervision, (III) Care Management and Coordination, (IV) Documentation, (V) Patient Education, (VI) Patient Selection and Assessment, (VII) Laboratory Monitoring, (VIII) Initiation and Stabilization of Warfarin Therapy, and (IX) Maintenance of Therapy. Recommendations are intended to inform the development of care systems containing elements with demonstrated benefit in improvement of anticoagulation therapy outcomes. Recommendations for delivering optimized anticoagulation therapy are intended to apply to all clinicians involved in the care of outpatients receiving anticoagulation therapy, regardless of the structure and setting in which that care is delivered.

Conclusions

Anticoagulation therapy, although potentially life-saving, has inherent risks. Whether a patient is managed in a solo practice or a specialized anticoagulation management service, a systematic approach to the key elements outlined herein will reduce the likelihood of adverse events. The need for continued research to validate optimal practices for managing anticoagulation therapy is acknowledged.

---

### Joint EANM / SNMMI guideline on radiomics in nuclear medicine: jointly supported by the EANM physics committee and the SNMMI physics, instrumentation and data sciences council [^18e8cef2]. European Journal of Nuclear Medicine and Molecular Imaging (2023). High credibility.

Table 1 — Radiomics analysis steps in nuclear medicine outlines key methodological practices across the pipeline. For study design, properly define the clinical context, endpoint, reasonable dataset size, and selection criteria and the process to collect and curate images and associated clinical information. For data collection and curation, double check data quality and integrity, record all acquisition and reconstruction parameters for all patients, and plan appropriate management of heterogeneity. For image pre-processing, if processing beyond standard reconstruction is applied, report results with and without these additional steps to evaluate the actual benefit on the resulting models. For detection and segmentation, ensure the chosen volume of interest is determined as accurate, robust, and reproducible as possible and avoid fixed thresholding methods. For feature calculation, follow IBSI recommendations, use software that follows IBSI standards, adhere to IBSI implementation, parametrization, and reporting, and justify how features are chosen and implemented. For modeling, avoid information leakage, divide the available data into training/validation and testing sets, justify the chosen modeling schemes, investigate and report performance, calibration, and explainability, and evaluate the potential impact on patient management. For evaluation, end-to-end evaluation is required using internal hold-out or independent datasets, with multicentric validation beneficial for robustness and generalizability.

---

### Improved autoregressive model for correction of noise serial correlation in fast fMRI [^b50e9c6c]. Magnetic Resonance in Medicine (2020). Medium credibility.

2 METHODS

A detailed description of the MRI data acquisition and Image preprocessing including citations to references 22, 23, 24, 25, 26, 27 are included in the supplementary material.

2.1 Data analysis

The SC effect was corrected using the prewhitening method based on the fixed AR(p) 18 and AR AICc models. The theory regarding the prewhitening method based on these two models is described in Supporting Information. Briefly, the AR AICc improves the fixed AR(p) model on two aspects: (1) In the fixed AR(p), the user is required to preselect a constant p which applies to all the voxels, while the AR AICc algorithm automatically determines the optimal voxel‐wise model orders with the AICc; (2) The cutoff lag (L) for the noise autocorrelation estimation = p in the fixed AR(p). In the AR AICc, L depends on the TR used for image acquisition: L = int (T cutoff /TR) where T cutoff = 10 s and int rounds a number to its nearest integer. Since the partial ACF (pACF) 28 and the Bayesian Information Criterion (BIC) 29 are also two common order selection critera used in previous studies on SC correction, 10, 17 the AR AICc algorithm also offers the options to use pACF or BIC for the order selection.

---

### Further evolution of the ACC / AHA clinical practice guideline recommendation classification system: a report of the American college of cardiology / American Heart Association task force on clinical practice guidelines [^d4656905]. Journal of the American College of Cardiology (2016). Medium credibility.

ACC/AHA recommendation system — Class of Recommendation (COR) provides standardized wording and benefit–risk framing. Class I (STRONG) indicates Benefit > > > Risk with suggested phrases including "is recommended," "is indicated/useful/effective/beneficial," "Should be performed/administered/other," and comparative options "Treatment/strategy A is recommended/indicated in preference to treatment B" or "Treatment A should be chosen over treatment B." Class IIa (MODERATE) indicates Benefit > > Risk with "is reasonable" and "can be useful/effective/beneficial," plus "Treatment/strategy A is probably recommended/indicated in preference to treatment B" or "It is reasonable to choose treatment A over treatment B." Class IIb (WEAK) notes Benefit ≥ Risk and uses "May/might be reasonable," "May/might be considered," and "Usefulness/effectiveness is unknown/unclear/uncertain or not well established." Class III: No Benefit (MODERATE) lists Benefit = Risk with "(Generally, LOE A or B use only)" and phrases "Is not recommended," "Is not indicated/useful/effective/beneficial," and "Should not be performed/administered/other." Class III: Harm (STRONG) specifies Risk > Benefit with "Potentially harmful," "Causes harm," "Associated with excess morbidity/mortality," and "Should not be performed/administered/other."

---

### Occult primary, version 3.2014 [^a13871fd]. Journal of the National Comprehensive Cancer Network (2014). Medium credibility.

NCCN Occult Primary — categories of evidence and consensus and categories of preference are defined to qualify recommendation strength: Category 1 is based upon high-level evidence (≥ 1 randomized phase 3 trials or high-quality, robust meta-analyses) with uniform NCCN consensus (≥ 85% support of the Panel) that the intervention is appropriate; Category 2A is based upon lower-level evidence with uniform NCCN consensus (≥ 85% support of the Panel); Category 2B is based upon lower-level evidence with NCCN consensus (≥ 50%, but < 85% support of the Panel); and Category 3 is based upon any level of evidence with major NCCN disagreement that the intervention is appropriate. All recommendations are category 2A unless otherwise indicated. Preference definitions are: Preferred intervention denotes interventions that are based on superior efficacy, safety, and evidence; and, when appropriate, affordability; Other recommended intervention includes other interventions that may be somewhat less efficacious, more toxic, or based on less mature data; or significantly less affordable for similar outcomes; and Useful in certain circumstances includes other interventions that may be used for selected patient populations (defined with recommendation). All recommendations are considered appropriate.

---