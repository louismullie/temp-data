# Medical Question & Answer

**Sample ID**: df70612f-e1ed-cd83-7321-35e0c4ad6832
**Dataset Index**: 210266

---

## Question

16. If a > 0, b > 0, then
min{max{a, b, [1/a²] + [1/b²]}} = 

---

## Answer

> Let's see… What do we have here? The user is asking to find the minimum value of the expression (max{a, b, [1/a²] + [1/b²]}) for (a > 0) and (b > 0). Let's break this down step-by-step. First, I need to think about symmetry and whether the minimum occurs when (a = b). Then, I should verify the behavior of the function and check for critical points. Next, I will solve the resulting equation to find the candidate value. Finally, I need to confirm that this candidate is indeed the global minimum by checking boundary behavior and second-order considerations.

> Let me first confirm the symmetry argument. Intuitively, because the expression is symmetric in (a) and (b), the minimum likely occurs when (a = b), which reduces the problem to a single variable and simplifies the analysis. I should double-check that this assumption doesn't overlook any asymmetric minima, but for now I'll proceed with (a = b) and verify later that this choice yields the global minimum.

> With (a = b), the expression becomes (max{a, a, [1/a²] + [1/a²]} = max{a, [2/a²]}). Now I need to find the value of (a > 0) that minimizes this maximum. Let me think about the intersection where the two arguments are equal, because the minimum of the maximum typically occurs when the competing terms balance each other.

> Setting (a = [2/a²]), I multiply both sides by (a²) to get (a³ = 2), so (a = ³√2). Wait, let me verify the algebra: yes, (a³ = 2) implies (a = ³√2), which is the cube root of 2. At this point, both arguments of the max are equal, so the max value is (³√2). I should confirm that this is indeed a minimum by checking the behavior on either side of this point.

> For (a < ³√2), the term ([2/a²]) dominates, so the max is ([2/a²]), which decreases as (a) increases toward (³√2). For (a > ³√2), the term (a) dominates, so the max is (a), which increases as (a) increases. This confirms that the minimum of the maximum occurs at (a = ³√2), where the value is (³√2). Hold on, I should verify that this pattern holds for the original two-variable problem as well, not just the symmetric case.

> Next, I should review the general two-variable case to ensure there isn't a lower value when (a ≠ b). Let me consider the function (f(a, b) = max{a, b, [1/a²] + [1/b²]}). If I fix the product (ab = k) and try to minimize, the sum ([1/a²] + [1/b²]) is minimized when (a = b) by the AM-GM inequality, which pushes the maximum downward when (a = b). Conversely, if I fix the sum ([1/a²] + [1/b²] = c) and try to minimize (max{a, b}), the minimum of (max{a, b}) occurs when (a = b). This supports that the symmetric case yields the global minimum, so I can be confident in the earlier result.

> Therefore, the minimum value of (max{a, b, [1/a²] + [1/b²]}) is achieved when (a = b = ³√2), and the minimum value is (³√2). I should double-check the final statement: yes, substituting (a = b = ³√2) gives (max{³√2, ³√2, [2/((³√2)²)]} = max{³√2, ³√2, ³√2} = ³√2), which confirms the result.

---

The minimum value of (max{a, b, [1/a²] + [1/b²]}) for (a, b > 0) is (³√2), achieved when (a = b = ³√2).

---

## Step-by-step solution

### Step 1: symmetry and simplification

By symmetry, the minimum occurs when (a = b). Let (a = b = x > 0); then the expression becomes:

max{x, x, [1/x²] + [1/x²]} = max{x, [2/x²]}

---

### Step 2: analyze the simplified expression

We need to minimize (max{x, [2/x²]}). The minimum occurs when the two arguments are equal, i.e. (x = [2/x²]), because:

- If (x < [2/x²]), then (max = [2/x²]), which decreases as (x) increases.
- If (x > [2/x²]), then (max = x), which increases as (x) increases.

Thus, the minimum of the maximum occurs when (x = [2/x²]).

---

### Step 3: solve for x

Solve (x = [2/x²]):

x³ = 2 ⇒ x = ³√2

---

### Step 4: compute the minimum value

Substitute (x = ³√2) back into the expression:

max{³√2, [2/((³√2)²)]} = max{³√2, ³√2} = ³√2

---

### Step 5: verify the solution

We confirm that this is indeed the minimum by checking neighboring values:

- **For (x = 1)**: (max{1, 2} = 2 > ³√2)
- **For (x = 2)**: (max{2, [1/2]} = 2 > ³√2)

Thus, the minimum value is (³√2).

---

The minimum value of (max{a, b, [1/a²] + [1/b²]}) is (³√2), achieved when (a = b = ³√2).

---

## References

### Incorporating economic evidence in clinical guidelines: a framework from the clinical guidelines committee of the American College of Physicians [^4483eea4]. Annals of Internal Medicine (2025). High credibility.

Figure 1 — comparative value of interventions — categorizes value by clinical net benefit and incremental cost for quality-adjusted life-year (QALY) with intervention versus comparator, where the incremental cost dimension reflects the incremental cost-effectiveness ratio per QALY gained. For favorable clinical net benefit, higher cost corresponds to high value (< $100 000), intermediate value ($100 000 to $200 000), or low value (> $200 000) with the intervention more effective and more costly; lower cost corresponds to high value with the intervention more effective and less costly (cost-saving). For unfavorable clinical net benefit, higher cost indicates no value with the intervention less effective and more costly (cost-dominated), and lower cost indicates no value with the intervention less effective and less costly.

---

### Guidance for the Heart Rhythm Society pertaining to interactions with industry endorsed by the Heart Rhythm Society on April 26, 2011 [^f1dedb5c]. Heart Rhythm (2011). Medium credibility.

Heart Rhythm Society financial relationship disclosure categories — greater transparency is required and the value of financial relationships is now categorized as $0; $1–$10,000; $10,001–$25,000; $25,001–$50,000; $50,001–$100,000; and greater than $100,000, whereas previously categories were none; modest ($1–$10,000); or significant (more than $10,000).

---

### Worldwide divergence of values [^f95bbaf6]. Nature Communications (2024). High credibility.

Item normalization

Supplementary Table 2 shows that items were asked on different scales. Some items involved binary responses (e.g. whether people mention not wanting to be neighbors with someone from a specific group). Others were asked with Likert-type scales, such as the 1–10 scale that people used to rate whether behaviors were morally justifiable. We normalized the item scales using min-max normalization, which is a common approach in data science and machine learning. Given a vector V = [v₁, v₂, … vₙ], we can determine min_V as the minimum value in the vector and max_V as the maximum value in the vector. We can create our normalized vector, V' using:

In other words, each element in the new vector is the result of subtracting the minimum value of the original vector from that element, then dividing by the range of the original vector (i.e. the difference between its maximum and minimum values). This procedure results in variables with ranges of 0–1, no matter their original scales. As an alternative to min-max normalization, we also considered a median split approach. We discuss the limitations of this approach in the Supplementary Methods, and show how our main findings replicate with this approach.

---

### Biodiversity enhances ecosystem multifunctionality across trophic levels and habitats [^371c3cf5]. Nature Communications (2015). Medium credibility.

Threshold approach

For each function in each experiment, we identified the maximum value of the mean response across all treatments. Next, we determined which treatments attained a given threshold (1–99%) of that maximum. Defining the maximum threshold at an unachievable high value, such as based on the single highest observed value, inevitably leads to finding no biodiversity effect at high thresholds because no biodiversity level can reach the threshold. On the other hand, defining the maximum threshold at an easily achievable low value inevitably leads to finding no biodiversity effect at low thresholds because all biodiversity levels will reach the threshold. Our use of the maximum mean value may be lower than the maximum obtained if we took the average of the n -1 samples from an individual experiment, were we to have the raw data. Thus, care should be taken to avoid over-interpreting biodiversity effects near zero at high or low thresholds. We then tallied the number of functions that exceeded the given threshold for each level of richness. It is also important to note that we weighted functions equally in our analysis. Weighting of functions to reflect, for instance, management goals or prioritization of different functions is an exciting frontier, but we had no strong a priori reason to assign differential weighting to functions.

---

### A neural mechanism for conserved value computations integrating information and rewards [^c3518866]. Nature Neuroscience (2024). High credibility.

Offers could have multiple types of reward distributions. For full details, see Supplementary Table 1. In brief, when randomly generating an offer, the offer first had its expected reward drawn uniformly at random from a prespecified set of possible expected rewards. To reduce the number of trials with trivial decisions where one offer was much better than the other, the expected reward of offer 2 was constrained to be within a prespecified range of the expected reward of offer 1 for some animals and sessions. Then, the offer had its reward distribution randomly drawn from the following types: safe distributions with 100% probability of a specific amount; 25/50/25 distributions with 25, 50 and 25% chances of small, medium and large amounts, where medium was the mean of small and large; 50/50 distributions with 50% chances of small or large amounts and, in some animals and sessions, 25/75 distributions with a 25% chance of one amount and a 75% chance of a different amount. After the offer's distribution type was selected, its reward range was randomly drawn from a prespecified set of ranges. Finally, the offer's four possible reward amounts were discretized to occur in increments of R step between 0 and R max. For example, in animal R, R step = 0.02 and R max = 0.6, so there were 31 possible reward amounts (0, 0.02, …, 0.6 ml).

---

### Electric transmission value and its drivers in United States power markets [^e08f1117]. Nature Communications (2025). High credibility.

Results

Geospatial patterns of transmission value

The transmission value analyzed in this section is a pairwise quantity between two wholesale market pricing nodes (i.e. a "link") defined as the mean absolute locational marginal price difference between the nodes over time (in units $/MWh). It represents the marginal energy value of spatial price arbitrage within a specific market interval. A link is uniquely defined by two pricing nodes; it does not correspond to a specific transmission line, and there may be zero, one, or multiple existing transmission paths between a link's nodes. This paper primarily focuses on the real-time market, because we are most interested in transmission's ultimate value to the system and real-time prices reflect physically binding dispatch decisions under the actual operating conditions of the system. Further, only real-time prices exist for all 70 links depicted in Fig. 1, though day-ahead prices, derived from a forward financial market, exist for many of the links. We will later offer a comparison to value based on prices from the day-ahead timeframe. The marginal value is useful as it can be directly compared to market prices, but it can also be converted to an equivalent total value per link, such as millions $/GW. Total value metrics are useful when compared to transmission costs. When considering total value metrics, it is important to also consider market saturation effects (e.g. in each hour, is the full GW of transmission capacity needed, or would prices converge with less capacity?).

Fig. 1
Geospatial patterns of transmission value.

a Map of mean marginal transmission market values for all 70 analyzed links over the entire study period (real-time market). The line segments depict which pairs of wholesale market pricing nodes are analyzed and do not portray existing transmission lines. b Distribution of mean marginal transmission market values (real-time market) across the set of 70 analyzed links. Each point represents one link, and there are the following number of links in each category: cross-interconnect: 9, interregional: 31, within-region: 30. The horizontal lines on each box plot show, from low to high, the smallest data point lying within 1.5x the inter-quartile range (IQR) from the 25th percentile, the 25th percentile, the 50th percentile (median), the 75th percentile, and the largest data point lying within 1.5x the IQR from the 75th percentile.

---

### Machine-guided design of cell-type-targeting cis-regulatory elements [^81bd27dc]. Nature (2024). Excellent credibility.

Propeller plots

A propeller dot plot (Fig. 2e (top row)) is a two-dimensional plot scheme of our own device that seeks to elucidate the cross-dimensional non-uniformity of three-dimensional points. In this coordinate system, a point's radial distance from the origin corresponds to the difference between the maximum and minimum values. Its deviant angle from the axis corresponding to the maximum value quantifies the position of the median value within the range of the minimum and maximum values. Namely, the angle is proportional to the ratio between two differences: (1) the difference of the median and minimum values; and (2) the difference of the maximum and minimum values. This ratio represents the 60°-angle fraction deviating from the axis corresponding to the maximum value towards the axis corresponding to the median value. A higher angle of deviation (maximum of 60°) indicates that the median value is closer to the maximum value, while a lower angle (minimum of 0°) of deviation indicates that the median value is closer to the minimum value.

---

### Peyronie's disease: AUA guideline [^d070e387]. The Journal of Urology (2015). Medium credibility.

Peyronie's disease — minimum diagnostic evaluation: The clinician should engage in a diagnostic process to document the signs and symptoms that characterize Peyronie's disease, with the minimum requirements being a careful history to assess penile deformity, interference with intercourse, penile pain, and/or distress, and a physical exam of the genitalia to assess for palpable abnormalities of the penis. Assessment of sexual function is of particular importance and penile sensation, ejaculatory function, erectile function, difficulty/pain with penile penetration, and concerns regarding penile length and girth should be assessed; the goal of the examination is to provide baseline values that document the presence of deformity, the point of maximum curvature, presence/location/size of penile plaque(s), penile length, and areas of tenderness. For patients and/or partners with significant distress, consideration should be given for referral to a mental health professional with expertise in sexuality.

---

### Reward expectation extinction restructures and degrades CA1 spatial maps through loss of a dopaminergic reward proximity signal [^02c863a1]. Nature Communications (2022). High credibility.

DA ramp slope and max

To characterize the ramping activity observed in VTA axons, the maximum and slope of the time binned fluorescence data were calculated for each lap. The maximum was defined as the maximum bin value of the time binned fluorescence data for each lap. The maximum values for each lap were then normalized by dividing by the average maximum value in the Rewarded condition for each mouse. To calculate the slope of the curve in the Rewarded condition, the maximum value near the end of the track (within 15 bins of lap end) and the minimum value near the beginning of the track (within 25 bins of lap start) were determined for each lap. In all other experiment conditions, the range of bins used to find the maximum and minimum values were restricted to the nearest and furthest bins where the maximum and minimum were found in the Rewarded condition for each mouse. A line was then fit to the data points between the defined maximum and minimum values using the matlab fitlm function. The slope of this line was found and normalized by dividing by the average slope in the Rewarded condition for each lap. The slope*max was calculated as the product of the slope and maximum values for each lap and was normalized by dividing the average slope*max in the Rewarded condition for each mouse. The average maximum, slope and slope*max in each experimental condition were calculated for each mouse.

Velocity encoding

To investigate velocity encoding in a VTA axon, we aligned the activity of the axon to motion initiation. Motion epochs were identified as periods where the animal's velocity ≥ 1 cm/s for at least 1 s. Motion epochs were aligned to motion initiation, or the first frame where velocity ≥ 1 cm/s. The Δ F / F data and velocity 2 s prior to motion initiation and 8 s after motion initiation were collected for each motion epoch. Velocity was normalized by dividing by the maximum velocity of each motion epoch. The average Δ F / F and velocity of all motion epochs was calculated for each experiment condition.

---

### An introduction to machine learning [^70a823d9]. Clinical Pharmacology and Therapeutics (2020). Medium credibility.

Different categories of loss functions

Different objective functions can be chosen to measure the distance between observed data and values predicted by the model. Some of the distance metrics used in practice can be associated to a likelihood. The likelihood indicates how probable it is to observe our data according to the selected model. The most common use of a likelihood is to find the parameters that make the model fit optimally to the data (i.e. the maximum likelihood parameter estimates). Usually, the negative logarithm of the likelihood is minimized and considered as objective function because it has favorable numerical properties. Similarly, in ML metrics, such as mean squared error, logistic objective, or cross‐entropy, are used to find optimal parameters or assess the fitness of the model.

In practice, analytical calculation of maximum likelihood or minimal loss may not be feasible, and it is often necessary to use a numerical optimization algorithm to solve for the best parameter values. Gradient descent is such an algorithm, where we first define an objective function for which we want to minimize and then iteratively update the values of the parameters in the direction with the steepest decrease (first‐order derivative) of the objective function until a convergence to a minimum distance is deemed reached. In the scenario of a nonconvex objective function, the success of finding a global minimum, as opposed to landing in some local minima, will depend on the choice of the initial set of parameter values, the learning rate (i.e. step size of each iteration) and the criterion for convergence. The reader can refer to ref. 35 for details on convex and nonconvex optimization processes. Stochastic gradient descent is an additional trick that can further speed up the optimization by randomly sampling a training dataset and summing the distances across this subset of training data points for approximating the objective function.

---

### Joint EANM / EANO / RANO / SNMMI practice guideline / procedure standard for PET imaging of brain metastases: version 1.0 [^2f557b29]. European Journal of Nuclear Medicine and Molecular Imaging (2025). High credibility.

PET image display — bit depth and color scaling by tracer: For optimal value range, PET images should ideally employ a minimum of 16‑bit pixels; for amino acid PET ([18F]FET, [11C]MET, [18F]FDOPA), the color scale should be adjusted so that the background radioactivity of the healthy brain is in the lower third of the range, and for [18F]FDOPA the striatum uptake can be adjusted with the maximal of the color scale; for [18F]fluciclovine, the maximum of the color scale should be adjusted to the lesion uptake; in [18F]FDG PET imaging, the color scale should be adjusted so that the healthy brain uptake is the maximal of the color scale, and if the lesion uptake is higher, the maximum of the color scale should be adjusted.

---

### Discordance abounds in minimum clinically important differences in THA: a systematic review [^6286102d]. Clinical Orthopaedics and Related Research (2023). Medium credibility.

Background

The minimum clinically important difference (MCID) is intended to detect a change in a patient-reported outcome measure (PROM) large enough for a patient to appreciate. Their growing use in orthopaedic research stems from the necessity to identify a metric, other than the p value, to better assess the effect size of an outcome. Yet, given that MCIDs are population-specific and that there are multiple calculation methods, there is concern about inconsistencies. Given the increasing use of MCIDs in total hip arthroplasty (THA) research, a systematic review of calculated MCID values and their respective ranges, as well as an assessment of their applications, is important to guide and encourage their use as a critical measure of effect size in THA outcomes research.

Questions/Purposes

We systematically reviewed MCID calculations and reporting in current THA research to answer the following: (1) What are the most-reported PROM MCIDs in THA, and what is their range of values? (2) What proportion of studies report anchor-based versus distribution-based MCID values? (3) What are the most common methods by which anchor-based MCID values are derived? (4) What are the most common derivation methods for distribution-based MCID values? (5) How do the reported medians and corresponding ranges compare between calculation methods for each PROM?

Methods

The EMBASE, MEDLINE, and PubMed databases were systematically reviewed from inception through March 2022 for THA studies reporting an MCID value for any PROMs. Two independent authors reviewed articles for inclusion. All articles calculating new PROM MCID scores after primary THA were included for data extraction and analysis. MCID values for each PROM, MCID calculation method, number of patients, and study demographics were extracted from each article. In total, 30 articles were included. There were 45 unique PROMs for which 242 MCIDs were reported. These studies had a total of 1,000,874 patients with a median age of 64 years and median BMI of 28.7 kg/m 2. Women made up 55% of patients in the total study population, and the median follow-up period was 12 months (range 0 to 77 months). The overall risk of bias was assessed as moderate using the modified Methodological Index for Nonrandomized Studies criteria for comparative studies (the mean score for comparative papers in this review was 18 of 24, with higher scores representing better study quality) and noncomparative studies (for these, the mean score was 10 of a possible 16 points, with higher scores representing higher study quality). Calculated values were classified as anchor-based, distribution-based, or not reported. MCID values for each PROM, MCID calculation method, number of patients, and study demographics were extracted from each study. Anchor-based and distribution-based MCIDs were compared for each unique PROM using a Wilcoxon rank sum test, given the non-normal distribution of values.

Results

The Oxford Hip Score (OHS) and the Hip Injury and Osteoarthritis Score (HOOS) Pain and Quality of Life subscore MCIDs were the most frequently reported, comprising 12% (29 of 242), 8% (20 of 242), and 8% (20 of 242), respectively. The EuroQol VAS (EQ-VAS) was the next-most frequently reported (7% [17 of 242]) followed by the EuroQol 5D (EQ-5D) (7% [16 of 242]). The median anchor-based value for the OHS was 9 (IQR 8 to 11), while the median distribution-based value was 6 (IQR 5 to 6). The median anchor-based MCID values for HOOS Pain and Quality of Life were 33 (IQR 28 to 35) and 25 (14 to 27), respectively; the median distribution-based values were 10 (IQR 9 to 10) and 13 (IQR 10 to 14), respectively. Thirty percent (nine of 30) of studies used an anchor-based method to calculate a new MCID, while 40% (12 of 30) used a distribution-based technique. Thirty percent of studies (nine of 30) calculated MCID values using both methods. For studies reporting an anchor-based calculation method, a question assessing pain relief, satisfaction, or quality of life on a five-point Likert scale was the most commonly used anchor (30% [eight of 27]), followed by a receiver operating characteristic curve estimation (22% [six of 27]). For studies using distribution-based calculations, the most common method was one-half the standard deviation of the difference between preoperative and postoperative PROM scores (46% [12 of 26]). Most reported median MCID values (nine of 14) did not differ by calculation method for each unique PROM (p > 0.05). The OHS, HOOS JR, and HOOS Function, Symptoms, and Activities of Daily Living subscores all varied by calculation method, because each anchor-based value was larger than its respective distribution-based value.

Conclusion

We found that MCIDs do not vary very much by calculation method across most outcome measurement tools. Additionally, there are consistencies in MCID calculation methods, because most authors used an anchor question with a Likert scale for the anchor-based approach or used one-half the standard deviation of preoperative and postoperative PROM score differences for the distribution-based approach. For some of the most frequently reported MCIDs, however, anchor-based values tend to be larger than distribution-based values for their respective PROMs.

Clinical Relevance

We recommend using a 9-point increase as the MCID for the OHS, consistent with the median reported anchor-based value derived from several high-quality studies with large patient groups that used anchor-based approaches for MCID calculations, which we believe are most appropriate for most applications in clinical research. Likewise, we recommend using the anchor-based 33-point and 25-point MCIDs for the HOOS Pain and Quality of Life subscores, respectively. We encourage using anchor-based MCID values of WOMAC Pain, Function, and Stiffness subscores, which were 29, 26, and 30, respectively.

---

### Estimating cumulative point prevalence of rare diseases: analysis of the orphanet database [^92022854]. European Journal of Human Genetics (2020). Medium credibility.

RDs with a numerical prevalence value

Mean prevalence values were used and assigned classes with the intervals (< 1/1 000 000, 1–9/1 000 000, 1–9/100 000, and 1–5/10 000) to correspond with the prevalence categories listed on Orphanet.

RDs with a prevalence range only

Data were verified to ensure that the prevalence range assigned concurred with the prevalence categories listed on Orphanet for comparability. No numerical median or mean value could be assigned within the prevalence range as the distribution of point prevalence data within each class was not known. Accordingly, for each RD, data were recorded as (i) the minimum value within each class was assigned (e.g. 1/100 000 for the class 1–9/100 000) and (ii) the maximum value within each class was assigned (e.g. 5/10 000 for the class 1–5/10 000) for each disease. For the class < 1/1 000 000, both the minimum and maximum values were assigned as 1/1 000 000.

Case and family reports

The point prevalence class was assumed to be < 1/1 000 000 for each RD represented by only single cases or families. The point prevalence value was not calculated for each RD described by only case- and family- reports. Instead, indirect point prevalence was calculated for these RDs as a group as the point prevalence of the sum of all the case- and family- reports, divided by the global population in 2017. To ensure that changing family size has a negligible effect, we repeated our analysis using ten cases per family instead of one case per family.

Calculation of overall point prevalence estimates

Minimum and maximum boundaries of the global point prevalence estimate were calculated by summing the results of all three groups: all disorder-specific point prevalence values (for disorders with a point prevalence value), disorder-specific minimum values (for minimum boundary) or maximum values (for maximum boundary)(for disorders with point prevalence class only), and the indirect point prevalence estimate (derived for cases and families).

Point prevalence estimates were summarized descriptively and presented as the number of cases per 100 000. Step by step analyses of prevalence data and disease classifications were carried out using R-3.5.3 and Perl scripts, as described in the Supplemental Files.

---

### ACR-AAPM-SPR practice parameter for diagnostic reference levels and achievable doses in medical X-ray imaging [^44bdab9c]. ACR/AAPM/SPR (2023). High credibility.

Diagnostic reference levels (DRL) and achievable doses (AD) in medical X-ray imaging — definitions, scope, and percentile calculation: A DRL value is a form of investigation level used as a tool to aid optimization of protection in the medical exposure of patients for diagnostic and interventional procedures, and DRL values are suggested action levels above which a facility should review its methods and determine if acceptable image quality can be achieved at lower doses; DRL values can be developed on a national level (National DRL) or on a local level (Local DRL) when no national DRL value is available, and for this practice parameter the term "DRL" refers to "National Diagnostic Reference Levels". The ICRP emphasizes that DRL values are not for regulatory or commercial purposes, not a dose restraint and not linked to limits or constraints, and the specific purpose of DRL and AD values is to provide benchmarks for comparison, not to define maximum or minimum dose limits; DRL values are based on patient or standard phantom measurements under specific conditions at a number of representative clinical facilities. National DRL values are defined as the third quartile (75th percentile) of the distribution of the median values of the appropriate DRL quantity observed at each health care facility, meaning the median value for the procedure is at or below the DRL value for three-fourths of participating institutions; DRL values should not be applied to individual patients. To make meaningful comparisons, facility median values for representative samples of patients of a particular group defined by the DRL values should be compared against these DRL values, and facilities must first ensure that they have sufficient data to yield a representative sample for their specific practice. AD values are set at the 50th percentile of the distribution of facility median examination doses and can be used with DRL values to assist in optimizing image quality and dose.

---

### There are considerable inconsistencies among minimum clinically important differences in TKA: a systematic review [^a121146c]. Clinical Orthopaedics and Related Research (2023). Medium credibility.

Background

Patient-reported outcome measures (PROMs) are frequently used to assess the impact of total knee arthroplasty (TKA) on patients. However, mere statistical comparison of PROMs is not sufficient to assess the value of TKA to the patient, especially given the risk profile of arthroplasty. Evaluation of treatment effect sizes is important to support the use of an intervention; this is often quantified with the minimum clinically important difference (MCID). MCIDs are unique to specific PROMs, as they vary by calculation methodology and study population. Therefore, a systematic review of calculated MCID values, their respective ranges, and assessment of their applications is important to guide and encourage their use as a critical measure of effect size in TKA outcomes research.

Questions/Purposes

In this systematic review of MCID calculations and reporting in primary TKA, we asked: (1) What are the most frequently reported PROM MCIDs and their reported ranges in TKA? (2) What proportion of studies report distribution- versus anchor-based MCID values? (3) What are the most common methods by which these MCID values are derived for anchor-based values? (4) What are the most common derivation methods for distribution-based values? (5) How do the reported medians and corresponding interquartile ranges (IQR) compare between calculation methods for each PROM?

Methods

Following Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines, a systematic review was conducted using the PubMed, EMBASE, and MEDLINE databases from inception through March 2022 for TKA articles reporting an MCID value for any PROMs. Two independent reviewers screened articles for eligibility, including any article that calculated new MCID values for PROMs after primary TKA, and extracted these data for analysis. Overall, 576 articles were identified, 38 of which were included in the final analysis. These studies had a total of 710,128 patients with a median age of 67.7 years and median BMI of 30.9 kg/m 2. Women made up more than 50% of patients in most studies, and the median follow-up period was 17 months (range 0.25 to 72 months). The overall risk of bias was assessed as moderate using the Jadad criteria for one randomized controlled trial (3 of 5 ideal global score) and the modified Methodological Index for Non-randomized Studies criteria for comparative studies (mean 17.2 ± 1.8) and noncomparative studies (mean 9.6 ± 1.3). There were 49 unique PROMs for which 233 MCIDs were reported. Calculated values were classified as anchor-based, distribution-based, or not reported. MCID values for each PROM, MCID calculation method, number of patients, and study demographics were extracted from each study. Anchor-based and distribution-based MCIDs were compared for each unique PROM using a Wilcoxon rank sum test given non-normal distribution of values.

Results

The WOMAC Function and Pain subscores were the most frequently reported MCID value, comprising 9% (22 of 233) and 9% (22 of 233), respectively. The composite Oxford Knee Score (OKS) was the next most frequently reported (9% [21 of 233]), followed by the WOMAC composite score (6% [13 of 233]). The median anchor-based values for WOMAC Function and Pain subscores were 23 (IQR 16 to 33) and 25 (IQR 14 to 31), while the median distribution-based values were 11 (IQR 10.8 to 11) and 22 (IQR 17 to 23), respectively. The median anchor-based MCID value for the OKS was 6 (IQR 4 to 7), while the distribution-based value was 7 (IQR 5 to 10). Thirty-nine percent (15 of 38) used an anchor-based method to calculate a new MCID, while 32% (12 of 38) used a distribution-based technique. Twenty-nine percent of studies (11 of 38) calculated MCID values using both methods. For studies reporting an anchor-based calculation method, a question assessing patient satisfaction, pain relief, or quality of life along a five-point Likert scale was the most commonly used anchor (40% [16 of 40]), followed by a receiver operating characteristic curve estimation (25% [10 of 40]). For studies using distribution-based calculations, all articles used a measure of study population variance in their derivation of the MCID, with the most common method reported as one-half the standard deviation of the difference between preoperative and postoperative PROM scores (45% [14 of 31]). Most reported median MCID values (15 of 19) did not differ by calculation method for each unique PROM (p > 0.05) apart from the WOMAC Function component score and the Knee Injury and Osteoarthritis Outcome Score Pain and Activities of Daily Living subscores.

Conclusion

Despite variability of MCIDs for each PROM, there is consistency in the methodology by which MCID values have been derived in published studies. Additionally, there is a consensus about MCID values regardless of calculation method across most of the PROMs we evaluated.

Clinical Relevance

Given their importance to treatment selection and patient safety, authors and journals should report MCID values with greater consistency. We recommend using a 7-point increase as the MCID for the OKS, consistent with the median reported anchor-based value derived from several high-quality studies with large patient groups that used anchor-based approaches for MCID calculation, which we believe are most appropriate for most applications in clinical research. Likewise, we recommend using a 10-point to 15-point increase for the MCID of composite WOMAC, as the median value was 12 (IQR 10 to 17) with no difference between calculation methods. We recommend use of median reported values for WOMAC function and pain subscores: 21 (IQR 15 to 33) and 23 (IQR 13 to 29), respectively.

---

### Healthy housing reference manual [^d866c439]. CDC (2006). Medium credibility.

Table 14.4. Swimming pool operating parameters — water clarity, disinfectant levels, and chemical values are specified, including combined chlorine with minimum None, ideal None, and maximum 0.5; bromine levels of 2 (minimum), 5 (ideal), 10 (maximum), and for wading or shallow pool for children 4, 7, 10; hardness, CaCO3 of 150 (minimum), 200–400 (ideal), 500+ (maximum); stabilizer, cyanuric acid of 10, 30–50, 100 with the comment that if level exceeds 100 ppm partial water replacement is recommended; algae and bacteria listed as None with the directive to shock treat and maintain required disinfectant levels and 7.2 to 7.6 pH; and free chlorine guidance stating continuous levels at 1 to 1.5 ppm minimum, with loss of clarity potentially due to the operator not running the filter 24 hours per day.

---

### Quantification of bilateral coronal synostosis: anterior brachycephaly [^ac0ba63a]. The Cleft Palate-Craniofacial Journal (2021). Medium credibility.

Figure 1.
Summary of methods.

Table 1.
Extracted and Calculated Variables From Curve.

Figure 2.
Visualization of the starting point of the curve and the resulting sinusoid curves and the used variables; the outline was made with the slices shown in (B). A, Plane on 0-cm height; this figure shows how the starting point of the curve is determined. Also, the degrees of the circle/outline are added, which are represented in the curve. B, Plane on 4-cm height; this figure shows the starting point and the direction of the curve. C, Shows the resulting curve; the different variables are marked. Curve starts at occiput (SP; B) and follows the skull outline (on CT scan) clockwise; therefore, first trough represents the right side of the head. Second peak is forehead; second trough is left side of the head. Curve stops where it started (at the occiput). CM, center of mass; F, maximum of forehead; L, minimum value of left side of head; O, maximum of occiput; R, minimum value of right side of head; SP, starting point; XF, X-value of maximum forehead value; XFL, X-value for the maximum forehead minus 0.1 on the left side; XFR, X-value for the maximum forehead minus 0.1 on the right side; XL, X-value of the minimum value of the width on the left side; XR, X-value of the minimum value of the width on the right side. CT indicates computed tomography.

---

### Healthy housing reference manual [^8939f071]. CDC (2006). Medium credibility.

Spa and hot tub operating parameters — disinfectant and chemical values — are given in ppm, with free chlorine minimum 3, ideal 4, maximum 10 and bromine minimum 4, ideal 5, maximum 10, both with continuous levels. Super-chlorinate when combined level exceeds 0.2, and combined chlorine has minimum None, ideal None, maximum 0.5 with super-chlorinate indicators including eye irritation or algae growth. pH targets are minimum 7.2, ideal 7.3, maximum 7.6 with an ideal range 7.2–7.6. Total alkalinity (CaCO3) lists minimum 60, ideal 80–100, maximum 180; dissolved solids list minimum 300 and maximum 2,000; hardness (CaCO3) lists minimum 150, ideal 200–400, maximum 500+. Stabilizer (cyanuric acid) lists minimum 10, ideal 30–50, maximum 100, and if level exceeds 100 ppm, partial water replacement may be required. For ozone, ultraviolet light, hydrogen peroxide, and others, consult product manufacturer and use also requires a disinfectant in most health jurisdictions. For algae or bacteria the minimum, ideal, and maximum are None, and if observed, shock treat and maintain required levels of disinfectant and the appropriate pH.

---

### Modelling the species-area relationship using extreme value theory [^55b9aad1]. Nature Communications (2025). High credibility.

The same conclusions can also be drawn by examining the relationship between the ratioand the corresponding parameters of the GEV distribution (Fig. 3). Beginning with the location parameter of the GEV, μ, it is apparent from Fig. 3a that the estimated value, approaches zero when, suggesting that the minimum, i.e. the first individual detected, is very close to the focal point. On the other hand, forthe relationship betweenandbecomes linear with a slope of one, i.e. the location of the minimumbecomes directly proportional to the distance between the focal point and the centre of the species range. In fact, when1, we can assume that the stochastic nature of the minima can be ignored because the plausible range of values of the distribution of the minimum distance is very small compared to the distances to the focal point. In this case, we can describe the ranges of each species simply as discs with a constant radius. Furthermore, in this case and in the limit of large areas, it can be shown that S = cA, where c is a constant (refer to Supplementary Note 2; Figs. S1 and S2 for details).

Fig. 3
The estimated parameters of the generalised extreme value distribution (GEV), as a function of υ p, the location parameter of the (parent) Rice distribution.

a The location parameter of the GEV. b A zoom in ofin double logarithm axes for the values of υ p associated with Phase II. c The shape parameter. d the scale parameter. The red dashed lines in plots (c, d) correspond to the mean of the values for υ p > 5, upper line, and for υ p < 1, lower line. Recall that υ p is also the distance of the centre of the bivariate normal distribution of the individuals' locations to the focal point.

Within the range of, and in a double logarithmic plot, the relationship betweenandexhibits an almost power-law behaviour, with β ≈ 3.45 (Fig. 3b). This observation, combined with the fact that υ p is uniformly randomly distributed, leads to a power law SAR with exponent z ≈ 0.29 (see also Supplementary Note 3). This value is similar to that previously mentioned in ref. for Phase II. However, contrary to the assumption of an underlying lognormal distribution for the species abundance distribution used by these authors, in our simulations, all species have the same number of individuals.

---

### Specifying and pilot testing quality measures for the American Society of Addiction Medicine's standards of care [^5ad69985]. Journal of Addiction Medicine (2016). Medium credibility.

Veterans Health Administration facility-level descriptive statistics — pharmacotherapy for AUD: For "Pharmacotherapy for AUD (n = 119)", the reported values were mean 6.05, minimum 1.16, 25th percentile 4.16, 50th percentile 5.48, 75th percentile 7.12, and maximum 19.25.

---

### ACR-AAPM-SIIM practice parameter for determinants of image quality in mammography [^9e4c6ab7]. SIIM/ACR/AAPM (2022). High credibility.

Mammographic image display — luminance response and contrast: The brightness and contrast of grayscale medical images result from the luminance in relation to the image gray level values, and current guidance regarding ambient luminance, minimum and maximum luminance, and display contrast response for displays is provided in the ACR-AAPM-SIIM Technical Standard for Electronic Practice of Medical Imaging; within the applicable luminance range, the device should render the image details with a consistent grayscale that should be measured and maintained over time, and the contrast (luminance) response of mammographic displays should comply with the AAPM Task Group 18 and Task Group 270 recommendations.

---

### Paediatric nuclear medicine practice: an international survey by the IAEA [^78c414a4]. European Journal of Nuclear Medicine and Molecular Imaging (2020). Medium credibility.

Fig. 4
99m Tc MAG3 renograms: median, box (25th and 75th percentiles) and whiskers (minimum and maximum values) for the scaling factor (a), minimum activity (b), maximum activity (c), activity for an hypothetical 5-year-old boy (20 kg, 110 cm tall) (d) and activity for an hypothetical 10-year-old girl (30 kg, 140 cm tall) (e). Values recommended by the EANM paediatric dosage card and the NACG are also reported as a reference

Fig. 5
99m Tc pertechnetate thyroid scans: median, box (25th and 75th percentiles) and whiskers (minimum and maximum values) for the scaling factor (a), minimum activity (b), maximum activity (c), activity for an hypothetical 5-year-old boy (20 kg, 110 cm tall) (d) and activity for an hypothetical 10-year-old girl (30 kg, 140 cm tall) (e). Values recommended by the EANM paediatric dosage card and the NACG are also reported as a reference

Fig. 6
FDG PET/CT: median, box (25th and 75th percentiles) and whiskers (minimum and maximum values) for the scaling factor (a), minimum activity (b), maximum activity (c), activity for an hypothetical 5-year-old boy (20 kg, 110 cm tall) (d) and activity for an hypothetical 10-year-old girl (30 kg, 140 cm tall) (e). Values recommended by the EANM paediatric dosage card and the NACG are also reported as a reference

Table 2
Activity per body mass, minimum activity, maximum activity, activity for a 5-year-old boy (20 kg, 110 cm tall) and activity for a 10-year-old girl (30 kg, 140 cm tall) for FDG PET studies and the four most common single-photon procedures

---

### Summary benchmarks-full set – 2024 [^db7367b2]. AAO (2024). High credibility.

Primary open-angle glaucoma — consensus-based follow-up intervals: When target IOP is achieved with no progression and Duration of Control (months) is ≤ 6, the Approximate Follow-up Interval (months)* is 6; if target IOP is achieved with no progression and Duration of Control (months) is > 6, the interval is 12; if target IOP is achieved with progression, the interval is 1–2; if target IOP is not achieved with progression, the interval is 1–2; and if target IOP is not achieved without progression, the interval is 3–6; IOP is defined and These intervals are the maximum recommended time between evaluations.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^b1513dd5]. CDC (2011). Medium credibility.

Table 1b — Minimum sample size for detecting geometric mean (GM) ratio k with α = 0.05 and W = 0.9 — presents required sample sizes by standard deviation (S) strata and defines parameters; α is significance level, W is power, GM is geometric mean, and S is standard deviation, noting that 1.2 is the standard deviation of national viral load (VL) data. Each jurisdiction will need to assess the standard deviation of their local VL data and then determine the appropriate sample size needed to assess VL, and if the sample size is inadequate to meet the recommended case inclusion criterion, an alternate method may need to be used, such as combining multiple years of data. For k = 3, sample sizes across S = 1, 1.1, 1.2, 1.3, 1.4, 1.5 are 75, 91, 108, 127, 147, 169, and Table 1b uses power = 90%; jurisdictions may also explore differences in means of viral loads, including categorical differences in the proportion with undetectable or very low VL.

---

### Evaluating the effectiveness of selection indices and their genomic prediction using environmental and historical rice data [^78e239f2]. G3 (2025). Medium credibility.

General trends across Models 3–5

Table 6 presents the years of training sets, minimum (Min.), mean, and maximum (Max.) values of the estimated correlations among the predicted and observed selection index values within each year using all negative and positive correlation values and using only positive values obtained with Models 3–5. For all 3 models, the average of the minimum (Min.), mean, and maximum (Max.) values of the estimated correlations among the predicted and observed selection index values within each year were very similar. This means that Model 3 is adequate for the prediction of the index values. In addition, note that the average of the maximum values of Models 3–5 were higher than the average of the maximum values of Models 1 and 2. Thus, the covariableis a good option to incorporate in the model predictions.

Table 6.
Years of training sets, minimum (Min.), mean, and maximum (Max.) values of the estimated correlations between the predicted and observed selection index values within each year using all negative and positive correlation values and using only positive values obtained with Models 3–5.

Models 3–5 yield similar results, with slight improvements observed as additional covariates are included (from Model 3 to Model 5). The addition of covariates in Models 4 and 5 enhances prediction performance slightly, as reflected in higher maximum and mean correlation values compared with Model 3. Filtering for positive values increases the minimum and mean correlations across all models, improving the robustness of the predictions.

Training sets for 2019–2020–2021 consistently provide the highest correlations, indicating that this training set captures relevant variability or relationships for prediction. The year 2020–2021, on the other hand, shows weaker correlations, likely due to limitations in data representativeness or prediction conditions for these years. Among the 3 models, Model 5 shows the best overall performance, particularly in terms of maximum correlation values, suggesting that it is the most reliable for selection index predictions.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^dee6cacc]. CDC (2011). Medium credibility.

Community viral load sample size calculations — sample size to detect differences in geometric mean (GM) viral load depends on power and standard deviation (S). The table specifies "α = 0.05 and W = 0.8", with S columns 1 to 1.5; for k = 3 the minimum sample sizes by S are 54, 66, 78, 92, 106, and 122, and "1.2 is the standard deviation of national VL data", so at S = 1.2 the needed sample size is 78.

---

### Guideline for minimizing radiation exposure during acquisition of coronary artery calcium scans with the use of multidetector computed tomography: a report by the society for atherosclerosis imaging and prevention tomographic imaging and prevention councils in collaboration with the Society of Cardiovascular Computed Tomography [^b049fda8]. Journal of Cardiovascular Computed Tomography (2011). Medium credibility.

Coronary artery calcium (CAC) computed tomography (CT) — systematic monitoring of radiation dose — Minimum Requirements state that laboratories should record radiation dose in each patient (dose-length-product (DLP) in mGy × cm and effective radiation dose (E) in mSv) and should determine average values in each quarter for all consecutive patients, and average and maximum radiation dose from each quarter should be reviewed by the laboratory in the context of recommended targets; Optional Recommendations state that laboratories may measure image noise in 30 patients in each quarter (10 each of small, medium, and large patients) and should review average image noise in each of the 3 patient categories, with a practical guide provided in Appendix B and Appendix C.

---

### ACR-ASNR-ASSR-SIR-SNIS practice parameter for the performance of image-guided epidural steroid injection [^ca58fe4b]. SIR (2025). High credibility.

Quality assurance and reporting for epidural steroid injection (ESI) indicate that reporting should be in accordance with the ACR–SIR–SPR Practice Parameter for the Reporting and Archiving of Interventional Radiology Procedures, and procedure thresholds or overall thresholds may be used as part of ongoing quality assurance programs; when measures such as indications or success rates fall below a minimum threshold or when complication rates exceed a maximum threshold, a review should be performed to determine causes and to implement changes if necessary. For example, if the incidence of infection is one measure of the quality of ESI, values in excess of the defined threshold (1% to 2%) should trigger a review of policies and procedures, and because patient referral patterns and selection factors may dictate different thresholds, each department is urged to alter the thresholds as needed to higher or lower values to meet its own quality assurance program needs.

---

### ACR-ASNR-SIR-SNIS practice parameter for the performance of diagnostic cervicocerebral catheter angiography in adults [^8c3d8918]. SNIS/SIR/ACR/ASNR (2021). High credibility.

Quality improvement and review thresholds — trigger criteria — state that when quality measures such as appropriateness of indication or angiographic success rates fall below a minimum threshold or when complication rates exceed a maximum threshold, a review should be performed to determine causes and implement changes. As an example, if permanent neurological deficit is a quality measure, values in excess of the suggested threshold (in this case > 1%) should trigger a review of policies and/or practices. The document notes thresholds may vary, setting universal thresholds is not feasible, and each department is urged to adjust thresholds as needed to meet its own quality improvement program needs.

---

### Sodium fluoride1.1%, potassium nitrate 5% (sodium fluoride 5000 ppm sensitive) [^0c434f29]. FDA (2020). Medium credibility.

Active Ingredients:

Sodium Fluoride 1.1% (w/w)

Potassium Nitrate 5%

---

### Best clinical practices for the sleep center adjustment of noninvasive positive pressure ventilation (NPPV) in stable chronic alveolar hypoventilation syndromes [^cb698697]. Journal of Clinical Sleep Medicine (2010). Medium credibility.

Noninvasive positive pressure ventilation (NPPV) initial and maximum pressures — The recommended minimum starting IPAP and EPAP should be 8 cm H2O and 4 cm H2O, respectively. (Level A - Consensus). The recommended minimum starting pressure support (difference between IPAP and EPAP) should be 4 cm H2O. (Level A - Consensus). The recommended maximum pressure support (difference between IPAP and EPAP) should be 20 cm H2O. (Level A - Consensus). The recommended maximum IPAP should be 20 cm H2O for patients < 12 years and 30 cm H2O for patients ≥ 12 years. (Level A - Consensus). The minimum and maximum incremental changes in PS during NPPV titration should be 1 and 2 cm H2O, respectively. (Level A - Consensus).

---

### Ultra-high dynamic range quantum measurement retaining its sensitivity [^ff9759ff]. Nature Communications (2021). High credibility.

So far in the examples with our algorithm, we used halved areas (Aₙ = A₀/2ⁿ for integer n ≥ 0). Even though the uncertainty is mostly defined by the largest area, and the range by the smallest, the middle areas are important for reaching the lowest uncertainty (see Fig. 3c: they partake in the optimal combination). Adding more areas at integer multiples of the smallest area decreases the uncertainty, though slightly (see Supplementary Note 4).

Algorithm measurement

In Fig. 2b, measurement results of our algorithm in the steep region are plotted (for details of the measurement see Supplementary Note 5), together with the Heisenberg limit (which is only true for a small range and infinite T₂) and the approximate large-range limit explained in Supplementary Note 3. As mentioned before, and just like in Fig. 3d, the focus is on the scaling that originates from the algorithm, hence all overhead time is ignored. Our algorithm is very close to the limit, as could be expected since at long measurement times most time is spent on the sequence with the largest area. Moreover, our results scale approximately as, which is less steep than the Heisenberg-like scaling of, since our algorithm keeps approaching this limit.

When merely halving areas in a measurement sequence, its range is defined by the smallest area. Therefore, it would only improve the uncertainty with respect to the standard single-area measurement, but not the range. In this way, given a limit on the time delay between the π/2-pulses, for example owing to a maximum time resolution or waiting time requirements, the maximum range is restricted. However, the range of our algorithm is the inverse of the greatest common divisor of the frequencies in measured signal of all included areas (see Supplementary Note 6). For halved areas, since all larger areas are integer multiples of the smaller ones, this means that the greatest common divisor is the lowest frequency, thus the one related to the smallest area. To increase the range beyond this limit, we combine areas that are not integer multiples of each other. When purely looking at the range, combining two sequences for slightly different areas increases the range far beyond the standard measurement's range. Thus in principle, the range can be extended unlimitedly. Adding the large areas as well, it is still possible to get arbitrarily close to the ultimate uncertainty (for details see Supplementary Note 6).

---

### Infectious Diseases Society of America guidelines on the treatment and management of patients with COVID-19 (September 2022) [^6881edd1]. Clinical Infectious Diseases (2024). High credibility.

Other considerations for patients with mild-to-moderate COVID-19 who are at high risk for progression to severe disease include that the panel agreed that the overall certainty of evidence was low due to concerns about imprecision, as less than half of the original projected sample size was enrolled; compared to prior trials, giving remdesivir early in the course of the viral infection appears to have a robust effect within the limitation of a limited sample size; the panel agreed that benefits are likely to outweigh any potential harms in patients at high risk for severe disease; and the evidence confirms that using remdesivir early in the disease process when viral loads are high confers maximum benefit.

---

### Functional health state description and valuation by people aged 65 and over: a pilot study [^02581050]. BMC Geriatrics (2018). Low credibility.

Results

The demographic information on all four groups is presented in Table 1. Seventy percent of the respondents from the SA sample indicated that they preferred the VAS method as compared to the TTO. Exemplary comments from the respondents with regard to the task were:

Table 1
Demographic data for all respondents

"The TTO exercise placed a heavy cognitive burden on me"; "I feel the TTO exercise is too difficult to complete"; "the VAS is much easier to complete"; and "I feel the TTO exercise might not provide accurate results". Based on the fact that respondents complained about and failed to complete the TTO exercise, it was decided to continue using the VAS in group two and group three in the South African study, and in all groups in the Dutch study.

Ranking the valuations of the South African EQ-5D + C health states from best to worst health state, illustrated in Table 2, the EQ-5D + C exhibits a gradual downwards trend, with a maximum of 100 and minimum VAS value of 41. The achieved functioning questionnaire also exhibits a gradual downwards trend, with a maximum of 1.00 and a minimum VAS value of 36 (Table 3).

Table 2
EQ-5D + C questionnaire ranked health states according to average VAS values

Table 3
CAF questionnaire ranked health states according to average VAS values

Table 4 summarizes the results from the EQ-5D + C health state descriptions. The South African and Dutch elderly had no difficulty with completing the health state descriptions. The CAF questionnaire also performed adequately, with evident discriminatory power between the functioning dimensions of the questionnaire, Table 5.

Table 4
EQ-5D + C description results

Table 5
Functioning description results

The results of the EQ5D + C subgroup valuations can be seen in Table 2. The EQ-5D + C for the Dutch independent group exhibits a gradual downwards trend, with a maximum of 86 and minimum VAS value of 35. The Dutch semi-dependent group exhibits a gradual downwards trend, with the exception of health state 212321. A maximum of 78 and minimum VAS value of 37 were found. The Dutch dependent group also exhibits a gradual downward trend, with a maximum of 82 and minimum VAS value of 60 found.

As for the subgroups of health state valuations of the CAF questionnaire, the Dutch independent group had a maximum of 85 and a minimum VAS value of 47. The Dutch semi-dependent exhibited an 80 maximum and minimum VAS value of 48. The Dutch dependent group exhibited a maximum of 77 and minimum VAS value of 57.

---

### Evaluating the effectiveness of selection indices and their genomic prediction using environmental and historical rice data [^2f9ae759]. G3 (2025). Medium credibility.

Estimated correlations among the predicted and observed selection index values for the year 2022

Table 5 presents the years of training sets, minimum (Min.), mean, and maximum (Max.) values of the estimated correlations among the predicted and observed selection index values within each year using all negative and positive correlation values and using only positive values obtained with Models 1 and 2 (Table 1). These estimates were obtained with a different number of traits (Chalk, Whole, Ratoon, and Yield) and a different number of sample size for each index (SIM, ESIM, and DG).

Table 5.
Years of training sets, minimum (Min.), mean, and maximum (Max.) values of the estimated correlations among the predicted and observed selection index values within each year using all negative and positive correlation values and using only positive values obtained with Models 1 and 2.

General trends across Models 1 and 2

Table 5 provides an overview of the correlations between the predicted and observed selection index values for Models 1 and 2 across various training sets and subsets of correlation values. The average values of minimum, mean, and maximum correlations for Models 1 and 2 are comparable, proving that the inclusion of environmental covariates in Model 2 does not significantly impact the overall prediction of index values. Excluding negative correlation values enhances the average minimum and mean correlations for both models, with Model 1 showing a slightly higher performance in this context. Certain years, particularly 2019 and combined multi-year datasets (e.g. 2019–2020–2021), yield higher correlations, suggesting that they provide more reliable or representative training data, while environmental covariates slightly improve the average of the maximum correlation values (e.g. 0.284 in Model 1 vs 0.293 in Model 2). In a similar manner, their overall effect on the average of mean and minimum correlations is minimal.

---

### The visual impairment of inherited retinal diseases in Portugal as per the national table of disabilities [^0b7691bb]. Ophthalmology Science (2023). Medium credibility.

The estimated visual disability coefficient calculation included the evaluation of the following 7 graduated categories available in the ophthalmology chapter of the TNI:
1) Orbital or eyelid deformities
2) Low vision
3) Visual field change
4) Loss of bi-foveolar fixation
5) Oculomotor palsy
6) Photophobia
7) Chronic conjunctivitis

Each category is subdivided into subcategories graded by fixed value ranges with minimum and maximum assignable values possible. Supplement Document 1 shows the ophthalmology chapter of Portuguese TNI translated into English for better visualization of subcategories and how are range graded.

An independent grader (A.M.) did a chart review and systematically collected data on the 7 categories for each patient, and then, using that data, she assigned the minimum and maximum estimated visual disability coefficient possible for each patient, resulting from the sum of minimum and maximum values obtained from each category, respectively, applying Portuguese TNI. Patients with missing data for a category were assumed to have a disability score of zero for that category.

For example, a patient with visual acuity of 0.5 (decimal scale) in both eyes and a concentric decrease in the visual field below 10 o in both eyes has the following:

- a minimum estimated visual disability coefficient of 0.73: sum of 0.02 (minimum value assignable because of this level of low vision) with 0.71 (minimum value assignable because of visual field change)
- a maximum estimated visual disability coefficient of 0.84: sum of 0.04 (maximum value assignable because of this level of low vision) + 0.80 (value assignable because of visual field change)

When the minimum or maximum estimated visual disability coefficient exceeded 1, it was rounded down to 1 (maximum possible value).

For example, a patient with visual acuity of 0.05 (decimal scale) in both eyes and a concentric decrease in the visual field below 10º in both eyes has the following:

- a minimum estimated visual disability coefficient of 1: sum of 0.95 (minimum value assignable because of low vision) with 0.71 (minimum value assignable because of visual field change) exceeds 1
- a maximum estimated visual disability coefficient of 1: sum of 0.95 (maximum value assignable because of low vision) + 0.80 (value assignable because of visual field change) exceeds 1

---

### Free choice shapes normalized value signals in medial orbitofrontal cortex [^86668c8e]. Nature Communications (2018). Medium credibility.

Fig. 5
Comparisons of the model performances for relative value coding. a Plots of the percent variance explained by the four normalization model for the mean response-based data estimated in 20 lottery pairs. b Same as a, but for the single trial-based data. c Plots of the percent variance explained by the models for the mean response-based data when cross-validation was performed. Percent variance explained for training data and test data are shown

To examine the descriptive ability of the advanced fractional model, we verified whether the estimated normalization parameters appropriately described all aspects of neural activity. Across our population, estimated parameters were stable and within reasonable ranges, with an R max of ~20 imp s⁻¹ (Fig. 6a, n = 81, Kruskal–Wallis test, P = 0.44, H = 1.62, df = 2), a β of ~80 μl (Fig. 6b, P = 0.16, H = 3.72, df = 2) and σ of ~90 μl (Fig. 6c, P = 0.07, H = 5.38, df = 2). Notably, estimated R max values were strongly correlated with observed maximal firing rates (Fig. 6d, n = 81, r = 0.68, P < 0.001, t = 8.18, df = 79). Estimated β and σ parameters were also reliable as follows. We quantified R max β σ⁻¹, a term equivalent to output of the normalization equation when EV₁ = EV₂ = 0; this quantity can be thought of as representing baseline firing rates in the normalization model. Across our population, R max β σ⁻¹ values were significantly correlated with observed baseline firing rates before the cue stimuli appeared (Fig. 6e, n = 81, r = 0.41, P < 0.001, t = 4.00, df = 79). Thus, the estimated parameters of the normalization model appear to appropriately capture aspects of the observed neural activity, suggesting that the advanced fractional model may underlie relative value signals in mOFC neurons.

---

### Healthy housing reference manual [^e8e7dd24]. CDC (2006). Medium credibility.

Definitions of terms related to chlorination — chlorine concentration is measured in parts per million (ppm), and in 1 million gallons of water a chlorine concentration of 1 ppm would require 8.34 pounds of 100% chlorine. For surface water systems, a contact time of 20 to 30 minutes is common. Parts per million is a weight-to-weight comparison in which 1 ppm equals 1 pound per million pounds and, because water weighs 8.34 pounds per gallon, it takes 8.34 pounds of any substance per million gallons to equal 1 ppm; in water chemistry, 1 ppm equals 1 mg/L. Residual is the amount of chlorine left after the demand is met and total available chlorine = free chlorine + combined chlorine. Breakpoint chlorination is described as a process sometimes used to ensure the presence of free chlorine in public water supplies by adding enough chlorine to satisfy the chlorine demand and to react with dissolved ammonia, and dosage is the total amount of chlorine added to water given in parts per million (ppm) or milligrams per liter (mg/L).

---

### Financial stability in response to climate change in a Northern temperate economy [^2df5171b]. Nature Communications (2021). High credibility.

With the optimized MARS model by province, we find that eight out of ten provinces have at least one cold-weather variable as a critical variable to predict the economic variability (Supplementary Fig. 2). The cold weather variables are Minimum Temperature, Snow, and Heating Degree Days. Alberta and Newfoundland are the only exceptions, though Newfoundland is optimized when December is used as a variable (Supplementary Fig. 2). Alberta's most important variables include maximum temperature and precipitation. When monthly data are further restricted to quarters — based on the Statistics Canada quarters, different variables become more critical. During the fall, temperature variables are the most important, with minimum temperature most important for British Columbia and Alberta, maximum temperature most important for the Central provinces of Saskatchewan, Manitoba, Ontario, and Quebec. The average temperature is most important for New Brunswick, and the remaining Atlantic provinces were not able to be predicted using just only data from fall. Minimum and maximum temperature, along with precipitation, are most important in winter. The maximum temperature was most valuable in BC and Alberta, the minimum temperature for Saskatchewan and Quebec, and rain for Manitoba and Ontario. The Atlantic provinces were unable to have the economic variables predicted using climate data only from winter. In Spring and Summer, the most important variables are less consistent. Only Newfoundland and Nova Scotia are unable to have trade predicted by climate.

---

### Summary benchmarks-full set – 2024 [^c9abe316]. AAO (2024). High credibility.

Preferred Practice Pattern (PPP) guidelines — GRADE evidence quality ratings are defined for forming recommendations for care as follows: "Good quality (GQ): Further research is very unlikely to change our confidence in the estimate of effect", "Moderate quality (MQ): Further research is likely to have an important impact on our confidence in the estimate of effect and may change the estimate", and "Insufficient quality (IQ): Further research is very likely to have an important impact on our confidence in the estimate of effect and is likely to change the estimate; any estimate of effect is very uncertain".

---

### Reconstruction of absorbed doses to fibroglandular tissue of the breast of women undergoing mammography (1960 to the present) [^3d5731f3]. Radiation Research (2012). Low credibility.

The assessment of potential benefits versus harms from mammographic examinations as described in the controversial breast cancer screening recommendations of the U.S. Preventive Task Force included limited consideration of absorbed dose to the fibroglandular tissue of the breast (glandular tissue dose), the tissue at risk for breast cancer. Epidemiological studies on cancer risks associated with diagnostic radiological examinations often lack accurate information on glandular tissue dose, and there is a clear need for better estimates of these doses. Our objective was to develop a quantitative summary of glandular tissue doses from mammography by considering sources of variation over time in key parameters, including imaging protocols, X-ray target materials, voltage, filtration, incident air kerma, compressed breast thickness, and breast composition. We estimated the minimum, maximum and mean values for glandular tissue dose for populations of exposed women within 5-year periods from 1960 to the present, with the minimum to maximum range likely including 90% to 95% of the entirety of the dose range from mammography in North America and Europe. Glandular tissue dose from a single view in mammography is presently about 2 mGy, about one-sixth the dose in the 1960s. The ratio of our estimates of maximum to minimum glandular tissue doses for average-size breasts was about 100 in the 1960s compared to a ratio of about 5 in recent years. Findings from our analysis provide quantitative information on glandular tissue doses from mammographic examinations that can be used in epidemiological studies of breast cancer.

---

### Introducing the mesh integration (MINT) index: a standardised ratio scale for assessing in vivo hernia mesh performance [^3cf3fec0]. Surgical Endoscopy (2025). Medium credibility.

Assessment score category — histological

Histology sections are to be stained using haematoxylin and eosin, and be assessed under light microscopy with 40 × magnification, using a 2-page standardised histology scoring worksheet (Supplementary 3).

The histology scoring worksheet was adapted from the combination of International Organization for Standardization (ISO) 10993–6:2016, Keating's scoring system, and Jenkins' scoring system. Each component score for a specific mesh sample is corrected by subtracting scores from control samples. Control samples are to be retrieved for each layer of implantation in each animal. Total scores are calculated by grouping relevant component scores.

For Integration:

The difference in the average histological scores of desirable and undesirable findings is calculated. A degree of inflammation is required for wound healing, however, excess inflammation and foreign body response are undesirable.

The individual components have equal weighting. It is possible to have a negative integration histology module score by having minimal integration and excessive inflammatory reaction. Minimum score is -100%, and maximum score is 100%.

For Fibrosis:

The percent value for average score of all findings that suggests fibrosis is obtained. Inflammatory scores are not included to avoid overlapping with integration.

The greater the value, the more pronounced the fibrosis is. Minimum score is 0%, maximum score is 100%.

For Degradation:

Different from visual degradation, implant degradation in histology scoring examines the cross section of implants, and assesses whether there are any local tissue changes from degradation or degradative products. Minimum score is 0%, maximum score is 100%.

---

### Generalized leaky integrate-and-fire models classify multiple neuron types [^8b6b3483]. Nature Communications (2018). Medium credibility.

Action potential trough (V trough): The action potential fast trough was defined as the minimum value of the membrane potential before the next spike (or end of the stimulus interval).

Upstroke/downstroke ratio (up:downstroke): The ratio between the absolutes values of the action potential peak upstroke (i.e. maximum dV/dt value before the peak) and action potential peak downstroke (i.e. minimum dV/dt value after the peak). Here, the upstroke/downstroke ratio was separately measured on action potentials evoked by a one-second (long square) current step and a 3 ms (short square) current step.

Sag: The sag was calculated as the difference between the minimum membrane potential value reached during a hyperpolarizing one-second current step and the steady-state membrane potential during that step, divided by the difference between the minimum membrane potential value reached during the step and the baseline membrane potential. The sag was calculated on the step where the minimum membrane potential was closest to a value of −100 mV.

f–I curve slope: The f – I curve was calculated by measuring the average firing rate during one-second current steps versus the stimulus amplitude. The supra-threshold part of the curve was fit with a line, and the slope was taken from that linear fit.

Latency to the first action potential (latency): Latency was calculated as the interval between the start of the stimulus and the time of the first spike evoked by the stimulus.

Maximum burst index (max. burst index): If a burst was identified during a response, a burst index was calculated as the difference between the maximum instantaneous firing rate inside the burst and the maximum instantaneous firing rate outside the burst, normalized by their sum. Bursts were identified as a change in the character of the voltage trajectory during the interspike interval (e.g. changing from a "direct" trajectory, where the membrane potential was always increasing after a spike, to a "delay" trajectory, where the membrane potential first hyperpolarized, then depolarized after a spike). If no burst was detected, the index was zero. The maximum index reported here was the maximum across all the supra-threshold responses evoked by depolarizing one-second current steps.

---

### Modeling COVID-19 scenarios for the United States [^525ce868]. Nature Medicine (2021). Excellent credibility.

Table 1
Cumulative deaths from 22 September 2020 through 28 February 2021, maximum estimated daily deaths per million, date of maximum daily deaths and estimated R effective on 28 February 2021 for three boundary scenarios

Results for two additional derivative scenarios are available in the Supplementary Information. NA, not applicable.

When we modeled the future course of the epidemic assuming that states will once again shut down social interaction and economic activity when daily deaths reach a threshold of 8 deaths per million (plausible reference scenario), the projected cumulative death toll across the United States is forecast to be lower than that under the mandate-easing scenario, with 511,373 (469,578–578,347) deaths by 28 February 2021 (Fig. 2). Thus, across the 45 states that are projected to exceed daily deaths of 8 deaths per million under the mandate-easing scenario by the end of February 2021 (Table 1), the reinstatement of SDMs under the plausible reference scenario could save 541,738 (281,283–886,373) lives. This scenario also results in 80,798,356 (47,333,280–121,526,052) fewer estimated infections across the United States by the end of February 2021 (Extended Data Fig. 5) compared with the mandate-easing scenario, with the highest rates of infections estimated to occur in Arizona (46.2% (38.8–55.9%) infected), New Jersey (41.1% (35.1–50.8%) infected) and Louisiana (33.3% (29.9–37.4%) infected) (Extended Data Fig. 6). As with the previous scenario, even with the reinstatement of SDMs when daily deaths exceed 8 per million population, all states would reach an R effective greater than one before the end of the February 2021 (Fig. 4 and Table 1). Further results for hospital resource-use needs are presented in Extended Data Figs. 2 and 3 and forecast infections by state under this scenario are presented in Extended Data Figs. 7 and 8.

---

### 2021 ACC / AHA key data elements and definitions for heart failure: a report of the American college of cardiology / American Heart Association task force on clinical data standards (writing committee to develop clinical data standards for heart failure) [^8b45c34c]. Circulation: Cardiovascular Quality and Outcomes (2021). High credibility.

Documented findings of continuous ambulatory electrocardiographic monitoring — permissible values and definitions include the following: permissible values comprise Duration of continuous ambulatory electrocardiographic monitoring, h; AV block; Mean heart rate, bpm; Minimum heart rate, bpm; Maximum heart rate, bpm; Number of ventricular extrasystoles; Nonsustained ventricular tachycardia; Sustained ventricular tachycardia; Sinus pause; Heart rate variability; and Atrial fibrillation. Duration of continuous ambulatory electrocardiographic monitoring, h is defined as the time during which the monitor is recording the heart's electrical signals, and AV block is when the electrical signal from the atria to the ventricles is delayed or blocked at the AV node. Heart rate fields (mean, minimum, maximum) are defined for a patient in atrial fibrillation during continuous ambulatory electrocardiographic monitoring. Ventricular tachycardia fields include nonsustained ventricular tachycardia defined as episodes of 3–15 consecutive beats at > 100 bpm during monitoring and sustained ventricular tachycardia defined as episodes ≥ 30 s at > 100 bpm during monitoring.

---

### Cutting edge or blunt instrument: how to decide if a stepped wedge design is right for you [^471f52f2]. BMJ Quality & Safety (2021). High credibility.

When might I consider doing a stepped wedge trial?

Research designs are shaped as much by practical constraints as by abstract schemes, and it is always a good idea to start with the constraints and work towards a design, rather than start with a design and try to fit it to constraints. These constraints will be unique to each research context, and box 1 lists some areas to think about. Still, there are some common features of settings where a stepped wedge trial might be considered as a possible design, and we now review these.

Box 1
Practical constraints on the design of a longitudinal cluster randomised trial

Are there limits on the time available to complete the evaluation, on the number of clusters, or on the number of participants (or the rate at which you can recruit participants) at each cluster? These constraints put limits on the overall scale of the evaluation, or force trade-offs between different design characteristics.
How will participants and their data be sampled in your study: as a series of cross-sectional surveys, as a continuous stream of incident cases, as a cohort followed over time, or some other way? Does the timescale divide into cycles, seasons or milestones that influence how you will sample participants and data?
Is there a limit on how many clusters can implement the intervention at the same time in the evaluation? If this is constrained by research resources (eg, if there are only enough trained research staff to implement the intervention one cluster at a time) then implementation must be staggered in some way.
If implementation is to be staggered, is there a minimum 'step length'? If the same team delivers the intervention in different clusters at different steps, then bear in mind it may take some time to get the intervention fully operational at a site, and the team will also need time to relocate from one cluster to the next.

---

### Higher emissions scenarios lead to more extreme flooding in the United States [^8a671dca]. Nature Communications (2024). High credibility.

Detection of projected changes in flood extremes

We use a Monte Carlo approach to detect the significant increasing (or decreasing) projected changes in annual maximum discharge considering the uncertainties in the GCM ensemble mean. This simulation-based approach allows the detection of statistically significant changes in a given AEP based on the ensemble mean of the GCMs and their variability. The procedure for detecting projected changes is as follows:
For each year, estimate the sampling distribution parameters of the mean of the selected GCMs' annual maximum discharge based on the central limit theorem.
From the sampling distribution, generate samples of the ensemble mean for historical and future periods.
Calculate the difference of median values between historical and future periods:whereandare the median values of generated flood extremes for historical and future periods, respectively.
Iterate steps (2)–(3) 10,000 times and calculate 2.5%, 50%, and 97.5% quantiles of(i.e. and).
Consider an increase (decrease) shift if the signs of all, andare positive (negative), while no shift if any signs of, orare different from the others.

For each site, the significant change of flood extreme for various AEPs and scenarios between historical (1985–2014) and future (2071–2100) periods is identified by conducting the simulation-based approach.

Projected changes in precipitation and temperature

To examine what climate drivers affect the projected shifts in flood extremes, we first obtain the ensemble mean of seasonal- and basin-averaged precipitation and temperature for all scenarios. Then we calculate the projected change inandas follows:where and are the median values of for historical (1985–2014) and future (2071–2100) periods, respectively. For each corresponding season, we also calculate the relative change in the ensemble mean of seasonal maximum discharge :whereandare the median values offor historical (1985–2014) and future (2071–2100) periods, respectively.

---

### Optimal adaptive control for quantum metrology with time-dependent hamiltonians [^f7dc3999]. Nature Communications (2017). Medium credibility.

Time-dependent quantum metrology

We now turn to the main topic of this work, quantum metrology with time-dependent Hamiltonians. Our goal is to find the maximum Fisher information for parameters in time-dependent Hamiltonians.

The starting point of quantum metrology with a time-dependent Hamiltonian is similar as with a time-independent Hamiltonian above. A system is initialized in some stateand evolves under the time-dependent Hamiltonian H_g(t) with g as the parameter to estimate, then after an evolution for some time T, one measures the final state of the system

where U_g(0→T) is the unitary evolution under the Hamiltonian H_g(t) for time T, and estimates g from the measurement results, which is just the standard recipe for a general quantum metrology. And the quantum Fisher information of estimating g from measuringis still determined by equation (3), which can be written as, where.

Everything is similar as before so far, but we can immediately see two major obstacles to deriving the maximum Fisher information. One is that due to the complexity of evolution under a time-dependent Hamiltonian, the unitary evolution U g (0→ T) is generally difficult to obtain. The other is that even if we can find a solution to U g (0→ T), it is hard to maximize the Fisher information, since h g (T) can be quite complex and the optimization is global involving the whole evolution history of the system for time T. To derive the maximum Fisher information for time-dependent Hamiltonians, we need to overcome these obstacles.

For the purpose of convenience, we first reformulate the quantum Fisher information as

which is dependent on the initial stateof the system now, and h_g(T) becomes i (0→T) δ_g U_g(0→T), which is different from the one in refs, and can no longer be interpreted as the local generator of parametric translation of U_g(0→T) with respect to g. But the maximum of the Fisher informationis still the squared gap between the maximum and minimum eigenvalues of h_g(T), as in the case of static Hamiltonians. Therefore, the key to determining the optimal estimation precision for the parameter g is finding h_g(T) and its maximum and minimum eigenvalues.

---

### Three-dimensional anthropometric database of attractive caucasian women: standards and comparisons [^5e666970]. The Journal of Craniofacial Surgery (2016). Low credibility.

Analysis of the vertical linear measurements along the midline shows a much smaller uncertainty value (average 0.15, minimum 0.09, maximum 0.21 mm). Figure 3 shows the average, minimum, and maximum values measured on the sample, as well as the standard deviation, for linear measurements, and Figure 4 for angular measurement. The analysis of linear measurements obtained shows very different values between individuals, probably as a function of changes in morphology and facial type of the finalists analyzed.

FIGURE 3
Linear measurements: average, minimum, and maximum values found in the sample, and standard deviation.

FIGURE 4
Angular measurements: average, minimum, and maximum values of the sample, and standard deviation.

---

### Correction [^26cbbc41]. Journal of Radiology Case Reports (2017). Low credibility.

[This corrects the article on p. 8 in vol. 10.].

---

### Choosing the appropriate measure of central tendency: mean, median, or mode? [^d99b58e6]. Knee Surgery, Sports Traumatology, Arthroscopy (2023). Medium credibility.

Mean, median, and mode are among the most basic and consistently used measures of central tendency in statistical analysis and are crucial for simplifying data sets to a single value. However, there is a lack of understanding of when to use each metric and how various factors can impact these values. The aim of this article is to clarify some of the confusion related to each measure and explain how to select the appropriate metric for a given data set. The authors present this work as an educational resource, ensuring that these common statistical concepts are better understood throughout the Orthopedic research community.

---

### Buprenorphine [^0b99b496]. FDA (2025). Medium credibility.

Dispense with Medication Guide available at: https://www.sunpharma.com/usa/products

---

### Saxagliptin and metformin hydrochloride [^7800834c]. FDA (2024). Medium credibility.

Table 10: Glycemic Parameters at Week 24 in a Placebo-Controlled Trial of Saxagliptin as Add-On Combination Therapy with Insulin*

* Intent-to-treat population using last observation on trial or last observation prior to insulin rescue therapy for patients needing rescue.

† Least squares mean adjusted for baseline value and metformin HCl use at baseline.

‡ p-value < 0.0001 compared to placebo + insulin.

§ p-value < 0.05 compared to placebo + insulin.

The change in fasting plasma glucose from baseline to Week 24 was also tested, but was not statistically significant. The percent of patients achieving an A1C < 7% was 17% (52/300) with saxagliptin in combination with insulin compared to 7% (10/149) with placebo. Significance was not tested.

Saxagliptin Add-On Combination Therapy with Metformin HCl plus Sulfonylurea

A total of 257 patients with type 2 diabetes mellitus participated in this 24-week, randomized, double-blind, placebo-controlled trial to evaluate the efficacy and safety of saxagliptin in combination with metformin HCl plus a sulfonylurea in patients with inadequate glycemic control (A1C ≥ 7% and ≤ 10%). Patients were to be on a stable combined dose of metformin HCl extended-release or immediate-release (at maximum tolerated dose, with minimum dose for enrollment being 1,500 mg) and a sulfonylurea (at maximum tolerated dose, with minimum dose for enrollment being ≥ 50% of the maximum recommended dose) for ≥ 8 weeks prior to enrollment.

---

### A machine learning automated recommendation tool for synthetic biology [^5caa5c39]. Nature Communications (2020). High credibility.

Optimization-suggesting next steps

The optimization phase leverages the predictive model described in the previous section to find inputs that are predicted to bring us closer to our objective (i.e. maximize or minimize response, or achieve a desired response level). In mathematical terms, we are looking for a set of N r suggested inputs, that optimize the response with respect to the desired objective. Specifically, we want a process that:
i. optimizes the predicted levels of the response variable;
ii. can explore the regions of input phase space (in Eq. (1)) associated with high uncertainty in predicting response, if desired;
iii. provides a set of different recommendations, rather than only one.

We are interested in exploring regions of input phase space associated with high uncertainty, so as to obtain more data from that region and improve the model's predictive accuracy. Several recommendations are desirable because several attempts increase the chances of success, and most experiments are done in parallel for several conditions/strains.

In order to meet these three requirements, we define the optimization problem formally aswhere the surrogate function G (x) is defined as:depending on which mode ART is operating in (see the "Key capabilities" section). Here, y * is the target value for the response variable, y = y (x), and Var(y) denote the expected value and variance, respectively (see "Expected value and variance for ensemble model" in Supplementary Information), denotes Euclidean distance, and the parameter α ∈ [0, 1] represents the exploitation-exploration trade-off (see below). The constraintcharacterizes the lower and upper bounds for each input feature (e.g. protein levels cannot increase beyond a given, physical, limit). These bounds can be provided by the user (see details in the "Implementation" section in Supplementary Information); otherwise, default values are computed from the input data as described in the "Input space set" section in Supplementary Information.

---

### Joint consensus statement of the American Academy of Sleep Medicine and sleep research society on the recommended amount of sleep for a healthy adult: methodology and discussion [^774449e8]. Journal of Clinical Sleep Medicine (2015). Medium credibility.

Consensus process — RAND voting, threshold vs range, and increments: The RAND Appropriateness Method uses a detailed literature search followed by two rounds of anonymous voting, with the first round completed without panel interaction; in a modification to RAM, the conference included a third round of voting to establish a single recommendation for the amount of sleep needed to promote optimal health in adults, with discussion of recommending an optimal sleep duration range versus a single threshold value, and the final Consensus Recommendation Statement resulted from the third round; panel members voted on the appropriateness of one-hour increments ranging from 5 to 10 hours of sleep, and of < 5 and ≥ 10 hours of sleep, and the final recommendation was based on the one-hour values determined by the panel to be "appropriate".

---

### Recommendations for quantification methods during the performance of a pediatric echocardiogram: a report from the pediatric measurements writing group of the American Society of Echocardiography pediatric and congenital heart disease council [^c4e65fe2]. Journal of the American Society of Echocardiography (2010). Medium credibility.

Pediatric echocardiography measurements of cardiovascular structures — body size adjustment using body surface area (BSA) and Z scores: Body surface area (BSA) appears to be a better parameter of somatic growth in normal children than height or weight alone, but published equations to calculate BSA often produce variable results, particularly at lower height and weight values, and some are derived from data that do not include children. The Haycock formula appears to provide the best correlation between BSA and the size of cardiovascular structures and is recommended for calculating BSA. Because of the linear relationship between cardiac output and BSA and the mostly linear relationship between cardiac size and the size of cardiovascular structures, "indexing" the size of structures to BSA has become a fairly common practice; however, assuming that BSA is linearly related to length, area, and volume measurements is mathematically impossible, and BSA-adjusted measurements often manifest a persistent dependence on BSA with changing variance known as heteroscedasticity. Once the mathematical relationship between a measurement and BSA has been determined, the next step involves the confidence intervals and the problem of heteroscedasticity, with one approach involving transformation of the measurements and/or BSA within a linear or nonlinear regression equation, and another involving a logarithmic transformation of the measurements that does not effectively describe the population at minimum and maximum BSA values nor fully eliminate heteroscedasticity. An increasingly popular approach in pediatric cardiology to account for the effects of body size and age has been the use of Z scores, with calculation of Z scores involving assessment of the distribution of measurement values (by determining the confidence intervals) across a range of body sizes in the normal population, and the Z score of a measurement defined as the number of standard deviations off that value from the mean value at a particular BSA.

---

### Tolazamide [^fd0bcd1f]. FDA (2006). Low credibility.

DOSAGE AND ADMINISTRATION

There is no fixed dosage regimen for the management of diabetes mellitus with tolazamide tablets or any other hypoglycemic agent. In addition to the usual monitoring of urinary glucose, the patient's blood glucose must also be monitored periodically to determine the minimum effective dose for the patient; to detect primary failure, ie, inadequate lowering of blood glucose at the maximum recommended dose of medication; and to detect secondary failure, ie, loss of adequate blood glucose response after an initial period of effectiveness. Glycosylated hemoglobin levels may also be of value in monitoring the patient's response to therapy.

Short-term administration of tolazamide may be sufficient during periods of transient loss of control in patients usually controlled well on diet.

Usual Starting Dose

The usual starting dose of tolazamide tablets for the mild to moderately severe type II diabetic patient is 100–250 mg daily administered with breakfast or the first main meal. Generally, if the fasting blood glucose is less than 200 mg/dl, the starting dose is 100 mg/day as a single daily dose. If the fasting blood glucose value is greater than 200 mg/dl, the starting dose is 250 mg/day as a single dose. If the patient is malnourished, underweight, elderly, or not eating properly, the initial therapy should be 100 mg once a day. Failure to follow an appropriate dosage regimen may precipitate hypoglycemia. Patients who do not adhere to their prescribed dietary regimen are more prone to exhibit unsatisfactory response to drug therapy.

---

### Rating certainty when the target threshold is the null and the point estimate is close to the null [^2f44331a]. BMJ Evidence-Based Medicine (2025). High credibility.

When one initially targets the null effect and the point estimate falls close to the null, two challenges exist in rating certainty of evidence. First, when the point estimate is near the null and the data, therefore, suggests little or no effect, rating certainty in a benefit or harm is misleading. Second, since in general the narrower the confidence interval (CI) the more precise the estimate, if the CI is narrow, rating down for imprecision due simply to crossing the null is inappropriate. This paper addresses these issues and provides a solution: to revise the target of certainty rating from a non-zero effect to a little or no effect. This solution requires estimating a range in which the minimal important difference (MID) for benefit and an MID for harm might lie, and thus establishing a range that represents little or no effect. If GRADE (Grading of Recommendations, Assessment, Development, and Evaluations) users are confident that the point estimate represents an effect less than the smallest plausible MID, they will revise their target and rate certainty to a little or no effect. If the entire CI falls within the range of little or no effect, they will not rate down for imprecision. Otherwise (if the CI includes an important effect), they will rate down. Using the solution provided in this paper GRADE users can make an optimal choice of the target of certainty rating.

---

### A method to construct the dynamic landscape of a bio-membrane with experiment and simulation [^d848a607]. Nature Communications (2022). High credibility.

The dynamic landscape also illustrates the origin of the T 1 temperature dependence in lipid chains: previous studies have not identified a T 1 minimum as a function of temperature for phospholipid chains in the liquid crystalline state. One expects T 1 to reach a minimum when the maximum of the total distribution of motion (Fig. 6e) approximately matches the center of T 1 sensitivity. From Fig. 6e, we are able to see why no minimum is observed: the maximum of the distribution falls at very short correlation times (1–10 ps), so that to have the T 1 sensitivity correspond with the maximum of the distribution would require significant cooling (causing the membrane to transition to the gel phase) or would require extremely high magnetic fields (~38 GHz ¹³C Larmor frequency). Note that we would expect a T 1 minimum with respect to temperature for typical fields and temperatures in the glycerol backbone, where the distribution has a maximum of around 1 ns; perhaps, it is not a coincidence that Milburn and Jeffrey find a T 1 minimum in bilayers of egg phosphatidylcholine for the nearby 31 P atom just below ambient temperature.

---

### Elective female genital cosmetic surgery: ACOG committee opinion, number 795 [^2996ee1b]. Obstetrics and Gynecology (2020). High credibility.

Variability of female genitalia measurements — selected normative values from Table 2 (Mean [in mm], Standard Deviation, Minimum [in mm], Maximum [in mm]) include: Width of clitoris — Mean 4.62, Standard Deviation 2.538, Minimum 1, Maximum 22; Length of clitoris — Mean 6.89, Standard Deviation 4.965, Minimum 0.5, Maximum 34; Length of labia minora (right) — Mean 42.1, Standard Deviation 16.35, Minimum 6, Maximum 100; Width of labia minora (right) — Mean 13.4, Standard Deviation 7.875, Minimum 2, Maximum 61.

---

### ID-file B… [^ee4be676]. ftp.cdc.gov (2025). Medium credibility.

16001000202, 16, 1, 202, "Under 1", 0. 007627, 100000, 763, 99314, 8305199,
83. 1, 0. 008,

1. 8306 16001000202, 16, 1, 202, 1–4, 0. 000514, 99237, 51, 396847, 8205886,
82. 7, 0. 0001, 1.
7179. 16001000500, 16, 1, 500, 1–4, 0. 000578, 99580, 58, 398203, 7832848,
78. 7, 0. 0001,

1. 5013 16001000500, 16, 1, 500, 5–14, 0. 000729, 99522, 73, 994857, 7434645,
74. 7, 0. 0002, 1.
5021. 16001000702, 16, 1, 702, "Under 1", 0. 009103, 100000, 910, 99181, 8079583,
80. 8, 0. 0067,

1. 5027 16001000702, 16, 1, 702, 1–4, 0. 000514, 99090, 51, 396257, 7980402,
80. 5, 0. 0001, 1.
4139. 16001002222, 16, 1, 2222, "Under 1", 0. 001446, 100000, 145, 99870, 8172556,
81. 7, 0. 0015,

1. 9582 16001002222, 16, 1, 2222, 1–4, 0. 000612, 99855, 61, 399300, 8072686,
80. 8, 0. 0001, 1.
9574. 16001002224, 16, 1, 2224, 25–34, 0. 005438, 98818, 537, 985489, 5438140,
55. 0, 0. 0032, 0.
9974. 16001002302, 16, 1, 2302, "Under 1", 0. 003196, 100000, 320, 99712, 7838802,
78. 4, 0. 0019,

1. 2961 16001002302, 16, 1, 2302, 1–4, 0. 000735, 99680, 73, 398575, 7739089,
77. 6, 0. 0002,

1. 2916

---

### Tolazamide (Tolinase) [^c2636c5d]. FDA (2006). Low credibility.

DOSAGE AND ADMINISTRATION

There is no fixed dosage regimen for the management
of diabetes mellitus with TOLINASE Tablets or any other hypoglycemic agent. In addition to the usual monitoring of urinary glucose, the patient's blood glucose must also be monitored periodically to determine the minimum effective dose for the patient; to detect primary failure, ie, inadequate lowering of blood glucose at the maximum recommended dose of medication; and to detect secondary failure, ie, loss of adequate blood glucose response after an initial period of effectiveness. Glycosylated hemoglobin levels may also be of value in monitoring the patient's response to therapy.

Short-term administration of TOLINASE may be sufficient during periods of transient loss of control in patients usually controlled well on diet.

Usual Starting Dose

The usual starting dose of TOLINASE Tablets for
the mild to moderately severe Type II diabetic patient is 100–250 mg daily administered with breakfast or the first main meal. Generally, if the fasting blood glucose is less than 200 mg/dl, the starting dose is 100 mg/day as a single daily dose. If the fasting blood glucose value is greater than 200 mg/dl, the starting dose is 250 mg/day as a single dose. If the patient is malnourished, underweight, elderly, or not eating properly, the initial therapy should be 100 mg once a day. Failure to follow an appropriate dosage regimen may precipitate hypoglycemia. Patients who do not adhere to their prescribed dietary regimen are more prone to exhibit unsatisfactory response to drug therapy.

---

### Influence of individual models and studies on quantitative mitigation findings in the IPCC sixth assessment report [^d09f70ce]. Nature Communications (2025). High credibility.

Impact measures

The impacts of removing individual models and studies are measured in two different ways, both shown in Table 1. 'Between' measures the impact relative to the differences between 1.5 °C and 2 °C scenarios: it is a unitless measure of the change in median value when an individual model/study is removed relative to the difference between the 1.5 °C and 2 °C medians. A value of 100% means that the change in median value is the same as the (absolute) difference between the 1.5 °C and 2 °C medians. A value of 0% means that there is no change.where X is an individual model or study. 'Within' measures the impact relative to other models and studies within the same (1.5 °C) climate category: it is a unitless measure of how close the reported median is to the median of the individual model/study that is removed versus the median of all the other models/studies combined. A value of 100% means that the median coincides with the median of the dominant model/study, and a value of 0% means that the ensemble median coincides with the median of all the other models/studies. A value above 50% means that the reported median is closer to the median of the dominant model/study than to the median of all the other models/studies taken together.where X is an individual model or study.

---

### 2024 update of the North American Consensus guidelines for pediatric administered radiopharmaceutical activities [^c80c63ad]. Journal of Nuclear Medicine Technology (2025). High credibility.

Gastric emptying imaging — 99mTc-sulfur colloid administered activity specifies "No weight-based dose", with oral liquid gastric emptying minimum 18.5 MBq (0.5 mCi) and maximum 37 MBq (1.0 mCi), and solid gastric emptying minimum 9.25 MBq (0.25 mCi) and maximum 18.5 MBq (0.5 mCi).

---

### Infectious Diseases Society of America guidelines on the treatment and management of patients with COVID-19 (September 2022) [^4561bde8]. Clinical Infectious Diseases (2024). High credibility.

Guideline panel conclusion descriptors — the panel states that "the desirable effects outweigh the undesirable effects, though uncertainty still exists, and most informed people would choose the suggested course of action, while a substantial number would not", and separately that "the undesirable effects outweigh the desirable effects, though uncertainty still exists, and most informed people would choose the suggested course of action, while a substantial number would not".

---

### Slice testing-considerations from ordering to reporting: a joint report of the Association for Molecular Pathology, college of American pathologists, and National Society of Genetic Counselors [^4565fa4d]. The Journal of Molecular Diagnostics (2024). High credibility.

Exome sequencing (ES) and slice test coverage — analytical performance and reporting thresholds are specified as follows: a key difference between traditional disease-focused gene panels and slices is a lower likelihood of achieving completeness of coverage for the latter. For any genetic testing, a minimum of 15× to 20× coverage per site is needed (often correlates to 100× average gene coverage). Current guidelines published by the ACMG recommend that ES should have an average depth of coverage of at least 100× and a minimum depth of coverage for variant assessment of at least 20×; with this criterion applied to the exons and 10 base pairs into flanking introns. Some diseases arise from low-frequency variants, and decreased coverage may prevent detection of mosaic variants (eg, some cases of epilepsy). A recent study indicates significant interlaboratory and intralaboratory variation in coverage that can be masked by using average depth of coverage as a standard; although average read depth was consistent within the laboratory (coefficient of variance, 1% to 4%), variability was higher in certain gene sets, including epilepsy genes (CV, maximum of 60%) and ACMG 59 secondary finding genes (CV, maximum of 71%). Coverage limitations should be summarized by gene and disclosed on the clinical report, and it is recommended that laboratories should disclose the percentage of each gene covered at a minimum necessary level (such as ≥ 20×) on each report.

---

### Quantitative assessment of full-width at half-maximum and detector energy threshold in X-ray imaging systems [^c65d8c68]. European Journal of Radiology (2024). Medium credibility.

Background

The response function of imaging systems is regularly considered to improve the qualified maps in various fields. More the accuracy of this function, the higher the quality of the images.

Methods

In this study, a distinct analytical relationship between full-width at half-maximum (FWHM) value and detector energy thresholds at distinct tube peak voltage of 100 kV has been addressed in X-ray imaging. The outcomes indicate that the behavior of the function is exponential. The relevant cut-off frequency and summation of point spread function S(PSF) were assessed at large and detailed energy ranges.

Results

A compromise must be made between cut-off frequency and FWHM to determine the optimal model. By detailed energy range, the minimum and maximum of S(PSF) values were revealed at 20 keV and 48 keV, respectively, by 2979 and 3073. Although the maximum value of FWHM occurred at the energy of 48 keV by 224 mm, its minimum value was revealed at 62 keV by 217 mm. Generally, FWHM value converged to 220 mm and S(PSF) to 3026 with small fluctuations. Consequently, there is no need to increase the voltage of the X-ray tube after the energy threshold of 20 keV.

Conclusion

The proposed FWHM function may be used in designing the setup of the imaging parameters in order to reduce the absorbed dose and obtain the final accurate maps using the related mathematical suggestions.

---

### 2024 update of the North American Consensus guidelines for pediatric administered radiopharmaceutical activities [^fb1d3475]. Journal of Nuclear Medicine Technology (2025). High credibility.

Thyroid imaging — Na123 I for thyroid imaging uses 0.28 MBq/kg (0.0075 mCi/kg) with minimum 1 MBq (0.027 mCi) and maximum 11 MBq (0.3 mCi); Na123 I for thyroid cancer imaging uses 3.7 MBq/kg (0.10 mCi/kg) with minimum 74 MBq (2 mCi) and maximum 148 MBq (4 mCi); 99mTc-pertechnetate for thyroid imaging uses 1.1 MBq/kg (0.03 mCi/kg) with minimum 7 MBq (0.19 mCi) and maximum 93 MBq (2.5 mCi).

---

### FDA oral history, maraviglia… [^51cc08d2]. FDA (2025). Medium credibility.

p e r i o d w h i c h was a y e a r, and j u s t b e f o r e t h e y e a r was up I was t r a n s f e r r e d t o t h e A t l a n t a s t a t i o n. I s t a y e d t h e r e. t e r s. T h e r e was one r e s i d e n t i n s p e c t o r o u t o f t h e w h o l e s t a t i o n and h e was i n J a c k s o n v i l l e. c o u p l e o f weeks. And so i t went, a c o u p l e o f weeks a t a t i m e w i t h each o f t h e o t h e r i n s p e c t o r s who had more e x p e r i -. A l t h o u g h, I m i g h t add t h a t i t depended on d i f f e r e n t i n s p e c t o r s y o u w o u l d go o u t. as any f o r m a l t r a i n i n g, by t h i s t i m e t h e r e was, i n t h e manual a s e c t i o n w i t h r e s p e c t t o t h e d r u g i n s p e c t i o n. o f q u i n i n e s u l f a t e. A r o u n d t h a t time t h e r e was a r e a l s h o r t a g e o f q u i n i n e y o u know

---

### Comparison of interlaboratory computational simulations… [^64493443]. FDA (2025). Medium credibility.

Tetrahedral {16), Hexahedral, Polyhedral Min:

0. **53, Max**:
76. **5, Mean**:

11. 6. Median:

9. **4 Min**:
0. **42, Max**:

60. **7, Mean**:
9. **9, Median**:

2.
8. CFD Quadrant I Quadrant2 PIV E = ~ f 2 n., max t = l □ ■Steady 100 ■Tran s i ent.
80. 0. 60 i: ., ~ 0 40 20 0 I 2 □ 140 ■k- < 0 SST 120. ■R ca li, able k-e
100. W 60 40 20 0 I 2 3 4 Test Condition 3 4 Test Condition 5 5 6 6 Common Interpolation Mesh □ 40% ■ Quadrant 1 ■ Quadrant 2 35% ■ Diffuser. Participant Number 40% □ ■Steady 35% ■Tra. t 30% 1o 25% 0 ~ 20% ~ 15% ¢ IO% 5% oo;. Quadrant 1. resolution mesh and a global error 5 for Quadrant 1, Quadrant 2, and the Diffuser was calculated. Where 'u' was either the PIV or CFD velocity. strongly correlated with accuracy was: not Condition 5's global error for A. quadrant 1, quadrant 2, and the Results i Pressure Compar A B son Large predict variability in CFD i across all condi ons was tions.

-k-ω SST -realizable k-ε -Spalart-Allmaras Figure 3: Percent error associated with CFD pump pressure head.

---

### Guidelines for handling decedents contaminated with radioactive materials [^3c500666]. CDC (2007). Medium credibility.

Rule of Seven for radiation dose rates — fallout dose rate after a detonation can be calculated and estimated as follows: "Dose rate = Initial dose rate × t⁻¹.²", and "the dose rate decreases by a factor of 10 for each sevenfold increase in time following a fission detonation"; this rule "is valid for only the first 2 weeks after a detonation", and "rain accelerates the decrease". Table values indicate percentage of initial dose rate remaining of 100% at 0 hour, 10% at 7 hours, 1% at 49 hours (2 days), and 0.1% at 343 hours (14 days).

---

### Infectious Diseases Society of America guidelines on the treatment and management of patients with COVID-19 (September 2022) [^b531c121]. Clinical Infectious Diseases (2024). High credibility.

IDSA COVID-19 guidelines — convalescent plasma: Section last reviewed and updated on 2/22/2023. Last literature search conducted 1/31/2023. Recommendation 13 (UPDATED 2/22/2023): Among immunocompetent patients hospitalized with COVID-19, the IDSA guideline panel recommends against COVID-19 convalescent plasma. (Strong recommendation, Moderate certainty of evidence). Recommendation 14 (NEW 2/22/2023): Among immunocompromised patients hospitalized with COVID-19, the IDSA guideline panel suggests against the routine use of COVID-19 convalescent plasma. (Conditional recommendation, very low certainty of evidence). Patients, particularly those who do not qualify for other treatments, who place a higher value on the uncertain mortality reduction and a lower value on the potential adverse effects of convalescent plasma would reasonably select convalescent plasma.

---

### Infectious Diseases Society of America guidelines on the treatment and management of patients with COVID-19 (September 2022) [^4dd6952a]. Clinical Infectious Diseases (2024). High credibility.

Clinical evaluation — Clinical evaluation should consider patient and pathogen specific factors that can influence choice of COVID-19 treatments, and at minimum should include assessment of severity of COVID-19, date of onset of symptoms, and risk factors for progression to severe disease or death.

---

### Shear wave elastography for breast masses is highly reproducible [^185ac940]. European Radiology (2012). Low credibility.

Quantitative intraobserver reproducibility of SWE features

Intraobserver reliability of size measurements on SWE using the RUBI system was almost perfect, with ICC ≥ 0.94 for diameter, perimeter and area across the three acquisitions (Table 4). Intraobserver reliability of quantitative elasticity measurements on the SWE images performed with the Q-Box quantification tool was also almost perfect for the mean and maximum elasticity values. Emean was the most reliable measurement of elasticity, with ICC = 0.87, and Emin was the least reliable (ICC = 0.71).

Table 4
Intraobserver reliability of quantitative shear wave elastography measurements for 614 benign and 144 malignant breast masses

a Diameter was the largest measurement of the mass

b Perimeter was the length of the border of the mass

c E minimum mass was the minimum value in the Q-box of the mass as calculated by the system

d E maximum mass was the maximum value in the Q-box of the mass as calculated by the system

e E mean mass was the mean value in the Q-box of the mass as calculated by the system

f E ratio (mass:fat) was the ratio between the mean elasticity value in the mass divided by the mean elasticity value in the fat

g E minimum fat was the minimum value of the Q-box in the fat

h E maximum fat was the maximum value of the Q-box in the fat

i E mean fat was the mean value of the Q-box in the fat

The reliability of SWE measurements of fat was lower than that for SWE measurements of masses. Intraobserver reliability was consistently higher for all measured SWE features of benign masses than of malignancies (Table 4).

---

### 2024 update of the North American Consensus guidelines for pediatric administered radiopharmaceutical activities [^8bf2a923]. Journal of Nuclear Medicine Technology (2025). High credibility.

Somatostatin receptor imaging — 68Ga-DOTATATE uses 2.0 MBq/kg (0.054 mCi/kg) with minimum 14 MBq (0.38 mCi) and maximum 200 MBq (5.4 mCi); 68Ga-DOTATOC uses 1.59 MBq/kg (0.043 mCi/kg) with minimum 11.1 MBq (0.30 mCi) and maximum 111 MBq (3 mCi).

---

### Red blood cell transfusion: 2023 AABB international guidelines [^ebbef0ce]. JAMA (2023). Excellent credibility.

Rationale for recommendations for adults states, 'The panel recommends that RBC transfusions be administered using a restrictive transfusion strategy of 7 g/dL for most hemodynamically stable adults (strong recommendation, high certainty evidence)', and adds that 'there is no strong clinical or biological basis for expecting different effects between 7 and 8 g/dL'.

---

### Cefuroxime [^4ad4369c]. FDA (2022). Medium credibility.

Impaired Renal Function:

A reduced dosage must be employed when renal function is impaired. Dosage should be determined by the degree of renal impairment and the susceptibility of the causative organism (see Table 2).

When only serum creatinine is available, the following formula1(based on sex, weight, and age of the patient) may be used to convert this value into creatinine clearance. The serum creatinine should represent a steady state of renal function.

Females: 0.85 x male value

NOTE: As with antibiotic therapy in general, administration of Cefuroxime for Injection should be continued for a minimum of 48 to 72 hours after the patient becomes asymptomatic or after evidence of bacterial eradication has been obtained; a minimum of 10 days of treatment is recommended in infections caused by Streptococcus pyogenes in order to guard against the risk of rheumatic fever or glomerulonephritis; frequent bacteriologic and clinical appraisal is necessary during therapy of chronic urinary tract infection and may be required for several months after therapy has been completed; persistent infections may require treatment for several weeks; and doses smaller than those indicated above should not be used. In staphylococcal and other infections involving a collection of pus, surgical drainage should be carried out where indicated.

Pediatric Patients Above 3 Months of Age:

Administration of 50 to 100 mg/kg/day in equally divided doses every 6 to 8 hours has been successful for most infections susceptible to cefuroxime. The higher dosage of 100 mg/kg/day (not to exceed the maximum adult dosage) should be used for the more severe or serious infections.

In bone and joint infections, 150 mg/kg/day (not to exceed the maximum adult dosage) is recommended in equally divided doses every 8 hours. In clinical trials, a course of oral antibiotics was administered to pediatric patients following the completion of parenteral administration of Cefuroxime for Injection.

In cases of bacterial meningitis, a larger dosage of Cefuroxime for Injection is recommended, 200 to 240 mg/kg/day intravenously in divided doses every 6 to 8 hours.

In pediatric patients with renal insufficiency, the frequency of dosing should be modified consistent with the recommendations for adults.

Preparation of Solution and Suspension:

The directions for preparing Cefuroxime for Injection, Pharmacy Bulk Package, are summarized in Table 5.

---

### Triazolam [^59f91090]. FDA (2025). Medium credibility.

WARNING: RISKS FROM CONCOMITANT USE WITH OPIOIDS; ABUSE, MISUSE, AND ADDICTION; and DEPENDENCE AND WITHDRAWAL REACTIONS

Concomitant use of benzodiazepines and opioids may result in profound sedation, respiratory depression, coma, and death. Reserve concomitant prescribing of these drugs in patients for whom alternative treatment options are inadequate. Limit dosages and durations to the minimum required. Follow patients for signs and symptoms of respiratory depression and sedation [see Warnings and Precautions (5.1), Drug Interactions (7.1)].
The use of benzodiazepines, including triazolam, exposes users to risks of abuse, misuse, and addiction, which can lead to overdose or death. Abuse and misuse of benzodiazepines commonly involve concomitant use of other medications, alcohol, and/or illicit substances, which is associated with an increased frequency of serious adverse outcomes. Before prescribing triazolam and throughout treatment, assess each patient's risk for abuse, misuse, and addiction [see Warnings and Precautions (5.2)].
The continued use of benzodiazepines, including triazolam, may lead to clinically significant physical dependence. The risks of dependence and withdrawal increase with longer treatment duration and higher daily dose. Abrupt discontinuation or rapid dosage reduction of triazolam after continued use may precipitate acute withdrawal reactions, which can be life-threatening. To reduce the risk of withdrawal reactions, use a gradual taper to discontinue triazolam or reduce the dosage [see Dosage and Administration (2.3), Warnings and Precautions (5.3)].

WARNING: RISKS FROM CONCOMITANT USE WITH OPIOIDS; ABUSE, MISUSE, AND ADDICTION; and DEPENDENCE AND WITHDRAWAL REACTIONS

See full prescribing information for complete boxed warning.

Concomitant use of benzodiazepines and opioids may result in profound sedation, respiratory depression, coma, and death. Reserve concomitant prescribing of these drugs in patients for whom alternative treatment options are inadequate. Limit dosages and durations to the minimum required. Follow patients for signs and symptoms of respiratory depression and sedation (5.1, 7.1).
The use of benzodiazepines, including triazolam, exposes users to risks of abuse, misuse, and addiction, which can lead to overdose or death. Before prescribing triazolam and throughout treatment, assess each patient's risk for abuse, misuse, and addiction (5.2).
Abrupt discontinuation or rapid dosage reduction of triazolam after continued use may precipitate acute withdrawal reactions, which can be life-threatening. To reduce the risk of withdrawal reactions, use a gradual taper to discontinue triazolam or reduce the dosage (2.3, 5.3).

---

### Changes in Chlamydia prevalence and duration of infection estimated from testing and diagnosis rates in england: a model-based analysis using surveillance data, 2000–15 [^06aa0bbb]. The Lancet: Public Health (2018). Medium credibility.

Background

Chlamydia screening programmes have been implemented in several countries, but the effects of screening on incidence, prevalence, and reproductive sequelae remain unclear. In England, despite increases in testing with the rollout of the National Chlamydia Screening Programme (NCSP; 2003–08), prevalence estimated in 10-yearly population-based surveys was similar before (1999–2001) and after (2010–12) the programme. However, the precision of these previous estimates was limited by the low numbers of infections. We aimed to establish annual, rather than 10-yearly, estimates of chlamydia prevalence and infection duration.

Methods

In this model-based analysis, we used previously published minimum and maximum estimates and Public Health England data for chlamydia test coverage and diagnoses in men and women aged 15–24 years in England, before, during, and after the scale-up of national chlamydia screening. We used a mechanistic model, which accounted for symptomatic chlamydia testing and asymptomatic screening, to estimate changes in prevalence and average duration of infections for each year. We describe estimates derived from the maximum and minimum numbers of tests and diagnoses as maximum and minimum estimates, regardless of their relative magnitude.

Findings

The data included numbers of tests and diagnoses in men and women aged 15–19 years and 20–24 years in England each year from 2000 to 2015. We estimated reductions in prevalence and average infection duration in both sexes once screening was fully implemented. From 2008 to 2010, estimated posterior median prevalence reductions in people aged 15–24 years were 0.68 percentage points (95% credible interval 0.26–1.40; minimum) and 0.66 percentage points (0.25–1.37; maximum) for men and 0.77 percentage points (0.45–1.27) for women (minimum and maximum estimates were the same for women). Over the same time period, mean duration of infection reduced by 75 days (95% credible interval 17–255; minimum) and 74 days (95% credible interval 17–247; maximum) in men and 30 days (22–40) in women. Since 2010, some of the progress made by the NCSP has been reversed, alongside a reduction in testing.

Interpretation

Our analysis provides the first evidence for a reduction in chlamydia prevalence in England concurrent with large-scale population testing. It also shows a consistent decline in the average duration of infections, which is a measure of screening effectiveness that is unaffected by behavioural changes.

Funding

National Institute for Health Research, Medical Research Council.

---

### Statistical considerations in the evaluation of continuous biomarkers [^c7960d51]. Journal of Nuclear Medicine (2021). Medium credibility.

Discovery of biomarkers has been steadily increasing over the past decade. Although a plethora of biomarkers has been reported in the biomedical literature, few have been sufficiently validated for broader clinical applications. One particular challenge that may have hindered the adoption of biomarkers into practice is the lack of reproducible biomarker cut points. In this article, we attempt to identify some common statistical issues related to biomarker cut point identification and provide guidance on proper evaluation, interpretation, and validation of such cut points. First, we illustrate how discretization of a continuous biomarker using sample percentiles results in significant information loss and should be avoided. Second, we review the popular "minimal- P -value" approach for cut point identification and show that this method results in highly unstable P values and unduly increases the chance of significant findings when the biomarker is not associated with outcome. Third, we critically review a common analysis strategy by which the selected biomarker cut point is used to categorize patients into different risk categories and then the difference in survival curves among these risk groups in the same dataset is claimed as the evidence supporting the biomarker's prognostic strength. We show that this method yields an exaggerated P value and overestimates the prognostic impact of the biomarker. We illustrate that the degree of the optimistic bias increases with the number of variables being considered in a risk model. Finally, we discuss methods to appropriately ascertain the additional prognostic contribution of the new biomarker in disease settings where standard prognostic factors already exist. Throughout the article, we use real examples in oncology to highlight relevant methodologic issues, and when appropriate, we use simulations to illustrate more abstract statistical concepts.

---

### 2022 American society of anesthesiologists practice guidelines for management of the difficult airway [^5298d89c]. Anesthesiology (2022). High credibility.

Difficult airway — consensus-based evidence and survey scoring indicates validation by consensus from survey opinion from expert consultants, survey opinions from randomly selected samples of active members of the American Society of Anesthesiologists (ASA) and participating organizations, and internet commentary, with only findings from formal surveys reported. Survey responses were recorded using a five-point scale and summarized based on median values, with categories defined as: strongly agree median score of 5 (at least 50% of the responses are 5), agree median score of 4 (at least 50% of the responses are 4 or 4 and 5), equivocal median score of 3 (at least 50% of the responses are 3, or no other response category or combination of similar categories contains at least 50% of the responses), disagree median score of 2 (at least 50% of responses are 2 or 1 and 2), and strongly disagree median score of 1 (at least 50% of responses are 1). When an equal number of categorically distinct responses are obtained, the median value is determined by calculating the arithmetic mean of the two middle values, and ties are calculated by a predetermined formula.

---

### Massive computational acceleration by using neural networks to emulate mechanism-based biological models [^2c01f625]. Nature Communications (2019). High credibility.

To identify the minimum size of dataset needed for accurately making predictions, we trained deep LSTM network on different training dataset sizes. The RMSEs are calculated based on predictions of a fixed test dataset, which contains 20,000 samples. Figure 2c demonstrates how the RMSEs of distributional data and peak values decrease with the increase of training data size. Since the x -axis is log-scaled, when the dataset size is beyond 10⁴, the rate of error reduction becomes asymptotically smaller. When the data size is 10⁵, the RMSE value decreased below a preset threshold (0.3), when we deemed a prediction to be accurate. In general, depending on specific models and the acceptable tolerance of errors, the threshold can be set differently, which could require different data sizes for effective training. This training dataset size is manageable and results in sufficient accuracy for our analysis. Based on error tolerance and numerical data generation efficiency, one can choose the desired dataset size for training the neural network. With an ensemble of deep neural networks, which will be described in the next section, the errors can be further reduced without increasing the dataset size.

---

### Practice guidelines for perioperative blood management: an updated report by the American society of anesthesiologists task force on perioperative blood management* [^5cd8c130]. Anesthesiology (2015). Medium credibility.

Perioperative blood management — opinion-based evidence and survey methodology state that all opinion-based evidence was considered, but only formal survey findings are reported; identical surveys were distributed to expert consultants and a random sample of ASA members. Category A: Expert Opinion and Category B: Membership Opinion responses are summarized in the text and listed in appendix 2, and responses are recorded using a 5-point scale and summarized by median values, defined as follows: Strongly Agree, median score of 5 (At least 50% of the responses are 5); Agree, median score of 4 (At least 50% of the responses are 4 or 4 and 5); Equivocal, median score of 3 (At least 50% of the responses are 3, or no other response category or combination of similar categories contain at least 50% of the responses); Disagree, median score of 2 (At least 50% of responses are 2 or 1 and 2); Strongly Disagree, median score of 1 (At least 50% of responses are 1). Category C: Informal Opinion is informally evaluated and discussed during formulation of recommendations, and when warranted the Task Force may add educational information or cautionary notes; when ties occur, the median is determined by calculating the arithmetic mean of the two middle values.

---

### Parallels in the sequential organization of birdsong and human speech [^4955ccdb]. Nature Communications (2019). High credibility.

To segment song bouts into syllables, we computed the spectral envelope of each song spectrogram, as the sum power across the Mel-scaled frequency channels at every time-sample in the spectrogram. We defined syllables operationally as periods of continuous vocalization bracketed by silence. To find syllables, we first marked silences by minima in the spectral envelope and considered the signal between each silence as a putative syllable. We then compared the duration of the putative syllable with an upper bound on the expected syllable length for each species. If the putative syllable was longer than the expected syllable length, it was assumed to be a concatenation of two or more syllables which had not yet been segmented, and the threshold for silence was raised to find the boundary between those syllables. This processes repeated iteratively for each putative syllable until it was either segmented into multiple syllables or a maximum threshold was reached, at which point it was accepted as a long syllable. This dynamic segmentation algorithm is important for capturing certain introductory whistles in the European starling song, which can be several times longer than any other syllable in a bout.

Several hyperparameters were used in the segmentation algorithm. The minimum and maximum expected lengths of a syllable in seconds (ebr_min, ebr_max) were set to 0.25/0.75 s. The minimum number of syllables (min_num_sylls) expected in a bout was set to 20. The maximum threshold for silence (max_thresh), relative to the maximum of the spectral envelope was set to 2%. To threshold out overly noisy song, a minimum length of silence threshold was expected in each bout (min_silence_for_spec), set at 0.5 s. The base spectrogram (log) threshold for power considered to be spectral background noise (spec_thresh) was set at 4.0. This threshold value was set dynamically, where the minimum spectral background noise (spec_thresh_min) was set to be 3.5.

---

### Cefuroxime sodium [^cbab6c8e]. FDA (2025). Medium credibility.

Impaired Renal Function

A reduced dosage must be employed when renal function is impaired. Dosage should be determined by the degree of renal impairment and the susceptibility of the causative organism (see Table 2).

When only serum creatinine is available, the following formula1(based on sex, weight, and age of the patient) may be used to convert this value into creatinine clearance. The serum creatinine should represent a steady state of renal function.

NOTE: As with antibiotic therapy in general, administration of Cefuroxime for Injection should be continued for a minimum of 48 to 72 hours after the patient becomes asymptomatic or after evidence of bacterial eradication has been obtained; a minimum of 10 days of treatment is recommended in infections caused by Streptococcus pyogenes in order to guard against the risk of rheumatic fever or glomerulonephritis; frequent bacteriologic and clinical appraisal is necessary during therapy of chronic urinary tract infection and may be required for several months after therapy has been completed; persistent infections may require treatment for several weeks; and doses smaller than those indicated above should not be used. In staphylococcal and other infections involving a collection of pus, surgical drainage should be carried out where indicated.

Pediatric Patients Above 3 Months of Age

Administration of 50 to 100 mg/kg/day in equally divided doses every 6 to 8 hours has been successful for most infections susceptible to cefuroxime. The higher dosage of 100 mg/kg/day (not to exceed the maximum adult dosage) should be used for the more severe or serious infections.

In bone and joint infections, 150 mg/kg/day (not to exceed the maximum adult dosage) is recommended in equally divided doses every 8 hours. In clinical trials, a course of oral antibiotics was administered to pediatric patients following the completion of parenteral administration of Cefuroxime for Injection.

In cases of bacterial meningitis, a larger dosage of Cefuroxime for Injection is recommended, 200 to 240 mg/kg/day intravenously in divided doses every 6 to 8 hours.

In pediatric patients with renal insufficiency, the frequency of dosing should be modified consistent with the recommendations for adults.

---

### Roflumilast (Zoryve) [^11a5acd0]. FDA (2024). Medium credibility.

The dosage of roflumilast TOP for treatment of plaque psoriasis in both children (in patients 6–12 years) is 1 application(s) TOP daily (0.3% cream)

---

### 2024 update of the North American Consensus guidelines for pediatric administered radiopharmaceutical activities [^7a89f490]. Journal of Nuclear Medicine Technology (2025). High credibility.

Blood pool and infection imaging — 99mTc-RBC (red blood cell) for blood pool imaging uses 11.8 MBq/kg (0.32 mCi/kg) with minimum 74 MBq (2 mCi) and maximum 740 MBq (20 mCi); 99mTc-WBC (white blood cell) for infection imaging uses 7.4 MBq/kg (0.2 mCi/kg) with minimum 74 MBq (2 mCi) and maximum 555 MBq (15 mCi).

---

### Recommendations for a standardized pulmonary function report. An official American Thoracic Society technical statement [^d6d8fcbc]. American Journal of Respiratory and Critical Care Medicine (2017). Medium credibility.

Spirometry reporting specifies that numerical values are given for the FEV1, the FVC, and the FEV1/FVC ratio; the latter should be reported as a decimal fraction and the space for percent predicted value left blank, and if bronchodilators are given the LLN column need not be repeated with absolute and percent change given only for FEV1 and FVC. Other numerical values such as the forced inspiratory flow at 75% of FVC (FEF75%) and FEF25–75% are not recommended for routine use. Graph requirements include that for the volume–time curve the volume scale should be at least 10 mm/L, the time scale at least 20 mm/s, and 1 second prior to the start of expiration should be displayed; on the flow–volume plot the flow display should be at least 5 l/min/L/s, and the ratio of flow to volume should be 2 L/s to 1 L, and linear and log scales where values are plotted as z-scores relative to the predicted value (z = 0) give an intuitive sense of severity.

---

### Roflumilast (Zoryve) [^e2de6cd7]. FDA (2024). Medium credibility.

The dosage of roflumilast TOP for treatment of plaque psoriasis in adults is 1 application(s) TOP daily (0.3% cream or foam)

---

### Practice guidelines for the prevention, detection, and management of respiratory depression associated with neuraxial opioid administration: an updated report by the American society of anesthesiologists task force on neuraxial opioids and the American Society of Regional Anesthesia and Pain Medicine [^c7d4883b]. Anesthesiology (2016). Medium credibility.

American Society of Anesthesiologists neuraxial opioid guideline — evidence grading and opinion methodology: Category B observational evidence permits directional inference, and for studies that report statistical findings, "the threshold for significance is P < 0.01"; Category B levels comprise "observational comparisons… with comparative statistics" (Level 1), "noncomparative observational studies with associative statistics" (Level 2), "noncomparative observational studies with descriptive statistics" (Level 3), and "case reports" (Level 4). Opinion-based inputs include formal surveys and informal sources; survey types are designated "Category A: Expert Opinion" and "Category B: Membership Opinion", with additional "Category C: Informal Opinion". Survey responses "are recorded using a five-point scale and summarized based on the median values", with median categories defined as follows: "Strongly Agree: Median score of 5 (at least 50% of the responses are 5)… Agree: Median score of 4 (at least 50% of the responses are 4 or 4 and 5)… Equivocal: Median score of 3 (at least 50% of the responses are 3, or no other response category or combination of similar categories contain at least 50% of the responses)… Disagree: Median score of 2 (at least 50% of responses are 2 or 1 and 2)… Strongly Disagree: Median score of 1 (at least 50% of responses are 1)". When equal numbers of distinct responses occur, "the median value is determined by calculating the arithmetic mean of the two middle values".

---

### SCCT guidelines on radiation dose and dose-optimization strategies in cardiovascular CT [^6e4c62f3]. Journal of Cardiovascular Computed Tomography (2011). Medium credibility.

ECG-based tube current modulation in helical cardiovascular CT — operation, benefits, and limitations are summarized as follows: Although retrospective ECG-gated helical scanning occurs throughout the cardiac cycle, images are reconstructed only during a specified cardiac phase, prompting algorithms that modulate tube current so it is fully applied during the most relevant phases and reduced or even shut off during remaining phases. When a reduced (but nonzero) tube current is applied during certain phases, data remain available but image quality is limited during periods of low current; thin-slice reconstruction (< 1 mm) is restricted to maximum tube current windows, though multi-phase image series for functional evaluation may still be possible, and thicker slices can decrease excessive noise. X-ray exposure during retrospective ECG-gated helical CT can be reduced ≥ 50% depending on heart rate, the minimum tube current value, and the duration of the maximum tube current phase. ECG-based tube current modulation imposes limitations in patients with irregular heart rates because averaging of previous R-R intervals can unintentionally lower tube current during desired phases, though several manufacturers have developed strategies to increase robustness for irregular heart rates.

---

### Corrections [^e34f1524]. The Lancet: Respiratory Medicine (2016). Medium credibility.

[This corrects the article DOI: 10.1016/S2213-2600(15)00283–0.].

---

### Peyronie's disease: AUA guideline [^b5a39ca2]. The Journal of Urology (2015). Medium credibility.

Peyronie's disease — surgical plication adverse events are reported with study counts and percent ranges, including urethral laceration (7 studies; minimum percent 0.00, maximum percent 4.35), urinary retention (4; minimum percent 1.40, maximum percent 16.70), hematoma (9; minimum percent 0.00, maximum percent 10.91), wound infection (13; minimum percent 0.00, maximum percent 6.70), and persistent erectile or penile pain post-surgery (8; minimum percent 0.00, maximum percent 27.60).

---

### Minimum required distance for clinically significant measurement of habitual gait speed [^2c900bea]. BMC Geriatrics (2025). Medium credibility.

Change of uncertainty with measured distance

A 5-m walk video of a skeleton with 14 key points was extracted from each recording using our pose estimation algorithm. This was further edited by cropping at 0.1-m intervals to generate 4.9- to 1.0-m segments. One 5.0-m walk video generated two 4.9-m segments, three 4.8-m segments, and so forth, up to 41 segments for a 1.0-m walk, culminating in 861 segments of varying distance (Fig. 2b, c).

The variability of gait speed across the measured distances was defined as the within-subject standard deviation (WSD) for each measured distance, calculated as the square root of the mean-square error in a one-way analysis of variance, where groups combined subjects with distance intervals. Three gait speed data from three measurements were collected for each group to avoid underestimating within-subject variation due to overlapping distances when distance intervals are not considered. For example, for a 4.7-m walk, four gait speed measurements were obtained at 4.7-m distances (0–4.7, 0.1–4.8, 0.2–4.9, and 0.3–5.0 m), and within-subject variation at a 4.7-m distance was estimated by considering different distance intervals.

Determination of minimum required distance

To determine the minimum required distance, we utilized WSD at each measured distance. Given that confidence intervals (CI) quantify variability, we computed the half-width of the CI using WSD and the critical value corresponding to the chosen confidence level. Specifically, the 95% CI was calculated as 1.96 × WSD, and the 90% CI as 1.64 × WSD. For the measurement to be clinically meaningful, the half-width of the CI, reflecting gait speed variability, had to remain below the MCID of 0.1 m/s. Thus, the minimum required distance was defined as the shortest distance at which this criterion was met, ensuring that gait speed measurements remained within an acceptable range of variability.

---

### Non-linear relationships between daily temperature extremes and US agricultural yields uncovered by global gridded meteorological datasets [^e807bdf6]. Nature Communications (2024). High credibility.

Supplementary Fig. 1 also assesses the impact of differences in the temporal scale of the climate data. Temporally aggregating ERA5-Land from hourly temperature readings to daily minimum and maximum temperature before calculating degree days using a sine interpolation between minimum and maximum temperature negligibly reduces RMS, suggesting that the sub-daily hourly records do not provide important additional information. Taken together, a global data set on minimum and maximum temperature correctly identifies the importance of temperature extremes and provides yield predictions that closely mirror more fine-scaled weather data.

One qualification of our findings is that some global weather data sets, such as GMFD, assimilate the weather station network of a country, which is dense in the United States. Other countries have fewer stations and the global weather data sets accordingly might be worse at capturing temperature extremes. Figure 4 explores this issue by comparing yield predictions in locations with and without weather stations in Sub-Saharan Africa. We find that ERA5-Land, which relies on satellite measurements rather than weather station networks, is unsurprisingly unaffected by the proximity of weather stations. GMFD, which incorporates station data, shows a slight, but statistically significant, increase in predictive power when we subset our data to only locations near weather stations. However, this increase is small relative to the overall reduction in RMS associated with weather variables provided by GMFD, providing suggestive evidence that GMFD is also well-suited for estimating yield impacts in Sub-Saharan despite low weather station density relative to the United States.

---

### Healthy housing reference manual [^d4c68057]. CDC (2006). Medium credibility.

Reducing heat loss and condensation — window energy efficiency metrics are defined. The energy efficiency of windows is measured in terms of their U-values (measure of the conductance of heat) or their R-values.

---

### Correction [^348be4e7]. BMJ Quality Improvement Reports (2017). Medium credibility.

[This corrects the article DOI: 10.1136/bmjquality.u212617.w5031.].

---

### Defining the time-limited trial for patients with critical illness: an official American Thoracic Society workshop report [^cf1ee11e]. Annals of the American Thoracic Society (2024). High credibility.

Time-limited trial in critical care — essential elements and phased process were derived through a Delphi process: investigators "identified 18 potential steps" and found first-round consensus that "11 of these were essential elements"; during the second round, they "identified seven additional essential elements". The committee then "combined 4 related items into two steps (to reach 16 essential elements)" and "organized steps into four phases of care: consider, plan, support, and reassess". Additional steps "may be helpful in some cases, but not necessary for all trials", and involvement of other disciplines is "highly dependent on a patient's specific situation and on the available hospital resources".