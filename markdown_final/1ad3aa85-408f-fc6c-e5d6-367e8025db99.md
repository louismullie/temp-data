# Medical Question & Answer

**Sample ID**: 1ad3aa85-408f-fc6c-e5d6-367e8025db99
**Dataset Index**: 236035

---

## Question

## Problem Statement

Find the point of intersection of the line and the plane.

[(x − 1)/−2] = [(y − 2)/1] = [(z + 1)/−1]
x − 2y + 5z + 17 = 0

---

## Answer

> Let's see… What do we have here? The user is asking how to find the point of intersection of a line and a plane. Let's break this down step-by-step. First, I need to think about converting the symmetric line equations into parametric form. Then, I should substitute those parametric expressions into the plane equation to solve for the parameter. Next, I will back-substitute the parameter value into the parametric equations to get the intersection coordinates. Finally, I should verify the solution by plugging the point back into both the line and plane equations to ensure consistency.

> Let me first confirm the line's parametric representation. The symmetric form ([(x − 1)/−2] = [(y − 2)/1] = [(z + 1)/−1]) implies a direction vector (d = (−2, 1, −1)) and a point on the line (P₀ = (1, 2, −1)), so the parametric equations are (x = 1–2t), (y = 2 + t), and (z = -1 - t), where (t) is a real parameter [^notfound].

> Wait, let me verify the plane equation before substituting. The plane is given as (x - 2y + 5z + 17 = 0), so I should substitute the parametric expressions for (x), (y), and (z) into this equation to find the value of (t) at intersection [^notfound].

> I will now substitute the parametric forms into the plane equation: ((1–2t) - 2(2 + t) + 5(-1 - t) + 17 = 0). Expanding this gives (1–2t - 4–2t - 5–5t + 17 = 0), which simplifies to (-9t + 9 = 0), so (t = 1). Hold on, I should double-check the arithmetic: (1–4–5 + 17 = 9) and (-2t - 2t - 5t = -9t), so yes, (t = 1) is correct [^notfound].

> Next, I should review the back-substitution to get the intersection point. Plugging (t = 1) into the parametric equations yields (x = 1–2(1) = -1), (y = 2 + 1 = 3), and (z = -1–1 = -2), so the intersection point is ((-1, 3, -2)) [^notfound].

> I need to ensure this point satisfies both the line and the plane. Let me first confirm it lies on the line: substituting into the symmetric form gives ([(-1 − 1)/−2] = [(3 − 2)/1] = [(-2 + 1)/−1]), which simplifies to (1 = 1 = 1), so the point is on the line. Now, I should confirm it lies on the plane: ((-1) - 2(3) + 5(-2) + 17 = -1–6–10 + 17 = 0), which checks out. Hmm, wait a minute, I initially thought the plane check might fail, but the math confirms the point satisfies the plane equation as well [^notfound].

---

The line and plane intersect at the point **(-1, 3, -2)**. To find this, I parameterized the line as (x = 1–2t), (y = 2 + t), (z = -1 - t) and substituted into the plane equation (x - 2y + 5z + 17 = 0), solving for (t = 1). Plugging (t = 1) back into the parametric equations gives the intersection point.

---

## Step 1: Parametrize the line

The symmetric equations of the line are:

[(x − 1)/−2] = [(y − 2)/1] = [(z + 1)/−1]

Let each ratio equal a parameter (t):

[(x − 1)/−2] = t ⇒ x = 1−2t

[(y − 2)/1] = t ⇒ y = 2 + t

[(z + 1)/−1] = t ⇒ z = −1 − t

So the parametric form is:

x = 1−2t, y = 2 + t, z = −1 − t

---

## Step 2: Substitute into the plane equation

The plane equation is:

x − 2y + 5z + 17 = 0

Substitute the parametric expressions for (x), (y), and (z):

(1−2t) − 2(2 + t) + 5(−1 − t) + 17 = 0

Simplify:

1−2t − 4−2t − 5−5t + 17 = 0

(1−4−5 + 17) + (−2t − 2t − 5t) = 0

9−9t = 0

---

## Step 3: Solve for the parameter (t)

9−9t = 0 ⇒ 9t = 9 ⇒ t = 1

---

## Step 4: Find the intersection point

Substitute (t = 1) back into the parametric equations:

x = 1−2(1) = −1

y = 2 + 1 = 3

z = −1−1 = −2

Thus, the intersection point is **(-1, 3, -2)**.

---

## Verification

Plug (-1, 3, -2) into the plane equation to verify:

(−1) − 2(3) + 5(−2) + 17 = −1−6−10 + 17 = 0

The point satisfies the plane equation, confirming the solution.

---

The line and plane intersect at **(-1, 3, -2)**.

---

## References

### Using both qualitative and quantitative data in parameter identification for systems biology models [^fc71653e]. Nature Communications (2018). Medium credibility.

Results

An illustration of the potential value of qualitative data

To demonstrate the potential value of qualitative data, we consider a simple case of solving for the coefficients of polynomial functions.

We consider two polynomial functions: y 1 = ax 2 − bx + c and y 2 = dx + e. Suppose we want to solve for the coefficients a, b, c, d, and e, which we will take to be positive. As the ground truth coefficients to be determined, we choose (a, b, c, d, e) = (0.5, 3, 5, 1, 1.5).

Suppose that a limited amount of quantitative information is available. Namely, it is known that the parabola y 1 contains the points (2, 1) and (8, 13), and the line y 2 contains the point (3.5,5). This is not enough information to solve for any of the coefficients because three points are required to specify a parabola, and two points are required to specify a line (Fig. 1a).

Fig. 1
A simple illustration using polynomial functions. We use qualitative and quantitative information to determine the unknown coefficients. a Visualization of the problem. We seek to find the coefficients of equations for a parabola and a line, with the ground truth shown (blue solid curves). Two points on the parabola and one point on the line are known (black dots). These three points are consistent with infinitely many possible solutions (e.g. orange dashed curves). Qualitative information (colored circles, x -axis) specifies whether the parabola is above (+) or below (−) the line. This information limits the possible values of intersection points x 1 and x 2 to the green shaded segments of the x -axis. b Bounds on coefficient values as a function of the number of qualitative points known. Shaded areas indicate the range of possible values of each coefficient

---

### Quenched disorder and instability control dynamic fracture in three dimensions [^5de46dc7]. Nature Communications (2024). High credibility.

The average crack velocity

A central quantity in this work is the average crack front velocity v. In the presence of quenched disorder, the crack front does not generally remain a continuous line propagating in a 3D space. As extensively shown above, not only can it be seriously distorted and meander out of the symmetry plane, but it actually undergoes various topological changes as the crack develops localized branches, hierarchal facets, segmentation and more. In view of these complex structures, the average crack front velocity v is operationally defined as follows: at each point in time t, the crack is defined through the phase-field ϕ (x, t) = 1/2 iso-surface. Then, we find the intersection of this iso-surface with the x– y plane associated with every z value. The intersection point with the largest x coordinate (the crack propagates in the positive x direction) corresponds to the front position f (z, t) = (f x (z, t), f y (z, t)). Finally, the average crack front velocity v (t) is obtained as the z -average of ∂ t f x (z, t), i.e. When the crack reaches a statistical steady state, v (t) features a plateau that defines the steady-state velocity v (for each G), accompanied by temporal fluctuations, as demonstrated in Fig. 7.

Fig. 7
An example of the time evolution of the average crack front velocity.

The average crack front velocity v (t)/ c s, as defined in the text, plotted against c s t / ξ for G / Γ 0 = 2.25 (with our generic quenched disorder parameters σ = 0.25 and R = 10 ξ). It is observed that after an initial acceleration phase, the crack settles into a statistical steady state (defining the mean velocity v per G, accompanied by temporal fluctuations), where our analysis is performed. Source data are provided as a Source Data file.

---

### Kinetic features dictate sensorimotor alignment in the superior colliculus [^5f54a1d3]. Nature (2024). Excellent credibility.

Next, we need to find the coordinates ofin the inertial reference frame once the head rotation has occurred:

With x, y and z corresponding to the components of the eye vector in the inertial frame.whereand.

Now, we need to find the intersection ofwith the plane defined in Equation (6) at times t and t + d t:

To find the point of intersection, we can substitute thecomponent in the equation of the plane and compute the coefficient m. Starting with Equation (6):

In order to have a better perspective of the track that the intersection ofwith the screen at different times produces, we treat each of the intersection points as the endpoint of a vector with its base at the inertial frame origin. Then we can rotate these vectors around the z axis of the inertial frame with a desired angle to have a better view. In other words, it is as if we have rotated the screen with that angle, since the relative geometry of the points on the screen would not change after this rotation. In order to perform this rotation, we use a Rodrigues' rotation formula:Where v is the vector of intersection points and β is the rotation angle around theaxis. If we pick, we practically rotate the screen such that it becomes parallel toandaxes of the inertial frame and perpendicular to.

In the above treatment, the gaze vectoris fixed in the head frame. However, this is not correct as the pupil would move in the head frame. In order to correct for this effect, we simultaneously recorded eye and head rotations in mice during foraging, as described, and implemented the pupil rotations in the head frame to our model. This effectively makes the direction of the gaze dependent on pitch, roll and yaw. In mathematical terms, in Equation (7) we would make the correction:

The rest of the transformations follows as before. The correction rotation matrix in head frame, was computed from the head–eye rotations measured and represented in Extended Data Fig. 9f, g.

---

### Finding the right angle: a geometric approach to measuring intersectional HIV stigma [^b29c9770]. AIDS and Behavior (2022). Medium credibility.

Intersectionality has emerged as theoretically and practically important to advancing HIV stigma research. However, few psychometric measures capture the intricacies of intersectional stigma. Grounded in the HIV stigma framework and contemporary theories of intersectionality, this paper describes a novel approach to conceptualizing the measurement of intersectional stigma. Taking the notion of an intersection literally, that is the point at which two or more lines meet and form a union, we offer a geometric conceptualization for developing a psychometric instrument to measure intersectional stigma. Ratings of stigmatized attributes, such as stigma ascribed to gender, race, sexual orientation, and HIV status are assessed on independent scales to calculate their intersection using the Pythagorean Theorem, c = √(a² + b²) and its extension to multiple stigmatized attributes d = √(a² + b² + c²). Data from a sample of Black /African American women living with HIV were used to test the concept of a geometric approach to measuring intersectional enacted stigma and intersectional anticipated stigma. Findings from the test of concept were encouraging and warrant further scale development research.

---

### Sensitivity and spectral control of network lasers [^ad9cccab]. Nature Communications (2022). High credibility.

A derivative-free, greedy iterative algorithm was used to find the optimised pump patterns. Firstly, a coarse grid (8 × 5 grid with each pixel corresponding to 60 × 60 μ m 2 size on sample) was used. Starting from the pixel closest to the centre of the grid, each pixel was switched off consecutively and the change in the intensity of the selected lasing mode was calculated using the recorded spectral counts. For a given lasing peak p, we calculated the following quality function at each optimisation step n :where a n is the ratio of the intensity of the selected lasing peak p to the average intensity of the top M strongest lasing peaks (M = 10 in our experiments), all under pump pattern n. If Φ n > 0, the pump on that pixel was kept off, otherwise it was switched back on, and the routine was iterated. The final pattern from a first run was then fed as the initial pattern for a subsequent re-run with a finer grid (patch sizes of 30 × 30 μ m 2) for further optimisation.

Numerical construction of Buffon graphs

Buffon graphs were generated by drawing lines on a plane at random points with random slope. The intersections of all the lines within a square region on the plane were obtained and the length of the line segments between intersections calculated. If a segment length was smaller than a minimum distance of 1 μ m, the intersection points were merged together to the median point. The final set of intersection points and line segments was then used to specify the graph vertices and adjacency matrix. The Buffon graphs used for numerical calculations were constructed to be similar to the polymer nanofiber networks, with 96 nodes, 131 edges, average degree 4, and mean edge length 23.8 μ m.

---

### To infinity and some glimpses of beyond [^d42883f3]. Nature Communications (2017). Medium credibility.

Methods

Complexification of ordinary differential equations

The complexified version(z = x + iy) leads to the two-dimensional dynamical system:

The real axis is an invariant subspace, retrieving our real results; yet complexification endows the dynamics with an intriguing capability: as Fig. 4a, b illustrates through the (x, y) phase plane, collapse is avoided in the presence of a minuscule imaginary part. Large elliptical-looking trajectories are traced on the phase plane, eventually returning to the neighborhood of the sole fixed point of (0, 0) — which in the real case one would characterize as semi-stable. The system of Eq. (19) can be tackled in closed form since the ODEyields 1/ z = − t + 1/ z (0). For z = x + iy (z (0) = x 0 + iy 0) we obtain the explicit orbit formulaEliminating time by dividing the two ODEs within Eq. (19) directly yields an ODE for y = y (x) (rather than the parametric forms of Eqs. (20), (21)). From this ODE, one can obtain that the quantityis an invariant of the phase plane dynamics, and thus the latter can be written as x 2 + (y − R) 2 = R 2, where. That is, the trajectory evolves along circles of radius R in the upper (resp. lower) half plane if y 0 > 0 (resp. y 0 < 0.) Approaching the axis with y 0 → 0, the curvature of these circles tends to 0 and their radius to ∞ (retrieving the real dynamics as a special case). Figure 4 through its planar projections illustrates not only the radial projection of the dynamics in the x − y plane, but the x − t and y − t dependencies.

---

### Superconductivity and a van hove singularity confined to the surface of a topological semimetal [^e858a2ef]. Nature Communications (2025). High credibility.

Results

We begin our discussion with an examination of the electronic band structure of ZrAs 2. ZrAs 2 belongs to the nonsymmorphic space group Pnma (No. 62) (Fig. 1a), which is known to host Dirac nodal lines; the sample characterization data can be found in Supplementary Figs. 1–3. Figure 1b illustrates the bulk and (001) surface projected Brillouin zone. In Fig. 1c, we present the electronic band structure (in the absence of spin-orbit coupling), revealing metallic behavior with both electron- and hole-like bands crossing the Fermi level. The partially filled bulk bands yield two hole-like Fermi surface pockets (and) and one electron-like Fermi surface pocket (Fig. 1 d and e). This is consistent with our experimental findings exposing three peaks in the FFT spectrum from quantum oscillatory measurements (see Supplementary Information Section I and Supplementary Fig. 4, 5). Examining the energy bands along the X → Γ, Γ → Z, and X → U → Z directions, we identify multiple band crossings, labeled as NL1, NL2, NL3, and NL4 between the magenta and cyan bands and NL5 between the green and magenta bands as shown in Fig. 1c. The electronic band structure calculations characterize ZrAs 2 as a nodal line semimetal with four nodal loops protected by the mirror M y and glide mirror (G x and G z) planes. Figure 1f plots the nodal loops/lines in the k x - k y - k z space, with black dots marking the nodal points along high-symmetry directions; the color bar shows the location of the nodes in energy. The distribution of the nodes (red lines) in the k z = 0 plane is illustrated in Fig. 1g. A pair of concentric intersecting coplanar ellipses from half-filled bands form a butterfly-like nodal loop around the U (π, 0, π) -point (Fig. 1h), as previously suggested.

---

### Standardization of spirometry 2019 update. An official American Thoracic Society and European Respiratory Society technical statement [^df365e99]. American Journal of Respiratory and Critical Care Medicine (2019). High credibility.

Back-extrapolated volume (BEV) on the volume–time curve — Time 0 is found by drawing a line with a slope equal to peak flow through the point of peak flow on the volume–time curve and setting Time 0 to the point where this line intersects the time axis. The BEV is equal to the volume of gas exhaled before Time 0, which, in these two examples from the same patient, is 0.136 L for the left panel (acceptable) and 0.248 L for the right panel (unacceptable). For this patient, the BEV limit is 5% FVC = 0.225 L.

---

### Pixel super-resolution with spatially entangled photons [^90794571]. Nature Communications (2022). High credibility.

Analytical derivation of Γ k k and Γ k k +1

We consider an unidimensional object t (x) illuminated by photon pairs using a near-field illumination configuration. Photon pairs are characterised by a two-photon wavefunction Ψ t (x 1, x 2) in the object plane. JPD values Γ k l are measured using an array of pixels with pitch Δ and gap δ. Assuming that the imaging system is not limited by diffraction but only by the sensor pixel resolution, its point spread function can be approximate by a Dirac delta function and Γ k l can be formally written as:where we assumed unity magnification between object and camera planes. A graphical representation of this integral is shown in Fig. 5 c. For clarity, we only represented an array of three pixels. The bivariate function ∣ t (x 1) t (x 2)∣ 2 is represented in green and overlaps with an grid of squares of size Δ and spacing δ. Each square represents an integration area associated to a specific JPD value. For example, the central square corresponds to the integration area of Γ k k i.e. In addition, the bivariate function ∣Ψ t (x 1, x 2)∣ 2 is represented by two dashed black lines. These two lines delimit the most intense part of the function, which corresponds to a diagonal band of width σ using a double Gaussian model.

We seek to calculate the JPD values Γ k k and Γ k k +1. Graphically, these values are located at the intersection between the grid, the green area and the surface inside the dashed lines. They are represented in blue and red, respectively. For small widths σ < Δ, it is clear in Fig. 5 c that the blue and red integration areas are tightening around the positions (x k, x k) and (x k +1/2, x k +1/2) positions, which results in Γ k k ~ ∣ t (x k)∣ 4 and Γ k k +1 ~ ∣ t (x k +1/2)∣ 4. More formally, one can also apply a change of variable and perform a first-order Taylor expansion in Eq. 6 to reach the same results:whereand S 1 ≈ σ 2 /2. Full calculations are provided in section 2.5 of the supplementary document. Note also that the difference between integration areas S 1 ≠ S 2 makes the normalization step after calculating the JPD projection necessary (see Methods section Normalization).

---

### Multiple tipping points and optimal repairing in interacting networks [^48be4231]. Nature Communications (2016). Medium credibility.

The problem of optimal repairing

Knowing and understanding the phase diagram of interacting networks enable us to answer some fundamental and practical questions. A partially or completely collapsed system of n ≥ 2 interacting networks in which some of them are in the low activity state is a scenario common in medicine, for example, when diseases or traumas affect the human body and a few organs are simultaneously damaged and need to be treated, and the interaction between the organs is critical. It is also common in economics, when two or more coupled sectors of the economyexperience simultaneous problems, or when a few geographical clusters of countries experience economic difficulties. The practical question that arises is: what is the most efficient strategy to repair such a system? Many approaches are possible if resources are unlimited, but this is usually not the case and we would like to minimize the resources that we spend in the repairing process.

For simplicity, consider two interacting networks, both damaged (low activity). Is repairing both networks simultaneously the more efficient approach, or repairing them one after the other? What is the minimum amount of repair needed to make the system fully functional again? In other words, what is the minimum number of nodes we need to repair, to bring the system to the functional 11 ('up–up') state, and how do we allocate repairs between the two networks? An optimal repairing strategy is essential when resources needed for repairing are limited or very expensive, when the time to repair the system is limited, or when the damage is still progressing through the system, threatening further collapse, and a quick and efficient intervention is needed.

We show below that this problem is equivalent to finding the minimum Manhattan distance between the point in the phase diagram where the damaged system is currently situated and the recovery transition lines to the 11 region. The Manhattan distance between two points is defined as the sum of absolute horizontal and vertical components of the vector connecting the points, with defined vertical and horizontal directions. It is a driving distance between two points in a rectangular grid of streets and avenues. In our phase diagram, it is equal to. It turns out that two triple points of the phase diagram play a very important role in this fundamental problem. We find that these special points have a direct practical meaning and are not just a topological or thermodynamic curiosity.

---

### Easy-to-actuate multi-compatible Truss structures with prescribed reconfiguration [^b0752f52]. Nature Communications (2024). High credibility.

Fig. 1
Schematic diagram for designing a multi-stable truss structure and its actuation design.

a Literature survey of different types of the multi-stable structures in terms of their number of designable stable states and the number of actuators needed for the reconfiguration. Heavy lines in different colors bound the upper limits of performance of the corresponding researches. b Illustration of the formation of multi-compatibility. (I) One four-bar linkage goes through three prescribed coupler-link configurations, denoted by the reference point P and its orientation θ. (II) Another four-bar linkage goes through the same prescribed coupler-link configurations as (I). A dissembled dyad with geometric and kinematic parameters is shown on the right. (III) Rigidly connect the couplers of these two four-bar linkages, then the union becomes an immovable structure and is multi-compatible at three prescribed coupler-link configurations P 1, P 2, P 3, represented by the intersections of the trajectories of two four-bar linkages in (I) and (II). There are two more path intersections in the 2D plot, U and N. When considering the rotation of the coupler link to plot trajectories in 3D space in the blue dashed box, only the point U is an intersection, i.e. a compatible state. c Illustration of minimum-energy-path (MEP) finding method connecting specified stable states by regarding the bars as elastic translational springs and employing Nudged Elastic Band (NEB) method, where initially linearly sampled configurable points iteratively move towards the valleys of the energy landscape. d Illustration of one actuation design method by finding two nodes (R and S) on the structure where the distance L in between decreases monotonically along the computed MEP, and consequently, a simple actuation by shortening the distance between these two nodes can be applied so that the structure might reconfigure along the computed path and reach the desired stable states without being bifurcated and falling into wrong stable states.

---

### A new method for calculating femoral anterior cortex point location and its effect on component sizing and placement [^76598f52]. Clinical Orthopaedics and Related Research (2015). Low credibility.

Fig. 1
Diagram showing the calculation of the DAA (midline of the femoral shaft distal one-third) and two mechanical axes (MA-1 = line connecting femoral head center and knee center; MA-2 = line connecting femoral head center and distal exit point of the DAA).

Two anterior cortex points were computed. First, the sizing point was defined as the saddle point, where the curve of the femur changes from convex to concave. This replicated the normal surgical practice of using a sizing guide. Second, the femoral resection anterior cortex (FRAC) point was defined as the point between the lowest and highest point on the lateral ridge that generates the most complete anterior resection contour (ie, prevents notching) and restores a balanced AP cut.

Implant sizing and placement for seven different designs were determined using landmarks. To find the proper implant size and placement, AP height was used to pick an initial implant size with the closest matching AP. The implant was placed using an anterior referencing technique with 0° internal/external rotation, 0° flexion/extension, and 0° varus/valgus. This method was selected to create a computer model of standard surgical practice. For component placement, we used three different longitudinal axes (MA-1, MA-2, and DAA) and three rotational measurements (PCA, PCA+3° of external rotation [PCA+3], and TEA). Final placement was performed using PCA+3 and MA-1. On placing the component, bone models were intersected with the implant cutting planes and a three-dimensional (3-D) contour was extracted, which was then flattened and used to calculate the bone footprint. The bone footprint was then evaluated against the implant footprint to calculate overhang and underhang in the mediolateral direction (Fig. 2). Thresholds of 1.5 mm overhang and 2 mm underhang were used to refine the implant size. These values were selected to simulate reasonable threshold allowances without compromising surgical outcome and to further refine our computer model of real-life surgical practice. The effect of using the computed FRAC point and the average point between the highest and lowest points on the lateral ridge was investigated. The resected bone thicknesses were measured on the anterior and posterior aspects of the femur for both the medial and lateral sides for each implant family. The four measurements included the anterior medial, anterior lateral, posterior medial, and posterior lateral thickness. The following angles between different alignments axes were computed to investigate the difference in axis alignment: (1) angle between PCA and TEA; (2) flexion/extension angle between MA-1 and DAA; (3) varus/valgus angle between MA-1 and DAA; (4) varus/valgus angle between MA-1 and MA-2; and (5) flexion/extension angle between MA-1 and MA-2.

---

### The trochlear sulcus of the native knee is consistently orientated close to the sagittal plane despite variation in distal condylar anatomy [^f9bf6bda]. Knee Surgery, Sports Traumatology, Arthroscopy (2023). Medium credibility.

Fig. 1
Constructions on the left femur of a representative CT bone model. A Coordinate system established on each femur, with + Z (blue) pointing superior along the mechanical axis, + Y (green) pointing anterior perpendicular to the surgical transepicondylar axis, + X (red) pointing lateral, centred at the apex of the intercondylar notch. B The trochlear sulcus axis was established as the line crossing the centre of this circle and parallel to the cylindrical axis. A total of eleven coaxial cutting planes rotated equally about the trochlear sulcus axis were created. Each coaxial cutting plane was defined by the percentage along the arc of the trochlear sulcus with 0% and 100% intersecting the most anteroproximal and posterodistal points, respectively

The trochlear sulcus was characterized according to previously described methods (Fig. 1 B). A circle was best fit to the trochlear sulcus in the sagittal plane (Fig. 1 B). The trochlear sulcus axis was established as the line crossing the centre of this circle and parallel to the cylindrical axis (Fig. 1 B). A total of eleven coaxial cutting planes rotated equally about the trochlear sulcus axis were created (Fig. 1 B). Each coaxial cutting plane was defined by the percentage along the arc of the trochlear sulcus with 0% and 100% intersecting the most anteroproximal and posterodistal points, respectively (Fig. 1 B). The deepest point of the trochlear sulcus was found at the cross-section of each cutting plane. The connection of the deepest point of each cross section was collectively defined by the sulcus (Fig. 2 A). Each point was then transferred to the coronal plane using a roll-out projection (Fig. 2 A), as described previously in the literature. With this process, the distance between points in the sagittal plane as well as the mediolateral distance of each point to the sagittal plane was maintained (Fig. 2 A).

---

### Low polyethylene creep and wear following mobile-bearing unicompartmental knee replacement [^92e1cacb]. Knee Surgery, Sports Traumatology, Arthroscopy (2021). Medium credibility.

Unpaired t tests were used to determine whether significant differences in the wear rate existed by the method of fixation (cemented vs. cementless). Pearson Correlation was used to test the association of wear rate with BMI, age, 5-year Oxford Knee Score (OKS) and Tegner activity score. The association of component size (tibial or femoral) with wear rate was tested with an ANOVA.

Bearing overhang beyond the tibial component and bearing distance from the tibial vertical wall were determined using the femoro-tibial contact point, as the bearing is not visible on stereo-radiographs. The femoro-tibial contact point was defined where joint space was narrowest and reflects the centre position of the bearing due to the spherical design of the femoral component and the fully congruent bearing. The bearing was assumed to be parallel with the tibial wall. Medial bearing overhang was noted when the distance between the femoro-tibial contact point and the medial edge of the tibial component was less than the distance from the centre to the medial edge of the bearing. The area of bearing overhanging the medial edge was found by fitting curves to the medial edges of the bearing base and the tibial component. If these curves intersected, they were integrated between the intersection points to find the area between the curves (Fig. 2). The distance from the lateral edge of the bearing to the vertical tibial wall in millimetres was also calculated. If this was found to be negative the bearing was considered to be impinging on the wall.

Fig. 2
Method for calculating the area of bearing overhang from RSA data. The bearing can exhibit no medial overhang in the coronal plane but overhang at the anterior or posterior margins of the tibial component is still possible. Both Medial Overhang and Area Overhang calculations are done with the assumption that the bearing is parallel with the wall of the tibial component

The area of the femoral component in contact with the upper surface of the bearing was also estimated. This was done by making the centre of the sphere that intersects with the upper surface of the bearing the origin of a spherical coordinate system, defining the border of the bearing surface (azimuth and elevation, in radians) and finding the femoral component coordinates that lay within this border. The area of the upper surface of the bearing occupied by the femoral component in radians squared was converted to millimetres squared using the radius of the sphere. As with the estimation of tibial overhang, this was done with an assumption that the bearing was parallel with the wall of the tibial component.

---

### 3D-FVS: construction and application of three-dimensional fundus vascular structure model based on single image features [^844c2c47]. Eye (2023). Medium credibility.

Vascular structure surface model

Considering the optic disc was one of the widest research areas in ophthalmic related diseases, our method only studied on it and these areas were labelled by a professional doctor firstly. In this stage, the methods used to build vascular structure surface models were the same as which was implemented in SimVascular, a software used to construct hemodynamic model in the following steps. Firstly, this method required to extract the centreline and downsample the points on it. Then the radius of cross-section corresponding to the point will be calculated and circles with these points as the centre will be drawn. Finally, these contours will be connected smoothly to form the vascular structure surface model.

This study utilized the Zhang-Suen thinning algorithm to skeletonize the segmented fundus vascular images. Each iteration step of this algorithm was to corrode the target pixels satisfying certain conditions. This algorithm was iteratively executed until no new pixels were corroded. The output of this skeletonization step was illustrated in Supplementary Fig. 1a. Then all the points on the skeleton line will be traversed for finding the coordinates of the endpoints and intersections of the skeleton line, as shown in Supplementary Fig. 1b, by calculating the number of points near the point with the size of 3 × 3 area. When the points on the skeleton line were too dense, it will lead to the intersection between the corresponding contours of every two points (which was shown in Fig. 2j), and the blood vessel modelling process cannot be completed at this time. Therefore, downsample was used to prevent intersections between the corresponding contours of every two feature points by removing points in a fixed number of intervals.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^6517cbfd]. Annals of the American Thoracic Society (2023). High credibility.

Basic stereological measurements — first-order parameters and probes identify that "First-order parameters are volume (three-dimensional [3D]), surface (two-dimensional [2D]), length (one-dimensional [1D]), and number (zero-dimensional [0D])". Measurements "are performed using geometric test probes, such as points (0D), lines (1D), planes (2D), or volumes (3D)". These probes create countable events in the image, and "Raw counts provide ratios… that are multiplied by the reference space volume to obtain absolute measures for the lung or subcompartment".

---

### Ventricular septum curvature ratio: a novel imaging marker to predict clinical deterioration in normotensive acute pulmonary embolism [^70cee2d7]. Critical Care (2025). Medium credibility.

Measurement of VS curvature ratio and VS deviation to LV in CTPA

The CTPA imaging protocols are detailed in Supplementary Method S1. CTPA reconstructions were performed using the Mimics Medical software (version 19.0, Mimics Medical Software, Leuven, Belgium). The short-axis view of the RV was reconstructed using double-oblique multiplanar reformation. For VS bowing to the RV, the VS curvature ratio was calculated as the ratio of the VS curvature radius to the LV free wall curvature radius (Fig. 1 A). VS curvature ratio was segmented according to its curve-fitting relationship with deterioration risk. As VS curvature radius increasing until a point where no curvature radius can be calculated, VS straight & bowing to the LV was defined (Fig. 1 B). For VS bowing to the RV, the following measurements were taken: (1) locating the two intersection points between the VS and the LV free wall, and use them as common points for measuring the curvature radii of the VS and the LV free wall. (2) finding the third point, which can be combined with the first two intersection points to create a circle that best fits the VS, and then calculate the VS curvature radius. (3) finding the fourth point, which can be combined with the first two intersection points to create a circle that best fits the LV free wall, and then calculate the LV free wall radius (Fig. 1 C).

Fig. 1
Measurement method of measurement VS curvature ratio and typical examples. (A) VS bowing to RV and VS curvature ratio was 1.16, which was calculated as VS curvature radius (34.1 mm)/LV free wall radius (29.35 mm) at double oblique plane; (B) VS straightness and VS bowing to LV at double oblique plane; (C) Segmentation of VS and LV free wall to measure VS curvature ratio at double oblique plane. VS, ventricular septum; LV, left ventricle; RV, right ventricle

Supplementary Figure S2 and Supplementary Appendix outline a simplified method for measuring the three side lengths of the triangle inscribed in the LV to calculate the VS curvature. This method allows the VS and LV free wall curvature radius to be measured using Picture Archiving and Communication Systems (PACS), which are commonly available in most hospitals (Supplementary Video).

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^075005b9]. Magnetic Resonance in Medicine (2021). Medium credibility.

Regions A and B are geometrically symmetric about the z = 0 plane, with minimum energy solutions (assuming no E‐field constraint) yielding z‐symmetric field solutions and zero B 0 concomitant fields. Hence, the open diamond starting point (representing the minimum energy solution with no E‐field constraints) for the solid and dashed curves (in both black and green cases) coincide. The symmetry is broken by the addition of a patient model with an E‐field constraint.

The knee in the curves marks the point where magnetic energy, current density, and winding complexity increase rapidly as E max is driven to lower values. These complexities render unrealizable or impractical any gradient designs on the vertical portions of the curves to the left of the knee. Examination of winding patterns indicates that solutions that exhibit energy increases > 25% (or even less depending on coil type) above the global minimum energy become unrealizable (eg, demonstrating two or more "eyes" per half coil [four or more total eyes for an x or y coil] in the fingerprint wire patterns).

The red and purple dotted curves in Figure 2 represent two practical cases in which the primary coil currents are restricted to a single inner surface near the patient and the shield coil currents to an outer cylinder, while at the same time adding torque and eddy current constraints. Line segments acd of Figure 1 represent a primary winding surface consisting of a cone and a cylinder, whereas line segment ab represents its cylindrical shield winding; this yields designs similar to those proposed by previous literature 8, 22 and results in the red dotted curves in Figure 2. A second case is defined by restricting primary currents to the cylinder represented by line segment cd and shield currents to the cylinder ab; this yields designs similar to those proposed by previous literature 28 and produces the purple dotted curves in Figure 2. For both configurations, the eddy current surface is a 1‐m‐long, 620‐mm‐diameter cylinder, centered about the gradient isocenter and placed outside the shield winding of the gradient coil. The time = 0 eddy current error is constrained to a peak deviation less than 0.1% of the ideal gradient field on the surface of a 20‐cm‐diameter volume, corresponding to 100 µT for a 1 T/m step change in gradient strength. The torque constraint is set to zero for a uniform z‐directed B 0 main magnetic field. There is no net force for a perfectly uniform main B 0 field in all calculations.

---

### Multiple tipping points and optimal repairing in interacting networks [^806c4333]. Nature Communications (2016). Medium credibility.

To optimize repairing we need to minimize this metric. Figure 5 shows the solution to the minimization problem and a detailed discussion is provided in the Methods section. The different colours in Fig. 5 correspond to the different optimal repair strategies, which depend on the failure state of the system. If the system is initially at point S 1, both networks are in a low activity state, that is, they are non-functional. Our goal is to decreaseand, and arrive to the region where the system is fully recovered (the green region) by performing a minimal number of repairs, that is, minimal N rep. We find that for any point in the red region there are actually two closest points in the green region, at an equal Manhattan distance away from the red region point. These two points are the triple points R1 and R2 shown in Fig. 5, which also correspond to the triple points in Fig. 2b. Although R1 may be closer to point A than R2 by Euclidian distance, the Manhattan distance is the same. Thus, two equally good repairing strategies are available. One involves allocating more node repairs to network A and the other allocating more repairs to network B. For the yellow regions (points S 2 and S 3), the closest points by Manhattan distance are R1 (for point S 2) or R2 (for point S 3). Here, only one triple point represents the optimal solution. It is noteworthy that the path samples in Fig. 5 are 'zig-zag' in shape (to highlight that we are minimizing); however, even when a diagonal path (direct straight line) to a triple point is used, the Manhattan distance is the same. For the dark blue regions (points S 4 and S 7), the optimal strategy is to decreaseonly, until the system is recovered. Similarly, for the light blue regions (points S 5 and S 6), the optimal strategy is to decrease only.

From our optimal repairing strategy analysis we find that the order of repair (the specific path taken between the initial point and final point) does not affect the final result. Minimizing the Manhattan distance only determines the optimal destination point. Therefore, there is actually a set of paths corresponding to equally optimal repairing processes.

---

### Spatially expandable fiber-based probes as a multifunctional deep brain interface [^501d9654]. Nature Communications (2020). High credibility.

After the scaffolding fiber is fabricated, an array of multifunctional fibers was inserted into the hollow channels of the scaffold. The scaffolding fiber is used to guide individual functional fibers as well as to alter the direction of the inserted fibers when exiting the scaffold. As illustrated in Fig. 2g, h, the employment of the spatially expandable fiber probes involves two steps during the implant surgery. First, we lower the scaffold to a predetermined depth of the brain and apply Metabond ® to fix the scaffolding fiber on the skull (Fig. 2g). Second, we further extrude the multifunctional fiber arrays through the scaffold by a calculated length until they reach their targeted locations (Fig. 2h) and fix the whole device onto the skull using a dental cement. The penetration depth of the fiber is controlled by the depth of the scaffolding fiber, the extrusion length of the inserted fiber, as well as the extrusion angle of the scaffold. The location of the inserted fiber can be further confirmed by the equation shown in Fig. 2i. For the fiber inserted into the center hole, it will stay straight when exiting the scaffold. The center point of the helix bottom is set to be the origin of the coordinates. The scaffolding fiber (Fig. 2e) comprises four helixes that intersect with the XY plane at (a, 0, 0), (0, a, 0), (− a, 0, 0), and (0, − a, 0), respectively. For the Helix A (acosθ, asinθ, hθ/2π), a is the radius, θ is the twisting angle of the scaffolding fiber, and h is the pitch of this circular helix. L is the length of the inserted fiber that is in direct contact with brain tissue. The point of the inserted fiber that intersects with the XY plane is defined as A 0 (a, 0, 0) and the endpoint of the inserted fiber is defined as A (X 1, Y 1, Z 1). As the inserted functional fiber that exits the scaffold will naturally form a tangent line to the Helix A, X 1 equals a. Based on a given value of a, L, θ, and h, the coordinates of the endpoint of the inserted fiber A (X 1, Y 1, Z 1) can be calculated by two θ -independent equations:and. Similarly, the locations of the inserted fiber that comes from Helix B (− asinθ, acosθ, hθ/2π), Helix C (−acosθ, −asinθ, hθ/2π), and Helix D (asinθ, −acosθ, hθ/2π) that intersects with XY plane at B (0, a, 0), C (− a, 0, 0), and D (0, − a, 0) are, and, respectively. Further calculation is needed for transferring the coordinates to the commonly used ones relative to bregma depending on how the scaffolding fiber is placed. As these coordinates suggest, we can observe a pattern that the diagonal lines of these four points are perpendicular to each other in the XY plane and the intersecting point of these two diagonal lines would determine where the scaffolding fiber should be placed in the XY plane.

---

### Engineering phase and polarization singularity sheets [^d73719c8]. Nature Communications (2021). High credibility.

Fig. 2
Comparison between phase gradient maximization and field minimization to obtain phase singularities.

Both methods can be used to obtain phase singularities, but they produce different field behavior in terms of its real (blue) and imaginary (red) zero-isosurfaces. Yellow dots label the positions at which the field and phase gradients are optimized. Inset surface plots are the logarithmically scaled field intensities at z = 0 μm over the same XY domain. The z = 0 μm plane is indicated with the gray plane in each isosurface plot. a When the phase gradient in a specified direction is maximized, the two zero-isosurfaces align approximately tangentially and in the direction normal to that specified gradient. This produces a flat low field intensity structure along these aligned zero-isosurfaces. b Minimizing the field amplitude at a point to produce a singularity merely enforces a crossing of the zero-isosurfaces without any alignment, producing a 1D line singularity. c Simultaneously optimizing two nearby points with directed phase gradients can extend the range of the singularity sheet. d Minimizing the field amplitude at two points simultaneously does not guarantee alignment of the zero-isosurfaces and can instead produce multiple crossing lines, each producing a 1D line singularity.

---

### Caliper-based precise positioning of the target (CALIPPOT) for transcranial magnetic stimulation without neuronavigation system [^03ee1dc2]. General Psychiatry (2024). Medium credibility.

Step 3. Positioning the scalp target

First, set the distance of the outside callipers as measured on the MRI images. Then, two experimenters simultaneously placed one end of the outside calliper at the centre of two marks (eg, M1 and M2), drew an arc with the other end of the outside calliper simultaneously on the scalp, and then could find out the intersection point. This intersection point was the scalp target, that is, T1'. This scalp target T1' was then marked on the scalp with a marker pen. Since the current method relies on calculating the Euclidean distance between at least two marks and the target for localisation, it necessitates the use of at least two callipers for measurements. It is not feasible for a single operator to simultaneously perform measurements on the scalp to find the intersection, which could pose potential safety risks to the subjects and lead to inaccurate localisation. Therefore, our method currently requires the involvement of two operators.

Step 4. Validation of the scalp target

This step was just like step 3 but used the other two marks (eg, M1 and M3) and to find the intersection point, that is, the scalp target T2'. If the distance between T1' and T2' (ie, location error) is more than 3 mm, redo step 3 and step 4. If this location error is less than 3 mm, just use the midpoint between T1' and T2' as the scalp target for TMS.

---

### Degenerate boundaries for multiple-alternative decisions [^8ec71b12]. Nature Communications (2022). High credibility.

There are geometric implications of using sequential Bayesian inference as coordinates for n -dimensional decision trajectories (Fig. 1 a, b). Although the decision trajectories have n probability-coordinates, P n, they are constrained such that ∑ i P i (t) = 1; therefore, the decision trajectories populate (n − 1)D simplices. For example, 2AFC decision dynamics are represented as a particle constrained to have P 0 (t) + P 1 (t) = 1, which is the 1D line P 1 = 1 − P 0 on a 2D (P 0, P 1) plot of the beliefs. It follows that 3AFC dynamics take place on a 2D plane (Fig. 1 a) and 4AFC dynamics in a 3D tetrahedron (Fig. 1 b) and so forth. Note that if any hypothesis has zero probability P i (t) = 0, then the space in which the decision trajectory evolves collapses to the remaining non-zero directions. For example, each face of the 4-choice tetrahedron in Fig. 1 b is a combination of three choices with non-zero probabilities and each edge a combination of two such choices.

As a result, decision boundaries are (n − 2)-dimensional objects in n -dimensional probability space. So for n > 2 choices, boundaries can have spatial dependence with respect to the decision space visualized in Fig. 1 a, b. For 2AFC tasks, decision boundaries are points on a 2D line, which are simply the transformed boundaries (equation 2) of the standard two-choice integration-to-threshold model. Likewise, for 3AFC, the decision boundaries are lines on a plane (Fig. 1 a, dashed lines) and for 4AFC are planes within a tetrahedron (Fig. 1 a, dark gray planes). The example boundaries shown are flat with a constant decision threshold in each dimension. An interesting consequence is that high-dimensional boundaries can have a nonlinear structure as a function of the n -dimensional beliefs P. Then, the linear 3AFC boundaries (Fig. 1 a, dashed lines) generalize to curves and the planar 4AFC boundaries (Fig. 1 b, dark gray planes) generalize to curved surfaces.

---

### Iobenguane I-123 (Adreview) [^0479e97e]. FDA (2024). Medium credibility.

Step 1.	Visual Guidelines for AdreView Cardiac Uptake on Anterior Planar Chest Images

a. Normal:

Distinct visualization of the left ventricular myocardium in the left lower chest, with greater uptake in the heart than in the adjacent lungs and mediastinum (Figure 1).
Figure 1.	Normal anterior planar AdreView image of the chest
b.	Abnormal:

Homogeneously or heterogeneously decreased cardiac uptake, with indistinct or absent visualization of the left ventricular myocardium. Cardiac activity is usually less than or equal to that of the adjacent left lung (Figure 2a). In extreme cases, little or no AdreView uptake is seen in the left lower chest (Figure 2b).
Figure 2.	Abnormal anterior planar AdreView images of the chest: a) Heterogeneously reduced cardiac uptake; b) Absent cardiac uptake

Step 2.	Quantitate AdreView Cardiac Uptake

The AdreView H/M ratio is determined from the activity in heart (H) and mediastinum (M) regions of interest (ROIs) drawn on the anterior planar chest image (Figure 3) using the following procedure:

Draw an irregular ROI defining the epicardial border of the heart. If the epicardial border cannot be defined because all or the majority of the myocardium is not visualized, draw the ROI based upon the presumed location of the heart, using the medial aspects of the left and right lower lung for anatomical guidance.
Draw a horizontal line to mark the estimated location of the lung apices. If the most superior aspect of the image does not include the lung apices (because of limited field of view for a small gamma camera), draw this line at the top of the image display.
Draw a vertical line approximately equidistant from the medial aspects of the right and left lung.
Examine the counts for the 12 pixels along the vertical line starting 4 pixels below the intersection point with the horizontal line determined in step 2, and identify the pixel with the lowest counts. If more than one pixel has this same number of counts, choose the most superiorly located pixel.
Using the pixel defined in step 4 as the center, draw a square ROI of 7×7 dimensions.
Calculate the H/M ratio by dividing the counts/pixel in the total myocardium ROI determined in step 1 by the counts/pixel in the 7×7 pixel mediastinal ROI determined in step 5.

Figure 3. Illustration of creation of regions of interest for determination of the H/M ratio

---

### Short-and long-term survival prediction in patients with acute type A aortic dissection undergoing open surgery [^51bab4a4]. Journal of Cardiothoracic Surgery (2024). Medium credibility.

Fig. 2
Nomogram for predicting 1-/3- month and 1-/4- year survival of patients with ATAAD undergoing surgical repair

In this, we provide a practical case to demonstrate how to use this model. First, find the corresponding points on the point axis according to the patient's characteristics. For example, a patient is 67 years old, the corresponding points on the points axis are 40; the patient has a history of heart surgery, the corresponding points on the points axis are approximately 67; the patient does not have Marfan syndrome, the points obtained on the points axis are 0; the patient does not have a history of Nephritis, the corresponding points on the points axis are 0; the patient's WBC is 12.8 (× 10*9/L), then it belongs to WBC ≥ 10.45, and the corresponding points on the axis are 40; the patient's phosphorus is 0.73 (mmol/L) and belongs to the ≤ 1.4 category, then the points are 0; the patient has ≥ 2 ruptures, then it belongs to the YES category, and the score on the axis is 0; the patient's D dimer value is 23.94 (mg/L), then it belongs to the ≥ 4.4 category, so the points obtained are approximately 45; the patient's TBIL is 14, the corresponding points on the points axis are 14; then add up all the points to get the total points. In this example, the total points are 40 + 65 + 0 + 0 + 40 + 0 + 0 + 45 + 14 = 204. Next, find the point corresponding to 204 on the total points axis, then draw a line down from the total points obtained until it intersects with the survival probability axis. In this example, the final score is 204, the corresponding 1-month survival rate is approximately 76%, the 3-month survival rate is approximately 70%, the 1-year survival rate is approximately 63%, and the 4-year survival rate is approximately 60%.

---

### Fast 3D imaging of spine, dendritic, and neuronal assemblies in behaving animals [^19708917]. Neuron (2016). Low credibility.

3D DRIFT AO Scanning

We derived a one-to-one relationship between the focal spot coordinates and speed, and the chirp parameters of the four AO deflectors to move the focal spot along any 3D line, starting at any point in the scanning volume (Movie S1). We need the following three groups of equations: (1) the simplified matrix equation of the AO microscope (Figure S1 C; Equations S1–S4); (2) the basic equation of the AO deflectors (Equation S5); and (3) temporally non-linear chirps for the acoustic frequencies (f) in the deflectors deflecting in the x-z (and y-z) plane,(where i = 1 or i = 2 indicates the first and second x deflector, D is the diameter of the AO deflector, and v a is the propagation speed of the acoustic wave within the deflector). When we calculate and then combine the expression z x (t) (Equation S17) with x 0 (t), the similarly calculated z y (t), and y 0 (t), and add all the required initial positions (x 0, y 0, z 0) and speed parameter values (v x0, v y0, v zx0 = v zy0) of the focal spot, we can determine all the parameters required to calculate the non-linear chirps according to Equation 1 in the four AO deflectors (Δf 0x = f 1x (0,0) − f 2x (0,0), b x1, b x2, c x1, c x2 and Δf 0y = f 1y (0,0) − f 2y (0,0), b y1, b y2, c y1, c y2). The calculations and AO driver signal generation are detailed in the Supplemental Experimental Procedures (Equations S1–S70; Data S1, S2, and S3; Figure S3). We have summarized the calculations in Table S1.

---

### Multiple tipping points and optimal repairing in interacting networks [^ad1069fa]. Nature Communications (2016). Medium credibility.

Additional phase diagrams

Figure 8a shows the collection of stable solutions (solid blue lines) and unstable solutions (dashed red lines) for the activity z A = 1− a A of network A, with parameter values as used in Fig. 1a, but for a range of different values of. The solid black line indicates, the value ofused in Fig. 1a. Green circles in this figure correspond to the stable states found in Fig. 1a and red crosses correspond to the unstable solutions for z A form Fig. 1a. Figure 8b shows an analogous phase diagram for the parameters with values as in Fig. 8a, again for a range of.

Forbidden transitions

Transition lines for 12→21 and 21→12 do not appear in our phase diagram and it is quite easy to understand why. Let us assume that the transition line for 12→21 does exist. To obtain that transition, the idea would be to simultaneously increaseand decrease(that is, increase the damage in one part of the system and decrease in another part). Suppose we are in phase 12 and infinitesimally close to the supposed transition line. Considering the local geometry of this line, we may be able to observe its angle with respect to theaxis. If a transition occurs when increasingand decreasing, the tangent on the supposed line would have an angle of. From here, it follows that by increasingonly, while keepingconstant, we would also make a transition (cross the transition line). The only other possibility would be that we were moving along the transition line, but this is easy to disprove because it would imply that the transition does not depend on. If increasingonly causes a transition, the transition must end in state 22 and not in 21. This is because if we only increase, we increase damage to both network A (directly) and network B (indirectly, through the interdependent links).

---

### Advanced statistics: linear regression, part I: simple linear regression [^18239641]. Academic Emergency Medicine (2004). Low credibility.

Simple linear regression is a mathematical technique used to model the relationship between a single independent predictor variable and a single dependent outcome variable. In this, the first of a two-part series exploring concepts in linear regression analysis, the four fundamental assumptions and the mechanics of simple linear regression are reviewed. The most common technique used to derive the regression line, the method of least squares, is described. The reader will be acquainted with other important concepts in simple linear regression, including: variable transformations, dummy variables, relationship to inference testing, and leverage. Simplified clinical examples with small datasets and graphic models are used to illustrate the points. This will provide a foundation for the second article in this series: a discussion of multiple linear regression, in which there are multiple predictor variables.

---

### Relative projective location of three bottom apexes of petrous bone on skull [^5c45ca89]. The Journal of Craniofacial Surgery (2016). Low credibility.

The complex anatomy of petrous part of temporal bone makes the craniotomy around this area challenging. To avoid damaging the interior structures of petrous part of temporal bone, the authors used computed tomography to get the projection of the petrous part of temporal bone on skulls, making the external contours of petrous part clear, thus protecting its interior structure as a reference in craniotomy. The objective of this study was to find out the three-dimensional location of 4 points of petrous part of temporal bone. Parameters of 120 patients (240 observations) between 25 and 65 years who were free of abnormalities and pathological changes in temporal bone were measured on high-resolution spiral multiple slice computed tomographic multiple planar reconstruction images that were parallel to the base plane. The data were analyzed by SPSS, statistical software with the comparison between sides and sexes. The authors found the accurate locations that 4 points of petrous part of temporal bone with mastoidale as the origin. Then the authors connect the 3 vertexes of underside and the petrous apex and lengthen it until intersect with skulls to get the external landmarks. In the end, the authors get the safe range that can be applied to the clinical surgery.

---

### Inner core backtracking by seismic waveform change reversals [^5c56e336]. Nature (2024). Excellent credibility.

Estimating the reversal time

In Fig. 4, the starting and ending times of the repeaters with similar waveforms (red dots) separated by more than 10 years show distinct linearity. We apply a linear fitting to each part separately, allowing intercept times T 1 and T 2 in equations (1) and (2) to differ.where t beg and t end are the starting and ending times of the repeaters in years, and T 1 and T 2 are the intersections at the x -axis. T pred is the predicted time intervals of the repeaters. k 1 and k 2, the two linear coefficients, together with T 1 and T 2, are the parameters for which we run the grid-search process to fit the observed recurrence intervals. The misfit function is shown in equation (3). We use the L1 norm instead of L2 norm to better ignore the outliers in the dataset. The uncertainties of the parameters are estimated using the bootstrapping method. We randomly pick 15 (70%) from all the 22 data points, and run the grid-search process repeatedly for 1,000 times. The standard deviation is used to represent the uncertainty.

The best-fitting linear coefficients k 1 and k 2 are equal to −3.54 ± 0.27 and 1.42 ± 0.04, respectively. The fitting intersection at the x -axis T 1 is equal to 2008.37 ± 0.28, and T 2 is equal to 2008.58 ± 0.28, so T 1 is almost equal to T 2. The lines are shown in Fig. 4. By contrast, we force the T 1 to be equal to T 2 and rerun the grid-search process. Our best fit shows a time of reversal of about 2008.5 ± 0.18, which is similar to that in ref.using the PKIKP time shifts. And the linear coefficients k 1 and k 2 are equal to −3.42 ± 0.19 and 1.42 ± 0.03. The lines are shown in Extended Data Fig. 9. It is noted that the slopes of the fitting lines are proportional to the rotation rate; consequently, we interpret that the rotation rate after 2008.45 ± 0.19 is about 2.5 times slower than that before 2008.5.

---

### A structural transition in physical networks [^88210010]. Nature (2018). Excellent credibility.

In many physical networks, including neurons in the brain 1,2, three-dimensional integrated circuits 3 and underground hyphal networks 4, the nodes and links are physical objects that cannot intersect or overlap with each other. To take this into account, non-crossing conditions can be imposed to constrain the geometry of networks, which consequently affects how they form, evolve and function. However, these constraints are not included in the theoretical frameworks that are currently used to characterize real networks 5–7. Most tools for laying out networks are variants of the force-directed layout algorithm 8,9 -which assumes dimensionless nodes and links-and are therefore unable to reveal the geometry of densely packed physical networks. Here we develop a modelling framework that accounts for the physical sizes of nodes and links, allowing us to explore how non-crossing conditions affect the geometry of a network. For small link thicknesses, we observe a weakly interacting regime in which link crossings are avoided via local link rearrangements, without altering the overall geometry of the layout compared to the force-directed layout. Once the link thickness exceeds a threshold, a strongly interacting regime emerges in which multiple geometric quantities, such as the total link length and the link curvature, scale with the link thickness. We show that the crossover between the two regimes is driven by the non-crossing condition, which allows us to derive the transition point analytically and show that networks with large numbers of nodes will ultimately exist in the strongly interacting regime. We also find that networks in the weakly interacting regime display a solid-like response to stress, whereas in the strongly interacting regime they behave in a gel-like fashion. Networks in the weakly interacting regime are amenable to 3D printing and so can be used to visualize network geometry, and the strongly interacting regime provides insights into the scaling of the sizes of densely packed mammalian brains.

---

### 3D multimodal cardiac data reconstruction using angiography and computerized tomographic angiography registration [^86748190]. Journal of Cardiothoracic Surgery (2015). Low credibility.

As mentioned in step 1, the Intersection Tracking algorithm starts from a seed point for each LM, LAD, LCX and RCA arteries. Different conditions are considered for choosing them. As shown in the "Cardiovascular tree model" in Figure 16, LCA is started from LM artery. Axial ices are sought from top to bottom to find slice S i as LM's seed point, where LCA starts from the aorta and i is the number of slice. Then, the above Intersection Tracking algorithm is applied on LM segmentation. When a bifurcation is detected in step 6, it means that the LM ends in that slice and both LAD and LCX would start from that point. Therefore, the bifurcation point is selected as a seed point for LAD and LCX segmentations, as shown in Figure 19.

Figure 19
LAD and LCX seed point detection. (a) A CTA slice includes LM artery. (b) Segmented region currently saved in matrix H. (c) Thinning by means of morphological operation for bifurcation detection.

For RCA, axial slices are sought from top to bottom to find slice S i as RCA's seed point, where the RCA starts from the aorta. Then, the same Intersection Tracking method is used for RCA segmentation. As shown in the "Cardiovascular tree model", RCA has one main branch with some sub-arteries and also two main branches, called R-PDA and R-PLB. The sub arteries should be removed, except for R-PDA and R-PLB because these two sub-arteries are considered as the main parts of RCA, and sometimes, stenosis can appear in these parts. A proper threshold is defined in step 7 of the above algorithm for preserving these two sub-arteries. The steps for LAD and LCX segmentation in few sequential slices are shown in Figure 20.

Figure 20
Coronary artery segmentation in each CTA slice using the proposed intersection tracking method. (a) - (d) Example of LAD segmentation. (e) - (h) Example of LCX segmentation.

The pseudo code of the proposed method in this phase is described in the following.

---

### Direction of actin flow dictates integrin LFA-1 orientation during leukocyte migration [^e05ce0f2]. Nature Communications (2017). Medium credibility.

Cartesian and spherical coordinate reference frames were defined to enable dipole orientations measured in microscopes, the orientation of the transition dipole in GFP, and the orientation of GFP with respect to the integrin in Rosetta ensembles to be used to define integrin orientation on cell surfaces. The coordinate system is defined by the three Cα atoms in the integrin and ligand described in the preceding paragraph. Because force passes through the junction between the ligand and integrin, and force balance requires that tensile force cause them to pivot toward alignment with the direction of force exertion, the ligand-point is used to define the origin. The line between the ligand point and the α-junction point defines the X axis. The β-junction point defines the XZ plane and lies near the Z axis. These positions in turn define the XY plane, which lies parallel to the microscope image plane and the plasma membrane of the cell adhering through integrins to ligands on the substrate.

As the reference frame is constructed with the ligand and head junction points in the XZ plane and optimally orients the integrin head toward the substrate, the integrin will remain close to this plane when it is tilted by cytoskeletal force, as shown by SMD. Spherical coordinates are useful for defining the orientation of the integrin and GFP transition dipole relative to the Cartesian reference frame. X, Y, Z positions in Cartesian coordinates are defined in spherical coordinates with the radial distance r and angles θ and φ. Integrin and dipole orientations are defined relative to the X axis with the α -junction point and r lying on this axis such that θ = 0° and φ = 90°. The orientation of r is defined by its angle φ with the Z axis and its angle θ with the X axis when projected on the XY plane. Similarly, the orientation of the GFP transition dipole when projected on the microscope imaging plane in our fluorescence microscopy experiments is measured as θ d relative to the direction of lamellipodial movement in the direction θ = 0° (normal to the leading edge). The reference frame is such that when actin retrograde flow is in the direction θ = 180°, the traction force model for integrin activation predicts that (1) the line between the ligand and the α -junction points tilts toward the Z axis with a decrease in φ and (2) the projection of this line on the XY plane has θ = 0°, as in the reference frame.

Data availability

The data that support the findings of this study are available from the first author or corresponding author upon reasonable request.

---

### Three-dimensional wave breaking [^58966bb2]. Nature (2024). Excellent credibility.

Fig. 1
Surface elevations of maximally steep 3D wave groups differ in space and time.

a – c, g – i, Top and bottom rows show the measured surface elevation of maximally steep non-breaking waves at the time of maximum amplitude with corresponding images above and below. a – c, Directionally spread wave groups (Δ θ = 0°) with σ θ = 0° (a), 20° (b) or 40° (c). g – i, Crossing wave groups (σ θ = 0°) with Δ θ = 90° (g), 135° (h) or 180° (i). d, e, Time series (d) and corresponding frequency spectra (e) measured at the intended point of the linear focus (x = 0 and y = 0) for maximally steep wave groups with fixed Δ θ = 0° (top) and fixed σ θ = 20° (bottom). The line colours go from dark to light as σ θ and Δ θ are increased. f, Visualization of the directional parameter space of our experiments (Δ θ = 0°; σ θ = 0°,10° or20°; Extended Data Table 1). Markers with black outlines correspond to the experiments shown in a – c and g – i. In a – c and g – i, the waves travel from left to right.

---

### Multiple tipping points and optimal repairing in interacting networks [^bf70cdce]. Nature Communications (2016). Medium credibility.

Geometry of the Manhattan distance minimization problem

The optimal strategies shown in different colours in Fig. 5 are derived from the geometrical reasoning shown in Fig. 9. Figure 9a shows a plot of a series of curves consisting of points at identical Manhattan distances from point S 1 (equidistant curves). They produce a 'diamond' shape, and the minimal Manhattan distance between point S 1 and the green region translates into the task of 'fitting' the diamond so that it just touches the green region and its centre is at S 1. The diamond in Fig. 9a touches the green region at two points — triple points, which are the solution to the minimization problem. Figure 9b shows the solution for point S 6 in the light blue region. Here the solution suggests a different strategy — decreasing only.

---

### 3D multimodal cardiac data reconstruction using angiography and computerized tomographic angiography registration [^de5b4a4f]. Journal of Cardiothoracic Surgery (2015). Low credibility.

Table 1
The performance of the main artery segmentation of the left coronary artery (LCA) in the dataset

Table 2
The performance of the main artery segmentation of the right coronary artery (RCA) in the dataset

Table 3
Running time for coronary artery segmentation on dataset

Evaluation of the intersection tracking method for main coronary artery segmentation in CTA

The first part of the Intersection Tracking method evaluation is the seed point detection. As mentioned before, ostiums for every LCA and RCA are detected manually by seeking axial slices from top to bottom. Some algorithms have proposed automatic coronary artery seed point detection in CTA by considering the starting point from the aorta. However, in some patients, there is a third coronary artery, Conus artery, which arises independently from the aorta. In this case, other algorithms failed to achieve the target seed points. Therefore, it is better to choose these points manually. As mentioned in the Intersection Tracking method, other seed points for LAD, LCX, are detected automatically. Therefore, the proposed method can be categorized as requiring minimal user-interaction by finding only the initial artery ostiums, as seed points.

---

### Study on the anatomic relationship between the clavicle and the coracoid process using computed tomography scans of the shoulder [^c9d80b20]. Journal of Shoulder and Elbow Surgery (2017). Low credibility.

Background

The current trend in the treatment of acromioclavicular dislocations is to reconstruct the coracoclavicular ligaments by using transosseous tunnels in the coracoid process or in the clavicle, yet there is no definition as to the location of these. To study the anatomic relationship between the coracoid process and the clavicle, we made measurements to find a convergence point (cP) between them that has intraoperative applicability for creating transosseous tunnels.

Methods

We analyzed 74 computed tomography scans (40 female and 34 male patients). Measurements were taken in the axial and sagittal planes and obtained from a cP, as determined by the intersection of the cortical surface of the clavicle and the coracoid process, with various relationships having been established.

Results

On average, the cP was determined to be about 2.9cm and 2.5cm distant from the coracoid process apex for male and female patients, respectively, whereas the width at this position was determined to be 2.1cm and 1.9cm. In the clavicle, this point is on average 2.9cm and 2.5cm distant from the acromioclavicular joint in male and female patients, respectively, and its anteroposterior width at this point is on average 1.9cm and 1.6cm.

Conclusion

The cP of the clavicle and the coracoid process was determined with the aim of preparing bone tunnels in operations for treating acromioclavicular dislocations.

---

### Three-dimensional analysis of bone morphology of the rheumatoid arthritis elbow [^c7f13557]. Journal of the American Academy of Orthopaedic Surgeons: Global Research & Reviews (2025). Medium credibility.

Points of Interest

The Cartesian coordinate systems of the humerus (X H, Y H, and Z H -axes), ulna (X U, Y U, and Z U -axes), and radius (X R, Y R, and Z R -axes) were determined for the reference bones (Figure 2, see Supplemental Digital Content 1).

Fig. 2
Illustration showing axis settings. (A) Distal humerus, (B) proximal ulna, and (C) radial head.

In the distal humerus, the sagittal planes were defined as the planes passing through the anatomical points of the (1) capitellum center, (2) lateral trochlear ridge, (3) trochlear groove, and (4) center of the medial trochlea. Seven planes (0°, 30°, 60°, 90°, 120°, 150°, and 180°), including the Y H -axis, were determined with the X H Y H plane at 0°/180° and the Y H Z H plane at 90°. Subsequently, the points of interest were determined at the intersection of the six planes, with the sagittal planes on the surface of the 3D model, and were categorized into anterior (0° and 30° planes), inferior (60°, 90°, and 120° planes), and posterior (150° and 180° planes) regions (Figure 3, A).

Fig. 3
Illustration showing planes to be evaluated for joint surfaces. A, Distal humerus, (B) proximal ulna, and (C) radial head.

In the proximal ulna, the sagittal plane was defined as the plane passing the anatomical points of the (1) lateral verge of the trochlear notch, (2) ridge of the trochlear notch, and (3) center of the medial trochlear notch. Seven planes are established at 0°, 30°, 60°, 90°, 120°, 150°, and 180°, including the Y U -axis. The Y U Z U plane corresponds to 0°/180°, whereas the X U Y U plane is positioned at 90°. Subsequently, the points of interest were determined at the intersection of the six planes, with the sagittal planes on the surface of the 3D model, and were categorized into anterior (0° and 30° planes), inferior (60°, 90°, and 120° planes), and posterior (150° and 180° planes) regions (Figure 3, B).

---

### In situ X-ray diffraction and the evolution of polarization during the growth of ferroelectric superlattices [^e796b727]. Nature Communications (2015). Medium credibility.

The respective motor movement in each scan corresponds to the movement normally performed during a rocking curve. Therefore, the measured intensity of each pixel is the integrated intensity over the rocking curve at that pixel. This leads to integration over one in-plane momentum transfer direction (Q y), while diffraction information in the two other momentum transfer directions (Q x and Q z) can be obtained from each camera image.

This technique can be employed for the (0 0 1) reflection by scanning the θ motor (Fig. 1a), and for the (1 0 1) reflection by scanning the φ motor (Fig. 1d). During the measurement these are the only motors that are moved. Some further explanation of the method is given in Supplementary Note 2 and Supplementary Fig. 1.

An example of the (0 0 1) data obtained is shown in Fig. 1b. The obtained images can be assembled into continuous movies that allow the observation of the evolution of diffraction features during the growth (Supplementary Movie 1). Our analysis of the data contained in these images is based on two principle lines of points.

The first line is along the Q z direction, which is a horizontal line in Fig. 1b. Q z is the momentum transfer in the z or out-of-plane direction. A plot along this line together with a fit to the data and basic superlattice attributes are shown in Fig. 1c.

The second line of interest in Fig. 1b is a vertical line through the first superlattice diffraction peak. It is along the Q x direction and gives information about the polarization domain periodicity in the superlattice. Q x is the momentum transfer in the x direction, which is one of the in-plane directions.

---

### Bony landmarks in the endoscopic endonasal transoculomotor approach [^1148e7e4]. Neurosurgical Review (2021). Medium credibility.

The endoscopic endonasal transoculomotor approach (EETA) has been recently described as a doorway to access the parapeduncular space and treat pituitary adenomas with oculomotor extension. Intraoperative identification of the oculomotor triangle endonasally is challenging and dissection can put the internal carotid artery (ICA) at risk. The aim of the present study is to find reliable landmarks that identify the oculomotor triangle (OCMT) during the EETA and protect the ICA from injury. Several lines were defined for calculations. Among them, one oblique line that extends from the inferior margin of the lateral orbital canal recess to the vidian canal was named the clinoid-to-vidian line (CVL), while a vertical line that extends over the most medial point of the paraclival ICA was titled the sagittal paraclival line (SPL). Anatomic relationships between the OCMT to these lines were assessed in 7 cadaveric heads. The intersecting point between the CVL and SPL is located within 2 mm of the center of the OCMT (mean 0.8 ± 0.5 mm), and 1.1 ± 0.8 mm medially and above the parasellar ICA. CVL and SPL are reliable landmarks during the EETA that can both protect the parasellar ICA and anatomically orientate to the blind spot that corresponds with the OCMT. We recommend starting dissection medial and superior to the CVL-SPL intersecting point, and carry the dissection laterally thereafter to avoid inadvertent injury of the ICA.

---

### On-chip cherenkov radiation tuning in 3.2–14 THz [^1df4335a]. Nature Communications (2025). High credibility.

Fig. 2
Measurement results of the THz radiation frequency and spectrum of the chip.

a Measured spectral peaks spanning 3.2–14 THz for different grating periods under different electron energies. The central frequency and the sample numbers are shown at the top and bottom of the figure, respectively. The corresponding values of E and p for different samples are listed in Supplementary Information Section S5. b Wavevector matching for the CR in the HMM and radiation coupled into free space. The deep red, red, and light red solid lines represent the projections of the k x - k z hyperbolic curve (the red hyperbolic curve indicated in Fig. 1b) onto the ω-k z plane at different frequencies. The black lines are the dispersion lines of the evanescent fields surrounding free electrons (namely, ω = u 0 ·| k z |) with different u 0 (E). The black lines and colored lines intersect at the deep red, red, and light red points, which indicate the end points of the k z of the excited CR in the HMM and correspond to the same k z. To extract the CR into free space, k z needs to be matched by the wavevector introduced by the grating (2π n / p) to change it to the free space radiation region (| k z | < ω / c). According to this figure, a higher electron velocity (energy) results in a higher radiation frequency of the chip. c The black line (ω = u 0 ·| k z |) intersects with the red, violet, and yellow solid lines (projections of the k x - k z hyperbolic curve onto the ω-k z plane) at the red, violet, and yellow points, which indicate the end points of the k z of the excited CR and correspond to different k z values. To extract the CR into free space, k z needs to be matched by the wavevector introduced by the gratings (2π n / p) of different grating periods p, and a smaller p corresponds to a higher radiation frequency. d Measured radiation spectra at E = 1.4 keV (deep red line), 2.0 keV (red line), and 2.6 keV (light red line). The grating period of the chip is fixed at 5 μm. e Measured radiation spectra at p = 5 μm (red line), 4 μm (violet line), and 3 μm (yellow line). The electron energy is fixed at 2 keV. Each spectrum in this figure is normalized by its own maximum peak.

---

### Critical exponents and scaling invariance in the absence of a critical point [^760713e6]. Nature Communications (2016). Medium credibility.

Scaling and characteristic lengths

As suggested by one of the reviewers, in a conventional ferromagnet scaling plots can also be written in such a way that the dependence on the correlation lengthis made explicit (ν being the corresponding critical exponent). Let us consider the following equations of state of a ferromagnet:

and

with F 1 (x) and F 2 (x) some scaling functions. In Fig. 5b, c the same data points shown in Fig. 4c are plotted in the representations defined above. Points falling in the grey zone are rendered in grey. Indeed, collapsing is observed for the coloured points while the grey ones spread out in the plot planes. Figure 5c appears very similar to Fig. 4c and basically the same considerations apply. Equation (7) leads instead to the plot in Fig. 5b that has a different shape.

If the spreading of grey points observed in all the scaling plots was due to the size of magnetic domains L acting as a cutoff for the correlation length, from equation (7) one would expect the following relation to be fulfilled in the patterned phase

with F 3 (x) andappropriate scaling functions. This scaling relation is not compatible with the one found in within the grey zone, which can be rewritten as

Equations (9) and (10) can be simultaneously fulfilled only for

This last relation is not obeyed by the 2D-Ising critical exponents β = 1/8, δ = 15 and ν = 1.

A more proper framework to discuss whether L acts as a cutoff for the correlation length is provided by the finite-size scaling (FSS) ansatz, according to which the magnetization M L (T) of a finite system of linear size L x should be related to the magnetization of the corresponding infinite systems M ∞ (T) by the law

---

### Infrared laser-induced gene expression for tracking development and function of single C. elegans embryonic neurons [^0e096d3e]. Nature Communications (2017). Medium credibility.

Axon-outgrowth measurement

Neurite length was quantified in ImageJ by marking a set of points along the axon and summing the Euclidean distance between these. The distance between neighbouring points (X, Y, Z)→(X′, Y′, Z′) was calculated by D 3D = [(D X-X′ 2 + D Y-Y′ 2 + D Z-Z′ 2)] 1/2. This distance was plotted as a function of developmental stage (tail-to-head length; Supplementary Fig. 3) to facilitate comparison between embryos. The tail-to-head ratio ranges from 0 (comma stage) to 1 (2-fold stage). Note that after twitching begins (tail-to-head = 0.5–0.6), some time points were omitted if the axon was not visible.

Dye-filling assays

The embryos were recovered after laser irradiation, grown until the L4 stage, and placed singly in drops of M9+5 μg mL −1 DiI for 30 min. The animals were recovered onto plates and imaged with wide-field microscopy.

3D renderings of embryogenesis

Nuclear coordinates were taken from a fully lineaged embryoat 202 min (AB128) and 357 min (early morphogenesis), and 3D models with coloured sublineages were rendered in MATLAB.

Data availability

The data that support the findings of this study are available from the corresponding author on request.

---

### Tirzepatide (Zepbound) [^b9dfd0f5]. FDA (2025). Medium credibility.

The cumulative frequency distributions of change in body weight are shown in Figure 1 for Study 1 and Figure 2 for Study 2. One way to interpret this figure is to select a change in body weight of interest on the horizontal axis and note the corresponding proportions of patients (vertical axis) in each treatment group who achieved at least that degree of weight reduction. For example, note that the vertical line arising from -10% in Figure 1 intersects the ZEPBOUND 15 mg and placebo curves at approximately 83.5%, and 18.8%, respectively, which correspond to the values shown in Table 2.

Figure 1: Changes in Body Weight (%) from Baseline to Week 72 in Study 1 in Patients with Obesity or Overweight (without Type 2 Diabetes)

Note: Based on average percent weight change of each randomized patient within each specific treatment arm from 100 imputed datasets including observed data and imputed data using hybrid approach for missing values.

Figure 2: Changes in Body Weight (%) from Baseline to Week 72 in Study 2 in Patients with Obesity or Overweight and Type 2 Diabetes

Note: Based on average percent weight change of each randomized patient within each specific treatment arm from 100 imputed datasets including observed data and imputed data using hybrid approach for missing values.

The time courses of weight reduction with ZEPBOUND and placebo from baseline through Week 72 are depicted in Figure 3 for Study 1 and Figure 4 for Study 2.

Figure 3: Change from Baseline (%) in Body Weight in Study 1 in Patients with Obesity or Overweight (without Type 2 Diabetes)

Note: Displayed results are from the Intent-to-Treat Population. (1) Observed mean value from Week 0 to Week 72, and (2) least-squares mean ± standard error at Week 72 hybrid imputation (HI).

Figure 4: Change from Baseline (%) in Body Weight in Study 2 in Patients with Obesity or Overweight and Type 2 Diabetes

Note: Displayed results are from the Intent-to-Treat Population. (1) Observed mean value from Week 0 to Week 72, and (2) least squares mean ± standard error at Week 72 hybrid imputation (HI).

Changes in waist circumference and cardiometabolic parameters with ZEPBOUND are shown in Table 3 for Study 1 and Study 2.

Weight Reduction Following Intensive Lifestyle Intervention in Adults with Obesity or Overweight (Study 3)

---

### Samarium hexaboride is a trivial surface conductor [^70abae29]. Nature Communications (2018). Medium credibility.

SmB 6 is predicted to be the first member of the intersection of topological insulators and Kondo insulators, strongly correlated materials in which the Fermi level lies in the gap of a many-body resonance that forms by hybridization between localized and itinerant states. While robust, surface-only conductivity at low temperature and the observation of surface states at the expected high symmetry points appear to confirm this prediction, we find both surface states at the (100) surface to be topologically trivial. We find the [Formula: see text] state to appear Rashba split and explain the prominent [Formula: see text] state by a surface shift of the many-body resonance. We propose that the latter mechanism, which applies to several crystal terminations, can explain the unusual surface conductivity. While additional, as yet unobserved topological surface states cannot be excluded, our results show that a firm connection between the two material classes is still outstanding.

---

### Correlation of contrast sensitivity at low spatial frequencies with myopic shift in Chinese children [^0b2d8bc4]. BMC Ophthalmology (2025). Medium credibility.

Discussion

This prospective study first observed qCSF results under different degrees of myopic shift. Our previous findings suggested that RS and SE are the main factors affecting qCSF in children without refractive correction. The findings of the present study confirmed these results and additionally revealed that children with stable refraction had lower CSF acuity and contrast sensitivity at 1.0–3.0 cpd during the 6-month follow-up. These results suggest that a lower contrast sensitivity may be correlated to a relatively slower myopic shift. Thus, contrast intervention may be practicable in children with controlled myopia. Meanwhile, the change rate of RS or SE with contrast sensitivity differed between the two groups. The different intersection positions of fitting lines of the two groups in Fig. 3 may indicate the starting point of appropriate intervention on contrast. At the right of the intersection point, the hyperopic children with myopic shift > 0.50 D in the future had lower contrast sensitivity, which may be correlated to the accelerated emmetropization in hyperopia state under the close-range work background.

---

### The XZZX surface code [^8f6ac9c8]. Nature Communications (2021). High credibility.

This structured noise model thus leads to two distinct regimes, depending on which failure process is dominant. In the first regime where, we expect that the logical failure rate will decay like. We find this behaviour with systems of a finite size and at high bias where error rates are near to threshold. We evaluate logical failure rates using numerical simulations to demonstrate the behavior that characterises this regime; see Fig. 6 (a). Our data show good agreement with the scaling ansatz. In contrast, our data are not well described by a scaling.

Fig. 6
Sub-threshold scaling of the logical failure rate with the XZZX code.

a Logical failure rateat high bias near to threshold plotted as a function of code distance d. We use a lattice with coprime dimensions d × (d + 1) for d ∈ {7, 9, 11, 13, 15} at bias η = 300, assuming ideal measurements. The data were collected usingiterations of Monte-Carlo (MC) samples for each physical rate sampled and for each lattice dimension used. The physical error rates used are, from the bottom to the top curves in the main plot, p = 0.19, 0.20, 0.21, 0.22 and 0.23. Error bars represent one standard deviation for the Monte-Carlo simulations. The solid lines are a fit of the data to, consistent with Eq. (2), and the dashed lines a fit to, consistent with Eq. (3) where we would expect, see Methods. The data fit the former very well; for the latter, the gradients of the best fit dashed lines, as shown on the inset plot as a function of, give a linear slope of 0.61(3). Because this slope exceeds the value of 0.5, we conclude that the sub-threshold scaling is not consistent with. b Logical failure ratesat modest bias far below threshold plotted as a function of the physical error rate p. The data (markers) were collected at bias η = 3 and coprime d × (d + 1) code dimensions of d ∈ {5, 7, 9, 11, 13, 15} assuming ideal measurements. Data is collected using the Metropolis algorithm and splitting method presented in refs. The solid lines represent the prediction of Eq. (3). The data show very good agreement with the single parameter fitting for all system sizes as p tends to zero.

---

### Foot deformity correction planning in the sagittal plane based on the vitruvian foot first metatarsal mechanical axis and calcaneus anatomic axis [^7bd5abb5]. The Journal of Foot and Ankle Surgery (2021). Medium credibility.

The aim of the study was to test a novel planning method for simultaneous midfoot and hindfoot deformity correction, based on reference lines and angles (RLA) of the talus, calcaneus and first metatarsal in 64 normal radiographs from 55 patients. Talus Joint Line (TJL), from the border of the articular surface of the talus and the posterior process of talus, and mechanical axis of the first metatarsal form the mechanical Lateral Talometatarsal Angle (mLTMA) = 23.6º (± 3.2). The length of the first metatarsal line was measured from its intersections with the TJL and first metatarsal head and it was 4.3 (± 0.94) times longer that TJL (k). For hindfoot correction planning, we used an axis of the calcaneus formed by a line starting at the middle of the back of the calcaneal tuberosity and going perpendicular to a line from the top point to the bottom point of the calcaneal tuberosity. The intersection of the calcaneal line and the anterior continuation of TJL form the lateral heel angle (LHA) = 15.2º (± 3.4). The following parameters were identified: the length from the intersection point of the lines and anterior point of TJL was 2.56 ± 1.1 longer than TJL (k1). The length from the intersection point and posterior border of the calcaneus was 4.59 ± 1.0 times longer than TJL (k2). Planning using the new method was demonstrated and confirmed on 3 case examples. A novel method for analysis and planning of midfoot and hindfoot sagittal plane deformity correction may be used separately or simultaneously for complex deformity correction.

---

### Revealing topology with transformation optics [^ffb7f764]. Nature Communications (2021). High credibility.

Fig. 1
The multiplicity of a conformal mapping.

Metasurface geometries in a, b the virtual space (u-v frame) and in c, d the real space (x – y frame). The relation between these two spaces is governed by the transformation in Eq. (1), and its contour plot containing the isolines of real and imaginary parts of z is shown by the light-gray solid lines in a, b. The filled orange circles and triangle markers in a, b, and e denote theandsingularities of the mapping, respectively. The solid orange lines in a and b denote the branch cut of the mapping, terminating at theandsingularities. All the magenta and black solid lines in a, b correspond to the boundary of the metasurface with the same colors shown in c, d, showing the multiplicity of the mapping. To further demonstrate such multiplicity, four points along the black line of the slab in a, b with coordinates (u, v) = (1, − π), (1, − π /2), (1, 0), and (1, π /2) are highlighted by the open stars, circles, triangles, and squares, and their equivalent points are shown by the same markers in c, d and in the eccentric cylinder of the virtual space in b. The values of a 0 are 0 in a and c, and 0.1 in b and d. Other geometric parameters are Λ = 30 π nm, w 0 = 1.5, u 0 = 1, and d = 0.5. e The left panel illustrates the geometries of the plasmonic metasurfaces in the virtual space for a complex a 0 = δ exp(i θ). The two solid lines show the trajectories of the ln(0) singularities as θ varies from − π to π, for two values of δ = 0.1 (green) and δ = 0.03 (purple). Along the solid green line, we depict the eccentric cylinders with different values of θ, and their corresponding metasurfaces in the real space are shown in the right panel. The orange dashed lines highlight the metasurfaces when δ = 0.

---

### Selective neural representation of objects relevant for navigation [^58adac12]. Nature Neuroscience (2004). Medium credibility.

As people find their way through their environment, objects at navigationally relevant locations can serve as crucial landmarks. The parahippocampal gyrus has previously been shown to be involved in object and scene recognition. In the present study, we investigated the neural representation of navigationally relevant locations. Healthy human adults viewed a route through a virtual museum with objects placed at intersections (decision points) or at simple turns (non-decision points). Event-related functional magnetic resonance imaging (fMRI) data were acquired during subsequent recognition of the objects in isolation. Neural activity in the parahippocampal gyrus reflected the navigational relevance of an object's location in the museum. Parahippocampal responses were selectively increased for objects that occurred at decision points, independent of attentional demands. This increase occurred for forgotten as well as remembered objects, showing implicit retrieval of navigational information. The automatic storage of relevant object location in the parahippocampal gyrus provides a part of the neural mechanism underlying successful navigation.

---

### Multiple tipping points and optimal repairing in interacting networks [^56cf6bf4]. Nature Communications (2016). Medium credibility.

Figure 2c, d show the regions of state 21 (purple) and state 12 (orange), respectively. Each has two different transitions and one critical point. For example, there are two possible ways out of state 21 (Fig. 2c): by a transition to the 11 (green arrow) state or the 22 (blue arrow) state. It is noteworthy that the different state regions (Fig. 2a–d) are not disjoint sets but there is an overlap, resulting in twofold, threefold or even fourfold hysteresis regions.

The state in which the system is found depends on the initial conditions or the system's past. There are a total of 10 different transitions (11→12, 11→22, 11→21, 12→11, 12→22, 21→11, 21→22, 22→12, 22→21 and 22→11) that connect different layers of the phase diagram (states 11, 12, 21 and 22), much similar to elevators connecting different floors. Transitions 12→21 and 21→12 are the only missing ('forbidden') combinations. Although regions 12 and 21 do overlap, there is no direct transition connecting these two states. The set of all allowed and forbidden transitions is presented in Fig. 2e. The total phase diagram (all four layers on top of each other) is presented in Fig. 3. Here, coloured lines represent the boundaries of four states, with each colour corresponding to the boundary of one state, for example, the green line is a boundary of the 11 state. Rich critical phenomena with discontinuous hybrid phase transitions and second-order transitions have been recently discovered in multiplex networks. In particular, Baxter et al. introduced weak bootstrap percolation and weak pruning percolation in multiplex networks, which have potential applications in infrastructure recovery and information security, and can even provide a way to diagnose missing layers in a multiplex network.

---

### Comparison of parameter optimization methods for quantitative susceptibility mapping [^26a0417b]. Magnetic Resonance in Medicine (2021). Medium credibility.

Purpose

Quantitative Susceptibility Mapping (QSM) is usually performed by minimizing a functional with data fidelity and regularization terms. A weighting parameter controls the balance between these terms. There is a need for techniques to find the proper balance that avoids artifact propagation and loss of details. Finding the point of maximum curvature in the L-curve is a popular choice, although it is slow, often unreliable when using variational penalties, and has a tendency to yield overregularized results.

Methods

We propose 2 alternative approaches to control the balance between the data fidelity and regularization terms: 1) searching for an inflection point in the log-log domain of the L-curve, and 2) comparing frequency components of QSM reconstructions. We compare these methods against the conventional L-curve and U-curve approaches.

Results

Our methods achieve predicted parameters that are better correlated with RMS error, high-frequency error norm, and structural similarity metric-based parameter optimizations than those obtained with traditional methods. The inflection point yields less overregularization and lower errors than traditional alternatives. The frequency analysis yields more visually appealing results, although with larger RMS error.

Conclusion

Our methods provide a robust parameter optimization framework for variational penalties in QSM reconstruction. The L-curve-based zero-curvature search produced almost optimal results for typical QSM acquisition settings. The frequency analysis method may use a 1.5 to 2.0 correction factor to apply it as a stand-alone method for a wider range of signal-to-noise-ratio settings. This approach may also benefit from fast search algorithms such as the binary search to speed up the process.

---

### Charge density wave induced nodal lines in LaTe [^cc2515f4]. Nature Communications (2023). High credibility.

Fig. 3
Band crossings and the Kramers nodal line (KNL).

a E (k z) bands at k x = 0.59 Å −1 without (w/o) spin-orbit coupling (SOC) for the 7f structure. The irreducible representations are shown. The vertical dashed line represents the k z point on Γ 2 X 2 i.e. the Σ line in the 2 nd BZ (see Fig. 1 d). Zoomed colored rectangles of a show the bands around b L, c R, d T, and e B. Comparison of ARPES and DFT for f R at k z = 0.229 Å −1 and g L at k z = 0.196 Å −1. The positions of these crossings obtained from DFT (orange and blue filled circles for R and L, respectively) are superimposed. The dashed orange and blue curves serve as guide to the eye. h A schematic representation of the gapless L and R crossings in the E - k z - k x space (red dashed lines) and their projection on the k x - k z plane showing the spinless nodal lines (thick red lines on both sides of the Σ line). i – m Same as a – e except that the calculations are performed with SOC. n E (k x) ARPES intensity plot at k z = 0.204 Å −1 (dashed red and black curves serve as guide to the eye) compared with the positions of the crossings from DFT for T (red, light red circles) and B (black, gray circles). o A schematic representation of the four crossings (green dashed lines) related to the upper and lower branches of T and B. The KNL appears along the Σ line and is denoted by a green thick line on the k x - k z plane.

---

### Quadrupole topological photonic crystals [^1e87be78]. Nature Communications (2020). High credibility.

Results

Quadrupole phase transition through band inversion

We start by presenting the topological phase transition between a trivial (Fig. 1 b) and a quadrupole two-dimensional (2D) PhC (Fig. 1 c). The 2D PhC consists of gyromagnetic rods in air and is homogeneous along the out-of-plane (z) direction. Experimentally, this boundary condition can also be realized using metals. The gapless transition point is achieved in a 2 × 2 super-cell structure with four square rods (Fig. 1 a). All rods are identical in shape and are of the same gyromagnetic material of Yttrium Iron Garnet (YIG) with isotropic dielectric permittivity of ϵ = 15 ϵ 0 and inplane permeability μ = 14 μ 0. To break time-reversal symmetry, an external magnetic field is applied along the out-of-plane direction (z), which induces complex-valued off-diagonal terms in the permeability tensor of YIG:This gyromagnetic response, breaks T but preserves C 4 and M x (y) T. Here M x (y) is mirror reflection that transforms x (y) to − x (y). At the phase transition, all rods are placed at a /2 away from their neighbors; the corresponding band structure for TM modes (E z, H x, H y) has twofold (fourfold) degeneracies at the center (corner) of the folded Brilluion zone Γ (M). Both degeneracies are lifted when the four rods are simultaneously displaced inward (d < 0, Fig. 1 b) or outward (d > 0, Fig. 1 c) along the diagonal lines of the unit cell. On either side of the transition point, the band structure is fully gapped owing to T -breaking (shaded in yellow) and supports two topologically distinct phases determined by the displacement d: for the choice of cell in Fig. 1, inward displacements with negative d give rise to trivial phases, whereas outward displacements with positive d correspond to quadrupole phases.

---

### Sources of path integration error in young and aging humans [^7066d5d0]. Nature Communications (2020). High credibility.

In order to allow for accumulation of path integration errors across stopping points, we therefore also used an alternative method to calculate the so-called "incremental" path integration error Err inc. For a given stopping point, the Euclidean distance between the presumed starting point (according to the participant's response at this respective stopping point) and the previously presumed starting point (according to the response at the previous stopping point) was calculated by

where x prevPresumed and y prevPresumed are the x and y coordinates of the previously presumed starting point (according to the response at the previous stopping point). Note that the previously presumed starting point at stopping point 1 is the correct starting point of the path (i.e. x prevPresumed = x origin and y prevPresumed = y origin). Consequently, this measure of the path integration error reflects only the incremental error that occurred on the latest path segment before the stopping point, but does not include the error that occurred on earlier segments of the same path. More specifically, at stopping point 1 it reflects the error that occurred between the starting point and stopping point 1, at stopping point 2 it reflects the error that occurred between stopping point 1 and stopping point 2 (not including the error between the starting point and stopping point 1), and so on. This method of calculating the path integration error allows, for each individual participant, to aggregate all error measures from all available stopping points, because each incremental path integration error measure includes only the incremental (i.e. unique) error contribution of one path segment.

---

### Self-assembly of amorphous calcium carbonate microlens arrays [^47ebb7f2]. Nature Communications (2012). Medium credibility.

The light path through an ACC microlens array and the focal length are characterized by confocal microscopy as shown in Fig. 3. Figure 3c shows 11 spots corresponding to the light of a collimated laser beam focused at the back focal plane of the microlens array as shown in Fig. 3a. The beam waists at the focal plane of the microlenses were uniform in size and smaller than 1.2 μm (measured at full width at 1/e 2). The x – z plane images in Fig. 3b, d show the position of the chitosan coating at the surface of the microlenses in contact with the microscope coverslip and the converging light path at the back plane of the microlenses, respectively. To calculate the focal length of the microlenses, we measured their thickness by atomic force microscopy line scans and the distance from the back plane of the microlenses and the focused point (Supplementary Fig. S5). We measured a focal length of 7.2 ± 0.3 μm. The focal length of the microlenses focusing in the glass coverslip was calculated using the relation, where R = 3.1 ± 0.2 μm is the radius of curvature calculated based on the geometry of 11 microlenses measured by atomic force microscopy line scans, and n glass and n ACC are refractive indices of glass (1.50) and ACC (1.58, taken from the measured value of 1.5791–1.5830 by Merten and group), respectively. Entering these parameters into equation (1), we find f = 8.0 ± 0.5 μm.

---

### Unconventional superconductivity without doping in infinite-layer nickelates under pressure [^cc5f0553]. Nature Communications (2024). High credibility.

Results

As the superconducting nickelate films are grown onto an STO substrate, particular care has to be taken when simulating the effect of isotropic pressure in the diamond anvil cell (cf. Supplemental Material (SM) Section IA for a flowchart of the overall calculations and Section IC for further details of the pressure calculation). First, since the thickness of the film is 10–100 nm and thus negligible compared to that of the STO substrate, we calculate the STO equation of state in DFT and, from this, obtain the STO lattice parameters under pressure. Second, we fix the in-plane a (and b) lattice parameters to that of STO under pressure and find the lattice parameter c for the nickelate which minimizes the enthalpy at the given pressure. The resulting lattice constants are shown in Table 1. This procedure reflects the response of the system to the rather isotropic pressures realized in the experiment whereas in ref.the a – b lattice parameters had been fixed to that of unpressured STO.

Table 1
Ab initio values for the lattice constants and the hoppings of the 1-orbital Hubbard model for PrNiO 2 under pressure

Here, and t ″ are the nearest, next-nearest, and next-next-nearest neighbor-hoppings.

With the crystal structure determined, we calculate the DFT electronic structure at pressures of 0, 12, 50, 100, and 150 GPa. Next, we perform a 10- and 1-orbital Wannierization around the Fermi energy, including all Pr- d plus Ni- d orbitals and only the Niorbital, respectively. The DFT band structures and Wannier bands are shown in SM Fig. S5 and as white lines in Fig. 2.

Fig. 2
Spectral function for undoped PNO.

Panels a and c show the DMFT spectral function A (k, ω) (color scale) and the Wannier bands (white lines) along a path through the Brillouin zone at temperature T = 300 K and a pressure of 0 and 50 GPa, respectively. Panels (b) and (d) show the same spectral function in the k z = 0 plane. A (k x, k y, k z = 0, ω = 0). The Γ point is at the center, i.e. (k x = 0, k y = 0).

---

### Non-linear relationships in clinical research [^668fb19a]. Nephrology, Dialysis, Transplantation (2025). Medium credibility.

Polynomial functions

In Fig. 4, we provide an example of a simple power transformation using the square function, which raises a variable to the power of 2 (x 2), providing a U-shaped curve. Higher powers of x can be also used to determine the shape of the function, such as the cubic function (x 3) which has a distinctive S-shape. These power terms form the core elements of so-called polynomial functions, which along with the coefficients included in the function, offer a flexible way to model various curves. By adjusting the coefficients and power functions, polynomials offer a wide variety of shapes. "Fractional" polynomial functions allow the power terms to be fractions instead of just whole numbers (i.e. x 1/2) [21]. A (fractional) polynomial function often provides sufficient flexibility to follow relatively simple non-linear curves, providing a simpler solution than the more advanced techniques we describe below. However, higher degree polynomials can be sensitive to "noise" in the data, and are not suited for fitting some of the more complex curves (e.g. sudden shifts, discontinuities, or logarithmic curves). They may also suffer from Runge's phenomenon, becoming unstable and oscillating at the edges of the data, and extrapolate poorly beyond the original range of the independent variable.

Regression splines

A powerful approach to dealing with non-linearity is provided by the family of spline functions. Instead of a single function defining the whole curve, such as polynomials or other transformations, splines are constructed by using a series of functions, each defining a different segment of the curve. As splines are constructed segment by segment — or piece by piece — they are often referred to as "piecewise" functions. Segments are connected to each other using so-called "knots", and the spline is restricted to join at these knots so there are no gaps in the curve. The simplest spline function is the linear spline function. This function assumes linearity within each segment, but the overall curve formed by the connected segments can be non-linear. For a small number of segments, linear spline models can be as easy to interpret as linear regression, as each segment can be represented by a single slope. Figure 3 provides an example of a simple linear spline with two knots (in green). These two knots divide the range of the independent variable into three segments, each with its own slope.

---

### Spin dephasing under nonlinear gradients: implications for imaging and field mapping [^eaf2803c]. Magnetic Resonance in Medicine (2012). Low credibility.

This work examines the prototypical MR echo that would be expected for a voxel of spins evolving in a strong nonlinear field, specifically focusing on the quadratic z(2) - ½(x(2) + y(2)) field. Dephasing under nonlinear gradients is increasingly relevant given the growing interest in nonlinear imaging, and here, we report several notable differences from the linear case. Most notably, in addition to signal loss, intravoxel dephasing under gradients creating a wide and asymmetric frequency distribution across the voxel can cause skewed and nonlinear phase evolution. After presenting the qualitative and analytical origins of this difference, we experimentally demonstrate that neglecting these dynamics can lead to significant errors in sequences that assume phase evolution is proportional to voxel frequency, such as those used for field mapping. Finally, simplifying approximations to the signal equations are presented, which not only provide more intuitive forms of the exact expression but also result in simple rules to predict key features of the nonlinear evolution.

---

### Using rigid motion constraints for the registration of free-form surfaces [^eaadaff5]. Journal of Digital Imaging (2001). Low credibility.

We present a new method for registration of freeform surfaces based on the iterative closest point (ICP) method and on geometric properties of reflected correspondence vectors. The method is based on computing relative gaps between reflected correspondences and between the projections of reflected correspondences along the rotation axis and using these to eliminate false matches. Experimental results on synthetic data and on real range images demonstrate that the method is robust and accurate for image registration with small motions.

---

### Characteristic rotational behaviors of rod-shaped cargo revealed by automated five-dimensional single particle tracking [^ec77546c]. Nature Communications (2017). Medium credibility.

Fig. 1
Principle and localization precision of the parallax-DIC microscope. a Schematic illustration of a gold nanorod placed in the 3D coordinate system. The x - and y -axes are set according to the polarization directions of the illumination light. The dipole shown here corresponds to the long axis of the gold nanorod, whose centroid locates at (x, y, z). The azimuthal angle and the elevation angle of the longitudinal axis of the gold nanorod are presented as ϕ and ψ, respectively. b Bright (left), dark (middle), and half-bright/half-dark (right) images of a gold nanorod (40 × 80 nm) at different orientations and vertical positions. The half-plane images are aligned by the nanorod's center of mass at the focal plane (z = 0 μm). The yellow dashed lines indicate the z -position of the center of the gold nanorod in focus. Scale bar is 1 μm. c Calibration of the 5D-SPT technique. The distance between the two half-plane images changes linearly with the z -position of the gold nanorod within ± 0.5 μm of the focal plane. The distance for an in-focus gold nanorod is defined as d 0. The error bars reflect the standard deviations of the distances measured when the nanorod's azimuthal angle ϕ changes in the range of 0–180° with 5° steps (error bar ± s.d. n = 36). The calibration curve returned a slope of +0.626 (d /Δ z) and R 2 of 0.997. d Three-dimensional localization distribution of the gold nanorod with standard deviations of 11 nm in x, 14 nm in y, and 17 nm in z. e The in-focus half-plane image patterns of a gold nanorod at different azimuthal angles when the sample slide is rotated in 5° steps for 180°. The scale bar represents 1 μm. f The normalized bright part (blue) and dark part (brown) intensities of the half-plane images on the top in each pair in E

---

### Metamaterials with index ellipsoids at arbitrary k-points [^01be2dad]. Nature Communications (2018). Medium credibility.

Forming closed equifrequency surfaces

The twisting of a single bundle in real space in the z -direction shifts the zero-frequency solution along k z and generates modes with linear dispersion along k z. However, we do not have a closed equifrequency surface, which requires a three-dimensional (3D) periodic structure. As such, we construct a 3D wire metamaterial by arranging helical wire – bundles in a two-dimensional (2D) hexagonal lattice with a lattice constant of a in the x – y plane as shown in Fig. 3a. The calculated band structure is shown in Fig. 3e. As expected, this bundle array supports quasistatic modes locating atfor m = ± 1, ± 2, ± 3. In the vicinity of, linear bands emerges along the Γ - A direction as shown in Fig. 3e. Their group velocities are plotted in Fig. 3g by black dotted lines, which are almost the same as that of a single bundle in Fig. 2c (colored lines in Fig. 3g). There is weak coupling between neighboring bundles since the eigenfields of the quasistatic modes localize strongly between the wires of the same bundle. The group velocities of m = ± 1 mode deviates from the single bundle case more than that of m = ± 2, ± 3, because the quasistatic mode with smaller m decays more slowly according to Eq. (3). Due to the weak coupling, the dispersion is nearly flat in the k x – k y plane for any value of k z. In other words, the band dispersions along the k z direction are almost independent of k x and k y (see Supplementary Note 4 and Supplementary Fig. 3). Similar flat equifrequency surfaces have been found in 2D wire arrays, which can be used for subwavelength imaging. Apart from the linear bands emerging at(m = ± 1, ± 2, ± 3), two linear bands emerge from the Γ point (the lowest two bands from k z = 0 to k z = 0.1 π / d), whose eigenfields resemble the plane-wave solutions with circular polarization (see Supplementary Fig. 4). As a chiral hyperbolic medium, its equifrequency surface consists of an ellipse and two flat sheets centered at the Γ point (see Fig. 3i for equifrequency surfaces at frequency 0.02 c / d). The other 10 flat sheets in Fig. 3i stem from the quasistatic modes at(m = ± 1, ± 2, ± 3).

---

### Topological data analysis in medical imaging: current state of the art [^dbb4626f]. Insights Into Imaging (2023). Medium credibility.

For example, suppose we have three points in a two-dimensional point cloud, two of which are closer together than either is to the third point (Fig. 1). In this example, we can take three patients who present with malignancy, each having a different 3D tumor volume on CT imaging. For patients 1 and 2, their volumes are similar and form a simplicial complex with only a small distance threshold. If we expand our distance threshold, we can now include other values that are increasing dissimilar, connecting all three points to create a triangle. In practice, we'd have many more points and dimensions in our point cloud, but this illustrates the principle of filtration and simplicial complex hierarchies at a basic level.

Fig. 1
An example of three patients with varying 3D tumor volumes within a two-dimensional point cloud. The point from patient 1 and patient 2 for 3D tumor volume is close, therefore only requiring a small distance threshold to create a simplicial complex. As the distance threshold is expanded, the simplicial complex can include additional points with increasing variance

Once the series of simplicial complexes has been built, their structures can be analyzed. Homology, a topological tool, counts the number of holes in each dimension that exist within a space. In simplicial complexes, these are connected components, loops, voids, and higher-dimensional voids. To build the intuition around this, it is important to consider a part in a simplicial complex made of three, two-way relationships (edges in a graph) but lacking a mutual three-way relationship (to form a triangle of three points within a mutual distance of each other). This forms a loop, a part of the space with a potentially higher-dimensional interaction that does not exist in the simplicial complex but includes the lower-dimensional interactions. We can consider mutual three-way relationships that do not form a mutual four-way relationship, which would create a void. Betti numbers, which track the number of holes that exist in each dimension for a space or a simplicial complex, are a good way to summarize and quantify this information.

---

### Articulation points in complex networks [^34563ec4]. Nature Communications (2017). Medium credibility.

An articulation point in a network is a node whose removal disconnects the network. Those nodes play key roles in ensuring connectivity of many real-world networks, from infrastructure networks to protein interaction networks and terrorist communication networks. Despite their fundamental importance, a general framework of studying articulation points in complex networks is lacking. Here we develop analytical tools to study key issues pertinent to articulation points, such as the expected number of them and the network vulnerability against their removal, in an arbitrary complex network. We find that a greedy articulation point removal process provides us a different perspective on the organizational principles of complex networks. Moreover, this process results in a rich phase diagram with two fundamentally different types of percolation transitions. Our results shed light on the design of more resilient infrastructure networks and the effective destruction of terrorist communication networks.

---

### Phase informed model for motion and susceptibility [^b1900879]. Human Brain Mapping (2013). Low credibility.

Performing the Dynamic Distortion Correction

From Eq. (5), the resulting map of local phase changes associated with each time point i can be scaled from radians to a change in B 0 field, ΔΒ 0 i in Hz by dividing by the echo time, TE, of the EPI volume, and a value of 2π since the phases are given in radians (i.e. ΔΒ 0 i = Δ ϕ correction i /(2π TE)). ΔΒ 0 i must be divided by the bandwidth per pixel in the phase‐encode direction, BW PE, to give the relative distortion in voxels, resulting in a voxel displacement map (vdm):Each vdm i describes the voxel displacement in the phase encode direction caused by the change in field at each voxel in the distorted image i with respect to the space of the first image. To calculate the field required to correct for the relative distortion between each image and the first in the time series, the vdm i must be inverted. For this inversion procedure, the forward mapping gives us x′ = f (x) for each value x on a regular grid, where x is a 1‐dimensional column in the phase encode direction. The inverse mapping yields x = f −1 (x ′) for each value x ′ on a regular grid. It is calculated by, for each value x ′, finding the first x i so that f (x i) > x ′ and then finding x by linear interpolation between f (x i −1) and f (x i). This is a valid procedure as long as f (x) is monotonously increasing, which is the case in general. When it is not, i.e. when the off‐resonance field changes very rapidly over space (compared with the effective encoding gradient strength), there will be almost total signal loss in the gradient echo EPI images, so the displacement of the nonexistent signal will not matter. Finally, at each time point i, the original distorted image can be distortion corrected to the space of the first image by resampling distorted image voxels at new locations along the phase encode direction according to the values in the vdm i [Hutton et al. 2002; Jezzard and Balaban, 1995].

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^13a4a404]. Magnetic Resonance in Medicine (2021). Medium credibility.

FIGURE 4
A, A region contours of constant Bz for Y gradient coil, with (red) and without (black) E max optimization, showing that gradient distortion is virtually identical despite the peak E‐field being reduced by a factor of 2.8 for the Y coil. B, Difference in the B y components of the gradient field with versus without E‐field optimization. Values are normalized to the gradient strength yielding units of length (mm) and show a highly uniform concomitant y‐directed field added to the optimized (asymmetric) solution. C, Wire pattern representing the difference between optimized (asymmetric) and nonoptimized (symmetric) solutions with same current scaling as Figure 3. Similar results are obtained for the X gradient coil

The key difference between the E‐field minimized and nonminimized solutions is the addition of a uniform concomitant B 0 field component in the x or y direction. Figure 4B shows a difference plot of the concomitant B y field, normalized to gradient strength (units of millimeters), which is responsible for the reduction in E‐field. Figure 4C shows the winding that would need to be added to the Y symmetric coil (Figure 3B) to obtain the winding pattern of the Y asymmetric coil (Figure 3D), and shows the fundamental difference between the two solutions. The winding in Figure 4C produces a uniform field transverse to the main B 0 field, resulting in a concomitant component with additional magnetic stored energy. Conceptually, this can be thought of as a second coil, which if activated, converts the symmetric coil into an asymmetric coil with reduced E‐field but otherwise identical distortion. The added concomitant field in Figure 4B is highly uniform with a 0.85% variation over the 26‐cm imaging region, resulting in minimal distortion of the desired gradient field; this concomitant field can be compensated with a phase/frequency offset correction by the scanner. Figure 4B shows that the average concomitant field of 88.5 mm within the imaging region can be directly compared with the z 0x defined by Meier et al, 29 in which a value of 127 mm was reported for an asymmetric head gradient. The z 0x for both the ESP and HG2 gradients are approximately 120 mm 30; these are both fully asymmetric designs (single eye per half coil with all return currents flowing above the head), similar to the original concept defined by Roemer. 12 The X coil of Figure 3 requires a smaller concomitant field (z 0y = 57.8 mm) than the Y coil, reflecting a decreased need to pull E‐field off the torso region due to the smaller extent of the body in the anterior–posterior direction.

---

### Novel surgical safety zones on bony-en-face view of humeral greater tuberosity: a fresh cadaveric dissection study [^0238b312]. Journal of Shoulder and Elbow Surgery (2025). Medium credibility.

Background

The neurovascular alignment in the humeral greater tuberosity (HGT) region has not been thoroughly investigated. However, many studies have documented the vascular-nerve architecture of the proximal humerus. The purpose of this study was to identify novel safety zones on the bony-en-face view of the HGT for surgical procedures.

Methods

Eighteen complete adult fresh frozen cadavers (36 paired shoulders) were dissected in this study (12 males and 6 females; mean age of 69.39 years). Five landmarks-A, B, C, D, and E-were established to define the boundary of the HGT. Point A was the intersection of the superior facet of HGT and the intertubercular groove of the long head of the biceps tendon. Point B was the junction of the attachment point between the supraspinatus and the infraspinatus muscle. Point C was the intersection of the infraspinatus and the teres minor muscle and point D was the lowest foot point of the teres minor muscle. Point E was on a vertical intersection line from point D to point A. Next, we segmented the individualized pentagon ABCDE into 15 zones. First, we drew line BF to ensure it was perpendicular to DE. Then, we designated points H, J, and M as the midpoints of the supraspinatus, infraspinatus, and teres minor, respectively, with H and J perpendicular to DE and M perpendicular to EA. Finally, we drew perpendicular lines from points J, C, and M to EA, which intersected at points K, G, and L, respectively. The neurovascular structures in each zone were identified to enable the calculation of percentages, allowing for the definition of safe and dangerous zones.

Results

We have identified the specific ranking of the safe zones for branches of the circumflex humeral artery as follows: 1a (19.44%, meaning blood vessels were observed in 7 of 36 shoulders, accounting for 19.44% of the total); 3a (25%); 2a (47.22%); 7 (66.66%); 2b (75%); 1b (77.77%); 3b (80.55%); 4, 10, and 11 (all 88.88%); 6 and 8 (both 91.67%); and 5, 9, and 12 (all 100%). The specific zone ranking of vascular-branch numbers is as follows: 1a < 3a < 2a < 7 < 2b < 1b < 10 < 3b < 4 < 6 < 11 < 8 < 9 < 12 < 5. The specific ranking of the dangerous zones for the anterior branches of the axillary nerve is 8 (5.55%), 11 (8.33%), 10 (38.88%), and 9 (66.66%).

Conclusion

We demonstrate the neurovascular distribution in the 15 zones on the bony-en-face view of the HGT, clearly highlighting both safe and dangerous zones. We recommend following clinical suggestions based on our anatomical findings: (1) selection of safe insert points from zones 1a, 3a, 2a, or 7 for screw fixation (Liu-Gang type I & II) and (2) avoidance of neurovascular dangerous zones 8, 11, 10, and 9 for plate fixation. However, we should keep in mind that this technique cannot prevent vascular disruption in these areas.

---

### Engineering phase and polarization singularity sheets [^352c3afb]. Nature Communications (2021). High credibility.

Engineered phase-singularity sheet

As a proof-of-concept for singularity sheet engineering, we design a 2D phase-singularity sheet with a heart-shaped cross-section (Fig. 3). The heart-shaped singularity is centered at z = 10 mm and is designed for the scalar field associated with the x -polarized electric field at λ 0 = 532 nm emitted from a 0.8 mm × 0.8 mm patterned aperture. The paraxial scalar field approximation (qualitatively supported by the propagation distance to the target plane being much larger than the aperture size) is justified by a full vectorial propagationof the electromagnetic fields, which shows that the time-averaged energy density associated with the y (transverse) and z (axial) polarization components over the volume of interest is much smaller (in this case, < 0.05%) than that of the x -polarization. The sheet singularity is constructed by maximizing the phase gradient in the directions oriented normally to a heart-shape at the target z = 10 mm plane. The free parameters are the propagation phase delay (from 0 to 2 π) at each pixel on the patterned aperture located at z = 0 mm. The optimized phase pattern is shown in Fig. 3b and does not exhibit any discernible long-scale pattern apart from a series of concentric rings, which appear to apply a focusing effect. Figure 3a shows a field intensity isosurface of the singularity profile to depict its orientation in 3D space (real and imaginary zero-isosurfaces are plotted in Supplementary Fig. 3), along with the locations and directions at which the phase gradient maximization was performed. This surface represents the points at which the phase gradient is very large, nearly reaching 100 times the wavenumber k 0. Simulated cross-sectional intensity and phase plots at the z = 10 mm plane are depicted in Fig. 3d, g, respectively. There is a visible phase jump of π radians across the singularity boundary as the field changes sign. The phase profile is in fact continuously differentiable with a well-defined phase gradient and just achieves a large gradient value at the singularity boundary. In Fig. 3c, we plot this phase gradient magnitude |∇ ⊥ ϕ | 2 = (∂ x ϕ) 2 + (∂ y ϕ) 2 profile alongside the intensity and phase profiles for the linear cut indicated in Fig. 3d. These profiles are qualitatively similar to those of a transverse cut through the singular optical axis of a fundamental LG 0,1 vortex beam of the same wavelength (with a beam waist diameter equal to the diagonal of the 0.8 mm × 0.8 mm square aperture), which are plotted using dotted lines in Fig. 3c. The transverse phase gradient over the transverse plane is plotted in Supplementary Fig. 4. This phase gradient achieves large magnitudes near the heart-shaped boundary and even exceeds k 0 by an order of magnitude, thereby exhibiting superoscillatory behavior. The longitudinal behavior of this cut profile with z is displayed in Supplementary Fig. 5, which shows that |∇ ⊥ ϕ | exceeds k 0 for a superoscillatory region ~150 μm in front of and behind the target z = 10 mm plane. The characteristic depth of this singularity sheet using this superoscillatory region is thus around 300 μm. The depth of a singularity sheet can be extended by maximizing the phase gradient over more than one transverse plane. We also exhibit additional phase-singularity sheet shapes (flat sheet and double-walled cylinders) in Supplementary Fig. 6 to demonstrate the versatility of this algorithm.

---

### Advanced optical analysis of divergence between the foci of the neodymium-doped yttrium aluminum garnet (Nd: YAG) and aiming beam lasers [^3e1f1249]. Ophthalmology Science (2024). Medium credibility.

Purpose

To evaluate the divergence between the neodymium-doped yttrium aluminum garnet (Nd:YAG) surgical laser and the aiming diode laser beams foci.

Design

Optical analysis and measurements were performed using a Volk Goldmann 3-mirror lens with a Nidek YC-1800 Nd:YAG laser apparatus.

Subjects

None.

Methods

We used the Zemax OpticStudio program for the model of Nd:YAG treatment in a human eye. Additionally, theoretical calculations were performed.

Main Outcome Measures

The divergence between the Nd:YAG laser focus and the intersection of the 2 aiming beams inside the eye.

Results

Focal points of the 2 laser beams converge 8 mm behind the cornea. Posterior to this point, the intersection of the diode laser aiming beams lies in front of the focal point of the Nd:YAG treatment laser, with distance between the 2 foci progressively increasing up to 305 microns at 24 mm behind the cornea.

Conclusions

We report the degree of divergence between the 2 lasers' focal points due to the difference in refraction between the corresponding wavelengths. These results have high practical relevance, as they provide a starting point for increasing the accuracy of Nd:YAG laser treatment, particularly when applied to the posterior segment, thereby minimizing the risk of complications. Current Nd:YAG laser devices have the built-in ability to modify the focal point of the aiming beam along the z -axis, thus providing possibility for an immediate application of our findings in clinical practice.

Financial Disclosures

The authors have no proprietary or commercial interest in any materials discussed in this article.

---

### Atlas (C1) lateral mass screw placement using the intersection between lateral mass and inferomedial edge of the posterior arch: a cadaveric study [^f3e7920d]. European Spine Journal (2022). Medium credibility.

Purpose

To compare the Atlas (C1) lateral mass screw placement between screw trajectories of 0° and 15° medial angulation while using the intersection between lateral mass and inferomedial edge of the posterior arch.

Methods

Forty-eight Atlas lateral masses were prepared and divided into 2 groups: Group 1; screws inserted at 3 mm lateral to the reference point with screw trajectory of 0° angulation(N = 24) and Group 2; those inserted with screw trajectory of 15° medial angulation(N = 24). We evaluated the atlas anatomy, screw purchase and the presence of any breaches using CT scan.

Results

The radiographic parameters for Groups 1 and 2 were found statistically different (p-value < 0.05): bilateral intraosseous screw lengths (17.92 ± 1.47 mm. vs. 20.71 ± 2.4 mm.), bilateral screw length (29.92 ± 1.72 mm. vs. 33.13 ± 1.78 mm.), left screw medial angulation (x°) (0.67° ± 0.78° vs.14.17° ± 3.51°), right screw medial angulation (y°) (0.83° ± 1.03° vs.14.25° ± 2.53°) and bilateral screw medial angulation (0.75° ± 0.9° vs. 14.21° ± 2.99°). Twenty-two screws (91.67%) using the 0° medial angulation and nineteen screws (79.17%) using the 15° medial angulation had no cortical violations (Grade 0). However, two screws (8.33%) with 0° medial angulation and five screws (20.83%) with 15° medial angulation had breach less than 2 mm (Grade 1). There were no screws with breach between 2 and 4 mm (Grade 2) or greater than 4 mm. (Grade 3).

Conclusion

A starting point of 3-mm lateral to the intersection between lateral mass and inferomedial edge of the Atlas posterior arch can be safely and effectively used to insert C1 lateral mass using both 0° and 15° medial angulation.

---

### Multiple tipping points and optimal repairing in interacting networks [^419121d8]. Nature Communications (2016). Medium credibility.

Systems composed of many interacting dynamical networks-such as the human body with its biological networks or the global economic network consisting of regional clusters-often exhibit complicated collective dynamics. Three fundamental processes that are typically present are failure, damage spread and recovery. Here we develop a model for such systems and find a very rich phase diagram that becomes increasingly more complex as the number of interacting networks increases. In the simplest example of two interacting networks we find two critical points, four triple points, ten allowed transitions and two 'forbidden' transitions, as well as complex hysteresis loops. Remarkably, we find that triple points play the dominant role in constructing the optimal repairing strategy in damaged interacting systems. To test our model, we analyse an example of real interacting financial networks and find evidence of rapid dynamical transitions between well-defined states, in agreement with the predictions of our model.

---

### Ultrasound-guided extraforaminal thoracic nerve root block through the midpoint of the inferior articular process and the parietal pleura: a clinical application of thoracic paravertebral nerve block [^a71c0b89]. Journal of Pain Research (2022). Medium credibility.

Figure 2
In-plane puncture was performed laterally to medially. (A) Ultrasonic probe and thoracic vertebra are in transverse position. (B) The probe could be rotated 5–15 degrees toward the caudal end to avoid the rib or scapula. (C) Oblique line A (red) and vertical line B (blue) were marked along the edges of the PP and IAP on ultrasonography, respectively. The starting point of line B was the IAP, and the end point was the intersection with line A. The midpoint of line B was the puncture end-point. (D) Puncture with a 22-gauge Tuohy needle using the in-plane technique.

To analyze the technique, we performed anteroposterior (AP) and lateral X-ray fluoroscopy to observe the position of the needle tip when the ultrasonic procedure was completed. A 2-mL volume of radiopaque agent (Iohexol, 50 mL: 17.5g, Shanghai General Pharmaceutical Co. Ltd.) was then injected to observe its diffusion range by fluoroscopy. After injection of the radiopaque agent, patients received 2 mL of 1% lidocaine as the experimental dose for 5 minutes. If the patient did not experience any adverse reactions such as chest pain, local anesthesia poisoning or total spinal anesthesia, a single 5 mL mixture of 0.3% ropivacaine (AstraZeneca AB, Sweden) and 4 mg of dexamethasone palmitate (Mitsubishi Tanabe Pharma Corporation, Japan) was injected. All drugs were injected in real time under ultrasound.

All procedures were performed by two pain management physicians (Pu S and Wu J), who were trained and had more than 10 years of professional experience in pain management using interventional techniques.

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^070d751c]. Magnetic Resonance in Medicine (2021). Medium credibility.

Force and torque constraints can be added using the known main B 0 field distribution, integrating over the current distribution for each basis function and entering the results into matrix H or C. One row is added for each direction of force or torque, to obtain an overall magnitude constraint. Eddy currents are computed in a similar manner; the step response for time‐dependent eddy currents on the surface of a conducting cylinder — typically the thermal shield in the magnet — is computed at multiple points in space and time. Each point in space and time is entered as a separate inequality constraint equation. It is usually sufficient to constrain eddy currents at time = 0 following a step change in gradient current, reducing the size of the problem.

Finally, and of primary significance to the present work, E‐field constraints can be handled in a similar manner to those for force and torque. At gradient frequencies of interest, the time evolution of E‐fields in human tissues is short, and therefore proportional to instantaneous slew rate and not the detailed waveform shape in time. Thus, given a body model, the E‐field is computed from each gradient coil basis function for unit slew rate at a series of points over the body surface, such as using the methods we have described recently. 17 Calculation at points on the interior of the model is not required, as the maximum magnitude always occurs on the surface of a uniform body model (see Supporting Information). A magnitude constraint is created on the surface by placing a series of rotated inequality constraints on the vector E‐field tangent to the surface. For example, we choose 32 directions at each point spaced over 360º, which constrains the magnitude to within 0.5% of the desired value.

---

### Creating, moving and merging dirac points with a fermi gas in a tunable honeycomb lattice [^88961d7c]. Nature (2012). Excellent credibility.

Dirac points are central to many phenomena in condensed-matter physics, from massless electrons in graphene to the emergence of conducting edge states in topological insulators. At a Dirac point, two energy bands intersect linearly and the electrons behave as relativistic Dirac fermions. In solids, the rigid structure of the material determines the mass and velocity of the electrons, as well as their interactions. A different, highly flexible means of studying condensed-matter phenomena is to create model systems using ultracold atoms trapped in the periodic potential of interfering laser beams. Here we report the creation of Dirac points with adjustable properties in a tunable honeycomb optical lattice. Using momentum-resolved interband transitions, we observe a minimum bandgap inside the Brillouin zone at the positions of the two Dirac points. We exploit the unique tunability of our lattice potential to adjust the effective mass of the Dirac fermions by breaking inversion symmetry. Moreover, changing the lattice anisotropy allows us to change the positions of the Dirac points inside the Brillouin zone. When the anisotropy exceeds a critical limit, the two Dirac points merge and annihilate each other-a situation that has recently attracted considerable theoretical interest but that is extremely challenging to observe in solids. We map out this topological transition in lattice parameter space and find excellent agreement with ab initio calculations. Our results not only pave the way to model materials in which the topology of the band structure is crucial, but also provide an avenue to exploring many-body phases resulting from the interplay of complex lattice geometries with interactions.

---

### Assumptions of statistical tests: what lies beneath [^d7ecccf4]. The Journal of Foot and Ankle Surgery (2017). Low credibility.

We have discussed many statistical tests and tools in this series of commentaries, and while we have mentioned the underlying assumptions of the tests, we have not explored them in detail. We stop to look at some of the assumptions of the t-test and linear regression, justify and explain them, mention what can go wrong when the assumptions are not met, and suggest some solutions in this case.

---

### Point singularity array with metasurfaces [^7b75dc33]. Nature Communications (2023). High credibility.

Fig. 2
Comparison between two methods of producing 0D singularities: intensity minimization and phase gradient maximization.

Only field behavior along the optic axis (z axis) is shown for simplicity. a Real (E r) and imaginary (E i) parts of scalar field E in the vicinity of a low intensity position with minimum intensity ϵ. Intensity minimization at z = 0 does not take the spatial distribution of fields around the low intensity point into account, producing fields with slowly varying E r and E i through the minimum, thereby producing a broad intensity minimum. b On the contrary, since phase gradient maximization at z = 0 simultaneously minimizes the intensity there and maximizes the field slopespassing through that point, the resultant intensity minimum is narrow. c The phase gradient peak through z = 0 for the field in (a) produced by intensity minimization there is typically much lower than that of phase gradient maximization, as depicted in (d), which plots the phase gradient for the field in (b).

---

### Sources of path integration error in young and aging humans [^feeec22b]. Nature Communications (2020). High credibility.

Most participants showed a characteristic increase in path integration error over the course of their trajectories (Fig. 2a). We first pooled path integration errors across individuals, separately for the group of young and older adults, and evaluated whether participants' performance in the path integration task was better than random guessing. Indeed, estimates of location were highly correlated with true location (Fig. 2b; r = 0.64–0.94, all p < 0.00001) while shuffled responses across trials (corresponding to different trajectories) per stopping point exhibited much larger squared errors (Fig. 2c).

Fig. 2
Path integration performance across both age groups.

a Absolute path integration errors over four stopping points for young and older adults. Average errors per stopping point are shown for each participant separately by blue (young adults) and orange (older adults) dots, connected with lines between stopping points. b Each participant's location estimate (y -axis) versus their true location (x -axis) at each of the four stopping points (columns), separately for x -coordinates (top row) and y -coordinates (bottom row). Plots show data from all participants and all paths. The diagonal (dashed line) indicates perfect response (estimated location = true location). All correlation coefficients are statistically significant (all p < 0.00001). Units are meters. c Absolute path integration errors of young and older adults versus errors with shuffled responses. It is evident that the mean absolute path integration error of both groups (solid lines) is much lower than the errors obtained from shuffling each participant's responses across trials. Error bars indicate group mean ± SEM.

---

### 3D atomic structure from a single X-ray free electron laser pulse [^d0199ca7]. Nature Communications (2024). High credibility.

Experimental setup

We have developed the experimental procedure for x-ray holography for many years at synchrotron sources and could reach measuring times in the range of 1 s for a statistically meaningful pattern. Kossel line pattern measurements require a very similar setup as inside source holography. except the spatial resolution of the 2D detector used for parallel detection of the fluorescent intensity forming the Kossel lines or the hologram. The short measuring time of holograms and Kossel lines at synchrotronsprompted us to try the measurement of Kossel lines at XFEL sources. We realized the possibility of collecting a pattern during a single pulse. Starting from intensity considerations only, this conclusion seems trivial, since in the probe beam at a synchrotron we have about the same number of photons during 1 s as we have in a single XFEL pulse. However, the collection of all these photons in the very short time of an XFEL pulse with the precision necessary for distinguishing the lines from the background is not straightforward. The reason is that the detectors used at synchrotrons are counting detectors, while their XFEL counterparts are charge-integrating detectors. We have already experienced at synchrotrons that the detector is the weak point in the measurement. Since at XFEL-s, the detector problem is even more pronounced, we tried to optimize all other experimental conditions for this demonstration experiment. First, we used samples (GaAs, GaP) from which we already collected good Kossel patterns or expected good-quality patterns. This allows us to check and strengthen the validity of XFEL measurements. Second, we choose the incident energy (10.5 keV) to excite only one element of the sample (Ga), increasing this way the signal to background ratio. Third, the sample was placed in He atmosphere in order to decrease air scattering. Unfortunately, we could not optimize two more parameters, the sample thickness and the experimental geometry. In the experiment, we used 100 micron thick samples in transmission geometry (Fig. 2 top left). None of the reflection geometries (Fig. 2 top right) were available due to technical limitations and the sample was thicker than the optimal 20–30 microns. Higher intensities obtained from thinner samples or in reflection geometry would cause saturation and malfunction of the detector. The implemented forward transmission arrangement (Fig. 2 bottom photo) yielded about 20/120 and 200/800 fluorescent photons/pixel/pulse at the edges/center of the 4 M Jungfrau detectorplaced at 120 mm from the sample for GaAs and GaP, respectively. Due to the mismatch between the detector speed and the intra-train pulse repetition rate only a single pulse was used from each train, namely data was acquired at 10 Hz. The spot size on the sample was set by compound refractive lenses to ~25 μm diameter. In one shot we had about 1 mJ total energy. Since pulses have different total energies because of the stochastic nature of the spontaneous emission, we took several shots, every shot at a new place of the sample to avoid the effect of radiation damage. With these beam parameters, we do not expect distortion of the Kossel lines caused by radiation damage. The radiation damage and possible nonlinear effects are discussed in more detail in the Supplementary Information file Supplementary Note 2. The sample motion was controlled by a fast x-y scanner, while the sample surface was checked by an optical microscope. Good shots were selected by visual inspection and statistical analysis of the recorded detector images later in the evaluation process.

---

### Biomarkers of severity and threshold of allergic reactions during oral peanut challenges [^5647322a]. The Journal of Allergy and Clinical Immunology (2020). Medium credibility.

Models combining different biomarkers to predict severity and threshold dose of allergic reactions during oral peanut challenges

We designed multivariate models combining different parameters to determine the risk of a severe reaction and, with the application of our findings to routine clinical practice in mind, we used these models to generate nomograms (Fig 4 A and see Fig E10, A - H in this article's Online Repository at). We performed internal validation of these models by using the bootstrap to correct for the bias of using the same data to fit and validate the model. Although the performance of both multivariate models was good (Table III), on the basis of calibration, the model including the BAT more accurately predicted the probability of severe or life-threatening reactions than did either the model without the BAT or the individual tests.

Fig 4
Nomogram for predicting reaction severity using the BAT, the SPT, and level of Ara h 2–specific IgE (A) and nomogram for predicting cumulative dose threshold using the BAT, the SPT, level of Ara h 2–specific IgE, and IgG4/IgE ratio (B) on the basis of the LEAP and PAS studies when subjects were approximately 5 years of age. Predictions from the models can be made in a clinical setting by simply adding up points earned from each of the variable axes and then using that total to read estimated probabilities from the probability axes. A, For example, if we encounter a participant with an rArah h 2 level of of 1.5, a peanut SPT result of 8, and a BAT result of 53, we first find the value 1.5 along the axis associated with rArah h 2 (second from the top) and read vertically up to the corresponding point along the top Points axis (blue arrow). Similarly, we find the value 8 along the Peanut SPT axis and follow vertically to the Points axis to find that a Peanut SPT result of 8 earns about 76 points (red arrow). Similarly, a BAT value of 53 earns about 78 points (green arrow). Totaling the points earned from each variable gives 155 points for this participant. We find this total points value on the Total Points axis (fourth from the bottom) and imagine a vertical line extending down from that point intersecting each of the probability axes. These points of intersection are the predicted probabilities of falling into each of the severity categories. Given the values for the aforementioned hypothetical participant, we estimate less than a 10% chance of having a severe reaction, a 90% chance of having a moderate reaction, and less than a 10% chance of no reaction. B, For example, if we suppose that in addition to the biomarker values seen in (A), the participant has a log 10 -IgG4/IgE ratio to peanut of 1.6, the nomogram could be used if we wanted to estimate the mean cumulative tolerated dose, or the probabilities of having mean cumulative doses greater than 0.1 g or 9.35 g given these biomarker values. With a BAT value of 53 we accrue about 62 points, and with an Ara h 2 value of 1.5 we accrue about 5 points; a peanut wheal of 8 gives about 85 points, and an IgG4/IgE ratio of 1.6 gives about 95 points. This individual then has about 247 points in total, which gives an estimated mean cumulative tolerated dose of less than 1 g of peanut, a 45% chance of tolerating more than 0.1 g of peanut, and less than a 10% chance of tolerating more than 9.35 g of peanut. In fact, this individual had a severe reaction during the peanut double-blind placebo-controlled food challenge (DBPCFC) and tolerated 0 g of peanut.

---

### Critical exponents and scaling invariance in the absence of a critical point [^7f60fa59]. Nature Communications (2016). Medium credibility.

The paramagnetic-to-ferromagnetic phase transition is classified as a critical phenomenon due to the power-law behaviour shown by thermodynamic observables when the Curie point is approached. Here we report the observation of such a behaviour over extraordinarily many decades of suitable scaling variables in ultrathin Fe films, for certain ranges of temperature T and applied field B. This despite the fact that the underlying critical point is practically unreachable because protected by a phase with a modulated domain structure, induced by the dipole-dipole interaction. The modulated structure has a well-defined spatial period and is realized in a portion of the (T, B) plane that extends above the putative critical temperature, where thermodynamic quantities do not display any singularity. Our results imply that scaling behaviour of macroscopic observables is compatible with an avoided critical point.

---

### Identifying domains of applicability of machine learning models for materials science [^72c4ba76]. Nature Communications (2020). High credibility.

An illustrative example

Before describing the details of DA identification and its integration into the ML process, let us illustrate the concept and its utility via a synthetic example (see Fig. 1). We consider a simple two-dimensional representation consisting of independent features x 1 and x 2 that are each distributed according to a normal distribution with mean 0 and variance 2 (N (0, 2)) and a target property y that is a third-degree polynomial in x 1 with an additive noise component that scales exponentially in x 2 :That is, the y values are almost determined by the third-degree polynomial for low x 2 values but are almost completely random for high x 2 values. Discovering applicable domains reveals how different models cope differently with this setting even if they have a comparable average error. To show this, let us examine the error distributions obtained from three different kernelized regression models of the formwith parameter vector ν that are fitted around a training, or fitting (F), setwith three different choices for the kernel function k. We observe:
When using the linear (lin) kernel, the resulting linear model is globally incapable to trace the variation of the third-order polynomial except for a small stripe on the x 1 -axis where it can be approximated well by a linear function. Consequently, there is a very high error globally that is substantially reduced in the DA described by σ lin (x 1, x 2) ≡ −0.3 ≤ x 1 ≤ 0.3.
When using the Gaussian kernel), the resulting radial basis function (rbf) model is able to represent the target property well locally unless (a) the noise component is too large and (b) the variation of the target property is too high relative to the number of training points. The second restriction is because the rbfs have non-negligible values only within a small region around the training examples. Consequently, the discovered DA is not only restricted in x 2 -direction but also excludes high absolute x 1 -values: σ rbf ≡ −3.3 ≤ x 11 ≤ 3.1 ∧ x 2 ≤ 0.1.
In contrast, when using the non-local third-degree polynomial (poly) kernel, data sparsity does not prevent an accurate modeling of the target property along the x 1 -axis. However, this non-locality is counterproductive along the x 2 -axis where overfitting of the noise component has a global influence that results in higher prediction errors for the almost deterministic data points with low x 2 -values. This is reflected in the identified DA σ poly (x 1, x 2) ≡ −3.5 ≤ x 2 ≤ 0.1, which contains no restriction in x 1 -direction, but excludes both high and low x 2 -values. This highlights an important structural difference between the rbf and the polynomial model that is not reflected in their similar average errors.

---

### Atomic structure and domain wall pinning in samarium-cobalt-based permanent magnets [^6e7f1588]. Nature Communications (2017). Medium credibility.

Transmission electron microscopy

Figure 1 shows bright-field transmission electron microscopy (TEM) images and selected area electron diffraction (SAED) patterns of two different samples. Figure 1a is a bright-field TEM image of sample 1 (lower iron content, see Table 1) oriented close to the [110] pole in two-beam condition. The diamond-shaped cellular structure of the 1:5 boundary phase and the Z-phase, therefore show strong diffraction contrast. A detailed energy-dispersive X-ray microanalysis (EDX) of the single phases is presented in Supplementary Fig. 1 and Supplementary Table 1. The diamond-shaped cellular structure has a uniform size ~200 nm and is very well aligned. The Z-phase platelets are ~4 nm in height and are densely distributed. They intersect the 10-nm-thick diamond-shaped 1:5 boundary phase. Figure 1b shows a SAED pattern along the [110] zone-axis (red part) with a [100] oriented twin (blue part). The inset shows a line profile along the [00l] direction. The additional reflections marked by the triangles as well as the slight streaking originate from the Z-phase platelets forming an ordered superstructure along the c -axis direction (see the {0,0,3/2} type of reflections revealed by the line profile). Figure 1c is a bright-field TEM image of sample 2 (higher iron content, see Table 1) oriented close to the [210] pole in two-beam condition. The Z-phase shows here diffraction contrast, however, the striking difference compared to sample 1 is that there is no diamond-shaped cellular structure in the 1:5 boundary phase present. Only single, isolated facets of 1:5 cells are found. Figure 1d shows a SAED along the [210] zone-axis. The different zone-axis orientation makes no difference to the visibility of the 1:5 cellular structure in the two-beam condition obtained bright-field TEM images. The strong streaking being present in the SAED along the [00l] direction originates from the presence of the Z-phase platelets. The inset shows a line profile along the [00l] direction with additional reflections marked by triangles. These additional reflections do not lie on the center between two regular spots of the Sm 2 Co 17 (2:17) phase as it is the case for sample 1 indicating together with the stronger streaking a larger Z-phase disorder for sample 2 as compared to sample 1. Therefore, it is obvious that the structure of sample 2 strongly deviates from that of sample 1: There is no diamond-shaped cellular structure of the 1:5 phase visible at all. However, still isolated unequally distributed 1:5-type lamellas occur. Some of them seem to act as bridges perpendicularly connecting to the Z-phase platelets. Those bridges may be boundaries between two phases, as the Z-phase platelets should only grow in one direction. A few of the Z-phase platelets also suddenly end somewhere in the 2:17 matrix, especially in sample 2.

---

### Estimation in medical imaging without a gold standard [^82dda7fe]. Academic Radiology (2002). Low credibility.

Rationale and Objectives

In medical imaging, physicians often estimate a parameter of interest (eg, cardiac ejection fraction) for a patient to assist in establishing a diagnosis. Many different estimation methods may exist, but rarely can one be considered a gold standard. Therefore, evaluation and comparison of different estimation methods are difficult. The purpose of this study was to examine a method of evaluating different estimation methods without use of a gold standard.

Materials and Methods

This method is equivalent to fitting regression lines without the x axis. To use this method, multiple estimates of the clinical parameter of interest for each patient of a given population were needed. The authors assumed the statistical distribution for the true values of the clinical parameter of interest was a member of a given family of parameterized distributions. Furthermore, they assumed a statistical model relating the clinical parameter to the estimates of its value. Using these assumptions and observed data, they estimated the model parameters and the parameters characterizing the distribution of the clinical parameter.

Results

The authors applied the method to simulated cardiac ejection fraction data with varying numbers of patients, numbers of modalities, and levels of noise. They also tested the method on both linear and nonlinear models and characterized the performance of this method compared to that of conventional regression analysis by using x-axis information. Results indicate that the method follows trends similar to that of conventional regression analysis as patients and noise vary, although conventional regression analysis outperforms the method presented because it uses the gold standard which the authors assume is unavailable.

Conclusion

The method accurately estimates model parameters. These estimates can be used to rank the systems for a given estimation task.

---

### Assessing and improving reliability of neighbor embedding methods: a map-continuity perspective [^ab4f01c9]. Nature Communications (2025). High credibility.

LOO-map reveals intrinsic map discontinuities

By analyzing the LOO loss, we identify the two observed discontinuity patterns as a result of the map discontinuities of f (x). We use t-SNE as an example to illustrate the main results.

We generate mixture data by sampling 500 points from two overlapping 2D Gaussian distributions and run t-SNE with two representative choices of perplexity, 5 and 50. The resulting visualizations confirm the two discontinuity patterns (Fig. 3 a). OI discontinuity pushes mixed points to cluster boundaries, creating overly tight structures, while FI discontinuity fragments embeddings into small pieces, leading to many sub-clusters. Similar discontinuity patterns are also common among other neighbor embedding methods (Supplementary Fig. 1).

Fig. 3
LOO loss landscape reveals the origins of two distortion patterns.

a We illustrate two discontinuity patterns on simulated Gaussian mixture data. OI discontinuity: t-SNE embeds points into well-separated clusters and creates visual overconfidence. FI discontinuity: t-SNE with an inappropriate perplexity creates many artificial fractures. b Origin of OI discontinuity: LOO loss contour plot shows distantly separated minima. We add a new input point x at one of the 4 interpolated locations x = t c 1 + (1 − t) c 2 where t ∈ {0, 0.47, 0.48, 1} and then visualize the landscape of the LOO loss L (y; x) using contour plots in the space of y. The middle two plots exhibit two well-separated minima (orange triangle), which cause a huge jump of the embedding point (as the minimizer of the LOO loss) under a small perturbation of x. c Origin of FI discontinuity: We show LOO loss contour plots with interpolation coefficient t ∈ {0.2, 0.4, 0.6, 0.8}. The plots show many local minima and irregular jumps. Under an inappropriate perplexity, the loss landscape is consistently fractured. Numerous local minima cause an uneven trajectory of embedding points (dashed line) when adding x at evenly interpolated locations. Source data are provided as a Source Data file.

---

### Transient power-law behaviour following induction distinguishes between competing models of stochastic gene expression [^b2b32cdd]. Nature Communications (2025). High credibility.

However, it is important to remember that these results rest on four main assumptions: (i) the number of cells is infinite — this is implicit in the calculation of the mean mRNA count from the CME; (ii) linear regression on the log-log plots is the optimal method to infer the exponent; (iii) all mRNA molecules in each cell are detected; (iv) the initial distribution of gene states is a Dirac delta function centred on one of the inactive states.

To address the limitations (i) and (ii) we used the following simulation protocol. We first chose a subset of 20 different parameter sets from those previously analyzed in Fig. 4. These are distinguished from each other by the mean mRNA count at the last time point which varies between 1 and 25 to capture the realistic range of mRNA abundance in mammalian cells (the median mRNA count per cell for a population of exponentially growing mouse fibroblasts is approximately 17). For each parameter set, we used the SSA to generate a dataset of mean versus time (sampled at 5-time points) for a finite population of M cells and linear regression was used to obtain the exponent from the log-log plots, as before. Repeating this procedure 5000 times leads to a distribution of exponent values. In Supplementary Fig. 3 we summarise these distributions by means of boxplots for the N -state model with N = 5, j = 4 and for populations of sizes M = 100, 500, 1000 and 10,000. The medians of all boxplots are in good agreement with the exponent estimated assuming an infinite population size (Fig. 4). Except for populations of 100 cells, the statistical dispersion as measured by the interquartile range is small indicating that for sample sizes of 500 or more cells, uncertainty in the exponent estimates due to finite sample size effects are negligible. This conclusion is valid independent of the mean mRNA count at the last time point, i.e. the method is robust even if the mean count is of order 1. Similar results are obtained when the inference is repeated using non-linear regression applied to the mean count versus time plots (Supplementary Fig. 4) and for the N -state model with N = 5, j = 1 (Supplementary Figs. 5–6).

---

### Correlation coefficients: appropriate use and interpretation [^02578b5f]. Anesthesia and Analgesia (2018). Low credibility.

Correlation in the broadest sense is a measure of an association between variables. In correlated data, the change in the magnitude of 1 variable is associated with a change in the magnitude of another variable, either in the same (positive correlation) or in the opposite (negative correlation) direction. Most often, the term correlation is used in the context of a linear relationship between 2 continuous variables and expressed as Pearson product-moment correlation. The Pearson correlation coefficient is typically used for jointly normally distributed data (data that follow a bivariate normal distribution). For nonnormally distributed continuous data, for ordinal data, or for data with relevant outliers, a Spearman rank correlation can be used as a measure of a monotonic association. Both correlation coefficients are scaled such that they range from -1 to +1, where 0 indicates that there is no linear or monotonic association, and the relationship gets stronger and ultimately approaches a straight line (Pearson correlation) or a constantly increasing or decreasing curve (Spearman correlation) as the coefficient approaches an absolute value of 1. Hypothesis tests and confidence intervals can be used to address the statistical significance of the results and to estimate the strength of the relationship in the population from which the data were sampled. The aim of this tutorial is to guide researchers and clinicians in the appropriate use and interpretation of correlation coefficients.

---

### Solving the where problem and quantifying geometric variation in neuroanatomy using generative diffeomorphic mapping [^fd44f32f]. Nature Communications (2025). High credibility.

The statistical interpretation allows us to accommodate images with non reference signals, such as missing tissue, tracer injection sites, or other anomalies. At each pixel, the identity of the signal type is modeled as missing data, and maximum likelihood estimators are computed using an Expectation Maximization algorithm, which alternates between the E step: compute posterior probability π i (x) that each pixel corresponds to the reference image rather than one of the non-reference types, and the M step: update parameters by solving a posterior weighted version of the above:As an EM algorithm, this approach is guaranteed to be monotonically increasing in likelihood. An example of posterior weights are shown in the right hand column of Fig. 2 b.

Our approach uses mixtures of Gaussians to model variability in data, to allow large outliers to be accommodated by additional components, even though the Gaussian distribution itself does not have long tails. The Gaussian model allows for closed form expression (in terms of matrix inverse) for contrast transformation parameters. Other groups have used long tailed distributions to model variability and outliers in a robust manner, most notably the exponential distribution for l1 optimization. Techniques such as iteratively reweighted least squares can be applied as in Reuter et al. which lead lead to a weighted least squares problem which is similar to ours.

Nonconvex optimization with low to high dimensional subgroups and resolutions

This registration problem is highly nonconvex, and allows for many local minima. To provide robustness in our solution, we solve a sequence of lower dimensional subproblems, initializing the next with the solution to the previous. (i) 2D slice to slice rigid alignment maximizing similarity to neighbors(ii) 3D affine only alignment, registration using the full model at (iii) low (200 μm), (iv) medium (100 μm), and (v) high (50 μm) resolution. Time varying velocity fields are discretized into 5 timesteps and integrated using the Semi Lagrangian method. For most subproblems, spatial transformation parameters are estimated by gradient descent, and intensity transformation parameters are updated by solving a weighted least squares solution at each iteration. For subproblems that include linear registration only, parameters are estimated using Reimannian gradient descent (discussed in ref.and similar to a second order Gauss–Newton optimization scheme).

---

### Probabilistic alignment of multiple networks [^39aa70ac]. Nature Communications (2025). High credibility.

The network alignment problem appears in many areas of science and involves finding the optimal mapping between nodes in two or more networks, so as to identify corresponding entities across networks. We propose a probabilistic approach to the problem of network alignment, as well as the corresponding inference algorithms. Unlike heuristic approaches, our approach is transparent in that all model assumptions are explicit; therefore, it is susceptible of being extended and fine tuned by incorporating contextual information that is relevant to a given alignment problem. Also in contrast to current approaches, our method does not yield a single alignment, but rather the whole posterior distribution over alignments. We show that using the whole posterior leads to correct matching of nodes, even in situations where the single most plausible alignment mismatches them. Our approach opens the door to a whole new family of network alignment algorithms, and to their application to problems for which existing methods are perhaps inappropriate.

---

### Dynamic spatiotemporal beams that combine two independent and controllable orbital-angular-momenta using multiple optical-frequency-comb lines [^b1e0a989]. Nature Communications (2020). High credibility.

Novel forms of beam generation and propagation based on orbital angular momentum (OAM) have recently gained significant interest. In terms of changes in time, OAM can be manifest at a given distance in different forms, including: (1) a Gaussian-like beam dot that revolves around a central axis, and (2) a Laguerre-Gaussian ([Formula: see text]) beam with a helical phasefront rotating around its own beam center. Here we explore the generation of dynamic spatiotemporal beams that combine these two forms of orbital-angular-momenta by coherently adding multiple frequency comb lines. Each line carries a superposition of multiple [Formula: see text] modes such that each line is composed of a different [Formula: see text] value and multiple p values. We simulate the generated beams and find that the following can be achieved: (a) mode purity up to 99%, and (b) control of the helical phasefront from 2π-6π and the revolving speed from 0.2–0.6THz. This approach might be useful for generating spatiotemporal beams with even more sophisticated dynamic properties.

---

### Uncomputability of phase diagrams [^e853d9ad]. Nature Communications (2021). High credibility.

The phase diagram of a material is of central importance in describing the properties and behaviour of a condensed matter system. In this work, we prove that the task of determining the phase diagram of a many-body Hamiltonian is in general uncomputable, by explicitly constructing a continuous one-parameter family of Hamiltonians H(φ), where [Formula: see text], for which this is the case. The H(φ) are translationally-invariant, with nearest-neighbour couplings on a 2D spin lattice. As well as implying uncomputablity of phase diagrams, our result also proves that undecidability can hold for a set of positive measure of a Hamiltonian's parameter space, whereas previous results only implied undecidability on a zero measure set. This brings the spectral gap undecidability results a step closer to standard condensed matter problems, where one typically studies phase diagrams of many-body models as a function of one or more continuously varying real parameters, such as magnetic field strength or pressure.

---

### MRI features of intersection syndrome of the forearm [^fcee9d6c]. AJR: American Journal of Roentgenology (2003). Low credibility.

Objective

The purpose of this original report is to describe the MRI findings in patients with intersection syndrome of the forearm.

Conclusion

Intersection syndrome is an overuse disorder of the dorsal distal forearm, presenting with particular symptoms and signs that may be clinically misdiagnosed. MRI can perform an important role in establishing the diagnosis. Peritendinous edema (peritendinitis) around the first and second extensor compartment tendons, extending proximally from the crossover point, is the most characteristic finding that should suggest a diagnosis of intersection syndrome. Chronic cases may be subtle and not show substantial MRI findings likely reflecting the development of a stenosing tenosynovitis.

---

### SimpleITK image-analysis notebooks: a collaborative environment for education and reproducible research [^8b7ece08]. Journal of Digital Imaging (2018). Low credibility.

We provide several components for display and interaction purposes that are useful for obtaining input for various registration and segmentation tasks:,… All components allow the user to zoom and pan the displayed images as part of the supported interactions.

Thecomponent allows one to acquire point data in two volumetric image domains either as input for paired point registration or for the acquisition of corresponding point pairs for registration evaluation. The component operates in two modes, one for data acquisition and the other for visual inspection of registration results. In data acquisition mode, the two volumes are displayed side by side and the user can localize corresponding points. Undoing the last point localization and clearing all data are supported. The interface forces the user to localize a point in each volume interleaving between the two. In visual inspection mode, in addition to the images, the user is required to provide a transformation that maps between the two volumes. In this mode, when the user localizes a point in one volume, it is mapped and displayed on the other volume using the given transformation or its inverse; this is sometimes referred to as linked cursor mode.

Thecomponent allows one to display a volumetric image and localize points as input for various segmentation algorithms that require user-supplied seed points. The component also allows one to add pre-determined point indexes with the constraint that they are inside the image index bounds. Note that the output from this component are the physical coordinates of the points in the image's coordinate system and not the point indexes.

Thecomponent allows us to display multiple volumetric images with the same dimensions side by side using a single slider to scroll through the image stack. This is a useful interface for qualitative evaluation of image registration and segmentation results. In the registration case, prior to using the interface one image is resampled to the grid of the other so that they share the spatial extent and dimensions. In the segmentation case, the results of several segmentation algorithms or segmentation steps can be visually compared side by side.

Finally, thecomponent displays a volumetric image and allows us to interactively select one or more box-shaped regions of interest. This is useful for creating masks for registration, limiting the computation of the similarity measure to the regions of interest or for segmentation purposes such as determining a local threshold in a region of interest.

---

### Quantum criticality in electron-doped BaFe2-xNixAs2 [^d499bedd]. Nature Communications (2013). Medium credibility.

A quantum critical point is a point in a system's phase diagram at which an order is completely suppressed at absolute zero temperature (T). The presence of a quantum critical point manifests itself in the finite-T physical properties, and often gives rise to new states of matter. Superconductivity in the cuprates and in heavy fermion materials is believed by many to be mediated by fluctuations associated with a quantum critical point. In the recently discovered iron-pnictide superconductors, we report transport and NMR measurements on BaFe(2-x)Ni(x)As₂ (0 ≤ x ≤ 0.17). We find two critical points at x(c1) = 0.10 and x(c2) = 0.14. The electrical resistivity follows ρ = ρ₀+AT(n), with n = 1 around x(c1) and another minimal n = 1.1 at x(c2). By NMR measurements, we identity x(c1) to be a magnetic quantum critical point and suggest that x(c2) is a new type of quantum critical point associated with a nematic structural phase transition. Our results suggest that the superconductivity in carrier-doped pnictides is closely linked to the quantum criticality.

---

### Guidelines for validation of next-generation sequencing-based oncology panels: a joint consensus recommendation of the Association for Molecular Pathology and college of American pathologists [^01148c3a]. The Journal of Molecular Diagnostics (2017). Medium credibility.

Nonparametric tolerance intervals for non-normal distributions: The above estimate of the tolerance interval would only be applicable to a population that is normally distributed, but when the underlying population is often not normal (eg, when there is a natural boundary that the data cannot exceed (ie, 0% or 100%)) it is helpful to define tolerance intervals using nonparametric methods; the one-sided nonparametric tolerance interval can be determined by finding the value for k that satisfies the cumulative binomial equation, where CL is the confidence level (eg, 0.95), and by setting k = 0 (ie, 0 failures) the formula can be simplified.

---

### Spirometry in occupational health-2020 [^fa524370]. Journal of Occupational and Environmental Medicine (2020). High credibility.

Spirometry in occupational health — early termination error arises "when expiration stops before the volume-time curve flattens into a 1-second plateau", so "the FVC may not be fully recorded". Such incomplete recordings "falsely increase the FEV1/FVC and may cause the spirometer interpretation to be 'normal' even when airways obstruction is present". The example shows Length of Test 5 sec versus 10 sec with FVC (L) 3.53 versus 4.08 and Ratio 69% versus 60%; "the dashed line shows the increase in FVC that would have occurred with only 5 more seconds of expiration", and "the resulting higher FVC and the lower, more accurate FEV1/FVC would trigger a correct interpretation of 'airways obstruction'. The note states "subjects should try to exhale to a 1-second plateau when possible", "however, curves longer than 15 seconds should not be recorded", and coaching is "keep blowing until I tell you to stop".

---