# Medical Question & Answer

**Sample ID**: 00a88e53-9516-c796-3a81-a368706b0265
**Dataset Index**: 223080

---

## Question

5. Given A([1/3], [1/a]), B([1/4], [1/b]), C([1/5], [1/c]) satisfy [a/(b + c)] = [1/3], [b/(a + c)] = [1/2]. Then the positions of points A, B, C are suitable for
(A) on the same straight line
(B) forming an acute triangle
(C) forming a right triangle
(D) forming an obtuse triangle

---

## Answer

> Let's see… What do we have here? The user is asking whether three points A, B, and C, defined in terms of parameters a, b, and c that satisfy two given ratio equations, are collinear or form an acute, right, or obtuse triangle. Let's break this down step-by-step. First, I need to think about solving the system of equations for a, b, and c. Then, I should verify the coordinates of A, B, and C. Next, I will check for collinearity using slopes or the area of the triangle. Finally, I will classify the triangle by its angles if it is not collinear, and confirm the correct option.

> Let me first confirm the given conditions and the points. We have A(1/3, 1/a), B(1/4, 1/b), C(1/5, 1/c), and the constraints a/(b + c) = 1/3 and b/(a + c) = 1/2. I need to solve these two equations for a, b, and c, recognizing that we have two equations in three unknowns, so I should expect a one-parameter family of solutions and then see if the geometric conclusion is invariant to that parameter.

> I will now examine the algebra. From a/(b + c) = 1/3, I get 3a = b + c, and from b/(a + c) = 1/2, I get 2b = a + c. Wait, let me verify the substitution path. Substituting c = 3a − b into the second equation gives 2b = a + (3a − b), which simplifies to 3b = 4a, so b = 4a/3. Then c = 3a − 4a/3 = 5a/3. So the solution set is parameterized by a, with b = 4a/3 and c = 5a/3, and I should confirm that these satisfy both original equations before proceeding.

> Hold on, let's not jump to conclusions about the points themselves. I initially thought the coordinates might be A(1/3, a), B(1/4, b), C(1/5, c), but wait, that would misread the y-coordinates. Let me correct that: the points are A(1/3, 1/a), B(1/4, 1/b), C(1/5, 1/c), so with b = 4a/3 and c = 5a/3, the y-coordinates become 1/a, 3/(4a), and 3/(5a) respectively. I should double-check that these expressions are correct before moving on.

> Next, I should review collinearity. A quick way is to compute the area of triangle ABC; if the area is zero, the points are collinear. Using the determinant formula for area with points (x1, y1), (x2, y2), (x3, y3), the area is 1/2 |x1(y2 − y3) + x2(y3 − y1) + x3(y1 − y2)|. Plugging in the coordinates, I get 1/2 |1/3(3/(4a) − 3/(5a)) + 1/4(3/(5a) − 1/a) + 1/5(1/a − 3/(4a))|. Let me simplify this carefully: 1/3(3/(4a) − 3/(5a)) = 1/3 · 3/(20a) = 1/(20a), 1/4(3/(5a) − 1/a) = 1/4 · (−2/(5a)) = −1/(10a), and 1/5(1/a − 3/(4a)) = 1/5 · 1/(4a) = 1/(20a). Summing these gives 1/(20a) − 1/(10a) + 1/(20a) = 0, so the area is zero and the points are collinear.

> But wait, what if I made a sign error or arithmetic mistake? Let me verify using slopes as a cross-check. The slope of AB is (1/b − 1/a)/(1/4 − 1/3) = (3/(4a) − 1/a)/(−1/12) = (−1/(4a))/(−1/12) = 3/a, and the slope of AC is (1/c − 1/a)/(1/5 − 1/3) = (3/(5a) − 1/a)/(−2/15) = (−2/(5a))/(−2/15) = 3/a. Since the slopes are equal and the points share no common x-coordinate, the points are indeed collinear, confirming the determinant result.

> Given that the points are collinear, I should confirm which option this corresponds to. Option A states the points are on the same straight line, which matches our derivation. Options B, C, and D presume a non-degenerate triangle, which is not the case here, so the correct choice is A.

---

The points A, B, and C are **collinear** because the slopes of AB and BC are equal, both being 3/a. This means they lie on the same straight line, so the correct answer is **(A) on the same straight line**.

---

## Step 1: Solve for a, b, and c

Given the equations:

[
\\frac{a}{b + c} = \\frac{1}{3} \\quad \\text{and} \\quad \\frac{b}{a + c} = \\frac{1}{2}
]

Cross-multiply to obtain:

[
3a = b + c \\quad \\text{and} \\quad 2b = a + c
]

Substitute (c = 3a - b) from the first into the second:

[
2b = a + (3a - b) \\implies 2b = 4a - b \\implies 3b = 4a \\implies b = \\frac{4a}{3}
]

Then:

[
c = 3a - b = 3a - \\frac{4a}{3} = \\frac{5a}{3}
]

So the solution is:

[
a = a, \\quad b = \\frac{4a}{3}, \\quad c = \\frac{5a}{3}
]

---

## Step 2: Determine the coordinates of A, B, and C

Using the expressions for (a, b, c), the coordinates are:

- (A\\left(\\frac{1}{3}, \\frac{1}{a}\\right))
- (B\\left(\\frac{1}{4}, \\frac{1}{b}\\right) = B\\left(\\frac{1}{4}, \\frac{3}{4a}\\right))
- (C\\left(\\frac{1}{5}, \\frac{1}{c}\\right) = C\\left(\\frac{1}{5}, \\frac{3}{5a}\\right))

---

## Step 3: Check for collinearity

Calculate the slope of AB:

[
\\text{slope}_{AB} = \\frac{\\frac{3}{4a} - \\frac{1}{a}}{\\frac{1}{4} - \\frac{1}{3}} = \\frac{-\\frac{1}{4a}}{-\\frac{1}{12}} = \\frac{3}{a}
]

Calculate the slope of BC:

[
\\text{slope}_{BC} = \\frac{\\frac{3}{5a} - \\frac{3}{4a}}{\\frac{1}{5} - \\frac{1}{4}} = \\frac{-\\frac{3}{20a}}{-\\frac{1}{20}} = \\frac{3}{a}
]

Since (\\text{slope}_{AB} = \\text{slope}_{BC} = \\frac{3}{a}), the points are **collinear**.

---

## Conclusion

The points A, B, and C lie on the same straight line, so the correct answer is **(A) on the same straight line**.

---

## References

### Using both qualitative and quantitative data in parameter identification for systems biology models [^fc71653e]. Nature Communications (2018). Medium credibility.

Results

An illustration of the potential value of qualitative data

To demonstrate the potential value of qualitative data, we consider a simple case of solving for the coefficients of polynomial functions.

We consider two polynomial functions: y 1 = ax 2 − bx + c and y 2 = dx + e. Suppose we want to solve for the coefficients a, b, c, d, and e, which we will take to be positive. As the ground truth coefficients to be determined, we choose (a, b, c, d, e) = (0.5, 3, 5, 1, 1.5).

Suppose that a limited amount of quantitative information is available. Namely, it is known that the parabola y 1 contains the points (2, 1) and (8, 13), and the line y 2 contains the point (3.5,5). This is not enough information to solve for any of the coefficients because three points are required to specify a parabola, and two points are required to specify a line (Fig. 1a).

Fig. 1
A simple illustration using polynomial functions. We use qualitative and quantitative information to determine the unknown coefficients. a Visualization of the problem. We seek to find the coefficients of equations for a parabola and a line, with the ground truth shown (blue solid curves). Two points on the parabola and one point on the line are known (black dots). These three points are consistent with infinitely many possible solutions (e.g. orange dashed curves). Qualitative information (colored circles, x -axis) specifies whether the parabola is above (+) or below (−) the line. This information limits the possible values of intersection points x 1 and x 2 to the green shaded segments of the x -axis. b Bounds on coefficient values as a function of the number of qualitative points known. Shaded areas indicate the range of possible values of each coefficient

---

### A novel oppositional binary crow search algorithm with optimal machine learning based postpartum hemorrhage prediction model [^f6de23e1]. BMC Pregnancy and Childbirth (2022). Medium credibility.

Whereasrepresent the opposite number and x ∈ R denotes a real number determined on range of x ∈[a, b]. While a = 0 and b = 1 Eq. (3) becomes

While there is a point P (x 1, x 2,… x n) in n dimension coordinate and x 1, x 2,…, x n ∈ R later, the opposite pointis determined as its coordinates:

In such cases, have 2 values, x represent initial arbitrary value in [a, b] anddenotes the opposite values of x. They calculate f (x)&in all the iterations of OBCSA, later, employ on the evaluation function g ifselect x or else selectConsequently, the f l would be in range: f l ∈[f l min, f l max]. The opposite numbercan be determined by:

Later, evaluate the fitness for the first f l value and the fitness forin all the iterations. When, they select f l, or elsewould be selected. The stages of presented method can be given in the following.

Step1: The count of crows is n c = 25, f l min = 0.1, f l max = 1.8, A P = 0.3, and the maximal number of iterations is t max = 100.

Step2: The position that represent the features are made by U (0, 1).

Step3: The fitness function (FF) can be determined by

Whereas C represent the classification performance, W represent the weighted factors in the range of zero and one, F all represent the overall amount of features and F sub signifies the length of elected feature.

Step4: The position of the crows are upgraded as Eq. (2)

Step5: Steps 3 & 4 are repetitive till a t max is attained.

---

### Lunar rock investigation and tri-aspect characterization of lunar farside regolith by a digital twin [^ab658cdd]. Nature Communications (2024). High credibility.

Wheel-terrain interaction states solution

For a grouser wheel moving on deformable terrains, its wheel-terrain interaction area is shown as the left red box in Supplementary Fig. 4. In this figure, {Σ I } is the inertial frame; {Σ e } is the wheel-terrain interaction frame. {Σ c } is the wheel center frame, and its origin is on the wheel center and its orientation is the same as the interaction frame. To determine the wheel-terrain interaction plane, three points (P 1 (x 1, y 1, z 1), P 2 (x 2, y 2, z 2), and P 3 (x 3, y 3, z 3)) both on the plane and at the edge of the wheel surface are selected for calculation. P 2, and P 3 are on the outer hoops of the wheel and coincide with the entrance angle, while P 1 is on the middle hoop of the wheel coinciding with the exit angle. The positions of P 1, P 2, and P 3 are calculated using the rotation matrix R e of the wheel-terrain interaction frame {Σ e } relative to the inertial frame {Σ I } at the last time step, and the position of the wheel center p c at this time step. Therefore, the corresponding homogeneous transform matrix T c for calculation is represented inwhereis a zero matrix with one row and three columns.

The terrain map is usually divided into triangle meshes, such as A 1 - A 2 - A 3, A 1 - A 3 - A 4. Each node of the triangular mesh has associated geometric and mechanical parameters. If the contact point P i (i = 1, 2, 3) lies in such a mesh, then the normal coordinate information of point P i can be obtained by linearizing and interpolating asin which (1- u - v), u, and v are the weight coefficients of nodes A 1, A 2, and A 3, respectively, ranging from 0 to 1.

With these determined points on the wheel-terrain interaction plane, the wheel sinkage z, and the rotation matrix of {Σ e } relative to the initial frame {Σ I } at this time step used for the next iteration can be calculated according ref.

---

### Smart touchless palm sensing via palm adjustment and dynamic registration [^87365748]. Nature Communications (2025). High credibility.

Valley points detection

In this section, we detail the methodology for analyzing the optimized pathsto identify valley points between finger edges. We begin by ordering the paths according to their average y -coordinates, resulting in a sorted collection. To identify the valley points between two refined lines, we seek to find a pair of specific points, one on each line. A straight line drawn through these points should act as a common tangent to both paths, with all points on the two paths located on one side of this tangent line. This ensures consistent relational positioning of points, which is crucial for aligning ROI images across various palm samples.

For two pathsand, the objective is to find specific pointssuch that:where L is the line through, and f L (v) denotes the half-plane relative to line L in which point v resides.

Considering the variation of finger line segments n, we adopt different strategies to identify specific valley points: the valleys between the little and ring fingers, and between the index and middle fingers. For n = 2, the valley points of the palm are identified as. For n = 3, we identifyas the specific valley points. When n = 4, bothandare considered, with the decision based on comparing the Euclidean distances between adjacent points. Specifically, ifwe chooseas the valley points, where d e indicates the Euclidean distance between two points. Otherwise, are determined as the valley points. The final specific valley points are identified as p t 1 and p t 2, respectively, for further processing.

Coordinate system establishment

Figure 5b illustrates the establishment of the palm coordinate system, with its origin set at the midpoint between the specific valley points p t 1 and p t 2. Additionally, the figure shows the geometric relationship between these valley points and the aligned ROI. Based on, the four ROI corner points p r 1, p r 2, p r 3, p r 4 in the palm coordinate system are expressed as:where l r is the Euclidean distance between the valley points p t 1 and p t 2. In addition, t 1 and t 2 are predefined parameters set toand, respectively.

To transform these pointsfrom the palm coordinate system to the image coordinate system, we use the following equations:where (x, y) represents the coordinates in the palm coordinate system,… Using these transformation equations, we can determine the coordinates of the four ROI corners in the image coordinate system, thus aligning the ROI to a unified position.

---

### Towards expert-level autonomous carotid ultrasonography with large-scale learning-based robotic system [^bb92486d]. Nature Communications (2025). High credibility.

Method. Stage 1: A convolution networkis employed to extract featuresof a batch of imagesfor multi-task learning. The features are then fed into two distinct heads. The first head (h cls) performs binary classification to determine the presence of internal membrane structures. Specifically, for a batch of N images, it predicts, eachindicates a predicted quality score between 0 and 1 of an image in the batch. The second head (h reg) predicts, eachis a 4-dimensional vector, indicating the coordinates of the bounding box's top-left and bottom-right points for an image in the batch.

During training, the backbone and the two heads are optimized jointly through binary cross entropy (BCE) loss, mean square error (MSE) loss and complete intersection over union (Complete-IoU) loss. Note that the the BCE loss is calculated on all images while the MSE loss and the Complete-IoU loss are only calculated on images which are labelled with clear internal membrane structures. The three losses are:The overall loss is a weighted sum of these three parts:

Stage 2: Inspired by previous works, we formulate the task of keypoint prediction as an offset prediction problem. Instead of directly regressing the coordinates, we first compute the mean positions of each keypoint in the training set as reference points (anchor points), and then predict the offsets to these points, as illustrated in Supplementary Fig. 6. The positional information of these reference points serves as prior knowledge, providing the model with approximate location cues for each keypoint, which has the potential to improve prediction accuracy. For simplicity, we denote the annotated key-points' y coordinate of the i -th image in a batch of N images as a i, b i, c i, where, respectively corresponding to the annotated 5 points on intima of near wall, intima of far wall and media of far wall. Before training, we firstly calculate the mean positions, for each of the point in the training dataset. Then the stage 2 models predicts offsets for each point relative to the corresponding mean positions:whererepresents the local region detected in Stage 1 that contains clear intima-media structures, with its spatial coordinates determined by. Since the x coordinates are fixed during annotation, only the y coordinates need to be predicted. The actual y coordinates are then computed from the predicted offsets through. The stage 2 models are optimized using the Mean Squared Error (MSE) loss function:

---

### Mean-shift exploration in shape assembly of robot swarms [^4d6e03f3]. Nature Communications (2023). High credibility.

Parameterization of the position and orientation of the desired shape

Another two parameters of the desired shape are the center position and orientation. There is no centralized assignment of the position or orientation. The robots can negotiate the two parameters in a distributed manner.

Before proceeding further, we need to introduce some necessary notations that will be used frequently later. Suppose there are n robot mobile robots inand n robot ≥ 2. Each robot is regarded as a circle with the radius as r body. Letbe the position of the center point of robot i in a global coordinate frame. The dynamic model of each robot is assumed to bewhere i = 1,…, n robot. Here, v i is the velocity command to be designed. When the distance between two robots is less than a threshold r sense, the two robots could share information with each other. The information network defines an undirected graph, which consists of a vertex setand an edge setsuch that. Here, ∥ ⋅ ∥ is the Euclidean norm. The set of neighbors of robot i is.

Suppose ρ o is the cell located closest to the center of the desired shape. Letandbe the position and velocity of the center point of cell ρ o in a global reference frame. Let ϕ denote the orientation angle of the desired shape. Then, the position and orientation of the desired shape could be represented byand ϕ, respectively.

Every robot has its own interpretation ofand, denoted asand. Initially, and, which means that each robot initially treats itself as the center of the desired group shape. The interpretations of different robots can gradually reach a consensus by the following distributed negotiation algorithm:There are two terms in (3). The first term in (3) is the average of the deficiency of the position interpretations between robot i and its neighbors. Here, sign(⋅) and ∣ ⋅ ∣ denote the sign and the absolute value of a real number. In addition, c 1 > 0 and 0 < α < 1 are two constant gains. The role of the first term is to drivewhere. The second term is the average of the velocities of the neighboring robots. Its role is to drivewhere. Since α < 1, consensus can be achieved in a finite time. This is important for speeding up the negotiation process. The convergence analysis is given in Theorem 1 in the Supplementary Information.

---

### Accurate global and local 3D alignment of cryo-EM density maps using local spatial structural features [^d632f584]. Nature Communications (2024). High credibility.

Results

Overview of the CryoAlign procedure

Figure 1a illustrates the workflow of CryoAlign. When provided with a density map, CryoAlign applies uniform sampling to generate a set of initial grid points, which act as the starting positions for the subsequent alignment process. At each sampled grid point, a corresponding density vector is assigned to reflect the trend of changes in density within its vicinity. These density vectors are derived from VESPER, which demonstrates their effectiveness as a representation of the local density variations around the grid points. However, the excessive number of initial grid points and the limited representation range of density vectors make them unsuitable for direct alignment. CryoAlign uses a mean shift algorithmto identify local dense points and applies a density-based spatial clustering methodto find cluster centers as the key points of point clouds (see the "Methods" section). The key points extracted by CryoAlign are chosen to consider both the distribution of density values and the connectivity of points, providing a rough representation of the protein backbones. Next, local spatial structural feature descriptors are calculated on the extracted key points by block-wise analyzing the distribution of density vectors within their vicinity. Compared to vectors, local feature descriptors capture structural information from multiple neighboring points instead of just a single grid point. This approach provides a more distinctive and comprehensive description of the local region, effectively improving the accuracy of the alignment results. Finally, CryoAlign implements a two-stage alignment approach to achieve accurate superimposition from coarse to fine. In the first stage, CryoAlign utilizes a mutual feature-matching strategy in the feature domain to establish correspondences between key points and efficiently estimate initial poses. This stage enables fast and stable alignment, laying the foundation for subsequent refinement. In the second stage, CryoAlign focuses on achieving the best possible superimposition. It considers the point-to-point correspondences between the initial grid points in the spatial domain and employs an iterative process to bring these points closer together. By iteratively adjusting the positions of overlapping points, CryoAlign continues to improve the alignment and strives for optimal alignment accuracy.

---

### Efficient self-organization of informal public transport networks [^f89ffbbd]. Nature Communications (2024). High credibility.

Detour profile

The length L of a route is the sum of distances between the successive GPS points. The GPS data is sufficiently detailed that this captures the influence of street geometry like curved roads. We quantify the structural efficiency of a route of length L by its detour profile d x, denoting the relative detour of smaller route segments of length L /3 at position x ∈ [0, 1] along the route. Each segment starts at a GPS point in the route and extends along the route to the first GPS point such that it has length ≥ L /3. Consequently, x = 0 denotes the segment starting at the first point in the route and ending at the first point at or beyond length L /3. Similarly, x = 1 denotes the segment starting at the last point before or at length 2 L /3 and ending at or slightly before the last point in the route. Due to the small spacing between successive GPS coordinates, the differences in segment length are small compared to the total length of a route (compare also Fig. 2 c and Supplementary Note 2).

To compute the detour factor d x of a segment at position x, we compute the shortest path distance s x between its start and end point in the street network from OpenStreetMap. The detour factor of the segment is then given as the relative detournormalized with respect to the segment length to keep the normalization the same for all segments since≈ L /3 (see Supplementary Note 2 for details and interpretation). The detour factor d x as a function of the position x along the route is the detour profile of the route. The detour profile of a city is the medianover all individual routes in the city for each normalized location x along the routes. In all figures, we illustrate the spatially resolved detour profiles by evaluating them at 50 approximately equally spaced points along the routes.

---

### An introduction to machine learning [^f0a93ce2]. Clinical Pharmacology and Therapeutics (2020). Medium credibility.

UNSUPERVISED LEARNING

In exploratory data analysis, we often do not know the true "labels", or we might want to examine the naturally emerging patterns in the data. For this purpose, we can use unsupervised learning methods, like clustering, frequent pattern detection, and dimensionality reduction. Here, we will focus particularly on clustering and dimensionality reduction as they have many applications in molecular biology and clinical practice.

Clustering

The goal of applying clustering methods is to identify relevant subgroups in a given dataset without having a predefined hypothesis on the properties subgroups might have. For example, in a cohort of patients with a particular disease, we might want to identify subtypes that represent distinct biological mechanisms driving the disease based on molecular measures taken. 17

A cluster is a subset of the data which are "similar" to each other, whereas points belonging to different clusters are more "different". There are multiple approaches to clustering that use different underlying algorithms to group data points by their "similarity". All of them have advantages and disadvantages and needed to be selected carefully depending on the application and properties of the data.

One simple approach to clustering is k ‐means clustering. 18 Here, the number of clusters to be identified is predefined by a user‐selected parameter k. Each cluster is represented by a cluster center, which is an artificial data point that represents the mean (or median) value of all points assigned to this cluster. In the beginning, k cluster centers, known as "seeds", are randomly placed in the feature space. The algorithm then iterates through two steps. In step one ("assignment"), data points are assigned to the cluster represented by the closest center. In step two ("center shift"), the position of each cluster center is updated based on the composition of the clusters after step one. After a number of iterations, this will usually converge to a local optimum where cluster assignments do not or only marginally change. The result of such a process is visualized in Figure 2 b. Although the procedure is intuitive, its major drawback is that usually the clustering is strongly influenced by the value of k, and more often than not the true number of clusters in the data is unknown a priori. Because there is rarely a clear cut right or wrong answer in clustering, further cluster investigation is required to identify meaningful clusters, which can be challenging particularly in the light of a high‐dimensional feature space.

---

### Enhancing endoscopic measurement: validating a quantitative method for polyp size and location estimation in upper gastrointestinal endoscopy [^1ac585ec]. Surgical Endoscopy (2024). Medium credibility.

Corresponding points

Repetitive and indistinctive texture surfaces in endoscopic images can adversely affect the feature detection and matching algorithms. Consequently, in this paper, we explore a new approach for determining corresponding points based on shape context, which is unaffected by the texture-less nature of the endoscopic images.

An object's shape can be represented by a discrete set of points, denoted P = ,…, where∈ R2 from the internal or external contours of the object. In the case of a polyp, the shape can be defined by a set of points located on its border. Given the set of points P, with n points of the polyp shape in one image and the set of points Q, with m points in the other image, the shape context method can be used to find one-to-one correspondences between these two 2D sets of points, P and Q. The shape context is a vector of local geometric information that characterises the distribution of points around a reference point on the shape boundary. The shape context can be defined as a histogram using a log-polar coordinate system. The log-polar system represents a point based on the logarithm of its distance from the origin (log r) and its angle (θ) from a reference direction. This is illustrated in Fig. 3 with a log-polar coordinate system of 5 bins for log r and 12 bins for θ.

Fig. 3
Concept of the Shape Context. Top row: Sample points on the border of one polyps in two endoscopic images and the diagram of a log-polar coordinate system with five bins for log r and 12 bins for ɵ. Bottom row: Shape context for reference samples marked by green, red and blue, on the polyp border (Color figure online)

Two shapes of the polyp border in two endoscopic images are presented by sample points. Considering a log-polar coordinate system; each shape context is a log-polar histogram of the coordinates of the rest of the point set measured using a reference point as the origin of the log-polar coordinate system. As shown in Fig. 3, the shape context of relatively similar points (i.e.g.reen and red) on the polyp border is visually more similar, while the shape context of another point (i.e. blue) is quite different. This concept was used to find corresponding points along the border of a polyp in the present study. The result of finding corresponding points for one polyp in the pig stomach experiment using this approach is illustrated in Fig. 4.

---

### Hierarchical organic microspheres from diverse molecular building blocks [^7f2fe368]. Nature Communications (2024). High credibility.

Establishment of coordinate systems and surface modeling of HOMs

The coordinates for the tips of the echinate HOMs and the intersection points of the striated HOMs were generated using ImageJ software from the corresponding SEM images. By default, the pixel at the top left corner of the SEM image was set as the origin point. We introduced a third z-coordinate to generate three-dimensional coordinates of all the points from their two-dimensional projections in SEM. An ellipsoid model with the following general formula. Here, (x, y, z) is the coordinate of a point. (a, b, 0) is the center coordinates of the ellipsoid. A, B, and C are the major axis, intermediate axis, and minor axis of the ellipsoid, respectively.

Subsequently, based on the corresponding surface equation, we deduce and calculate the z-axis coordinate for each point (Supplementary Methods 8 and Supplementary Code 2). For the images with multiple particles, the recognition of tips was automatically performed by ImageJ. Only tips from microspheres at the top layer were considered. Undesired tips for microspheres at deeper layers can be filtered by adjusting the brightness threshold since the tips at the top tend to appear brighter due to discharge effects in electron microscopy.

Geometric parameterization of HOMs based on the Delaunay triangulation

After obtaining the coordinates of selected points, we performed Delaunay triangulation on the point sets using MATLAB R2021a (Supplementary Methods 9 and Supplementary Code 3). We employed the built-in Delaunay module in MATLAB to perform triangulation to obtain the corresponding point connection. Subsequently, taking into account the z-axis coordinates, we calculated the average length of all triangle edges, which was set as the initial average. Based on the closest packing model, the distance from a tip to its second nearest tip is √3 times the distance to the nearest tip. So, the threshold value will be set as √3 times the initial average. All the larger lengths will be filtered. Then, we recalculated the average of the remaining lengths as the final result. The overall procedure is illustrated in Supplementary Figs. 19 and 20, and all the related data is listed in Supplementary Data 1.

---

### Accurate global and local 3D alignment of cryo-EM density maps using local spatial structural features [^c687aade]. Nature Communications (2024). High credibility.

Discussion

In this study, we introduced CryoAlign, a highly accurate method for aligning cryo-EM density maps at both global and local levels. CryoAlign operates by transforming the input maps into 3D points and leveraging local spatial structural feature descriptors to capture the underlying structural information effectively. The alignment process in CryoAlign is conducted in two stages. In the first stage, CryoAlign employs clustering-based key point extraction and mutual feature matching techniques to establish correspondences between the extracted key points in the feature domain. This enables CryoAlign to set a solid foundation for achieving fast and robust superimposition. In the second stage, CryoAlign focuses on establishing correct point-to-point correspondences between the sampled points in the spatial domain. By carefully building these correspondences, CryoAlign calculates the final transformation parameters, resulting in a highly precise superimposition.

CryoAlign surpasses existing methods in terms of alignment accuracy for global alignment tasks, while maintaining a good execution time. By achieving more precise density map superimposition, CryoAlign enables researchers to identify and analyze differences or changes between two maps, leading to a better understanding of biological structures. While the parameter settings used in the experiment results demonstrate the superior alignment performance of CryoAlign, it is worth noting that these settings are not necessarily optimized for all tasks or imaging environments. Users have the flexibility to explore different parameter configurations based on their specific requirements ("Parameter settings" in Supplementary Material). In addition to alignment accuracy, CryoAlign offers a scoring function that measures the similarity between two maps. This scoring function can be used in map retrieval tasks, allowing researchers to search for maps with similar characteristics or features.

---

### Metasurface-driven full-space structured light for three-dimensional imaging [^a3bfd548]. Nature Communications (2022). High credibility.

Fig. 4
Depth estimation of 3D objects.

a Schematic of the optical setup for depth estimation using 2D dot arrays scattered on objects. b Schematic of the stereo matching algorithm used in (a). The algorithm uses camera trigonometry and the coordinate difference of the dot points in two image planes. c A photograph of the objects; one placed normally and the other placed at 50° with respect to laser beam axis. d 3D depth reconstruction results of objects in (c) in different rotation view. The first and second row are the depth images of object 1 and object 2, respectively. The depths are presented in colors with respect to the image plane of camera described as the red arrows.

The depth estimation takes three steps. (1) 2D coordinate extraction of the dots from the two captured images. (2) Matching each dot in camera 1 and its corresponding dot in camera 2 (Fig. 4b). (3) Calculating the depth using the stereo camera trigonometry with the coordinate information of the matched dot pairs. In step 1, the captured images are Gaussian-blurred and binarized and then the resultant contours are detected to determine the coordinate of each dot. In step 2, to match each corresponding dot pair, we use a point set registration method called coherent point drift (CPD) (Supplementary Note 3). Due to its probabilistic modeling approach, CPD is found to be robust against outliers and missing points and can preserve the topological structure of the point sets. Note that the CPD algorithm has to compute the inversion of a M M matrix per iteration and therefore has a computation complexity ofin the case of a non-rigid transformation, where M represents the number of points. In step 3, based on the matched point pairs and the obtained camera parameters, the depth of each dot is calculated using the camera trigonometry relation.

---

### GRAF-pop: a fast distance-based method to infer subject ancestry from multiple genotype datasets without principal components analysis [^8851f403]. G3 (2019). Medium credibility.

In GRAF-pop, we use the expected D values calculated using Equation (3) to find the vertices of ΔEFA, and use it as the reference triangle to calculate barycentric coordinates. When there are missing genotypes, we first calculate the barycentric coordinates using the SNPs with genotypes, then map the coordinates onto the reference triangle when no genotypes are missing. Specifically, we do the following steps to normalize the genetic distances and plot the results:

For each subject group U {E, F, A}, calculate the expected genetic distances D U1, D U2, D U3, to the first three reference populations, using Equation (3) for the full set of 10,000 fingerprint SNPs.
Represent each group with a 3-D point in space by treating D U1, D U2, D U3 as the x, y, z Cartesian coordinates. Build a triangle by connecting the three points representing the three subject groups.
Rotate and translate the triangle so that it is in the plane z = 0, and side FA is parallel to the x -axis. Denote this triangle as ΔEFA 0, to be used as the reference triangle for calculating barycentric coordinates.
Given a subject i, find the subset, T, of fingerprint SNPs with genotypes for this subject.
For each subject group U {E, F, A}, calculate the expected genetic distances D U1T, D U2T, D U3T, to the first three reference populations using Equation (4) for subset T. Represent each group with a 3-D point in the space.
Calculate the genetic distances D i1, D i2 and D i3 from subject i to the first three reference populations. Represent subject i as a 3-D point, Q, by treating D i1, D i2, D i3 as the x, y, z Cartesian coordinates.
Build a triangle by connecting the three points representing the three subject groups. Rotate and translate the three points, together with point Q, so that the triangle is in the plane z = 0. Denote this triangle as ΔEFA T.
Using the x, y coordinates of point Q after transformation, calculate the barycentric coordinates (λ ie, λ if, λ ia) for subject i with respect to ΔEFA T, using Equations (5) and (6).
Convert the barycentric coordinates back to the Cartesian coordinates (x i0, y i0) using reference triangle ΔEFA 0: where (x e0, y e0), (x f0, y f0), (x a0, y a0) are the Cartesian coordinates of the three vertices of ΔEFA 0.
Plot the converted Cartesian coordinates of subject i, together with ΔEFA 0, on the x-y plane. The final x i0, y i0 values are the normalized genetic distances, called GD1 and GD2 scores in this article and in GRAF.
The z coordinate of point Q after transformation (step 7), called GD3 score, is also used for plotting results.
Calculate the genetic distances D i4 and D i5 from subject i to the last two reference populations South Asian and Mexican/Latino. The difference D i5 - D i4, called GD4 score, is plotted against GD1 scores to separate South Asians from Latin Americans.

---

### Evaluating continuous curvilinear capsulorhexis proficiency via video analysis [^54fa4443]. BMJ Open Ophthalmology (2025). High credibility.

Video data extraction process

Using bespoke software algorithms, individual frames from the surgical video are systematically extracted and processed in chronological order. Each frame undergoes manual annotation of the capsulorhexis forceps tip, which facilitates the extraction of detailed positional data throughout the CCC procedure. This process captures critical information regarding the forceps' displacement, movement trajectory and open/close status.

Additionally, for every surgical video, CCC-related data analysis is performed using images taken on completion of the procedure. These images incorporate the intraocular lens (a perfect circle with a diameter of 6.0 mm) and the actual morphology of the capsulorhexis opening. The analysis employs a custom-developed script in MATLAB R2009a, V.7.8.0.347 (MathWorks, Natick, Massachusetts, USA), establishing a two-dimensional (2D) coordinate system. Here, the centre of the limbus functions as the origin, while the intraocular lens (IOL) diameter serves as the scale. The resulting 2D coordinates of the CCC's centre position are then used to calculate specific quantitative metrics (figure 2).

Figure 2
Data processing workflow illustration. This workflow outlines the systematic processing of continuous curvilinear capsulorhexis video data using MATLAB. (A) Video frame extraction: the VideoReader function in MATLAB is employed to extract the video as sequential distinct images. (B) Feature point annotation: MATLAB function is used to annotate specific feature points, such as the tip of the forceps, the limbal boundary and the capsulorhexis edge, etc. The annotated data are then systematically stored in a coordinate file. (C) Data interpretation and metric calculation: a specialised MATLAB data reading function is responsible for interpreting the information contained within the coordinate file.

Video data analysis

Total duration of the CCC Procedure as θ 1

After the creation of the flap, the moment when the capsulorhexis forceps first make contact is designated as the starting point, while the point at which the CCC is completed serves as the endpoint. The interval between these two points is recorded in seconds. A threshold value of = 25 s has been established. The specific calculation and determination method for this parameter is as follows:

Effective CCC operation duration as θ 2

This is the total CCC operation time minus the duration spent adjusting the position of the capsulorhexis forceps, measured in seconds. A threshold value of = 20 s has been established. The specific calculation and determination method for this parameter is as follows:

---

### Filopodia-based contact stimulation of cell migration drives tissue morphogenesis [^44e029fb]. Nature Communications (2021). High credibility.

Mercator projection

An approximation of the central axis is performed by splitting the dataset in ten subsets along the x -axis. In every subset, yz coordinates of the center point are approximated by triangulation using the leftmost, rightmost, and uppermost points. A central axis is derived from the point of gravity of the first five subsets and the last five subsets. Based on that, the x -axis is moved with a rotation matrix. This process gets reiterated three times (summarized in Fig. 3b–c).
An yz -vectorfrom every point's respective yz -coordinate to the yz -coordinate of the central axis is generated. Its magnitude is the radiusof this point. The maximal radius of all points is. The formula of the central angle θ depends on the position of the yz coordinates of every respective point. For y n < y axis and z n > z axis the formula is For y n > y axis and z n > z axis the formula is For z n < z axis the formula is A new y -coordinate is generated using the formula (summarized in Supplementary Fig. 2c–e).
To correct the x -axis with respect to, all datapoints are sorted by x -coordinate.is the x -coordinate of a given spot before correction.is the point preceeding this point. Its corresponding point after correction is(summarized in Fig. 3e, f).

For the very first point the formula is:

For all further pointsthe formula is

Track speed mean was measured in motility lab using smoothed tracking data, in order not to quantify manual tracking inaccuracies.

Biased angle to x -axis

The usual biased angle method measures the bias toward a predefined point. As myotubes do not migrate toward a point, but along a defined axis, we measured the angle-distribution to the x -axis to analyze myotube directionality. As angles get strongly affected by speed, this method can only compare cells with the same distance on x value (summarized in Supplementary Fig. 3f). Rose plots were generated in R using the ggplot2 package.

---

### Spine localization in X-ray images using interest point detection [^9417708b]. Journal of Digital Imaging (2009). Low credibility.

This study was conducted to evaluate a new method used to calculate vertebra orientation in medical x-ray images. The goal of this work is to develop an x-ray image segmentation approach used to identify the location and the orientation of the cervical vertebrae in medical images. We propose a method for localization of vertebrae by extracting the anterior-left-faces of vertebra contours. This approach is based on automatic corner points of interest detection. For this task, we use the Harris corner detector. The final goal is to determine vertebral motion induced by their movement between two or several positions. The proposed system proceeds in several phases as follows: (a) image acquisition, (b) corner detection, (c) extracting of the corners belonging to vertebra left sides, (d) global estimation of the spine curvature, and (e) anterior face vertebra detection.

---

### Machine learning for cluster analysis of localization microscopy data [^acfdc75b]. Nature Communications (2020). High credibility.

Our models utilize the nearest-neighbor distance as input. To explore whether this approach was necessary, we also trained models supplied with only normalized xy coordinate data. The overall layer specification was maintained, however instead of a one-dimensional input vector of Euclidean distances for a point's 100 or 1000 nearest neighbors, a two-dimensional vector of the neighboring points' x and y coordinates (normalized and relative to the origin point's coordinates) was used. These models were able to achieve similar performance (~94% accuracy) to those trained on Euclidean distances but at the expense of considerably longer training times; for 1000 neighbors the training time, when using normalized coordinates as input, was ~15 days (excluding data preparation time) compared with a few hours for models trained using Euclidean distances (Supplementary Note 2). It is possible that this time can be improved (as for any such training task) through strategies such as early stopping to conclude training once a pre-set performance target is reached. This alternative approach still required calculation of distance matrices to identify which neighboring points' coordinates to use for training but, as it was neither faster nor more accurate than models trained on the distance values, the Euclidean distance trained models were used for the evaluation of experimental data. Computation times may be further reduced by selecting and processing candidate points for the training pool during the data simulation stage.

---

### Semiautomatic segmentation of vertebrae in lateral X-rays using a conditional shape model [^f2aa1975]. Academic Radiology (2007). Low credibility.

Rationale and Objectives

Manual annotation of the full contour of the vertebrae in lateral x-rays for subsequent morphometry is time-consuming. The standard six-point morphometry is commonly used instead. It has been shown that the information from the complete contour improves the quality of the study. In this article, the six landmarks are given and the vertebrae are segmented taking advantage of that information. The result is a semiautomatic system in which the full contour is found with high precision, and that only requires a radiologist to mark six points per vertebra.

Materials and Methods

A shape model was built for both the six landmarks and the full contours of the vertebrae L1, L2, L3, and L4 of 142 patients. The distribution of the principal components of the full contour was then modeled as a Gaussian conditional distribution depending on the principal components of the six landmarks. The conditional mean was used as initialization for active shape model optimization, and the conditional variance was used to constrain the solution to plausible shapes.

Results

The achieved point-to-line error was 0.48 mm, and 95% of the points were located within 1.36 mm of the annotated contour. The accuracy is superior to those of previously published studies, at the expense of requiring the six points to be marked. Fractures and osteophytes are well approximated by the model, although they are sometimes oversmoothed.

Conclusions

The proposed method provides hence a richer description than the six points, and can be used as input for shape-based morphometry to detect and quantify vertebral deformation more accurately.

---

### Automatic correspondence on medical images: a comparative study of four methods for allocating corresponding points [^db565d3a]. Journal of Digital Imaging (2010). Low credibility.

The accurate estimation of point correspondences is often required in a wide variety of medical image-processing applications. Numerous point correspondence methods have been proposed in this field, each exhibiting its own characteristics, strengths, and weaknesses. This paper presents a comprehensive comparison of four automatic methods for allocating corresponding points, namely the template-matching technique, the iterative closest points approach, the correspondence by sensitivity to movement scheme, and the self-organizing maps algorithm. Initially, the four correspondence methods are described focusing on their distinct characteristics and their parameter selection for common comparisons. The performance of the four methods is then qualitatively and quantitatively compared over a total of 132 two-dimensional image pairs divided into eight sets. The sets comprise of pairs of images obtained using controlled geometry protocols (affine and sinusoidal transforms) and pairs of images subject to unknown transformations. The four methods are statistically evaluated pairwise on all image pairs and individually in terms of specific features of merit based on the correspondence accuracy as well as the registration accuracy. After assessing these evaluation criteria for each method, it was deduced that the self-organizing maps approach outperformed in most cases the other three methods in comparison.

---

### Accurate global and local 3D alignment of cryo-EM density maps using local spatial structural features [^c7e6ad8a]. Nature Communications (2024). High credibility.

Advances in cryo-electron microscopy (cryo-EM) imaging technologies have led to a rapidly increasing number of cryo-EM density maps. Alignment and comparison of density maps play a crucial role in interpreting structural information, such as conformational heterogeneity analysis using global alignment and atomic model assembly through local alignment. Here, we present a fast and accurate global and local cryo-EM density map alignment method called CryoAlign, that leverages local density feature descriptors to capture spatial structure similarities. CryoAlign is a feature-based cryo-EM map alignment tool, in which the employment of feature-based architecture enables the rapid establishment of point pair correspondences and robust estimation of alignment parameters. Extensive experimental evaluations demonstrate the superiority of CryoAlign over the existing methods in terms of both alignment accuracy and speed.

---

### An improved spinning lens test to determine the stiffness of the human lens [^811629d6]. Experimental Eye Research (2011). Low credibility.

2.7 Fitting cubic splines to the lens and a circle to the calibration image

A smoothed and averaged axisymmetric representation of the lens outline at each stage in the test sequence is determined by fitting (in a least-squares sense) two cubic splines (in polar coordinates) to the set of 8 outlines determined from the images as described in Section 2.6. One spline represents the geometry above the support ring. This spline has a zero slope condition at the axis of rotation and a fixed end point at the top outside corner of the support ring (Point P 1 in Fig. 3 c). It has seven internal knots spaced at equal angular intervals, with the first knot positioned at half of this interval from the axis of rotation and the last knot positioned at one-eighth of the interval from the fixed end point. A second spline represents the outline of the lens below the supporting ring. The spline is fixed at one end to the inside corner of the support ring (Point P 2 in Fig. 3 c) and, at the axis of rotation, the slope is constrained to be zero. The spline has two internal knots. These two splines, together with the internal lens support ring surface between Points P 1 and P 2, form the full axisymmetric outline of the lens.

The reference outline (which is needed for the generation of the finite element mesh that is used to infer the lens stiffness parameters from Test B on the de-capsulated lens) is determined as described above, but on the basis of the complete set of 16 lens outlines captured in Tests B ref and C ref.

Spline representations of the lens outlines for the 33-year de-capsulated lens are plotted in Fig. 6. The target outline refers to the averaged spline representation of the lens geometry in Test B and the reference outline refers to the averaged spline representation for the lens geometry from the images collected in Tests B ref and C ref.

A similar procedure is adopted to analyse the calibration images of the ball bearing, but in this case, a circle is fitted to the outline points identified in each image. The average diameter in pixel units of these 8 circles is compared to the measured diameter of the ball bearing to determine the scale factor (mm/pixel) that is used to calibrate the observed lens outline geometries.

---

### Optically guided patient positioning techniques [^c23b2112]. Seminars in Radiation Oncology (2005). Low credibility.

Optical tracking determines an object's position by measuring light either emitted or reflected from the object. The hallmark of optical tracking systems is their high spatial resolution and measurement in real time; such systems can resolve the position of a point source within a fraction of a millimeter and report at a rate of 10 Hz or faster. Several systems have been developed for radiation therapy, all of which track infrared markers attached to the patient's external surface. The positions of the optical markers relative to the target volume, together with the desired marker positions relative to treatment isocenter, are determined during computed tomography simulation. In the treatment room, the real marker positions are measured relative to isocenter; rigid-body mathematics then determine marker displacements from their desired positions and hence target displacement from isocenter. Real-time feedback allows one to correct the patient's position. The first systems were used for intracranial stereotaxis radiotherapy; rigid arrays of optical markers were attached to the patient via a biteplate linkage. Subsequent systems for extracranial radiotherapy tracked external markers to determine patient position and/or gate the radiation beam based on patient motion. Lastly, optical tracking has been integrated with ultrasound or stereoscopic x-ray imaging to determine the position of internal anatomy targets relative to isocenter.

---

### A novel theory for rapid localization of the transverse-sigmoid sinus junction and "keyhole" in the retrosigmoid keyhole approach: micro-anatomical study, technique nuances, and clinical application [^5930bc2c]. Neurosurgical Review (2024). Medium credibility.

Fig. 1
The method of locating the keypoint and "keyhole". A: location of the TSJ; B: drilling the "keyhole" (6 mm in diameter); C: confirming the baseline; D: marking the extracranial anatomical landmarks; E: measuring the length between the anatomical landmarks; F: measuring the degree of ∠α. A: the top point of the digastric groove; B: mastoidale; C: asterion; D: keypoint; E: the central point of "keyhole"; F: mastoid foramen; K: intersection point of tangent line between inferior margin of transverse sinus and posterior margin of sigmoid sinus; TSJ: the inferior margin of the transverse sinus–medial margin of the sigmoid sinus junction; ITS: tangent line of inferior margin of transverse sinus; PSS: tangent line of posterior margin of sigmoid sinus; SNL: superior nuchal line; FHL: the baseline between the infraorbital margin and superior margin of the external acoustic meatus; ∠α: the anterior inferior angle between AD and the baseline

Fig. 2
Establishing the coordinate system for locating "keypoint" and "keyhole". A: observing the relationship between burr hole and TSJ from skull surface; B: measuring the position between point A and D in the coordinate system; C: measuring the position between point A and E in the coordinate system; D: concept of locating the central point of "keyhole" in the coordinate system. A: the top point of the digastric groove; B: mastoidale; C: asterion; D: keypoint; E: the central point of "keyhole"; F: mastoid foramen; SNL: superior nuchal line; FHL: the baseline between the infraorbital margin and superior margin of the external acoustic meatus; T: tube of emissary vein; a: the perpendicular distance between D and A in the coordinate system; b: the horizontal distance between D and A in the coordinate system; x: the perpendicular distance between E and A in the coordinate system; y: the horizontal distance between E and A in the coordinate system

---

### Human navigation strategies and their errors result from dynamic interactions of spatial uncertainties [^88fca879]. Nature Communications (2024). High credibility.

Observation model and observation variability

At each timestep, the agent makes noisy egocentric observations z t, i.e. relative distance and bearing, of landmarks and objects in the environment. When the agent encounters landmarks or objects for the first time, observations are converted to allocentric coordinates and then stored within the internal representation. The non-linear observation model z t = h (x t) + r t consists of observations with additive Gaussian noise. Once in the field of view of the agent, an observation of a landmark l consists of its distance and direction relative to the agent, which can be expressed as:We assume that correspondence between a measurement and landmark l is unambiguously known. The agent observes landmarks or targets if they fall inside the field of view of the agent. Thus the complete environment is not observable to the agent at once. Further, observations are subject to state-dependent Gaussian noise, which depends on the current position and heading direction of the agent relative to the observed object, with noise parameters.

Observations of an object's distance get noisier with increasing distance and the more peripheral they are relative to the center of the agent's field of view:where d l refers to the distance and β l refers to the angle between the agent's gaze direction and the vector between the agent and the landmark or target. Similarly, noise in the perception of the bearing of an object relative to the observer increases with both distance and relative to the center of the field of view, :Thus the perceptual uncertainty in the current observation of a single landmark can be expressed as follows:

Belief-space representation

As the true state of the world can only be perceived indirectly, the agent only has access to the belief state b t = (μ t, Σ t). This extends the state-space formulation from Eq. (10) by an explicit representation of spatial uncertainty over the agent's position, heading, landmark, and goal locations.

The belief b t at timestep t describes this as follows (t dropped for notational convenience):with the following submatrices which express the uncertainty about the current position and heading, the internal map, and the relation between those:Having access to the full belief state, rather than a single point estimate of self and landmark locations allows for the model to keep track of the growing positional uncertainty and resolve it later by actively reorienting and thereby combining noisy observations of landmarks with prior expectations based on the internal map about their relative position.

---

### Accurate global and local 3D alignment of cryo-EM density maps using local spatial structural features [^1d255951]. Nature Communications (2024). High credibility.

CryoAlign adopts a two-stage alignment architecture to achieve precise pose estimation. The aforementioned key points based feature matching is utilized in the first stage, and provides a robust but relatively coarse pose. This stage serves as a foundation for the alignment process. In the second stage, CryoAlign shifts its focus to the initial sampling points after transformation, aiming to bring the two points sufficiently close. By combining these two stages, CryoAlign generates a more accurate superimposition of the density maps. Figure 2c collects the RMSD distributions of one-stage alignment and two-stage alignment. Almost all data points are located along or above the dashed line, illustrating that the second stage refinement consistently improves the alignment accuracy. Meanwhile, the larger bubbles are mostly concentrated in the range ≤ 3 Å, showing the key role of point-based correspondences in the spatial domain in high precision alignment. Moreover, thanks to the initial pose estimation provided by the first stage, the second stage of point-based alignment requires less time to converge. Figure 2d presents the distribution of execution time for the alignment processes, revealing that the duration of the second stage is acceptable considering the improvement in accuracy.

---

### Using grid cells for navigation [^f3e2d7fc]. Neuron (2015). Low credibility.

Algorithmic Solution in 2D

In 2D, the location of an activity bump can be defined by considering any two non-collinear axes (denoted by unit vectorsand). An activity bump at phasein module i then maps onto an infinite series of periodic locations+, wherecan be any pair of integers. We initially assume, for simplicity, that the orientations of different grid modules are aligned, i.e.andare independent of i and that grid firing fields are circularly symmetric as opposed to elliptical, i.e. the scale s i is the same for directionsand(but see). In this case, the location of an activity bump within grid module i can be visualized on a cylindrical polar plot as, whererepresents the direction of the grid axes (e.g.and). Considering the phases of the goal representation along each axis, and following the logic of the 1D solution, the distance and direction to the goal location is indicated by the maximum gradient of a plane through the origin that fits the phase points p j, i + 2 πn j, i for all modules i and axes j and lies within the capacity of the grid cell system (Figure 4 C).

Again, this result can be generalized to arbitrary current and goal locations by replacing the absolute phases p j, i that define the goal location with the phase difference Δp j, i between the current and goal locations on each axis and in each module. This solution is consistent with the Fourier shift theorem (see), with the sets of grid cells in each module that share a common phase on each axis acting as Fourier components of the spatial representation. If grid cell orientations are identical across modules, then the displacement between start and goal locations can be solved independently on each axis as in the 1D case: by finding the line through the origin that best fits the phase points along that axis. We note that it is sufficient to solve for two directions, as more axes do not provide additional independent information — the constraint thatfor 3 directions separated by 120° is implicitly included by fitting lines through the origin. However, given independent noise in the firing rates of biological neurons, pooling estimates across directions could potentially mitigate error in the extracted translation vector. Additionally, if grid cell orientations are not conserved across modules, or if grid firing fields are elliptical, then the solution still holds, but the plane must be fit to a family of phase points that differ in axesacross grid cell modules and in spatial scale s i across axes.

---

### Accurate global and local 3D alignment of cryo-EM density maps using local spatial structural features [^74c519b9]. Nature Communications (2024). High credibility.

Two-stage alignment

After the sampling and clustering stages, two input density maps are efficiently transformed into point clouds and corresponding key points, denoted asfor source (moving) map, andfor target (fixed) map. In the first stage of alignment, CryoAlign utilizes a feature-based approach to estimate the initial transformation parameters. This involves collecting the key points and their corresponding feature descriptors from both the source and target point clouds. To efficiently reduce the size of the candidate set, CryoAlign employs a bidirectional nearest point matching strategy. This strategy assigns a binary value, denoted as, to each pair of key points, indicating whether they should be considered as a potential match. When, the corresponding feature pair between key pointand key pointis considered a valid match. In contrast, when, it means that the corresponding feature pair is discarded. The feature matching process is performed by bidirectionally checking the nearest neighbors:wheredetermines whether the latter point is the nearest one to the former point in the feature domain. In other words, CryoAlign compares the Euclidean distances between the feature descriptors of key pointand all the feature descriptors of key pointsin the target point cloud, and select the one with smallest distance as the nearest neighbor. Given the filtered feature point correspondences, truncated least squares estimation and semidefinite relaxation (TEASER)are used to estimate the initial rigid transformation parameters, by optimizing the following objective function:where R is the 3 × 3 rotation matrix andis the 3D translation vector.

The feature-based method provides a rough initial superimposition, while the point-based method aims to align the point clouds more closely. Accounting for the different distributions of the point clouds, CryoAlign utilizes the sparse-icp algorithmin the second stage. This algorithm replaces the L-2 norm with the L-p norm (where < 1), allowing for a higher tolerance for outliers. Unlike the first stage, which focuses on key point pairs, in the second stage, CryoAlign considers the initial point pairsgenerated by the nearest neighbor algorithm in 3D space. The optimization function based on point correspondences is formulated as:where < 1 and I SO (3) constraints for the rotation matrix.

---

### Relationship between myopia control and amount of corneal refractive change after orthokeratology lens treatment [^bd8d683f]. BMC Ophthalmology (2023). Medium credibility.

Data preprocessing

The data were preprocessed to fit the missing data. For the radial data, linear interpolation was used to fit data with a value of 0. The tangential curvature data were transformed into tangential refractive power (in diopters) as follows:

The transformation is shown below:

Then, any missing data with a value of 0 was also fitted using linear interpolation.

Mean filtering and smoothing

Mean filtering was used to remove noise and high-frequency information generated during the acquisition process, resulting in smoother data.

3D modeling

According to the acquisition principle of Placido, 32 data points were collected at 1.2° intervals. This allowed for the location of each collection point on the cornea to be determined using the polar coordinate system. Additionally, each collection point corresponded to a tangential refractive power. When using the corneal center as the coordinate origin of the polar coordinate system, the coordinates of the collected corneal data points were as follows:

After transforming the polar coordinate system into a Cartesian coordinate system, the coordinates of the corneal data points were obtained as follows:

Each coordinatecorresponded to a diopter, and the following three-dimensional coordinate point set was obtained:

in which.

Based on the obtained coordinate point set, 3D modeling was carried out by interpolation, and the results are shown in Fig. 1.

Fig. 1
3D modeling of the corneal refractive change. Based on the obtained coordinate point set, 3D modeling was carried out by interpolation

Polynomial fitting

The data was collected using the Medmont E300 topographer, which gathered 32 points at 1.2° intervals. In total, data points were collected in 300 directions. Subsequently, 64 points were selected by choosing those with an angle difference of 180°, and they were plotted on the Cartesian coordinate system.

A two-dimensional coordinate system was established by plotting the radial data on the horizontal axis and the tangential refractive power on the vertical axis, with the corneal center as the origin. Polynomial fitting was carried out for the 64-point scatter diagrams with the fitting formula shown below.

in which, represents the highest degree of the polynomial; its value in this algorithm was 21. The fitting results are shown in Figure S 1 (a).

---

### ACR-ARS practice parameter for the performance of stereotactic body radiation therapy [^14416c48]. ARS/ACR (2024). High credibility.

Stereotactic body radiation therapy (SBRT) image-guided localization and verification — This procedure must be a two-step process: the first step must be designed to use the image-guided system to position 1 or more test points (fiducials) at known coordinates, and the second step must work through the treatment planning system to irradiate these test points with the actual treatment beam using an imaging technique that verifies acceptable target localization. Some technologies employ two independent imaging systems, for example a cone-beam device on the linear accelerator for image guidance with verification imaging performed using a megavoltage beam impinging on an electronic portal imaging device (EPID).

---

### Heading direction with respect to a reference point modulates place-cell activity [^5f01e531]. Nature Communications (2019). High credibility.

Model of HD modulation relative to a reference point

Having demonstrated HD tuning in general, we proceeded to characterize the structure of this tuning across the spatial extent of the enclosure. To construct a more general model than simple modulation by heading relative to a fixed direction in the room and inspired by the recent work of Sarel et al. we considered firing-rate modulation as a function of the angle (θ) between the HD and a line extending from the animal to a fixed location in the room, either within or outside the enclosure (Fig. 2a). We called this fixed location, determined by fitting, the reference points and the angle thus defined, the reference-heading (RH) angle. Specifically, we considered the model R (x, y, H) = α + g* cos(θ − θ p), where we fit 4 parameters for each neuron: g, the modulation strength; θ p, the preferred RH angle; and 2 parameters describing the coordinates of the reference point. The angle θ depends on x, y, H as well as on the location of the reference point. The value of α is determined not by fitting but by imposing the fact that, by construction, the average of R (x, y, H) over HD angle H is 1 ("Methods"). Thus α values different from 1 correct for sampling biases in θ.

---

### A comparison of skeletal muscle diffusion tensor imaging tractography seeding methods [^573f9a3f]. NMR in Biomedicine (2025). Medium credibility.

2.1.2 Updated Aponeurosis Seeding Scheme: Noise‐Free Condition

An updated method for initiating fiber tracts from the points defining a seeding mesh was defined and implemented. Specifically, we introduce the following procedure to ensure that any seed point placed within one voxel of the muscle‐aponeurosis boundary can be used to initiate a fiber tract, while still beginning at the preferred seed point. The method is based on the assumption that the spatial frequency of variations in muscle fiber orientation is low enough that the diffusion tensor from any voxel containing muscle tissue neighboring the voxel of interest can be used to estimate the diffusion tensor within the voxel of interest:
Form masks defining the internal aponeurosis boundaries and the muscle boundaries (the latter excluding the internal aponeurosis).
Define an aponeurosis seeding mesh at the muscle‐aponeurosis boundary. Define each vertex in this mesh as a seed point and find its row, column, and slice coordinates.
Round the slice coordinates using standard rounding conventions; for the row and column coordinates, take both the floor and ceiling.
For each of the four combinations of integer row and column coordinates, determine if the point is included within the muscle boundary mask or the aponeurosis boundary mask.
For each point included within the muscle boundary mask, determine the distance between the rounded coordinates and the seed point; define the point with the smallest distance as the closest included point.
Propagate a tract from the seed point using the diffusion direction found upon lookup using the closest included point.

---

### Fiducial point placement and the accuracy of point-based, rigid body registration [^f58d5135]. Neurosurgery (2001). Low credibility.

Objective

To demonstrate that the shape of the configuration of fiducial points is an important factor governing target registration error (TRE) in point-based, rigid registration.

Methods

We consider two clinical situations: cranial neurosurgery and pedicle screw placement. For cranial neurosurgery, we apply theoretical results concerning TRE prediction, which we have previously derived and validated, to three hypothetical fiducial marker configurations. We illustrate the profile of expected TRE for each configuration. For pedicle screw placement, we apply the same theory to a common anatomic landmark configuration (tips of spinous and transverse processes) used for pedicle screw placement, and we estimate the error rate expected in placement of the screw.

Results

In the cranial neurosurgery example, we demonstrate that relatively small values of TRE may be achieved by using widely spread fiducial markers and/or placing the centroid of the markers near the target. We also demonstrate that near-collinear marker configurations far from the target may result in large TRE values. In the pedicle screw placement example, we demonstrate that the screw must be approximately 4 mm narrower than the pedicle in which it is implanted to minimize the chance of pedicle violation during placement.

Conclusion

The placement of fiducial points is an important factor in minimizing the error rate for point-based, rigid registration. By using as many points as possible, avoiding near-collinear configurations, and ensuring that the centroid of the fiducial points is as near as possible to the target, TREs can be minimized.

---

### Three-dimensional determination of variability in colon anatomy: applications for numerical modeling of the intestine [^1f19160a]. The Journal of Surgical Research (2012). Low credibility.

Background

Precise knowledge of variability in colonic anatomy is of great importance for numerical modeling studies of the abdomen. This knowledge would allow the creation of personalized models for the gastrointestinal tract used for surgical simulations or in studies of virtual trauma.

Materials and Methods

To determine the colonic configuration in the general population and define its variability by gender, age, and corpulence, the layout of the colon was determined via the following reference points: ileocecal junction, left and right colonic flexures, and colosigmoid junction (CSJ). Three-dimensional coordinates for each point were recorded on scanned sections of 100 healthy adults to examine the colonic layout under physiological conditions. Coordinates were repositioned in a new anatomical reference for comparison. The average points' coordinates, standard deviations, and distances between them were compared for each group.

Results

The right colonic flexure was the most variable point. The CSJ was the least variable. Gender affected mainly the height of the colonic flexures and the length of its segments. Age affected the length of the transverse mesocolon root. Corpulence affected both the position of the ileocecal and CSJs and the length of the right colon. Differences in size and perivisceral fat distribution between groups explained these differences. Three-dimensional anatomical models of the colon were defined for each group by statistical equations.

Conclusion

These equations, combined with data concerning the actual lengths of the colonic segments, enable reconstruction of different anatomical models of the colon that are representative according to gender, age, and corpulence.

---

### Three-dimensional printing template for intraoperative localization of pulmonary nodules in the pleural cavity [^ab204db5]. JTCVS Techniques (2022). Medium credibility.

Navigational Template Design and 3D Printing

After the patients were included in the study, the CT scan sequences were obtained from Picture Archiving and Communication Systems. The First Hospital of Lanzhou University performed CT scans with a thickness of 1.5 mm on patients. After the sequence was acquired, the position information of the pleural cavity, bony landmarks (first costal margin, sternoclavicular joint, and cost-vertebral joint), and pulmonary nodules were determined. Subsequently, Mimics (Mimics Research 20.0, Materialise NV) software was used to process the acquired CT scan sequence information. First, we established a 3D digital model of the patient's chest and integrated the location information of the nodules into the digital model. We built a digital model of the navigational template based on the location information collected previously (Figure 1). The 3D model of the navigational template is shown in Figure E1. The navigational template consists of 5 functional modules: (1) The key positioning module uses the thoracic lung apex as the positioning site. This part is the anchor point of the navigational template, which assists the placement and position calibration of the navigational template during surgery (Figure E1, A); (2) the assisted positioning module uses the upper thoracic vertebra as the positioning part, which can assist in the alignment of the navigational template and undertake the role of fixation and support (Figure E1, B); (3) the ring positioning module is used to indicate the position, and the center of the ring corresponds to the projection of the pulmonary nodule on the lung surface (Figure E1, C); (4) the arcuate positioning arm is the connecting device between the key positioning module and the annular positioning module, which is consistent with the curvature of the thorax and can be fitted entirely with the thorax (Figure E1, D); (5) the rib positioning module verifies the navigational template again. When correctly placed, the position and direction of the rib positioning arm will be consistent with the rib (Figure E1, E). The detailed design steps of the navigational template are shown in Figure E2, Figure E3, Figure E4.

---

### Different strategies in pointing tasks and their impact on clinical bedside tests of spatial orientation [^f943dfac]. Journal of Neurology (2022). Medium credibility.

A modified version of the PointingApp was written that uses the built-in accelerometer data in a smartphone from which a 3D pointing vector can be calculated, assuming a stable gravitational force in the z -axis without other accelerational forces present when the device is held in a stationary position. The iPhone® used in this study came equipped with a 6-axis accelerometer/gyroscope unit containing digital-output X -, Y -, and Z -axis angular rate sensors with a programmable range of ± 250, ± 500, ± 1000, and ± 2000°/s (Invensense (TDK), CA, USA). The sensor readouts were acquired, averaged and normalized multiple times after user confirmation. To rule out relevant accelerational forces present which would hamper the vector calculation, a measurement was only recorded when the normalized values after user confirmation did not exceed a ± 5% margin. Otherwise, device motion was assumed and another set of readouts was acquired. From these vectors, a representation in a spherical coordinate system can be derived, giving an azimuth and a polar value. These spherical coordinates could then be compared to the two sets of calibrations. The introduction of spherical coordinates on a unit sphere initially detaches the real-world targets from the performed task, e.g. the subjective direction. By restricting the degrees of freedom in which the subject as the center of the unit sphere can move, the deviation from calibration vector and reproduction vector still yields a meaningful result.

The modified standardized pointing paradigm is as follows: A 3 × 3 matrix is marked with red 20 mm points on a white wall. The central point is marked with a 10 cm wide cross. The distance between points is 100 cm. A viewing angle of 55° between the outer points is achieved by having the participant sit on a revolving chair 192 cm away from the wall. The participant's eye level can be adjusted by changing the height of the chair and matching it to the central horizontal row of the calibration points. In our clinically oriented setup, we refrain from using bite bars or multi-point straps but strictly control the chair position by adjusting its center of rotation to a defined point marked on the ground. No visual cues are visible on the wall except for a 35 cm wide white power outlet. Only artificial lighting is used. The chair provides only back support but no head or arm rest to minimize proprioceptive input from neck muscles or head position. The only source of sound in the test room is the handheld device itself.

---

### Different strategies in pointing tasks and their impact on clinical bedside tests of spatial orientation [^17b9c0fb]. Journal of Neurology (2022). Medium credibility.

Fig. 1
Simplified model without interlimb mobility showing the discrepancies between retinotopic pointing (red) and the corresponding pointing vector of the extended arm and index finger (blue). The pointing vector in cartesian coordinates (x, y, z) can be transformed into spherical coordinates (φ for Azimuth angle, ϑ for polar angle/inclination), if the origin of both coordinate systems is identical

In the second strategy, the stretched arm with the index finger form a vector which is aligned to the line of sight. Since world-based and subject-based pointing strategies are usually both available when performing a pointing task, the actual strategy chosen depends on various factors. In terms of complexity, a subject space-based, retinotopic strategy only requires the visual input and an eye-centered coordinate system to encode spatial information, whereas a world-based pointing strategy requires complex transformations of the eye-centered coordinates relative to the actual 3D position of the fovea to the effector-organ centered coordinates to generate an appropriate movement plan (see Fig. 2 for details).

Fig. 2
A Example of a retinotopic pointing strategy. The task can be performed sufficiently by adjusting the finger phalanx and the target position in a retinotopic reference frame. B Example of a world-based pointing strategy with the pointing vector leading towards the target in real-world coordinates. This task can only be performed by creating a mental map of the target and the interrelations with its environment

---

### Rating certainty when the target threshold is the null and the point estimate is close to the null [^159c2302]. BMJ Evidence-Based Medicine (2025). High credibility.

When to revise the target of certainty of evidence rating

One might ask how close the point estimate needs to be to the null before one should consider revising the target of certainty rating from a non-zero effect to a little or no effect. The previous GRADE guidance does not provide an answer. We suggest that, once GRADE users conclude that the point estimate may represent little or no effect (ie, the point estimate is consistent with an effect less than the MID), they should consider revising the target of certainty rating. GRADE users often choose the null as the threshold to minimise value and preference judgements; when the point estimate is near the null such judgement becomes necessary.

Formal approaches to help establish MIDs are now available. Alternatively, searching the literature for studies of values and preferences and health state utilities may be helpful. If the outcome is a patient-reported measurement instrument, such as a Visual Analogue Scale (VAS) score for pain intensity, GRADE users are likely to find relevant literature establishing a suggested MID. Given the usual paucity of evidence regarding patients' values and the variation in patients' values, uncertainty regarding the MID is invariably appropriate. Thus, GRADE users may consider a range of plausible MIDs from the largest to the smallest plausible MID (figure 3).

Figure 3
The relative location of the point estimate to a range of plausible MIDs. In situation A, the point estimate is consistent with an increase in the effect that exceeds the largest plausible MID, and GRADE users can confidently rate certainty in a non-zero effect. In situation C, the point estimate falls below the value they have designated as the smallest plausible MID, and they can revise the target of certainty rating to a little or no effect. In situation B, the point estimate falls in the range of uncertainty regarding the MID, they may or may not revise the target of certainty rating to a little or no effect. GRADE (Grading of Recommendations, Assessment, Development, and Evaluations). MID, minimally important difference.

If the point estimate is consistent with an increase in the effect that exceeds the largest plausible MID (A in figure 3), they would confidently rate certainty in a non-zero effect. If, on the other hand, the point estimate falls below the value they have designated as the smallest plausible MID, and the point estimate, therefore, represents little or no effect (C in figure 3), they would confidently revise the target of certainty rating to a little or no effect.

---

### A framework for evaluating correspondence between brain images using anatomical fiducials [^03382768]. Human Brain Mapping (2019). Medium credibility.

Accurate spatial correspondence between template and subject images is a crucial step in neuroimaging studies and clinical applications like stereotactic neurosurgery. In the absence of a robust quantitative approach, we sought to propose and validate a set of point landmarks, anatomical fiducials (AFIDs), that could be quickly, accurately, and reliably placed on magnetic resonance images of the human brain. Using several publicly available brain templates and individual participant datasets, novice users could be trained to place a set of 32 AFIDs with millimetric accuracy. Furthermore, the utility of the AFIDs protocol is demonstrated for evaluating subject-to-template and template-to-template registration. Specifically, we found that commonly used voxel overlap metrics were relatively insensitive to focal misregistrations compared to AFID point-based measures. Our entire protocol and study framework leverages open resources and tools, and has been developed with full transparency in mind so that others may freely use, adopt, and modify. This protocol holds value for a broad number of applications including alignment of brain images and teaching neuroanatomy.

---

### Heading direction with respect to a reference point modulates place-cell activity [^4a91ee7d]. Nature Communications (2019). High credibility.

Fig. 3
Fitted model parameters across neurons. a Histogram of the amplitude of the angular modulation for all neurons and for neurons with significant reference-heading (RH)-angle tuning (neurons above the dotted line in Fig. 2b). b Histogram of the angle of the preferred RH direction. c Histogram of the distances of reference points from the center of the enclosure. d Reference points located within the enclosure (square in the center of the panel), in the proximity of the enclosure (dashed square), and at distal locations (collapsed onto a circle of 150 cm diameter). e Density map of reference point locations inside and near the enclosure. The concentration of reference points toward the center of the arena is not statistically significant. f Circular histogram of the direction to reference points at distal locations shows a significant concentration in the S-E direction (outside the 95% conf. interval). reference points within the box do not show any significant anisotropy. g Scatter plot of reference point coordinates (x — top, y — bottom) compared to the coordinates of the centers of the place fields for each neuron. There is no correlation between the locations of the reference points and the place field center of mass for the same neuron

Because our model reduces to a pure HD tuning when the reference point is far from the animal (Supplementary Fig. 8), neurons with distal reference points correspond to head-direction modulated neurons. The distal reference points we extracted show an angular preference (Fig. 3d–f), with the density peaking at a direction that coincides with the exit door of the experimental room, which is almost due south on the schematics (Fig. 3f and Supplementary Fig. 9). In contrast to the distal reference points, the distribution of proximal reference points that are within the enclosure, corresponding to distinctively RH-modulated neurons, do not show any angular preference, but they have a higher density near the center of the arena than near its edges. This difference does not reach statistical significance, however (Fig. 3d, e). We also found no correlation between the location of the reference point within the enclosure for a given neuron and the center of its place field (Pearson's correlation coefficient r = −0.05 for x coordinate and r = −0.03 for y coordinate; Fig. 3g; "Methods"). This implies that place and RH tuning use two different reference systems.

---

### Heading direction with respect to a reference point modulates place-cell activity [^aaafe946]. Nature Communications (2019). High credibility.

Previous work on the modulation of activity with respect to HD relative to location in space considered locations that were distinguished by the presence of an object or a visual cue, or a reward. Our work reveals modulation of place-cell activity by HD relative to unmarked points in the environment; reference points inside the enclosure seem to have no particularly distinguishing characteristic. RH tuning may be related to the type of visual-cue modulation reported by Wilber et al.and Acharya et al. It would be interesting to use our model and approach to analyze other data sets that identified object- or goal-direction tuning to see whether more general reference-point tuning is also present in these data. Conversely, our analysis could be extended to include objects and goal locations in the environment.

What are the origins and functional significance of modulation with respect to RH angle? Determination of spatial location requires integration of a large number of factors, including both proximal and distal sensory cues and internal measures of path integration. Because these factors are key components of the position signal that drives place-selectivity in the hippocampus, it is not surprising to see them reflected in the modulation of place-cell activity. Furthermore, these factors are likely to be correlated with both well-defined and subtly defined features and locations in the environment. Thus any model that takes into account the complexity of location-determining computations would be expected to include modulation by factors that are more complex than pure location tuning. The modulation by HD with respect to unmarked reference points that we report matches what would be expected from such a model.

---

### Constrained optimization for position calibration of an NMR field camera [^362cc817]. Magnetic Resonance in Medicine (2018). Low credibility.

Purpose

Knowledge of the positions of field probes in an NMR field camera is necessary for monitoring the B 0 field. The typical method of estimating these positions is by switching the gradients with known strengths and calculating the positions using the phases of the FIDs. We investigated improving the accuracy of estimating the probe positions and analyzed the effect of inaccurate estimations on field monitoring.

Methods

The field probe positions were estimated by 1) assuming ideal gradient fields, 2) using measured gradient fields (including nonlinearities), and 3) using measured gradient fields with relative position constraints. The fields measured with the NMR field camera were compared to fields acquired using a dual-echo gradient recalled echo B 0 mapping sequence. Comparisons were done for shim fields from second- to fourth-order shim terms.

Results

The position estimation was the most accurate when relative position constraints were used in conjunction with measured (nonlinear) gradient fields. The effect of more accurate position estimates was seen when compared to fields measured using a B 0 mapping sequence (up to 10%-15% more accurate for some shim fields). The models acquired from the field camera are sensitive to noise due to the low number of spatial sample points.

Conclusion

Position estimation of field probes in an NMR camera can be improved using relative position constraints and nonlinear gradient fields. Magn Reson Med 80:380–390, 2018. © 2017 International Society for Magnetic Resonance in Medicine.

---

### Time course of tumor SUV in 18F-FDG PET of breast cancer: presentation of a simple model using a single reference point for time corrections of tumor SUVs [^a5bb56eb]. Journal of Nuclear Medicine (2011). Low credibility.

Unlabelled

Tumor standardized uptake values (SUVs) vary with the interval between 18F-FDG injection and image acquisition. This paper presents a simple method using a single reference point to make appropriate time corrections for tumor SUVs.

Methods

The reference point method was algebraically deduced from observations made by Beaulieu et al., who found that tumor SUVs behaved linearly over time (∼30 to 75 min after 18F-FDG injection). Eighteen patients with breast cancer were dynamically examined with PET/CT (∼60 and 80 min after 18F-FDG injection). Maximum SUV was calculated by applying 2 different iterative reconstruction methods (high-definition reconstruction and attenuation-weighted ordered-subsets expectation maximization). Reference points for time corrections were given, and errors for corrections obtained with the reference point method were calculated.

Results

Variations in the reconstruction algorithm strongly influenced the coordinates of the reference point. Time corrections using the reference point method were more accurate at higher tumor SUVs (> 8 at high-definition reconstruction and > 6 at attenuation-weighted ordered-subsets expectation maximization) than at lower ones.

Conclusion

A common origin of tumor SUVs over time exists in breast cancer. In combination with the linear behavior of tumor SUVs between approximately 30 and 80 min, such a reference point allows for straightforward time corrections of tumor SUVs. Parameters for image reconstruction must be considered because they influence the coordinates of the reference point.

---

### Three-dimensional cephalometry: a method for the identification and for the orientation of the skull after cone-bean computed tomographic scan [^cdd8f03e]. The Journal of Craniofacial Surgery (2013). Low credibility.

The aims of this work were (1) to describe a method to identify new skeletal landmarks useful to define the reference system to orient the skull in a new position after cone-bean computed tomographic scan and (2) to demonstrate the reliability of this new method. Ten orthognathic patients (5 male, 5 female; mean [SD] age, 18.9 [1.2] years) underwent the cone-bean computed tomographic scan before surgery. Seven 3-dimensional skeletal measurements derived from 4 skeletal point of construction (C) (right, left, and median orbital C, and sella C) have been used for this study. Reliability has been calculated using Pearson correlation coefficient tests. Intraobserver reliability was 0.9999 for operator A (T1-T2) and 0.9999 for operator B (T1-T2); interobserver reliability was 0.9999 between the first (T1-T1) measurement and 0.9999 between the second (T2-T2). The original method is able to reduce the variability of landmark identification due to the variability of the human anatomy and the influence of the human error in cephalometric analysis. The innovation of this new method is the real possibility to use the anatomical structures in a 3-dimensional way, enhancing the reliability of the reference points.

---

### Automated sequence design of 2D wireframe DNA origami with honeycomb edges [^74acff68]. Nature Communications (2019). High credibility.

Structural analysis of MD trajectories

Atomic coordinates for the triangular wireframe DNA origami objects (42- and 84-bp edge length, DX- and 6HB-based object) were extracted from the production MD simulations every 1 ns. At each sampled time point, atomic coordinates were superposed onto the reference geometric coordinates (t = 0 ns), and the root-mean-square deviation (RMSD) of the sampled atomic coordinates was calculated with respect to these reference coordinates. The total RMSD of all atoms was calculated at each time point. After equilibration time of ~50 ns, the total RMSD was calculated from the average of three separate bins of 50 ns (50–100 ns, 100–150 ns, and 150–200 ns). Superposition of atomic coordinates and RMSD calculations were performed using the Python package ProDy. Also, root-mean squared fluctuations (RMSF) of all atomic coordinates were averaged over the production MD simulations for each triangular wireframe structure, again performed using the Python package ProDy. To determine the average internal angle, θ, of each triangular wireframe object, a geometric approach for analyzing each frame in the MD trajectory was utilized. At each vertex, two M -bp DNA N -helix edges are connected, and the bp of each edge are indexed as bp 1,1,…, bp 1, M,…, bp N,1,…, bp N, M. Using the ProDypackage, the geometric center of atoms in each bp, denoted (x 1,1,…, x N, N), and the geometric center of atoms in each pair of bp (bp 1, i, bp 2, i) for DX- or sextet of bp for 6HB-based object, i = 1, 2,…, M, denoted c i, is calculated at each MD frame. A right-handed orthonormal basis (b 1, b 2, b 3) is defined using the three principal axes of the point cloud { c 1,…, c M }, in which b 1 is coincident with the first principal axis and points from c 1 to c M, b 2 is coincident with the second principal axis and points from the inner to the outer bp, and b 3 is coincident with the third principal axis and points outward of the nanoparticle. Next, a L -bp region at the starting end of each edge is selected to define a vector e 1, which is coincident with the first principal axis of the point clouds { c 1,…, c L }, and points from c 1 to c L. For the 42-bp and 84-bp objects, L was chosen as 20 and 40 bps, respectively. At each frame, a triangular plane is determined from the three center points of the edges (c M /2), and the normal to this plane is calculated as c norm. Next, both left- and right-hand edge vectors of a triangular vertex are projected onto the c norm plane as e l, proj and e r, proj, respectively. The internal angles at each vertex are then θ i = e l, proj
- e r, proj, where i = 1, 2, 3, and the average internal angle at each frame is θ. In addition, the out-of-plane angles at each vertex are calculated as ω i = e norm
- c norm, where i = 1, 2, 3, e norm = e 1 × e 2, and the average out-of-plane angle at each frame is ω.

---

### Quantitative mappings between symmetry and topology in solids [^ce1ff365]. Nature Communications (2018). Medium credibility.

The study of spatial symmetries was accomplished during the last century and had greatly improved our understanding of the properties of solids. Nowadays, the symmetry data of any crystal can be readily extracted from standard first-principles calculation. On the other hand, the topological data (topological invariants), the defining quantities of nontrivial topological states, are in general considerably difficult to obtain, and this difficulty has critically slowed down the search for topological materials. Here we provide explicit and exhaustive mappings from symmetry data to topological data for arbitrary gapped band structure in the presence of time-reversal symmetry and any one of the 230 space groups. The mappings are completed using the theoretical tools of layer construction and symmetry-based indicators. With these results, finding topological invariants in any given gapped band structure reduces to a simple search in the mapping tables provided.

---

### Novel cardiac CT method for identifying the atrioventricular conduction axis by anatomic landmarks [^9254e56d]. Heart Rhythm (2025). Medium credibility.

Background

Understanding the conduction axis location aids in avoiding iatrogenic damage and guiding targeted heart rhythm therapy.

Objective

Cardiac structures visible with clinical imaging have been demonstrated to correlate with variability in the conduction system course. We aimed to standardize and assess the reproducibility of predicting the location of the atrioventricular conduction axis by cardiac computed tomography.

Methods

We evaluated 477 patients with acquired aortic valve disease by cardiac computed tomography to assess variability in cardiac structures established to relate to the conduction system. We standardized 3 points (points A-C) to estimate the course from the atrioventricular node to the nonbranching bundle and left bundle branch origin and further compared this with measures of variability in the aortic root and membranous septum.

Results

The mean distances between the aortic valve virtual basal ring and points A, B, and C were 9.5 ± 3.5 (0.3–20.1) mm, 5.0 ± 2.6 (-1.7 to 15.9) mm, and 2.9 ± 2.5 (-5.2 to 12.0) mm, respectively. The midpoint of the membranous septum deviated posteriorly a median of -4.4 (interquartile range, -12.4 to +3.0) degrees relative to the commissure between the right coronary and noncoronary leaflets. Intraclass coefficients for both intraobserver and interobserver variability for all measured points were excellent (≥ 0.78).

Conclusion

These findings further infer the intimate yet highly variable relationship between the conduction axis and aortic root. This reproducible and standardized approach needs validation in populations of patients requiring accurate identification of the atrioventricular components of the conduction axis, which may serve as a noninvasive means for estimating its location.

---

### Heading direction with respect to a reference point modulates place-cell activity [^327d5435]. Nature Communications (2019). High credibility.

Model fitting

For model fitting, we used neurons that satisfied the following conditions: minimum number of spatial bins that satisfy the acceptance criteria given above is equal to 20 and minimum range of HD angles to which the cell is responsive is more than 50 deg. We also reproduced the same results with lower thresholds of minimum firing rate (0.1 Hz) than the standard 0.5 Hz cutoff.

The model has a periodic dependence on the angle between the HD of the animal's trajectory and the location of the reference point (see Fig. 1b)where.

We fitted the values of g, θ p, X Ref. Point, and Y Ref. Point by minimizing the squared difference between the model and the data, summed over all bins. We performed the minimization using an unconstrained nonlinear optimization procedure, the fminsearch function from MATLAB. For the initial parameter estimates, we used: g = 0; θ p = 0; X Ref. Point = Place-cell's center of mass X coordinate, Y Ref. Point = Place-cell's center of mass Y coordinate.

Statistical test for modeled data

In Fig. 1a, we computed the variance explained by a place description to describe how well the mean rate over all angular bins explain the neural activity,

In Fig. 1b, we show, in a polar plot, the average rate for each of the 10 HD angles, averaged over the entire experiment.

For Fig. 1d, we performed a chi-square goodness-of-fit test and rejected the hypothesis that the distributions in the X and Y axes come from the same distribution with the actual values computed being p value = 6 × 10–14.

In Fig. 2b, we performed a chi-square goodness-of-fit test and rejected the hypothesis that the distributions in the X and Y axis were coming from the same distribution with the actual value computed being p value = 4 × 10–15.

In Fig. 2c, we compared the variance explained by the place tuning to the variance explained by including RH angular dependence where the reference point was fitted by the model and

---

### Probabilistic alignment of multiple networks [^39aa70ac]. Nature Communications (2025). High credibility.

The network alignment problem appears in many areas of science and involves finding the optimal mapping between nodes in two or more networks, so as to identify corresponding entities across networks. We propose a probabilistic approach to the problem of network alignment, as well as the corresponding inference algorithms. Unlike heuristic approaches, our approach is transparent in that all model assumptions are explicit; therefore, it is susceptible of being extended and fine tuned by incorporating contextual information that is relevant to a given alignment problem. Also in contrast to current approaches, our method does not yield a single alignment, but rather the whole posterior distribution over alignments. We show that using the whole posterior leads to correct matching of nodes, even in situations where the single most plausible alignment mismatches them. Our approach opens the door to a whole new family of network alignment algorithms, and to their application to problems for which existing methods are perhaps inappropriate.

---

### Experimental nonclassicality in a causal network without assuming freedom of choice [^e83d6c77]. Nature Communications (2023). High credibility.

Violation of a causal compatibility inequality

In order to demonstrate the nonclassicality of the experimental data relative to the triangle causal network, we seek to identify some causal inequalities, which must be satisfied by all distributions compatible with the classical triangle network but which are violated by our experimental statistics. To this end, we turn to the inflation technique for causal inference introduced in ref.

As detailed in the Methods, the inflation technique relates compatibility with a given causal structure to feasibility of a linear program (LP). If the LP related to an inflation of(see Fig. 5 (a)) is found to be infeasible, then evidently p is incompatible with. In our case, is taken to be the classical triangle scenario causal structure depicted in Fig. 1 (b).

Fig. 5
Inflation technique for the triangle network.

a The second order inflation graph of the triangle network. Such an inflation doubles the number of latent variables relative to the triangle scenario, having six latent variables. The inflation quadruples the number of observable random variables of the triangle scenario, having twelve observable random variables { a (1), b (1), c (1), a (2), b (2), c (2), a (3), b (3), c (3), a (4), b (4), c (4) }. Distributions compatible with this inflated structure satisfy symmetry properties, and have marginals corresponding to products of triangle-compatible distribution. This can be exploited to derive suitable causal compatibility inequalities that are violated by the experimental data. b This plot depicts the 64 × 64 coefficientsfor a quadratic inequality of the form of Eq. (7) such that the left-hand side is nonnegative on all distributions compatible with the classical triangle scenario, but which evaluates to the negative number V e x p = − 0.02436 ± 0.00016 on our experimental data. The x -axis ranges over the values of (a 1, b 1, c 1) while the y -axis ranges over the values of (a 2, b 2, c 2), and the color at a given point denotes the value ofaccording to the mapping set out in the legend.

---

### Heading direction with respect to a reference point modulates place-cell activity [^ecb2c6fb]. Nature Communications (2019). High credibility.

The tuning of neurons in area CA1 of the hippocampus emerges through a combination of non-spatial input from different sensory modalities and spatial information about the animal's position and heading direction relative to the spatial enclosure being navigated. The positional modulation of CA1 neuronal responses has been widely studied (e.g. place tuning), but less is known about the modulation of these neurons by heading direction. Here, utilizing electrophysiological recordings from CA1 pyramidal cells in freely moving mice, we report that a majority of neural responses are modulated by the heading-direction of the animal relative to a point within or outside their enclosure that we call a reference point. The finding of heading-direction modulation relative to reference points identifies a novel representation encoded in the neuronal responses of the dorsal hippocampus.

---

### Meshless deformable models for 3D cardiac motion and strain analysis from tagged MRI [^bb8a9663]. Magnetic Resonance Imaging (2015). Low credibility.

Tagged magnetic resonance imaging (TMRI) provides a direct and noninvasive way to visualize the in-wall deformation of the myocardium. Due to the through-plane motion, the tracking of 3D trajectories of the material points and the computation of 3D strain field call for the necessity of building 3D cardiac deformable models. The intersections of three stacks of orthogonal tagging planes are material points in the myocardium. With these intersections as control points, 3D motion can be reconstructed with a novel meshless deformable model (MDM). Volumetric MDMs describe an object as point cloud inside the object boundary and the coordinate of each point can be written in parametric functions. A generic heart mesh is registered on the TMRI with polar decomposition. A 3D MDM is generated and deformed with MR image tagging lines. Volumetric MDMs are deformed by calculating the dynamics function and minimizing the local Laplacian coordinates. The similarity transformation of each point is computed by assuming its neighboring points are making the same transformation. The deformation is computed iteratively until the control points match the target positions in the consecutive image frame. The 3D strain field is computed from the 3D displacement field with moving least squares. We demonstrate that MDMs outperformed the finite element method and the spline method with a numerical phantom. Meshless deformable models can track the trajectory of any material point in the myocardium and compute the 3D strain field of any particular area. The experimental results on in vivo healthy and patient heart MRI show that the MDM can fully recover the myocardium motion in three dimensions.

---

### ACR-ARS practice parameter for image-guided radiation therapy (IGRT) [^89b325b0]. ARS/ACR (2024). High credibility.

IGRT implementation — imaging modalities, calibration, and registration specifies that the IGRT system needs to be calibrated to ensure high-quality imaging and must also be accurately aligned to the reference point, which may be the isocenter of the linear accelerator and registered with the TPs; orthogonal images should be obtained and compared with digitally reconstructed radiographs (DRRs) from the treatment-planning CT for coincidence when applicable, and each facility needs to develop QA procedures to ensure reliability and reproducibility of the IGRT process; available options include orthogonal megavoltage and kilovoltage portal images with or without fiducial markers, ultrasound, CT, and MRI used alone or in combination or with camera-based surface rendering systems; fiducial markers with orthogonal plain films or port images do not provide information about changes in the size and shape of tumors and surrounding organs during a course of radiation therapy and this problem can be minimized via volumetric imaging modalities (ultrasound, MRI, or CBCT) with or without fiducial markers; registration of planning and on-board images uses specialized software to determine positional deviations and adjust patient positioning via shifts along the x, y, and z axes, and some algorithms and treatment units also allow for rotational corrections; conventional CT or CBCT can be used to identify most superficial or deep-seated tumors and surrounding OARs, and ultrasonography depicts echogenicity differences between tumors and surrounding tissues and has been used mainly for localizing the prostate and other superficial tumors.

---

### A consensus document on robotic surgery [^13765706]. Surgical Endoscopy (2008). Medium credibility.

Integrated surgery with robotic platforms — robotic surgery presents an excellent opportunity to integrate anatomic and physiologic data into the operative field, with preoperative or intraoperative imaging (e.g. CT, MRI, or ultrasound) revealing the three-dimensional topology of the operative field before tissue is disturbed. Because the spatial coordinates (x, y, z axis) of surgical instruments are known at all times by the surgical robot, the robotic interface can register and fuse imaging with the computer visual field to provide visual overlays of anatomy, function, and even tumor mapping, enabling the surgeon to 'see into' tissues; virtual barriers or 'no fly zones' could be mapped to help guide the surgeon away from potential hazard. This information could guide procedures intraoperatively or be used to simulate a proposed procedure before it is carried out.

---

### Methods to locate center of gravity in scoliosis [^84f688a7]. Spine (2003). Low credibility.

Study Design

Prospective evaluation of the location of the center of gravity during supine, standing, and gait.

Objective

Develop methods to quantify center of gravity locations in patients with scoliosis and controls and to evaluate the merit of the quantitative assumptions relative to spinal fusion surgery.

Summary and Background Data

The center of gravity, or balance point of the body, is generally considered to be the single best estimate of the body's location. To date, investigators have not examined the body's center of gravity location to assist surgical planning to maintain and/or restore coronal and sagittal plane balance, nor have they used center of gravity location to help assess surgical outcomes.

Materials and Methods

The whole-body center of gravity (MR-COG) was determined for three subjects from magnetic resonance imaging data obtained supine. The whole-body center of gravity was also determined using subject specific (SS-COG) and literature-based (STD-COG) segment center of gravity locations in conjunction with a video motion capture system obtained supine, standing and during gait.

Results

Differences existed among the three methods of determining COG locations in supine, with the SS-COG and MR-COG being most closely aligned. Results from gait data indicated typical anterior/superior and right/left COG shifts during the gait cycle. The SS-COG method consistently determined a COG location inferior to the STD-COG method; however, variation within the gait cycle was similar. Shifts in COG locations relative to a coordinate system fixed in the pelvis were more than 5 cm in the superior/inferior direction, approximately 4 cm in the anterior/posterior direction, and minimal in the left/right direction.

Conclusions

Methods have been developed to determine locations of the whole body COG in both preoperative and postoperative subjects undergoing spinal fusion surgery and controls. The methods are robust to include men and women, subjects with and without instrumentation, and subjects in various positions including gait.

---

### ACR-ARS practice parameter for image-guided radiation therapy (IGRT) [^de97dddc]. American Journal of Clinical Oncology (2025). High credibility.

Image-guided radiation therapy (IGRT) operational process — IGRT refers to the use of imaging immediately before and/or during treatment delivery to ensure the target position is reproducibly located according to a predetermined plan; this spatial relationship is often determined from a 3-D image set, most commonly X-ray CT, acquired at initial simulation, although MRI simulation is an emerging technology; target location may be assessed at some predetermined frequency using methods ranging from soft-tissue volumetric imaging (CT, ultrasound, MRI) to localization of surrogates (bone, implanted fiducial markers, or external surface markers or features) via planar imaging, fluoroscopy, electromagnetic localization, or optical surface imaging; the match or discrepancy with the simulated location may be determined manually by visual alignment or by using automated image analysis software, and if a discrepancy is found, a correction is applied so treatment is delivered precisely and accurately according to the approved treatment plan.

---

### Using rigid motion constraints for the registration of free-form surfaces [^eaadaff5]. Journal of Digital Imaging (2001). Low credibility.

We present a new method for registration of freeform surfaces based on the iterative closest point (ICP) method and on geometric properties of reflected correspondence vectors. The method is based on computing relative gaps between reflected correspondences and between the projections of reflected correspondences along the rotation axis and using these to eliminate false matches. Experimental results on synthetic data and on real range images demonstrate that the method is robust and accurate for image registration with small motions.

---

### Repeatability and reproducibility of a new method for centration analysis via optical zone tangent points after corneal refractive surgery [^ffbfce2e]. BMC Ophthalmology (2024). Medium credibility.

Fig. 3
On the pachymetry difference map, the positions of four tangent points marked with a black cross are located on the smallest circle containing the maximum pachymetric difference. Examiners could also judge the location of the tangent point by moving the mouse and observing the changes in the values of the coordinates and thickness during the measurement process. The 85u represents the magnitude of the pachymetric difference at the tangent point is 85um. The coordinates of the tangential point are also displayed directly in the lower left corner of each panel

The coordinates of refer to the displacement of the decenter relative to the preoperative CV. was also equivalent to the horizontal(vertical) decentration. As previously described, the decentration in the tangential curvature difference map was calculated as, whereandare the preoperative pupil center coordinates, andandare the postoperative pupil center coordinates. In the pachymetry difference map, the values ofandwere used to calculate the parameters ofand.

The magnitude of total decentration in each difference map was calculated as follows,

We take the coordinates of four tangential points in Fig. 2 as an example to show how to calculate the value of the. The coordinats of, andwere (mm, mm), (mm, mm), (mm, mm), and (mm, mm), respectively. Bringing the above coordinates into Eq. (1), andwere calculated to bemm and 0.26 mm, respectively. The coordinates of the pupil center were shown directly on the Pentacam. Here, the preoperative pupil center coordinates was (mm, mm); the postoperative pupil center coordinates was (mm, mm). By bringing them into Eq. (3), it can be calculated that the was (mm, 0.10 mm). Finally, the value of thewas calculated from Eq. (4) as 0.10 mm.

---

### Modified surface measurement method to determine catheter tip position of totally implantable venous access port through right subclavian vein [^a875649c]. Journal of Vascular Surgery: Venous and Lymphatic Disorders (2021). Medium credibility.

Background

Optimal catheter tip position of a totally implantable venous access port (TIVAP) is important to maintain its function and to avoid severe complications. In this study, we aimed to assess the reliability of a modified surface measurement method to determine optimal tip position of a TIVAP catheter inserted through the right subclavian vein.

Methods

Clinical and radiologic information of 105 patients who underwent TIVAP implantation through the right subclavian vein was collected retrospectively. The length of the implanted catheter was determined by a modified surface measurement method, as follows. The distance from the puncture point (point A) to the middle point of the sternal notch (point B), then from the middle point of the sternal notch (point B) to the middle point of Louis angle (point C) was added up. The equation for the catheter length is given by catheter length (cm) = AB + BC + 3. Postprocedure plain chest radiography (CXR) and enhanced chest computed tomography (CT) were used to check the catheter tip position and to calculate optimal position rate. Distance from the carina to the catheter tip and the length of the vertebral body unit were measured on both CXR and CT. Distances from carina to caval-atrial junction (CAJ) and from catheter tip to CAJ were measured on CT.

Results

Mean length of the implanted catheter of all patients was 17.0 ± 0.7 cm (male vs female, 17.3 ± 0.5 cm vs 16.7 ± 0.7 cm; P < .001). On CXR, a catheter tip located within 2.4 vertebral body units below the carina was identified as the optimal position, and the optimal position rate was 97.1% (102/105 cases). On CT, two definitions of optimal position were used: within 2 cm above or below the CAJ and within 2 cm above or at the CAJ; the optimal position rate was 92.4% (97/105 cases) and 78.1% (82/105 cases), respectively. Median follow-up time was 9.4 months. During the follow-up, no severe cardiac complication was recorded.

Conclusions

The modified surface measurement had high reliability in determining the optimal catheter length to accurately place the tip in the superior vena cava near the CAJ.

---

### Using grid cells for navigation [^f5d9ba0e]. Neuron (2015). Low credibility.

Algorithmic Solution in 1D

The cyclical nature of the grid representation within each module i is such that an activity bump at phase p i implicitly represents an infinite set of "unwrapped" phases p i + 2 πn i, where n i can take any integer value, corresponding to an infinite set of distances s i (p i /2 π + n i) along that 1D axis that are separated by the scale s i of module i. Initially, we assume that all phases are zero at the current location a and the distance d to a goal location b must be inferred from the grid cell representation across modules at that location { p i (b)} = { p 1 (b), p 2 (b),…, p M (b)}. The grid representation of the goal location b is such that there is a set of unwrapped phases (one for each module) that explicitly represent the same distance — i.e. there is a set of integers { n i } for which:

Graphically, this coherent set of unwrapped phases across modules falls on a horizontal line when plotted against a y axis of represented distance (i.e. y = d; Figure 4 A) or, equivalently, on a straight line through the origin when plotted against a y axis of phase against inverse grid scale (Equation 2; Figure 4 B) — i.e. there is a set of integers { n i } for which:

This latter relationship is obtained by re-arranging Equation 1 and corresponds to the Fourier shift theorem (see discussion of the Algorithmic Solution in 2D below;). Thus, the distance d to a goal location represented by the set of module phases { p i } can be inferred by fitting a straight line through the origin on a plot of unwrapped phases p i + 2 πn i against inverse grid scale 1/ s i across modules (Figure 4 B). Moreover, this result can be generalized to any pair of arbitrary current and goal locations on that 1D axis, by replacing the absolute phase p i at the goal location with the phase difference Δp i between grid cell representations of current and goal locations in each module (Equation 3):

---

### Retinal image registration using geometrical features [^468189a4]. Journal of Digital Imaging (2013). Low credibility.

In this study, we have introduced an accurate retinal images registration method using affine moment invariants (AMI's) which are the shape descriptors. First, some closed-boundary regions are extracted in both reference and sensed images. Then, AMI's are computed for each of those regions. The centers of gravity of three pairs of regions which have the minimum of distances are selected as the control points. The region matching is performed by the distance measurements of AMI's. The evaluation of region matching is performed by comparing the angles of three triangles which are built on these three-point pairs in reference and sensed images. The parameters of affine transform can be computed using these three pairs of control points. The proposed algorithm is applied on the valid DRIVE database. In general (for the case, each sensed image is produced by rotating, scaling, and translating the reference image with different angles, scale factors, and translation factors), the success rate and accuracy is 95 and 96%, respectively.

---

### Analysis of the thickness characteristics of the left atrial posterior wall and its correlation with the low and no voltage areas of the left atrial posterior wall in patients with atrial fibrillation [^22e621f7]. Journal of Cardiothoracic Surgery (2024). Medium credibility.

Fig. 1
Measurement of the thickness of the posterior wall of the left atrium

Fig. 2
Left atrial measurement point diagram. a. In the oblique horizontal position for measuring the left atrial transverse diameter, the left atrial body between the bilateral pulmonary venous sinuses (dotted lines) is divided equally into four parts by lines c - e. Wall thickness is measured along these lines (c - e) in the oblique sagittal plane perpendicular to the transverse left atrial diameter. Figures c, d and e correspond to the lines in figure a. The arrows indicate the measurement points. Measurement point 4 is the midpoint of the posterior wall; measurement point 1 is located in the upper 1/3 of the line connecting measurement point 4 to the top line of the left room in figure c. Measurement points 2 and 3 are measured in the same way as measurement point 1; measurement point 7 is located in the lower 2/3 of the line connecting measurement point 4 to the bottom line of the left room in figure c. Measurement points 8 and 9 are measured in the same way as measurement point 7; the figures shown correspond to the positions of the measurement points shown in Fig. 1. Measurement point 1 = top right of the rear wall, measurement point 2 = top middle of the rear wall, measurement point 3 = top left of the rear wall, measurement point 4 = middle right of the rear wall, measurement point 5 = middle of the rear wall, measurement point 6 = middle left of the rear wall, measurement point 7 = bottom right of the rear wall, measurement point 8 = bottom middle of the rear wall, measurement point 9 = bottom left of the rear wall, comparison between top middle and bottom of the rear wall for 1, 2, 3; 4, 5, 6; 7, 8,9 The comparison between the three groups of data is 3, 6, 9; 2, 5, 8; 1, 4, 7 for the left-centre-right comparison of the rear wall

---

### Different strategies in pointing tasks and their impact on clinical bedside tests of spatial orientation [^c954ce45]. Journal of Neurology (2022). Medium credibility.

Deficits in spatial memory, orientation, and navigation are often early or neglected signs of degenerative and vestibular neurological disorders. A simple and reliable bedside test of these functions would be extremely relevant for diagnostic routine. Pointing at targets in the 3D environment is a basic well-trained common sensorimotor ability that provides a suitable measure. We here describe a smartphone-based pointing device using the built-in inertial sensors for analysis of pointing performance in azimuth and polar spatial coordinates. Interpretation of the vectors measured in this way is not trivial, since the individuals tested may use at least two different strategies: first, they may perform the task in an egocentric eye-based reference system by aligning the fingertip with the target retinotopically or second, by aligning the stretched arm and the index finger with the visual line of sight in allocentric world-based coordinates similar to using a rifle. The two strategies result in considerable differences of target coordinates. A pilot test with a further developed design of the device and an app for a standardized bedside utilization in five healthy volunteers revealed an overall mean deviation of less than 5° between the measured and the true coordinates. Future investigations of neurological patients comparing their performance before and after changes in body position (chair rotation) may allow differentiation of distinct orientational deficits in peripheral (vestibulopathy) or central (hippocampal or cortical) disorders.

---

### Ultrasound evaluation of a new surface reference line to describe sural nerve location and safe zones to consider in posterior leg approaches [^fc89b90b]. Knee Surgery, Sports Traumatology, Arthroscopy (2023). Medium credibility.

Purpose

Several authors have described methods to predict the sural nerve pathway with non-proportional numerical distances, but none have proposed a person-proportional, reproducible method with anatomical references. The aim of this research is to describe ultrasonographically the distance and crossing zone between a surface reference line and the position of the sural nerve.

Methods

Descriptive cross-sectional study, performed between January and April 2022 in patients requiring foot surgery who met inclusion criteria. The sural nerve course in the posterior leg was located and marked using ultrasound. Landmarks were drawn with a straight line from the medial femoral condyle to the tip of the fibula. Four equal zones were established in the leg by subdividing the distal half of the line. This way, areas based on simple anatomical proportions for each patient were studied. The distance between the marking and the ultrasound nerve position was measured in these 4 zones, creating intersection points and safety areas. Location and distances from the sural nerve to the proposed landmarks were assessed.

Results

One-hundred and four lower limbs, 52 left and 52 right, assessed in 52 patients were included. The shortest median distance of the nerve passage was 2.9 mm from Point 2. The sural nerve intersection was 60/104 (57.7%) in Zone B, 21/104 (20.1%) in Zone C and 19/104 (18.3%) in Zone A. Safety zones were established. Average 80.5% of coincidence in sural nerve localization was found in the distal half of the leg, in relation to the surface reference line when comparing both legs of each patient.

Conclusions

This study proposes a simple, reproducible, non-invasive and, for the first time, person-proportional method, that describes the distance and location of the main areas of intersection of the sural nerve with points and zones (risk and safe zones) determined by a line guided by superficial anatomical landmarks. Its application when surgeons plan and perform posterior leg approaches will help to avoid iatrogenic nerve injuries.

Level Of Evidence

IV.

---

### Stereodivergent 1, 3-difunctionalization of alkenes by charge relocation [^e4b3af6d]. Nature (2024). Excellent credibility.

a, Synthesis of 4-ipomeanol and other biologically active molecules. b, Proposed mechanism of 1,3-alkene difunctionalization, involving charge relocation. c, Mechanistic investigations support the hypothesis that nascency of the charge does not affect the constitution of the obtained product (Supplementary Information). d, Complete stereocontrol for the formation of a 1,2,3-trisubstituted cyclohexane.

From a mechanistic point of view (Fig. 4b) we believe that the 1,3-difunctionalizations presented above rely on a rapid isomerization event. This converts, under thermodynamic control, what would be the first intermediate of electrophilic addition, the β-keto cation, into the rearranged, cyclic oxocarbenium ion rac -I – — with the formation of rac -I constituting a locking event to prevent further isomerization and non-selective product formation. This common intermediate is then intercepted either in hydrolytic fashion at the carbonyl (affording the syn -configured products) or through invertive displacement at the secondary sp 3 -centre C3 with other nucleophiles, resulting in the formation of the anti -configured products described above.

The concept of charge relocation is best illustrated by the mechanistic experiments depicted in Fig. 4c. We established that, regardless of where the carbocation is initially formed (by bromide abstraction), the overwhelming majority of the material is converted into the expected 1,3-difunctionalized target: the carbocation was drawn to the γ position independently of its nascent state.

The reactions of more complex substrates also proved interesting. When 1-methylcyclohexene, a trisubstituted alkene, was used, the all- syn- hydroxyketone 54 was obtained as a single diastereomer (see X-ray structure to the right; Fig. 4d). This stereochemical outcome is probably governed by the preferred equatorial orientation of the only substituent not bound within a ring, the methyl group (Fig. 4d).

---

### Descent trajectory reconstruction and landing site positioning of chang' E-4 on the lunar farside [^5eca887b]. Nature Communications (2019). High credibility.

According to photogrammetric bundle adjustment theory, the relationship between the lunar surface points, the corresponding image points and the camera projection center can be expressed by the classical collinear equation, which is as follows.where (x, y) are the image coordinates of the feature points, (x 0, y 0) are the image coordinates of the image principal point, (Δ x,Δ y) are self-calibration correction terms of the camera, including lens distortion correction, (X, Y, Z) are the lunar space coordinates of the feature points, (X s, Y s, Z s) are the lunar space coordinates of the image principal point, f is the focal length of the camera, and r 11– r 33 are the elements of the rotation matrix R(φ, ω, κ), which is formed by the Euler attitude angle (φ, ω, κ) of the LCAM and used to translate feature points from the lunar space coordinates to the image coordinates. (X s, Y s, Z s, φ, ω, κ) forms the exterior orientation (EO) parameters of the LCAM. Using Taylor's formula, the linearized error equations of each pixel can be derived by formula (1). The EO parameters of each image and the lunar space coordinates of each feature point can be solved by the least squares method. We implemented the photogrammetric bundle adjustment theory by ContextCapture Master software in this study. Therefore, we can use the location of each image to reconstruct the descent trajectory of the CE4 lander.

After the adjustment, the RMS error of the reprojection error for all the tie points is 0.5 pixels. The horizontal and vertical RMS errors of the GCPs are, respectively, 0.715 m (1δ) and 1.040 m (1δ) (Table 4), which represent the accuracy of the CE-4 descent trajectory reconstruction.

Table 4
Horizontal and vertical deviations of the GCPs for the LCAM

---

### Males but not females report genital sensations evoked by fixed-parameter stimulation of somatosensory cortex [^8f99f393]. Brain (2025). Medium credibility.

Figure 4
Stimulation responses evoked at the coordinates of female genital cortex as identified by MRI of sensory genital responses. (A) Left: Composite map of stimulation points in males superimposed to a standard brain (MNI space). Only stimulation points close to the coordinates of female genital cortex (the centre of which is marked by the green disk) as identified by imaging of sensory responses in females by Knop et al.are shown. As indicated by n, we placed numerous stimulation points at such coordinates. Stimulation points where stimulation evoked genital sensations are shown in red; other stimulation points are shown in blue. Right: Pie chart of sensory responses evoked in males at cortical coordinates of female genital cortex. Note the large fraction of genital sensations, which indicates that male and female genital cortex share the same cortical coordinates. (B) Left: Composite map of stimulation points in females superimposed to a standard brain (MNI Space). Only stimulation points close to the coordinates of female genital cortex (the centre of which is marked by the green disk) as identified by imaging of sensory responses in females by Knop et al.are shown. As indicated by n, we placed numerous stimulation points at such coordinates. Conventions as in A. Right: Pie chart of sensory responses evoked in females at cortical coordinates of female genital cortex. Note the absence of genital sensations and the large fraction of leg sensations. The fraction of negative responses is slightly lower than in males, suggesting female genital cortex is not simply unresponsive; instead, genital cortex stimulation seems often to evoke leg sensations. MNI = Montreal Neurological Institute.

---

### Repeatability and reproducibility of a new method for centration analysis via optical zone tangent points after corneal refractive surgery [^c2a71e18]. BMC Ophthalmology (2024). Medium credibility.

Fig. 1
The left panel is a composite picture using the square method to measure the COZ on the Pentacam tangential difference map. A rectangle is formed by hypothetical tangents (red dashed lines) in four directions: superior, inferior, nasal, and temporal to the optical zone. Point O is the geometric center of the rectangle, i.e. the center of the optical zone. In the right panel, the point of the farthest edges of OZ at the temple is located on the Pentacam tangential difference map. The diopter of this point is 0.0D and the coordinates of this point (-2.53 mm, -0.57 mm) are directly shown on the map. Examiners could judge the location of the tangent point by moving the mouse and observing the changes in the values of the coordinates and diopters during the measurement process

Located the tangent points on the farthest edges of the OZ at the temple, nasal, superior, and inferiorregions (Fig. 2)). The coordinates of the COZin the tangential difference maps were calculated using the following formulas,

Fig. 2
On the tangential difference maps, the tangent point is depicted with a black cross, which also indicates the position of the mouse cursor during the measurement. The left aspect of the image represents the temporal side. The coordinates of the tangent point are displayed directly in the lower left corner of each panel. For the right eye, the positive x values indicated nasal decentration and negative x values indicated temporal decentration

The centration analysis on the pachymetry difference maps was conducted similarly. The OZs in the pachymetry difference maps resemble the shape of concentric circles. The coordinates of the four tangent points were located on the smallest circle encompassing the maximum pachymetrical difference (Fig. 3). The coordinates of the COZin pachymetry difference maps were calculated by the following formula

---

### A bedside application-based assessment of spatial orientation and memory: approaches and lessons learned [^e8207622]. Journal of Neurology (2019). Medium credibility.

Spatial orientation and memory deficits are an often overlooked and potentially powerful early marker for pathological cognitive decline. Pen-and-paper tests for spatial abilities often do not coincide with actual navigational performance due to differences in spatial perspective and scale. Mobile devices are becoming increasingly useful in a clinical setting, for patient monitoring, clinical decision-making, and information management. The same devices have positional information that may be useful for a scale appropriate point-of-care test for spatial ability. We created a test for spatial orientation and memory based on pointing within a single room using the sensors in mobile phone. The test consisted of a baseline pointing condition to which all other conditions were compared, a spatial memory condition with eyes-closed, and two body rotation conditions (real or mental) where spatial updating were assessed. We examined the effectiveness of the sensors from a mobile phone for measuring pointing errors in these conditions in a sample of healthy young individuals. We found that the sensors reliably produced appropriate azimuth and elevation pointing angles for all of the 15 targets presented across multiple participants and days. Within-subject variability was below 6° elevation and 10° azimuth for the control condition. The pointing error and variability increased with task difficulty and correlated with self-report tests of spatial ability. The lessons learned from the first tests are discussed as well as the outlook of this application as a scientific and clinical bedside device. Finally, the next version of the application is introduced as an open source application for further development.

---

### An adaptive off-line procedure for radiotherapy of prostate cancer [^b2009f19]. International Journal of Radiation Oncology, Biology, Physics (2007). Low credibility.

Purpose

To determine the planning target volume (PTV) margin for an adaptive radiotherapy procedure that uses five computed tomography (CT) scans to calculate an average prostate position and rectum shape. To evaluate alternative methods to determine an average rectum based on a single delineation.

Methods and Materials

Repeat CT scans (8–13) of 19 patients were used. The contoured prostates of the first four scans were matched on the planning CT (pCT) prostate contours. With the resulting translations and rotations the average prostate position was determined. An average rectum was obtained by either averaging the coordinates of corresponding points on the rectal walls or by selecting the "best" rectum or transforming the pCT rectum. Dose distributions were calculated for various expanded average prostates. The remaining CT scans were used to determine the dose received by prostate and rectum during treatment.

Results

For the prostate of the pCT scan and a 10-mm margin, all patients received more than 95% of the prescribed dose to 95% of the prostate. For the average prostate, a margin of 7 mm was needed to obtain a similar result (average PTV reduction 30%). The average rectum overestimated the mean dose to the rectum by 0.4 ± 1.6 Gy, which was better than the pCT rectum (2.1 ± 3.0 Gy) and the alternative average rectums (1.0 ± 2.6 Gy and 1.4 ± 3.2 Gy).

Conclusions

Our adaptive procedure allows for reduction of the PTV margin to 7 mm without decreasing prostate coverage during treatment. For accurate estimation of the rectum dose, rectums need to be delineated and averaged over multiple scans.

---

### Human navigation strategies and their errors result from dynamic interactions of spatial uncertainties [^5c48940c]. Nature Communications (2024). High credibility.

Ideal observer analysis (heading direction)

Zhao & Warrenperformed cue integration analysis based on heading direction rather than Euclidean distances. Heading errors were fitted to von-mises distributions for each cue condition separately (self-motion:; landmark:; combined:). Predictions of mean heading direction and heading variability in combined cue and conflict conditions are predicted based on heading variability and heading directions from single cue conditions as follows:where θ refers to the mean homing direction and κ to the concentration. In conflict conditions, Δ refers to the angle of the landmark shift applied in conflict conditions. Circular standard deviations are computed based on concentration parameters κ according to:where I (x) refers to the Bessel function of the first kind.

Dynamic Bayesian actor model

State space representations

The agent state x t consists of its pose (x, y, θ), including its position and heading direction, as well as the global (x, y)-coordinates of the landmarks (and target locations) in an allocentric frame of reference. The complete state thus can be described as x = (x pose, x map) whereand:where L is the number of landmark and goal locations in the environment. The current state of the world at timestep t is expressed as x t.

Motion model and motor variability

The agent changes its position and heading direction in space by sequentially performing motor actions. For the non-linear dynamics x t + 1 = f (x t, u t) we assume a unicycle motion model with control inputs u t = (v t, w t). Prior research has shown that this non-holonomic motion model applies to human data for goal-oriented locomotion. Here, we only model the discrete first-order dynamics with direct inputs of linear velocity v t and angular velocity w t for a discrete timestep d t :Further, we assume that these inputs u t = (v t, w t) are subject to signal-dependent noise α with noise parameters (α 1, α 2, α 3, α 4):

---

### ACR-ARS practice parameter for the performance of stereotactic body radiation therapy [^644c87bf]. ARS/ACR (2024). High credibility.

ACR–ARS SBRT simulation and treatment — positioning and immobilization states that immobilization to minimize motion and setup variation may use frame-based systems that adhere to the treatment table or frameless systems that rely on stable anatomical landmarks and/or fiducial markers and precise image guidance, that external reference fiducials can be used to aid in targeting but relying solely on body frame localization is strongly discouraged, that frameless stereotactic methods include metallic seed implantation or fiducials within a tumor, use of surrogate anatomy, use of the target itself as a fiducial, and optical surface guidance, that for accurate SBRT treatment delivery the target position should be confirmed with a radiographic imaging when using optical surface imaging, and that daily image guidance is used for treatment setup.

---

### ACR-ARS practice parameter for the performance of brain stereotactic radiosurgery [^66f169f6]. ARS/ACR (2021). High credibility.

Brain stereotactic radiosurgery — treatment delivery responsibilities include that the radiation oncologist is responsible for ensuring accurate patient positioning and field placement for each fraction; if required, the image-guided stereotactic procedure is used to verify or correct position relative to the planning image data set; positioning prior to each treatment must be verified; the team must be aware of setup limitations and thresholds for stopping, repositioning, and reimaging and must communicate and update each other when errors or malfunctions are suspected; patient treatment should be paused if the patient is out of position beyond thresholds specified by the radiation oncologist; for frameless systems, 3-D optical surface–guided monitoring systems can help provide an additional tool for intrafraction motion management; the qualified medical physicist should be present for setup, image guidance, and motion review for the entirety of the first fraction; the radiation oncologist should approve the image guidance and motion review and be present at the start of each treatment fraction; and the qualified medical physicist and radiation oncologist must be readily available should issues arise during treatment delivery.

---

### Rimabotulinumtoxinb (Myobloc) [^f75ffbd1]. FDA (2025). Medium credibility.

2.3	Dosing for Chronic Sialorrhea

Dosing Information

The recommended dosage of MYOBLOC for chronic sialorrhea is 1,500 Units to 3,500 Units, divided among the parotid and submandibular glands (Table 1). Patient response to treatment should be considered when determining subsequent MYOBLOC dosage [see Clinical Studies (14.2)]. The typical duration of effect of each treatment is up to 3 months; however, the effect may vary in individual patients. The frequency of MYOBLOC repeat treatments should be determined by clinical response but should generally be no more frequent than every 12 weeks.

Administration Information

A suitable sterile needle (e.g., 30-gauge, 0.5 inch) should be used for intra-salivary gland administration.

Figure 1:	Glands for Injection in Chronic Sialorrhea

Guidelines for locating salivary glands using anatomical landmarks (Figure 1):

1. To inject the parotid gland, bisect the distance between the tip of the tragus (Site A) and the angle of the mandible (Site B). Inject one finger breadth anterior to this site (Injection Site 1).
2. To inject the submandibular gland, bisect the distance between the angle of the mandible (Site B) and the tip of the chin (Site C). Inject one finger breadth medial to the inferior surface of the point of bisection (Injection Site 2).

In clinical studies, MYOBLOC was injected using anatomical landmarks to localize the salivary glands, or using ultrasound guidance for gland location. Both methods produced similar reduction in the unstimulated salivary flow rate.

---

### Simultaneous 3D localization of multiple MR-visible markers in fully reconstructed MR images: proof-of-concept for subsecond position tracking [^a9a9c04f]. Magnetic Resonance Imaging (2012). Low credibility.

Purpose

To determine whether a greatly reduced spatial resolution of fully reconstructed projection MR images can be used for the simultaneous 3D localization of multiple MR-visible markers and to assess the feasibility of a subsecond position tracking for clinical purposes.

Materials and Methods

Miniature, inductively coupled RF coils were imaged in three orthogonal planes with a balanced steady-state free precession (SSFP) sequence and automatically localized using a two-dimensional template fitting and a subsequent three-dimensional (3D) matching of the coordinates. Precision, accuracy, speed and robustness of 3D localization were assessed for decreasing in-plane resolutions (0.6–4.7 mm). The feasibility of marker tracking was evaluated at the lowest resolution by following a robotically driven needle on a complex 3D trajectory.

Results

Average 3D precision and accuracy, sensitivity and specificity of localization ranged between 0.1 and 0.4 mm, 0.5 and 1.0 mm, 100% and 95%, and 100% and 96%, respectively. At the lowest resolution, imaging and localization took ≈350 ms and provided an accuracy of ≈1.0 mm. In the tracking experiment, the needle was clearly depicted on the oblique scan planes defined by the markers.

Conclusion

Image-based marker localization at a greatly reduced spatial resolution is considered a feasible approach to monitor reference points or rigid instruments at subsecond update rates.

---

### A clearly visible endoscopic instrument shaft on the monitor facilitates hand-eye coordination [^a52556f2]. Surgical Endoscopy (2002). Low credibility.

Background

Passing an instrument through a small incision alters the kinematics of the instrument, thus hampering hand-eye coordination. Nevertheless, the incision provides a stable, nearly invariant, point of rotation for instrument movements. Therefore, we set out to evaluate the effects of the altered kinematics on hand-eye coordination. In addition, we assessed the hypothesis that the hand-eye coordination of laparoscopic surgeons incorporates the incision as a point of reference.

Methods

Eight surgeons with experience in laparoscopy repeatedly performed a positioning task on a two-dimensional endoscopic manipulation simulator. Task time was measured. In the first experiment, normal endoscopic manipulation was compared to a condition in which the kinematic effects of the incision were compensated for. In the second experiment, the instrument shaft on the monitor was not visible during half of the trials, so that all visual information about the location of the incision was obscured.

Results

Task performance improved significantly when the kinematic effects of the incision were compensated for (p = 0.001). Task performance improved when the instrument shaft was clearly visible on the monitor (p < 0.05).

Conclusions

Compensating for the kinematic effects introduced by the incision improves hand-eye coordination. The results of this study indicate that the incision provides a point of reference for hand-eye coordination during endoscopic manipulation.

---

### A novel theory for rapid localization of the transverse-sigmoid sinus junction and "keyhole" in the retrosigmoid keyhole approach: micro-anatomical study, technique nuances, and clinical application [^76329d99]. Neurosurgical Review (2024). Medium credibility.

Conclusions

This localization method we named "one point, two lines, and two distances" theory. "one point" is the top point of the digastric groove. "two line" is the baseline between the infraorbital margin and superior margin of the external acoustic meatus and the perpendicular line to the baseline through the top point of the digastric groove. "two distances" is the perpendicular and horizontal distances between the centre point of keyhole and the top point of the digastric groove in the coordinate system. The spatial positions of the keypoint and drilling point can be confirmed using the coordinate system. The drilling point was 14.0 mm above and 6.5 mm behind the top point of the digastric groove in the coordinate system. The keypoint was located approximately 3–4 mm medial-superior to the drilling point. Our localization method is simple, safe, operable, and practical. Further, this method can provide a quantitative anatomical basis for safe, accurate, and rapid craniotomy.

---

### Human navigation strategies and their errors result from dynamic interactions of spatial uncertainties [^f92daba7]. Nature Communications (2024). High credibility.

Data preprocessing & replication of prior analysis

All endpoint data, i.e. empirical data from the respective studies and data from model simulations, were reanalyzed following the procedures used in prior work –. We normalized homing responses for each homing location by centering them within a common coordinate system, with either the actual homing direction as the north-directionor centered around the true target location. Outliers were removed based on distances to the mean location within each condition by excluding those trials that exceeded the third quartile by three times the interquartile range. For data of Chen et al.and Zhao & Warren, we also removed biases in the four individual target locations before pooling them together so as not to increase response variability artificially. After pooling data from all four target locations, we computed the response variability for each of the simulated and real participants in each of the four conditions. We did so either as the standard deviation of the Euclidean distances (or heading directions) between the response locations for each trial or the mean response location (or heading) across all trials. We used computed response variances for the two single cue conditions (self-motion and landmark) to predict response variance for the combined cue condition according to the perceptual cue integration model for Euclidean distance, or heading direction. We considered the integration of cues statistically optimal when the reduction in response variability in the combined cue conditions can be predicted from response variability in single cue conditions (Equation (5)). Further, we used mean responses in conflict conditions to predict relative response proximity to the landmark or self-motion-defined target locations. We compared them with optimal predictions based on response variability. All data were analyzed at the single participant level if not indicated otherwise.

---

### Heading direction with respect to a reference point modulates place-cell activity [^e94e32d9]. Nature Communications (2019). High credibility.

Results

HD modulation of place-cells activity

We recorded the activity of 1244 neurons in the dorsal region of both the left and right hippocampi (area CA1; "Methods"; Supplementary Fig. 1) in 12 C57BL/J6 mice. We recorded daily during 4 sessions of 10 min each over a period of 10 days. The analysis presented here is based on 697 neurons that satisfied a set of minimal response and sampling criteria ("Methods"). During each session, food-deprived animals foraged freely within a 50-by-50 cm enclosure. In addition to monitoring the location of the animal (x, y), we tracked its absolute HD angle (H), defined as the angle of the animal's direction of motion relative to a fixed orientation in the room that coincided with a cue card on one wall of the enclosure ("Methods"). Motion direction was determined by computing the difference between the locations of the animal at two times separated by 1/30 s. For these analyses, the enclosure was divided into 100 square spatial bins (5-by-5 cm each). The heading angle was in turn divided into 10 angular bins of 36° each. To obtain the firing rate data r(x, y, H), firing rates of the recorded neurons were averaged across multiple occupancies within each bin to obtain the firing-rate vector r (x, y, H).

---

### Prevention and treatment of motion sickness [^132cfad3]. American Family Physician (2014). Medium credibility.

Regarding nonpharmacologic interventions for motion sickness, more specifically with respect to body positioning and visual attention, AAFP 2014 guidelines recommend to advise patients to focus on a fixed point on the horizon and avoid close visual tasks while in vehicles to prevent and reduce symptoms of motion sickness.

---

### Reliability of a preliminary 3-D pain mapping program [^f834d392]. Pain Medicine (2011). Low credibility.

Objective

The objective of this preliminary investigation was to evaluate the test-retest reliability of a new pain assessment method referred to as 3-D pain mapping.

Methods

In Study 1, 101 chronic noncancer pain patients from four sites reported their pain using the method on two occasions (separated by approximately 10 days). The patients marked intensity, surface location, and depth of pain on a 3-D computer display of a male or female body. The model body could be rotated in order to mark multiple pain locations. In Study 2, 25 patients from a single site were tested with a revised version of the mapping program used in Study 1. Each patient gave ratings on two occasions separated by approximately 1 week.

Results

In Study 1, the intra-class correlations of the 3-D pain mapping measures were moderate to high for maximum pain intensity (0.73), vertical location of the point of maximum pain (0.94), and the number of pain marks (0.84). Correlations were low for the horizontal location of the point of maximum pain (0.56) and for the depth of pain (0.50). In Study 2, using the revised program, intra-class correlations were moderate for pain intensity (0.76), and high for the vertical (0.99) and horizontal (0.98) locations of the point of maximum pain, number of pain marks (0.89), and the depth of pain (0.84).

Conclusion

Three-dimensional pain mapping enables patients to report the location and intensity of their pain on all parts of the body, and such ratings are highly reliable. Future studies are needed to determine whether the clinical value of this method can improve the accuracy of pain diagnoses and the quality of pain management.

---

### A novel theory for rapid localization of the transverse-sigmoid sinus junction and "keyhole" in the retrosigmoid keyhole approach: micro-anatomical study, technique nuances, and clinical application [^c0bba0c2]. Neurosurgical Review (2024). Medium credibility.

To determine a rapid and accurate method for locating the keypoint and "keyhole" in the suboccipital retrosigmoid keyhole approach. (1) Twelve adult skull specimens were selected to locate the anatomical landmarks on the external surface of the skull. The line between the infraorbital margin and superior margin of the external acoustic meatus was named the baseline. A coordinate system was established using the baseline and its perpendicular line through the top point of diagastric groove. The perpendicular distance (x), and the horizontal distance (y) between the central point of the "keyhole" and the top point of the digastric groove in that coordinate system were measured. The method was applied to fresh cadaveric specimens and 53 clinical cases to evaluate its application value. (1) x and y were 14.20 ± 2.63 mm and 6.54 ± 1.83 mm, respectively (left) and 14.95 ± 2.53 mm and 6.65 ± 1.61 mm, respectively (right). There was no significant difference between the left and right sides of the skull (P > 0.05). (2) The operative area was satisfactorily exposed in the fresh cadaveric specimens, and no venous sinus injury was observed. (3) In clinical practice, drilling did not cause injury to venous sinuses, the mean diameter of the bone windows was 2.0–2.5 cm, the mean craniotomy time was 26.01 ± 3.46 min, and the transverse and sigmoid sinuses of 47 patients were well-exposed. We propose a "one point, two lines, and two distances" for "keyhole" localization theory, that is we use the baseline between the infraorbital margin and superior margin of the external acoustic meatus and the perpendicular line to the baseline through the top point of the digastric groove to establish a coordinate system. And the drilling point was 14.0 mm above and 6.5 mm behind the top point of the digastric groove in the coordinate system.

---

### Self-powered multifunctional sensing based on super-elastic fibers by soluble-core thermal drawing [^0ff227e1]. Nature Communications (2021). High credibility.

Fig. 5
Applications as an adaptive sensor net on regular and irregular shaped surfaces for monitoring sports performance and training.

a A fiber-based sensing net that was conformally adapted on the 2D inner surface of a baseball glove to locate the hitting points with different catching speeds. b Photo to show the ball-catching using functional baseball glove. c The detection to locate the hitting points with different catching speeds when the baseball was caught by the glove. Colors indicate different catching speeds. d Conductive fibers on a 3D surface of a football to perform the sensing function of a spherical coordinate. e Schematic to show the cross point when pressed by fingers. f – k When a cross point was pressed, the corresponding signal was visualized on the spherical coordinates. f and g Point (0°, 45°) was pressed. h and i Point (60°, 90°) was pressed. j and k Point (120°, 135°) was pressed. The color indicates the signal value, and if both coordinate values are high enough, the upright coordinate line segments or area would be highlighted, which means that this cross point is pressed.

---

### In vivo measurement of the frame-based application accuracy of the neuromate neurosurgical robot [^8fbb1e55]. Journal of Neurosurgery (2015). Low credibility.

Object

The application accuracy of the Neuromate neurosurgical robot has been validated in vitro but has not been evaluated in vivo for deep brain stimulation (DBS) electrode implantations. The authors conducted a study to evaluate this application accuracy in routine frame-based DBS procedures, with an independent system of measurement.

Methods

The Euclidian distance was measured between the point theoretically targeted by the robot and the point actually reached, based on their respective stereotactic coordinates. The coordinates of the theoretical target were given by the robot's dedicated targeting software. The coordinates of the point actually reached were recalculated using the Stereoplan localizer system. This experiment was performed in vitro, with the frame fixed in the robot space without a patient, for 21 points spatially distributed. The in vivo accuracy was then measured in 30 basal ganglia targets in 17 consecutive patients undergoing DBS for movement disorders.

Results

The mean in vitro application accuracy was 0.44 ± 0.23 mm. The maximal localization error was 1.0 mm. The mean (± SD) in vivo application accuracy was 0.86 ± 0.32 mm (Δx = 0.37 ± 0.34 mm, Δy = 0.32 ± 0.24 mm, Δz = 0.58 ± 0.31 mm). The maximal error was 1.55 mm.

Conclusions

The in vivo application accuracy of the Neuromate neurosurgical robot, measured with a system independent from the robot, in frame-based DBS procedures was better than 1 mm. This accuracy is at least similar to the accuracy of stereotactic frame arms and is compatible with the accuracy required in DBS procedures.

---

### ACR-ARS practice parameter for image-guided radiation therapy (IGRT) [^ab887d5c]. ARS/ACR (2024). High credibility.

Image-guided radiation therapy (IGRT) documentation — reporting should be in accordance with the ACR–ARS Practice Parameter for Communication: Radiation Oncology, and successful implementation includes an IGRT directive that specifies the imaging modality, its frequency, the anatomical structures or fiducial targets used for registration, and the threshold for shifts above which a physician or medical physicist is required to review images and/or patient setup before treatment; documentation should also include patient-specific or equipment-related methods to minimize organ motion, reasons for shifts exceeding tolerance, corrective actions, and any reimaging modality; when the physician and physicist are already present for SRS and SBRT, documenting the threshold for shifts would indicate when exceeding a set threshold would necessitate evaluating the patient on the table for setup errors; the IGRT directive may be modified or updated with anatomic or modality/frequency changes, and it is advised that it be a separate patient-specific order not linked to the radiation treatment prescription; patient simulation setup and position should be documented by photographs, with site setup photos in the medical record for 3-D conformal treatments and clinical simulation light-field photographs for en face electron or photon treatments kept per ROPA Program Requirements, which are useful when therapists rotate or when centers use temporary or traveling therapists.

---

### C-arm based navigation in total hip arthroplasty-background and clinical experience [^75ebcfe3]. Injury (2004). Low credibility.

After experimental and preclinical evaluation of a CT-free image guided surgical navigation system for acetabular cup placement, the system was introduced into clinical routine. The computation of the angular orientation of the cup is based on reference coordinates from the anterior pelvic plane concept. A hybrid strategy for pelvic landmark acquisition has been introduced, involving percutaneous pointer-based digitization with the noninvasive bi-planar landmark reconstruction using multiple registered fluoroscopy images. From January 2001 to October 2003, a total of 236 consecutive patients (mean age 66 years, 144 male, 92 female, 124 left and 112 right hip joints) were operated on with the hybrid CT-free navigation system. During each operation, the angular orientation of the inserted implant was recorded. To determine the placement accuracy of the acetabular components, the first 50 consecutive patients underwent a CT scan 7–10 days postoperatively to analyze the cup position relative to the anterior pelvic plane. This procedure was done blinded and with commercial planning software. There was no significant learning curve observed for the use of the system. Mean values for postoperative inclination read 42 degrees (SD 3.6, range (37–49)) and anteversion 21 degrees (SD 3.9, range (10–28)). The resulting system accuracy, ie, the difference between intraoperatively calculated cup orientation and postoperatively measured implant position shows a maximum error of 5 degrees for the inclination (mean 1.5 degrees, SD 1.1) and 6 degrees for the anteversion (mean 2.4 degrees, SD 1.3). An accuracy of better than 5 degrees inclination and 6 degrees anteversion was achieved under clinical conditions, which implies that there is no significant difference in performance from the established CT-based navigation methods. Image-guided CT-free cup navigation provides a reliable solution for future total hip arthroplasty (THA).

---

### ACR-ARS practice parameter for the performance of total body irradiation [^790bd86b]. ACR/ARS (2022). High credibility.

Total body irradiation (TBI) — radiation therapist responsibilities include setting up the patient in the treatment position, including using appropriate treatment devices; verifying that the prescribed and calculated treatment distances match the used treatment distances; performing and reviewing imaging procedures to verify the setup and blocking, if any; treating the patient according to the prescription and plan provided; and monitoring and evaluating the patient during the treatments.

---

### Human navigation strategies and their errors result from dynamic interactions of spatial uncertainties [^3bb02419]. Nature Communications (2024). High credibility.

Ideal observer analysis (Euclidean distance)

To predict participants' response variability and bias in the double cue condition, we computed response variability in each cue condition as the Euclidean distance for each response to the mean response location. For the analysis, all error distributions in single cue conditions, i.e. p (L ∣ S) and p (L ∣ V), and double cue conditions, i.e. p (L ∣ S, V), are assumed to be normally distributed (self-motion:; landmark:; combined:).

This assumption allows for a weighted linear combination of the two single cue Gaussian distributions relative to their response variability to predict response variability and bias in double cue conditions. Based on the observed response variability in single cue conditions, optimal static cue weights (w l m + w s m = 1) can be computed as follows:The variance in double cue conditions can be predicted from response variance in single cue conditions as follows:This weighted average yields lower response variability in double cue conditions compared to the variance of single conditions. Further, the optimal cue weights predict participants' response location in double conditions from their response location in single cue conditions. This cue integration prediction can be explicitly tested when putting landmark cues into conflict by rotating them around the location of the last target (conflict condition). Doing so creates two response locations indicating exclusive use of either visual landmark or self-motion cues.

Proximity of participants responseto either of those location, e.g. Where the self-motion consistent location x sm is either the true target's location, e.g. (0,0), or when accounting for a particular participant's response bias by using the mean location of the self-motion consistent location, i.e. For the landmark-consistent location, the rotated normalized target location is used. It can further be corrected for participants' intrinsic response bias by subtracting the participants' mean responseobserved in the landmark condition. Given both proximities to either of the single cue consistent location, i.e. d s m and d l m, we calculated relative response proximity to the landmark-consistent location as follows:Response proximity to the landmark-consistent location is always between zero and one. Zero indicates participants responding at the self-motion consistent location, whereas one indicates participants responding at the landmark-consistent location. Relative response proximity can, therefore, also be interpreted as an empirical cue weight participants place on either cue, given homing responses in conflict conditions.

---

### Goal-oriented representations in the human hippocampus during planning and navigation [^d5d13577]. Nature Communications (2023). High credibility.

Consistent with the prospective representation of goal-relevant states in the hippocampus, we found several clusters showing higher similarity for converging compared to diverging sequences (Fig. 4, Supplemental Figs. 5–7). Interestingly, there was a significant off-diagonal cluster (outlined in red: T 22 = 3.34, p = 0.038, d = 0.27, 95% CI [0.0031, 0.013], maximum cluster corrected) that roughly corresponds to the activation of the decision point (position 3) when participants were at position 1 (approx. TRs 10–15). Other clusters tended to overlap with key locations in the experiment, which roughly correspond to position one activating position five (TRs 18 to 21) and position three activating position five (TRs 18 to 20) (Fig. 4D), although these clusters did not survive multiple comparison correction. These data are consistent with the idea that information about position 3 was preferentially activated in converging sequences, in which the same key decision was required to navigate to the same goal.

Fig. 4
Results from TR by TR pattern similarity analysis during active navigation in bilateral hippocampus.

A Group level pattern similarity results from converging sequences during active navigation. B Same as A but showing diverging sequences. C TR by TR pattern similarity results depicting a statistical map of converging – diverging. Z values were calculated using a bootstrap shuffling procedure with 10,000 permutations. D Thresholded statistical map at p < 0.025 (two-tailed). Cluster based permutation tests with 10,000 permutationswere performed with a cluster defining threshold of p < 0.05 (two-tailed) and a cluster alpha of 0.05 (two-tailed). Outlined in red is a significant cluster of timepoints that survives multiple comparisons correction (T 22 = 3.34, p = 0.038, d = 0.27, 95% CI [0.0031, 0.013], maximum cluster corrected). Note that this cluster corresponds to approximately position 1 activating position 3 which was shared by both converging and diverging sequences. Trial labels were manually lagged by 4 TRs (TR = 1.22, Inter-Item-Interval = 5 s) to account for hemodynamic response lag. In panels C and D, each pixel of a statistical comparison (T-value, N = 23) was converted into a Z value by normalizing it to the mean and standard error generated from our permutation distributions (see Methods).

---

### Spatiotemporal data analysis with chronological networks [^1bb536ca]. Nature Communications (2020). High credibility.

The number of spatiotemporal data sets has increased rapidly in the last years, which demands robust and fast methods to extract information from this kind of data. Here, we propose a network-based model, called Chronnet, for spatiotemporal data analysis. The network construction process consists of dividing a geometric space into grid cells represented by nodes connected chronologically. Strong links in the network represent consecutive recurrent events between cells. The chronnet construction process is fast, making the model suitable to process large data sets. Using artificial and real data sets, we show how chronnets can capture data properties beyond simple statistics, like frequent patterns, spatial changes, outliers, and spatiotemporal clusters. Therefore, we conclude that chronnets represent a robust tool for the analysis of spatiotemporal data sets.

---

### Standards of care in diabetes – 2025 [^31be65a6]. Diabetes Care (2025). High credibility.

Regarding diagnostic investigations for hypoglycemia, more specifically with respect to screening for cognitive impairment, ADA 2025 guidelines recommend to simplify diabetes treatment plans as much as possible for patients with cognitive impairment and tailor to minimize the risk of hypoglycemia.

---

### Diagnosis, management and treatment of the Alport syndrome-2024 guideline on behalf of ERKNet, ERA and ESPN [^45eede36]. Nephrology, Dialysis, Transplantation (2025). High credibility.

Regarding diagnostic investigations for Alport syndrome, more specifically with respect to hearing assessment, ERA/ERN ERKNet/ESPN 2025 guidelines recommend to consider obtaining a hearing evaluation at diagnosis or upon reaching adulthood in female patients with X-linked alport syndrome, and then every 5 years in the absence of hearing loss symptoms.

---

### Benchmarking tools for detecting longitudinal differential expression in proteomics data allows establishing a robust reproducibility optimization regression approach [^2c64c4ed]. Nature Communications (2022). High credibility.

If the time points in the data are not aligned between the individuals and the expression levels between the different conditions cannot be directly compared at different time points, the DiffROTS module is adjusted to such a design. This is done by examining the expression level differences between the conditions after accounting for time-associated trends of varying complexity in the data. More specifically, polynomial regression models of degrees j = 0,…, d are first fit to each protein: whereis the individual specific baseline. The maximum degree d is by default defined as, whereis the median number of time points over all the individuals. Individual variation is taken into account by adding a random effect for the individual baseline but can be adjusted to incorporate individual slopes as well. The model residualsare then recorded for each individual u in each of their measured time point t, and differentially expressed proteins between the two conditions are determined by comparing all the residuals of the individuals in one condition to those in the other condition using two-group ROTS, separately for the different polynomial degrees j. To detect any differential expression between the conditions, the final DiffROTS score for a protein is determined as the minimum over the significance values p j over the comparisons:

PolyReg

The PolyReg module applies polynomial regression modeling to each protein to detect longitudinal differential expression over time t across the conditions c :where d is the polynomial degree of the model, andare the time and condition-related regression coefficients, respectively, andis the error term. Individual variation can be taken into account by adding a random effect for the individual baseline or slope. By default, RolDE uses fixed effects models for the PolyReg module when the time points are aligned and mixed models with random effects for the individual baseline when the time points are not aligned. Using the mixed effects modeling approach should be considered especially when heterogeneity and uneven sampling points (e.g. non-aligned time points) are expected among individuals. The degree d is by default defined as, whereis the median number of time points over all the individuals. For each of the condition related coefficients, the null hypothesis is, that is, the condition related variable is not statistically significantly associated with the abundance of the protein. Each null hypothesis is examined using t -test, which is the standard way of assessing the significance of regression coefficients. The corresponding significance valuesare then used to determine the final score for the PolyReg module, which is calculated as the minimum over the significance values of the condition related regression coefficients:

---

### ACR-ARS practice parameter for the performance of stereotactic body radiation therapy [^94cb6251]. ARS/ACR (2024). High credibility.

ACR–ARS SBRT treatment delivery and verification — Precision of radiation dose delivery should be validated by the QC process and maintained throughout the entire treatment process. The radiation oncologist is responsible for ensuring that patient positioning and isocenter placement are accurate for each fraction, and the image-guided stereotactic procedure is used to verify or correct the patient's position relative to the planning image data set. Given how critical patient positioning is for this procedure, positioning prior to each treatment must be verified, and the team must be aware of the limitations of the setup and the tolerance or threshold for stopping, repositioning, and reimaging. Patient treatment should be paused if it is felt that the patient is out of position, beyond any thresholds previously specified by the radiation oncologist, and intrafractional systems may be used to track patient positioning during treatment. The Qualified Medical Physicist should be present for the setup, image guidance, and motion review for the entirety of the first fraction, and the radiation oncologist should approve the image guidance and motion review and be present at the start of each treatment fraction. The Qualified Medical Physicist and radiation oncologist must be readily available should issues arise during treatment delivery.

---

### Restoration of complicated epicanthus: modified reverse skin redraping with mini-epicanthoplasty for rescue in unsatisfied epicanthoplasty patients [^d16764e8]. Annals of Plastic Surgery (2017). Low credibility.

Surgical Technique

All surgeries were performed under local anesthesia with the patients in the supine position and performed usually at least 6 months after previous epicanthoplasty. Surgery started with our previous reverse skin-redraping methods. Briefly, "point A" was marked at the inner medial part, 1 mm from the lacrimal lake (innermost point of the medial canthus). "Point B" was marked 4 mm away and 70° upward from point A. These points were used as the baseline, and an elective line was drawn at the subciliary line. Finally, "point C" was marked 5 to 6 mm away from the lacrimal punctum, along the previously marked subciliary line (Fig. 1). After marking these base points, an elective incision line connecting points A, B, and C was drawn, and local anesthesia was injected. An incision on drawn line was made using a blade (no. 15). Submuscular dissection was then performed under the slashed red area in Figure 1 from the upper eyelid in the direction of the lower lid until sufficient tissue was obtained (Fig. 1). This is a key step in our previous restoration method that can reduce skin tension and allow easy movement of the skin-muscle flap. When pulling a skin to a medial direction with thumb, point A was shifted medially to point A'. After placing points A' and B in a straight line, we performed suturing at points A and B. At this point, point B' was marked on a line connecting B and A at a distance 2.0 to 2.5 mm from point B which was used for mini-epicanthoplasty (Fig. 2).

FIGURE 1
Mark point A at 1 mm medial from the innermost portion of epicanthus, and mark point B at a location 4 mm away and at 70 degrees upward on the upper eyelid (left). Mark point C is at an outer position following the subcilliary line. After drawing a continuous line from B-A-C (a black line), an incision is made using a blade (no. 15). Then, submuscular dissection is performed under the slashed red area (right).

FIGURE 2
The skin flap was pulled to medial nose and point A was shifted medially (upper column). A shifted point became point A'. Point B' was marked on a line connecting BA with distance of 2.0 to 2.5 mm from point B (lower column).