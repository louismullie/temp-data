# Medical Question & Answer

**Sample ID**: e48a9531-66fc-4dbf-b8e4-5c6d5a6524d2
**Dataset Index**: 305218

---

## Question

## Task 6

Calculate the products $8 \cdot 93$ and $9 \cdot 82$.

Determine the numbers that lie between the two products. Add these numbers.

---

## Answer

> Let's see… What do we have here? The user is asking me to calculate the products 8 × 93 and 9 × 82, identify the integers between them, and then sum those integers. Let's break this down step-by-step. First, I need to think about the exact values of the two products. Then, I should verify which product is smaller and which is larger to define the interval correctly. Next, I will list the integers strictly between the two products. Finally, I will add those integers and double-check my arithmetic to ensure accuracy.

> Let me first confirm the products. 8 × 93 equals 744, and 9 × 82 equals 738, so the two products are 744 and 738 respectively. Wait, let me verify the order before I proceed: 738 is indeed less than 744, so the interval of interest is from 739 to 743 inclusive, which are the integers strictly between 738 and 744 [^notfound].

> I will now examine the integers between the two products. The numbers that lie strictly between 738 and 744 are 739, 740, 741, 742, and 743. Hold on, I should verify that I'm not including the endpoints; yes, "between" means strictly greater than the smaller product and strictly less than the larger product, so the endpoints 738 and 744 are excluded from the list.

> Next, I should add these integers. Let me calculate: 739 + 740 + 741 + 742 + 743. I can pair them to simplify: (739 + 743) = 1482, and (740 + 742) = 1482, plus 741, which totals 1482 + 1482 + 741 = 3705. Hmm, wait a minute, I initially thought the sum might be 3704, but that would be off by 1; the correct sum is 3705, which I just confirmed by direct addition and by pairing.

> Final answer: The sum of the numbers between 8 × 93 and 9 × 82 is 3705.

---

The two products are (8 \\times 93 = 744) and (9 \\times 82 = 738). The numbers between 738 and 744 are 739, 740, 741, 742, and 743. Their sum is (739 + 740 + 741 + 742 + 743 = 3705).

---

## Calculation of the products

First, calculate the two products:

- (8 \\times 93 = 744)
- (9 \\times 82 = 738)

---

## Identification of numbers between the products

The numbers between 738 and 744 are the integers strictly greater than 738 and strictly less than 744:

- 739
- 740
- 741
- 742
- 743

---

## Sum of the numbers between the products

Add these integers:

[
739 + 740 + 741 + 742 + 743 = 3705
]

---

The sum of the numbers between (8 \\times 93) and (9 \\times 82) is **3705**.

---

## References

### A comes before B, like 1 comes before 2. is the parietal cortex sensitive to ordinal relationships in both numbers and letters? An fMRI-adaptation study [^3b855942]. Human Brain Mapping (2020). Medium credibility.

Accuracy was near ceiling for both the letter and number ordinality‐training task (Table 8). Therefore, reaction time data analyses included only correct trials. To examine the effect of distance on the reaction time data, distance effects were calculated using the numerical distance between the presented symbol and the standard symbol (5 or E depending on number or letter condition) for each participant. For this purpose, we used a regression analysis with distance (1, 2, and 3) as a predictor to estimate an individual distance effect for every subject (De Smedt, Verschaffel, & Ghesquière, 2009; Sasanguie, Smedt, Defever, & Reynvoet, 2012; Vanbinst, Ghesquiere, & De Smedt, 2012). The regression slope is an indicator of the size of the distance effect; the larger the regression slope value, the greater the size of the distance effect (Table 9). These standardized regression slopes were then tested against 0 with a one‐sample t test to determine whether a significant distance effect was present. Participants in both the number and letter groups demonstrated a negative slope; indicative of decreased reaction time as a function of increasing numerical distance between the presented symbol and the standard in all four runs, in the letter, t Run1 (89) = −11.50, p < .001.; t Run2 (89) = −9.44, p < .001; t Run3 (87) = −8.00, p < .001; t Run4 (87) = −7.83, p < .001 and number group, t Run1 (91) = −16.93, p < .001.; t Run2 (90) = −15.82, p < .001; t Run3 (91) = −13.66, p < .001; t Run4 (91) = −15.90, p < .001. This decrease in reaction time for larger numerical distances can be visualized in the average reaction time across the three distances (Figure 6).

---

### Primary and secondary prevention of cardiovascular disease: antithrombotic therapy and prevention of thrombosis, 9th ed: American College of Chest Physicians evidence-based clinical practice guidelines [^28ac07eb]. Chest (2012). Medium credibility.

Framingham risk score for cardiovascular events — calculator for men outlines a point-based process in which the number of points for each risk factor is determined in steps 1 through 6, summed in step 7, and the point total is then used in step 8 to find the corresponding 10-year coronary heart disease (CHD) risk using the low-density lipoprotein cholesterol (LDL-C) or cholesterol column selected in step 2. The figure defines CHD, high-density lipoprotein cholesterol (HDL-C), and LDL-C terminology and indicates that a calculator for women appears on the next page. The text also notes that the Framingham risk score does not allow separate calculation of nonfatal and fatal MI and does not include stroke or major extracranial bleeding.

---

### Quantifying the unknown impact of segmentation uncertainty on image-based simulations [^9ef4f637]. Nature Communications (2021). High credibility.

To help further illustrate this critical result, the region between the (μ + σ)- and (μ − σ)-percentile segmentation ratio curves are shaded dark gray and the region between the 10- and 90-percentile segmentation curves is shaded light gray. At the ratio peak, the behavior is intuitive (i.e. monotonic) with the shaded regions enveloping all their respective curves. However, later in time, the ratio gradually becomes increasingly non-monotonic with percentile segmentation. At t = 7.8 s the 10- and 90-percentile segmentation ratios fail to bound other percentile segmentation ratios and ultimately intersect each other moments later. Moreover, each ratio becomes progressively intertwined with others, such that it becomes difficult to predict how a new percentile segmentation ratio calculation would fall on this graph.

The δ τ curves portrayed in Fig. 5 h emphasize the caution required in bounding segmentation uncertainty using only a few simulations. In the first two exemplars, the results are monotonic with increasing percentile segmentations, and the approximation of the uncertainty distribution using a CDF is representative. However, that does not have to be the case with more complicated models. For example, simply using (μ ± σ)-percentile segmentations to bound the segmentation uncertainty not only fails to encompass all of the intermediate percentile values, it also fails to capture the mean behavior. While this does not invalidate our approach to segmentation uncertainty quantification, it does urge caution in blindly performing simulations for only the standard segmentations for a new exemplar without first checking more intermediate segmentations.

---

### Structure and inference in annotated networks [^005e543f]. Nature Communications (2016). Medium credibility.

Putting it all together, our expression for the log-likelihood is

Neglecting terms beyond first order in small quantities, the first sum can be rewritten as

where we have made use ofand.

The first two terms in (13) are constant for any given network and hence can be neglected — they are irrelevant for comparing the likelihood values between different runs on the same network. The final term can be rewritten using equation (8) as

which is also a constant and can be neglected. Thus, only the third term in (13) need be carried over.

The second sum in (12) is

where we have used equation (8) again in the third equality.

The final sum in (12) is the entropy of the posterior distribution q (s), which is harder to calculate because it requires not just the marginals of q but the entire distribution. We get around this by making the so-called Bethe approximation:

which is exact on trees and locally tree-like networks, and is considered to be a good working approximation on other networks. Substituting this form into the entropy term gives

Finally, combining equations (13)–(17), and substituting into equation (12), our complete expression for the log-likelihood, neglecting constants, is

The run that returns the largest value of this quantity is the run with the highest likelihood and hence the best fit to the model.

---

### Quantum algorithmic measurement [^618274ff]. Nature Communications (2022). High credibility.

QUALM complexity

Having defined tasks and QUALMs, we now turn to defining QUALM complexity.

Definition 10 (Gate complexity, query complexity, and QUALM complexity). The gate complexity of a given QUALM over the admissible set of gatesis the length (i.e. the number of symbols from) of the sequence, minus the number of □ symbols. We denote this by GateComplexity[QUALM], and call this the QUALM gate complexity. Similarly, the query complexity is the number of □'s appearing in, and this is denoted by QueryComplexity[QUALM]. This is called the QUALM query complexity. We call the sumthe QUALM complexity.

The exact (respectively, approximate) QUALM complexity of a task is given by the QUALM with least QUALM complexity, which achieves the task exactly (respectively, approximately).

We also note that it might be relevant, in various situations, to weight gates versus query calls differently, namely to consider the QUALM complexity to befor some suitable penalty factor λ.

As usual in computational complexity, one is interested in families of tasks and QUALMs, where some parameter dictating the size of the problem grows to infinity, and we ask how the complexity grows as a function of that parameter.

---

### History… [^57e99693]. FDA (2025). Medium credibility.

We took plastic polyethylene beads and then chemically linked enzymes to it. And we could screen drugs by washing the drugs through a column of this immobilized enzyme to see where it bound and where it didn't. It was a fascinating idea, and it turned out to be interesting work. RT: Now, was that — according to some information you have provided — about in the period of 1980 to '83. JES: That's right, that's right.
8. drug law, you know, basic, advanced, they've got some specialized classes. I've taught some of them. I find it fascinating how much better we've gotten than we used to be. RT: Just to kind of put in perspective where you were. JES: that the formulation can be reproducibly manufactured and delivered, and there's no guiding principle other than good science. There are requirements for the numbers of studies, the types of things that have to be submitted. But the ultimate approval of a drug requires scientific judgment by people like us. And I find that fascinating.

Not too many regulatory agencies where you see that.
16. United States, in the various European countries and Canada, in Asia, and what one of the interesting things was, was the science of the formulation. Why did we approve the formulation we approved here, and how did it compare to some of the others. So we did an awful lot of formulation comparison. The requirements for dissolution testing of. be attributable to what you give the patient. In Europe, you assume that the first drug you're comparing it to has the same effect, and if it doesn't, it's difficult to interpret. So I think there's room for both, and I think it's something that we're hashing out right now as we speak.
19. element of history of drug regulation. JES: That's right, that's absolutely right. And I'm not going to discuss the ethics of it, but I'll discuss the science of it. If I were testing an oncology product, that is, a cytotoxic agent, would I want to.

---

### Too many digits: the presentation of numerical data [^a41454ae]. Archives of Disease in Childhood (2015). Low credibility.

Thus a decimal places rule that ignores significant digits does not work. But equally, and perhaps surprisingly, a significant digits rule that ignores decimal places does not always work either. Reporting risk ratios to three significant digits for example leads to the largest ratio below 1 being reported as 0.999 and the smallest above 1 as 1.01, with three and two decimal places, respectively. This is clearly unsatisfactory as they differ in precision by a factor of ten. In this instance a combination of significant digits and decimal places, the rule of four, works best: round the risk ratio to two significant digits if the leading non-zero digit is four or more, otherwise round to three.

The rule of four gives three decimal places for risk ratios from 0.040 to 0.399, two from 0.40 to 3.99 and one from 4.0 to 39.9. Applying it to the example of 22.68 above gives 22.7 (95% CI 7.5 to 74). Alternatively one can apply the rule with one less significant digit, giving 23 with CI 8 to 70.

Another example is the reporting of test statistics such as t or F. Specifying one decimal place would permit say t = 30.1, where 30 is clearly sufficient as it is so highly significant. Conversely specifying two significant digits would permit t = −0.13, where again the extra precision is irrelevant as it is far from significant. A suitable rule specifies up to one decimal place and up to two significant digits.

When comparing group means or percentages in tables, rounding should not blur the differences between them. This is the basis for the Hopkins two digits rule, whereby the mean has enough decimal places to ensure two significant digits for the SD. An analogous rule for percentages might be to use enough decimal places to ensure two significant digits for the range of values across groups, eg, if the range is 10% or more use whole numbers, if less than 1% use two decimal places, and otherwise one. In practice percentages are usually given along with their corresponding frequencies, so precision is less critical as the exact values can be calculated.

---

### Why population attributable fractions can sum to more than one [^48796442]. American Journal of Preventive Medicine (2004). Low credibility.

Background

Population attributable fractions (PAFs) are useful for estimating the proportion of disease cases that could be prevented if risk factors were reduced or eliminated. For diseases with multiple risk factors, PAFs of individual risk factors can sum to more than 1, a result suggesting the impossible situation in which more than 100% of cases are preventable.

Methods

A hypothetical example in which risk factors for a disease were eliminated in different sequences was analyzed to show why PAFs can sum to more than 1.

Results

PAF estimates assume each risk factor is the first to be eliminated, thereby describing mutually exclusive scenarios that are illogical to sum, except under special circumstances. PAFs can sum to more than 1 because some individuals with more than one risk factor can have disease prevented in more than one way, and the prevented cases of these individuals could be counted more than once. Upper and lower limits of sequential attributable fractions (SAFs) can be calculated to describe the maximum and minimum proportions of the original number of disease cases that would be prevented if a particular risk factor were eliminated.

Conclusions

Improved descriptions of the assumptions that underlie the PAF calculations, use of SAF limits, or multivariable PAFs would help avoid unrealistic estimates of the disease burden that would be prevented after resources are expended to reduce or eliminate multiple risk factors.

---

### Guidelines for foodborne disease outbreak response. 2nd ed [^fa40728e]. CDC (2014). Medium credibility.

CIFOR performance indicator — outbreak clinical specimen collections — defines the metric as the "Number and % of outbreak investigations with clinical specimens collected and submitted to PHL from two or more people" and defines a foodborne illness outbreak as "The occurrence of two or more similar illnesses resulting from ingestion of a common food". Measurement methods state to "Determine the number of foodborne illness outbreaks that were investigated" for the denominator and to "Determine the number of outbreaks for which clinical specimens were collected and submitted to the PHL from two or more people" for the numerator, then "Divide the numerator by the denominator and multiply by 100". The performance fields label "Denominator (No. outbreaks) = ", "Numerator (No. outbreaks with clinical specimens collected) = " and compute "Rate (Num./Denom. x 100) = ". Feasibility notes that "This metric is associated with CIFOR Indicator 8.2.4 "Foodborne outbreaks investigated". It extends FoodCORE metrics to investigations for all pathogens".

---

### Developing a clinical prediction score: comparing prediction accuracy of integer scores to statistical regression models [^91dd14ad]. Anesthesia and Analgesia (2021). Medium credibility.

Researchers often convert prediction tools built on statistical regression models into integer scores and risk classification systems in the name of simplicity. However, this workflow discards useful information and reduces prediction accuracy. We, therefore, investigated the impact on prediction accuracy when researchers simplify a regression model into an integer score using a simulation study and an example clinical data set. Simulated independent training and test sets (n = 1000) were randomly generated such that a logistic regression model would perform at a specified target area under the receiver operating characteristic curve (AUC) of 0.7, 0.8, or 0.9. After fitting a logistic regression with continuous covariates to each data set, continuous variables were dichotomized using data-dependent cut points. A logistic regression was refit, and the coefficients were scaled and rounded to create an integer score. A risk classification system was built by stratifying integer scores into low-, intermediate-, and high-risk tertiles. Discrimination and calibration were assessed by calculating the AUC and index of prediction accuracy (IPA) for each model. The optimism in performance between the training set and test set was calculated for both AUC and IPA. The logistic regression model using the continuous form of covariates outperformed all other models. In the simulation study, converting the logistic regression model to an integer score and subsequent risk classification system incurred an average decrease of 0.057–0.094 in AUC, and an absolute 6.2%-17.5% in IPA. The largest decrease in both AUC and IPA occurred in the dichotomization step. The dichotomization and risk stratification steps also increased the optimism of the resulting models, such that they appeared to be able to predict better than they actually would on new data. In the clinical data set, converting the logistic regression with continuous covariates to an integer score incurred a decrease in externally validated AUC of 0.06 and a decrease in externally validated IPA of 13%. Converting a regression model to an integer score decreases model performance considerably. Therefore, we recommend developing a regression model that incorporates all available information to make the most accurate predictions possible, and using the unaltered regression model when making predictions for individual patients. In all cases, researchers should be mindful that they correctly validate the specific model that is intended for clinical use.

---

### Massive yet grossly underestimated global costs of invasive insects [^7df964c3]. Nature Communications (2016). Medium credibility.

Removing potential double counts

We made every effort to eliminate redundant amounts from the monetary values we used to estimate cost sums. First, we removed values that were obvious re-estimates of older values (with the more recent estimates tending to be more reproducible than older ones; for example, Supplementary Data 1, column E). We further separated costs into 'extrapolation' versus 'actual estimate' categories (columns G and H in Supplementary Data 1, respectively). Further removing those estimates already deemed irreproducible (column F), column I indicates with absolute certainty which estimates should be retained to avoid any potential case of double counting (that is, species with reproducible estimates that do not include both extrapolated and actual estimates).

The sum of estimates in column I ($22,629,029,314) versus our sum of the total costs (US$25,166,603,981) reported in the main text is only 10.1%, which suggest that even in the unlikely case of double counting, the bias is minimal, and well within the margin of error expected for a sum of median cost rates across the globe. It is essential to note that even if a species includes both extrapolations and actual values, it does not necessarily equate to double counting because often the different estimates apply to different regions of the insect's distribution or different economic components of their costs. However, this does not exclude the possibility of double counting within the irreproducible category, simply because we cannot verify how the estimates were derived to check for instances of potential double counting.

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^e283a86a]. Circulation (2014). Medium credibility.

Quality of Health Economic Studies (QHES) instrument — example scoring and content are shown, with item 1 ("Was the study objective presented in a clear, specific, and measurable manner?") assigned 7, item 8 requiring discounting of benefits and costs that go beyond 1 year "(3% to 5%)" and assigned 7, and item 16 on funding disclosure assigned 3; the instrument totals "TOTAL POINTS 100".

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^2d4b1f9d]. Journal of the American College of Cardiology (2014). Medium credibility.

Quality of Health Economic Studies (QHES) instrument — scoring items and total are specified as follows: The instrument assigns fixed points to each question with a stated TOTAL POINTS 100; examples include item 1 "Was the study objective presented in a clear, specific, and measurable manner?" (7 points), item 5 "Was uncertainty handled by (1) statistical analysis to address random events, (2) sensitivity analysis to cover a range of assumptions?" (9 points), item 8 requiring benefits and costs beyond 1 year be "discounted (3% to 5%)" (7 points), and item 16 "Was there a statement disclosing the source of funding for the study?" (3 points).

---

### Number needed to treat (or harm) [^d0b683ae]. World Journal of Surgery (2005). Low credibility.

The effect of a treatment versus controls may be expressed in relative or absolute terms. For rational decision-making, absolute measures are more meaningful. The number needed to treat, the reciprocal of the absolute risk reduction, is a powerful estimate of the effect of a treatment. It is particularly useful because it takes into account the underlying risk (what would happen without the intervention?). The number needed to treat tells us not only whether a treatment works but how well it works. Thus, it informs health care professionals about the effort needed to achieve a particular outcome. A number needed to treat should be accompanied by information about the experimental intervention, the control intervention against which the experimental intervention has been tested, the length of the observation period, the underlying risk of the study population, and an exact definition of the endpoint. A 95% confidence interval around the point estimate should be calculated. An isolated number needed to treat is rarely appropriate to summarize the usefulness of an intervention; multiple numbers needed to treat for benefit and harm are more helpful. Absolute risk reduction and number needed to treat should become standard summary estimates in randomized controlled trials.

---

### Using the number needed to treat in clinical practice [^646ae153]. Archives of Physical Medicine and Rehabilitation (2004). Low credibility.

The number needed to treat (NNT) is gaining attention as a method of reporting the results of clinical trails with dichotomous outcome measures. The NNT is defined as the number of patients who would need to be treated, on average, with a specific intervention to prevent 1 additional bad outcome or to achieve 1 desirable outcome in a given time period. Because it reports outcomes in terms of patient numbers, it is extremely useful to clinicians for making decisions about the effort expended with a particular intervention to achieve a single positive outcome. This special communication describes the NNT statistic and its utility for choosing clinical interventions.

---

### Selecting fitted models under epistemic uncertainty using a stochastic process on quantile functions [^7bce234b]. Nature Communications (2025). High credibility.

Fig. 4
Loss PPF for different models.

Each column corresponds to a different model. The PPF (percent point function; bottom row) is the inverse of the CDF (cumulative density function; top row). For calculations we interpolate 2 10 = 1024 points (cyan line) to obtain a smooth function; for illustration purposes here only 30 points are shown. The data for the first two columns were generated with the neuron model described at the top of our Results, where the additive noise follows either a Gaussian or Cauchy distribution. The black body radiation data for the third column were generated from a Poisson distribution using equation (38) with s = 2 14 and λ in the range 6 μ m to 20 μ m. Here the true noise is binomial, but the loss assumes a Gaussian. The fourth column shows an example where the data are high-dimensional; the same 30 dimensional, unit variance, isotropic Gaussian is used for both generating the data and evaluating the loss. In all panels the loss function used is the log likelihood under the model.

Since by construction, the abscissae Φ of an empirical PPF are spaced at intervals of 1/ L, the Riemann sum for the integral in equation (20) reduces to the sample average. More importantly, we can interpret the risk as a functional in, which will allow us below to define a generic stochastic process that accounts for epistemic uncertainty.

Up to this point with equation (20) we have simply rewritten the usual definition of the risk. Recall now that in the previous section, we proposed to equate replication uncertainty with misspecification; specifically we are interested in how differences between the candidate modeland the true data-generating processaffect the loss PPF, since this determines the risk. Therefore we also compute the PPF ofunder its own model (recall from equation (1) thatmust be a probabilistic model):from which we obtain the synthetic PPF :The only difference betweenandis the use ofinstead ofin the integral. In practice this integral would also be evaluated by sampling, usingto generate a datasetwith L synth, A samples. Because in this case the candidate model is used for both generating samples and defining the loss, we call the synthetic PPF (CDF).

---

### A DNA-based system for selecting and displaying the combined result of two input variables [^afa284ca]. Nature Communications (2015). Medium credibility.

Oligonucleotide-based technologies for biosensing or bio-regulation produce huge amounts of rich high-dimensional information. There is a consequent need for flexible means to combine diverse pieces of such information to form useful derivative outputs, and to display those immediately. Here we demonstrate this capability in a DNA-based system that takes two input numbers, represented in DNA strands, and returns the result of their multiplication, writing this as a number in a display. Unlike a conventional calculator, this system operates by selecting the result from a library of solutions rather than through logic operations. The multiplicative example demonstrated here illustrates a much more general capability — to generate a unique output for any distinct pair of DNA inputs. The system thereby functions as a lookup table and could be a key component in future, more powerful data-processing systems for diagnostics and sensing.

---

### Guidelines for foodborne disease outbreak response. 2nd ed [^bec32442]. CDC (2014). Medium credibility.

CIFOR performance indicator — Outbreak etiology reported to the National Outbreak Reporting System (NORS) defines the metric as the "Number and % of outbreaks for which etiology was identified and reported to NORS". Measurement methods specify to "Determine the number of foodborne outbreaks that were investigated" as the denominator, to "Determine the number of outbreaks for which an etiology was identified and reported to NORS" as the numerator, and to "Divide the numerator by the denominator and multiply by 100". Definitions include "Foodborne illness outbreak: The occurrence of two or more similar illnesses resulting from ingestion of a common food", and criteria for "Etiology identified" in which "CDC considers an outbreak to have a confirmed etiology if there are two or more lab-confirmed cases", with suspicion possible based on clinical symptom combinations, incubation periods, and duration of illness; the NORS form is described as "National Outbreak Reporting System, Foodborne Disease Outbreaks and Enteric Disease Outbreaks Transmitted by Contact with Persons, Animals, or Environmental Sources, or by an Unknown Mode; NORS Form (CDC 52.13 Form)". Feasibility notes that the metric is associated with "CIFOR Indicator 8.3.1 'Etiology of outbreak identified'. The performance section provides fields for "Denominator (No. outbreaks)", "Numerator (No. with etiology reported to NORS)", and "Rate (Num./Denom. x 100)".

---

### Clinical trials must cope better with multiplicity [^cfdf5a88]. Nature Medicine (2012). Excellent credibility.

Clinical trials typically address more than one question. But in attempting to protect against misleading results that are due to chance when multiple interrelated tests are run simultaneously, researchers sometimes apply overly strict statistical devices that mask true effects. They should give more consideration to choosing the type of statistical analysis that fits best.

---

### Guidelines for foodborne disease outbreak response. 2nd ed [^f641ae22]. CDC (2014). Medium credibility.

CIFOR performance indicator — Outbreak contributing factor reported to NORS (National Outbreak Reporting System) defines the metric as the "Number and % of outbreaks for which contributing factors were identified and reported to NORS". Measurement methods specify determining the number of investigated foodborne outbreaks as the denominator, the number with a contributing factor identified and reported to NORS as the numerator, and to "Divide the numerator by the denominator and multiply by 100". Definitions include "Foodborne illness outbreak: The occurrence of two or more similar illnesses resulting from ingestion of a common food" and "Contributing factors (CFs) are defined as the food safety practices and behaviors which most likely contributed to a foodborne illness outbreak", with the caution that "A CF should be identified only if the investigator has strong evidence that it actually occurred in the investigated outbreak; just because a factor has been cited in similar outbreaks in the past does not mean it was involved in the investigated outbreak". The feasibility note links this measure to "CIFOR Indicator 8.3.3 "Contributing factor identified".

---

### Approaches to analyzing comparative use human factors… [^d5d64941]. FDA (2025). Medium credibility.

fda. gov/cdersbia 4 Current Use of CUHF Studies to Support Other Design Differences. product through the noninferiority test in CUHF studies as discussed in the draft guidance: Step 1
- Determine the allowable margin by which ERT could exceed ERR. Step 2
- Estimate the study sample size considering assumed error rates and d. Step 3
- Observe error rates for the critical task during the CUHF experiments. Step 4
- Perform the NI hypothesis test. H0: ERT
- **ERR > d HA**: ERT
- ERR ≤ d. fda. gov/cdersbia 7 NI test for CUHF studies Step 1 Determine the allowable margin by which ERT could exceed ERR
- The value of d will differ between products, depending on the indication and the clinical consequences associated with failing to perform the critical tasks appropriately.
- The acceptable d should be decided in consultation with the FDA before the study is conducted. fda.

gov/cdersbia 8 NI test for CUHF studies Step 2 Calculate the study sample size considering assumed error rates and d
- The draft guidance provides an example using the Tango method to calculate some power simulations given selected sample sizes with α = 0. 05 and an allowable margin = 0.
10. fda. gov/cdersbia 10 Observe error rates for the critical task during the experiment.
- Definition of critical tasks
- Observe error/success results of subjects for each critical task NI test for CUHF studies Step 3. fda. gov/cdersbia 11 Perform the NI hypothesis test.
- Compare the upper bound of the CI for the difference of error rates between T and R to d.
- If α = 0. 05 and the upper bound of 95% CI is less than d, H0 is rejected and NI is demonstrated. NI test for CUHF studies Step 4 H0: ERT
- **ERR > d HA**: ERT
- ERR ≤ d. Questions. Jing Wang, Ph. D. Staff Fellow, Division of Quantitative Methods and Modeling Office of Research and Standards, Office of Generic Drugs CDER | U. S.

FDA jing. wang1@fda. hhs. gov.

---

### Number needed to treat and number needed to harm are not the best way to report and assess the results of randomised clinical trials [^f243221a]. British Journal of Haematology (2009). Low credibility.

The inverse of the difference between rates, called the 'number needed to treat' (NNT), was suggested 20 years ago as a good way to present the results of comparisons of success or failure under different therapies. Such comparisons usually arise in randomised controlled trials and meta-analysis. This article reviews the claims made about this statistic, and the problems associated with it. Methods that have been proposed for confidence intervals are evaluated, and shown to be erroneous. We suggest that giving the baseline risk, and the difference in success or event rates, the 'absolute risk reduction', is preferable to the number needed to treat, for both theoretical and practical reasons.

---

### Correction for multiple testing: is there a resolution? [^d7fc83b5]. Chest (2011). Low credibility.

In most studies, many statistical tests are performed. They can be run to compare the groups at baseline, look at relationships among the various measures, and, for intervention trials, examine more than one end point. As the number of tests increases, so does the probability of finding at least one of them to be statistically significant just by chance (the problem of multiplicity). A number of procedures have been developed to deal with multiplicity, such as the Bonferroni correction, but there is continuing controversy regarding if and when these procedures should be used. In this article, we offer recommendations about when they should and should not be brought into play.

---

### "Binary" and "non-binary" detection tasks: are current performance measures optimal? [^8d7e974c]. Academic Radiology (2007). Low credibility.

We have observed that a very large fraction of responses for several detection tasks during the performance of observer studies are in the extreme ranges of lower than 11% or higher than 89% regardless of the actual presence or absence of the abnormality in question or its subjectively rated "subtleness". This observation raises questions regarding the validity and appropriateness of using multicategory rating scales for such detection tasks. Monte Carlo simulation of binary and multicategory ratings for these tasks demonstrate that the use of the former (binary) often results in a less biased and more precise summary index and hence may lead to a higher statistical power for determining differences between modalities.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^c734ee06]. Journal of the American College of Cardiology (2025). High credibility.

ACC/AHA economic value statement templates — three formats and threshold — are specified as follows: The examples define key terms and use a cost-effectiveness threshold of $120 000 per QALY gained; Format 1 asks "What is the cost-effectiveness of the intervention at its current cost?" and may include "an ICER of $i per QALY gained (< $120 000 per QALY gained in p% of probabilistic simulations)"; Format 2 asks "What would the cost of the intervention have to be in order for the intervention to meet the cost-effectiveness threshold?" and states the strategy is cost-effective "at a threshold of $120 000 per QALY gained if the cost of the (intervention) is less than $t"; Format 3 combines both questions; ICER (incremental cost-effectiveness ratio) and QALY (quality-adjusted life year) abbreviations are defined on-page.

---

### 2022 AHA / ACC key data elements and definitions for cardiovascular and noncardiovascular complications of COVID-19: a report of the American college of cardiology / American Heart Association task force on clinical data standards [^7c00ac0e]. Journal of the American College of Cardiology (2022). High credibility.

Maximum fraction of inspired oxygen (FiO2) is defined as the maximum molar fraction of oxygen in an inhaled gas, with permissible value type Numeric.

---

### Summary benchmarks-full set – 2024 [^c9abe316]. AAO (2024). High credibility.

Preferred Practice Pattern (PPP) guidelines — GRADE evidence quality ratings are defined for forming recommendations for care as follows: "Good quality (GQ): Further research is very unlikely to change our confidence in the estimate of effect", "Moderate quality (MQ): Further research is likely to have an important impact on our confidence in the estimate of effect and may change the estimate", and "Insufficient quality (IQ): Further research is very likely to have an important impact on our confidence in the estimate of effect and is likely to change the estimate; any estimate of effect is very uncertain".

---

### An official American Thoracic Society workshop report: developing performance measures from clinical practice guidelines [^369e6d46]. Annals of the American Thoracic Society (2014). Medium credibility.

Agency for Healthcare Research and Quality performance measure attributes — Desirable features of performance measures include relevance to stakeholders and addressing important aspects of health, with evidence of a need for the measure; evidence should be explicitly stated, results should be reproducible and truly measure what they purport to measure, and specifications should explicitly define the numerator and denominator with understandable data collection requirements; necessary data sources should be available within the measurement timeframe and data collection costs justified by potential improvement in care or health.

---

### Guidelines for foodborne disease outbreak response. 2nd ed [^82234c6a]. CDC (2014). Medium credibility.

CIFOR performance measure — cluster source identification defines the metric as the "Number and % of clusters with more than five cases in which a source was identified". A cluster is defined as "Two or more isolates with a matching molecular subtype pattern identified in a period of two weeks". "Cluster source identification" is "The number of identified clusters for which a specific food transmission setting, meal, food item or ingredient was identified, leading the cluster to be considered an outbreak". Measurement methods state to "Determine the number of clusters that include five or more cases. This will be the denominator for the metric", and to "Determine the number of clusters for which a source was identified that include five or more cases. This will be the numerator for the metric", then "Divide the numerator by the denominator and multiply by 100". The performance section specifies Denominator "No. clusters with ≥ 5 cases", Numerator "No. clusters with ≥ 5 cases with source identified", and Rate "Num./Denom. x 100". This metric is linked to "CIFOR Indicator 8.2.5 'Case clusters investigated'.

---

### Whole-genome sequencing to understand the genetic architecture of common gene expression and biomarker phenotypes [^6bd27bdd]. Human Molecular Genetics (2015). Low credibility.

Calculating statistical thresholds for association analyses

For cis -eQTLs analyses there were a total of 9 187 579 analyzable variants (MAC ≥ 4 and imputation r 2 > 0.7) that fell within 11 132 2 Mb windows around each of the gene expression probes. Given the estimated number of independent variants within a 2 Mb region was 2848 we calculated 2848 × 11 122 gene expression phenotypes = 31 675 456 independent tests. A P -value of 1.6 × 10 −9 provides a Bonferroni corrected P -value of 0.05 and a P -value of ∼1 × 10 −06 provides a false-discovery rate of ∼5% given the number of cis -eQTLs we identified at that threshold (1314).

For the 93 circulating biomarkers we first estimated the number of independent variants across the whole genome by multiplying the number of independent (r 2 < 0.8) variants in a 2 Mb window, 2848, by the approximate number of 2 Mb windows, 1500 = 4 272 000. We multiplied this number by number of circulating biomarkers we were testing to give a total of 397 296 000 independent tests. A P -value of 8 × 10 −10 provides a Bonferroni corrected P -value of 0.05.

---

### Guidelines for foodborne disease outbreak response. 2nd ed [^355cc092]. CDC (2014). Medium credibility.

CIFOR performance indicators — outbreaks detected from complaints — define a metric and standardized rate for surveillance based on complaint data. The metric counts "Number outbreaks detected as a result of foodborne illness complaints" and calculates the "Rate of outbreaks detected per 1,000 complaints received". Measurement methods specify to "Determine the number of foodborne illness complaints that were received during the year. This will be the denominator for the metric", and to "Determine the number of foodborne illness outbreaks that were detected as a result of a foodborne illness complaint investigation during the year. This will be the numerator for the metric", then "Divide the numerator by the denominator and multiply by 1,000". Definitions include: "Outbreak detected from a complaint: A foodborne illness outbreak that was detected as a result of a foodborne illness complaint investigation", "Foodborne illness outbreak: The occurrence of two or more similar illnesses resulting from ingestion of a common food", and "Foodborne illness complaint: A report of illness experienced by one or more persons following exposure to a specific event or establishment". Feasibility notes that the metric "is associated with CIFOR Indicator 8.2.1 'Foodborne complaints investigated'" and that it "provides a consistent expectation for the use of complaint data system", enabling comparisons "from year to year" and "across agencies".

---

### Pediatric application of coding and valuation systems [^ab85dde2]. Pediatrics (2019). High credibility.

National drug code (NDC) reporting — manufacturers may use different NDC configurations with variation in the number of digits assigned to each of the 3 segments; to accommodate this, an 11th digit (a leading 0) may be inserted into a segment, and payers request that administered units be appended to NDC codes on claim forms. An example states that in multidose packaging 1 U equates to 1 dose and, if units are specified in milliliters for a 0.5-mL vaccine dose, one would specify 0.5 U rather than 1 U.

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^dcb8e5e6]. Circulation (2014). Medium credibility.

WHO‑CHOICE framework adaptation — The committee anchored value definitions to WHO‑CHOICE thresholds, defining highly cost‑effective as less than GDP per capita, cost‑effective as between 1 and 3 times GDP per capita, and not cost‑effective as > 3 times GDP per capita, and selected the Table 2 values as initial threshold recommendations that may need modification as future information or consensus develops.

---

### Diagnosis and treatment of osteochondritis dissecans [^7f2b7e80]. AAOS (2023). High credibility.

Appendix VIII — Nominal group technique (NGT) voting for guideline recommendations describes the method and thresholds used to adopt recommendations. Each member ranks agreement on a scale ranging from 1 to 9 (where 1 is "extremely inappropriate" and 9 is "extremely appropriate"), and consensus is obtained if the number of individuals who do not rate a measure as 7, 8, or 9 is statistically non-significant (as determined using the binomial distribution). The number of permissible dissenters varies by work group size: ≤ 3 not allowed, statistical significance cannot be obtained; 4–5: 0; 6–8: 1; 9: 1 or 2. The NGT is conducted by first having members vote on a given recommendation without discussion; if the number of dissenters is "permissible", the recommendation is adopted without further discussion, otherwise there is further discussion; Three rounds of voting are held to attempt to resolve disagreements, and if disagreements are not resolved after three voting rounds, no recommendation is adopted.

---

### Expert panel on integrated guidelines for cardiovascular health and risk reduction in children and adolescents: summary report [^3327f722]. Pediatrics (2011). Medium credibility.

Table 5–1 — estimated calorie needs per day by age, gender, and physical activity level provides Calorie Requirements (kcals) by Activity Level at three different levels of physical activity and states that the estimates are rounded to the nearest 200 calories and that an individual's calorie needs may be higher or lower than these average estimates. At age 2–3 years, daily estimates are 1,000–1,200 (sedentary), 1,000–1,400 (moderately active), and 1,000–1,400 (active). For females 9–13 years the values are 1,400–1,600, 1,600–2,000, and 1,800–2,200; for females 14–18 years they are 1,800, 2,000, and 2,400. For males 14–18 years the values are 2,000–2,400, 2,400–2,800, and 2,800–3,200; for males 19–30 years they are 2,400–2,600, 2,600–2,800, and 3,000. Sedentary means a lifestyle that includes only the light physical activity associated with typical day-to-day life, moderately active means a lifestyle that includes physical activity equivalent to walking about 1.5 to 3 miles per day at 3 to 4 miles per hour, and active means a lifestyle that includes physical activity equivalent to walking more than 3 miles per day at 3 to 4 miles per hour, in addition to the light physical activity associated with typical day-to-day life; estimates for females do not include women who are pregnant or breastfeeding.

---

### Recommendations for a standardized pulmonary function report. An official American Thoracic Society technical statement [^d6d8fcbc]. American Journal of Respiratory and Critical Care Medicine (2017). Medium credibility.

Spirometry reporting specifies that numerical values are given for the FEV1, the FVC, and the FEV1/FVC ratio; the latter should be reported as a decimal fraction and the space for percent predicted value left blank, and if bronchodilators are given the LLN column need not be repeated with absolute and percent change given only for FEV1 and FVC. Other numerical values such as the forced inspiratory flow at 75% of FVC (FEF75%) and FEF25–75% are not recommended for routine use. Graph requirements include that for the volume–time curve the volume scale should be at least 10 mm/L, the time scale at least 20 mm/s, and 1 second prior to the start of expiration should be displayed; on the flow–volume plot the flow display should be at least 5 l/min/L/s, and the ratio of flow to volume should be 2 L/s to 1 L, and linear and log scales where values are plotted as z-scores relative to the predicted value (z = 0) give an intuitive sense of severity.

---

### Summary benchmarks-full set – 2024 [^6f68d3ad]. AAO (2024). High credibility.

Preferred Practice Pattern (PPP) guidelines — use and ethics note states that "The PPPs are intended to serve as guides in patient care, with greatest emphasis on technical aspects", that "true medical excellence is achieved only when skills are applied in a such a manner that the patients' needs are the foremost consideration", and that "The Academy is available to assist members in resolving ethical dilemmas that arise in the course of practice".

---

### The CCAS-scale in hereditary ataxias: helpful on the group level, particularly in SCA3, but limited in individual patients [^b257ed16]. Journal of Neurology (2022). Medium credibility.

Total sum score

Patients with SCA3 reached a lower total sum score (90.9 ± 11.4) compared to SCA3 controls (102.0 ± 8.9). Total sum score was also lower in SCA6 patients (93.3 ± 11.9) compared to SCA6 controls (101.3 ± 8.6), and FRDA patients (96.9 ± 8.9) compared to FRDA controls (102.0 ± 7.0). The difference between SCA3 patients and SCA3 controls was significant (MD: − 11.1; CI − 16.3, − 6.1; p < 0.001). Comparisons of FRDA (MD: − 5.0; CI − 10.1, − 0.4; p = 0.051) and SCA6 patients and matched controls (MD: − 8.0; CI − 15.4, − 0.3; p = 0.057; two-sided permutation t test; Fig. 1 B) failed significance.

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^2873c1b8]. Journal of the American College of Cardiology (2014). Medium credibility.

Societal perspective in economic evaluation — costs for medical interventions or programs are counted regardless of payer to avoid mere cost shifting, so all costs should be included irrespective of who pays. This principle emphasizes that redistributing costs across patients, providers, payers, or others does not save money and supports using a societal perspective when assessing value.

---

### A practical guide for understanding confidence intervals and P values [^c0a7d4a0]. Otolaryngology — Head and Neck Surgery (2009). Low credibility.

The 95 percent confidence interval about the mean demarcates the range of values in which the mean would fall if many samples from the universal parent population were taken. In other words, if the same observation, experiment, or trial were done over and over with a different sample of subjects, but with the same characteristics as the original sample, 95 percent of the means from those repeated measures would fall within this range. This gives a measure of how confident we are in the original mean. It tells us not only whether the results are statistically significant because the CI falls totally on one side or the other of the no difference marker (0 if continuous variables; 1 if proportions), but also the actual values so that we might determine if the data seem clinically important. In contrast, the P value tells us only whether the results are statistically significant, without translating that information into values relative to the variable that was measured. Consequently, the CI is a better choice to describe the results of observations, experiments, or trials.

---

### The SNMMI and EANM practice guideline for small-bowel and colon transit 1.0 [^15fa9b54]. Journal of Nuclear Medicine (2013). Medium credibility.

Colon transit scintigraphy — delayed-release capsule geometric center method — calculates the geometric center (GC) as a weighted average across colonic segments, computed as the sum of counts in each region multiplied by the region number divided by total counts; this method assigns numbers from 1 to 5 as weighting factors including activity in defecated stool, and reports reference values of less than 1.4 at 4 h, 1.6–3.8 at 24 h, and 3.0–4.8 at 48 h, with slow colon transit defined as a GC less than these reference values at 24 and 48 h.

---

### The emperor has No platelets: minimal effects in an alopecia split-scalp study unsurprising as platelet-rich plasma was actually platelet-poor [^19b00a71]. Aesthetic Surgery Journal (2022). Medium credibility.

Looking more closely at the study, 2 batches of PRP were used, A and B, representing low and high concentrations, respectively. However, both Batch A and B are described as "4.5 times the baseline platelet concentration of a patient's whole blood". Also, 1-mL aliquots of each batch were sent for CCA. Table 5 shows a very precise relationship between the batches; for both mean and standard deviations, the values for Batch B are exactly double the values for Batch A. This would not be expected if separate samples were measured by CCA. A PIF value of 4.5× still appears on Eclipse's current website, based on "An average of several independent, verified tests" and "Whole Blood Platelets counts of 209 (10 6 /mL)" (Table 2).

Table 2.
Eclipse HC PRP

Important questions arise from the manufacturer's claims. How does the PIF improve from 3.5× to 4.5× simply by using 2 identical tubes, with no other change in protocol? How can the total number of platelets claimed be more than the starting number in whole blood multiplied by the claimed yield (~85%). For the 44-mL kit (2 × 22 mL): total platelets = 0.85 × (44 mL × 209 million/mL) = 7.8 billion < 10 billion claimed; for the 22-mL kit: total platelets = 0.85 × (22 mL × 209 million/mL) = 3.9 billion < 5 billion claimed. To obtain 5 and 10 billion platelets from the 22- and 44-mL kits would require yields of 93% and 123%, respectively. Where do the extra platelets come from?

---

### Imaging-based noninvasive liver disease assessment for staging liver fibrosis in chronic liver disease: a systematic review supporting the AASLD practice guideline [^1809562c]. Hepatology (2025). High credibility.

Primary sclerosing cholangitis (PSC) — transient elastography (TE) performance: Two studies reported TE accuracy. For significant fibrosis (F2-4), a TE-LSM cutoff value of 8.7 kPa yielded a sensitivity of 81%–89% and a specificity of 72%–88%, whereas for advanced fibrosis (F3-4), a cutoff of 9.6 kPa had a sensitivity of 90% and a specificity of 82%–93%.

---

### Contemporary issue: health and safety of female wrestlers [^c2819a17]. Current Sports Medicine Reports (2024). High credibility.

Female wrestlers — body fat distribution and MWW threshold reconsideration shows that even in trained, highly fit female wrestlers body fat values are between 18% and 22% and it is extremely rare that the 12% threshold is approached; from Table 2 data, a sample size weighted mean of 20.3% with a pooled standard deviation of 4.2% in a sample of 326 female wrestlers yields a lower boundary of 17.9% body fat, with 12% clearly falling in the unexpected region. In line with these data, the authors state, "we encourage SGB to reevaluate using 12% fat as the minimum set for all female wrestlers" and that "a value like 18% body fat might be a more reasonable minimum", adding that "If 18% were adopted, 0.82 in the MWW calculation would replace 0.88", and clarifying that "biological females with less than 18% body fat at the time of weight class determination would not be disqualified", although preseason values under 18% would prohibit further reductions to reach a lower class.

---

### The World Health Organization adult attention-deficit / hyperactivity disorder self-report screening scale for DSM-5 [^5fd3b51f]. JAMA Psychiatry (2017). Medium credibility.

Importance

Recognition that adult attention-deficit/hyperactivity disorder (ADHD) is common, seriously impairing, and usually undiagnosed has led to the development of adult ADHD screening scales for use in community, workplace, and primary care settings. However, these scales are all calibrated to DSM-IV criteria, which are narrower than the recently developed DSM-5 criteria.

Objectives

To update for DSM-5 criteria and improve the operating characteristics of the widely used World Health Organization Adult ADHD Self-Report Scale (ASRS) for screening.

Design, Setting, and Participants

Probability subsamples of participants in 2 general population surveys (2001–2003 household survey [n = 119] and 2004–2005 managed care subscriber survey [n = 218]) who completed the full 29-question self-report ASRS, with both subsamples over-sampling ASRS-screened positives, were blindly administered a semistructured research diagnostic interview for DSM-5 adult ADHD. In 2016, the Risk-Calibrated Supersparse Linear Integer Model, a novel machine-learning algorithm designed to create screening scales with optimal integer weights and limited numbers of screening questions, was applied to the pooled data to create a DSM-5 version of the ASRS screening scale. The accuracy of the new scale was then confirmed in an independent 2011–2012 clinical sample of patients seeking evaluation at the New York University Langone Medical Center Adult ADHD Program (NYU Langone) and 2015–2016 primary care controls (n = 300). Data analysis was conducted from April 4, 2016, to September 22, 2016.

Main Outcomes and Measures

The sensitivity, specificity, area under the curve (AUC), and positive predictive value (PPV) of the revised ASRS.

Results

Of the total 637 participants, 44 (37.0%) household survey respondents, 51 (23.4%) managed care respondents, and 173 (57.7%) NYU Langone respondents met DSM-5 criteria for adult ADHD in the semistructured diagnostic interview. Of the respondents who met DSM-5 criteria for adult ADHD, 123 were male (45.9%); mean (SD) age was 33.1 (11.4) years. A 6-question screening scale was found to be optimal in distinguishing cases from noncases in the first 2 samples. Operating characteristics were excellent at the diagnostic threshold in the weighted (to the 8.2% DSM-5/Adult ADHD Clinical Diagnostic Scale population prevalence) data (sensitivity, 91.4%; specificity, 96.0%; AUC, 0.94; PPV, 67.3%). Operating characteristics were similar despite a much higher prevalence (57.7%) when the scale was applied to the NYU Langone clinical sample (sensitivity, 91.9%; specificity, 74.0%; AUC, 0.83; PPV, 82.8%).

Conclusions and Relevance

The new ADHD screening scale is short, easily scored, detects the vast majority of general population cases at a threshold that also has high specificity and PPV, and could be used as a screening tool in specialty treatment settings.

---

### Guidelines for foodborne disease outbreak response. 2nd ed [^d3705f5c]. CDC (2014). Medium credibility.

Performance indicators — CIFOR performance measure: foodborne illness outbreak rate defines the metric as "Number foodborne outbreaks reported, all agents" with the rate expressed as "Rate of outbreaks reported / 1,000,000 population". A "Foodborne illness outbreak" is "The occurrence of two or more similar illnesses resulting from ingestion of a common food", and the "Foodborne illness outbreak rate" is "The number of confirmed foodborne illness outbreaks within a jurisdiction during a year, divided by the population of the jurisdiction x 1,000,000". Measurement methods state to determine the population of the jurisdiction as the denominator, determine the number of foodborne illness outbreaks reported during the year as the numerator, and divide the numerator by the denominator and multiply by 1,000,000 to convert to a standardized rate. Feasibility notes association with CIFOR Indicator 8.2.4 "Foodborne outbreaks investigated", aggregation of FoodCORE metrics for outbreak investigations across all pathogens, and that reporting foodborne outbreaks is part of PHEP Performance Measure 13.3 Outbreak Investigation Reports, enabling comparisons from year to year and across agencies.

---

### Guidelines for foodborne disease outbreak response. 2nd ed [^8b49f77b]. CDC (2014). Medium credibility.

Foodborne disease outbreak response performance indicator — Isolate/CIDT-positive clinical specimen submissions to public health laboratory (PHL) — defines the metric as the number and % of isolates from confirmed cases and clinical specimens from patients diagnosed by culture independent diagnostic test (CIDT) submitted to PHL, with isolate defined as primary isolates of Salmonella, Shiga toxin-producing E. coli (STEC) or Listeria and PHL as the state or local public health laboratory designated to serve as a reference laboratory for confirmation and subtyping. Measurement methods direct programs to determine the number of confirmed cases as the denominator and the number of isolates and clinical specimens submitted to the PHL as the numerator, then divide the numerator by the denominator and multiply by 100 to create a standardized rate, measured and reported separately for confirmed Salmonella, E. coli (STEC), and Listeria cases. Performance labels specify Denominator (No. confirmed cases), Numerator (No. isolates/ CIDT-positive clinical specimens submitted), and Rate (Num./Denom. x 100) for Salmonella, E. coli (STEC), and Listeria, and the feasibility note states the metric is associated with CIFOR Indicator 8.2.3 and is consistent with FoodCORE common metrics for Salmonella, STEC, and Listeria.

---

### What is the lifetime risk of developing cancer? the effect of adjusting for multiple primaries [^af675f3b]. British Journal of Cancer (2011). Low credibility.

Background

The 'lifetime risk' of cancer is generally estimated by combining current incidence rates with current all-cause mortality ('current probability' method) rather than by describing the experience of a birth cohort. As individuals may get more than one type of cancer, what is generally estimated is the average (mean) number of cancers over a lifetime. This is not the same as the probability of getting cancer.

Methods

We describe a method for estimating lifetime risk that corrects for the inclusion of multiple primary cancers in the incidence rates routinely published by cancer registries. The new method applies cancer incidence rates to the estimated probability of being alive without a previous cancer. The new method is illustrated using data from the Scottish Cancer Registry and is compared with 'gold-standard' estimates that use (unpublished) data on first primaries.

Results

The effect of this correction is to make the estimated 'lifetime risk' smaller. The new estimates are extremely similar to those obtained using incidence based on first primaries. The usual 'current probability' method considerably overestimates the lifetime risk of all cancers combined, although the correction for any single cancer site is minimal.

Conclusion

Estimation of the lifetime risk of cancer should either be based on first primaries or should use the new method.

---

### The cost of large numbers of hypothesis tests on power, effect size and sample size [^d03b4141]. Molecular Psychiatry (2012). Low credibility.

A third way to quantify the cost of multiple tests is the increase in sample size needed to maintain the original level of power at the original effect size. If the sample size is increased by a factor m, it has the effect of dividing the standard error by, narrowing the widths of both the null and alternative curves accordingly (Figure 1d). To offset the addition of Δ, the distance between the two curves expressed in terms of the new standard errorfor the larger sample size and H tests should equal the distance expressed in the original standard errorsfor a single test. Thus, m should satisfyor

For two tests, α = 0.05 and 80% power, the sample size should be multiplied by m = 1.2 to maintain the original power at the original effect size. Again, m depends only on H, α and β and not the effect size or original sample size. Note that the sample size multiplier is the square of the effect size multiplier.

More generally, suppose a study design with H tests at unadjusted significance level α and power 1− β is to be compared to a second study design with H* tests at unadjusted significance level α * and power 1− β *, then the detectable effect size for the second design relative to the effect size of the first design iswhere the numbers in the denominator are based on the initial design and the numbers in the numerator are based on the second. Furthermore, a sample size multiplier for the second design relative to the first is given by

Numerical results were calculated using the Normal distribution and expressions (1) and (2) in R. All tests are two tailed and, if not otherwise specified, at significance level α = 0.05. Logs, unless otherwise indicated, are base 10. A Cost of Multiple Tests calculator that implements equations (1)–(4) in Microsoft Excel 2003 for any choices of H, α and β is also provided (Supplementary Table 1).

---

### Health checks for people aged 75 and over… [^62639282]. Occasional Paper (1993). Low credibility.

The clinical calculator "Abbreviated mental test (AMT-10)" for mild cognitive impairment and dementia.

The Abbreviated Mental Test (AMT-10) is a commonly used clinical calculator designed to assess cognitive function in elderly patients. It is particularly useful in identifying cognitive impairment, including conditions such as dementia and delirium. The AMT-10 consists of ten questions that evaluate various aspects of cognitive function, including memory, attention, and orientation.

The AMT-10 is applicable to the elderly population, particularly those in hospital or care home settings, or those presenting with confusion or memory problems. It is a quick and easy tool for healthcare professionals to screen for cognitive impairment and to monitor changes in cognitive function over time.

The clinical utility of the AMT-10 lies in its ability to provide a rapid assessment of a patient's cognitive status. It can help guide further diagnostic testing, inform treatment decisions, and assist in the planning of care.

Exclusion criteria for the AMT-10 include patients who are unable to communicate effectively, such as those with severe hearing or speech impairments, or non-English speakers without an interpreter. It may also be less accurate in patients with high levels of education or intelligence, as they may score well despite having significant cognitive impairment.

The Abbreviated Mental Test (AMT-10) is designed to assess cognitive function through a series of 10 straightforward questions. Each question evaluates an aspect of mental awareness and cognitive recall, with responses marked as either "Correct" or "Incorrect".

The scoring system for the AMT-10 is simple:

- Each correct response earns 1 point.
- Each incorrect response earns 0 points.

The total score, which ranges from 0 to 10, is calculated by summing the scores from all the answers provided.

Here's a breakdown of the questions evaluated:

- **Age**: Correct/Incorrect
- **Time**: Correct/Incorrect
- **Current Year**: Correct/Incorrect
- **Patient's Address**: Correct/Incorrect
- **Date of Birth**: Correct/Incorrect
- **Year the First World War I Started**: Correct/Incorrect
- **Name of Current President**: Correct/Incorrect
- **Count Backwards from 20 to 1**: Correct/Incorrect
- **What Jobs Do These People Do? (based on a picture of a postman or a cook)**: Correct/Incorrect
- **Ask to Repeat the Address Given Earlier**: Correct/Incorrect

After calculating the total score based on these responses, the AMT-10 provides an interpretation of cognitive function:

- A score between 0 and 3 suggests "Severe cognitive impairment".
- A score between 4 and 5 indicates "Moderate cognitive impairment".
- A score between 6 and 10 indicates "No cognitive impairment".

The process involves collecting responses to these questions, scoring them, and using the total score to assess the level of cognitive function. This straightforward approach ensures an effective evaluation using a standardized method.

---

### A summary of the methods that the national clinical guideline centre uses to produce clinical guidelines for the national institute for health and clinical excellence [^17347588]. Annals of Internal Medicine (2011). Medium credibility.

NICE study search and retrieval workflow — Search results undergo a First sift: titles (done by information scientist or systematic reviewer) to exclude studies outside the topic; a Second sift: abstracts (done by systematic reviewer) to exclude studies that are not relevant to the review questions; and Assessment of full articles (done by systematic reviewer) to exclude studies on limits set by the GDG (for example, study design or outcomes), after which studies included proceed for data extraction; because of potential bias or error, a second reviewer performs sampling checks, and usually several thousand titles are sifted at the first stage.

---

### Guidelines for foodborne disease outbreak response. 2nd ed [^ec6a280f]. CDC (2014). Medium credibility.

CIFOR performance indicator — PFGE subtyping of isolates defines the metric as the number and percent of isolates with pulsed-field gel electrophoresis (PFGE) information, with "Isolate" specified as primary isolates of Salmonella, Shiga toxin-producing E. coli (STEC), or Listeria, limited to first or representative isolate or sample for each case. Measurement methods state to determine the number of isolates submitted to the PHL as the denominator and the number of isolates with PFGE information as the numerator, then divide the numerator by the denominator and multiply by 100 to convert to a standardized rate, and to measure and report separately for confirmed Salmonella, E. coli (STEC), and Listeria cases. The table also lists Denominator (No. isolates submitted) and Numerator (No. isolates with PFGE information) for A. Salmonella, B. E. coli (STEC), and C. Listeria, with the rate shown as "Num./Denom. x 100". Feasibility notes associate this with CIFOR Indicator 8.2.3, align it with FoodCORE common metrics for Salmonella, STEC, and Listeria, and state that reporting numbers supports year-to-year comparisons within an agency and reporting rates allow comparisons across agencies.

---

### Rubidium rb 82 (Ruby-fill) [^4f9a790d]. FDA (2020). Medium credibility.

Rubidium Eluate Testing:

The dose calibrator is automatically set for Rb 82 within the Elution System.
The Quality Control test begins by automatically initiating a generator flush using 75 mL of 0.9% Sodium Chloride Injection USP. This eluate is by default diverted towards the waste container and is ultimately discarded.
After the generator flush, the system waits approximately 15.2 minutes to accomplish a complete generator recharge of 12 Rb 82 half-lives
The system then elutes a calibration sample (35 mL of 0.9% Sodium Chloride Injection USP at 20 mL/min). Using the dose calibrator, the system automatically quantifies the activity of Rb 82 in the calibration sample (Rb 82 decay does not need to be corrected for because of a real-time automated measurement).

Strontium Eluate Testing (Strontium Breakthrough):

Using the calibration sample obtained from the Rb 82 eluate testing, the system allows the sample to stand for 30 minutes to allow for the complete decay of Rb 82.
The system measures the activity of the sample to automatically determine the total Sr 82 and Sr 85 activity.
The system automatically determines the ratio (R) on the day (post calibration) of the measurement using the ratio of Sr 85/Sr 82 on the day of calibration provided on the generator label and the Sr 85/Sr 82 ratio factor from the Sr 85/Sr 82 ratio based on generator age using the following equation:

4. The system uses a correction factor (F) of 0.48 to compensate for the contribution of Sr 85 to the reading.

**5. The system calculates the amount of Sr 82 in the sample using the following equation**:

6. The system determines if Sr 82 in the eluate exceeds an Alert or Expiration Limit by dividing the mcCi (or kBq) of Sr 82 by the mCi (or MBq) of Rb 82 at End of Elution (see below for further instructions based on the Sr 82 level)

7. The system determines if Sr 85 in the eluate exceeds an Alert or Expiration Limit by multiplying the result obtained in step 6 by (R) as calculated in step 3 (above).

The system uses Table 1 to calculate the decay factor for Rb 82

*Elution time

The system uses Table 2 to calculate the ratio (R) of Sr 85/Sr 82.

* Day of Calibration.

---

### Measurement of renal volume using respiratory-gated MRI in subjects without known kidney disease: intraobserver, interobserver, and interstudy reproducibility [^7872a374]. European Journal of Radiology (2011). Low credibility.

Objective

Since renal volume is to be considered in managing renal diseases, a reproducible technique is needed. Our aim was to estimate intraobserver, interobserver, and interstudy reproducibility of renal volume measurement in subjects without known kidney disease using magnetic resonance (MR) imaging.

Materials and Methods

We studied 20 patients (age range 33–82 years) without known renal disease using 1.5-T MR imaging with a respiratory-gated two-dimensional coronal balanced steady state free precession sequence. Each patient repeated the study after 1h. Two readers independently segmented the area of both kidneys of the first study, subtracting cysts. After 1 week, the first reader segmented the second study and repeated the segmentation of the first study. The volume of each kidney was obtained by multiplying the renal area on each slice by the slice thickness and summing all the partial volumes. Reproducibility was assessed by Bland-Altman and Wilcoxon statistics. The coefficient of repeatability (CoR) was summed to the absolute value of bias; the ratio between this sum and the mean of the two data sets was used as a measure of variability while its complement to 100% was used as a measure of reproducibility.

Results

Acquisition time was 2–3 min. Segmentation time was 20–25 min. Intraobserver variability results in a CoR of 7 mL and in a reproducibility of 95%, interobserver variability 8.8–9.8 mL and 87–88%, interstudy variability 9.8–10.6 mL and 91–93%, respectively. Considering both the effect of observer and the repetition of the study, the reproducibility was 83–87%.

Conclusion

Renal volume measurement by MR imaging is highly reproducible.

---

### An official multi-society statement: the role of clinical research results in the practice of critical care medicine [^6198cd13]. American Journal of Respiratory and Critical Care Medicine (2012). Medium credibility.

Variability in clinical practice — the weight given to facts and reasons for a clinical decision can differ between clinicians, resulting in variability; factors beyond study design and execution can make clinical research results more compelling and are summarized in Table 2, but no particular clinical study can be expected to satisfy all criteria; when research results are not compelling, clinicians will be more likely to weight experiential or pathophysiologic knowledge more heavily, so clinicians can reasonably come to a different clinical conclusion even when considering the same research; differences may derive from differing professional values and prior knowledge, and making the clinical decision-making process explicit will aid in identifying the sources of variability in practice.

---

### Stereo tests as a screening tool for strabismus: which is the best choice? [^1ff85979]. Clinical Ophthalmology (2014). Low credibility.

The results for positive predictive value (PPV) were 93% (95% CI 82.8–97.7) for Lang I, 74.6% (95% CI 63–83.6) for Lang II, 77.8% (95% CI 66–86.4) for Titmus, and 81% (95% CI 69–89.2) for TNO.

In this study, the NPV was also calculated. Lang I was found to be the most testable (93%, 95% CI 85.3–97) compared to Lang II (88.2%, 95% CI 78.8–93.9), Titmus (87.5%, 95% CI 78.3–93.3), and TNO (85.9%, 95% CI 76.8–91.9).

The authors found Lang I to be the stereo test with higher sensitivity (89.8%), specificity (95.2%), PPV (93%), and NPV (93%). All these results are shown in both Table 1 and Figure 1.

The area under ROC curve analysis revealed a statistically significant superiority of Lang I test in detecting strabismus, including microstrabismus, when compared with all the other tests: 0.92 versus 0.82, 0.83, and 0.83 for Lang I, Lang II, Titmus, and TNO, respectively (P = 0.0001) (Figure 2).

---

### Digital measurement of SARS-CoV-2 transmission risk from 7 million contacts [^dd774ec9]. Nature (2024). Excellent credibility.

Empirical estimation of individuals' probability of testing positive from summary statistics

In general, each contact in our dataset had multiple exposure windows, each of which had a duration (anything up to 30 min) and a risk score. We summarized these data for each contact into metrics including the maximum risk score from any of the windows, the cumulative risk score over all windows and the cumulative duration over all windows. We binned (grouped) contacts by the value of their summary metrics and, within each bin, calculated the fraction of contacts reporting a positive test in the observation interval. Confidence intervals on this fraction were calculated through the associated binomial distribution (defined with the number of 'trials' equal to the group size and the number of 'successes' equal to the number of contacts reporting a positive test). We extrapolated our estimates to risk score 1 (that is, 2 m away from an index case with standard infectiousness for 15 min (indicated by a grey circle in Fig. 1) as a point of comparison) via a quadratic fit. In Figs. 2 and 4 the background risk estimate from the maximum-likelihood approach outlined below was subtracted from the result. In all figures the x coordinate for each bin corresponds to the mean of all scores within the bin.

---

### The minimal work cost of information processing [^927873c9]. Nature Communications (2015). Medium credibility.

Classical mappings and dependence on the logical process

Our result, which is applicable to arbitrary quantum processes, applies to all classical computations as a special case. Classically, logical processes correspond to stochastic maps, of which deterministic functions are a special case. As a simple example, consider the AND gate. This is one of the elementary operations computing devices can perform, from which more complex circuits can be designed. The gate takes two bits as input, and outputs a single bit that is set to 1 exactly when both input bits are 1, as illustrated in Fig. 2a.

The logical process is manifestly irreversible, as the output alone does not allow to infer the input uniquely. If one of the inputs is zero, then the logical process effectively has to reset a three-level system to zero, forgetting which of the three possible inputs 00, 01 or 10 was given; this information can be viewed as being discarded, and hence dumped into the environment. We can confirm this intuition with our main result, using the fact that a general classical mapping is given by the specification of the conditional probability p (x ′| x) of observing x ′ at the output if the input was x. Embedding the classical probability distributions into the diagonals of quantum states, the infinity norm in expression (2) becomes simply

---

### The role of PD biomarkers in biosimilar development-to get the right answer one must first ask the right question [^5622b216]. Clinical Pharmacology and Therapeutics (2023). Medium credibility.

The general premise of biosimilar development, akin to that of generics, is that a medicine matching that of a branded originator product can be made by a different sponsor at a reduced cost because the sponsor knows what they are making, and that further market entrants will enable a competitive marketplace to ensue. Two elements contribute to such potential competition and these ultimately govern commercial viability for the subsequent market entrant(s):
The cost of getting to market from initial development through licensure for the biosimilar; and
the cost of making the biosimilar on an ongoing basis and supplying the marketplace reliably with a quality product.

The cost of development is a sunk cost, a one‐off for which the return on investment may be amortized for some period of commercialization of the biosimilar depending on the number of market entrants and shared period of sustainable pricing. It has been estimated that the cost of development of a biosimilar can be up to 100 times that of the average generic. Namely $100–500 million vs. $1–5 million. Exact numbers will vary, often driven by the cost of the reference product needed to do the comparative clinical studies. Timelines for biosimilar development are 5–10 years for a biosimilarvs. 10–15 years for an originator product. As such, the companies that are able to invest and that also have the expertise are limited.

---

### Mathematical biases in the calculation of the living planet index lead to overestimation of vertebrate population decline [^2bc59efb]. Nature Communications (2024). High credibility.

The methodological procedure for calculating the LPI consists of these steps:
Addition of a constant of 1% of the population mean (the mean from all non-zero values) to all values of the time series if the time series contains zero in any year. If a population series contains only zeros, the added constant is 10 −17 (we removed these cases).
Estimation of the new population values by two methods (also the way to estimate missing values, i.e. values for years without population records): GAM method is used if the length of the time series is equal to or longer than 6 records and only if the GAM fits well. The GAM smoothing parameter is set to 1/2 of the length of the time series. The GAM method is implemented on logarithmic (base e) values and the values estimated by the model are subsequently delogarithmized. Chain method is used if the length of the time series is less than 6 records or if the GAM does not fit well (or if all population values are the same). It is a log-linear interpolation for missing values in the population series (see Equation 2 in Collen et al.).
Logarithmic transformation (base 10) of the population values.
Calculating the difference between the (logarithmized) population values between every two consecutive years = the logarithm of the ratio of population values = population growth = lambda:
Calculating the arithmetic mean of lambdas (the logarithm of the geometric mean) of all populations of one species within one biogeographical realm (for an individual year). There are 5 (for the terrestrial and freshwater ecosystem) or 6 (for the marine ecosystem) biogeographical realms distinguished (see below).
Calculating the arithmetic mean of species-specific lambdas across all species of one taxon within one realm (for an individual year). There are 3 (for the terrestrial ecosystem) or 4 (for the freshwater and marine ecosystem) taxa distinguished (see below).
Calculating the weighted arithmetic mean of taxon-specific lambdas across all taxa within one realm (for an individual year). The taxon-specific lambdas are weighted by the ratio of the species richness of a given taxon and the species richness of all the taxa together (the weighted method was implemented by McRae et al.).
Calculating the weighted arithmetic mean of realm-specific lambdas across all realms (for an individual year). The realm-specific lambdas are weighted by the ratio of the species richness of a given realm and the species richness of all the realms together (the weighted method was implemented by McRae et al.). The result is one lambda for a certain year.
Calculating the arithmetic mean of ecosystem-specific lambdas across all ecosystems (for an individual year) is obtained by dividing the realm-specific weights by the number of ecosystems (only in the case when the global LPI is calculated), i.e. all the realm-specific weights are multiplied by 1/3 (this procedure is not implemented in the code).
The calculation of the LPI as, where Ip is the index of the previous year and the index of the starting year 1970 was set to 1.
The bootstrap calculation of the confidence intervals of the index. The method involves 100 resamplings of species from each taxon with replacement. The last 7 steps run in a loop for each year.

---

### Universal scaling in real dimension [^329e2ba7]. Nature Communications (2024). High credibility.

Based on the previous arguments and in agreement with ref.we assume in our subsequent analysis that the spectral dimension of the LRDG follows Eq. (6) with η = 0. Since our analysis will mostly focus in the neighbourhood of d s = 3, which falls below σ = 1.5, the quantitative analysis of the possible correction η ≲ 0 will be left to future work.

In order to validate the universality of scaling phenomena on the LRDG graph, we computed the correlation length exponent of the SARW on the graph. The results of this analysis are reported in Fig. 3 and compared with the theoretical expectation obtained by the Flory theory, replacing the integer dimension d with the spectral dimension d s in Eq. (5). The MC data fall neatly on the theoretical curve in the whole range d s ∈ [2, 3.5] providing a very strong indication of universality in the LRDG.

Fig. 3
Inverse correlation length exponent 1/ ν as a function of the spectral dimension d s.

The value of 1/ ν, obtained from Monte Carlo simulations (red diamonds), is compared with analytical and numerical results in integer dimensions (black squares) and with the Flory theory prediction Eq. (5) with d = d s (grey dashed line). Uncertainties on the regular lattice are not shown as the values in d = 2, 4 are exact and the one in d = 3 has a precision better than 0.01%. The symbol contains vertical and horizontal lines representing the uncertainty. Each diamond symbol is obtained by fitting the gyration ratio of the SARW for the three largest sizes of the LRDG and taking the average. The uncertainty is obtained as the largest deviation between the aforementioned values, see the Supplementary Note II for more information. The MC uncertainty of the square boxes is smaller than the size of the symbol.

---

### Physical activity and sleep changes among children during the COVID-19 pandemic [^bbc20921]. NPJ Digital Medicine (2024). Medium credibility.

Data/statistical analysis

Step data were aggregated at the daily level for each participant by summing the step count within each epoch for each day only for epochs with an associated MMI ≥ 1. The average daily steps per month were calculated for each participant, and then averaged across all participants to calculate the average daily step count per month for the entire cohort. These average values and their standard deviations were reported for each of the three time periods: pre-closure, during-closure and post-closure (n = 93, 53, and 8, respectively), to enable comparison of PA during each period and to explore whether a relationship would emerge between PA and closures. For analysis of PA during school times, step count observations beginning from 7:00 AM and before 4:00 PM on weekdays, for all months except June, July and August, were included. Daily step count (averaged by month) for school times were calculated in the same way as the overall step count analysis described above (n = 93, 52 and 8, respectively for pre-closure, during-closure and post-closure).

For the sleep analysis, we used the time stamp of the earliest sleep epoch recorded after 6:00 PM on that day and 8:00 AM the following day to define the sleep start time, or bedtime. Similarly, we defined waketime as the latest sleep end time among all such epochs. If the bedtime was after midnight, the bedtime date was adjusted to be the date for the previous day. Total daily sleep duration per participant was calculated as the sum of the durations of all sleep epochs for each day. Average bedtime, waketime, and sleep duration per participant were calculated for each month, and these values were averaged for all participants to obtain the overall population average. Average bedtime, and waketime were each rounded to the nearest 15 min and were reported, along with the standard deviations, for each of the three time periods: pre-closure, during-closure and post-closure. Additionally, we report summer bedtime and waketime values separately to emphasize similarities in trends during typical summer pre-closure and both school-year and summer months during-closure.

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^9f37e2bb]. Circulation (2014). Medium credibility.

ACC/AHA cost-effectiveness thresholds and affordability — Benchmarks cited include "the oft-cited $50000 per QALY benchmark for an acceptable cost-effectiveness ratio", a World Health Organization proposal of "3 times the GDP per capita" as an upper threshold, and a U.S.-specific estimate that "the GDP per capita in the United States was approximately $48,000", implying "an upper cost-effectiveness threshold near $150 000 per QALY". The statement notes that "programs with cost-effectiveness ratios above this range would generally be considered economically unattractive", whereas ratios "below 1 GDP per capita would generally be considered affordable and cost-effective ($50000 per QALY in an economy with a per capita GDP of the United States)". Uncertainty is emphasized ("The cost-effectiveness acceptability curve is a commonly used graphical way of representing this uncertainty".), and "the total budgetary impact of a medical program also needs to be considered".

---

### Acetaminophen ER [^5b378a64]. FDA. Low credibility.

The drug Acetaminophen ER (also known as Tylenol 8HR).

---

### A space-time tradeoff for implementing a function with master equation dynamics [^57fa10b0]. Nature Communications (2019). High credibility.

Master equations are commonly used to model the dynamics of physical systems, including systems that implement single-valued functions like a computer's update step. However, many such functions cannot be implemented by any master equation, even approximately, which raises the question of how they can occur in the real world. Here we show how any function over some "visible" states can be implemented with master equation dynamics-if the dynamics exploits additional, "hidden" states at intermediate times. We also show that any master equation implementing a function can be decomposed into a sequence of "hidden" timesteps, demarcated by changes in what state-to-state transitions have nonzero probability. In many real-world situations there is a cost both for more hidden states and for more hidden timesteps. Accordingly, we derive a "space-time" tradeoff between the number of hidden states and the number of hidden timesteps needed to implement any given function.

---

### Guidance on the limits to the number of embryos to transfer: a committee opinion [^dc7b5280]. Fertility and Sterility (2021). High credibility.

Embryo transfer limits — other scenarios specify conditional increases or stricter limits. In each of the preceding age groups, patients who do not meet the criteria for a favorable prognosis may have an additional embryo transferred according to their individual circumstances, and the patient must be counseled regarding the additional risk of twin or higher-order multiple pregnancy. If otherwise favorable patients fail to conceive after multiple cycles with high-quality embryo(s) transferred, the physicians and patients may consider proceeding with an additional embryo to be transferred. Patients with a coexisting medical condition for which a multiple pregnancy may increase the risk of significant morbidity should not have more than one embryo transferred. In the rare cases in which recommended limits are exceeded, both the counseling and the justification must be documented in the patient's permanent medical record. In women ≥ 43 years of age, there are insufficient data to recommend a limit on the number of embryos to transfer when the patient uses her own oocytes, and caution should be exercised as the risk associated with multiple pregnancy increases dramatically with advancing maternal age.

---

### Fractional response analysis reveals logarithmic cytokine responses in cellular populations [^b8e8ae49]. Nature Communications (2021). High credibility.

Although we can now measure single-cell signaling responses with multivariate, high-throughput techniques our ability to interpret such measurements is still limited. Even interpretation of dose-response based on single-cell data is not straightforward: signaling responses can differ significantly between cells, encompass multiple signaling effectors, and have dynamic character. Here, we use probabilistic modeling and information-theory to introduce fractional response analysis (FRA), which quantifies changes in fractions of cells with given response levels. FRA can be universally performed for heterogeneous, multivariate, and dynamic measurements and, as we demonstrate, quantifies otherwise hidden patterns in single-cell data. In particular, we show that fractional responses to type I interferon in human peripheral blood mononuclear cells are very similar across different cell types, despite significant differences in mean or median responses and degrees of cell-to-cell heterogeneity. Further, we demonstrate that fractional responses to cytokines scale linearly with the log of the cytokine dose, which uncovers that heterogeneous cellular populations are sensitive to fold-changes in the dose, as opposed to additive changes.

---

### Probabilistic photonic computing with chaotic light [^16eeeb89]. Nature Communications (2024). High credibility.

Next, we investigate the behavior of independent samples drawn from the four WDM wavelength channels shown in Fig. 2c when sampling is performed in parallel. Figure 2d shows the measured standard deviation of the output distribution in each channel in dependence of the mean of the distribution. For each wavelength the standard deviation follows the model prediction. Small differences between the output distributions are caused by slightly different spectral shapes of the WDM channels and the fact that there are four different readout circuits with slightly different ground noise. Since the ASE can be modelled as the superposition of independent random emitters with fixed wavelength, there is no correlation between the intensity fluctuations in different wavelength channels for ideal demultiplexing. Practically, the measured correlation coefficients between different channels during parallel sampling is below 10–2 as shown Fig. 2e.

For a single symbol the mean of the distribution is directly connected to the variance by Eq. 1. In order to generate mean values with desired variance, we take the sum of 9 subsequent symbols which enables shaping the distribution of the measured sum. Figure 2f shows the distribution for three different mean-variance tuples encoded in channel 34. If we encode the mean of the distribution only in a single symbol and set all other to zero (dark blue trace), the distribution of the sum behaves like that of a single symbol (standard deviation of 0.47). In contrast, spreading the same mean over all 9 symbols (light blue trace) leads to a distribution with the same mean but lower variance as the noise partially averages out (standard deviation of 0.29). In this way, we can tune the mean and variance of the output distribution independently. The main advantage of this encoding scheme is that the electronic readout circuit always performs identical operations, i.e. summing over 9 received symbols, and does not require any information about the noise distribution. The distribution is solely encoded in the waveform encoded on the chaotic optical carrier at the input and is propagated through the circuit. We note, that employing longer time sequences with more symbols provides a wider tuning range in the variance at the cost of longer integration time and an increased impact of the ground noise.

---

### Improving the reporting of clinical trials of infertility treatments (IMPRINT): modifying the CONSORT statement [^6dad3921]. Fertility and Sterility (2014). Medium credibility.

IMPRINT infertility trials — analysis sets, unit of analysis, and multiple pregnancy reporting include "For each group, number of participants (denominator) included in each analysis and whether the analysis was by original assigned groups". The guidance specifies "The preferred unit of analysis is per randomized individual/couple (not cycles or oocytes/embryos) for a specified period of time (preferably displayed with life table analysis)". It adds "If per-cycle analysis is used, it should be justified and must account for individuals receiving multiple cycles". Multiple pregnancy handling includes "Clearly describe what happens to all multiple pregnancies, including fetal reduction and vanishing gestations", "Report multiple pregnancy outcome both per woman and per pregnancy", and "Separate out twin/triplets/quads/etc".

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^9d0e2219]. Journal of the American College of Cardiology (2025). High credibility.

Supporting text requirements for economic value statements specify that supporting text should include key elements: a summary of the high-quality CEAs used to generate the statement with rationale for which studies were included and details such as study population, intervention, comparator, clinical outcomes, sources of key effectiveness and safety parameters, perspective, analytic horizon, base-case treatment cost, and source of funding; point estimates and the proportion of simulations that were cost-effective at a specified threshold; and results of key sensitivity analyses, noting that a 1-way sensitivity analysis of intervention cost variation can be helpful, that additional information about sensitivity to intervention cost should be provided, and that inclusion of a figure similar to Figure 4 is encouraged if available.

---

### Factor VIII / von Willebrand factor complex [^9c17790e]. FDA. Low credibility.

The dosage of factor VIII / von Willebrand factor complex IV for treatment of von Willebrand disease in adults (spontaneous and trauma-induced bleeding episodes) is 40–80 unit(s)/kg IV q8-12h

---

### Diagnosis of obstructive coronary artery disease using computed tomography angiography in patients with stable chest pain depending on clinical probability and in clinically important subgroups: meta-analysis of individual patient data [^6278496e]. BMJ (2019). Excellent credibility.

Table 2
Model based predictive values of computed tomography angiography for obstructive coronary artery disease, including and excluding non-diagnostic results

PPV = positive predictive value, NPV = negative predictive value.

Clinically important subgroups

The sensitivity of CTA for all patients was 95.2% (92.6% to 96.9%) and the specificity was 79.2% (74.9% to 82.9%, table 3). The sensitivity of CTA for women and men was 93.5% (89.6% to 96.0%) and 95.8% (93.4% to 97.4%), respectively, while the specificity was 80.6% (75.9% to 84.6%) and 77.4% (72.4% to 81.8%, likelihood ratio test11.28, df: 2, P < 0.001, table 3). Empirical data of women and men and their assignment to pretest probability categories are tabulated in supplementary tables 7 and 8 in web appendix 2. For patients older than 75, the sensitivity of CTA was 93.2% (88.6% to 96.0%) and the specificity was 73.6% (65.7% to 80.2%, table 3).

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^7090401d]. Journal of the American College of Cardiology (2014). Medium credibility.

National Health Spending 1997–2010 — whether expressed as a percentage of GDP, as per capita spending, or as total national US health expenditures (shown here), healthcare spending has risen dramatically from 1997 to 2010.

---

### Drawing statistical conclusions from experiments with multiple quantitative measurements per subject [^70dff523]. Radiotherapy and Oncology (2020). Medium credibility.

In experiments with multiple quantitative measurements per subject, for example measurements on multiple lesions per patient, the additional measurements on the same patient provide limited additional information. Treating these measurements as independent observations will produce biased estimators for standard deviations and confidence intervals, and increases the risk of false positives in statistical tests. The problem can be remedied in a simple way by first taking the average of all observations of each specific patient, and then doing all further calculations only on the list of these patient means. A more sophisticated statistical modeling of the experiment, for example in a linear mixed model, is only required if (i) there is a large imbalance in the number of observations per patient or (ii) there is a specific interest in actually identifying the various sources of variation in the experiment.

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^0c50d5ed]. Journal of the American College of Cardiology (2014). Medium credibility.

Cost-effectiveness thresholds and benchmarks — An oft-cited $50000 per QALY benchmark for an acceptable cost-effectiveness ratio is noted, and the World Health Organization (WHO) suggests an upper threshold of 3 times the GDP per capita; in 2011, the GDP per capita in the United States was approximately $48,000, which implies an upper cost-effectiveness threshold near $150000 per QALY. Programs with cost-effectiveness ratios above this range would generally be considered economically unattractive, whereas programs with cost-effectiveness ratios below 1 GDP per capita would generally be considered affordable and cost-effective ($50000 per QALY in an economy with a per capita GDP of the United States).

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^25a6d4e2]. Circulation (2014). Medium credibility.

ACC/AHA guidelines and performance measures — background notes that "The ACC and AHA have jointly developed clinical practice guidelines for nearly 3 decades", that expert analysis of available data "can improve the quality of care and patient outcomes", that "clinical practice guidelines serve as the underpinnings for performance measures", and that the organizations "have also developed an explicit methodology to select and create performance measures".

---

### Usefulness of a complete blood count-derived risk score to predict incident mortality in patients with suspected cardiovascular disease [^354709b3]. The American Journal of Cardiology (2007). Low credibility.

The complete blood cell (CBC) count is an inexpensive, frequently obtained blood test whose information content is potentially underused. We examined the predictive ability of the CBC count for incident death in 29,526 consecutive consenting patients who underwent coronary angiography. Subjects were randomly assigned to training (60%) and test (40%) groups and were followed for an average of 4.9 years. Computed and integer risk score models for all-cause death were developed for 30 days and 1, 5, and 10 years using multivariable logistic regressions applied to CBC metrics, age, and gender. The study cohort was an average age of 61 years, 62% were men, and had a 3.3% annual risk of mortality. An integer (scalar) risk score (range 0 to 18) successfully separated patient cohorts into subgroups at markedly different mortality risks (< 1% to > 14% at 30 days). Predictive fractions (area under risk curve) at 30 days for the CBC-only model and the age- and gender-adjusted CBC model were 0.76 and 0.78, respectively, in the training set and 0.71 and 0.75, respectively, in the test set (all p values < < 0.001). The CBC model was markedly more informative than models based only on hematocrit, white blood cell count, or age and gender and was superior to models with all 7 traditional risk factors. In conclusion, in a large, prospectively assembled database, a CBC risk model had high predictive ability for risk of incident mortality. A total CBC score is an important new addition to risk prediction, and it can be easily generated by computer for clinical use at negligible incremental cost.

---

### Dorsolateral prefrontal cortex activity during maintenance and manipulation of information in working memory in patients with schizophrenia… [^aac29e77]. JAMA Network (2005). Excellent credibility.

B, In the task 2 depicted, subjects were asked to remember 3 and 5 locations during a fixed 3-second delay. Each trial in task 2 lasted 9 seconds, and subjects performed 12 trials per memory set size. Task 2 included 16 blocks of trials and lasted 10 minutes 57 seconds. Yellow circles indicate targets; green circles, probes; and crosshatches, central fixation. female, respectively; χ2 = 1. 39, P = 0. 23), handedness, and parental education, were recruited to participate in the functional MRI experiments. When the probe circles appeared, subjects determined if the locations of the probe stimuli matched the inverted target stimuli. In task 2, subjects were shown an array of 1, 3, 5, or 7 target circles positioned pseudorandomly around a central fixation.

After a fixed delay, subjects were shown a single probe circle and were asked to determine if the probe was in the same position as one of the target circles. Therefore, voxels that are strongly associated with one task condition but not another or voxels that are represented in only one group would not be included in the conjunction ROIs. For every subject, percentage signal change maps contrasting each cognitive condition with rest were generated separately. Functionally defined ROIs were morphed back into native space, and the mean value from all voxels within each region was determined. These values were then entered into separate ANOVAs for each task. For task 1, a 2 × 3 × 2 ANOVA modeling the effects of diagnostic group, ROI, and task condition was performed.

Additional analyses were performed with subgroups of subjects matched for behavioral performance to address the potential confound of task performance and group membership.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^31d7d596]. CDC (2011). Medium credibility.

Table 2 — types of viral load (VL) analyses and measures — describes mean-based metrics that average per-case results. One metric is calculated by "Determine the most recent VL for each case, total the values of those VLs, and divide by the number of cases with a VL" and indicates "The average number of virus particles in a population; can be influenced by large outliers; useful for comparisons between subpopulations (e.g., disparities)". A log-transformed variant uses "Log transform the most recent VL for each case, average the log transformed values, total the average values, and divide by the number of cases with a VL" and "The log transformation will provide a stable estimate by reducing the influence of outliers; tightens the association of trend between decline in CVL and new diagnoses". Another metric based on the per-case mean is computed by "Determine the mean VLs for each case, total the values of those mean VLs, and divide by the number of cases with a VL" and "Provides an average of the average number of virus particles per case; this may reflect a greater influence of those individuals with multiple measurements and those who were started on ART and trended towards suppression within 1 year". For starred metrics, " The denominator includes all viral load results, including undetectable viral load".

---

### Listing criteria for heart transplantation: International Society for Heart and Lung Transplantation guidelines for the care of cardiac transplant candidates – 2006 [^680000ea]. The Journal of Heart and Lung Transplantation (2006). Medium credibility.

Heart Failure Survival Score (HFSS) calculation and risk strata are specified as follows: The HFSS is calculated by taking the absolute value of the sum of the products of each component variable's value and its model coefficient; example coefficients include ischemic cardiomyopathy β = +0.6931 and resting heart rate β = +0.0216; for ischemic cardiomyopathy and intraventricular conduction delay (IVCD) with QRS ≥ 120 ms, use 1 or 0 for "yes"; mean blood pressure (BP) is defined as diastolic BP + 1/3 (systolic BP − diastolic BP); and HFSS risk strata are defined as low-risk ≥ 8.10, medium-risk 7.20 to 8.09, and high-risk < 7.20.

---

### AGA white paper: optimizing endoscopic ultrasound-guided tissue acquisition and future directions [^ee3a6dfb]. Clinical Gastroenterology and Hepatology (2018). Medium credibility.

Endoscopic ultrasound–guided fine-needle aspiration (EUS-FNA) technique and pass number in pancreatic masses are detailed as follows: a randomized trial of 81 patients found that samples in suction groups were associated with a higher diagnostic yield, accuracy, bloodiness, and cellularity, whereas in lymph nodes suction increases bloodiness without impacting diagnostic yield; a randomized trial showed the "fanning" motion is superior to sampling a single region per pass; in a post hoc analysis, 4 passes detected malignancy with 92% sensitivity (95% CI, 87–95) and tumor size > 2 cm was the only variable associated with positive cytology results (odds ratio, 7.8; 95% CI, 1.9–31.6); in masses > 2 cm, 4 passes had a sensitivity of 93% (95% CI, 89–96) and for masses ≤ 2 cm, 6 passes had a sensitivity of 82% (95% CI, 61–93) with no improvement in sensitivity with increasing passes; these results showed that in the absence of ROSE, 4 EUS-FNA should be performed for pancreatic masses > 2 cm and at least 6 passes in lesions ≤ 2 cm, and the sensitivity of > 85% can be achieved in solid pancreatic lesions with ≤ 3 passes; in the presence of ROSE, alternative sampling such as EUS-FNB should be considered when on-site cytology is negative despite high clinical suspicion.

---

### Brief resolved unexplained events (formerly apparent life-threatening events) and evaluation of lower-risk infants [^7e69974f]. Pediatrics (2016). Medium credibility.

Guideline definitions for key action statements (Table 4) — a strong recommendation is defined as "A particular action is favored because anticipated benefits clearly exceed harms (or vice versa) and quality of evidence is excellent or unobtainable", with the implication "Clinicians should follow a strong recommendation unless a clear and compelling rationale for an alternative approach is present". A moderate recommendation is defined as "A particular action is favored because anticipated benefits clearly exceed harms (or vice versa) and the quality of evidence is good but not excellent (or is unobtainable)", implying "Clinicians would be prudent to follow a moderate recommendation but should remain alert to new information and sensitive to patient preferences". A weak recommendation (based on low-quality evidence) is defined as "A particular action is favored because anticipated benefits clearly exceed harms (or vice versa), but the quality of evidence is weak", with the implication "Clinicians would be prudent to follow a weak recommendation but should remain alert to new information and very sensitive to patient preferences". A weak recommendation (based on balance of benefits and harms) is defined as "Weak recommendation is provided when the aggregate database shows evidence of both benefit and harm that appear to be similar in magnitude for any available courses of action", implying "Clinicians should consider the options in their decision-making, but patient preference may have a substantial role".

---

### ["Simplified acute physiology score" (SAPS II) ina the assessment of severity of illness in surgical intensive care patients] [^df228325]. Der Chirurg; Zeitschrift Fur Alle Gebiete Der Operativen Medizen (2002). Low credibility.

The clinical calculator "Simplified Acute Physiology Score (SAPS II)" for ICU mortality and hyperkalemia.

The Simplified Acute Physiology Score (SAPS II) is a severity score and mortality estimation tool developed for use in Intensive Care Units (ICUs). It is designed to measure the severity of disease for patients admitted to ICUs aged 15 or above. The SAPS II score is calculated from 17 variables, including age, type of admission, three physiological variables, and twelve routine physiological measurements.

The clinical utility of the SAPS II is to provide an estimate of the risk of death for a patient in the ICU, which can assist in clinical decision-making and resource allocation. It can also be used for research purposes, such as comparing the performance of ICUs, or studying the efficacy of new interventions.

The SAPS II should not be used in children under the age of 15, as it was not validated in this population. Additionally, it may not be accurate in patients with certain conditions that significantly alter physiological parameters, such as pregnancy or severe burns.

The Simplified Acute Physiology Score (SAPS II) calculator evaluates the severity of a patient's condition upon admission to the intensive care unit by considering various physiological and health status indicators. The calculator assigns numerical scores to individual inputs, which are then summed to derive a total score. This total score is used to estimate the probability of in-hospital mortality, where higher scores correlate with a higher risk of death.

For each input, various options are provided and each option corresponds to a specific score based on preset criteria:

1. **Age, years**:
- **< 40**: 0
- **40–59**: 7
- **60–69**: 12
- **70–74**: 15
- **75–79**: 16
- **≥ 80**: 18

2. **Heart rate**:
- **< 40**: 11
- **40–69**: 2
- **70–119**: 0
- **120–159**: 4
- **≥ 160**: 7
- **Varies from cardiac arrest to extreme tachycardia**: 11

3. **Systolic blood pressure, mmHg**:
- **< 70**: 13
- **70–99**: 5
- **100–199**: 0
- **≥ 200**: 2

4. **Temperature**:
- < 39ºC [102.2ºF]: 0
- ≥ 39ºC [102.2ºF]: 3

5. **Glasgow Coma Scale score**:
- **14–15**: 0
- **11–13**: 5
- **9–10**: 7
- **6–8**: 13
- **< 6**: 26

6. Arterial partial pressure of oxygen/fraction of inspired oxygen if on mechanical ventilation or CPAP:
- **< 100**: 11
- **100–199**: 9
- **≥ 200**: 6
- **Not on mechanical ventilation or CPAP within the last 24 hours**: 0

7. **BUN, mg/dL [serum urea, mmol/L]**:
- **< 28 [< 10]**: 0
- 28–83 [10–29.9]: 6
- **≥ 84 [≥ 30]**: 10

8. **Urine output, mL/day**:
- **< 500**: 11
- **500–999**: 4
- **≥ 1000**: 0

9. **Sodium, mmol/L**:
- **< 125**: 5
- **125–144**: 0
- **≥ 145**: 1

10. **Potassium, mEq/L (worst value in 24 hours)**:
- < 3.0: 3
- 3.0–4.9: 0
- ≥ 5.0: 3

11. **Bicarbonate, mEq/L**:
- **< 15**: 6
- **15–19**: 3
- **≥ 20**: 0

12. **Bilirubin**:
- < 4.0 mg/dL [< 68.4 mcmol/L]: 0
- 4.0–5.9 mg/dL [68.4–102.5 mcmol/L]: 4
- ≥ 6.0 mg/dL [≥ 102.6 mcmol/L]: 9

13. **White blood cell, ×10³/mm³**:
- < 1.0: 12
- 1.0–19.9: 0
- ≥ 20.0: 3

14. **Chronic disease**:
- **None**: 0
- **Metastatic cancer**: 9
- **Hematologic malignancy**: 10
- **AIDS**: 17

15. **Type of admission**:
- **Scheduled surgical**: 0
- **Medical**: 6
- **Unscheduled surgical**: 8

Each chosen input option is summed to calculate the total SAPS II score. This total score is then used to determine the risk of in-hospital mortality expressed as a percentage. Interpretations are provided for various score ranges:

- Scores from 0 to 2 indicate a risk of 0.0% to 0.1%.
- A score of 125 represents a risk of 100.0%.

---

### The problem with unadjusted multiple and sequential statistical testing [^02331c8d]. Nature Communications (2019). High credibility.

In research studies, the need for additional samples to obtain sufficient statistical power has often to be balanced with the experimental costs. One approach to this end is to sequentially collect data until you have sufficient measurements, e.g. when the p -value drops below 0.05. I outline that this approach is common, yet that unadjusted sequential sampling leads to severe statistical issues, such as an inflated rate of false positive findings. As a consequence, the results of such studies are untrustworthy. I identify the statistical methods that can be implemented in order to account for sequential sampling.

---

### How have research questions and methods used in clinical trials published in clinical rehabilitation changed over the last 30 years? [^629f0bdc]. Clinical Rehabilitation (2016). Low credibility.

Table 7 summarizes the samples sizes and drop-outs across studies. The average sample size was 83 people with a wide variation ranging from five to 3312. The proportion of drop-outs or people with data otherwise missing postintervention averaged 9% with a range from 0% to 55%.

The characteristics of the statistical methods are presented in Table 8. The status of missing data was often not reported. There were only 51 studies (13%) with no missing data. Of the 338 studies with some missing data, how the missing data was handled was sometimes unclear (18%) or not reported (11%). Most often missing data were excluded from the analysis (58%) and studies rarely used reasonable approaches to deal with missing data, such as simple imputation or modelling (12%) or multiple imputation (2%). Intention-to-treat analysis was planned or carried out in 194 studies, but these results were rarely reported (95/194; 49%). Investigators often reported that the results were similar to the per protocol analysis, so did not report the intention-to-treat results; sometimes only the wording 'intention-to-treat' was used and the analysis was not carried through to the data presentation. Power was reported in less than half of studies, 43%. The planned analyses were fully described in 63% of studies, but the analysis matched the data collected in only 68% of studies. Some examples are: analysing event data like falls as measured data and comparing means, rather than as a count and comparing proportions; and comparing groups on outcomes at each time point rather than allowing time to be a factor.

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^b4d5889f]. Journal of the American College of Cardiology (2014). Medium credibility.

ACC/AHA cost/value methodology — special considerations states that the goal of adding value considerations to guidelines "should be to provide information rather than to be prescriptive". It advises that efforts "should focus on interventions associated with high costs or volume", that published resource-use studies "should be part of a comprehensive evidence review", and it notes that methods to assess economic studies are "not as well developed as that used to judge efficacy in clinical trials".

---

### Multiplicity of data in trial reports and the reliability of meta-analyses: empirical study [^8d4d1d85]. BMJ (2011). Excellent credibility.

Fig 2 Monte Carlo distributions of possible pooled SMDs in each meta-analysis. Dots = number of trials included. Open dots = trials without multiplicity of data. Filled dots = trials with multiplicity of data. Stars = published pooled SMDs. Meta-analyses are ordered according to the number of trials included. Negative SMDs on y axis indicate experimental intervention has more beneficial effect than control intervention

Table 5presents the variability of pooled SMD results according to different sources of multiplicity (that is, groups, time points, or scales). Eighteen meta-analyses included trials with multiple data for at least one source. In these 18 meta-analyses, the treatment effect from multiplicity of data varied greatly (median difference between the smallest and largest SMDs within the same meta-analysis, 0.40 standard deviation units, range 0.04 to 0.91).

Table 5
Variability in meta-analyses results

---

### ACC / AHA statement on cost / value methodology in clinical practice guidelines and performance measures: a report of the American college of cardiology / American Heart Association task force on performance measures and task force on practice guidelines [^edb1d3a4]. Journal of the American College of Cardiology (2014). Medium credibility.

Goals for incorporating cost and value into ACC/AHA guideline development — stated aims: Given these considerations, the recommendation to consider cost and value in the guideline development process has these goals: 1) to enhance overall value in the delivery of cardiovascular care and 2) to involve healthcare professionals.

---

### Allergy diagnostic testing: an updated practice parameter [^fca2f012]. Annals of Allergy, Asthma & Immunology (2008). Medium credibility.

Prick/puncture skin testing — proficiency testing and quality assurance steps specify alternating positive and negative controls, timed readings, and quantitative criteria: perform testing with positive (histamine 1–10) and negative controls (saline 1–10) in an alternate pattern; record histamine results at 8 minutes and saline results at 15 minutes; calculate mean wheal diameter as (D + d)/2 and determine coefficient of variation (CV) = SD/mean with the quality standard that CV be less than 30%; all negative controls should be < 3-mm wheals and < 10-mm flares.

---

### Machine learning for real-time aggregated prediction of hospital admission for emergency patients [^c296d5f7]. NPJ Digital Medicine (2022). Medium credibility.

Fig. 5
QQ plots evaluating the predicted distributions of the number of admissions after Steps 3, 5 and 7.

Abbreviations: cdf (cumulative distribution function). The first column of plots evaluates the distributions for all patients currently in the ED, without applying a prediction window. The second column evaluates the distributions for all patients currently in the ED, with a prediction window of 4 and 8 hours. The third column evaluates the distributions for all patients currently in ED, and patients yet to arrive, with a prediction window of 4 and 8 hours.

Figure 6 compares the model predictions with the conventional six-week rolling average benchmark for daily admissions, adjusted for use at 16:00 h (see Methods for how this was derived). Mean Absolute Error (MAE) was used to compare the approaches, as this avoids positive and negative deviations cancelling each other out, and the error was also expressed as a percentage of observed admissions to derive a mean percentage error (MPE). The prediction pipeline underestimated the number of admissions within the 8-hour window but performed better than the benchmark (MAE of 4.0 admissions with MPE of 17%, compared with 6.5 and 32% for the benchmark).

Fig. 6
Comparing model predictions with six week rolling average benchmark for number of admissions within a prediction window of 8 hours after 16:00, including patients who are yet to arrive.

a Shows the difference between the observed number of admissions and the expected value from the probability distribution for the model predictions (the red dots) and between the observed number of admissions and expected value from the benchmark (the blue dots). Where the expected value equals the observed value, the dots fall on the x axis (y = 0). The grey shaded band represents the range of probability between the 10 th and the 90 th centile of the cumulative probability distribution of the model. b Shows the distribution of errors (difference between observed and expected). See Methods for a rationale for conducting the evaluation at 16:00 with an 8-hour prediction window.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^943345bf]. Journal of the American College of Cardiology (2025). High credibility.

Figure 3 — health opportunity cost approach to US cost-effectiveness thresholds reports 50000 simulations with varying input values, with 23902/50000 (48%) thresholds < $100000/QALY and 7006/50000 (14%) thresholds > $150000/QALY; the base-case estimate is $104,000/QALY in 2019 US dollars with a (95% UI, $51,000–$209,000/QALY), and updating to 2024 US dollars suggests a cost-effectiveness threshold of $117000 per QALY.

---

### Quality indicators for gastrointestinal endoscopy units [^bee78dc2]. VideoGIE (2017). Medium credibility.

Procedure-related quality indicators (Delphi survey — procedure) include multi-item ratings under Related to quality; 1st round Meaningful to measure, Feasible to measure, and Compliance in own endoscopy unit; and 2nd round Related to quality. "Mechanism(s) are in place to detect, assess, and address concerns raised regarding physicians' competence" shows 5; 5 (89.7); 5 (75.9); 4 (17.2); and 5 (86.4). "Endoscopy unit records, tracks, and monitors procedure quality indicators for both the endoscopy unit and individual endoscopists" shows 5; 5 (89.7); 5 (75.9); 5 (62.1); and 5 (86.4). "Unit has policy in place for patient pause/time-out that satisfies all key elements" shows 5; 5 (90.0); 5 (82.8); 5 (93.3); and 5 (82.8). "Peer review of procedures by endoscopists is performed" shows 5; 5 (80.0); 5 (82.8); 4 (10.3); and 5 (77.3). "ERCP volume and sphincterotomy volume by physician and unit are tracked and considered for privileging" shows 5; 5 (41.3); 5 (44.8); 5 (13.3); and 5 (57.9).

---

### A clinical score (RAPID) to identify those at risk for poor outcome at presentation in patients with pleural infection [^d5154658]. Chest (2014). Low credibility.

The clinical calculator "RAPID score for pleural infection" for community-acquired pneumonia, ventilator-associated pneumonia and parapneumonic effusion and empyema.

The RAPID score is a clinical calculator used for patients with pleural infection. RAPID stands for Renal function, Age, Purulence, Infection source, and Dietary status. This scoring system is used to predict the mortality risk in patients with pleural infection, helping clinicians to stratify patients based on their risk and guide treatment decisions.

The RAPID score is applicable to patients diagnosed with pleural infection, regardless of the underlying cause. It is not suitable for patients without a confirmed diagnosis of pleural infection or those with pleural effusion due to non-infectious causes. The score may also be less accurate in patients with multiple comorbidities or complex medical histories that could independently affect the variables included in the score.

The RAPID score calculator is designed to assess the risk of 3-month mortality in patients with pleural infections. It uses five input variables: blood urea nitrogen, age, purulence of pleural fluid, infection source, and serum albumin levels. Each input corresponds to predefined categorical options that are assigned specific numerical scores based on clinical findings, allowing the calculator to estimate the risk level.

The scoring system for each input variable is as follows:

1. **Blood Urea Nitrogen**:
- **Less than 14 mg/dL [5 mmol/L]**: 0 points
- **Between 14–23 mg/dL [5–8 mmol/L]**: 1 point
- **Greater than 23 mg/dL [8 mmol/L]**: 2 points

2. **Age (years)**:
- **Less than 50**: 0 points
- **Between 50–70**: 1 point
- **Greater than 70**: 2 points

3. **Purulence of Pleural Fluid**:
- **Purulent**: 0 points
- **Non-purulent**: 1 point

4. **Infection Source**:
- **Community-acquired**: 0 points
- **Hospital-acquired**: 1 point

5. **Serum Albumin**:
- Equal to or greater than 2.7 g/dL [27 g/L]: 0 points
- Less than 2.7 g/dL [27 g/L]: 1 point

To compute the total RAPID score, each input answer is converted into a score using the system outlined above, and the scores are summed together. The maximum possible score is 7, while the minimum possible score is 0. Based on the total score, risk of mortality within 3 months is categorized into one of three levels:

- A total score of 2 or less indicates a low risk of 3-month mortality.
- A total score between 3 and 4 indicates a medium risk of 3-month mortality.
- A total score of 5 or more indicates a high risk of 3-month mortality.

---

### Approaches to analyzing comparative use human factors studies… [^70007ef0]. FDA (2025). Medium credibility.

fda. gov/cdersbia 4 Current Use of CUHF Studies to Support Other Design Differences. product through the noninferiority test in CUHF studies as discussed in the draft guidance: Step 1
- Determine the allowable margin by which ERT could exceed ERR. Step 2
- Estimate the study sample size considering assumed error rates and d. Step 3
- Observe error rates for the critical task during the CUHF experiments. Step 4
- Perform the NI hypothesis test. H0: ERT
- **ERR > d HA**: ERT
- ERR ≤ d. fda. gov/cdersbia 7 NI test for CUHF studies Step 1 Determine the allowable margin by which ERT could exceed ERR
- The value of d will differ between products, depending on the indication and the clinical consequences associated with failing to perform the critical tasks appropriately.
- The acceptable d should be decided in consultation with the FDA before the study is conducted. fda.

gov/cdersbia 8 NI test for CUHF studies Step 2 Calculate the study sample size considering assumed error rates and d
- The draft guidance provides an example using the Tango method to calculate some power simulations given selected sample sizes with α = 0. 05 and an allowable margin = 0.
10. fda. gov/cdersbia 10 Observe error rates for the critical task during the experiment.
- Definition of critical tasks
- Observe error/success results of subjects for each critical task NI test for CUHF studies Step 3. fda. gov/cdersbia 11 Perform the NI hypothesis test.
- Compare the upper bound of the CI for the difference of error rates between T and R to d.
- If α = 0. 05 and the upper bound of 95% CI is less than d, H0 is rejected and NI is demonstrated. NI test for CUHF studies Step 4 H0: ERT
- **ERR > d HA**: ERT
- ERR ≤ d. Questions. Jing Wang, Ph. D. Staff Fellow, Division of Quantitative Methods and Modeling Office of Research and Standards, Office of Generic Drugs CDER | U. S.

FDA jing. wang1@fda. hhs. gov.

---

### The cost of large numbers of hypothesis tests on power, effect size and sample size [^9df69432]. Molecular Psychiatry (2012). Low credibility.

To compensate for a greater number of tests, a more realistic strategy may be to increase the sample size (equation 2). Table 1 and Figure 2c give sample sizes needed to maintain the original power at the original targeted effect size. For one million tests, the sample size multiplier is 5.06 for 80% power and 4.33 for 90% power, using equation (2). In the first example above, 506 subjects would be sufficient to reach 80% power to detect that the means differ by 2 in one million Bonferroni-adjusted tests. Although it might appear counterintuitive, the sample size multiplier is smaller for 90% power because the initial sample size is larger. In the same example, 132 subjects would be needed to reach 90% power for one test. For 90% power for one million tests, 4.33 × 132 = 572 subjects are needed. Noting the nearly linear relationship in Figure 2c, we also obtained an approximate rule-of-thumb for the sample size multiplier by fitting zero-intercept linear regression models to the results in Figure 2c. The estimated slopes show that m is approximately, where γ = 1.2 for 50% power, 0.68 for 80% power, 0.55 for 90% power and 0.38 for 99% power.

The rate at which the critical value and, consequently, the effect size and sample size multipliers increase becomes slower and slower as the number of tests becomes larger (Figure 2d), owing to the exponential decline in the tails of the Normal density. For example, effect size multipliers for one million vs ten million tests at 80% power are 2.25 and 2.39, respectively. Sample size multipliers are 5.06 and 5.71. At 80% power, ten million tests require only a 6% increase in the targeted effect size or a 13% increase in the sample size when compared to one million tests. In contrast, 10 tests require a 30% increase in the targeted effect size or a 70% increase in the sample size as compared with a single test. For 80% power and one billion or one trillion tests, the required sample sizes, respectively, are approximately 7 or 9 times that needed for a single test. See Table 1 for some numerical results and the provided Excel calculator (Supplementary Table 1) to explore unreported results and specific study designs.

---

### Guidelines for reasonable and appropriate care in the emergency department 2 (GRACE-2): low-risk, recurrent abdominal pain in the emergency department [^2c8246c6]. Academic Emergency Medicine (2022). High credibility.

PHQ-based depression screening diagnostic accuracy — pooled results show the following: PHQ-9 ≥ 10 alone had sensitivity 86% (80%–90%) and specificity 85% (82%–87%); PHQ-2 ≥ 2 alone had sensitivity 92% (88%–95%) and specificity 67% (63%–70%); PHQ-2 ≥ 3 alone had sensitivity 72% (67%–77%) and specificity 86% (83%–87%); PHQ-2 ≥ 2 followed by PHQ-9 ≥ 10 had sensitivity 82% (76%–86%) and specificity 87% (84%–89%); PHQ-2 ≥ 3 followed by PHQ-9 ≥ 10 had sensitivity 70% (64%–75%) and specificity 91% (89%–93%).

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^5355d6ea]. CDC (2011). Medium credibility.

Community viral load categorical measurement — additional measures and distribution guidance include examining the proportion of HIV-infected persons that meet a standardized definition of in-care, e.g., at least two lab results obtained within a calendar year that are at least 60 days apart. Categorical measures might be more informative than means, the actual distribution of VL results in surveillance populations is highly skewed with a large proportion of the population having undetectable or very low values (e.g., < 200 copies/mL), and jurisdictions should examine their data to determine the local viral load distribution and the best measures to describe it, including outlier cutoff values; such distributions can also be stratified by CD4+ T-lymphocyte count to reflect stage of illness and the U.S. HIV Treatment Guidelines recommendations on initiation of antiretroviral therapy.

---

### Factor VIII glycoPEGylated (recombinant) [^2dfe7eab]. FDA. Low credibility.

The dosage of factor VIII glycoPEGylated (recombinant) IV for treatment of bleeding episodes in both children (in patients ≥ 12 years) with hemophilia A (major) is 50 unit(s)/kg IV once, followed by additional doses every 24 hours if necessary

---

### PICADAR: a diagnostic predictive tool for primary ciliary dyskinesia [^4c4a4b61]. The European Respiratory Journal (2016). Low credibility.

The clinical calculator "Primary ciliary dyskinesia rule (PICADAR)" for primary ciliary dyskinesia.

The Primary Ciliary Dyskinesia Rule, also known as PICADAR, is a clinical calculator used in the diagnosis of Primary Ciliary Dyskinesia (PCD), a rare, genetically heterogeneous disorder characterized by chronic upper and lower respiratory tract disease. This calculator is applicable to patients who present with symptoms suggestive of PCD, such as chronic cough, chronic rhinosinusitis, and recurrent or persistent lower respiratory tract infections.

The PICADAR score is a useful tool for identifying patients who are at high risk of having PCD and who may benefit from further diagnostic testing. It uses seven clinical features to calculate a score, including full-term gestation, persistent wet cough, persistent rhinitis, neonatal chest symptoms, situs inversus or unexplained cardiac defects, congenital hearing defect, and a history of PCD in a sibling.

Exclusion criteria for the use of the PICADAR score may include patients who have other known causes for their respiratory symptoms, such as cystic fibrosis, asthma, or immunodeficiency disorders. It's also important to note that while the PICADAR score can help identify patients at high risk for PCD, it is not definitive and further diagnostic testing is required for a confirmed diagnosis.

The PICADAR calculator helps estimate the likelihood of Primary Ciliary Dyskinesia (PCD) by evaluating a patient's symptoms through eight targeted questions. Each response translates into a numerical score based on a specific scoring framework, which together reflect the risk of PCD.

Patients answer the following questions:

- Do they have a daily wet cough that started in early childhood? A "Yes" translates to 0 points, whereas "No" scores 15 points.
- Were they born preterm or at full term? Being born "Term" adds 2 points.
- Did they experience chest symptoms such as tachypnea, cough, or pneumonia in the neonatal period? If "Yes", 2 points are awarded.
- Were they admitted to a neonatal unit? Similar to chest symptoms, a "Yes" yields 2 points.
- Do they have a situs abnormality like situs inversus or heterotaxy? A "Yes" response results in 4 points.
- Is there a congenital heart defect present? This also contributes 2 points if responded with "Yes".
- Do they have persistent perennial rhinitis? A "Yes" equals 1 point.
- Finally, do they experience chronic ear or hearing symptoms such as glue ear, serous otitis media, hearing loss, or ear perforation? A "Yes" scores another point.

Responses are converted into scores, and all are summed to create a total. This sum determines the risk of PCD based on the following score-to-risk mapping:

- Score of 0 corresponds to a 0.1% risk.
- Score of 1 indicates a 0.3% risk.
- Score of 2 suggests 0.8% risk.
- Score of 3 means 1.9% risk.
- Score of 4 estimates a 4.7% risk.
- Score of 5 reaches an 11.1% risk.
- Score of 6 suggests 23.9% risk.
- Score of 7 indicates a 44.1% risk.
- Score of 8 corresponds to a 66.4% risk.
- Score of 9 represents 83.3% risk.
- Score of 10 implies 92.6% risk.
- Score of 11 shows 96.9% risk.
- Score of 12 corresponds to 98.7% risk.
- A score of 13 or higher suggests an overwhelming 99.8% risk of PCD.

Crucially, a score of -1 or below reflects a scenario not supported by this calculator, emphasizing its reliance on the presence of a wet cough as a key factor.

---