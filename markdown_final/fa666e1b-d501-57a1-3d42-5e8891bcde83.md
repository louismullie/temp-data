# Medical Question & Answer

**Sample ID**: fa666e1b-d501-57a1-3d42-5e8891bcde83
**Dataset Index**: 368987

---

## Question

For deception in an experiment to be permissible, it is essential that the

Answer Choices:
A. the participants have given their informed consent to be deceived
B. deception does not involve withholding information about the purpose of the research
C. investigator include a careful explanation of the deception within 3 years following the experiment
D. merits or value of the scientific investigation warrants the type of deception used
E. the deception involves providing false information about the purpose of the research
F. the deception is revealed to the participants at the end of the study, but only if they ask

---

## Answer

> Let's see… What do we have here? The user is asking which condition is essential for deception in an experiment to be permissible. Let's break this down step-by-step. First, I need to think about the core ethical framework governing human subjects research. Then, I should verify how deception fits within that framework, including informed consent, risk–benefit assessment, and debriefing. Next, I will examine each answer choice against those principles and identify which is truly essential. Finally, I will double-check for any exceptions or nuances that might change the conclusion and confirm the best answer with supporting references.

> Let me first confirm the foundational ethical framework. Modern research ethics rests on seven core requirements: social value, scientific validity, fair participant selection, favorable risk–benefit ratio, independent review, informed consent, and respect for participants. These are derived from the Nuremberg Code, the Declaration of Helsinki, the Belmont Report, and the Common Rule, and they apply across clinical and behavioral research contexts [^1141ijSC] [^114NinYX].

> Now, I need to think about where deception fits. Deception is generally incompatible with fully informed consent because it involves misleading participants about some aspect of the study, yet it may be permissible only when the scientific question cannot reasonably be answered without it, the potential benefits outweigh the risks, and appropriate safeguards are in place. This is a strict exception, not a routine practice, and it must be justified to an IRB in advance [^1141ijSC] [^114NinYX].

> Wait, let me verify the role of informed consent even when deception is used. Even when deception is employed, researchers must obtain legally effective informed consent to the extent feasible, often via authorized deception or a waiver of some disclosure elements, and they must debrief participants afterward. This means participants still consent to participate in research, even if they are not told everything up front, and they are later informed about the deception and its rationale [^112BoJ9p].

> I will now examine each option against this framework. Option A claims participants must give informed consent to be deceived; hold on, let's not jump to conclusions — this is too strong because true informed consent to deception is contradictory. Participants cannot fully consent to be deceived in advance, so the correct approach is that participants consent to research with disclosure of deception when possible or with a waiver and subsequent debriefing, not that they consent to the deception itself [^112BoJ9p] [^116D7iZ9].

> Option B says deception must not involve withholding information about the purpose; hmm, wait a minute, that would eliminate most legitimate deception, which often requires concealing the true purpose to preserve validity. So this cannot be correct as a general rule, even though minimization of deception is preferred when feasible [^116SNNNy].

> Option C proposes explaining the deception within 3 years; I should double-check the timing. Ethical guidance requires debriefing as soon as reasonably possible after participation, typically immediately or shortly thereafter, not years later, so a 3-year delay is unacceptable and inconsistent with respect for participants [^116D7iZ9].

> Option D asserts that the merits or value of the scientific investigation must warrant the deception; this aligns with the core requirement that deception be justified by scientific necessity and a favorable risk–benefit ratio. Let me reconsider — yes, this is the essential condition that makes deception ethically permissible when it is otherwise incompatible with full disclosure [^1141ijSC] [^114NinYX].

> Option E states deception must involve providing false information about the purpose; hold on, I should verify — this describes a common form of deception, but it is not a requirement. Deception can also involve omission or partial disclosure, so making this a definitional requirement is incorrect [^112oATWw].

> Option F suggests revealing deception only if participants ask; I need to ensure this is not sufficient. Passive disclosure contingent on participant inquiry is inadequate. Ethical practice requires active debriefing of all participants after participation, regardless of whether they ask [^notfound].

> Putting this together, the essential condition is that the scientific value and risk–benefit profile of the study justify the use of deception, with appropriate safeguards and debriefing. Therefore, the correct answer is D, and the other options either overstate consent requirements, misstate timing, or mischaracterize what deception entails [^1141ijSC] [^114NinYX].

---

The correct answer is **D. the merits or value of the scientific investigation warrants the type of deception used**. Deception in research is ethically permissible only when the study has **significant scientific value** that cannot be achieved without deception, the risks to participants are minimized, and there is a plan for debriefing and correcting any harm [^1141ijSC] [^114NinYX]. Informed consent must still be obtained to the extent possible, but the key justification is the **scientific necessity and value** of the deception, not consent to be deceived [^112BoJ9p] [^116D7iZ9].

---

## Ethical principles governing deception in research

Several **ethical principles** guide the use of deception in research:

- **Social value**: The study must have the potential to improve human health or increase knowledge [^1141ijSC].
- **Scientific validity**: The study must use accepted scientific methods [^115XURKP].
- **Fair participant selection**: Participants should be selected based on scientific criteria, avoiding vulnerable populations when possible [^114NinYX].
- **Favorable risk-benefit ratio**: Risks to participants must be minimized and justified by potential benefits [^1141ijSC].
- **Independent review**: Studies must be reviewed and approved by an independent ethics committee (IRB) [^114NinYX].
- **Informed consent**: Participants must be informed about the study's purpose, risks, benefits, and alternatives, and consent must be voluntary [^112BoJ9p].
- **Respect for participants**: Participants must be treated with respect, and their privacy and interests protected [^114NinYX].

---

## Conditions under which deception is permissible

Deception is permissible only when the following **conditions are met**:

- **Scientific necessity**: The research question cannot be answered without deception.
- **Minimal risk**: The deception does not expose participants to significant risk or harm.
- **IRB approval**: The study has been reviewed and approved by an independent ethics committee [^114NinYX].
- **Debriefing**: Participants are informed of the deception as soon as possible after participation, and any misconceptions or harm are corrected [^notfound].

---

## Analysis of answer choices

| **Answer choice** | **Analysis** | **Correctness** |
|-|-|-|
| A. Participants have given informed consent to be deceived | Incorrect. Participants cannot truly consent to be deceived, as deception inherently involves withholding information. However, researchers must obtain informed consent to the extent possible and debrief participants afterward [^112BoJ9p] [^116D7iZ9]. | Incorrect |
| B. Deception does not involve withholding information about the purpose of the research | Incorrect. Deception often involves withholding information about the true purpose of the research to prevent participant bias. | Incorrect |
| C. Investigator includes a careful explanation of the deception within 3 years following the experiment | Incorrect. Deception must be explained to participants as soon as possible after participation, not years later [^notfound]. | Incorrect |
| D. Merits or value of the scientific investigation warrants the type of deception used | Correct. The scientific value and necessity of the deception must be clearly demonstrated and approved by an IRB [^1141ijSC] [^114NinYX]. | Correct |
| E. The deception involves providing false information about the purpose of the research | Incorrect. While deception may involve providing false information, this is not a requirement for its permissibility. | Incorrect |
| F. The deception is revealed to the participants at the end of the study, but only if they ask | Incorrect. Deception must be revealed to all participants regardless of whether they ask, and any harm must be corrected [^notfound]. | Incorrect |

---

## Conclusion

Deception in research is ethically permissible only when the **scientific value and necessity of the deception** are clearly demonstrated, the risks to participants are minimized, and there is a plan for debriefing and correcting any harm. The correct answer is **D. the merits or value of the scientific investigation warrants the type of deception used**.

---

## References

### Specialty guidelines for forensic psychology [^115RfLEu]. The American Psychologist (2013). Medium credibility.

Guideline 11.01: Accuracy, fairness, and avoidance of deception — Forensic practitioners make reasonable efforts to ensure their services and public statements are communicated to promote understanding and avoid deception; in expert roles they facilitate understanding of evidence, do not distort or withhold relevant evidence, strive to have data considered readily available for inspection subject to legal and professional constraints, present conclusions and professional products in a fair manner, and do not participate in misrepresentation or partisan attempts to subvert contrary evidence while remaining free to forcefully present supporting data and reasoning.

---

### Deception by research participants [^112fRhAV]. The New England Journal of Medicine (2015). Excellent credibility.

Study participants who fabricate, falsify, or fail to disclose important information can undermine the integrity of clinical trials, with negative consequences for both future patients and the participants themselves. What can investigators do to address the problem?

---

### Fraud, deception, and subversion: recommendations for maintaining data integrity [^1172h1z5]. Archives of Physical Medicine and Rehabilitation (2025). Medium credibility.

Researchers increasingly use online tools to advertise studies, recruit participants, and collect data, enabling access to individuals in remote or rural areas, those with limited mobility, and participants facing time constraints. While online platforms offer significant advantages, online research remains vulnerable to fraudulent activity, which can compromise the validity of study findings and deplete both funding and human resources. This special communication describes the real-world experiences of two research groups, one in Canada and one in the United States, who encountered fraudsters in both randomized controlled trials (RCTs) and observational studies. We conducted a literature review and identified 32 peer-reviewed articles addressing fraudulent participation and deceptive behaviors in online research. Drawing from both our experiences and the literature, we synthesize actionable strategies to prevent, detect, and manage fraud throughout the research process, including study design (e.g. community involvement), advertisement (e.g. limited information), recruitment and screening (e.g. knowledge-based eligibility questions), assessment (e.g. embedding repeated questions), data analysis (e.g. removing fraudulent data), and remuneration (e.g. clarifying reimbursement conditions). Despite the availability of these strategies, each study design presents unique vulnerabilities, and not all approaches are universally applicable. Researchers are encouraged to assess the specific risks associated with their study design and select strategies that align with their study objectives, balancing the need to minimize fraud, recruit genuine participants, and maintain data integrity.

---

### 2020 APHRS / HRS expert consensus statement on the investigation of decedents with sudden unexplained death and patients with sudden cardiac arrest, and of their families [^112M5PBp]. Heart Rhythm (2021). High credibility.

ACC/AHA recommendation system — applying Class of Recommendation (COR) and Level of Evidence (LOE) is defined as follows: Class 1 (strong) "Benefit > > > Risk", with suggested phrases including "Is recommended", "Is indicated/useful/effective/beneficial", "Should be performed/administered/other", and comparative phrases "Treatment/strategy A is recommended/indicated in preference to treatment B" and "Treatment A should be chosen over treatment B". Class 2a (moderate) "Benefit > > Risk", with "Is reasonable", "Can be useful/effective/beneficial", and comparative phrases "Treatment/strategy A is probably recommended/indicated in preference to treatment B" and "It is reasonable to choose treatment A over treatment B". Class 2b (weak) "Benefit ≥ Risk", with "May/might be reasonable", "May/might be considered", and "Usefulness/effectiveness is unknown/unclear/uncertain or not well-established". Class 3: No Benefit (moderate) "Benefit = Risk", with "Is not recommended", "Is not indicated/useful/effective/beneficial", and "Should not be performed/administered/other". Class 3: Harm (strong) "Risk > Benefit", with "Potentially harmful", "Causes harm", "Associated with excess morbidity/mortality", and "Should not be performed/administered/other". LOE categories include Level A with "High-quality evidence‡ from more than 1 RCT", "Meta-analyses of high-quality RCTs", and "One or more RCTs corroborated by high-quality registry studies"; Level B-R (Randomized) with "Moderate-quality evidence‡ from 1 or more RCTs" and "Meta-analyses of moderate-quality RCTs"; Level B-NR (Nonrandomized) with "Moderate-quality evidence‡ from 1 or more well-designed, well-executed nonrandomized studies, observational studies, or registry studies" and "Meta-analyses of such studies"; Level C-LD (Limited Data) with "Randomized or nonrandomized observational or registry studies with limitations of design or execution", "Meta-analyses of such studies", and "Physiological or mechanistic studies in human subjects"; and Level C-EO (Expert Opinion) with "Consensus of expert opinion based on clinical experience". The table notes that "COR and LOE are determined independently (any COR may be paired with any LOE)".

---

### Association between financial incentives and participant deception about study eligibility [^116FsUSz]. JAMA Network Open (2019). High credibility.

Introduction

Offering payment for research participation is often both practically necessary and ethically fraught. Relying on participant altruism or the prospect of direct medical benefit may be insufficient to achieve recruitment goals, necessitating offers of reimbursement, compensation, and incentives to encourage enrollment and retention. Concern about undue influence stemming from such payment can be minimized by the requirement that institutional review boards (IRBs) approve research only when its balance of risks and benefits is objectively reasonable. However, even if ethical concerns can be managed, an important pragmatic concern persists: anecdotal evidence and common sense suggest that payment may encourage participants to mislead investigators about their eligibility or other aspects of participation by concealing or fabricating information to secure payment. Intentional misrepresentation of this nature, otherwise known as deception, may have serious consequences for participant safety and the validity of research results.

Systematic, prospective data regarding whether and to what extent participants will deceive when offered payment in a real study are lacking. Therefore, we designed a randomized survey experiment in a nationally representative sample of US adults participating in an online panel, with the objectives of quantifying payment-associated deception about eligibility and evaluating whether variable payment amounts are associated with variable rates of deception.

---

### Is it ethical to keep interim findings of randomised controlled trials confidential? [^112Gxw7y]. Journal of Medical Ethics (2008). Low credibility.

Data monitoring committees often are employed to review interim findings of randomised controlled trials. Interim findings are kept confidential until the data monitoring committee finds that they provide sufficiently compelling evidence regarding efficacy, typically because they have crossed the pre-defined statistical boundaries, or they raise serious concerns about safety. While this practice is vital to maintaining the scientific integrity of controlled trials and thereby ensuring their social value, it has been criticised as unethical. Commentators argue that withholding interim findings from research participants is deceptive, inconsistent with valid informed consent, and a violation of respect for participants' autonomy. The present article examines these arguments, focusing specifically on confidential data monitoring for efficacy. This practice need not be deceptive provided its use is disclosed to prospective research participants. In addition, confidential data monitoring does not make research participants worse off than they would be in the clinical setting and represents an acceptable limitation on the options available to prospective research participants. Taken together, these considerations suggest confidential data monitoring, subject to adequate safeguards, is ethically acceptable.

---

### Attitudes and perceptions toward authorized deception: a pilot comparison of healthy controls and fibromyalgia patients [^116SNNNy]. Pain Medicine (2020). Medium credibility.

Introduction

Several recent studies have shown positive outcomes of open-label placebo treatments, in which patients were informed that they were receiving a placebo medication. Nevertheless, the long-term outcomes of open-label placebo treatments are unknown, and deception in placebo studies is still widely used and has resulted in many important findings. Study designs that include deceiving participants circumvent the accepted ethical norms that govern human research, particularly informed consent. When the entirety of a study is not truthfully disclosed, the potential participant lacks information that may affect their decision about participating in the research study, which negates the process of making informed decisions.

Until there is better evidence that deception is not needed to create a full placebo response, studies of the placebo effect will continue to use deception. In the case of placebo analgesia studies, deception is used for altering pain perception, thereby requiring investigators to mislead prospective participants about the purpose of the study and/or the experimental manipulations. With growing interest in the effects of placebo analgesia, it is important for investigators to consider and properly gauge the perception that their study population will have about being misled. Unfortunately, published results of deceptive experiments do not typically discuss the use of deception or ask for participants' feedback, and therefore little information is available about participants' experiences.

---

### Detecting spontaneous deception in the brain [^111bCpnc]. Human Brain Mapping (2022). Medium credibility.

Deception detection can be of great value during the juristic investigation. Although the neural signatures of deception have been widely documented, most prior studies were biased by difficulty levels. That is, deceptive behavior typically required more effort, making deception detection possibly effort detection. Furthermore, no study has examined the generalizability across instructed and spontaneous responses and across participants. To explore these issues, we used a dual-task paradigm, where the difficulty level was balanced between truth-telling and lying, and the instructed and spontaneous truth-telling and lying were collected independently. Using Multivoxel pattern analysis, we were able to decode truth-telling versus lying with a balanced difficulty level. Results showed that the angular gyrus (AG), inferior frontal gyrus (IFG), and postcentral gyrus could differentiate lying from truth-telling. Critically, linear classifiers trained to distinguish instructed truthful and deceptive responses could correctly differentiate spontaneous truthful and deceptive responses in AG and IFG with above-chance accuracy. In addition, with a leave-one-participant-out analysis, multivoxel neural patterns from AG could classify if the left-out participant was lying or not in a trial. These results indicate the commonality of neural responses subserved instructed and spontaneous deceptive behavior as well as the feasibility of cross-participant deception validation.

---

### The interpretation of clinical trial data – wrongly ACCLAIM' ed? [^1111582B]. American Heart Journal (2009). Low credibility.

Advances in medicine continue to drive forward through the practice of often impressive and innovative investigation. Through the application of randomized clinical trials, statistical analyses deliver the notorious "P values" to provide evidence of whether an intervention results in the desired clinical effect. However, it would appear that it is becoming increasingly common for trial reports to "cheat" the statistical system, particularly when lucrative industrial reward might be at stake. Fortunately, there is a safety net in place for the clinician who is less well accustomed to critiquing the research manuscript. In the United States, the Food and Drug Administration rigorously analyzes evidence relating to safety and efficacy of new therapies before approving them for general use. In Europe, the European Medicines Agency provides a similar service. Yet of much concern, there appears to be clear differences over the respective level of scrutiny of clinical trial data. This article discusses the unease of how a flawed international trial report appeared to deceive the European Union into approving a device-based product for chronic heart failure despite an important lack of credible data.

---

### Association between financial incentives and participant deception about study eligibility [^116no3cx]. JAMA Network Open (2019). High credibility.

Conclusions

Ethical concerns about undue influence have dominated discussions about payment for research participation, but investigators and IRBs also should be aware of the potential for payment to interfere with a study's scientific integrity and participant protections. Our study found that as many as 10.5% to 22.8% of ineligible participants were motivated to deceive about their eligibility to enroll in an online survey to secure payment, although higher rates of payment were not associated with higher rates of deception. Because offering payment can be an important and ethical tool for recruiting, retaining, and fairly compensating participants, we caution against responding to these findings by eliminating or reducing offers of payment. Instead, it is necessary to develop, test, and implement comprehensive alternative approaches to minimize the likelihood of participant deception.

---

### Heart rythm society expert consensus statement on electrophysiology laboratory standards: process, protocols, equipment, personnel, and safety [^116shUQV]. Heart Rhythm (2014). Medium credibility.

Clinical research studies during clinical procedures require prioritizing patient welfare, noncoercive recruitment, adequate consent time, independent oversight, and honest reporting: Clinical research, however, exposes patients to some risk without proven direct benefit; as a researcher, the operator's primary responsibility is generating knowledge, whereas as a physician, the operator's primary responsibility is the well-being of the patient, and when there is a conflict between these two roles, the role of the physician must override the role of the researcher; patients should be considered for a research protocol if they are looking for improved outcomes compared with those of current therapies, recruitment of patients should be carried out in a manner that does not coerce participation, and the opportunity for participation should be presented to all patients fulfilling inclusion and exclusion criteria even if the attending physician does not believe that the patient is an ideal candidate; a necessary amount of time should be given to informed consent in sufficient advance so the patient is not unduly pressured, and when children or adults unable to consent are considered, it may be helpful to have an independent advocate; the protocol must have scientific merit with an adequate likelihood of success as well as an expectation of social benefit, all research protocols performed in the EP laboratory must be reviewed and approved by an independent group, such as an institutional review board, and results must be reported honestly.

---

### Participatory approaches should be used to address the ethics of social media experiments [^115uU2wk]. Communications Psychology (2025). Medium credibility.

The problems in current ethical practices

Typically, psychological research within an academic setting that involves human participants is evaluated by an ethics committee, also known as institutional review boards (IRB) — unlike in industry. However, these traditional evaluators of ethics have struggled to keep pace with the rapid innovations in software and experimental designs developed for social media field experiments, leaving ethical boundaries blurred and dilemmas unresolved.

The general principles enforced by IRBs (e.g. minimisation of harm) straightforwardly apply to traditional laboratory experiments, but this is not the case for experiments conducted on active social media platforms. In social media contexts, issues like deception, consent, and real-time intervention are especially difficult to navigate. While some issues have been addressed (e.g. IRBs rightly do not view user acceptance of a platform's terms of service as informed consent to participate in an experiment), many other difficulties remain. For example, consider an experiment on the efficacy of an intervention to reduce toxic language on social media that uses automated accounts posing as humans to expose users to certain content. Should this deception be declared as a potential harm? Or, should deception via automated accounts be accepted as a regular occurrence online? And to what lengths should researchers go to ensure their online interventions do not exacerbate or introduce new vulnerabilities?

The current model suffers from a misalignment of interests. Researchers' interests in generating valuable data often conflict with the interests of social media users, who prioritise informed consent and autonomy, and the platforms, which are motivated by business goals and data monetisation. Where a researcher might argue that potential harms imposed by their experiment are commonplace on social media and outweighed by the potential impact of their research findings, the users involved in that same study may disagree and place a greater value on informed consent than potential research impact. Moreover, if the researcher collaborates with the involved platform, which has an interest in producing findings that portray the platform in a positive light, a conflict of interest can arise and open a door to industry capture of academic research if this is not explicitly declared. A further discussion of this can be found in the recent critique surrounding a high-profile Science paper, which counted former Meta employees as co-authors and suggested Facebook's algorithm plays little role in driving political polarisation — whilst failing to declare that the platform implemented 63 changes to the algorithm during the experiment that were specifically geared towards reducing harmful content.

---

### Deception studies manipulating centrally acting performance modifiers: a review [^112uCSsP]. Medicine and Science in Sports and Exercise (2014). Low credibility.

Athletes anticipatorily set and continuously adjust pacing strategies before and during events to produce optimal performance. Self-regulation ensures maximal effort is exerted in correspondence with the end point of exercise, while preventing physiological changes that are detrimental and disruptive to homeostatic control. The integration of feedforward and feedback information, together with the proposed brain's performance modifiers is said to be fundamental to this anticipatory and continuous regulation of exercise. The manipulation of central, regulatory internal and external stimuli has been a key focus within deception research, attempting to influence the self-regulation of exercise and induce improvements in performance. Methods of manipulating performance modifiers such as unknown task end point, deceived duration or intensity feedback, self-belief, or previous experience create a challenge within research, as although they contextualize theoretical propositions, there are few ecological and practical approaches which integrate theory with practice. In addition, the different methods and measures demonstrated in manipulation studies have produced inconsistent results. This review examines and critically evaluates the current methods of how specific centrally controlled performance modifiers have been manipulated, within previous deception studies. From the 31 studies reviewed, 10 reported positive effects on performance, encouraging future investigations to explore the mechanisms responsible for influencing pacing and consequently how deceptive approaches can further facilitate performance. The review acts to discuss the use of expectation manipulation not only to examine which methods of deception are successful in facilitating performance but also to understand further the key components used in the regulation of exercise and performance.

---

### Deception of children in research [^116F59My]. Journal of Medical Ethics (2015). Low credibility.

The aim of this article is to draw attention to an under-recognised but ethically important phenomenon involving the deception of children in research. The type of deception we are referring to is not planned deception that is part of the research design. Instead it is deception that occurs in individual cases where parents ask researchers not to reveal something about the research to their child. Our focus is children who do not have ultimate decisional authority — children around the ages of 7–14 years old who may have the cognitive capacity to understand but not to consent for themselves; children whose agreement is required but not sufficient to authorise research. We provide three illustrative scenarios for analysis. Then, we identify circumstances in which non-disclosure might be justified and set out reasons why providing information to non-competent children is ethically required. On this basis, we argue that non-planned deception requested by parents is very unlikely to be ethically acceptable. Finally, we recommend that guidelines should (a) require researchers to consider what to do if parents do not want to disclose information to a child and (b) clarify that the most ethical response is to simply not include that child in the research.

---

### Neurofeedback as placebo: a case of unintentional deception? [^1132Wobh]. Journal of Medical Ethics (2022). Medium credibility.

The use of placebo in clinical practice has been the topic of extensive debate in the bioethics literature, with much scholarship focusing on concerns regarding deception. While considerations of placebo without deception have largely centred on open-label placebo, this paper considers a different kind of ethical quandary regarding placebo without an intent to deceive-one where the provider believes a treatment is effective due to a direct physiological mechanism, even though that belief may not be supported by rigorous scientific evidence. This is often the case with complementary and alternative medicine (CAM) techniques and also with some mainstream therapies that have not proven to be better than sham. Using one such CAM technique as a case study-electroencephalography (EEG) neurofeedback for attention-deficit/hyperactivity disorder (ADHD)-this paper explores the ethics of providing therapies that may have some beneficial effect, although one that is likely due to placebo effect. First, we provide background on EEG neurofeedback for ADHD and its evidence base, showing how it has proven to be equivalent to-but not better than-sham neurofeedback. Subsequently, we explore whether offering therapies that are claimed to work via specific physical pathways, but may actually work due to the placebo effect, constitute deception. We suggest that this practice may constitute unintentional deception regarding mechanism of action. Ultimately, we argue that providers have increased information provision obligations when offering treatments that diverge from standard of care and we make recommendations for mitigating unintentional deception.

---

### Detecting spontaneous deception in the brain [^1146j683]. Human Brain Mapping (2022). Medium credibility.

1 INTRODUCTION

Deception is a complex cognitive activity that usually occurs when people attempt to convince others to accept incorrect beliefs. Deception could come in many different forms, such as outright lies, exaggerations, omissions, and subtle lies (DePaulo, Kashy, Kirkendol, Wyer, & Epstein; Vrij, Edward, Roberts, & Bull,), and it affects various aspects of life, including politics, marketing, and personal relationships. Given that human society is trust‐based, deception may hamper communication and destroy the relationship, leading to negative consequences such as loss of property and sometimes even life. Therefore, deception detection has attracted researchers' attention for decades and human society has long sought scientific methods for detecting deceptive behaviors.

Polygraph is one of the pioneering techniques in measuring peripheral responses such as blood pressure, pulse rate, respiration, and electrodermal responses (Lykken; Saxe, Dougherty, & Cross). However, the use of polygraphs could be problematic, since measured physiological responses tend to correlate closely with emotional reactions like anger, fear, and anxiety. These unspecified responses may not necessarily be associated with lying behavior under real‐world interrogations, which can result in false positives in deception detection (Steinbrook).

Over time, the traditional measures have been supplemented by electroencephalographic (EEG) and functional magnetic resonance imaging (fMRI). Prior fMRI studies on deception fall into two categories. On the one hand, researchers have been focusing on detecting deception in each and every individual. For instance, indexed by whole‐brain resting‐state functional connectivities (RSFC), a prior study demonstrated that brain networks involving executive controlling (dorsolateral prefrontal cortex, middle frontal cortex, and orbitofrontal cortex), social and mentalizing (the temporal lobe, temporo‐parietal junction, and inferior parietal lobule), and reward (putamen and thalamus) could predict participants' deceptive behaviors in an independent task (Tang et al.). Also, it has been demonstrated that within a single individual, lying can be differentiated from truth‐telling with an accuracy of 78% (Langleben et al.). All aforementioned works demonstrated the values of the utilization of fMRI in distinguishing deceptive from truthful responses.

---

### Association between financial incentives and participant deception about study eligibility [^1168aqjK]. JAMA Network Open (2019). High credibility.

Key Points

Question

Is payment associated with participant deception about research eligibility and, if so, is higher payment associated with more deception?

Findings

In this randomized survey experiment of a nationally representative sample of 2275 US adults, offers of payment to participate in an online survey were associated with substantial deception by participants about their eligibility compared with the control condition, with estimated proportions of ineligible individuals who engaged in deception ranging from 10.5% to 22.8%. Larger payments were not associated with increased rates of deception.

Meaning

Payment may be associated with deception about eligibility for study participation, but higher payment may not lead to higher rates of deception.

---

### When should global health actors prioritise more uncertain interventions? [^116XBaTd]. The Lancet: Global Health (2023). High credibility.

Notably, Karnofsky's argument for supporting interventions with more certain cost-effectiveness estimates hinges on an empirical claim: that sceptical prior beliefs are warranted. But this claim does not apply equally in all areas: in some arenas, uncertain interventions more reliably prove effective, and more optimistic prior beliefs might be indicated. For instance, new vaccines are ten times more likely than new cancer drugs to progress from phase 1 trials to approval. At a minimum, the consistently superior performance of some types of interventions or organisations means that differing degrees of scepticism are warranted, depending on the intervention being considered. For some disease areas or intervention types, cost-effectiveness estimates for uncertain interventions should probably not be tempered by sceptical prior beliefs. For global health actors to determine when scepticism is warranted can be challenging, yet they can attempt to do so by, for instance, considering how similar interventions within a given arena have done. Because global health actors often focus on specific diseases (eg, malaria) or intervention types (eg, immunisations), and repeatedly partner with the same organisations, they might be well positioned to make these assessments.

Assuming global health actors can identify these patterns, and can do so reliably, actors in areas where uncertain interventions have performed just as well as more certain ones have no reason to prioritise more certain interventions. Indeed, in these areas, organisations might forgo expected health benefits by favouring more certain interventions.

Will valuable information be gained?

Askell acknowledges the merit of Karnofsky's argument, writing "a skeptical prior about interventions will cause us to have a lower estimate of the effectiveness of an intervention that lacks evidential support". However, putting aside this instrumental justification for supporting more certain interventions, Askell suggests that "all else being equal, we should expect to derive more value from investing in interventions for which we have less evidential support".

When the expected values of two interventions are comparable, Askell argues that there is no reason to prefer the more certain one, as across many interventions, the predicted value of the interventions will tend to approach the true value of those interventions. As a result, choosing interventions with the greatest expected value will, across time, maximise cost-effectiveness. When donors place prima facie value on certainty, they sacrifice health gains they might otherwise have reaped.

---

### Ethical issues in schizophrenia research: a commentary on some current concerns [^112vLqbq]. Schizophrenia Bulletin (2006). Low credibility.

An essential aspect of research on schizophrenia is ensuring that worthwhile scientific studies are done in a way that does not place vulnerable individuals at unreasonable risk. It is important to educate researchers, advocates, potential participants, reviewers, IRBs, and the general public about ethical principles and controversial issues as they impact research on schizophrenia. Federal regulations mandate IRB consideration of "the special problems of research involving… mentally disabled persons… " (45CFR46.111a3). In recent years, there has been a greater focus on subject monitoring to improve safeguards and minimize risks. The process of informed consent is also going through a process of evolution, in order to help ensure that participants are as aware as possible of key aspects of a study, including risks, benefits, alternatives, purpose and design, etc. We focus here on a few of the issues that are current, are relevant to schizophrenia research, and merit additional empirical study. They include medication discontinuation and placebo control designs, compensation for participation, and capacity to consent.

---

### Recommendations for the appropriate structure, communication, and investigation of tobacco harm reduction claims. An official American Thoracic Society policy statement [^1151CrfF]. American Journal of Respiratory and Critical Care Medicine (2018). Medium credibility.

Tobacco harm reduction research — risk assessment, consent, and fairness are emphasized: "Hazards of prospective population-based evaluations of tobacco harm reduction strategies may qualify as 'greater than minimal risk'. Care should be taken to assess research risks in comparison to current standards of care for reducing harm among people already weary or unwilling to quit, rather than in comparison to the no-intervention condition". "Harm reduction researchers must protect the autonomy of research subjects by discussing the unique nature of the risks of such research with those subjects and by promoting their individual understanding". Autonomy is specified as when participants "have the capacity to understand the risks they are assuming, are given the information necessary to achieve that understanding, have their understanding verified by a researcher qualified to make such an assessment, and consent voluntarily to assume the risks of the research". Unknown risks "must be included in the informed consent discussion", and "the long-term risks of harm reduction methods are not yet fully known — a fact that must be disclosed during the consent process". The policy cautions that "Human subjects may be vulnerable to coercion" and assigns a "particular responsibility of harm reduction investigators to avoid overemphasizing known benefits or minimizing unknown risks", and directs that "Harm reduction researchers should protect research subjects from unforeseen or tragic consequences of their research through fair methods that promote just outcomes", with fairness described as "a uniform process" promoting "the equitable distribution of benefits and harms".

---

### Frequency and reasons for outcome reporting bias in clinical trials: interviews with trialists [^11389pzP]. BMJ (2011). Excellent credibility.

Discussion

Researchers have a moral responsibility to report trial findings completely and transparently. Failure to communicate trial findings to the clinical and research community is an example of serious misconduct. Previous research has shown that non-publication of whole studies or selected results is common, but there has been little previous research into the awareness among researchers of their responsibilities to publish fully their research findings or of the possible harm associated with selective publication.

Principal findings

When comparing the trial protocol with the subsequent publication, we carefully distinguished the cases where an outcome was measured and analysed but not reported, measured but not analysed or reported, and not measured. There are two key messages from our work. Firstly, most unreported outcomes were not reported because of a lack of a significant difference between the trial treatments, thus leading to an overoptimistic bias in the published literature as a whole. However, we believe that non-reporting mainly reflected a poor understanding of how any individual trial forms part of the overall evidence base, rather than intentional deception. Secondly, from the reasons given for outcomes being either measured but not analysed or not measured, there was a general lack of clarity about the importance and feasibility of data collection for the outcomes chosen at the time of protocol development.

We identified one study, however, in which the trialists intentionally chose to withhold data on a statistically significant increase in harm associated with the trial intervention. This type of "distorted reporting" in relation to adverse events has been previously described. The reported findings from the trial were published in a prestigious journal, and since publication the paper has been cited by others on a number of occasions. We have strongly encouraged the trialist to make these unreported results publicly available.

We identified an apparent over reliance on the arbitrary but widely used cut off of 0.05 to distinguish between significant and non-significant results. In many cases trialists described subdividing P values into "significant" and "non-significant", and deciding to not report "non-significant" results. Yet statistically significant results may not always be clinically meaningful. Likewise an observed difference between treatment groups might be clinically important, yet fail to reach statistical significance. Whether or not a finding is reported should not depend on its P value.

---

### The neurobiology of deception: evidence from neuroimaging and loss-of-function studies [^111c6qoJ]. Current Opinion in Neurology (2009). Low credibility.

Purpose Of Review

Visualization of how the brain generates a lie is now possible because of recent conceptual and technical advances in functional neuroimaging; this has led to a rapid increase in studies related to the cognitive neuroscience of deception. The present review summarizes recent work on the neural substrates that underlie human deceptive behavior.

Recent Findings

Functional neuroimaging studies in healthy individuals have revealed that the prefrontal cortex plays a predominant role in deception. In addition, recent evidence obtained from loss-of-function studies with neuropsychological investigation and transcranial direct current stimulation has demonstrated the functional contribution of the prefrontal cortex to deception. Other research into the relationship between deception and the brain has focused on the potential use of functional MRI for lie detection, neural correlates of pathological lying, and brain mechanisms underlying inference of deceit by others.

Summary

Converging evidence from multiple sources suggests that the prefrontal cortex organizes the processes of inhibiting true responses and making deceptive responses. The neural mechanisms underlying various other aspects of deception are also gradually being delineated, although the findings are diverse, and further study is needed. These studies represent an important step toward a neural explanation of complex human deceptive behavior.

---

### Research in critically ill patients: standards of informed consent [^111JnReP]. Critical Care (2007). Low credibility.

Patients in critical care lose their capability to make a judgement, and constitute a 'vulnerable population' needing special and reinforced protection. Even if the standard of informed consent is an essential way of demonstrating respect for the patient's autonomy, the usual informed-consent procedure is not as applicable as required or sufficient to warrant this ethical principle in critical care.

---

### Ethics in clinical research [^111ibJcy]. Journal of Hepatology (2009). Low credibility.

R&D of new drugs is driven by pharmaceutical companies that invest considerable amounts of money for this purpose. This may introduce bias, to emphasize the clinical value of drugs to be allowed onto the market. Bias is caused by methodological flaws including the population under study, the choice of inadequate comparators or of their dosage, the adoption of surrogate or composite endpoints, the decision to publish mainly positive findings or to overlook some safety concerns, etc. All this happens in a legal context that requires no added value for new drugs to be approved for the market. This encourages the use of placebo even when active comparators are available, or the search for non-inferiority of new products in comparison with active comparators. Superiority over placebo and non-inferiority to active comparators may allow drugs onto the market that are in fact less active (or safe, tolerable, convenient, etc.) than those already available, usually with consolidated properties and lower costs. In addition, they do not meet patients' or physicians' needs of defining the place in therapy and respective roles of new and available treatments. The current legislative and regulatory setting seems designed to meet commercial interests rather than public health needs.

---

### Inclusion of authorized deception in the informed consent process does not affect the magnitude of the placebo effect for experimentally induced pain [^116D7iZ9]. Pain (2010). Low credibility.

The ethics of placebo research have been of paramount concern since the discovery of the phenomenon. To address these ethical concerns, Miller and colleagues (PLoS Med 2005 Sep;2(9):e262, 0853–0859) propose an alternate approach to placebo research, called "authorized deception", in which participants are alerted of the use of deception in the research prior to study enrollment and thus knowingly permit its use if they decide to participate. The present study sought to investigate the authorized deception methodology in experimentally induced placebo analgesia. The participants were randomly assigned to an authorized deception or non-authorized deception group. A commonly used protocol was employed wherein heat pain stimulation was surreptitiously lowered following the application of a placebo cream during a series of conditioning trials and the magnitude of the placebo effect was subsequently assessed in test trials for which the stimulus intensity was the same for both the placebo and control creams. Authorized deception did not have any negative impact on the magnitude of the placebo effect, recruitment and retention of participants, nor did it result in any significant psychological harm. The majority of participants who received this form of consent preferred it to the traditional approach in which the participants are not alerted to the presence of deception. These findings suggest that the use of authorized deception is a viable and ethically preferable alternative consent process for laboratory-based studies on placebo analgesia. Further studies are needed to examine the effect of authorized deception in clinical trials and other placebo research within a clinical setting.

---

### Association between financial incentives and participant deception about study eligibility [^1139WpUx]. JAMA Network Open (2019). High credibility.

Limitations and Research Agenda

The primary limitation of our study is that it was conducted in the context of a survey relying on self-reported eligibility; therefore, it cannot directly answer questions about the possibility and influence of payment-induced deception in the clinical trial context. In addition, there was no comparison of responders (59.4%) with nonresponders, which may limit generalizability of these findings. In contrast to some clinical trials that may entail high levels of burden and risk, participants in this brief online survey were asked to undertake little burden and no risk for proportionately high payment. They could also engage in deception without fear of being caught or of incurring physical risk by evading eligibility criteria intended to protect them. It is unclear whether clinical trial participants will be more inclined to deceive as a result of typically higher offers of payment in that setting or less inclined given greater potential consequences for themselves or investment in the outcome of the research.

Our study design cannot rule out the possibility that reported rates of recent influenza vaccination varied according to the eligibility criteria not as a result of payment-associated deception but rather as a result of participant desire to report eligibility in a way that would assist researchers (a social desirability or "helpfulness" bias). However, there is no evidence to suggest that individuals are eager to participate in research for which they are not eligible in the absence of incentive payments.

Another limitation is that we tested only 3 payment levels, which could obscure signals that may have become evident by evaluating more payment amounts at tighter increments. In addition, our assessment of whether payment was associated with different information provided by research participants after deception about eligibility was limited to an exploratory measure based on a small number of additional questions regarding vaccine attitudes not validated for that particular purpose.

One pressing research need is to replicate these findings among participants in clinical trials that have some self-reported criteria for initial and continuous eligibility. Further research is also needed to understand whether a dose-response relationship between payment amount and deception rates might be seen in other contexts or at different amounts, as well as to systematically assess the downstream influence of the inclusion of individuals in research who were deceptive about their eligibility. As further data are developed, research evaluating the effectiveness of approaches to minimize payment-induced deception will also be important.

---

### Deception, intention and clinical practice [^111QJUrN]. Journal of Medical Ethics (2023). Medium credibility.

Regarding the appropriateness of deception in clinical practice, two (apparently conflicting) claims are often emphasised. First, that 'clinicians should not deceive their patients'. Second, that deception is sometimes 'in a patient's best interest'. Recently, Hardman has worked towards resolving this conflict by exploring ways in which deceptive and non-deceptive practices extend beyond consideration of patients' beliefs. In short, some practices only seem deceptive because of the (common) assumption that non-deceptive care is solely aimed at fostering true beliefs. Non-deceptive care, however, relates to patients' non-doxastic attitudes in important ways as well. As such, Hardman suggests that by focusing on belief alone, we sometimes misidentify non-deceptive care as 'deceptive'. Further, once we consider patients' beliefs and non-doxastic attitudes, identifying cases of deception becomes more difficult than it may seem. In this essay, I argue that Hardman's reasoning contains at least three serious flaws. First, his account of deception is underdeveloped, as it does not state whether deception must be intentional. The problem is that if intention is not required, absurd results follow. Alternatively, if intention is required, then identifying cases of deception will be much easier (in principle) than Hardman suggests. Second, Hardman mischaracterises the 'inverse' of deceptive care. Doing so leads to the mistaken conclusion that common conceptions of non-deceptive care are unjustifiably narrow. Third, Hardman fails to adequately separate questions about deception from questions about normativity. By addressing these issues, however, we can preserve some of Hardman's most important insights, although in a much simpler, more principled way.

---

### Restoring invisible and abandoned trials: a call for people to publish the findings [^112Nqcq1]. BMJ (2013). Excellent credibility.

Well designed and well performed randomised controlled trials are considered to provide the most reliable evidence on the effects of health related interventions. However, the credibility of findings from individual trials and from summaries of trials examining a similar research question (that is, systematic reviews and meta-analyses) has been undermined by numerous reporting biases in the published medical literature. Reporting biases are often difficult to detect, but have the potential to discredit earnest efforts towards evidence based decision making.

Two basic problems of representation are driving growing concerns about relying on published research to reflect the truth. The first is no representation (invisibility), which occurs when a trial remains unpublished years after completion. The second is distorted representation (distortion), which occurs when publications in medical journals present a biased or misleading description of the design, conduct, or results of a trial. Both go against the fundamental scientific and ethical responsibility that all research on humans be used to advance knowledge and are symptomatic of a general culture of data secrecy. The end result is that the healthcare, biomedical research, and policy communities may, despite best intentions and best practices, end up drawing scientifically invalid conclusions based on only those parts of the evidence base they can see.

---

### An official multi-society statement: the role of clinical research results in the practice of critical care medicine [^115BGrLh]. American Journal of Respiratory and Critical Care Medicine (2012). Medium credibility.

Factors beyond study design and execution that may make clinical research compelling to clinicians include biologic plausibility; confirmatory replication; consistency with other clinical or experimental results; low cost; ease of implementation (including local availability, acceptance, and technical expertise); large effect size; generalizability/applicability to one's own patient population; high value outcomes meaningful to patients; objectivity with lack of conflicts of interest; alignment with prior knowledge/belief; safety with low risk of significant harm; and rapid time to effect.

---

### Characteristics of clinical trials associated with appeal and return on investment to participants: a review and framework [^115LWSP7]. The Oncologist (2025). Medium credibility.

Lastly, the control group on a clinical trial could alter the perception of appeal or return on investment from trial participation. For instance, control arms that do not mirror current standard treatments can potentially subject control group patients to suboptimal care, while casting doubt on the real advantages for patients in the experimental group. Although the Food and Drug Administration (FDA) generally requires studies to employ what is considered the standard of care at the initiation of the study, that standard can change over the course of the study, sometimes leading to a control arm that was demonstrated to be inferior to an approach approved after the study was initiated. Placebo, while uncommon in cancer clinical trials, can be administered if there is no clear standard of care at the time in which the study is being conducted.

Investigated agent and subsequent approval

The return on investment to participants from receiving a particular investigational agent in a clinical trial is easier to assess retrospectively, as it is dependent on the agent's efficacy, which is determined after the trial concludes. However, when therapies are already approved in a different tumor type or treatment setting, these could be considered as potentially more promising, and as such could be assessed in a prospective fashion (Figure 3).

Figure 3.
Pros and cons of different classes of investigational agents by retrospective analysis in clinical Trials. Arrow from left to right indicates classes of agents with less perceived value (left) to higher perceived value (right). For each class of agent, pros and cons of participation in a study based on retrospective assessment of the agent from a participant perspective is shown.

First-in-class drugs are pharmaceutical agents with novel mechanisms of action that are thought to be innovative and can lead to unprecedented patient outcomes.

One of the potential appeals of participating in trials is the ability to access innovative, first-in-class drugs. While these agents could be revolutionary and lead to changes in the standard of care, there is often minimal data regarding safety and efficacy at the time in which they are being studied. On the other hand, agents that improve upon previously available ones or that are already proven effective in other indications may have a similar mechanism of action and therapeutic indications as first-in-class agents, but are designed to enhance the efficacy and/or tolerability of existing drugs. As such, participating in studies evaluating such agents could lead to significant patient benefits with potentially less uncertainty about the potential efficacy and toxicity, and would allow to evaluate the appeal of the agent in a prospective fashion.

---

### Study registration: encouraging the practice of hypothetical-deductive research in the journal [^111CvrFG]. Journal of the American Academy of Child and Adolescent Psychiatry (2018). Low credibility.

Earlier this year, we shared with you our commitment to supporting the dissemination of research that is well designed, carefully conducted, and properly interpreted, and our belief that authors, reviewers, editors, publishers, and readers should jointly strive to ensure the integrity of the science that we publish. 1 Toward this end, we are pleased to announce a new submission type beginning in 2019: Registered Reports.

---

### The need for change in generating evidence for the critically ill [^117XHeTP]. American Journal of Respiratory and Critical Care Medicine (2023). Medium credibility.

The high stakes of critical illness (i.e. a high risk of dying) should not alone exclude a pragmatic trial from being considered minimal research risk. Even trials whose primary outcome is death could be considered to add little or no research risk if sufficient safeguards to ensure that randomized allocation of the study intervention is compatible with genuine, independent clinical decisions made for the sake of patients. Such strategies have successfully been applied in critical care and emergency settings. The safeguards for ensuring independent judgment, free from undue influence to enroll a patient, would be especially important for maintaining trust in the system. Funders such as the National Institutes of Health could sponsor the development of a rigorous consensus framework of safeguards for pragmatic trials that would allow such studies to be conducted with alterations or waivers of informed consent and would align with the strategy to concentrate efforts on more inclusive trials.

---

### Unintentional deception still deceives [^111iyAxw]. Journal of Medical Ethics (2023). Medium credibility.

In my recent article, Pretending to care, I argue that a better understanding of non-doxastic attitudes could improve our understanding of deception in clinical practice. In an insightful and well-argued response, Colgrove highlights three problems with my account. For the sake of brevity, in this reply I focus on the first: that my definition of deception is implausible because it does not involve intention. Although I concede that my initial broad definition needs modification, I argue that it should not be modified by involving intention but by involving responsibility.

---

### Current sample size conventions: flaws, harms, and alternatives [^114duArX]. BMC Medicine (2010). Low credibility.

Background

The belief remains widespread that medical research studies must have statistical power of at least 80% in order to be scientifically sound, and peer reviewers often question whether power is high enough.

Discussion

This requirement and the methods for meeting it have severe flaws. Notably, the true nature of how sample size influences a study's projected scientific or practical value precludes any meaningful blanket designation of < 80% power as "inadequate". In addition, standard calculations are inherently unreliable, and focusing only on power neglects a completed study's most important results: estimates and confidence intervals. Current conventions harm the research process in many ways: promoting misinterpretation of completed studies, eroding scientific integrity, giving reviewers arbitrary power, inhibiting innovation, perverting ethical standards, wasting effort, and wasting money. Medical research would benefit from alternative approaches, including established value of information methods, simple choices based on cost or feasibility that have recently been justified, sensitivity analyses that examine a meaningful array of possible findings, and following previous analogous studies. To promote more rational approaches, research training should cover the issues presented here, peer reviewers should be extremely careful before raising issues of "inadequate" sample size, and reports of completed studies should not discuss power.

Summary

Common conventions and expectations concerning sample size are deeply flawed, cause serious harm to the research process, and should be replaced by more rational alternatives.

---

### SPIRIT 2025 explanation and elaboration: updated guideline for protocols of randomised trials [^115XURKP]. BMJ (2025). Excellent credibility.

Explanation

The ethical and scientific justification for a trial depends on the uncertainty of the benefit or harm of the intervention to be tested. This uncertainty depends in turn on what is known on the topic before the trial commences. The background section of a protocol should summarise the relevance of the research question, justify the need for the trial in the context of available evidence, and present any available preliminary data on the potential effects of the interventions (benefits and harms), thus reporting a rationale for the trial.

This information is particularly important to the trial participants as it provides motivation for contributing to the trial. It is also relevant to funders, research ethics committees or institutional review boards, and other groups who evaluate the scientific and ethical basis for trial approval. The background should also present a plausible explanation of how the intervention might work. Understanding the rationale or theory underpinning an intervention helps readers to understand which aspects or components are likely to be essential to its efficacy or harm, and which are likely to be incidental.

Reviews of two samples of 108 and 292 trial protocols from 2016 found that 44% and 26%, respectively, justified the research question.

The World Medical Association's Declaration of Helsinki states that biomedical research involving people should be based on a thorough knowledge of the scientific literature, as it is unethical to expose humans unnecessarily to the risks of research. To place the trial in the context of available evidence, it is strongly recommended that an up-to-date, systematic review of relevant trials be summarised and cited in the protocol, or, in the absence of a published review, that the protocol authors systematically identify and summarise previous trials. This evidence can also help researchers to optimise the usefulness of the new trial by informing design aspects such as outcome definition and sample size.

Several funders request this background information in grant applications. Failure to review the cumulative evidence can lead to unnecessary and wasteful duplication of researchor to trial participants being deprived of effective interventions or exposed to harmful interventions. Previous reviews of trial protocols have found that many do not cite the systematic reviews or trials that exist on the same topic.

Summary of key elements to address

Importance of the research question
Why a new trial is needed in the context of available evidence: explanation of how the intervention might work; pretrial evidence of the benefits and harms of the interventions; and reference to systematic review(s) of relevant trials; if none is available, a summary of relevant trials based on a systematic search.

Item 9b: Explanation for choice of comparator

---

### Characteristics of clinical trials associated with appeal and return on investment to participants: a review and framework [^111b4NeN]. The Oncologist (2025). Medium credibility.

Experimental design

Figure 2 shows an overview of different issues regarding the study design.

Figure 2.
Key components of study design in assessing appeal or return on investment. The first column outlines the primary study design elements. The second column outlines the description of each study design component. The third column notes features of greater perceived value shown at the top and lesser perceived shown at the bottom.

Certain aspects of the experimental design of a trial could make it more or less appealing or provide a higher return on investment. Randomization, which reduces the selection bias between study arms, introduces the possibility — often a 50% chance — that participants may not receive the novel agent being tested. From a scientific perspective, randomization is one of the methodological pillars of well-designed clinical trials, but is only ethical in a setting where equipoise as to which treatment is better can be reasonably determined to apply. Studies show that patients frequently view the prospect of being randomized to a control arm in a clinical trial as potentially harmful. Aversion to randomization has been reported as one of the primary reasons for trial participation refusal in various studies.

As a crossover would eventually allow a patient on the control arm access to the investigational agent, this could be considered a positive attribute of a randomized clinical trial. When the investigational agent is already approved, crossover in a clinical trial would be the already established standard of care. A clinical trial that incorporates crossover upon progression could help ease the fear of randomization as participants would have confidence that they will receive the experimental agent during the course of their disease. Of note, although crossover can be a positive attribute from a patient's perspective, frequently participants are not eligible to crossover based on worsening of laboratory values or clinical condition while the patient is receiving control arm therapy.

While blinding safeguards against potential biases, the uncertainty associated with blinding may generate discomfort or dissatisfaction, particularly for individuals who value transparency in their medical care. Qualitative evidence has shown that blinding can lead to patient concerns about potential side effects or adverse reactions, as patients are not fully informed about the specific treatment they are receiving, resulting in heightened anxiety or apprehension, especially when patients are unable to anticipate or understand the potential outcomes of their treatment.

---

### Bayesian analysis of the effect of transcranial direct current stimulation on experimental pain sensitivity in older adults with knee osteoarthritis: randomized sham-controlled pilot clinical study [^1132FrgC]. Journal of Pain Research (2018). Low credibility.

Bayesian inference has demonstrated the utility for decision-making in the context of continuing investigation into treatment effects found in pilot trials. Vague, neutral priors (~Normal(µ = 0, σ² = 1 × 10⁶)) were used to maximize the influence of the present data on posterior probabilities. The focus of the present Bayesian analysis is to provide the probability that the alternative hypothesis is true. Disparate researchers might identify different posterior probabilities that constitute a meaningful likelihood of an effect existing. Such probabilities should be based on the specific research context and investigator domain knowledge, rather than using a monolithic cutoff value as in frequentist inference. In the present study, a posterior probability ≥ 75% that an effect of treatment exists was considered to merit further consideration. This value was chosen for its consistency with previous probability thresholds chosen a priori in the similar context of existing medication trials.–In our scientific and clinical opinion, the current research would be worth pursuing if there was a 3/4 chance that our alternative hypothesis was correct. Higher or lower probabilities might serve as better cutoffs depending on the potential risks or benefits associated with a given intervention. For instance, we might argue that a posterior probability of 66% is warranted if the intervention provides some benefit for an otherwise fatal disorder for which no effective treatment exists. Each individual presented with the present alternative hypothesis must ascertain whether a 75% chance of benefit as defined here warrants further investigation.

While a comprehensive account of Bayesian vs frequentist inference is beyond the scope of the present article, additional details regarding the difference between the Bayesian posterior probability and the frequentist P -value merit further discussion. A null hypothesis test at the frequentist P ≤ 0.05 level evaluates the probability of observing the current data, or data more extreme, given that the null hypothesis is true. The Bayesian posterior probability is the probability that the alternative hypothesis is true, given the data. These describe qualitatively different issues: the first attempts to reject the null hypothesis, while the latter estimates the probability of the alternative hypothesis. This is important because it reveals that the P -value is not the complement of the posterior probability; that is, posterior probability is not equivalent to 1 − P-value (75% posterior probability ≠ 0.25 P-value).

---

### Evaluation, treatment, and prevention of vitamin D deficiency: an endocrine society clinical practice guideline [^11417Mw1]. The Journal of Clinical Endocrinology and Metabolism (2011). Medium credibility.

Regarding diagnostic investigations for vitamin D deficiency, more specifically with respect to vitamin D measurement, ES 2011 guidelines recommend to do not obtain serum 1, 25-dihydroxyvitamin D assay for the evaluation of vitamin D status in patients at risk for vitamin D deficiency.

---

### Deception is associated with reduced social connection [^115YrsGD]. Communications Psychology (2023). Medium credibility.

Lies can have major consequences if undetected. Research to date has focused primarily on the consequences of deception for receivers once lies are discovered. We advance deception research and relationship science by studying the social consequences of deception for the sender — even if their lies remain undetected. In a correlational study of video conversations (Study 1; N = 776), an experimental study of text conversations (Study 2; N = 416), and a survey of dispositional tendencies (Study 3; N = 399), we find consistent evidence that people who lie tend to assume that others are lying too, and this impedes their ability to form social connections. The findings provide insight into how (dis)honesty and loneliness may go together, and suggest that lies — even when undetected — harm our relationships.

---

### Big tobacco focuses on the facts to hide the truth: an algorithmic exploration of courtroom tropes and taboos [^115VrZyE]. Tobacco Control (2020). Medium credibility.

Ignore the truth, focus only on the facts

Another surprising rhetorical divergence is truth versus facts. The plaintiffs focus on documenting the truth about the industry and its misconduct, including its decades of casting doubt on research linking cigarettes and disease. The defendants do not so much deny this history as simply ignore it, while insisting that the jury focus on the facts of the specific case, which shifts all agency away from the industry. This strategy, too, can be found in the industry's 1980s litigation training manuals: "our great strength is the particular plaintiff — her specific disease and her personal option to quit. Our potential weakness surfaces at the 'universal' level: general causation, failure to warn the public, and alleged deception: advertising, industry research, lobbying".(p96)

Focusing on individual facts isolates a particular trial from its larger context and allows the industry to appear calm and rational, presenting 'just the facts' while claiming that plaintiffs want to arouse emotions. Defence attorneys sometimes even suggest that plaintiffs are using scare tactics (table 6): "I submit you heard those things (from the plaintiffs) to make you angry, to get you mad, to distract you from the facts of Mr. Ahrens' case… Dr. Proctor talked to you for 4 days in the hopes of getting you so mad that you would decide the case based on emotion… If you keep your eye on the ball, and focus on Mr. Ahrens and the facts of his life, Mrs. Ahrens loses".

---

### AAN position statement: ethical issues in clinical research in neurology [^114NinYX]. Neurology (2020). High credibility.

Ethical principles for clinical research — core requirements and definitions are as follows: Social value: A study must have the potential to improve human health or meaningfully increase society's knowledge of human biology. Scientific validity: A study must use accepted scientific methodology to produce valid and reproducible results. Fair participant selection: Study sites, populations, and participants must be selected based primarily on scientific criteria and vulnerable populations must not be targeted or excluded in clinical studies. Favorable risk–benefit ratio: Risks to participants must be minimized and potential benefits to participants and society must exceed the risks. Independent review: Clinical studies must be reviewed and approved by knowledgeable individuals unaffiliated with the research. Informed consent: Participants must be accurately informed of and understand the purpose, risks, benefits, and alternatives of a clinical study, and make an uncoerced decision whether or not to participate. Respect for enrolled and potential participants: Potential and enrolled participants must be treated respectfully, with attention to and protection of their privacy and interests throughout the course of the study. Principles are noted as derived from the Nuremberg Code, the Declaration of Helsinki, the Belmont Report, and the US Common Rule, and originally developed by Emanuel et al.

---

### Informed consent in international research: the rationale for different approaches [^111wK1Qr]. The American Journal of Tropical Medicine and Hygiene (2010). Low credibility.

In developed countries, informed consent is based on the autonomy of the individual, a written description of the studies proposed, and previous experience of the participant with Western medicine. Consent is documented by the signature of the participant and supervised by institutional review boards (IRBs), which have conflicts of interest because they are also responsible for limiting institutional liability. In developing countries, the initial decision-making for informed consent is typically vested in the community rather than the individual, and illiteracy is common-limiting the value of written documents and signatures. The challenges in developing countries are exacerbated by the fact that persons at greatest risk of disease are often illiterate, have limited experience with Western medicine, and have limited understanding of the scientific rationale for the studies proposed. Given these differences, it is unrealistic to expect that consent strategies used in developed countries would be effective in such diverse settings.

---

### The need for change in generating evidence for the critically ill [^114ji11N]. American Journal of Respiratory and Critical Care Medicine (2023). Medium credibility.

Research Risk of Pragmatic Trials in Critically Ill Patients

There is no universally accepted way of determining the research risk of pragmatic trials comparing standard-of-care interventions. Some argue that if the interventions are both within standard of care and there are no rigorous data showing their relative merits, then there is no additional research risk. However, although there may be sufficient community equipoise to justify a trial, this does not mean that all clinicians must also have personal equipoise. An experienced clinician may acknowledge the lack of rigorous evidence and yet have reasonable preferences in individualized cases. Thus, disregarding such a preference by bypassing consent will sometimes mean that some patients will receive interventions that they or their doctors would not have wanted and be exposed to different welfare outcomes solely because of the research.

We argue that the key to designing pragmatic trials in the intensive care unit ill patients who have minimal research risk lies in ensuring that every enrolled patient is assigned an intervention that is also supported by individualized, clinically based reasoning. That is, a protocol-determined, randomized selection of a study intervention must also be a clinically motivated, individualized decision. Although this may sound strange in the abstract, there are examples of studies in which each enrollee's randomly assigned intervention can be overridden by the patient's doctor on clinical grounds. In such trials, the risks of the intervention being tested cannot be attributed solely to research participation, because those risks will have been deemed acceptable from an individualized clinical perspective. Such clinical risks should not be counted as research risks, and thus such trials should be deemed of minimal research risk, reflecting the embedded nature of a research trial into practice. Allocation concealment is an important feature of many clinical trials to attribute any observed efficacy to a particular study intervention. However, if we are interested in estimating the real-world effectiveness of starting a patient on a particular therapy, then allowing modifications to a randomly assigned intervention is a more realistic approach than what is standard in pragmatic comparative effectiveness research. As long as the outcome data are analyzed according to the intention-to-treat principle, we would not expect selection bias.

---

### Ethical issues in psychiatric research on children and adolescents [^11571mDe]. Child and Adolescent Psychiatric Clinics of North America (2008). Low credibility.

Psychiatric research on children and adolescents is ethically justified by the need to reduce the burden that mental illnesses place on young people, their families, and society. Such research must be conducted with careful attention to the ethical principles of beneficence, justice, and respect for persons. Child and adolescent psychiatrists who collaborate on research trials or advise patients and families about research participation should consider nine domains when evaluating the ethical acceptability of particular protocols. These domains include scientific merit and design; expertise, commitment, and integrity; risks and benefits; confidentiality; participant selection and recruitment; informed consent and decisional capacity; incentives; institution and peer/professional review; and data presentation. Special ethical issues in child and adolescent psychiatry research concern the use of randomized, controlled treatment trials; the informed consent process for research involving adolescents; the therapeutic misconception; and conflicts of interest in physician referrals.

---

### Enduring and emerging challenges of informed consent [^115sxFQ4]. The New England Journal of Medicine (2015). Excellent credibility.

The author summarizes emerging standards for informed consent as the underpinning of ethical research in humans.

---

### Behavioral dishonesty in multiscenes: associations with trait honesty and neural patterns during (dis) honesty video-watching [^111Ze61i]. Human Brain Mapping (2024). Medium credibility.

Second, the dominant trend of investigating deception in behavioral studies is capturing deceptive behaviors in a single type of context; yet, the method suffers from the problems of weak representation and high lability. The occurrence of deceptive behaviors is influenced by both personal and situational factors (Gerlach et al.). Most of the previous studies tend to use one type of task to capture individuals' deceptive behaviors (Gerlach et al; Rosenbaum et al.). Consequently, they may only reveal a single type of behavioral tendency in a specific context, overlooking the significant influence of situational factors contributing to the variability of deceptive behaviors. Besides, deception is judged differently when dishonest actions are diverse in motives underneath and consequences accompanying, especially when they differ in the pro‐self and prosocial nature (Yin & Weber). However, previous research mainly focused on lies out of pro‐self motives with prosocial lies less explored. Heterogeneity in the pro‐self and prosocial deceiving tendencies would further aggravate the problems of cross‐situational inconsistency and within‐person variations.

---

### Participatory approaches should be used to address the ethics of social media experiments [^116WtJSw]. Communications Psychology (2025). Medium credibility.

Academic researchers make subjective, ethical judgments when designing experiments on human participants. This is particularly evident in the decisions psychologists must make when designing and implementing field experiments on social media. These experiments typically involve administering some treatment to users and analysing their online behaviour before and after the treatment. They can be run with platform cooperation (e.g. with direct industry-academia collaboration, as in ref.) or independently, without explicit collaboration agreements with the platform on which they are run (e.g. by having consenting users download web browser extensions that scrape posts from their feed, as in ref.). They can also be run with participants' informed consent (e.g. by transparently recruiting participants through a crowdsourcing platform and requiring a consent form to be signed, as in ref.), or without it (e.g. by responding to users' public posts and observing their reactions without disclosing the experiment taking place, as in ref.).

Ethical concerns related to field experiments have long been discussed in the social sciences, but recent adaptations to social media platforms renew these concerns and raise new questions. Academic psychologists most familiar with experiments in controlled laboratory-type settings may quickly find themselves faced with ethical dilemmas that current guidelines struggle to address. For example, a central motivation for conducting a social media field experiment is to observe users' natural behaviours, so researchers may argue they should be excused from obtaining informed consent or permitted to deceive users for the sake of ecological validity. Such trade-offs mean that even researchers who follow guidance and carefully evaluate the harms and benefits of their study face many open questions and may unwittingly engage in ethical practices that spark controversy. Indeed, previously implemented field experiments on social media have raised ethical concerns and faced public scrutiny (Box 1). Such instances highlight the need for clearer ethical guidelines for academic experiments run on social media platforms, even if those experiments ultimately aim to shed light on the overarching issue of platforms' power over their users.

---

### Definition of "experimental" [^1156rv4M]. Fertility and Sterility (2008). Low credibility.

This Practice Committee Opinion offers a definition of what is "experimental".

---

### Deception is associated with reduced social connection [^113uTPiW]. Communications Psychology (2023). Medium credibility.

Limitations

Future research should seek to further understand the robustness of this effect by altering the laboratory methodology. The veracity manipulation employed in Study 2 was rather blunt, as individuals were instructed to tell the truth or lie for the entirety of the conversation. Future research should explore more ecologically valid manipulations or situations — perhaps having participants answer dishonestly to only a select number of questions or leading some participants to lie without explicitly instructing them to do so. In order to provide additional ecological validity, future work may consider using a face-to-face context. Since there is some evidence that deception may be expressed and evaluated differently in close relationships (vs. stranger dyads), future research should also examine how lies impact perceived closeness in already established relationships. Generalizability may also be improved by studying individuals from other countries and cultures. Our data are limited to residents of the United States — a western, industrialized, and individualistic nation.

Future work should also consider additional psychological mechanisms underpinning the relationship between deception and social connection. While we provide evidence that 'deceiver's distrust' appears to mediate the relationship between deception and closeness in an experimental context, the data in correlational Studies 1 and 3 are also consistent with the possibility that lying decreases trust by reducing social connection. In other words — the relationship between deceivers' distrust and feelings of closeness or loneliness may be bidirectional. Other mechanisms too may be worth testing. For example, the cognitively taxing experience of telling a lie may be subjectively experienced as disfluency and misattributed to evaluations of the conversational partner. Although future research may provide additional insight into mechanisms, current findings are consistent with meta-analytic findings that interventions targeting maladaptive social cognition can reduce loneliness and suggest that focusing on biases that affect the perceived trustworthiness of conversational partners, including one's own trustworthiness, may improve people's ability to forge social connections.

---

### Introduction… [^116s4tdE]. FDA (2020). Medium credibility.

On this page:

- Introduction
- Exception from Informed Consent Requirements for Emergency Research Introduction No clinical investigator may involve a human being as a subject in research unless the investigator has obtained the legally effective informed consent from the subject. Informed Consent is a written notification to human subjects involved in clinical investigations that provides them with sufficient opportunity to consider whether or not to participate in the study. The informed consent document must include all the basic elements of informed consent or it may be a short form written consent document stating that the elements of informed consent have been presented orally. If the short form method is used, there must be a witness to the oral presentation.

An investigator shall seek such consent only under circumstances that provide the prospective subject or the representative sufficient opportunity to consider whether or not to participate and that minimize the possibility of coercion or undue influence. The information that is given to the subject or the representative shall be in language understandable to the subject or the representative. No informed consent, whether oral or written, may include any exculpatory language through which the subject or the representative is made to waive or appear to waive any of the subject's legal rights, or releases or appears to release the investigator, the sponsor, the institution, or its agents from liability for negligence.
- A statement that the study involves research, an explanation of the purposes of the research and the expected duration of the subject's participation, a description of the procedures to be followed, and identification of any procedures which are experimental.
- A description of any reasonably foreseeable risks or discomforts to the subject.
- A description of any benefits to the subject or to others which may reasonably be expected from the research.
- A statement that significant new findings developed during the course of the research which may relate to the subject's willingness to continue participation will be provided to the subject.
- The approximate number of subjects involved in the study. The consent form must be signed by the subject or the subject's legally authorized representative. Each signed consent must be maintained by the clinical investigator and a copy of the informed consent must be provided to the human subject.
- the intervention under investigation must be administered before consent from the subjects' legally authorized representatives is feasible
- there is no reasonable way to identify prospectively the individuals likely to become eligible for participation in the clinical investigation
- Participation in the research holds out the prospect of direct benefit to the subjects because:

- subjects are facing a life-threatening situation that necessitates intervention.

---

### Listeners' perceptions of the certainty and honesty of a speaker are associated with a common prosodic signature [^116B3rUw]. Nature Communications (2021). High credibility.

Research on deception detection has shown that observers are relatively poor at detecting liars explicitly in laboratory settings. As mentioned above, this is partly explained by the fact that liars have a relative control over their displays, with the consequence that no behavioral cue to deceit is mandatory. Yet, it has also been suggested that there is a dissociation between explicit and implicit (or intuitive) abilities to detect lies. While observers may be quite good at picking up relevant cues unconsciously (or intuitively), they may not always use them to overtly and explicitly report dishonesty, in particular if they assess that "the costs of failing to detect deception (are inferior to) those of signaling distrust", or if they have been taught to rely on cues that turn out to be unreliable such as gaze aversion.

---

### Psychedelics and hypnosis: commonalities and therapeutic implications [^112vCnx5]. Journal of Psychopharmacology (2018). Low credibility.

Background

Recent research on psychedelics and hypnosis demonstrates the value of both methods in the treatment of a range of psychopathologies with overlapping applications and neurophenomenological features. The potential of harnessing the power of suggestion to influence the phenomenological response to psychedelics toward more therapeutic action has remained unexplored in recent research and thereby warrants empirical attention.

Aims

Here we aim to elucidate the phenomenological and neurophysiological similarities and dissimilarities between psychedelic states and hypnosis in order to revisit how contemporary knowledge may inform their conjunct usage in psychotherapy.

Methods

We review recent advances in phenomenological and neurophysiological research on psychedelics and hypnosis, and we summarize early investigations on the coupling of psychedelics and hypnosis in scientific and therapeutic contexts. Results/outcomes: We highlight commonalities and differences between psychedelics and hypnosis that point to the potential efficacy of combining the two in psychotherapy. We propose multiple research paths for coupling these two phenomena at different stages in the preparation, acute phase and follow-up of psychedelic-assisted psychotherapy in order to prepare, guide and integrate the psychedelic experience with the aim of enhancing therapeutic outcomes.

Conclusions/Interpretation

Harnessing the power of suggestion to modulate response to psychedelics could enhance their therapeutic efficacy by helping to increase the likelihood of positive responses, including mystical-type experiences.

---

### Self-deception: distorted metacognitive process in ambiguous contexts [^115JJwai]. Human Brain Mapping (2023). Medium credibility.

The self‐deception task we used in the current study combined the advantages of previous cheating and self‐deception studies and revised parts that might bring confounding factors. We combined and revised the cheating task (Zoë Chance et al.) and the numerical discrimination task (Fleming et al; Halberda et al.) to capture self‐deception in three studies. Perceptual discrimination tasks, such as a numerical distinguishing task, are relatively consistent in performance across species and development (Feigenson et al.) and are previously used to investigate individuals' metacognition (Fleming & Lau). More importantly, compared to general knowledge, individuals have little experience or anticipations about their performance on the dot discrimination task, excluding potential confounds brought by preexisted self‐efficacy belief. Besides, by applying two‐alternative forced‐choice perceptual tasks, patients with lesions in the medial prefrontal cortex (mPFC) had a selective deficit in perceptual metacognitive accuracy (Fleming & Lau). These findings suggest it is a valid experimental design to investigate self‐deception.

In addition to the modified task, we applied a psychometric modeling approach (Figure 1) to quantify individuals' actual ability and prediction errors in binary decision tasks to clarify the internal connections between quantified variables and self‐deception. The key ideas behind the statistical modeling are that two types of prediction errors should be partitioned from each other: (1) one that can be captured in the classic metacognitive task by comparing participants' prediction of their future performance and their actual performance, and (2) one that is potentially associated with self‐deception and can only be identified in a cheating opportunity context where participants are provided with opportunities to adjust their evaluation processes. Last, we manipulated the difficulty of peeking at answer keys and allowed the verification of high ambiguity context facilitating self‐deception. By separating these two types of errors induced by the ambiguity of attributions and finding relations among ability, prediction errors, and self‐efficacy belief, we could identify false belief and its sources.

---

### Work-relatedness [^113s8Kdx]. Journal of Occupational and Environmental Medicine (2018). Medium credibility.

Work-relatedness — Table 1 steps for evaluating epidemiological evidence list procedural actions and criteria: "Collect all epidemiological literature reported on that disorder", "Identify the design of each study", and "Assess each study's methods" including "Exposure assessment methods and potential biases", "Disease ascertainment methods and potential biases", "Absence of significant uncontrolled confounders; consideration of residual confounding", "Addressing of other potential biases", "Adequacy of biostatistical methods and analytical techniques", and "Ascertainment of statistical significance — degree to which chance may have produced those results". The table then directs to "Assess the studies using the Updated Hill's Criteria" including "Temporality", "Strength of association", "Dose–response", "Consistency", "Coherence", "Specificity", "Plausibility", "Reversibility", "Prevention/Elimination", "Experiment", and "Predictive Performance", and to make a "Conclusion regarding the degree to which such a causal association is/is not met".

---

### Professional relationships with industry: ACOG committee statement no. 2 [^1171YuTJ]. Obstetrics and Gynecology (2022). High credibility.

Study design and approval — ethical review, role definition, and compensation are specified: "Investigators should adhere to their institutions' policies regarding approval and conduct of clinical research. All trial protocols should undergo unbiased scientific review to ensure validity of the technical background, methods, interventions, and outcomes". "Trials involving animals or humans should also be reviewed by the appropriate Institutional Animal Care and Use Committee or IRB, respectively, for adherence to appropriate ethical standards". "Trial-related obligations of the sponsor and of the investigator should be clearly defined in writing (eg, data collection, data analysis, drafting of manuscripts)". Regarding payments, "Investigators may accept reasonable compensation at fair market value for consultation related to the design of industry-sponsored research", and "Reimbursement to investigators and their institutions for involvement in research, including recruitment of participants, should not exceed reasonable costs of these activities". " 'Finder's fees' or bonuses specifically for recruitment of patients are discouraged and should be disclosed to both the IRB for consideration during the review process and potential study participants before trial enrollment".

---

### Telling truth from lie in individual subjects with fast event-related fMRI [^1162Eg5X]. Human Brain Mapping (2005). Low credibility.

Deception is a clinically important behavior with poorly understood neurobiological correlates. Published functional MRI (fMRI) data on the brain activity during deception indicates that, on a multisubject group level, lie is distinguished from truth by increased prefrontal and parietal activity. These findings are theoretically important; however, their applied value will be determined by the accuracy of the discrimination between single deceptive and truthful responses in individual subjects. This study presents the first quantitative estimate of the accuracy of fMRI in conjunction with a formal forced-choice paradigm in detecting deception in individual subjects. We used a paradigm balancing the salience of the target cues to elicit deceptive and truthful responses and determined the accuracy of this model in the classification of single lie and truth events. The relative salience of the task cues affected the net activation associated with lie in the superior medial and inferolateral prefrontal cortices. Lie was discriminated from truth on a single-event level with an accuracy of 78%, while the predictive ability expressed as the area under the curve (AUC) of the receiver operator characteristic curve (ROC) was 85%. Our findings confirm that fMRI, in conjunction with a carefully controlled query procedure, could be used to detect deception in individual subjects. Salience of the task cues is a potential confounding factor in the fMRI pattern attributed to deception in forced choice deception paradigms.

---

### A three-stage strategy for conducting an experimental investigation: a recommendation to improve the reproducibility of reported conclusions [^115RXJb2]. Journal of Psychopharmacology (2025). Medium credibility.

The reproducibility of the results from preclinical research rests on many factors, including the selection of appropriate experimental designs for the individual experiments that constitute the investigation. The design of each of these experiments depends on their purpose within the entire investigation and the information to be gained from conducting them. Here, we explain and justify a three-stage strategy comprising a series of different types of experiment, each with a different purpose and design: a pilot study, a hypothesis-generating experiment and a final hypothesis-confirming experiment. Compliance with this three-stage strategy, over the course of an entire investigation, will not only strengthen its reproducibility but, importantly, can save time and other resources, including the total number of animals used.

---

### The ethics of clinical research [^116SwLG6]. The Journal of Hand Surgery (2011). Low credibility.

The purpose of this article is to discuss the ethical concepts involved in the conception, design, execution, analysis, publication, and reporting of clinical research. Although it might seem burdensome to comply with these ethical necessities, they can assist in the organization of a well-run clinical trial, if considered at the onset of a study, while also protecting the valuable human subjects who volunteer for these trials.

---

### Placebos without deception reduce self-report and neural measures of emotional distress [^114Dzwap]. Nature Communications (2020). High credibility.

Several recent studies suggest that placebos administered without deception (i.e., non-deceptive placebos) can help people manage a variety of highly distressing clinical disorders and nonclinical impairments. However, whether non-deceptive placebos represent genuine psychobiological effects is unknown. Here we address this issue by demonstrating across two experiments that during a highly arousing negative picture viewing task, non-deceptive placebos reduce both a self-report and neural measure of emotional distress, the late positive potential. These results show that non-deceptive placebo effects are not merely a product of response bias. Additionally, they provide insight into the neural time course of non-deceptive placebo effects on emotional distress and the psychological mechanisms that explain how they function.

---

### An official multi-society statement: the role of clinical research results in the practice of critical care medicine [^117KucQe]. American Journal of Respiratory and Critical Care Medicine (2012). Medium credibility.

Negotiating between various kinds of medical knowledge — no set hierarchy of knowledge to guide clinical decision making in all situations is possible, and a ranking based on study design or quality measures cannot be directly applied to clinical decisions; clinicians must continue to rely on sound clinical judgment to negotiate between potentially conflicting facts and reasons, and explicitness is to be greatly valued, as clinicians should be able to identify and articulate the sources and kinds of knowledge invoked; the initial step is identifying pertinent medical knowledge, including clinical research, pathophysiologic understanding, and clinical experience, and since no kind of knowledge is always superior, simply relying upon a randomized controlled trial or meta-analysis will be insufficient; clinicians are obligated to consider information and knowledge that might suggest action that would run counter to that suggested by clinical research, and a clinician ought to be able to concisely outline and justify the process of clinical reasoning for scrutiny and revision.

---

### An official multi-society statement: the role of clinical research results in the practice of critical care medicine [^113Vh898]. American Journal of Respiratory and Critical Care Medicine (2012). Medium credibility.

Variability in clinical practice — the weight given to facts and reasons for a clinical decision can differ between clinicians, resulting in variability; factors beyond study design and execution can make clinical research results more compelling and are summarized in Table 2, but no particular clinical study can be expected to satisfy all criteria; when research results are not compelling, clinicians will be more likely to weight experiential or pathophysiologic knowledge more heavily, so clinicians can reasonably come to a different clinical conclusion even when considering the same research; differences may derive from differing professional values and prior knowledge, and making the clinical decision-making process explicit will aid in identifying the sources of variability in practice.

---

### Structural under-reporting of informed consent, data handling and sharing, ethical approval, and application of open science principles as proxies for study quality conduct in COVID-19 research: a systematic scoping review [^115Ciy97]. BMJ Global Health (2023). High credibility.

Informed consent is a legal and ethical construct used in a state-of-the-art investigation of patient data, where legal and ethical rules and regulations apply. Although legal rules vary between regions and countries, which has likely driven the differences in reporting across regions of the world, the scientific community embraces general ethical regulations globally. Obtaining informed consent during the COVID-19 pandemic, however, came with significant challenges. For example, study personnel was at risk of infection when contacting patients to obtain a signature for written informed consent. Also, scarce personnel resources were likely to be employed clinically instead of in research activities. Importantly, informed consent protects the patients' autonomy, particularly regarding study risks, such as interventions under study and sharing of sensitive personal health data. Therefore, the Council for International Organizations of Medical Sciences states that obtaining informed consent should continue, even in situations of duress and other methods than written informed consent are possible. For example, verbally asking for consent with a witness present is an accepted alternative, as well as asking a legally authorised representative of the patient. When a representative is unavailable, asking for consent at a later point (deferred consent) could also be considered. This may explain why many studies did not explicitly report written informed consent during the COVID-19 pandemic. We found that a waiver of consent was most often applied for observational studies, apparently balancing individual risks versus the overall general gain of data investigation. Taken together, we feel that reporting informed consent is at least a proxy for study quality conduct, although informed consent is neither an obstacle nor a guarantee for good-quality data. To our knowledge, no quantitative data are available about the effect of acquiring informed consent on the quality of study results. Although the rapid growth of COVID-19 publications appeared to affect journal impact factors, we found that consent reporting did not differ according to the journal impact factor.

---

### Self-deception: distorted metacognitive process in ambiguous contexts [^113io7HX]. Human Brain Mapping (2023). Medium credibility.

As one of the commonly used folk psychological concepts, self-deception has been intensively discussed yet is short of solid ground from cognitive neuroscience. Self-deception is a biased cognitive process of information to obtain or maintain a false belief that could be both self-enhancing or self-diminishing. Study 1 (N = 152) captured self-deception by adopting a modified numerical discrimination task that provided cheating opportunities, quantifying errors in predicting future performance (via item-response theory model), and measuring the belief of how good they are at solving the task (i.e., self-efficacy belief). By examining whether self-efficacy belief is based upon actual ability (true belief) or prediction errors (false belief), Study 1 showed that self-deception occurred in the effortless (easier access to answer cues) rather than effortful (harder access to answer cues) cheating opportunity conditions, suggesting high ambiguity in attributions facilitates self-deception. Studies 2 and 3 probed the neural source of self-deception, linking self-deception with the metacognitive process. Both studies replicated behavioral results from Study 1. Study 2 (ERP study; N = 55) found that the amplitude of frontal slow wave significantly differed between participants with positive/self-enhancing and negative/self-diminishing self-deceiving tendencies in incorrect predictions while remaining similar in correct predictions. Study 3 (functional magnetic resonance imaging study; N = 33) identified self-deceiving associated activity in the anterior medial prefrontal cortex and showed that effortless cheating context increased cheating behaviors that further facilitated self-deception. Our findings suggest self-deception is a false belief associated with a distorted metacognitive mental process that requires ambiguity in attributions of behaviors.

---

### Reporting of ethical issues in publications of medical research [^111cbcEj]. Lancet (2002). Excellent credibility.

Clinical investigators rarely describe the rationale for ethically controversial features of study design or procedures instituted to enhance the protection of patients taking part in research, or how they ensured informed consent. We recommend a policy of extensive reporting of pertinent ethical issues to promote public accountability for clinical research. Guidelines are presented, and possible objections to this recommended policy are addressed.

---

### Must research benefit human subjects if it is to be permissible? [^113KbT5H]. Journal of Medical Ethics (2017). Low credibility.

Introduction

The ethics of experimentation involving patients is least troubling when participation in the research offers the best prospects for the subjects' future well-being of all available options. This 'favourable risk-benefit ratio' does not obviate the need for informed consent, but this is ordinarily forthcoming once the prospective subject understands what is on offer.

But must an experiment offer patients their best prospect for healthy recovery, in order to be ethically justified? Indeed, might some studies offer greater prospect of harm than benefit, and still be judged ethically sound?

And if an experiment is to be performed not on patients but on healthy volunteers, must any risks be more than offset by prospective benefits to these subjects, in order to be ethically permissible?

The answers to these questions are almost certainly and unequivocally 'No'. Experiments on patients and on healthy volunteers alike may be ethically justified even when the subjects would be likely to fare better by declining to participate, either to choose other options (eg, treatment) or simply to do nothing. Nor is this in any way a secret in the research ethics literature or in government or professional regulations and guidelines.

If this conclusion is both well established and widely and officially recognised, why is it worth devoting an essay to its defence?

---

### The ethics of research publication [^115BN8Fk]. European Journal of Clinical Nutrition (2017). Low credibility.

This corrects the article DOI: 10.1038/ejcn.2017.20.

---

### Physician perspectives on placebo ethics [^114gvtKf]. Journal of Medical Ethics (2021). Medium credibility.

Clinical use of placebos is controversial among bioethicists. While placebos have been shown to provide benefit for patients with some conditions, offering placebos to patients without disclosing that they are placebos raises ethical concerns, including the concern that this lack of transparency about the nature of placebos amounts to deceiving patients. Some have proposed open-label placebos (OLPs) as an ethically preferable alternative: patients are offered placebos and told that the treatment being offered is a placebo. To contribute to the ongoing discussion about the ethics and feasibility of clinical use of placebos, we conducted focus groups to explore physician attitudes about clinical use of placebos, including non-disclosed and OLPs, and physician attitudes about the underlying ethical issues. We found that while the non-transparency and deceptiveness of offering non-disclosed placebos was a concern for some physicians, their primary focus when considering both non-disclosed and OLPs was identifying and weighing potential harms and benefits to patients. Some participants also felt further research and training in prescribing OLPs would be needed before they would be willing to use them in their practice.

---

### Pediatric and adult brain death / death by neurologic criteria consensus guideline [^1142thwT]. Neurology (2023). High credibility.

Regarding diagnostic investigations for brain death, more specifically with respect to consent acquisition, AAN/AAP/CNS/SCCM 2023 guidelines recommend to make a reasonable attempt to inform the patient's family of the plan to perform a BD/death by neurologic criteria examination when planning to evaluate a patient for BD/death by neurologic criteria.

---

### The nature and ethics of natural experiments [^116eRh21]. Journal of Medical Ethics (2015). Low credibility.

Natural experiments are an important methodology often used to answer research questions that would, otherwise, be impossible to address, or employed because of ethical concerns about the use of randomisation to interventions that carry known risks. The UK Medical Research Council (MRC) recently produced an extremely useful document discussing the nature and significance of natural experiments within medical and public health research. In this paper, however, we suggest that the MRC document's definition of the term 'natural experiment' is insufficiently precise. In response, we offer a taxonomy of different types of natural experiments and related methods, and explore the ethical implications of these different types. We argue that while the ethical issues that may arise within natural experiments in relation to risks of harm or informed consent may differ from those within the randomised controlled trial, they are not thereby less pressing. The implications of the argument are explored and recommendations made for those involved in research governance.

---

### ESR statement on good scientific practice and publishing [^117RusZo]. Insights Into Imaging (2012). Low credibility.

Research ethics

In biomedical research, it is of the utmost importance to comply with ethical principles and avoid any form of unethical experimentation in human or animal studies, adhere to ethical guidelines, seek ethics committee approval, obtain adequate subject consent and protect the privacy of the participants.

The fundamental document in the field of ethics in biomedical research that has influenced the formulation of international, regional and national legislation and codes of conduct is the Declaration of Helsinki, issued by the World Medical Association in 1964. This Declaration has been developed as a statement of ethical principles for medical research involving human subjects, including research on identifiable human material and data. As well as following this statement of basic values of ethical biomedical research, investigators should follow all applicable rules and regulations, including national laws and regulatory guidelines. The Council for International Organizations of Medical Sciences (CIOMS), established jointly by WHO and UNESCO as an international, non-governmental organisation, has issued its International Ethical Guidelines for Biomedical Research Involving Human Subjects to serve the interests of the international biomedical community and help countries in defining national policies on the ethics of biomedical research involving human subjects. Another basic source of reference is the Medical Ethics Manual, published by the World Medical Association.

One of the most important basic requirements in research involving patients or healthy test subjects is informed consent. This implies good communication, providing clear explanations of the procedures, treatments, risks, burdens and potential benefits. The approval of an ethics committee must be obtained; this committee should review the comprehensibility of the written communication, the soundness of the methodology, and assess the potential risks and burdens of the procedures in view of the anticipated benefits for the participants or the group they represent. Researchers should also make sure that the sample size is sufficiently high to provide statistically meaningful results and seek the early help of a statistician whenever appropriate. It would be unethical to subject patients (or animals) to risk and discomfort if a too-small sample size does not allow significant scientific conclusions. The European Institute for Biomedical Imaging Research has compiled a document on best practice in biomedical imaging, which provides a valuable resource of basic premises and principles of ethical research.

---

### Acknowledgment of uncertainty: a fundamental means to ensure scientific and ethical validity in clinical research [^1143FUeN]. Current Oncology Reports (2001). Low credibility.

Recognition of the importance of uncertainty in the design of randomized, controlled trials (RCT) has reached the status of a principle. The "uncertainty principle", or less ambiguously, equipoise, holds that a patient should be enrolled in an RCT only if there is substantial uncertainty about which of the trial treatments would benefit the patient most. In fact, the "uncertainty principle" addresses the most important issue of a clinical trial — the choice of an adequate comparative control. Studies in which intervention and control group are believed to be non-equivalent violate the uncertainty principle. Therefore, one would expect that both editors and authors would be particularly careful to include a statement concerning prior beliefs of the investigator(s) about the uncertainty of the treatments that are reported. However, we found no evidence of such a policy in the randomized, controlled trials we examined. We also show that there is a predictable relationship between the uncertainty principle, that is, the moral principle upon which trials are based, and the ultimate outcomes of clinical trials. We postulate that about 50% of innovations are successful, leading to the conclusion that preserving the ethics of clinical research may be the best investment strategy available.

---

### Self-deception: distorted metacognitive process in ambiguous contexts [^115AtMHN]. Human Brain Mapping (2023). Medium credibility.

Abstract

As one of the commonly used folk psychological concepts, self‐deception has been intensively discussed yet is short of solid ground from cognitive neuroscience. Self‐deception is a biased cognitive process of information to obtain or maintain a false belief that could be both self‐enhancing or self‐diminishing. Study 1 (N = 152) captured self‐deception by adopting a modified numerical discrimination task that provided cheating opportunities, quantifying errors in predicting future performance (via item‐response theory model), and measuring the belief of how good they are at solving the task (i.e. self‐efficacy belief). By examining whether self‐efficacy belief is based upon actual ability (true belief) or prediction errors (false belief), Study 1 showed that self‐deception occurred in the effortless (easier access to answer cues) rather than effortful (harder access to answer cues) cheating opportunity conditions, suggesting high ambiguity in attributions facilitates self‐deception. Studies 2 and 3 probed the neural source of self‐deception, linking self‐deception with the metacognitive process. Both studies replicated behavioral results from Study 1. Study 2 (ERP study; N = 55) found that the amplitude of frontal slow wave significantly differed between participants with positive/self‐enhancing and negative/self‐diminishing self‐deceiving tendencies in incorrect predictions while remaining similar in correct predictions. Study 3 (functional magnetic resonance imaging study; N = 33) identified self‐deceiving associated activity in the anterior medial prefrontal cortex and showed that effortless cheating context increased cheating behaviors that further facilitated self‐deception. Our findings suggest self‐deception is a false belief associated with a distorted metacognitive mental process that requires ambiguity in attributions of behaviors.

---

### Questions and answers on informed consent eliements, 21 CFR 50.25 (C) [^112bPxnx]. FDA (2025). Medium credibility.

regarding certain studies still apply. 21 CFR § 56.
109. Even if documentation is waived under 21 CFR §
56. 109, the trial participant still provides consent and the statement is required during the oral presentation of the research and/or in the written. statement regarding the research, if required by the IRB under 21 CFR § 56.
109. Under 21 CFR §§
50. 23 and 50. 24 regarding exceptions to informed consent, the statement is also required in the informed consent documents if these trials are applicable clinical trials.
14. In what situations may the new requirement be waived. Section 801 of FDAAA does not provide for a waiver of the new requirement to include the new statement in the informed consent documents and process for applicable clinical trials. FDA's regulations require informed consent for participation in FDA-regulated clinical investigations except under limited circumstances as described in 21 CFR § 50.
23.

Contains Nonbinding Recommendations The investigator and sponsor are responsible for determining whether a trial is an applicable clinical trial and to include the required statement in the informed consent document, as appropriate, for approval by the IRB. If an error is made, the IRB should be notified as soon as possible and a revised consent form that includes the required. statement should be provided to the IRB for review and approval.
17. Does the new statement have to be included in informed consent documents for trials with de-identified data — that is, trials that are not subject to the Health Information Portability and Accountability Act. If the trial is determined to be an applicable clinical trial, the investigator or sponsor must. investigators/sponsors do not need to inform participants about the availability of information on the www. ClinicalTrials. gov website.

The required statement should not be included in informed consent documents or processes for clinical trials that are not applicable clinical trials. However, if investigators/sponsors independently believe that reporting data on www. ClinicalTrials. gov may influence subjects' willingness to. participate, nothing in this regulation prevents investigators/sponsors from voluntarily reporting trial data and informing trial participants in an appropriate manner.
19. Should investigators/sponsors include the statement in consent documents for a trial that is not an "applicable clinical trial. " Because U. S. law only requires that applicable clinical trials be submitted to.

---

### Committee opinion no. 665: guidelines for adolescent health research [^112kzyjv]. Obstetrics and Gynecology (2016). Medium credibility.

45 C.F.R. § 46.408(c) parental permission waiver — Under Subpart D, 45 C.F.R. § 46.408(c) specifically allows for a waiver of parental permission, and if an institutional review board (IRB) determines that a research protocol is designed for conditions or a subject population for which parental permission is not a reasonable requirement to protect subjects, it may waive consent requirements provided an appropriate mechanism for protecting the children who will participate as research subjects is substituted and provided the waiver is not inconsistent with federal, state, or local law; examples include research designed to identify factors related to the incidence or treatment of certain conditions in adolescents for which, in certain jurisdictions, they legally may receive treatment without parental consent, and research in which the subjects are "mature minors" with procedures that entail essentially no more than minimal risk that such individuals might reasonably assume on their own.

---

### Ethical issues, safety, and data integrity in clinical trials [^112BL6yW]. Inflammatory Bowel Diseases (2005). Low credibility.

Published in 1974, the Belmont Report established the ethical principles for conducting clinical research in the United States. The essential concepts are respect for the research participant, beneficence for society at large, and justice (equal access to participation and equal treatment) toward subjects in a research study. These principles are applied through the use of informed consent, risk/benefit assessment, and the impartial selection of study subjects. Strict adherence to these criteria often results in conflicts of interest, which the investigator must anticipate and manage. Investigators must also be thoroughly acquainted with the principles of Good Clinical Practice and regulatory requirements. Recent implementation of the Privacy Rule now requires the investigator to protect not only the safety but the privacy of the research subject. While the regulatory obligations can appear onerous, strict compliance results in clinical research that is safe, scientifically sound, and ethical.

---

### Read the belmont report | HHS.gov… [^1128m1qe]. HHS (2018). Low credibility.

Official websites use. gov A. gov website belongs to an official government organization in the United States. Secure. gov websites use HTTPS A lock or https: // means you've safely connected to the. gov website. Share sensitive information only on official, secure websites.

---

### Interpretation of gene associations with risk of acute respiratory distress syndrome: P values, bayes factors, positive predictive values, and need for replication [^116AM2yi]. Critical Care (2016). Low credibility.

Conclusions

The observed evidence (the P value, or better yet, the BF) can be combined with prior considerations of plausibility to determine how well two hypotheses are supported (posterior probability, PPV). The posterior probability (PPV) that there is an association between exploratory SNPs and severity of ARDS in children is low given the low prior probability, the modest BF (reflected in modest P values and power), and potential for bias. This is not necessarily a problem if our interest is in generating hypotheses for further scientific study. An interesting hypothesis has been suggested (i.e. a gene association) and warrants further investigation; we should wait for replication in additional larger studies before accepting this hypothesis. These future studies will have a prior probability that is closer to 0.1 (the posterior probability after the current study), and thus replication would move us much further toward accepting the hypothesis. Overall, caution is warranted: most genetic associations for ARDS in adults have not replicated.

---

### Forced to be free? Increasing patient autonomy by constraining it [^114v8Hf4]. Journal of Medical Ethics (2014). Low credibility.

Independent testing helps to ensure that scientific claims are neither fraudulent nor spurious: that data is not faked nor arises from irrelevant factors (say contamination of samples or order effects). Independent testing is also typically hypothesis driven: that is, it aims at attempting to replicate the experiment, and does so in the service of a particular interpretation of the data, thereby aiding in the refinement of the theories that explain the data. This hypothesis-driven methodology, when combined with relations of trust between scientific research groups, enables rapid scientific progress. Researchers do not need to build their theories from the ground up; rather, they aim to add incrementally to the work of their predecessors (science moves so fast that a scientist's predecessors, in this context, may be a group whose work was published last week).

Because science is deeply dependent on a distribution of cognitive labour, it is perilous to infer from the success of science as an epistemic enterprise to the reliability of individual human rationality. It is not because scientists are freed from all constraints that science works as well as it does: it is because scientists accept a range of constraints on what can be said and how it can be said, on what counts as evidence and what should be tested. If anything, the success of science might support the opposite conclusion to the one drawn by Enlightenment thinkers: we might take it to show the epistemic importance of tradition, where 'tradition' is understood as constraining not content but form.

On the one hand, then, we can explain the success of our best epistemic enterprises (in important part) by reference to their social organisation. On the other hand, as I shall now show, when we enquire into the powers of individual human reasoners the picture we are presented with is in many ways bleak. Human beings are, under a variety of conditions, systematically bad reasoners, and many of their reasoning faults can be expected to affect the kind of judgements that they make when they are called upon to give informed consent. In what follows, I will outline a small subset of the evidence about the limitations of individual human reasoning, with special emphasis on the kinds of limitations that might be expected to be relevant to situations in which informed consent is sought.

---

### AAN position statement: ethical issues in clinical research in neurology [^117GJEBP]. Neurology (2020). High credibility.

Informed consent and surrogate decision-making — When impaired decision-making capacity precludes direct fulfillment of the requirement for informed consent, a legally authorized representative may make the decision, and the 2017 amendment to the Common Rule specifies that surrogates for medical decision-making can also be considered surrogates for decisions about clinical research where state law does not specify rules. The surrogate should use a substituted judgment standard based on the participant's historical beliefs and values, and IRBs may require additional safeguards, such as independent consent monitors, depending on the degree of cognitive incapacity and the study's risk-benefit ratio and complexity. For participants with dementia and other cognitive impairments, IRBs should make every effort to fully protect participants while minimizing impediments, and for pediatric participants IRBs should endeavor to balance rigorous protection with minimization of impediments to clinical research on pediatric neurologic disorders. Where possible, researchers should consider disclosing relevant conflicts of interest during the informed consent process.

---

### Specialty guidelines for forensic psychology [^115pJgHv]. The American Psychologist (2013). Medium credibility.

Communication in research contexts — dissemination and accuracy: When engaged in research or scholarly activities connected with forensic practice, forensic practitioners "seek to negotiate with the client the circumstances under and manner in which the results may be made known to others", and "strive to balance the potentially competing rights and interests of the retaining party with the inappropriateness of suppressing data, for example, by agreeing to report the data without identifying the jurisdiction in which the study took place". Practitioners also "represent the results of research in an accurate manner".

---

### AAN position statement: ethical issues in clinical research in neurology [^1141ijSC]. Neurology (2020). High credibility.

Ethical framework for clinical research in neurology — foundational sources and core requirements are summarized using Ezekiel Emanuel's framework of 7 principles. The foundation of modern clinical research ethics is the Nuremberg Code (1947), the Declaration of Helsinki (1964), and the Belmont Report (1978), which together inform the Common Rule (45 CFR part 46). These 7 principles — social value, scientific validity, fair participant selection, favorable risk-benefit ratio, independent review, informed consent, and respect for participants — are stated as requirements: social value is the requirement that a clinical study must have the potential to improve human health or meaningfully increase society's knowledge of human biology; scientific validity is the requirement that a study must use accepted scientific methodology to produce valid and reproducible results; fair participant selection is the requirement that study sites, populations, and participants be selected based primarily on scientific criteria and that vulnerable populations neither be targeted nor excluded in clinical studies; favorable risk-benefit ratio is the requirement that risks to participants be minimized and that potential benefits to participants and society be disproportionately greater than the risks to participants; independent review is the requirement that clinical studies be reviewed and approved by knowledgeable individuals unaffiliated with the research, traditionally by an institutional review board (IRB) or a peer review committee; informed consent is the requirement that participants be accurately informed of and understand the purpose, risks, benefits, and alternatives of a clinical study, and that they make an uncoerced decision whether or not to participate; and respect for participants is the requirement that both potential and enrolled participants be treated respectfully, with attention to and protection of their privacy and interests throughout the course of the study. Addressing all 7 principles is necessary and sufficient for clinical research to be considered ethically permissible.

---

### Good clinical practice and informed consent are inseparable [^112fV2sY]. Heart (2002). Low credibility.

It is now widely accepted that clinicians should negotiate rather than dictate what is in the best interests of patients.

---

### Placebos without deception reduce self-report and neural measures of emotional distress [^112UccC3]. Nature Communications (2020). High credibility.

Early LPP in Experiment 2

The early LPP (400–1000 ms) indexes attention allocation to incoming emotional stimuli. As noted earlier, we did not have strong predictions regarding how the non-deceptive placebo we administered would affect the early LPP because prior research provides mixed evidence regarding how deceptive placebos influence attention allocation processes. While some studies suggest that deceptive placebos amplify attention to negative stimuli, others suggest the opposite.

We examined the effects of non-deceptive placebos on the attentional stages of emotional processing by performing a mixed-factorial ANOVA on the same broad set of topographically organized clusters of electrodes, but focused on the early LPP time window (400–1000 ms; see "Methods" section for details of our preregistered data analytic approach). This analysis revealed a complicated set of interactions, such as a three-way condition by time by anterior/posterior interaction F (1, 194) = 4.00, p = 0.047, = 0.02, as well as a five-way condition by picture type by time by hemisphere by anterior/posterior interaction F (1, 194) = 4.46, p = 0.036, = 0.022. Probing these interactions did not, however, reveal any consistent condition effects (see Supplementary Table 6 and Supplementary Table 7 for contrasts). Moreover, we did not detect any condition effect at CPz, where the early LPP is typically maximal (all p > 0.05). We did not further probe any significant interactions with sample and condition for the early LPP. In summary, we found no reliable non-deceptive placebo effect on the early LPP.

---

### Towards a common European ethical and legal framework for conducting clinical research: the GATEKEEPER experience [^113h8YDH]. NPJ Digital Medicine (2024). Medium credibility.

Moreover, there were striking differences noted regarding the pilots' Ethical Approval Forms themselves. For reference, based on the comparative analysis performed, it became evident that the approaches widely differ based on jurisdiction and the field of activities of each pilot. In particular, the following was noted:
A. Where the pilot was performed in the context of a University Hospital, the requirements tended to be stricter and more extensive compared to pilots performed outside the context of university hospitals and clinics. This is understandable considering not only the frequency in which university hospitals and clinics are subject to such procedures but also the overall sensitive nature of their activities. Considering that their performance of research activities almost always involves patients, vulnerable populations, health data, clinical and medical studies, or a combination of those, it is logical that a higher level of protection and attention to detail is imperative.
B. Pilots performed outside of the EU, albeit still in the EEA, were inclined to impose stricter requirements and request additional information/documentation, frequently simulating the information requested and the structure of the Horizon 2020 and Horizon Europe programmes. The proposed Ethical Application Form has taken into consideration those requirements, even though they do not reflect the situation in the entirety of the pilots, so as to ensure that all pilot sites are adequately represented. As such, the proposed Ethical Application Form leaves room for the application and compliance with national dispositions that may be applicable.
C. The description and analysis of measures and safeguards adopted throughout the research with regard to privacy and personal data protection have been a central focal point in the procedures of all pilots. Given the transition to a data-centred economy and the ever-increasing processing of personal data, ensuring data subjects' privacy is becoming more and more essential to democratic societies. This focus on privacy and personal data protection reflects precisely the need to balance innovation and human rights, without either of them excluding the other.
D. Most Ethical Review Boards required specific and explicit information on funding sources, aiming at ensuring the impartiality of research. By validating that funding is secured through objective and impartial sources, and that adequate measures are in place, it is ensured that the results are unbiased and trustworthy.
E. In most pilots, a long list of supporting documents was requested, further exaggerating the bureaucratic element of the procedure. Such documents most frequently included the detailed research protocol, the patient information leaflet, and the consent forms, as well as documentation regarding funding and insurance. In many of the pilots, the researchers' curriculum vitae was also requested, along with a formal declaration of assumption of responsibility with regard to the project.

---

### A structured preapproval and postapproval comparative study design framework to generate valid and transparent real-world evidence for regulatory decisions [^1113t9kB]. Clinical Pharmacology and Therapeutics (2019). Medium credibility.

In Figure 6, Question A asks whether there is sufficient evidence that baseline randomization is feasible. This question refers to the feasibility of randomizing a sufficient sample of the study population to the treatment/comparator of interest. Lack of randomization feasibility may arise from issues with ethics, equipoise, sample size, confidentiality or operational issues, and patient or physician willingness to participate, etc. Other than for reasons of ethical violations, which will likely be known to the researcher at the start of the design process, sample‐size calculations (typically taking the largest of a reasonable range of minimal sample sizes estimated by varying assumptions) will be needed to answer this question.

If the answer to Question A is yes, the user should consider a design with baseline randomization and will continue down the left side of Figure 6. If the answer to Question A is no, the user should consider an observational epidemiological design and continue down the right side of Figure 6. Question B then asks whether there is a data source that meets the requirements specified in Step 3. (Note that if the answer to Question A was no, the potential confounders specified in Table 1, rows 7−N should be included in the feasibility assessment conducted to answer Question B.) Again, the responses are yes or no. A yes response indicates that the user should consider using the existing data. By "existing data" we mean a data source in which the types of data needed for the study are already collected into an electronic system, even if the specific data needed for the study are not yet in the dataset (i.e. will accumulate in the future). For instance, if a data source included all the necessary variables but does not yet include people exposed to the treatment of interest, we would still consider the data source feasible if we have evidence that a sufficient number of people exposed to the treatment will become captured in the data in the time frame needed for the study. The response to Question B should also consider whether an existing data source that includes the majority of necessary data can be supplemented. In this circumstance, we would typically evaluate the feasibility of adding the field to the existing data‐source collection structure (which would change the response to yes), or collecting the missing information de novo for study participants and merging it with the electronic data. If it is feasible to supplement the existing data, the answer to Question B can be yes.

---

### Informed consent guidance for IRBs, clinical investigators,… [^112BoJ9p]. FDA (2025). Medium credibility.

3 All references to the Code of Federal Regulations throughout this document can be found at www. ecfr. gov. prospective subject to ask questions and to consider whether to participate, obtaining the prospective subject's voluntary agreement to participate prior to enrollment, and continuing to provide information as the clinical investigation progresses or as the enrolled subject or situation requires. 10 Except as provided in 21 CFR 50. 23 and
50. 24, 11 (see section III. A. 1, "Exceptions to Informed. 11 FDA has issued a proposed rule that, if finalized, would allow an exception from the requirement to obtain informed consent when a clinical investigation poses no more than minimal risk to the human subject and includes appropriate safeguards to protect the rights, safety, and welfare of human subjects. 83 FR 57378, November 15. prospective subject should conduct a consent discussion.

The consent discussion and the consent form must contain information to allow prospective subjects to make an informed decision about participation in a clinical investigation and provide an opportunity for prospective subjects to ask questions about the clinical investigation and the information in the consent document (see section III, "FDA Informed. A. General Requirements for Informed Consent 21 CFR 50. 20:
- Except as provided in
50. 23, and 50. 24, no investigator may involve a human being as a subject in research covered by these regulations unless the investigator has obtained the legally effective informed consent of the subject or the subject's legally authorized representative.
- An investigator shall seek such consent only under circumstances that provide the prospective subject or the representative sufficient opportunity to consider whether or not to participate and that minimize the possibility of coercion or undue influence.

- The information that is given to the subject or the representative shall be in language understandable to the subject or the representative.
- No informed consent, whether oral or written, may include any exculpatory language through which the subject or the representative is made to waive or appear to waive any of the subject's legal rights, or releases or appears to release the investigator, the sponsor, the institution, or its agents from liability for negligence. 15 For further information, see section III. D, "Element of Informed Consent for 'Applicable Clinical Trials. '". not be performed on study participants; when applicable, this should be discussed as part of the informed consent process.

---

### Revising ethical guidance for the evaluation of programmes and interventions not initiated by researchers [^11395GNs]. Journal of Medical Ethics (2020). Medium credibility.

It has also been argued that researchers must justify the choice of control condition in cluster studies. While it is correct that the researcher, given a choice of possible controls, should select the controls to maximise their scientific value, the researcher cannot be held responsible for the fact that controls have not received the intervention, since it is the policymaker, not the researcher, who decides where and when to intervene (and where not to do so). As such, controls may not meet the high standard of a trial where the researcher has full control of all aspects of the intervention. Insisting that the intervention must receive ethical approval simply because it is part of an evaluative study does not solve the problem. It would be perverse if, by agreeing to an evaluation of an intervention, a government minister claiming a democratic mandate or a hospital chief acting on behalf of their board, then had to subject the intervention to a research ethics committee, when they could otherwise proceed unhindered: an example of the adage that 'you can do anything you like, as long as you promise not to learn from it'.
The consequences of the poor alignment between ethical recommendations and the specificities of improvement evaluations are highly practical and far reaching. For instance, the assumption that the researcher controls any prospectively evaluated intervention is so strongly entrenched that it is difficult to register an evaluation of a policymaker's intervention on ClinicalTrials.gov, the first, largest and most widely used clinical trials registry. If individuals are not 'assigned by an investigator… to receive specific interventions', then the study must be classified as observational, according to their guidelines. Moreover, having entered 'observational' the study cannot then be classified as prospective, but must be classified as retrospective in order to be accepted by the system. Thus, a prospective stepped-wedge randomised controlled trial in which researcher involvement with the intervention and its implementation is limited only to randomising the order of units in the roll-out must be classified as a retrospective, observational study. The implication is that an investigator cannot mount a prospective study of an intervention implemented by a policymaker or programme leader. The pre-registration of a trial is an essential component to ensuring its validity. The impossibility of registering the type of study we describe here on the largest trials registry is indicative of the lack of consideration given to the 'grey area' of opportunistic evaluation and further serves as another hindrance to conducting valid studies with appropriate oversight.

---

### Studies of medical tests: design and analytical considerations [^1132cBRc]. Chest (2020). Medium credibility.

Medical tests are procedures intended to detect, diagnose, characterize, or monitor a specific medical condition. Understanding the accuracy of a medical test is a critical part of informed decision-making in patient management, as it allows clinicians to appreciate the types of errors a medical test might be prone to making and how often it makes them. Designing a study to assess the performance of a medical test, however, presents unique challenges, from acquiring a reference standard to dealing with the complexities that arise when the test involves an interpretation by a human reader. This article provides an overview of design considerations in this context, including common biases and how to avoid them, statistical considerations, and reporting guidelines. A short list of questions is also provided, which can serve as a quick reference for anyone designing, implementing, or reviewing a study that intends to assess the performance of a medical test.

---

### Self-deception: distorted metacognitive process in ambiguous contexts [^116brsiN]. Human Brain Mapping (2023). Medium credibility.

Third, the circumstances that would allow for false internal representation should be clarified. High ambiguity in attributions or interpretations that allows for distortions of reality would make self‐deception feasible as suggested by previous theories and research (Sloman et al; Zhong et al.). Self‐deception was more often observed when the unsupported evidence for false belief is vague (Sloman et al; Zhong et al.). When the feedback on the task uses precise terms rather than vague terms (Sloman et al.) or the answer keys are not easily accessible (Zhong et al.), participants would then be less likely to distort reality.

Previous functional magnetic resonance imaging (fMRI) studies of deception usually focus on individuals' dishonest behaviors in the sense of deceiving others, including but not limited to telling lies to others or cheating in a game (Speer et al; Yin et al; Yin & Weber,), with deceiving oneself less explored. As we introduced above, to capture the biased mental process in self‐deception, contexts should allow ambiguous interpretations or attributions. In this sense, cheating tasks that offer individuals cheating opportunities to elevate their perceived performance, are one of the qualified options. By applying cheating tasks in self‐deception studies, previous studies tested participants' task performance and predictions in solving general knowledge tests (Zoe Chance et al; Zoë Chance et al; Ren et al; Zhong et al.). The mismatch between actual ability and predictions suggests the occurrence of self‐deception. However, general knowledge tests suffer from the problem of individual variations and might bring up overconfidence (Yates et al.). Besides, using predictions of future performance as a measurement of efficacy belief might not be a true reflection of their beliefs due to the possibility that participants might intentionally match their predictions to their elevated performance for covering cheating. Last, previous studies did not explicitly investigate the essential factors underlying cheating tasks that make them qualified enough to capture self‐deception in tasks that are unrelated to general knowledge. Circumstances that would allow for false internal representation should be clarified. Manipulating the degree of ambiguous attributions of elevated perceived performance in cheating tasks could help us verify if ambiguous contexts are necessary for self‐deception.

---

### Self-deception: distorted metacognitive process in ambiguous contexts [^114CoNpR]. Human Brain Mapping (2023). Medium credibility.

Second, self‐deception could be self‐enhanced or self‐diminished. Previous studies suggested that self‐deception might arise from the motivation of seeing the self and the world positively (Zoë Chance & Norton; Zoë Chance et al; Schwardmann & van der Weele; van der Leer & McKay). For example, a previous behavioral study found that individuals who cheated on tests were more engaged in self‐deception, believing that the good performance was due to their intelligence (Zoë Chance et al.). In our study, although participants' performance was significantly better in the answer cue phase than that in the no‐answer cue session, suggesting a significant proportion of cheating, overestimation of future performance was not observed at the group level. Despite overconfidence being a kind of false belief, self‐deception is not necessarily equal to an unrealistic positive view of oneself or the world (Trivers). Cultural differences in self‐serving biases and self‐criticism might also contribute to our current findings (Heine et al; Heine & Hamamura; Mezulis et al.).

---

### Definition of "experimental procedures" [^112qm4Wo]. Fertility and Sterility (2009). Low credibility.

This Practice Committee Opinion provides a revised definition of "experimental procedures". This version replaces the document "Definition of Experimental" that was published most recently in November 2008.

---

### Common errors in statistics and methods [^114yqoDu]. BMJ Paediatrics Open (2024). High credibility.

Quality assessment of studies

Quality assessment should be performed as a quantitative assessment of the studies included in meta-analysis using a set of predefined safeguards to reduce the risks of bias. Quality assessment tools should be used as they were designed to be used, with any user-defined adaptations clearly justified. Any issues of quality or potential risk of bias, which may impact on meta-analysis results, should be briefly described. Quality 'scores' should only be assigned according to scoring systems defined by the tool, and user-defined scores (ie, user-defined thresholds for high, moderate, low quality, etc) should be avoided. While a study with the best 'score' does not ensure high quality, it ensures that predefined safeguards to reduce risks of bias are met.

Lack of grading the certainty of the main results in meta-analysis

It is common practice to accept the combined results of a meta-analysis at face value and categorise them as significant or non-significant without considering the importance of the findings as well as potential biases and flaws in both the individual studies included in the meta-analysis and the overall estimation (particularly heterogeneity, publication bias or small study bias). To be valuable in clinical practice, the results of a meta-analysis should also be evaluated for certainty and quality using methods such as GRADE.

Incomplete info to understand/reproduce the search results in meta-analysis

This is another illustration of the general rule that your paper should have enough information to allow other researchers to duplicate what you did. Some authors simply list terms (and not search engines or detailed search structure) or do not give dates.

---

### Deception is associated with reduced social connection [^112oATWw]. Communications Psychology (2023). Medium credibility.

Deception is the act of intentionally misleading another, and may include complete falsifications (i.e. lies), distorting, or concealing the truth. Engaging in deception differs from truth-telling on many dimensions. For example, deception is more cognitively taxing than telling the truth. Whereas the truth can be relayed from memory, deceptive statements must be invented to be plausible and avoid contradicting prior knowledge of the receiver. Additionally, deception may result in greater (or different) emotional arousal relative to truth-telling. A liar may feel guilty about their behavior, or nervous about their lies being discovered. Alternatively, deception may involve attempting to falsify emotions that are not actually felt, or hiding experienced emotions. Other research suggests that deception may be associated with more impression management, relative to telling the truth. Attempts to appear honest might backfire if a liar overcontrols their behavior, resulting in an unnaturally stiff impression. These theories are purported to predict behavioral cues that may reveal deception in real-time. Indeed, a primary focus of research on deception has been on detecting its behavioral manifestations, with relatively little attention on the internal experience and intrapersonal consequences of this common conversational act.

People sometimes engage in deception because they are seeking personal gain or to avoid negative consequences. Other times, people avoid having honest conversations because they believe that it will be uncomfortable, unpleasant, or perceived as unkind. However, recent research suggests that these concerns may be misplaced. When randomly assigned to spend three days being absolutely honest or kind, participants overestimated the social connection associated with kindness and underestimated the social connection associated with honesty. Although this research did not include a lie condition, it suggests that engaging in deception may have negative consequences for feelings of social connection. Relatedly, research has examined the process and consequences of keeping secrets, which are conceptually similar to deception in that they also involve concealing the truth. People report that they feel 'alone' with their secrets and that keeping secrets makes them feel isolated from others. Similarly, a longitudinal study found that adolescent secret-keeping was bi-directionally associated with decreased parent-child relationship quality. Thus, while research has not examined the effect of telling lies on social connection in dyadic conversations with strangers or on feelings of loneliness, related work supports this possibility.

---

### 2018 ESC guidelines for the diagnosis and management of syncope [^113k4pDA]. European Heart Journal (2018). Medium credibility.

Regarding diagnostic investigations for syncope, more specifically with respect to history and physical examination, ESC 2018 guidelines recommend to elicit a careful history (concerning present and previous attacks, as well as eyewitness accounts, in person or through a telephone interview) and perform a physical examination (including supine and standing BP measurements) in patients with transient loss of consciousness of suspected syncopal nature.

---

### Should desperate volunteers be included in randomised controlled trials? [^111LU7SE]. Journal of Medical Ethics (2006). Low credibility.

Randomised controlled trials (RCTs) sometimes recruit participants who are desperate to receive the experimental treatment. This paper defends the practice against three arguments that suggest it is unethical first, desperate volunteers are not in equipoise. Second clinicians, entering patients onto trials are disavowing their therapeutic obligation to deliver the best treatment; they are following trial protocols rather than delivering individualised care. Research is not treatment; its ethical justification is different. Consent is crucial. Third, desperate volunteers do not give proper consent: effectively, they are coerced. This paper responds by advocating a notion of equipoise based on expert knowledge and widely shared values. Where such collective, expert equipoise exists there is a prima facie case for an RCT. Next the paper argues that trial entry does not involve clinicians disavowing their therapeutic obligation; individualised care based on insufficient evidence is not in patients best interest. Finally, it argues that where equipoise exists it is acceptable to limit access to experimental agents; desperate volunteers are not coerced because their desperation does not translate into a right to receive what they desire.

---

### Separate the sheep from the goats: use and limitations of large animal models in intervertebral disc research [^113bNnDR]. The Journal of Bone and Joint Surgery: American Volume (2017). Low credibility.

Approximately 5,168 large animals (pigs, sheep, goats, and cattle) were used for intervertebral disc research in identified studies published between 1985 and 2016. Most of the reviewed studies revealed a low scientific impact, a lack of sound justifications for the animal models, and a number of deficiencies in the documentation of the animal experimentation. The scientific community should take suitable measures to investigate the presumption that animal models have translational value in intervertebral disc research. Recommendations for future investigations are provided to improve the quality, validity, and usefulness of animal studies for intervertebral disc research. More in vivo studies are warranted to comprehensively evaluate the suitability of animal models in various applications and help place animal models as an integral, complementary part of intervertebral disc research.

---

### Strengthening causal inference from randomised controlled trials of complex interventions [^115Dmm8E]. BMJ Global Health (2022). High credibility.

Multiplicity in trials of complex interventions

Multiplicity occurs when many comparisons are carried out. Multiplicity has raised concerns about false-positive findings, which has led to recommendations to limit the number of comparisons made and/or to implement statistical adjustments based on the number of comparisons that are made. The latter recommendation is controversial with markedly opposing views. Multiplicity can arise in trials in general for six reasons:

A trial has multiple outcomes of interest.
Researchers conduct analyses to understand differences in effects across subgroups.
Trials have more than two study arms.
Findings from initial comparisons prompt examining other comparisons or relationships.
Analyses of repeated measures of the same outcomes are conducted, that is, when participants are assessed at multiple visits.
Interim analyses are conducted.

We discuss the first reason (ie, multiple outcomes) in depth and then each of the other five reasons briefly for trials of complex interventions.

Multiple outcomes of interest

When a set of hypotheses (each about a different outcome) is tested simultaneously, the overall type I error rate, that is, the probability of wrongly rejecting at least one null hypothesis, increases. Simultaneous hypothesis testing assumes a universal null hypothesis that the intervention has no effect for all the outcomes investigated versus the alternative hypothesis of impact on at least one of these outcomes. Adjusting for multiplicity is only warranted if a set of hypotheses is tested simultaneously in this formal sense, but this test of a universal null vs the stated alternative hypothesis is nearly always irrelevant to the scientific or evaluation questions being investigated. When each hypothesis is limited to a single outcome, as is typically the case in impact evaluation, the probability of a false positive result remains the same irrespective of whether one or a million comparisons are tested. Because the p value is a simple transformation of a test statistic (eg, t-statistic or χ² statistic) for a given outcome to a 0–1 scale using the assumed (eg, t or χ²) distribution, the type I error rate holds for that outcome regardless of whether other outcomes have been similarly transformed.

---

### P value and the theory of hypothesis testing: an explanation for new researchers [^113Zt6wN]. Clinical Orthopaedics and Related Research (2010). Low credibility.

In the 1920s, Ronald Fisher developed the theory behind the p value and Jerzy Neyman and Egon Pearson developed the theory of hypothesis testing. These distinct theories have provided researchers important quantitative tools to confirm or refute their hypotheses. The p value is the probability to obtain an effect equal to or more extreme than the one observed presuming the null hypothesis of no effect is true; it gives researchers a measure of the strength of evidence against the null hypothesis. As commonly used, investigators will select a threshold p value below which they will reject the null hypothesis. The theory of hypothesis testing allows researchers to reject a null hypothesis in favor of an alternative hypothesis of some effect. As commonly used, investigators choose Type I error (rejecting the null hypothesis when it is true) and Type II error (accepting the null hypothesis when it is false) levels and determine some critical region. If the test statistic falls into that critical region, the null hypothesis is rejected in favor of the alternative hypothesis. Despite similarities between the two, the p value and the theory of hypothesis testing are different theories that often are misunderstood and confused, leading researchers to improper conclusions. Perhaps the most common misconception is to consider the p value as the probability that the null hypothesis is true rather than the probability of obtaining the difference observed, or one that is more extreme, considering the null is true. Another concern is the risk that an important proportion of statistically significant results are falsely significant. Researchers should have a minimum understanding of these two theories so that they are better able to plan, conduct, interpret, and report scientific experiments.