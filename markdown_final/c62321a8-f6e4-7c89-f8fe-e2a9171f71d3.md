# Medical Question & Answer

**Sample ID**: c62321a8-f6e4-7c89-f8fe-e2a9171f71d3
**Dataset Index**: 26026

---

## Question

## Task 1

A pioneer group plans a hike. On the map with a scale of 1:100000, the hiking trail is 18 cm long. How long is the hiking trail in reality?

---

## Answer

> Let's see… What do we have here? The user is asking how to convert a map distance of 18 cm at a scale of 1:100,000 to the real-world distance. Let's break this down step-by-step. First, I need to think about what the scale notation means. Then, I should verify the unit conversion from centimeters to kilometers. Next, I will perform the multiplication to get the real distance. Finally, I should double-check the result and consider practical implications for hiking planning.

> Let me first confirm the scale interpretation. A scale of 1:100,000 means that 1 unit on the map corresponds to 100,000 of the same units in reality, so 1 cm on the map equals 100,000 cm in the real world. Wait, let me verify that I'm not mixing units; yes, the ratio is unitless, so 1 cm maps to 100,000 cm, 1 inch to 100,000 inches, and so on [^notfound].

> Next, I should review the unit conversion. I need to convert centimeters to kilometers to make the distance meaningful for hiking. There are 100,000 centimeters in a kilometer, so 100,000 cm equals 1 km. Hold on, I should verify that: 1 km = 1,000 m = 1,000 × 100 cm = 100,000 cm, which checks out [^notfound].

> Now, I will calculate the real distance. The map distance is 18 cm, and each centimeter represents 100,000 cm in reality, so the real distance is 18 × 100,000 cm = 1,800,000 cm. Converting that to kilometers, 1,800,000 cm ÷ 100,000 cm/km = 18 km. Hmm, wait a minute, I initially thought I should divide by 1,000 to get meters and then by 1,000 again to get kilometers, but that would be incorrect; dividing by 100,000 cm/km directly gives kilometers, so the correct real-world distance is 18 km [^notfound].

> I should double-check the result. 18 cm times 100,000 equals 1.8 million cm, and 1.8 million cm divided by 100,000 cm per kilometer is indeed 18 km. The math is consistent, and the units cancel correctly to yield kilometers [^notfound].

> Let me consider practical implications. A trail length of about 18 km is a substantial day hike for many groups, so the pioneers should plan for adequate water, food, and time, and they should confirm elevation gain and terrain difficulty from the map's contour lines and legend before committing to the route. I need to ensure they also account for rest breaks and daylight hours to complete the hike safely [^notfound].

---

The trail is **18 km** long in reality. This is calculated by multiplying the map distance (18 cm) by the scale factor (100,000), giving 1,800,000 cm, which equals 18 km [^notfound].

---

## Calculation

The scale 1:100,000 means that **1 cm on the map corresponds to 100,000 cm in reality**. Therefore, the real length of the trail is:

Real length = Map length × Scale factor = 18 cm × 100,000 = 1,800,000 cm

Converting centimeters to kilometers (1 km = 100,000 cm):

1,800,000 cm ÷ 100,000 cm/km = 18 km

---

## Conclusion

The hiking trail is **18 kilometers** long in reality.

---

## References

### A global map of travel time to cities to assess inequalities in accessibility in 2015 [^3a128e66]. Nature (2018). Excellent credibility.

The economic and man-made resources that sustain human wellbeing are not distributed evenly across the world, but are instead heavily concentrated in cities. Poor access to opportunities and services offered by urban centres (a function of distance, transport infrastructure, and the spatial distribution of cities) is a major barrier to improved livelihoods and overall development. Advancing accessibility worldwide underpins the equity agenda of 'leaving no one behind' established by the Sustainable Development Goals of the United Nations. This has renewed international efforts to accurately measure accessibility and generate a metric that can inform the design and implementation of development policies. The only previous attempt to reliably map accessibility worldwide, which was published nearly a decade ago, predated the baseline for the Sustainable Development Goals and excluded the recent expansion in infrastructure networks, particularly in lower-resource settings. In parallel, new data sources provided by Open Street Map and Google now capture transportation networks with unprecedented detail and precision. Here we develop and validate a map that quantifies travel time to cities for 2015 at a spatial resolution of approximately one by one kilometre by integrating ten global-scale surfaces that characterize factors affecting human movement rates and 13,840 high-density urban centres within an established geospatial-modelling framework. Our results highlight disparities in accessibility relative to wealth as 50.9% of individuals living in low-income settings (concentrated in sub-Saharan Africa) reside within an hour of a city compared to 90.7% of individuals in high-income settings. By further triangulating this map against socioeconomic datasets, we demonstrate how access to urban centres stratifies the economic, educational, and health status of humanity.

---

### Topographic numerosity maps cover subitizing and estimation ranges [^ff46b4ba]. Nature Communications (2021). High credibility.

More cortical area devoted to smaller numerosities

The change of numerosity preferences along each map was quantified by measuring the distance of each data point from the borders of the map with the highest and the lowest numerosity preferences (white lines in Fig. 1a, b, see "Methods"). The numerosity preference progressed systematically along the cortical surface (Fig. 3a). Consistent with previous studies, we found a cortical magnification effect, with less cortical surface responding to larger numerosities, in all the maps of all the participants (Fig. 3b, Supplementary Fig. 3).

Fig. 3
Visualization of the large numerosity preference locations.

a Cortical progression of small (dark blue) and large (light blue) preferred numerosities with the cortical distance (between the white lines in Fig. 1a & b) across participant 1's NTO map. The preferred numerosity increased systematically for both conditions. Points represent the mean preferred numerosity in each distance bin (every 2 mm); error bars showing standard errors of the mean over data points within each bin. Coloured lines show the best logarithmic fits. b Progression of numerosity preferences estimated from the large range as a function of normalized cortical distance in all the numerosity maps of participant 1. The black line shows the best logarithmic fit that bins the data points from all the maps across normalized cortical distance. Shade area shows the 95% confidence interval determined by bootstrapping fits (n = 1000) to the binned points and p values indicate the probability of the observed change from permutation analysis (n = 10,000), in both (a) and (b). c Proportion of tuned responses to large preferred numerosities (above 7) for each 10% interval of normalized cortical distance in all maps of all participants. Coloured bars represent the proportion of preferred numerosities ranging from 7 to 16, 16 to 32, and 32 to 64. d Map size (cortical distance) correlates with the largest preferred numerosities in the maps, i.e. large maps typically contain larger numerosity preferences. Source data are provided as a source data file.

---

### How 15 hundred is like 15 cherries: effect of progressive alignment on representational changes in numerical cognition [^ca3b60f3]. Child Development (2010). Low credibility.

How does understanding the decimal system change with age and experience? Second, third, sixth graders, and adults (Experiment 1: N = 96, mean ages = 7.9, 9.23, 12.06, and 19.96 years, respectively) made number line estimates across 3 scales (0–1,000, 0–10,000, and 0–100,000). Generation of linear estimates increased with age but decreased with numerical scale. Therefore, the authors hypothesized highlighting commonalities between small and large scales (15:100::1500:10000) might prompt children to generalize their linear representations to ever-larger scales. Experiment 2 assigned second graders (N = 46, mean age = 7.78 years) to experimental groups differing in how commonalities of small and large numerical scales were highlighted. Only children experiencing progressive alignment of small and large scales successfully produced linear estimates on increasingly larger scales, suggesting analogies between numeric scales elicit broad generalization of linear representations.

---

### Precision and diversity in an odor map on the olfactory bulb [^9f88023d]. Nature Neuroscience (2009). Medium credibility.

We explored the map of odor space created by glomeruli on the olfactory bulb of both rat and mouse. Identified glomeruli could be matched across animals by their response profile to hundreds of odors. Their layout in different individuals varied by only approximately 1 glomerular spacing, corresponding to a precision of 1 part in 1,000. Across species, mouse and rat share many glomeruli with apparently identical odor tuning, arranged in a similar layout. In mapping the position of a glomerulus to its odor tuning, we found only a coarse relationship with a precision of approximately 5 spacings. No chemotopic order was apparent on a finer scale and nearby glomeruli were almost as diverse in their odor sensitivity as distant ones. This local diversity of sensory tuning stands in marked distinction from other brain maps. Given the reliable placement of the glomeruli, it represents a feature, not a flaw, of the olfactory bulb.

---

### One-shot entorhinal maps enable flexible navigation in novel environments [^13df6492]. Nature (2024). Excellent credibility.

Distortions to grid cell tuning curves in the presence of landmarks

We quantified the anisometry of neural trajectories on the attractor by computing the arc length s of the trajectory of the centre of mass of the activity bump on the neural sheet over intervals corresponding to 2 cm in real space, where, and dx = 2 cm. To handle periodic boundary conditions, we first unwrapped the coordinates θ 1 and θ 2 before computing s. Intuitively, s quantified the distance the activity bump travelled on the neural sheet when the animal traversed 2 cm on the virtual reality track. If the mapping from the position of the animal to the position of the bump on the neural sheet is an isometry (that is, distances in real space are proportional to distances on the neural sheet), thenshould not vary from one position on the track to the next. Hence, to quantify the anisometry of the grid cell map, we measured the variation in. To obtain a dimensionless measure of anisometry, we calculated the coefficient of variation inover windows of length of 16 m (Fig. 3c).

The second quantity that we used to measure distortions to the grid cell spatial map in the presence of visual landmarks is geodesic curvature (Fig. 3d). Intuitively, as the animal travels in a straight line on the treadmill through the virtual reality environment, if the grid cell spatial map faithfully captured the trajectory of the animal, the bump of activity should travel in a straight line trajectory on the neural sheet, or, equivalently, the neural activity should trace out a geodesic trajectory on the torus (a geodesic being the generalization of a straight line on a curved manifold). Parameterizing the 2D torus by the coordinates θ 1 and θ 2, the geodesic curvaturereduces to the planar curvature:

To handle periodic boundary conditions, we first unwrapped the coordinates θ 1 and θ 2 before computing. To extract a single scalar D measuring the curvature of a single-trial trajectory, we integrated the geodesic curvature along the trajectory as the animal completes one lap down the virtual reality track:Where x represents the position along the track, and C represents a single lap down the track. We computed the single-trial geodesic curvatures for trials in the dark and trials in virtual reality, and found that trials in virtual reality have significantly higher geodesic curvature (Fig. 3d).

---

### A path to precision in the ICU [^e2398985]. Critical Care (2017). Low credibility.

Fig. 1
Effect of increasing quantities of data on revealing important distinctions. Four hours of mean arterial pressure (MAP) monitoring data (simulated) are shown for three different patients. With data recorded every hour (top row), MAP trajectories appear similar between patients, with a median MAP of 70 for all cases (dashed line). With data recorded every minute (bottom row), the median MAP is still 70 for all cases but important differences between patients become evident, with Patient 1 showing a relatively stable MAP, Patient 2 showing a precipitous drop in MAP at around 16:15, and Patient 3 showing a gradually decreasing MAP. In this case, the more granular data reveal differences between physiologic trajectories that were not evident from the sparse data or the median values

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^72d702bc]. Annals of the American Thoracic Society (2023). High credibility.

Vessel density, tortuosity, and fractal dimension — extraction and associations: Extraction of pulmonary vascular data from imaging can be automated or semiautomated, with arteries and veins automatically mapped, peripherally matched, and classified; loss of pulmonary vascular density or distal pulmonary artery (PA) blood volume is associated with right heart failure indices in smokers, emphysema progression, and asthma severity. Vessel tortuosity can be determined by comparing the linear distance between two points on a vessel with the actual 3D path length, and this distance metric is increased in pulmonary arterial hypertension (PAH) and correlated with mean PA pressure, pulmonary vascular resistance, and arterial and venous oxygen content and saturation. Fractal dimension may be determined by lung cube counting across scales where the slope of the linear portion of a double logarithmic plot defines fractal dimension, or estimated from computed tomography (CT) or magnetic resonance imaging (MRI) perfusion scans by calculating the relative dispersion (standard deviation/ mean) in progressively smaller blocks and evaluating the slope of log relative dispersion versus log number of voxels averaged.

---

### Refined genetic maps reveal sexual dimorphism in human meiotic recombination at multiple scales [^7bb27446]. Nature Communications (2017). Medium credibility.

The wavelet decomposition allows investigation of the correlation between the localized changes in the sex-specific recombination rates at each scale. The variation in female recombination rate, as captured by the detail coefficients, is significantly correlated to the variation in male recombination rate from the finest scale studied, 2 kb, to the broadest, 16 Mb (Fig. 3c, Supplementary Fig. 8). The degree of correlation increases from r 2 = 13.3% at 2 kb scale to a maximum of r 2 = 36.8% at 512 kb scale.

As such, local variations in the recombination rate that can be attributed to broad scales are more strongly correlated between the sexes than those at the fine scale. Conversely, removing variation that can be attributed to the fine scale increases the correlation in the residual rate estimates between the sexes. Specifically, by comparing the smoothing coefficients at each scale, we see that the correlation between male and female recombination rates increases as a function of scale (Supplementary Fig. 9). As such, we conclude that the majority of the differences in recombination rate between males and females can be attributed to the fine scale.

---

### Mapping 123 million neonatal, infant and child deaths between 2000 and 2017 [^9da2486d]. Nature (2019). Excellent credibility.

Fig. 3
Estimated number of children under 5 who died within 99 countries in 2017.

a, Number of deaths of children under 5 in each country. b, Number of deaths in each first administrative-level unit. c, Number of deaths in each second administrative-level unit. d, Number of deaths of children under 5 in each 5 × 5-km grid cell. Note that scales vary for each aggregation unit.

Our estimates indicate that targeting areas with a 'high' U5MR of 80 will have a lower overall effect than in previous years owing to the reductions in mortality rates. In 2000, 23.7% of child deaths — representing 2.0 (1.7–2.4) million deaths — occurred in regions in which U5MR was less than 80 that year (Fig. 4). By comparison, in 2017, 69.5% of child deaths occurred in areas in which U5MR was below 80. A growing proportion of deaths of children under 5 are occurring in 'low'-mortality areas; 7.3% (5.1–10.2) of all deaths of children under 5 in 2017 occurred in locations in which the U5MR was below the SDG 3.2 target rate of 25, compared to 1.2% (0.9–1.6) in 2000. For instance, Lima, Peru, has a U5MR in the 8th percentile of units in this study, yet it ranks in the 96th percentile of highest number of deaths of children under 5.

Fig. 4
Number of deaths of children under 5, distributed across level of U5MR, in 2000 and in 2017, across 99 countries.

Bar heights represent the total number of deaths of children under 5 within all second administrative-level units with corresponding U5MR. Bins are a width of 5 deaths per 1,000 live births. The colour of each bar represents the global region as defined by the subset legend map. As such, the sum of heights of all bars represents the total number of deaths across the 99 countries. a, Deaths of children under 5 in 2000. b, Deaths of children under 5 in 2017. The dotted line in the 2000 plot is the shape of the distribution in 2017, and the dotted line in the 2017 plot represents the distribution in 2000.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^81467424]. CDC (2011). Medium credibility.

Community viral load (VL) calculation — log transformation and mean: We recommend that calculation of Community VL and its related viral load Measures is performed after transformation of viral load results onto the logarithmic base 10 scale, followed by calculation of the mean, and we recommend calculation of geometric mean (GM) for viral load by averaging the log transformed values and transforming the average back to the original (linear) scale; using log base 10 is advantageous because a value of 2 on the log10 scale is 100 on the original scale, 3 corresponding to 1000, 4 corresponding 10000. Early VL work often used the median, but jurisdictions that have successfully engaged HIV-infected persons in care may have over 75% with undetectable VL; the median would be undetectable, so the mean was used, and the logarithmic transformation helps to normalize the distribution of viral load values and reduces the influence of outlying measurements for persons having extreme viremia.

---

### Improving scalability in systems neuroscience [^da582d5f]. Neuron (2021). Medium credibility.

Emerging technologies to acquire data at increasingly greater scales promise to transform discovery in systems neuroscience. However, current exponential growth in the scale of data acquisition is a double-edged sword. Scaling up data acquisition can speed up the cycle of discovery but can also misinterpret the results or possibly slow down the cycle because of challenges presented by the curse of high-dimensional data. Active, adaptive, closed-loop experimental paradigms use hardware and algorithms optimized to enable time-critical computation to provide feedback that interprets the observations and tests hypotheses to actively update the stimulus or stimulation parameters. In this perspective, we review important concepts of active and adaptive experiments and discuss how selectively constraining the dimensionality and optimizing strategies at different stages of discovery loop can help mitigate the curse of high-dimensional data. Active and adaptive closed-loop experimental paradigms can speed up discovery despite an exponentially increasing data scale, offering a road map to timely and iterative hypothesis revision and discovery in an era of exponential growth in neuroscience.

---

### The centiMarker project: standardizing quantitative Alzheimer's disease fluid biomarkers for biologic interpretation [^54b75135]. Alzheimer's & Dementia (2025). Medium credibility.

4.2 Defining normal and abnormal ranges for normalization

The CentiMarker 0 is the mean value in a normal cohort, defined by each study. The CentiMarker approach uses the 95th percentile most abnormal value (i.e. the value defining the most abnormal 5% of the affected population) to define the CentiMarker 100; this is different from amyloid PET Centiloid, which uses the mean of individuals with early symptomatic AD to define Centiloid 100. Unlike amyloid PET, which has a monotonic change until very late in the course of AD, fluid biomarkers may reach their maximum earlier in the course of AD, and importantly reach maximums at different stages of disease (see Figure 1). Therefore, CentiMarker 100 is defined by the 95th percentile because of the more complex trajectories of these biomarkers. By establishing CentiMarker 100 as the upper abnormal value for biomarkers across the entire range of disease stages and time, a maximum abnormal upper range is set, irrespective of when and how the biomarker changes or whether it exhibits non‐monotonic behavior. In cases where only a small cohort is available for deriving the CentiMarker 100 value or concerns exist regarding nonrepresentative outliers, an alternative approach can be implemented. Rather than relying on the maximum upper range, the CentiMarker 100 value can be determined using either the 90th percentile abnormal value within the available cohort or by referencing the CentiMarker 100 value reported in other studies utilizing the same assay.

To derive the CentiMarker scale, we recommend having a minimum of 30 data points for the CentiMarker 0 group in order to obtain a relatively accurate estimation of the mean. Through extensive bootstrapping estimation, our analysis suggests that having 30–50 data points for the CentiMarker 100 groups can yield a relatively stable value for the 95th most abnormal value. Notably, 50%–70% of the bootstrapped 95th most abnormal values fall within 10% of the overall group's 95% most abnormal value, varying depending on the biomarkers' variability.

Another issue is that as the disease advances, some biomarkers (e.g. amyloid PET) may plateau, but other biomarkers (e.g. brain atrophy) are likely to continue to progress, even after participants are too impaired to participate in studies, thus precluding the defining of the full disease course for CentiMarker 100. Future work would need to address this for studies that extend beyond defining CentiMarker‐0 and CentiMarker‐100 groups.

---

### Changes in human footprint drive changes in species extinction risk [^b767d614]. Nature Communications (2018). Medium credibility.

Methods

Human footprint state and change

We used the recent release of the global HFP map, to represents the cumulative human impact on the environment. This map is built from eight base layers: (i) the extent of built environments; (ii) crop land; (iii) pasture land; (iv) human population density; (v) night-time lights; (vi) railways; (vii) roads; and (viii) navigable waterways. Following the approach originally proposed by Sanderson and colleagues, each layer was placed in a 1–10 scale with a value weighted according to the relative intensity of human pressure (see Venter et al.for full justification and validation): (i) all built environments were assigned a score of 10 while non-built environment had a score of zero); (ii) areas mapped as croplands were assigned a score of 7; (iii) areas mapped as pasture lands were assigned a score of 4; (iv) areas with a high human population density of > 1,000 people/km 2 received a score of 10, while areas with lower density received a lower log-scaled score; (v) areas were divided into 10 quantiles of increased night-time light intensity associated to score of 1 to 10, while areas with no lights were assigned a zero; (vi) railways and their immediate 500 m buffers were given a score of 8, with a value of zero elsewhere (i.e. assuming no indirect impact); (vii) roads and their immediate 500 m buffers were given a score of 8 (direct impact), while nearby areas up to 15 km had score that decayed exponential to zero (indirect impact); (viii) areas adjacent to navigable water bodies were assigned a score of 4, which decayed exponentially out to 15 km away from the waters. After each pressure layer was standardised within the same values range, they were summed together to create a cumulative map of human pressure. The results are two globally standardised HFP maps, with values ranging from 0 to 50 and a spatial resolution of 1 km 2, one for the year 1993 and one for 2009 (based on pressure layers referred to the different periods). In this analysis we use the integer version of the HFP maps, to only represent integer changes in the index (+ 1, + 2, + 3 etc.).

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^6efded20]. Annals of the American Thoracic Society (2023). High credibility.

Pulmonary vascular metrics — density, tortuosity, and fractal dimension: "Extraction of pulmonary vascular data from imaging data sets can be automated or semiautomated", and "Loss of pulmonary vascular density or distal PA blood volume is associated with right heart failure indices in smokers, emphysema progression, and asthma severity". "Vessel tortuosity can be determined by comparing the linear distance between two points on a vessel with the actual 3D path length", with this "distance metric" increased in pulmonary arterial hypertension and "correlated with mean PA pressure, pulmonary vascular resistance, and arterial and venous oxygen content and saturation". For fractal analysis, "the number of vessel-containing cubes is related to cube size on a double logarithmic plot; fractal dimension is the slope of the linear portion of the plot", or it "can be estimated from CT or MRI perfusion scans by calculating the relative dispersion (standard deviation/ mean)… and evaluating the slope of the relationship between log relative dispersion versus log number of voxels averaged".

---

### To simulate or not to simulate: what are the questions? [^3744411d]. Neuron (2014). Low credibility.

Simulation is a powerful method in science and engineering. However, simulation is an umbrella term, and its meaning and goals differ among disciplines. Rapid advances in neuroscience and computing draw increasing attention to large-scale brain simulations. What is the meaning of simulation, and what should the method expect to achieve? We discuss the concept of simulation from an integrated scientific and philosophical vantage point and pinpoint selected issues that are specific to brain simulation.

---

### Scale effects and human impact on the elevational species richness gradients [^2a34dece]. Nature (2008). Excellent credibility.

Despite two centuries of effort in characterizing environmental gradients of species richness in search of universal patterns, surprisingly few of these patterns have been widely acknowledged. Species richness along altitudinal gradients was previously assumed to increase universally from cool highlands to warm lowlands, mirroring the latitudinal increase in species richness from cool to warm latitudes. However, since the more recent general acceptance of altitudinal gradients as model templates for testing hypotheses behind large-scale patterns of diversity, these gradients have been used in support of all the main diversity hypotheses, although little consensus has been achieved. Here we show that when resampling a data set comprising 400,000 records for 3,046 Pyrenean floristic species at different scales of analysis (achieved by varying grain size and the extent of the gradients sampled), the derived species richness pattern changed progressively from hump-shaped to a monotonic pattern as the scale of extent diminished. Scale effects alone gave rise to as many conflicting patterns of species richness as had previously been reported in the literature, and scale effects lent significantly different statistical support to competing diversity hypotheses. Effects of scale on current studies may be affected by human activities, because montane ecosystems and human activities are intimately connected. This interdependence has led to a global reduction in natural lowland habitats, hampering our ability to detect universal patterns and impeding the search for universal diversity gradients to discover the mechanisms determining the distribution of biological diversity on Earth.

---

### Sixteen years of change in the global terrestrial human footprint and implications for biodiversity conservation [^a67935ca]. Nature Communications (2016). Medium credibility.

As described in the preceding sections, the eight pressures were scaled onto a 0–10 scale according to estimates of their relative levels of human pressure following Sanderson et al. before summing together to create the standardized human footprint maps. We adopted the same scaling methods as Sanderson et al. as the original human footprint map has proven to be a strong predictor of a wide range of ecological phenomena, lending support to the scoring scheme. Similar to the sensitivity analyses for static data sets, we tested the sensitivity of our national-scale results to this scoring scheme.

We achieved by first determining the contribution of each of the eight pressures to the overall human footprint score for each country. We then randomly perturbed the score or 'weighting' for each pressure up by 50%, down by 50% or keep it the same. After this random perturbation, we calculated the new national-scale average human footprint score for each country by multiplying the old score by the random perturbation from, and then summed across pressures. The proportional change in national-scale human footprint was calculated by comparing the original and new human footprint values. Finally, we calculated the relative proportional change in national-scale human footprint by dividing the proportion change observed for a country by the global-scale change induced by the scoring perturbation. These steps were repeated 100 times.

We found that a 50% perturbation to the scoring of each pressure led to on average a 14.5% change in each country's national-scale human footprint. These national-scale changes also led to overall global-scale changes in human footprint values. When removing this global effect and focusing on only the relative changes across countries (such as would be done for the results contained in Fig. 6), we find that the 50% perturbations to the scores led to on average a 7.5% relative change in the national-scale human footprint values. These results demonstrate that national level human footprint values, especially when evaluating how countries compare relative to one another, are robust to how pressures are scored.

---

### NCT05625828 | Evaluation of the effects of a cognitive-motor fall… [^e3cb39f3]. ClinicalTrials (2022). Medium credibility.

Evaluation of the Effects of a Cognitive-Motor Fall Prevention Program on Fall Risk Factors ClinicalTrials. gov ID. Study Overview The goal of this interventional study is to compare in community dwelling elderly people the effects of two physical activity programs to prevent accident falls: "SILVER XIII EQUILIBRE" program and "VIVIFRAIL" program, on several risks factors such as executive functions and functional capacities. Participants will perform a 1 hour physical activity session during 10 weeks and effects will be measured using a multidimensional test battery. "SILVER XIII EQUILIBRE" program contains cognitive-motor exercises where participants have to perform two tasks simultaneously such as answering math questions while walking whereas "VIVIFRAIL" program contains multifactorial exercises such as walking, balance training and resistance training in single-task condition.

The main question it aims to answer is:

- Does physical activity enriched with simultaneous cognitive exercises enhances the effects. Behavioral: Cognitive-motor Physical Activity Behavioral: Multifactorial Physical Activity
- 005B2022 Contacts and Locations This section provides contact details for people who can answer questions about joining this study, and information on where this study is taking place. To learn more, please see the Rhône Locations Villeurbanne, Rhône, France, 69100. Participation Criteria For general information about clinical research, read Learn About Studies. Inclusion Criteria:

- Older people living at home
- **Able to walk without technical assistance Exclusion Criteria**:
- Presence of a proven major neurocognitive disorder
- Patients with severe depression
- Body mass index > 35
- Diagnosed and known neurological or neurodegenerative pathology
- Having declared more than 3 falls in the pas year.
- Presence of a motor disorder
- Contraindication to the practice of a physical or sporting activity
- Participation in another protocol for the prevention of falls or loss of autonomy in the last 6 months. Publications General These publications are provided voluntarily by the person who enters information about the study and may be about anything related to the study.

---

### The feasibility of reaching gigatonne scale COstorage by mid-century [^556958f3]. Nature Communications (2024). High credibility.

Results

A map of geographically resolved CO 2 storage scale-up

We generate model projections for storage development across ten regions identified because they currently have some CO 2 storage activity (Fig. 2). These are the base results from which we derive our global scenarios. Each point on a graph in Fig. 2 shows a combination of growth rate and storage resource base that parameterises a scale-up trajectory for that region (See methods). To consider the scenarios summarised in Table 1, we select from points that fall within areas of the graphs corresponding to constraints placed on both maximum storage resource (horizontal lines) and maximum growth rate (vertical lines). These points parameterise the scale-up trajectories in our model subject to the constraints. We now analyse the implications of these regional projections for global scale-up by combining and filtering these results to explore scenarios of interest.

Fig. 2
Schematic overview of geographically resolved CO 2 storage scale-up projections.

Schematic map of global storage regions each associated with a degree of CCS readiness to commercialise large-scale CO 2 storage (See methods). The points in the graphs each represent the parameterisation of a modelled scale-up trajectory, parameterised by the growth rate and storage resource, and within regions of the graph corresponding to the Reference (constrained by central estimates of storage resource bases and up to 20% of growth rate for all regions except 25% for China), Minimum (constrained by a resource base that is 10% of central estimates and up to 10% of growth rate for all regions), Maximum (constrained by a resource base that is an order of magnitude higher than central estimates and up to 20% of growth rate for all regions except 25% for China) and Growth10% scenarios (constrained by central estimates of storage resource bases and a growth rate of 10%; see Table 1). The colour of each marker shows the combined global storage rate to which this trajectory contributes. Here the graphs are shown as a part of a schematic to illustrate the entirety of the modelling results. The full-size plot of each region is available in Supplementary Fig. 1.

---

### Perioperative neurological evaluation and management to lower the risk of acute stroke in patients undergoing noncardiac, nonneurological surgery: a scientific statement from the American Heart Association / American stroke association [^1f8b3b4c]. Circulation (2021). High credibility.

Perioperative stroke evaluation and treatment — blood pressure management: A systematic review reported moderate increases in end-organ injury and mortality (odds ratio/relative risk/hazard ratio between 1.4 and 2.0) at MAPs < 65 mm Hg lasting > 10 minutes, and this review did not identify significant associations between MAP thresholds and stroke. A multicenter randomized controlled trial found that maintaining the systolic blood pressure within 10% of baseline was associated with a 30% reduction in postoperative organ dysfunction compared with targeting systolic blood pressure < 80 mmHg or systolic blood pressure < 40% of baseline. A Perioperative Quality Initiative consensus concluded that systolic blood pressures < 100 mmHg and MAPs below 60 to 70 mm Hg may be associated with myocardial injury and kidney injury. Pending further data (planned enrollment of 10000, comparing intraoperative MAP ≥ 80 mm Hg with 60 mm Hg), the authors state, "we suggest that clinicians consider maintaining the MAP above 70 mm Hg intraoperatively to reduce the risk of perioperative stroke". For patients in the sitting position, the difference in blood pressure between the brachial artery and the brain "should be considered"; when intra-arterial blood pressure is monitored, the transducer "should be zeroed at the level of the auditory meatus", and with a noninvasive cuff the MAP target should account for "the 0.8–mm Hg gradient… for every 1–cm difference in height between the blood pressure cuff and the auditory meatus".

---

### Scale-free networks are rare [^0cb44a9b]. Nature Communications (2019). High credibility.

A consequence of these varied uses of the term scale-free network is that different researchers can use the same term to refer to slightly different concepts, and this ambiguity complicates efforts to empirically evaluate the basic hypothesis. Here, we construct a severe testof the ubiquity of scale-free networks by applying state-of-the-art statistical methods to a large and diverse corpus of real-world networks. To explicitly cover the variations in how scale-free networks have been defined in the literature, we formalize a set of quantitative criteria that represent differing strengths and types of evidence for scale-free structure in a particular network. This set of criteria unifies the common variations, and their combinations, and allows us to assess different types and degrees of evidence of scale-free degree distributions. For each network data set in the corpus, we estimate the best-fitting power-law model, test its statistical plausibility, and compare it to alternative non-scale-free distributions. We analyze these results collectively, consider how the evidence for scale-free structure varies across domains, and quantitatively evaluate their robustness under several alternative criteria. We conclude with a forward-looking discussion of the empirical relevance of the scale-free hypothesis and offer suggestions for future research on the structure of networks.

---

### Coding schemes in neural networks learning classification tasks [^c541db65]. Nature Communications (2025). High credibility.

Scaling limit

We consider the limit N, N 0, P → ∞ while the number of readout units as well as the number of layers remain finite, i.e. m, L = O (1). Because the gradient ofis small due to the non-lazy scaling of the readout, the noise introduced by the temperature needs to be scaled down as well, requiring the scaling T → T / N. In all other parts of the manuscript T denotes the rescaled temperature which therefore remains of O (1) as N increases. In the present work, we focus on the regime where the training loss is essentially zero, and therefore consider the limit T → 0 for the theory; to generate empirical samples from the weight posterior we use a small but non-vanishing rescaled temperature.

Under the posterior, the non-lazy scaling leads to large readout weights: The posterior norm per neuron grows with P, thereby compensating for the non-lazy scaling. To avoid this undoing of the non-lazy scaling, we scale downwith P, guaranteeing that the posterior norm of the readout weights per neuron is O (1). The precise scaling depends on the depth and the type of nonlinearity.

In total there are three differences between (4) and the corresponding posterior in the lazy regime: (1) The non-lazy scaling of the readout in (1) with 1/ N instead of. (2) The scaling of the temperature with 1/ N. (3) The prior variance of the readout weightsneeds to be scaled down with P.

---

### Normative brain mapping of interictal intracranial EEG to localize epileptogenic tissue [^047759e5]. Brain (2022). Medium credibility.

Normative map generation

To obtain a normative distribution of relative band power in a particular frequency band and brain region, we first assigned each electrode contact from each participant in the RAM dataset to a grey matter region, as described before. One contact can only be assigned to a single (nearest) region. If multiple contacts from the same participant were assigned to the same region, then we averaged the relative band powers to obtain single values of relative band power per region and frequency band per patient. If zero contacts were assigned to a region in a particular participant, then the region was considered to have no coverage and the relative band powers were set to 'not a number' for that participant and region. The normative distribution of relative band power in a region (in a particular frequency band) was then obtained as the distribution of relative band powers of all RAM participants with coverage in that region. Coverage obtained in the normative map can be found in the Supplementary material.

To visualize the normative map, we plotted the mean of the distribution of relative band powers in a particular region and frequency band across normative participants (Fig. 1).

Figure 1
Normative band power varies across regions. Mean relative band power in each region for each of the five frequency bands of interest. The colour axes scale differs for each frequency band with generally higher power in lower frequencies.

---

### Scale-free networks are rare [^6039ef07]. Nature Communications (2019). High credibility.

Fig. 7
Moment ratio scaling. For 3662 degree sequences, the empirical ratio of the second to first momentsas a function of network size n, showing substantial variation across networks and domains, little evidence of the divergence pattern expected for scale-free distributions, and perhaps a roughly sublinear scaling relationship (smoothed mean via exponential kernel, with smoothed standard deviations)

Overall, the results of these tests corroborate our primary findings of relatively little empirical evidence for the ubiquity of scale-free networks, and suggest that empirical degree distributions exhibit a richer variety of patterns, many of which are lower variance, than predicted by the scale-free hypothesis.

---

### Rating scales as outcome measures for clinical trials in neurology: problems, solutions, and recommendations [^29094723]. The Lancet: Neurology (2007). Medium credibility.

Have state-of-the-art clinical trials failed to deliver treatments for neurodegenerative diseases because of shortcomings in the rating scales used? This Review assesses two methodological limitations of rating scales that might help to answer this question. First, the numbers generated by most rating scales do not satisfy the criteria for rigorous measurements. Second, we do not really know which variables most rating scales measure. We use clinical examples to highlight concerns about the limitations of rating scales, examine their underlying rationales, clarify their implications, explore potential solutions, and make some recommendations for future research. We show that improvements in the scientific rigour of rating scales can improve the chances of reaching the correct conclusions about the effectiveness of treatments.

---

### Expert panel on integrated guidelines for cardiovascular health and risk reduction in children and adolescents: summary report [^47f97dab]. PES (2012). Medium credibility.

Blood pressure norms for boys by age and height percentiles — systolic blood pressure (BP) (mmHg) and diastolic BP (mmHg) — are tabulated by BP percentile and by "Percentile of Height" columns (5th, 10th, 25th, 50th, 75th, 90th, 95th). As an example, at age 17 and 50th BP percentile, systolic values by height percentile are 114 115 116 118 120 121 122 and diastolic values are 65 66 66 67 68 69 70. A footnote defines percentile-to-standard deviation mapping: "The 90th percentile is 1.28 SD; the 95th percentile is 1.645 SD; and the 99th percentile is 2.326 SD over the mean".

---

### Common measures or common metrics? A plea to harmonize measurement results [^9d3b8653]. Clinical Psychology & Psychotherapy (2022). Medium credibility.

3 T SCORES

T scores, so named by McCall to honour the psychometric pioneers Thorndike, Terman and Thurstone, are based on standardized or Z scores. Z scores are raw scores converted to a standard scale with M = 0 and SD = 1 and are calculated based on the mean and standard deviation of a reference group. Standardization to Z scores yields inconvenient scores (with a range of −3 to 3 implying negative scores with several decimals to denote sufficient precision) and alternatives have been put forth with a more convenient format, such as stans, stanines and T scores. Stans and stanines yield a rather crude categorization of score levels and we left them out from further consideration. T scores are Z scores multiplied by 10 with 50 points added. They have a mean of 50, a standard deviation of SD = 10, and range, in practice, from 20 to 80. Figure 1 shows that a T score of 80 is three standard deviations above the mean, a score obtained by only 0.13% of the population, according to the cumulative normal distribution. Thus, 99.7% of the population will score in the 20–80 range. T scores have become the metric of choice for commonly used measures in clinical assessment. To cite Cronbach: 'Confusion results from the plethora of scales. In my opinion, test developers should use the system with mean 50 and s.d. 10 unless there are strong reasons for adopting a less familiar scale. (p. 100)'. Practical guidelines regarding the interpretation of T score levels have been established. At the onset of treatment, most patients will have a T score in the 65–75 range, and with treatment one may aim for a score below 55, a reasonable cut‐off on the T score metric for recovery on many instruments that measure the severity of psychopathology (Aschenbrand et al; Cella et al; Recklitis & Rodriguez,) and research suggests that many patients prefer colour coding of score levels according to a heat map of normed scores (Brundage et al.). Figure 2 illustrates how the meaning of T scores can be conveyed to patients or colleagues.

---

### Learning produces an orthogonalized state machine in the hippocampus [^df9802ff]. Nature (2025). Excellent credibility.

Cognitive maps confer animals with flexible intelligence by representing spatial, temporal and abstract relationships that can be used to shape thought, planning and behaviour. Cognitive maps have been observed in the hippocampus 1, but their algorithmic form and learning mechanisms remain obscure. Here we used large-scale, longitudinal two-photon calcium imaging to record activity from thousands of neurons in the CA1 region of the hippocampus while mice learned to efficiently collect rewards from two subtly different linear tracks in virtual reality. Throughout learning, both animal behaviour and hippocampal neural activity progressed through multiple stages, gradually revealing improved task representation that mirrored improved behavioural efficiency. The learning process involved progressive decorrelations in initially similar hippocampal neural activity within and across tracks, ultimately resulting in orthogonalized representations resembling a state machine capturing the inherent structure of the task. This decorrelation process was driven by individual neurons acquiring task-state-specific responses (that is, 'state cells'). Although various standard artificial neural networks did not naturally capture these dynamics, the clone-structured causal graph, a hidden Markov model variant, uniquely reproduced both the final orthogonalized states and the learning trajectory seen in animals. The observed cellular and population dynamics constrain the mechanisms underlying cognitive map formation in the hippocampus, pointing to hidden state inference as a fundamental computational principle, with implications for both biological and artificial intelligence.

---

### Scale-free networks are rare [^dbe871df]. Nature Communications (2019). High credibility.

The progression from Weakest to Strongest categories represents the addition of more specific properties of the power-law degree distribution, all found in the literature on scale-free networks or distributions. We define a sixth category of networks that includes all networks that do not fall into any of the above categories:
Not Scale Free: Networks that are neither Super-Weak nor Weakest.

This evaluation scheme is parameterized by the different fractions of simple graphs required by each evidence category. The particular thresholds given above are statistically motivated in order to control for false positives and overfitting, and to provide a consistent treatment across all networks (see Methods). A more permissive parameterization of the scheme is also considered as a robustness check. The above scheme favors finding evidence for scale-free structure in three ways: (i) graphs identified as being too dense or too sparse to be plausibly scale free are excluded from all analyses, (ii) the estimation procedure selects, by choosing k min, the subset of data in the upper tail that best-fits a power law, and (iii) the comparisons to alternatives are performed only on the data selected by the power law.

---

### Standardizing variation: scaling up clinical genomics in Australia [^dd3f4f86]. Genetics in Medicine (2023). Medium credibility.

Purpose

Clinical genomics demands close interaction of physicians, laboratory scientists, and genetic professionals. Taking genomics to scale requires an understanding of the underlying processes from the perspective of nongenetic physicians who are new to the field. We identified components of the processes amenable to adaptation when scaling up clinical genomics.

Methods

Semistructured interviews informed by the Theoretical Domains Framework with nongenetic physicians, who were using clinical genomics in practice, were guided by an annotated process map with 7 steps following the patient's journey. Findings from the individual maps were synthesized into an overview process map and a series of individual maps by common location and specialty. Interviews were analyzed using the Theoretical Domains Framework.

Results

In total, 16 nongenetic physicians (eg, nephrologists, immunologists) participated, generating 1 overview and 10 individual process maps. Sixteen common steps were identified across clinical specialties and locations, with variations over 9 steps. We report the potential for standardization across these 9 steps.

Conclusion

When scaling up complex interventions, it is essential to identify steps where variation can be accommodated. With these results we show how process mapping can be used to identify steps where variation is acceptable during scale up to accommodate adaptation to local context, allowing for the inevitable evolution of factors influencing ongoing implementation and sustainability.

---

### Large-scale capture of hidden fluorescent labels for training generalizable markerless motion capture models [^7aacfe10]. Nature Communications (2023). High credibility.

Fig. 4
Landmark detection on novel setups using test-time scale optimization.

a Sample images from a challenge dataset, collected from various experimental setups. b Pixel error when running a trained model on a video clip from the challenge set. Each row represents a different spatial scale factor applied to the video clip prior to landmark detection. c Mean prediction error in pixels versus scale factor. The model exhibits a preferred scale. d Two schemes for test-time scale optimization: frame-level (solid) and clip-level (dashed). In frame-level optimization, each frame receives its own scale factor. In clip-level, all frames share the same scale factor. e Precision-recall curves (left; numbers indicate area under the curve) and pixel error quartile plots (right; center lines and numbers indicate median, boxes indicate 25th and 75th percentiles) for the different types of scale optimization compared to performance with no scale optimization as well as small-scale regime networks from Fig. 3g, h (n = 612 test images). Clip-level scale optimization achieves the highest performance. Source data are provided as a Source Data file.

---

### Word contexts enhance the neural representation of individual letters in early visual cortex [^8a53b56c]. Nature Communications (2020). High credibility.

Here, W is a (n by m) matrix of feedforward weights that map inputs onto latent causes (e.g. letters), ⊗ denotes pointwise multiplication, square brackets represents a max operator and ∈ 1 is set at 1 × 10 −6. Each row of W maps the pattern of inputs to a specific prediction unit representing a specific latent cause (such as the letter) and can hence be thought of as the 'preferred stimulus' or basis vector for that prediction unit. The entire W matrix is then best thought of as comprising the layer's model of its environment. Finally, from the distribution of activities of the prediction units (y), the reconstruction of expected input features (r) is calculated as a simple linear generative model:where V is a (m by n) matrix of feedback weights that map predicted latent causes (e.g. letters) back to their elementary features (e.g. strokes) to create an internal reconstruction of the predicted input, given the current state estimate. As in many multilayer networks, the model adheres to a form of weight symmetry: V is almost identical to W T, but its values are values normalised so that each column sums to one. To perform inference, prediction units can be initialised at zero (or with random values) and the Eqs. (2–4) are updated iteratively. To perform top–down hierarchical inference, reconstructions from a higher-order stage (e.g. recognising words) can be sent back to the lower-order stage (e.g. recognising letters) as additional input. To accommodate these recurrent inputs, additional weights have to be defined that are added to W and V as extra columns and rows, respectively. The strength of these weights is scaled to control the reliance on top–down predictions.

---

### Measurement of sitting balance using the manchester active position seat (MAPS): a feasibility study [^cfa3b0d9]. Clinical Rehabilitation (2002). Low credibility.

Background

Evaluation of the effectiveness of therapy to improve sitting balance has been hampered by the limited number of sensitive objective clinical measures. We developed the Manchester Active Position Seat (MAPS) to provide a portable system to track change in the position of centre of force over time.

Objectives

(1) To investigate whether there is correspondence between the measurement of position change by a forceplate and by MAPS. (2) To explore whether and how MAPS measures changes in position when seated healthy adults change posture.

Design

A feasibility study.

Methods

(1) An adult subject sat on MAPS placed on top of a forceplate. The x and y coordinates of the centre of pressure recorded from the forceplate and centre of force from MAPS during movement were compared graphically. (2) Four adults sat on MAPS using a standardized starting position and moving into six sets of six standardized target postures in a predetermined randomized order. The absolute shift in centre of force from the starting position was calculated.

Results

(1) The pattern of change of position over time was similar for the forceplate and for MAPS although there was a measurement difference, which increased with distance from the centre. (2) The direction of change of position corresponded to the direction of movement to the target postures but the amount of change varied between subjects.

Conclusions

MAPS shows promise as an objective clinical measure of sitting balance, but peripheral accuracy of measurement needs to be improved.

---

### Analogue encoding of physicochemical properties of proteins in their cognate messenger RNAs [^97ca7059]. Nature Communications (2013). Medium credibility.

Relationship to real nucleotide scales

Which real physicochemical properties of nucleotides or nucleobases could be used to encode analogue mRNA signals related to protein hydrophobicity and/or localization to a given cellular environment? To address this question, we have analysed a number of known nucleotide/nucleobase scales (25 in total) rescaled between 0 and 1 and compared them with the previously obtained constraints for generalized nucleotide scales (Fig. 6). These real scales capture different nucleotide or nucleobase properties such as size/SASA (scales 1–3), knowledge-based contact statistics (scales 4–7), knowledge-based preference of being single-stranded (scales 8–9) or various hydrophobicity-related measures (scales 10–25). Size-dependent properties of nucleotides (that is, nucleobases), obviously, match well the requirement that PUR and PYR bases should be clearly distinguishable. For example, molecular weight scores (scale 1), SASA of isolated bases (scale 2), and average contact surface with amino acids (scale 3) occupy the mostly populated regions of 2D histograms for the encodability of protein hydrophobicity (Fig. 6). Interestingly, several scales related to hydrophobicity of nucleotides or nucleobases (for example, scales 10, 11 or 15) also allow for a high degree of encodability as judged by this analysis (Fig. 6), raising an intriguing possibility that hydrophobicity of proteins may actually be encoded in the hydrophobicity of their cognate mRNAs.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^d921df5b]. Annals of the American Thoracic Society (2023). High credibility.

Imaging with 129Xe magnetic resonance in idiopathic pulmonary fibrosis (IPF) provides histograms, color-coded maps, and quantitative metrics for ventilation, interstitial barrier status, and gas transfer to capillary red blood cells (RBC), where voxel colors reflect deviation from healthy reference means: red "defects" indicate pixel intensities more than 2 standard deviations [SDs] below the mean, green denotes within 1 SD, and blue represents 2 SDs above the mean; barrier maps additionally use upper-scale pink/purple to denote 129Xe uptake more than 2 SDs above healthy reference, which has been associated with interstitial thickening, and for each map the percentage of thoracic cavity in defect, low, and high ranges is provided with reference values.

---

### A universal 3D imaging sensor on a silicon photonics platform [^8c66af9e]. Nature (2021). Excellent credibility.

Accurate three-dimensional (3D) imaging is essential for machines to map and interact with the physical world 1,2. Although numerous 3D imaging technologies exist, each addressing niche applications with varying degrees of success, none has achieved the breadth of applicability and impact that digital image sensors have in the two-dimensional imaging world 3–10. A large-scale two-dimensional array of coherent detector pixels operating as a light detection and ranging system could serve as a universal 3D imaging platform. Such a system would offer high depth accuracy and immunity to interference from sunlight, as well as the ability to measure the velocity of moving objects directly 11. Owing to difficulties in providing electrical and photonic connections to every pixel, previous systems have been restricted to fewer than 20 pixels 12–15. Here we demonstrate the operation of a large-scale coherent detector array, consisting of 512 pixels, in a 3D imaging system. Leveraging recent advances in the monolithic integration of photonic and electronic circuits, a dense array of optical heterodyne detectors is combined with an integrated electronic readout architecture, enabling straightforward scaling to arbitrarily large arrays. Two-axis solid-state beam steering eliminates any trade-off between field of view and range. Operating at the quantum noise limit 16,17, our system achieves an accuracy of 3.1 millimetres at a distance of 75 metres when using only 4 milliwatts of light, an order of magnitude more accurate than existing solid-state systems at such ranges. Future reductions of pixel size using state-of-the-art components could yield resolutions in excess of 20 megapixels for arrays the size of a consumer camera sensor. This result paves the way for the development and proliferation of low-cost, compact and high-performance 3D imaging cameras that could be used in applications from robotics and autonomous navigation to augmented reality and healthcare.

---

### Community mitigation guidelines to prevent pandemic influenza-United States, 2017 [^299cced4]. MMWR: Recommendations and Reports (2017). Medium credibility.

Pandemic Severity Assessment Framework — transmissibility is measured on a scale of 1–5 and clinical severity on a scale of 1–7. Colors transition from light to dark as the estimated number of deaths increases. Axes are labeled Scaled measure of transmissibility and Scaled measure of clinical severity, and the framework is presented on the basis of past pandemics and influenza seasons.

---

### Recommendations for the assessment of carotid arterial plaque by ultrasound for the characterization of atherosclerosis and evaluation of cardiovascular risk: from the American Society of Echocardiography [^dcb92f9f]. Journal of the American Society of Echocardiography (2020). High credibility.

Pixel distribution analysis (PDA) mapping — plaque grayscale patterns and risk — has been explored using a method of mapping grayscale value ranges across a plaque in patients assessed for cardiovascular disease, where increased carotid plaque echogenicity from fibrous and calcium-like tissues correlated with increased coronary artery disease and a combination of plaque height, % calcium, and/or % fat increased risk for cardiovascular events; accordingly, the pattern of gray scale values across a plaque using techniques such as PDA may confer greater risk prediction benefit than a gross GSM value, and the unifying panel calls for further research into gray scale median analysis to identify plaque vulnerability and inform cardiovascular risk stratification.

---

### Multiple QTL determine dorsal abdominal scale patterns in the mosquito aedes aegypti [^edc9c62b]. The Journal of Heredity (2016). Low credibility.

The mosquito, Aedes aegypti (L.) originated in Sub-Saharan Africa as a dark form sylvan species (A. aegypti formosus). Evolution of A. aegypti aegypti type form as a human commensal facilitated its colonization of most semitropical and tropical areas. We investigated the genetic basis for abdominal white scale presence that represents the diagnostic for sylvan A. aegypti formosus (scales absent), from type form (scales present) and A. aegypti queenslandensis form (dense scaling). We performed quantitative trait locus (QTL) mapping using 3 criteria for scale patterns among 192 F1 intercross progeny from matings between a queenslandensis type and an aegypti type form. Results identified 3 QTL determining scale patterns and indicated that classification criteria impact robustness of QTL LOD support. Dark- and light-colored forms exist in sympatry, but vary in multiple phenotypic characteristics, including preferences for vertebrate host, oviposition container, house-entering behavior, and dengue vector competence. Markers associated with 2 QTL regions reflected major reductions in recombination frequencies compared with the standard type form linkage map, suggestive of inversion polymorphisms associated with observed linkage disequilibrium between type-specific characteristics. Understanding the genic basis for differences in A. aegypti forms could inform efforts to develop new mosquito and arboviral disease control strategies.

---

### Clinical practice guideline for screening and management of high blood pressure in children and adolescents [^1e4a6d34]. Pediatrics (2017). Medium credibility.

Oscillometric versus auscultatory blood pressure measurement — although pediatric normative BP data are based on auscultatory measurements, oscillometric BP devices have become commonplace in health care settings. Unlike auscultatory measurement, however, oscillometric devices measure the oscillations transmitted from disrupted arterial flow by using the cuff as a transducer to determine mean arterial pressure (MAP). Rather than directly measuring any pressure that correlates to SBP or DBP, the device uses a proprietary algorithm to calculate these values from the directly measured MAP, and because the algorithms vary for different brands of oscillometric devices, there is no standard oscillometric BP.

---

### Precision network modeling of transcranial magnetic stimulation across individuals suggests therapeutic targets and potential for improvement [^c8eae836]. Human Brain Mapping (2025). Medium credibility.

At each point in the subsampled search grid, an E‐field simulation was run with SimNIBS (Thielscher et al.) using a standardized stimulation intensity (1 A/μs) and coil to scalp distance (2 mm), with a MagVenture Cool‐B70 coil model (MagVenture Inc. Farum, Denmark). At this step, the standardized stimulation intensity (1 A/μs) from TANS was used as E‐field strength varies linearly with stimulation intensity; thus, it would not affect the optimal coil position (Lynch et al.). The optimal coil position was selected from these simulations based on an adapted form of the "on‐target value" specified in Lynch et al. In brief, the on‐target value was defined as the surface area of the target network(s) in the E‐field thresholded at 99.0%–99.9% (top 0.1%–1% of non‐zero values averaged across thresholds) divided by the total surface area of the thresholded E‐field. At the optimal coil position, angles at 5° increments were tested, and the optimal orientation angle was identified to further maximize the "on‐target value". The final coil position (represented as the x, y, z coordinates where the coil center should be) and orientation (represented as the x, y, z coordinates toward which the coil handle should point) were saved.

Finally, to characterize optimal "dose" a range of stimulation intensities was tested at the optimal coil placement. Assuming a neural activation threshold of 100 V/m, suprathreshold E‐field values were quantified for each network at each intensity level, and the level with the highest on‐target value was recorded.

(5) Spatial Selectivity. For each E‐field map, the spatial selectivity for networks was calculated at various thresholds ranging from 99.0% to 99.9% (0.1% increments). For example, at threshold 99.5%, the top 0.5% of the non‐zero E‐field values are kept, and the network assignment for each vertex in this thresholded map is pooled into a bar plot representing the % of vertices in the E‐field map that belong to each network. For example selectivity plots, see Figures 1, 2 and 2. Each row in the plot represents a different threshold, and each color represents a different network. This selectivity measure is adapted from Lynch et al.

---

### A clinimetric overview of scar assessment scales [^5641b76c]. Journal of Burn Care & Research (2012). Low credibility.

Standardized validated evaluation instruments are mandatory to increase the level of evidence in scar management. Scar assessment scales are potentially suitable for this purpose, but the most appropriate scale still needs to be determined. This review will elaborate on several clinically relevant scar features and critically discuss the currently available scar scales in terms of basic clinimetric requirements. Many current scales can produce reliable measurements but seem to require multiple observers to obtain these results reliably, which limits their feasibility in clinical practice. The validation process of scar scales is hindered by the lack of a "gold standard" in subjective scar assessment or other reliable objective instruments which are necessary for a good comparison. The authors conclude that there are scar scales available that can reliably measure scar quality. However, further research may lead to improvement of their clinimetric properties and enhance the level of evidence in scar research worldwide.

---

### Scale-free networks are rare [^9c1c1630]. Nature Communications (2019). High credibility.

Real-world networks are often claimed to be scale free, meaning that the fraction of nodes with degree k follows a power law k -α, a pattern with broad implications for the structure and dynamics of complex systems. However, the universality of scale-free networks remains controversial. Here, we organize different definitions of scale-free networks and construct a severe test of their empirical prevalence using state-of-the-art statistical tools applied to nearly 1000 social, biological, technological, transportation, and information networks. Across these networks, we find robust evidence that strongly scale-free structure is empirically rare, while for most networks, log-normal distributions fit the data as well or better than power laws. Furthermore, social networks are at best weakly scale free, while a handful of technological and biological networks appear strongly scale free. These findings highlight the structural diversity of real-world networks and the need for new theoretical explanations of these non-scale-free patterns.

---

### KDOQI clinical practice guidelines and clinical practice recommendations for diabetes and chronic kidney disease [^4b089782]. American Journal of Kidney Diseases (2007). Medium credibility.

Table 31 — effect of different blood pressure targets on CKD in type 1 and type 2 diabetes — includes a comparison of mean arterial pressure (MAP) targets, specifically "MAP < 92" versus "MAP 100–107", with outcomes displayed under clinical outcomes headings and interpreted using the legend where "NS = No significant difference between the 2 interventions".

---

### Age and gender as factors of pressure sensitivity of pain-free persons: are they meaningful? [^e9e43b63]. Journal of Pain Research (2020). Medium credibility.

Purpose

Prior findings suggest that women and elderly persons are more sensitive to pressure than men and younger persons; however, the magnitudes of these differences are substantially inconsistent. We answered the question whether the higher sensitivity of women and elderly persons is quantitatively meaningful. Specifically, we investigated if it is large enough to hamper the diagnosis, classification and follow-up of pain conditions by clinicians.

Materials and Methods

From each age stratum (18–20, 21–30, 31–40, 41–50, 51–60, 61–70, 71–80, and > 80 years), 40 pain-free women and 40 pain-free men were recruited. They rated the intensity of pressure of ten Newtons over ten seconds on an analogue zero to ten rating scale. The pressure was applied on their middle fingers and ear lobes with a threshold algometer. Centile curves visualized the sex- and age-dependent fluctuation of pressure sensitivity.

Results

Over the entire age range from 20 to 80 years, the median curves fluctuated within the interval of less than two points. The distance between the median curves of men and women was also less than two points. On the average, the median difference was half a point on the finger (p = 0.249) and the ear lobe (p = 0.083).

Conclusion

Less than two points is below the minimal clinically important difference for a zero to ten analogue pain rating scale; differences smaller than one point are even below the resolution of the scale. Sex differences and age fluctuations of pressure sensitivity are negligible.

---

### Predicting visual function by interpreting a neuronal wiring diagram [^dc2c4362]. Nature (2024). Excellent credibility.

Fig. 4
Dm3 ERFs predicted by mapping disynaptic pathways.

a – c, Heat maps (hexagons) of disynaptic pathways from Tm1 to Dm3, aligned and averaged over Dm3p (a), Dm3q (b) and Dm3v (c) cells. The portion of a disynaptic map outside the pCRF is a predicted ERF component mediated by the named intermediary type (text next to map). Pathways are ranked clockwise (curved arrow) by anatomical strength (Extended Data Fig. 7, green lines). The numbers indicate the fraction of disynaptic input in units of 0.01%: heat map maximum (white) and spatial sum over hexels. For each Dm3 type, the top two pathways are mediated by the two other Dm3 types, and the third strongest pathway is mediated by T2a. Ellipse approximations are superimposed on each map, with magenta (green) signifying pathways presumed inhibitory (excitatory). Centre: ellipses are shown again, anchored on the average pCRF (dotted ellipse) and enlarged for visibility by ×1.5. Ellipse opacity represents anatomical strength relative to the strongest inhibitory (magenta) or excitatory (green) pathway. d, Aligned ellipse approximations to Tm1–T2a–Dm3 maps for 50 representative Dm3p (blue), Dm3q (gold) and Dm3v (brown) cells. e – g, T2a-mediated disynaptic maps from Tm1 to Dm3 extend beyond the pCRFs, as shown by 1D longitudinal projections of average maps. A pERF component is predicted in both pCRF end zones for Dm3v (e), and mainly in the posterior end zone for Dm3p (f) and Dm3q (g). The unit of displacement is lattice constant. Ribbons represent standard deviation across Dm3 cells. Dm3 and Tm1 sample sizes are as in Fig. 1, and 866 T2a cells were included. Scale bars (a – c centre, d), one lattice constant (p and q axes).

---

### A low-power wearable acoustic device for accurate invasive arterial pressure monitoring [^d1b4d03d]. Communications Medicine (2023). Medium credibility.

The mean arterial pressure measured by the clinical transducer, when compared to the calculated mean arterial pressure using the height tracking system, differed on average by 0.19 ± 2.8 mmHg as shown in Fig. 6 a with 90% of the measurements within 4.3 mmHg (Fig. 6 b). Given the use of a height conversion factor to calculate the pressure difference, it was important to assess for measurement bias as the distance from the lowest bed height increased. A linear fit of the difference between the clinical and calculated mean arterial pressure was performed and showed a slope of 0.4 mmHg over a height range of 50 cm.

Fig. 6
Results from two-transducer clinical testing:

a Comparison of the estimated mean arterial pressure calculated from the height tracking system vs. the clinical transducer mean arterial pressure. The solid line shows the best linear fit while the dashed lines depicts twice the standard deviation. b Cumulative density function of the differences in mean arterial pressure for the height tracking system and clinical measurement. c Comparison of mean arterial pressure variation over two minutes with the difference between the clinical and calculated mean arterial pressure for individual patient study sessions. Each box represents a different patient and includes the differences between the clinical transducer and the automated height tracking system for all measured heights (9), normalized to the average difference for all measurements for a given patient. Median values are shown as gray lines in between the 1st and 3rd quartile line. Whiskers extend to minimum and maximum values for each patient. The enclosed dots above and below each bar represent the range of mean arterial pressure values measured over a two-minute timespan using the clinical transducer. MAP mean arterial pressure.

---

### Best practices guidelines for acute pain management in trauma patients [^0aa8091b]. ACS (2020). High credibility.

Functional pain scale (FPS) — score-to-function mapping is: 0 No Pain; 1 Tolerable and does not prevent activities; 2 Tolerable and prevents some activities; 3 Intolerable, but can use telephone, watch TV, or read; 4 Intolerable and cannot use telephone, watch TV, or read; 5 Intolerable and unable to communicate due to pain.

---

### Assessing the effectiveness of a national protected area network for carnivore conservation [^938ff71b]. Nature Communications (2020). High credibility.

Results and discussion

Matching analyses reveal no PA effects on carnivores

Finland has a rather uneven distribution of PAs (Fig. 1; Supplementary Table 1) but an extensive forest cover (76% of the country) that supports the persistence of carnivore species throughout. From the 1805 sampling units available, we were able to pair 1220 units (610 inside PAs and 610 outside PAs) using a matching procedure based on habitat and accessibility characteristics considered likely to influence large carnivore population trends. Most of these matched pairs of PA and non-PA sampling units had carnivore population data covering a period of ~30 years and represented well the four main biogeographical regions (n = 563 paired sampling units; total of 3111 observations for all units and all years, see Supplementary Table 2).

Fig. 1
Carnivore population trends by sampling unit.

Maps showing (i) the location of Finland in the world (top left); (ii) the extent of forest cover at the national scale (lower left); and (iii) all monitored units integrated in the Finnish Wildlife Triangle Scheme (right), showing the percent of positive population trends between 1989 and 2017 depending on the number of large carnivore species detected at each site and their population trends at the respective sites (e.g. 1 species with positive trends and 2 species with negative trends: 33%). Colored circles represent monitored sampling units. Circle size represents the number of carnivore species detected while circle color represents the percent of positive population trends per unit. Game management areas are separated by dashed lines (Southern Finland; Central Finland; Northern Finland and Lapland) and gray areas represent the Finnish protected area network.

---

### Organization of the human intestine at single-cell resolution [^560eedf8]. Nature (2023). Excellent credibility.

Fig. 3
Multilevel hierarchical structural description of the small intestine and colon.

a – d, Representation of multiple levels of hierarchical description: cell type (a), multicellular neighbourhood (b), community (based on clustering windows of cell neighbourhoods) (c) and tissue units (based on clustering communities) (d) comparing the small bowel with the colon for two representative tissue sections (from a total of 64 sections from 8 donors). Scale bar, 1 mm. e, Tissue hierarchy graph of the multilevel network of the tissue comprised of the different structures. Shapes correspond to structural level (cell type, neighbourhoods, communities, tissue units); colours represent individual categories as indicated in a – d; the size of shapes represents the percentage of tissue; and the size of connected lines represents the overall contribution to the next level of the structure when moving down the graph in increasing tissue structural hierarchy. The black rectangles highlight a single trajectory highlighted within this Article. The red bracket indicates separation of stromal tissue units from the mucosal tissue units. f, Magnified mucosal area of a colon community map shown within c. Scale bar, 100 µm. g, The spatial-context maps of the colon highlighting relationships of communities across the entire sample. This structure is defined by the number of unique communities required to make up at least 85% in a given window. The circles represent the number of cells represented by a given structure. The green rectangle highlights a structure discussed in this Article and maps this structure back to g. The colours are as indicated in c. h, The cell type percentage of immune cells shown for each community ordered in relative order of general increasing proximity to the lumen on the basis of community spatial-context analysis.

---

### African safaris and climbing expeditions | Yellow book… [^e875ff5c]. CDC (2025). Medium credibility.

Purpose Destination overview Arguably the ultimate in adventure travel, an African safari is the experience of a lifetime. Safari-goers have options to view wildlife from different vantages:

- On land
- On the water
- From the air. Hiking with trained, licensed guides in well-scouted settings offers another opportunity to see wildlife up close; treks to view chimpanzees or gorillas, for example, are highly popular. With > 150 game parks and reserves across the African continent, individual travelers, families, backpackers, and people with similar interests have a range of choices and budget options. Some parks are remote and rustic, with long drives to see the animals but with fewer tourists. Other parks are easily accessible, with self-drive options.

Many safaris accept young children and adolescent participants; gorilla trekking and other more strenuous activities require participants to be ≥ 15 years of age. Although the centerpiece of safari-going remains viewing majestic animals in their natural habitat, many tour operators now also offer programs on local culture and history, ecosystems, and geology. Conservation-based tours promoting responsible tourism allow travelers to stay safe, help safeguard wildlife, protect vital habitats, and benefit local people. Africa has a wide range of mountains that provide a perfect climbing experience for the adventurous. The East African region has some of the choicest of mountain ranges that provide unique trekking challenges to the mountain tops. The most popular mountains are. Each of these magnificent peaks provides a climatic range on the way to the top.

Travelers should prepare for picturesque nature walks and mind-blowing landscapes that these respective majestic mountains have to offer. They also have an option of taking advantage of touring the nature and game reserves that lie below these majestic mountains as part of their experience in the respective countries. This will require the travelers to work with the respective country mountain tour operators for a detailed mountain excursion. Climate and sun exposure Some parks are located at higher elevations and closer to the equator, making proper sun precautions imperative for avoiding sunburn, heat exhaustion, heat stroke, and dehydration. Advise travelers to seek shade, when possible, to avoid the sun during midday hours, and to carry water.

---

### Event-driven figure-ground organisation model for the humanoid robot iCub [^7cd34f42]. Nature Communications (2025). High credibility.

Methods

Frame-based figure ground organisation model

The frame-based system of figure-ground organisation proposed by Hu et al.implements a recurrent network to extract edges from the input image using CORF operators (each sensitive to a particular orientation), which is a model of V1 simple cells. Each simple cell operator is composed of different Centre-Surround cells modelled with Difference of Gaussian (DoG) distributions with different polarity, (-1 for centre-off, and +1 for centre-on), namely the Centre-OFF and Centre-ON Surround cells. Opposite polarity aligned groups of Centre-Surround cells compose a sub-unit sensitive to a specific orientation (see Fig. 1 a), Eq. (2).where the four-tuple (δ i, σ i, ρ i, ϕ i) represents the properties of a pool of afferent model LGN cells, called a sub-unit. Specifically, δ i represents the polarity of the Centre-Surround receptive fields (DoG distribution), σ i the standard deviation of the outer Gaussian function of the involved DoG functions, and ρ i, ϕ i are the polar coordinates of the sub-units centre with respect to the receptive field's centre.

The output of this network stage is a map of edge orientations in the scene (see Orientation Matrix Fig. 1). The Orientation Matrix is obtained using the edge maps at different orientations from each S cell, where each pixel contains the angle information for each edge in the image. The second layer of the model is the "Border Ownership Pyramid"(see B cells in Fig. 1) fed with the Orientation Matrix. This layer simulates the Border Ownership cells observed in V2(see Eq. (3)) as von Mises (VM) filters, a curved kernel first introduced in this context by Russell et al. at different orientations and different scales to achieve scale invariance.where R 0 represents the distance of the VM filter from the centre and will later define the radius of the opposite orientation of von Mises filters, grouping the information to detect the proto-object defining the range of detectable sizes; and t a n −1 takes two arguments and returns values in radians in the range (- π, π).

---

### KDIGO 2021 clinical practice guideline for the management of blood pressure in chronic kidney Disease [^db99a43b]. Kidney International (2021). High credibility.

KDIGO 2021 blood pressure intensity metrics — mean arterial pressure (MAP) — note that both MDRD and AASK studies employed a target MAP of < 92 mm Hg in the intensive BP arm, which is often considered equivalent to 125/75 mm Hg, but it is also equivalent to 116/80, 135/70, 140/68, 145/65, or other figures, depending on the pulse pressure.

---

### What to do when faced with an unmeasurable ambulatory blood pressure? [^1dcf447d]. Journal of Hypertension (2011). Low credibility.

If ambulatory blood pressure measurement is not possible because the upper-arm circumference is so great that even the largest cuff provided with the monitor will not encircle the arm, satisfactory measurements can be obtained by applying a cuff to the forearm.

---

### Development of the perceived risk of HIV scale [^31a69de7]. AIDS and Behavior (2012). Low credibility.

Fig. 1
IIFs plots for 10 items

Fig. 2
Test information and standard error of measurement functions for 10- and 8-item scales. Solid lines indicate total information; dotted lines indicate standard error

ORFs were examined independently by two of the authors to identify whether some items response options were redundant and could be collapsed. For example, item 7 response option 3 (somewhat agree) was not likely to be endorsed at any level of perceived risk. As shown in Fig. 3, response category 3 was most likely to be selected around the mean of the trait (θ = 0). However, at θ = 0, the probability of selecting the response option 3 was approximately 16%, which is much lower than the probability of selecting response options 2 (34%) or 4 (30%), suggesting this response option is redundant. Therefore, response option 3 was recoded to 2. Similarly, for item 1, response option 4 was redundant and collapsed with option 5 (both coded as 4). For item 2, response options 4, 5 and 6 were collapsed (all coded to 4), and for item 8 response options 1, 2 and 3 were collapsed (all coded as 3).

Fig. 3
ORF plots for Items 2, 3, 7 and 9

Criterion-Related Validity

Multilog was used to estimate person location (θ, reflecting participants' perceived risk) using maximum a posteriori (MAP) estimation. In addition, using the collapsed item categories, responses to each of the items were summed to create a total PRHS score. This total score provides an approach to scoring the measure that could easily be applied in future research. Total scores ranged from 10 to 40 (M = 22.7, SD = 7.4). Only 5.5% of participants received the lowest score on the measure (10), indicating they believed they had absolutely no risk of getting HIV because of their sex behaviors. The 8-item scale was found to have excellent internal consistency (α = 0.88). Criterion-related validity was examined for both the total score and θ, and the results were extremely similar using both methods of scoring, therefore, only results for the total score are presented below.

---

### Guidelines of care for the management of psoriasis and psoriatic arthritis. section 3. guidelines of care for the management and treatment of psoriasis with topical therapies [^b026871d]. Journal of the American Academy of Dermatology (2009). Medium credibility.

Psoriasis topical therapy dosing — fingertip unit guidance: One fingertip unit is approximately 500 mg, and it is generally accepted that approximately 400 g of a topical agent is required to cover the entire body surface of an average-sized adult when used twice daily for 1 week. Guidance derives from the fingertip unit concept, mapping body areas to number of fingertip units and approximate body surface area (%): scalp 3 with approximate body surface area (%) 6; face and neck 2.5 and 5; one hand (front and back) including fingers 1 and 2; one entire arm including entire hand 4 and 8; elbows (large plaque) 1 and 2; both soles 1.5 and 3; one entire leg including entire foot 8 and 16; buttocks 4 and 8; knees (large plaque) 1 and 2; trunk (anterior) 8 and 16; trunk (posterior) 8 and 16; genitalia 0.5 and 1.

---

### Guidelines for the appropriate use of bedside general and cardiac ultrasonography in the evaluation of critically ill patients-part II: cardiac ultrasonography [^ef336f61]. Critical Care Medicine (2016). Medium credibility.

Cardiac ultrasonography guideline — GRADE factors for evidence assessment and recommendation development specify that Section A categorizes the outcome factor as Critical, Important, Less important, or Not important, while Section B (factors 2–10) sets study-design starting points and quality levels with "Randomized controlled trial = 4" and "Observational studies = 2", mapping to "A = High = Four points", "B = Moderate = Three points", "C = Lowc = Two points", and "D = Very lowc = One point". Quality is lowered by the five downgraders — "Risk of bias" (−1 Serious; −2 Very serious), "Inconsistency" (−1 Serious; −2 Very serious), "Indirectness" (−1 Serious; −2 Very serious), "Imprecision" (−1 Serious; −2 Very serious), and "Publication bias" (−1 Likely; −2 Very likely) — and raised by three upgraders — "Large effect" (+1 Large; +2 Very large), "Dose response" (+1 Evidence of a gradient), and "Antagonistic bias" (+1 All plausible confounding would reduce the effect, or +1 Would suggest a spurious effect when results show no effect). "Based on the design, the evidence will qualify for four points (if randomized controlled trial) or two points (if observational) and then points will move down by one or two points (by downgraders) or up (by upgraders) if applicable as indicated in the table", and Section C (factors 11–15) lists "The five-GRADE transformers", with voting "using ninepoint Likert's scale".

---

### Pancreatitis: global research activities and gender imbalances: a scientometric approach using density-equalizing mapping [^f0b4b21f]. Pancreas (2016). Low credibility.

Objective

Despite the high impact of acute and chronic pancreatitis on the global burden of disease, no scientometric evaluation in this research field has yet been conducted. Therefore, we have issued an analysis in the field of pancreatitis research covering the past 112 years.

Methods

Data were retrieved from the Web of Science database. Density-equalizing mapping and large-scale data analysis were used to visualize bilateral and multilateral research cooperation.

Results

Finland is the only 1 of the 15 most productive countries showing a ratio in favor of female scientists. The United States is the most productive supplier with 24.1% of all publications. The most successful international cooperation proved to be the one between the United States and Germany. Although the United States holds the highest h-index, Switzerland obtains by far the highest citation rate. China, Russia, and India show only little international cooperation, given their scientific productivity.

Conclusions

For the benefit of scientific progress, more countries with considerable numbers of patients should contribute to international collaborations and female researchers should be encouraged and supported.

---

### Tbo-filgrastim (Granix) [^fde6140a]. FDA (2023). Medium credibility.

For example: If your prescribed dose is 1 mL you would prepare 1 syringe with 0.8 mL and a second syringe with 0.2 mL.

Important: When using 2 syringes always adjust the first syringe to 0.8 mL.

How to read the syringe markings

What the markings on the syringe mean:

The syringe is labeled in 0.1 mL unit increments from 0.1 mL to 0.8 mL. There is a line next to each 0.1 mL unit increment.

To read the dose scale always hold the syringe with the needle-end facing up so that 0.1 mL is at the top and 0.8 mL is at the bottom.

How to adjust the medicine level for your prescribed dose

When setting your dose, (See 2C) you will line up the top edge of the grey rubber stopper with the line on the syringe scale that matches your prescribed dose.
Note: The top edge of the grey rubber stopper is the edge directly below the dome at the top of the stopper.

Do not use the top of the cone or the middle or lower edges of the grey stopper to measure your dose.

Injection steps (follow the steps below for each day of dosing)

1. Prepare for injection

1A Each time you inject a dose gather the following supplies:

GRANIX syringe(s)
Alcohol swabs
Paper towel
Cotton ball or gauze pad
Adhesive Bandage, if needed
Sharps disposal container (hard-walled container for discarding syringes)

---

### The feasibility of reaching gigatonne scale COstorage by mid-century [^15d775bd]. Nature Communications (2024). High credibility.

The Sixth Assessment Report by the Intergovernmental Panel on Climate Change projects subsurface carbon storage at rates of 1–30 GtCO 2 yr -1 by 2050. These projections, however, overlook potential geological, geographical, and techno-economic limitations to growth. We evaluate the feasibility of scaling up CO 2 storage using a geographically resolved growth model that considers constraints from both geology and scale-up rate. Our results suggest a maximum global storage rate of 16 GtCO 2 yr -1 by 2050, but this is contingent on the United States contributing 60% of the total. These values contrast with projections in the Sixth Assessment Report that vastly overestimate the feasibility of deployment in China, Indonesia, and South Korea. A feasible benchmark for global CO 2 storage projections, and consistent with current government technology roadmaps, suggests a global storage rate of 5–6 GtCO 2 yr -1, with the United States contributing around 1 GtCO 2 yr -1.

---

### Reply to: "Re-evaluating the evidence for a universal genetic boundary among microbial species" [^03613cb3]. Nature Communications (2021). High credibility.

Fig. 1
Example of a read recruitment plot.

This figure showcases the result of processing a Blastn search of metagenomic short reads (each matching read is represented by a dot in main panel 1) against a reference MAG sequence recovered from the same metagenome (x-axis). 1 Main panel representing the reads recruited (mapped), placed by location (x-axis) and identity (y-axis) across the reference sequence. 2 Sequencing depth (or coverage) across the reference, i.e. how many reads map at each base pair position, in logarithmic scale. Bars lower than the average represent regions with fewer mapped reads, which denote gene content differences. 3 Identity histogram of mapped reads per unit of identity (light gray) and smoothed spline (black), in logarithmic scale. 4 Sequencing depth histogram. Peaks based on the sequencing depth revealed in panel 2 are automatically identified as skewed normal distributions (in red). The background of panels 1 and 3, and the line colors in panels 2 and 4, correspond to matches with identity above (dark blue) and below (light blue) a user-defined cutoff. By default, the identity cutoff is set to 95%. Note the area of sequence discontinuity denoted by a decrease, by more than one order of magnitude (x-axis, panel 3), in the number of reads mapping around 95% identity (red arrow) relative to reads mapping at > 98% identity. ANIr is estimated based on reads in the dark blue area only and represents the average nucleotide identity of reads to the reference sequence. The MAG represents an uncultivated member of the Actinobacteria phylum that shows about 45% average amino acid (AAI) to Ilumatobacter coccineus, its closest related named species with available genome representative(s). The metagenome was obtained from a planktonic sample from 1000 m in the Gulf of Mexico.

---

### Appropriate cuff size for blood pressure measurement: a target not yet achieved in clinical practice? [^59a362d5]. Hypertension Research (2025). Medium credibility.

Interaction between scientific and regulatory organizations, device manufacturers/sellers, and users with the goal of selecting the proper cuff size for accurate blood pressure measurement in every patient.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^c7ccd043]. Annals of the American Thoracic Society (2023). High credibility.

129Xe magnetic resonance imaging in idiopathic pulmonary fibrosis — quantitative ventilation, interstitial barrier, and red blood cell (RBC) transfer metrics are illustrated with histograms, color-coded maps, and healthy-reference comparisons; the RBC: Barrier ratio is 0.230 versus 0.60 ± 0.07 and lung inflation is 2.35L versus 3.16 ± 0.27. Red pixels indicate defects when pixel intensities are more than 2 standard deviations (SDs) below the mean, green voxels fall within 1 SD, and blue represent intensities 2 SDs above the mean for ventilation and RBC transfer maps, while barrier maps uniquely display upper-scale pink/purple for voxels with 129Xe uptake more than 2 SDs above the healthy reference; for each map, the percentage of thoracic cavity within defect, low, and high ranges is provided alongside values from a young, healthy reference population.

---

### Modifying the medical research council grading system through rasch analyses [^0da162ad]. Brain (2012). Low credibility.

Rationale for using Rasch method

In health care, outcome measures often consist of ordinal multi-item questionnaires, based on the classical test theory. Concerns have been raised about inappropriate analysis of the generated summed scores that are erroneously assumed to be at the interval level. The ability of a scale to provide fundamental measurements should be established before the more commonly reported psychometric attributes such as being simple, valid, reliable and responsive. Modern scientific methods have been adopted to overcome the shortcomings of traditional measurements. One of the most widely used modern techniques is the Rasch method that transforms ordinal obtained scores into interval-level variables, and whose fit of data satisfies numerous checkpoints as part of model expectations.

In the current study setting, the Rasch model assumes that a patient with less weakness (thus more strength) will have a greater chance of receiving a higher MRC grade by the examining physician. A comprehensive description of the Rasch analysis specifically for neurologists is provided elsewhere. Briefly, the Rasch model shows what should be expected in response to ordinal items if interval scaling is to be achieved. For this, the following criteria should be fulfilled.
Thresholds examination: when using items with more than two response categories, as for the MRC grades, proper ordering of the response options should be verified using category probability curves for each muscle group examined, since this will reflect the ability of physicians to use the MRC in a correct way. Ordered thresholds are where the transition (threshold) between categories map on to the underlying construct in the expected manner. Thus the transition between categories (e.g. 1–2 and 2–3) reflects increasing levels of muscle strength (Fig. 1, top). Disordered thresholds can occur when physicians use the response options inconsistently, and this inconsistency can be a source of misfit to model expectations. The difficulty discriminating between response options may be a result of too many options, or where the labelling of the options is confusing, both of which may lead to misinterpretation.
Fit statistics: fit statistics give an indication of how well the items fit the expected ordering required by the model. This ordering is a probabilistic version of Guttman Scaling. There are two general categories for detecting misfit: overall (summary) misfit, using the entire response matrix, and the individual fit (examining all items and all persons individually). At the summary level the overall mean residual values for both persons and items can be calculated. These values are expressed as a z -score with a mean of 0 and a SD of 1, values of which indicate perfect fit to model expectations. The summary item–trait interaction statistic reflects the fit of the observed data to the model's expectations and is represented by the chi-square. This statistic gives an indication of the invariance of the ordering of items across patients with different levels of muscle strength. A significant chi-square indicates a failure to retain this ordering. Besides the overall fit residuals, individual item–chi square and item and person residuals can be calculated.
Item bias: response to an item should not vary between groups (e.g. males versus females), given the same level of the underlying trait (e.g. muscle strength). We assessed item bias (differential item functioning) on the MRC data for various available person factors. A panel (I.S.J.M. and C.G.F.) have studied the range of the factors age, disease duration and physician's experience in the available cohorts. Subsequently, these factors were categorized into subgroups for item bias analyses, aiming for an equivalent distribution of participants among the subgroups (25–33% per subgroup).
Local dependency: local dependency arises when items are linked such that the response on one item is dependent upon the response to another. Item sets with correlations > 0.3 are considered a source of misfit to the model.
Unidimensionality: the Rasch model assumes unidimensionality and consequently post hoc tests are included in the analysis to ensure that this assumption holds. These tests involve a comparison of person estimates (of muscle strength) based upon two sets of items identified from the first principal component analysis of the residuals. The estimates for every individual are compared by a t -test, and where < 5% of these comparisons are significantly different, this is taken to support the assumption of unidimensionality.

---

### Validation of non-invasive central blood pressure devices: ARTERY society task force consensus statement on protocol standardization [^aad40817]. European Heart Journal (2017). Low credibility.

Data from meta-analysis indicate that using MAP and DBP could be a preferred calibration option to provide a relatively more accurate non-invasive estimation of central SBP. Several methods may be used to derive MAP, including by calculation from potentially inaccurate brachial cuff BP [e.g. DBP + 1/3 (or 40%) pulse pressure, or from integration of the pressure waveforms calibrated to cuff BP], or estimation from the peak oscillometric signal, but information regarding the accuracy of these approaches is limited. Central BP indices derived from oscillometric MAP and DBP calibrated peripheral waveforms show stronger associations with hypertension-related end organ disease and outcomes than either brachial BP or central BP derived by calibration using brachial oscillometric SBP and DBP. These data come from independent investigators that have used the same device, and it remains to be clarified if the findings may be more widely generalizable or if this is a device-specific phenomenon. The observation that much of the inaccuracy in estimated central BP lies with poor calibration from inaccurate brachial cuff BP, implies that better BP risk stratification might be achieved with more accurate brachial cuff BP per se. Indeed, calls have been made for more rigorous brachial BP accuracy criteria.

---

### Assessing critical care unit performance: a global measure using graphical analysis [^b566e6f3]. Anaesthesia (2002). Low credibility.

Outcome measurement in critical care is difficult because of the wide variety of patients treated and the diverse therapeutic options and pathways available. Individual outcome measures for critical care are available but are naturally limited to only a single aspect of performance. Most importantly, better performance in one aspect of care may compromise the standard of care in another. A global measure of performance would be helpful. For the year 1999–2000, the five hospitals in the East Anglian Critical Care Network provided data on capacity, workload and performance. The data was transformed and displayed graphically on a radar chart so that the area of the polygon within the radar chart was proportional to each unit's overall performance. The results from the five hospitals suggest that there is little overall difference in the units' global performance but the graphical representation highlighted some individual deficiencies. Graphical analysis of complex processes such as critical care delivery may facilitate performance assessment, providing that the measures chosen, weightings assigned and scales used are standardised with care.

---

### Mean arterial pressure differences between cuff oscillometric and invasive blood pressure [^fea1672e]. Hypertension Research (2025). Medium credibility.

Conclusions

The difference between oscillometric MAP and invasive MAP was associated with the difference in cuff systolic BP and diastolic BP compared with invasive BP. Efforts to improve oscillometric BP measurement methods should be prioritised. Advocacy to increase transparency of oscillometric algorithms used in BP devices is also needed to understand the way that BP is measured and enable open-source availability of deidentified cuff oscillometric traces to accelerate research on the topic.

---

### Dalhousie dyspnea scales: construct and content validity of pictorial scales for measuring dyspnea [^f89470d2]. BMC Pediatrics (2005). Low credibility.

Background

Because there are no child-friendly, validated, self-report measures of dyspnea or breathlessness, we developed, and provided initial validation, of three, 7-item, pictorial scales depicting three sub-constructs of dyspnea: throat closing, chest tightness, and effort.

Methods

We developed the three scales (Throat closing, Chest tightness, and Effort) using focus groups with 25 children. Subsequently, seventy-nine children (29 children with asthma, 30 children with cystic fibrosis. and 20 children who were healthy) aged 6 to 18 years rated each picture in each series, using a 0–10 scale. In addition, each child placed each picture in each series on a 100-cm long Visual Analogue Scale, with the anchors "not at all" and "a lot".

Results

Children aged eight years or older rated the scales in the correct order 75% to 98% correctly, but children less than 8 years of age performed unreliably. The mean distance between each consecutive item in each pictorial scale was equal.

Conclusion

Preliminary results revealed that children aged 8 to 18 years understood and used these three scales measuring throat closing, chest tightness, and effort appropriately. The scales appear to accurately measure the construct of breathlessness, at least at an interval level. Additional research applying these scales to clinical situations is warranted.

---

### Machine learning enables completely automatic tuning of a quantum device faster than human experts [^fd71e035]. Nature Communications (2020). High credibility.

Searching for the hypersurface

In each iteration, the algorithm first locates the hypersurface in gate voltage space. To do this, it selects a search direction, specified by a unit vector u which during the first 30 iterations of the algorithm is selected randomly from a hypersphere, restricted to the octant where all gate voltages are negative. The gate voltages are then scanned along a ray beginning at the origin o and parallel to u (Fig. 4 a). During this scan, the current is monitored; when it falls below a threshold of 20% of full scale, this is taken as defining a location v (u) on the hypersurface.

Fig. 4
Characterising the boundary hypersurface using machine learning.

Each panel illustrates a step of the algorithm presented in Fig. 3. The gate voltage space, restricted to two dimensions for illustration, is divided into regions of near-zero (blue) and non-zero current (pink), separated by a boundary hypersurface. a Locating the hypersurface. The gate voltages are scanned along a ray (violet arrow) starting at the origin (white circle) and defined by direction u. By monitoring the current, the intersection with the hypersurface is measured. b To determine whether a region should be pruned, the algorithm scans each gate voltage individually toward the bottom of its range from a location just inside the hypersurface as shown. If only one scan intersects the hypersurface (as in the inset), future exploration of that region is inhibited by displacing the origin as shown. c Based on a short 1D scan, the location is classified according to whether it shows current peaks indicating Coulomb blockade. d If peaks are found, a 2D scan (violet square) is performed in the plane of V 3 and V 7, and is possibly repeated at higher resolution. e From the first thirty measurements (green and yellow circles), the algorithm builds a model of the hypersurface and assigns a probabilitythat peaks will be found. f To refine the model, the algorithm generates a set of candidate search locations (squares), each weighted by its corresponding value of, and selects one at random. A new scan is then performed in the corresponding direction to generate a new measurement of the hypersurface location. Steps d – f are then repeated indefinitely. Inset: Scheme for numerically sampling the hypersurface using simulated Brownian motion. Each point represents a simulated particle moving inside the enclosed volume. The collisions between the particles and the modelled hypersurface generate a set of candidate search locations.

---

### Relationship between body mass index and mean arterial pressure in normotensive and chronic hypertensive pregnant women: a prospective, longitudinal study [^cdb0751f]. BMC Pregnancy and Childbirth (2015). Low credibility.

Definition of time-point measurements

Anthropometric parameters and blood pressure were measured at the following four time points: 12–14 weeks, 18–22 weeks, 29–33 weeks, and delivery. Each of these time points were converted to a time scale ranging from 0 to 1. Therefore, the initial time (i.e. before pregnancy) was considered to be time = 0, and the time of delivery was considered to be time = 1.

Maternal anthropometrics

The height (cm) and weight (kg) of each subject were measured without heavy clothing and shoes at each time point. Data about maternal weight just before pregnancy was obtained through questionnaires. Pre-pregnancy body mass index (BMI) was categorized into the following three categories: lean or normal (16–24 kg/m 2), overweight (25–29 kg/m 2) and obese (30–50 kg/m 2).

Blood pressure assessment

The blood pressure (BP) was measured using an automated instrument (GE Healthcare Carescape™ V100 Vital Signs Monitor with DINAMAP Technology, Milwaukee, WI, USA); it was measured two consecutive times and averaged. Mean arterial pressure (MAP) was obtained according to the following formula:

Prior to the measurement, each of the participants was seated and asked to relax for 5–10 min. A cuff (CRITIKON Blood Pressure Cuffs®, GE Healthcare, 23–33 cm, Milwaukee, WI, USA) was placed around the non-dominant upper arm at the level of the heart, with the pressure cuff bladder midline over the brachial artery. A larger cuff (32–42 cm) was used in patients who had an upper arm that exceeded 33 cm. As enrolment in our study took place during pregnancy, we were unable to measure maternal blood pressure before pregnancy.

Definition of normal pregnancy

To restrict enrolment to patients with normal course pregnancies, we excluded 117 (20.2%) pregnant women who experienced any of the following events during their pregnancies: endocrine disorders, psychiatric disorders, history of bariatric surgery, secondary hypertension, gestational hypertension/preeclampsia, preterm delivery, foetal growth restriction, antihypertensive medication use, multiple gestation, and foetal death. After these exclusions, 461 women who had a normal pregnancy remained. Therefore, the study used basic inclusion criteria, including patients who were healthy or had stable chronic hypertension without known target organ involvement.

---

### Enhanced future changes in wet and dry extremes over Africa at convection-permitting scale [^286ec5d0]. Nature Communications (2019). High credibility.

We see large departures from CC-scaling locally, with evidence of 'super-CC scaling' occurring more widely across Africa in CP4A (Fig. 10; Supplementary Fig. 13). In particular, 11% of 25 -km grid points show scaling coefficients > 2xCC in CP4A compared with 4% in R25. Both models also sample negative scaling rates, with 5% of grid points showing negative scaling in CP4A and 13% in R25. Locally varying negative to strongly positive scaling rates typically happen due to displacements of extreme convective storms in future, and may be symptomatic of an undersampling of extreme storms in the 10-year model simulations. The fact that super-CC scaling is more prevalent than negative scaling in CP4A (but not R25) shows that this is not simply explained by displacements of extreme storms. We note that over much of central Africa where super-CC scaling is observed in CP4A, future changes in extreme precipitation intensity (Fig. 5) are significantly higher in CP4A than in R25 taking into account year-to-year variability. These results suggest that higher scaling rates at convection-permitting scale for Africa as a whole are robust, but given the results are based on single 10-year model realisations, there is uncertainty in the actual scaling values at the 25 -km grid point scale.

On using surface temperature (instead of dew point) as the scaling variable (Supplementary Fig. 16), we see a downturn in scaling at a high-temperature change explained by moisture availability not increasing as fast as temperature, with a decrease in relative humidity. We see some consistency between models in regions showing sub-CC scaling; in particular, both models show a large area of sub-CC scaling with surface temperature change in SW Africa, consistent with regional drying. However, in general, variation in the scaling coefficient across grid points in CP4A is not strongly related to that in R25, with a correlation of 0.4 or less. At high temperature change (> 8 K), scaling coefficients in the two models are uncorrelated, suggesting a different response in dry environments where future warming is likely largest.

---

### Guidelines for performing a comprehensive transthoracic echocardiographic examination in adults: recommendations from the American Society of Echocardiography [^6df4db3f]. Journal of the American Society of Echocardiography (2019). High credibility.

Scale/PRF — color Doppler velocity scale settings specify the range of velocities that can be displayed without aliasing, and aliasing can be eliminated by increasing the scale range from 0.69 to 0.77 m/sec in the illustrated example.

---

### EANM practice guideline / SNMMI procedure standard for dopaminergic imaging in parkinsonian syndromes 1.0 [^24307025]. European Journal of Nuclear Medicine and Molecular Imaging (2020). High credibility.

Visual analysis — images should be read on the computer screen since it is of paramount importance to adjust the color scale appropriately, and the first step of visual reading is the setting of the maximum color scale value; care should be taken in the 3D alignment of images to insure the proper appreciation of putaminal uptake asymmetry. It is recommended to visualize all the transaxial slices containing striatal uptake as well as those including midbrain in order to be able to detect extra-striatal uptake, and normal [18F]fluorodopa striatal uptake is much less dependent on age than DAT tracers.

---

### Joint consensus statement of the American Academy of Sleep Medicine and sleep research society on the recommended amount of sleep for a healthy adult: methodology and discussion [^0b7dd518]. Journal of Clinical Sleep Medicine (2015). Medium credibility.

Consensus voting methodology for adult sleep duration links agreement with a fixed statement to specific hours-of-sleep bands, a 9-point Likert scale, and median-based interpretation, with independent Round 1 voting and conference-guided Round 2 voting. Panel members voted on the statement "Based on the available evidence, [X] hours of sleep is associated with optimal health within the [X] subcategory in the [X] category", across "Hours of Sleep" categories of < 5 hours, 5 to 6 hours, 6 to 7 hours, 7 to 8 hours, 8 to 9 hours, 9 to 10 hours, and ≥ 10 hours. Voting used "a 9-point Likert scale where 1 meant 'strongly disagree', 9 meant 'strongly agree', and 5 meant 'neither agree nor disagree'", and panel medians were interpreted as "1–3 indicated disagreement", "4–6 indicated uncertainty", and "7–9 indicated agreement". Independence was maintained because "Panel members were instructed not to discuss the evidence or their votes", votes "were collected and compiled to determine the median and distribution", and "subcategory results were collapsed to reveal overall category specific results" when relevant. For Round 2 procedures, "one panel member was selected to act as a category expert", members "reviewed the results of Round 1 voting" and the expert's evidence review, then "completed Round 2 voting… following the same procedures from Round 1 voting"; "some subcategories were collapsed or dropped for Round 2 voting" based on "the availability and strength of evidence". Figure color coding maps interpretation categories as "Inappropriate (Panel Agreement), Inappropriate-to-Uncertain (Disagreement), Uncertain (Panel Agreement), Uncertain-to-Appropriate (Disagreement), [and] Appropriate (Panel Agreement)".

---

### The missing reality of real life in real-world evidence [^9cbd9976]. Clinical Pharmacology and Therapeutics (2019). Medium credibility.

Reality is defined as a real event, a real thing, or state of affairs. Reality exists in the places where we live our daily lives, in the relationships we have with others, and in our experiences, circumstances, and situations that occur across the lifespan. As the everydayness of our lives becomes increasingly digitized, data generated from the reality that exists outside of our healthcare encounters holds much promise to fill recognized gaps in real‐world evidence (RWE). In the past decade, many factors have converged to uniquely position person‐generated data for use in health care delivery, payment reform, product development, and regulatory decision making. Yet, real‐world data will fall short of its promise to fill gaps in RWE if what we learn does not reflect the real lives of real people from across the spectrum of social, economic, and cultural experiences.

---

### Opportunities and challenges associated with clinical diagnostic genome sequencing: a report of the Association for Molecular Pathology [^ac422a46]. The Journal of Molecular Diagnostics (2012). Medium credibility.

Clinical diagnostic genome sequencing — base-calling quality scoring uses a Phred score generated on a logarithmic scale (Q = − 10 log E) to estimate error probability, where a Phred of 10 corresponds to a 1/10 probability of error and a Phred of 20 corresponds to 1/100. For sequencing information, the Clinical Laboratory Standards Institute has recommended filtering on a Phred score of 20 to 30, resulting in an error rate of 1/100 to 1/1000, and when interrogating variants in population-level situations such as microbes or tumor samples, higher thresholds may be necessary.

---

### Pressure mapping systems: reliability of pressure map interpretation [^945f9ba0]. Clinical Rehabilitation (2003). Low credibility.

Background

Pressure mapping systems offer a new technology to assist with pressure care assessment. Data output from such systems can be presented in three forms: numerical data, a three-dimensional grid and a colour-coded pressure map.

Objectives

To (1) investigate whether sole use of the pressure map was a reliable method of interpreting interface pressures when compared with use of the numerical data; (2) establish the inter- and intra-rater reliability of using pressure maps to assess pressure and determine whether reliability depended upon system operator experience; and (3) examine whether reliability extended to the range of seating surfaces being tested.

Design

A reliability study assessing the ranking of pressure maps recorded by the Force Sensing Array pressure mapping system.

Setting

A university occupational therapy department and a community NHS trust.

Subjects

Fifteen occupational therapists with experience in pressure mapping and 50 occupational therapy students with no practical experience of pressure mapping.

Interventions

Two sets of pressure maps were pre-recorded with an able-bodied adult seated on a variety of surfaces, with maps on each individual surface recorded over a 20-minute period at 2-minute intervals. Subjects ranked both sets of maps in terms of 'best to poorest' distribution of pressure.

Main Outcome Measures

Rank orders of (1) pressure maps; (2) average interface pressures (mmHg); (3) maximum interface pressures (mmHg).

Results

The use of pressure maps to interpret interface pressures was a reliable method. Significant agreement existed within (p < 0.001) and between groups of operators and reliability extended over the range of seating surfaces tested.

Conclusions

The practice of using pressure maps to interpret interface pressures in seating as opposed to using the associated numerical data can be supported. This was shown to be a reliable method of assessment by both experienced and less experienced operators across a range of seating surfaces.

---

### Composite rating scales [^2fbad343]. Journal of the Neurological Sciences (2010). Low credibility.

Rating scales are instruments that are very frequently used by clinicians to perform patient assessments. Typically, rating scales grade the attribute on an ordinal level of measurement, i.e., a rank ordering, meaning that the numbers assigned to the different ranks (item scores) do not represent 'real numbers' or 'physical magnitudes'. Single-item scales have some advantages, such as simplicity and low respondent burden, but they may also suffer from disadvantages, such as ambiguous score meanings and low responsiveness. Multi-item scales, in contrast, seem more adequate for assessment of complex constructs, allowing for detailed evaluation. Total scores representing the value of the construct may be quite precise and thus the responsiveness of the scale may be high. The most common strategy for obtaining the total score is the sum of the item scores, a strategy that constitutes one of the most important problems with these types of scales. A summative score of ordinal figures is not a 'real magnitude' and may have little sense. This paper is a review of the theoretical frameworks of the main theories used to develop rating scales (Classical Test Theory and Item Response Theory). Bearing in mind that no alternative is perfect, additional research in this field and judicious decisions are called for.

---

### Clinical practice guideline for screening and management of high blood pressure in children and adolescents [^27320e33]. Pediatrics (2017). Medium credibility.

Table 4 (continued) — Blood pressure percentiles by age and height present reference values for children. Systolic blood pressure (SBP) and diastolic blood pressure (DBP) in mm Hg are organized by age 8, 9, 10, 11, 12, 13, 14 and stratified by height percentiles 5th, 10th, 25th, 50th, 75th, 90th, 95th, with rows for BP percentile levels (including 50th, 90th, 95th). Clinicians can match a child's age and measured height percentile to locate the corresponding SBP/DBP percentile values shown in the table.

---

### The quality of life impact refractive correction (QIRC) questionnaire: validation of the malay-translated version of the QIRC using rasch analysis [^0bf56f56]. BMC Ophthalmology (2021). Medium credibility.

Fig. 3
Person-item map for the functional scale of the Final Malay QIRC. The left side of the dashed line represents the participants, with lower ability participants near the top of the map. The right side of the dashed line represents the items, with less difficult items near the top of the map. Each '#' = three participants; each ". = one participant; M = mean; S = one standard deviation; T = two standard deviations

Fig. 4
Person-item map for the emotional scale for the Final Malay QIRC. The left side of the dashed line represents the participants, with lower ability participants near the top of the map. The right side of the dashed line represents the items, with less difficult items near the top of the map. Each '#' = three participants; each ". = one participant; M = mean; S = one standard deviation; T = two standard deviations

Analysis of the DIF revealed that all items of the functional and emotional scales had a DIF contrast of less than 0.50 logits. However, Item 18 ' able to do the things you want to do' showed a significant probability between genders (DIF contrast, 0.40 logits; t = 2.12, p = 0.04). It indicated that Item 18 was 0.40 logits tougher for females than for males.

There was no significant difference in QIRC scores between the test and retest (mean difference, 1.09 ± 4.07 units; t = 2.05, p = 0.05). Test-retest reliability analysis showed a high ICC (single measures, 0.94) and Cronbach's α (0.97) with a CoR of ± 8.14 units. In addition, the time required to complete the questionnaire between the first and second visits was insignificant (mean difference, 0.12 ± 0.70 min; t = 1.33, p = 0.19). These findings confirmed that the 19-item Final Malay QIRC had excellent repeatability and internal consistency.

---

### Global strategy for the diagnosis, management, and prevention of chronic obstructive pulmonary disease (2025 report) [^a8d1193f]. GOLD (2025). High credibility.

Regarding classification and risk stratification for chronic obstructive pulmonary disease, more specifically with respect to severity assessment, GOLD 2025 guidelines recommend to use the modified MRC dyspnea scale, based on the level of dyspnea, for severity assessment:

| **Situation** | **Guidance** |
|-|-|
|Grade 0|- I only get breathless with strenuous exercise|
|Grade 1|- I get short of breath when hurrying on the level or walking up a slight hill|
|Grade 2|- I walk slower than people of the same age on the level because of breathlessness, or I have to stop for breath when walking at my own pace on the level|
|Grade 3|- I stop for breath after walking about 100 meters or after a few minutes on the level|
|Grade 4|- I am too breathless to leave the house or I am breathless when dressing or undressing.|

---

### Selection of a rating scale in receiver operating characteristic studies: some remaining issues [^01445ac6]. Academic Radiology (2008). Low credibility.

Rationale and Objectives

The aim of this study is to compare the ratings of a group of readers that used two different rating scales in a receiver operating characteristic (ROC) study and to clarify some remaining issues when selecting a rating scale for such studies.

Materials and Methods

We reanalyzed a previously conducted ROC study in which readers used both a 5-point and a 101-point scale to identify abdominal masses in 95 cases. Summary statistics include the distribution of scores by reader for each of the rating scales, the proportion of tied scores when using the 5-point scale that correctly resolved when using the 101-point scale and the proportion of paired normal-abnormal cases where the two rating scales resulted in a different selection of an abnormal case.

Results

As a group, the readers used 84 of the rating categories when using the 101-point scale but the categories used differed for individual readers. All readers tended to resolve the majority of ties on the 5-point scale in favor of correct decisions and to maintain correct decisions when a more refined scale was used.

Conclusions

The reanalysis presented here provides additional evidence that readers in a ROC study can adjust to a 101-point scale and the use of such a refined scale can increase discriminative ability. However, the decision of selecting an appropriate scale should also consider the underlying abnormality in question and relevant clinical considerations.

---

### EACTS / STS guidelines for diagnosing and treating acute and chronic syndromes of the aortic organ [^4646764f]. European Journal of Cardio-Thoracic Surgery (2024). High credibility.

Kommerell diverticulum — measurement standardization and definitions emphasize that some controversy exists regarding the actual size measurement with no clear consensus, and for consistency, multiple measurements are recommended including the subclavian artery diameter at its orifice, the size of the combined diameters of the diverticulum and the adjacent aorta, and the cross-sectional aberrant right subclavian artery diameter 1 cm distal to the ostium of the vessel (DAW: distance to the opposite aortic wall). Figure 33 defines A = Kommerell diverticulum neck diameter, B = Cross sectional diameter inside the body of the Kommerell diverticulum (measured at 1 cm of the entry orifice), and C = Distance to opposite aortic wall (DAW).

---

### Blood pressure measurement and assessment of arterial structure and function: an expert group position paper [^7e2c161c]. Journal of Hypertension (2024). Medium credibility.

Measuring blood pressure (BP) and investigating arterial hemodynamics are essential in understanding cardiovascular disease and assessing cardiovascular risk. Several methods are used to measure BP in the doctor's office, at home, or over 24h under ambulatory conditions. Similarly, several noninvasive methods have been introduced for assessing arterial structure and function; these methods differ for the large arteries, the small ones, and the capillaries. Consequently, when studying arterial hemodynamics, the clinician is faced with a multitude of assessment methods whose technical details, advantages, and limitations are sometimes unclear. Moreover, the conditions and procedures for their optimal implementation, and/or the reference normality values for the parameters they yield are not always taken into sufficient consideration. Therefore, a practice guideline summarizing the main methods and their use in clinical practice is needed. This expert group position paper was developed by an international group of scientists after a two-day meeting during which each of the most used methods and techniques for blood pressure measurement and arterial function and structure evaluation were presented and discussed, focusing on their advantages, limitations, indications, normal values, and their pragmatic clinical application.

---

### Evaluating clinical rating scales for evidence-based dermatology: some basic concepts [^520419f3]. Dermatologic Clinics (2005). Low credibility.

Evidence-based dermatology has necessitated the development of rating scales that measure multidimensional and abstract constructs, such as quality of life. This article discusses some basic psychometric concepts, such as reliability, validity, standardization, and measurement precision, which need to be considered when choosing a clinical rating instrument. Also discussed is the impact of these parameters on increasing the statistical power of a clinical trial.

---

### Utility-weighted modified rankin scale scores for the assessment of stroke outcome: pooled analysis of 20 000 + patients [^f2c46124]. Stroke (2020). Medium credibility.

Background and Purpose

Patient-centered care prioritizes patient beliefs and values towards wellbeing. We aimed to map functional status (modified Rankin Scale [mRS] scores) and health-related quality of life on the European Quality of Life 5-dimensional questionnaire (EQ-5D) to derive utility-weighted (UW) stroke outcome measures and test their statistical properties and construct validity.

Methods

UW-mRS scores were derived using linear regression, with mRS as a discrete ordinal explanatory response variable in 8 large international acute stroke trials. Linear regression models were used to validate UW-mRS scores by assessing differences in mean UW-mRS scores between the treatment groups of each trial. To explore the variability in EQ-5D between individual mRS categories, we generated receiver operator characteristic curves for EQ-5D to differentiate between sequential mRS categories and misclassification matrix to classify individual patients into a matched mRS category based on the closest UW-mRS value to their observed individual EQ-5D value.

Results

Among 22 946 acute stroke patients, derived UW-mRS across mRS scores 0 to 6 were 0.96, 0.83, 0.72, 0.54, 0.22, -0.18, and 0, respectively. Both UW-mRS and ordinal mRS scores captured divergent treatment effects across all 8 acute stroke trials. The sample sizes required to detect the treatment effects using UW-mRS scores as a continuous variable were almost half that required in trials for a binary cut point on the mRS. Area under receiver operator characteristic curves based on EQ-5D utility values varied from 0.66 to 0.81. Misclassification matrix showed moderate agreement between actual and matched mRS scores (kappa, 0.68 [95% CI, 0.67–0.68]).

Conclusions

Medical strategies that target avoiding dependency may provide maximum benefit in terms of poststroke health-related quality of life. Despite variable differences with mRS scores, the UW-mRS provides efficiency gains as a smaller sample size is required to detect a treatment effect in acute stroke trials through use of continuous scores. Registration: URL: https://www.clinicaltrials.gov; Unique identifiers: NCT00226096, NCT00716079, NCT01422616, NCT02162017, NCT00120003, NCT02123875. URL: http://ctri.nic.in; Unique identifier: CTRI/2013/04/003557. URL: https://www.isrctn.com; Unique identifier: ISRCTN89712435.

---

### Proportional change: an additional method of reporting technical and functional outcomes following clinical interventions [^45763dcc]. European Journal of Neurology (2001). Low credibility.

One of the major challenges in disability management research is to express results in a manner that can be generalized to subjects with varying degrees of disability. Absolute measurements of change are often dependent on initial characteristics, in which case they can only be generalized to subjects with the same characteristics. We define proportional change as the ratio of change to the maximum possible or targeted change. It can be assessed in any situation where a maximum possible or targeted change is definable. Its estimated value will be sensitive to the choice of denominator. Subjective assessments, such as those measured with Likert scales, are naturally expressed as proportional change with the denominator being set by the subject. Denominators may also be determined objectively by physical limitations or, less desirably, by the measurement tool. Where there is no readily or objectively determinable denominator, they should be chosen for each subject in advance of the intervention according to carefully specified criteria. Proportional change is proposed, as an adjunct to the reporting of absolute measures of change following therapeutic interventions, as a means of expressing change in a manner that is both individualized and generalizable.

---

### Mean arterial pressure differences between cuff oscillometric and invasive blood pressure [^287aedce]. Hypertension Research (2025). Medium credibility.

Discussion

To our knowledge, this is the first study to examine if the difference between automated cuff oscillometric MAP and invasive MAP may relate to the difference in cuff systolic BP and diastolic BP compared with invasive measurement. This was determined using an invasive reference standard across five unique automated cuff BP measurement devices. The main findings were that ∆MAP was associated with ∆systolic BP in four of five devices, whereas ∆MAP was associated with ∆diastolic BP in all five devices. The strength of the associations between ∆MAP and ∆systolic or ∆diastolic BP, and magnitude of the differences were device specific. These data highlight that equivalence between cuff oscillometric MAP and invasive MAP cannot be assumed, and this could be a significant factor contributing to ∆systolic or ∆diastolic BP. Efforts to improve oscillometric BP measurement methods are needed, as well as greater transparency of the BP estimation algorithms that are used in commercially available devices.

---

### What makes a measurement instrument valid and reliable? [^77d2a878]. Injury (2011). Low credibility.

High quality instruments are useful tools for clinical and research purposes. To determine whether an instrument has high quality, measurement properties such as reliability and validity need to be assessed, using standardised criteria. This paper discusses these quality domains and measurement properties using the standardised criteria that were recently published by the COSMIN group. Examples are given of studies evaluating the measurement properties of instruments frequently used in trauma. This paper presents a helpful tool for readers who want to evaluate or assess the quality of a measurement instrument on reliability and validity.

---

### De novo motor learning creates structure in neural activity that shapes adaptation [^caf9b726]. Nature Communications (2024). High credibility.

Fig. 4
The structure in neural space of multi-movement networks resulting from de novo learning is responsible for their patterns in adaptation.

Networks were given either angular (a) or categorical (d) inputs to simulate different learning experiences. After training on different repertoires, they had to adapt to a 10° VR perturbation. b Latent activity, for example, network with angular inputs trained on four movements during preparation (500 ms before go cue) and execution (1000 ms after go cue). Each trace corresponds to the trial-averaged activity for each movement projected on the neural manifold computed before adaptation. Solid lines, activity before adaptation; dotted lines, activity after adaptation. c Left: Input structure, measured as the cosine dissimilarity between input vectors for pairs of movements for the network in Panel b. Right: Neural structure, measured as the normalized median Euclidean distances between latent trajectories during preparation and execution for different movements for the same network. e, f. Same as panels (b, c) but for a categorical input network. Inset in Panel e: zoomed view. g Congruency between the input and neural structure, quantified as the Pearson's correlation between their dissimilarity matrices. Congruency for mismatched input-activity pairings shown as control. Circle and error bars, mean of congruency values for each seed (n = 10) and 95% confidence intervals (CIs) with bootstrapping. h Motor output following skill-learning for angular input networks. Bottom: Loss during adaptation training. Traces, shaded surfaces, smoothed mean, and 95% CIs across networks of different seeds (n = 10). i Same as panel h but for categorical input networks. j Decay constants for exponential curves fitted to the loss curves in panels (h, i). Circles, error bars, means, and 95% CIs with bootstrapping. k Relative weight changes during adaptation. Circles and error bars, means of the median changes across all weights for each seed, and 95% CIs with bootstrapping. l Schematic for a 'deviation angle' between the 'adjacent movement vector' (red solid line in panel b, e) and the 'adaptation vector' (red dotted line in panel b, e). m Deviation angles during adaptation. Circles and error bars, means of the median deviation angles across all time steps for each seed and 95% CIs with bootstrapping.

---

### Clinical practice guideline for screening and management of high blood pressure in children and adolescents [^e45eb057]. Pediatrics (2017). Medium credibility.

Blood pressure percentiles by age and height — systolic blood pressure (SBP) reference values are organized by age and by height percentiles, listing height in centimeters at the 5th, 10th, 25th, 50th, 75th, 90th, and 95th percentiles and SBP (mm Hg) at the 50th, 90th, 95th, and "95th + 12 mm Hg" levels.

---

### Quantifying the value of stroke disability outcomes: WHO global burden of disease project disability weights for each level of the modified rankin scale [^b9e97587]. Stroke (2009). Low credibility.

Background and Purpose

The modified Rankin Scale (mRS) categorizes poststroke disability among 7 broad, ordinal grades, but the interval distances between these levels are spaced along the disability spectrum have not been previously investigated.

Methods

We used the person trade-off procedure developed by the World Health Organization Global Burden of Disease Project (WHO-GBDP) to generate disability weights (DWs) ranging from 0 (normal) to 1 (dead) for each of 7 mRS grades. The ratings of an international, 9-member panel of stroke experts were combined by a modified Delphi process.

Results

DWs (95% CI) were 0 for mRS 0, 0.046 (0.004 to 0.088) for mRS 1, 0.212 (0.175 to 0.250) for mRS 2, 0.331 (0.292 to 0.371) for mRS 3, 0.652 (0.625 to 0.678) for mRS 4, 0.944 (0.873 to 1.015) for mRS 5, and 1.0 for mRS 6. DWs of adjacent mRS levels were significantly different (P < 0.001 for all). Coefficients of variation showed a high degree of consensus for DWs among panel members. DWs placed each of the 5 intermediate mRS states in different disability class levels of the WHO-GBDP anchor conditions and identified natural clusters to use when reducing the mRS to fewer categories.

Conclusions

Formal DW assignment confirms that the mRS is an ordered but unequally spaced scale. The availability of DWs for each mRS level now permits direct comparison of each poststroke outcome state with the outcomes of hundreds of other diseases in the WHO-GBDP and the expression of stroke burden in different populations by using the uniform metric of disability-adjusted life-years lost.

---

### Activity rating scales in adult muscle disease: how well do they actually measure? [^a1d643ea]. Muscle & Nerve (2014). Low credibility.

Introduction

In an accompanying study we reported on the content of several activity rating scales that have been used for muscle disease. To further aid in achieving consensus we conducted a systematic review to assess the quality of the 19 activity rating scales designed specifically for muscle disease.

Methods

We analyzed the measurement properties and the feasibility of the 19 instruments. Several databases were searched for studies relating to the quality of the instruments under review. Two independent reviewers selected studies and assessed instrument quality using pre-agreed criteria based on published frameworks.

Results

We found that none of the 19 instruments have sufficiently comprehensive reporting of measurement or feasibility performance as would be required by regulatory authorities.

Conclusions

Further work is required urgently to address these deficiencies of reporting or acquiring additional data. Until then, there will remain a major barrier for translational research to overcome.

---

### Reducing the global burden of myopia by delaying the onset of myopia and reducing myopic progression in children: the academy's task force on myopia [^fa9e692b]. Ophthalmology (2021). High credibility.

Global myopia projections — Figure 1 depicts estimates of the number of people with myopia and high myopia for each decade from 2000 through 2050, and displays error bars representing the 95% confidence intervals to convey projection uncertainty.

---

### Best practices guidelines for acute pain management in trauma patients [^645a357e]. ACS (2020). High credibility.

Unidimensional assessment tools for cognitively intact adults — "Unidimensional pain assessment tools take little time to administer, are easy to trend over time, and are familiar to patients and health care providers", yet "these tools are subjective, require patients to be responsive, and may not completely and appropriately assess a patient's pain", so "no single unidimensional tool is superior for pain assessment". The numeric rating scale (NRS) is "an 11-point, patient-reported metric that scores current pain level on a scale from 0 to 10, with 0 being no pain and 10 being the worst imaginable pain", and "is commonly used to assess acute pain because it is familiar and simple to understand". The visual analog scale (VAS) is "a self-reported acute pain assessment tool" in which "the patient marks their pain level on a 10 cm line with no pain written on the left and worst possible pain on the right side"; "for scoring, numbers from 0 to 10 can be under the line… or a centimeter ruler can be used to measure the mark from the line's left side". The Defense and Veterans Pain Rating Scale (DVPRS) "is a self-reported, graphic acute pain assessment tool", and "It uses the same scale as the NRS".

---