# Medical Question & Answer

**Sample ID**: 18ac723e-9c61-a927-2dd8-e0e1049d5a29
**Dataset Index**: 136494

---

## Question

G9.3 If $S = a b+a-b-1$ and $a = 101, b = 49$, find $S$.

---

## Answer

> Let's see… What do we have here? The user is asking to evaluate the expression S = ab + a − b − 1 when a = 101 and b = 49. Let's break this down step-by-step. First, I need to think about substituting the given values into the expression. Then, I should verify the order of operations and compute the multiplication before addition and subtraction. Next, I will perform the arithmetic stepwise and double-check each intermediate result. Finally, I will confirm the final answer and consider whether any simplification of the original expression could have made the calculation easier, just to ensure I didn't miss a shortcut.

> Let me first confirm the substitution. Replacing a with 101 and b with 49 gives S = (101)(49) + 101 − 49 − 1, and I should keep the parentheses around the multiplication to avoid any ambiguity in order of operations, even though it's conventional to multiply before adding or subtracting [^notfound].

> Now, I will compute the multiplication 101 × 49. Wait, let me verify this carefully: 100 × 49 = 4900, and 1 × 49 = 49, so 101 × 49 = 4900 + 49 = 4949. Hold on, I should double-check that addition: 4900 + 49 is indeed 4949, so the product is correct [^notfound].

> Next, I should review the rest of the expression stepwise. After the multiplication, the expression becomes 4949 + 101 − 49 − 1. I will now perform the additions and subtractions left to right: 4949 + 101 = 5050, then 5050 − 49 = 5001, and finally 5001 − 1 = 5000. Let me reconsider each step to ensure no arithmetic slips: 4949 + 101 is 5050, 5050 − 49 is 5001, and 5001 − 1 is 5000, which checks out [^notfound].

> But wait, what if I had simplified the original expression algebraically first? I could factor S = ab + a − b − 1 as a(b + 1) − (b + 1) = (a − 1)(b + 1), which gives (101 − 1)(49 + 1) = 100 × 50 = 5000. Hmm, wait a minute, I initially thought that shortcut might yield a different result, but no, it confirms the same answer, which reassures me that the direct substitution method was correct [^notfound].

> Final answer: S = 5000.

---

The value of (S) is **5000**. This is found by substituting (a = 101) and (b = 49) into the expression (S = ab + a - b - 1), which yields (S = 101 \\times 49 + 101–49–1 = 4949 + 101–49–1 = 5000).

---

## Step-by-step calculation

Given the expression:

[S = ab + a - b - 1]

Substitute (a = 101) and (b = 49):

[S = (101 \\times 49) + 101–49–1]

Calculate the product:

[101 \\times 49 = 4949]

Now substitute back:

[S = 4949 + 101–49–1]

Perform the addition and subtraction from left to right:

[4949 + 101 = 5050]

[5050–49 = 5001]

[5001–1 = 5000]

---

Therefore, the value of (S) is **5000**.

---

## References

### The total value equation: a suggested framework for understanding value creation in diagnostic radiology [^f498c20c]. Journal of the American College of Radiology (2014). Low credibility.

As a result of macroeconomic forces necessitating fundamental changes in health care delivery systems, value has become a popular term in the medical industry. Much has been written recently about the idea of value as it relates to health care services in general and the practice of radiology in particular. Of course, cost, value, and cost-effectiveness are not new topics of conversation in radiology. Not only is value one of the most frequently used and complex words in management, entire classes in business school are taught around the concept of understanding and maximizing value. But what is value, and when speaking of value creation strategies, what is it exactly that is meant? For the leader of a radiology department, either private or academic, value creation is a core function. This article provides a deeper examination of what value is, what drives value creation, and how practices and departments can evaluate their own value creation efficiencies. An equation, referred to as the Total Value Equation, is presented as a framework to assess value creation activities and strategies.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^c734ee06]. Journal of the American College of Cardiology (2025). High credibility.

ACC/AHA economic value statement templates — three formats and threshold — are specified as follows: The examples define key terms and use a cost-effectiveness threshold of $120 000 per QALY gained; Format 1 asks "What is the cost-effectiveness of the intervention at its current cost?" and may include "an ICER of $i per QALY gained (< $120 000 per QALY gained in p% of probabilistic simulations)"; Format 2 asks "What would the cost of the intervention have to be in order for the intervention to meet the cost-effectiveness threshold?" and states the strategy is cost-effective "at a threshold of $120 000 per QALY gained if the cost of the (intervention) is less than $t"; Format 3 combines both questions; ICER (incremental cost-effectiveness ratio) and QALY (quality-adjusted life year) abbreviations are defined on-page.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^68cfa501]. Journal of the American College of Cardiology (2025). High credibility.

Cost-effectiveness thresholds — framework and updates explain that the 2014 ACC/AHA statement provided per–capita GDP–based thresholds such that an intervention with an ICER < $50 000 per QALY gained should be considered high value, $50 000 to < $150 000 (1-3x per capita GDP) per QALY gained should be considered intermediate value, and ≥ $150 000 per QALY gained should be considered low value. The World Health Organization's program suggested that costs less than 3 times the national annual GDP per capita per disability-adjusted life year averted should be considered cost-effective, whereas costs less than 1 times should be considered highly cost-effective; however, experts have argued this approach lacks theoretical justification, and World Health Organization experts now also advise against the use of per capita GDP-based cost effectiveness thresholds and instead suggest considering cost-effectiveness information alongside other contextual information in a transparent multicriterion decision process. The writing committee reviewed alternative approaches, including relying on US-based studies; for example, a health opportunity cost analysis estimated that at 2019 prices, for every $1000000 increase in health care expenditures 1860 persons were projected to become uninsured with 81 QALYs lost due to mortality and 15 QALYs lost due to morbidity, implying a cost-effectiveness threshold of $104 000 per QALY ($51 000 to $209 000 per QALY) in 2019 US dollars, and in the probabilistic analysis 40% of the simulations suggested the threshold was less than $100 000 per QALY.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^00cf701b]. Journal of the American College of Cardiology (2025). High credibility.

Cost-effectiveness threshold for U.S. clinical guidelines — the writing committee "recommend the use of $120 000 per QALY as the cost-effectiveness threshold for clinical guidelines", with the threshold to be "periodically reexamined", "not be adjusted annually for inflation", and "revised every 10 years (or sooner…)". Supporting estimates include a 2024 Personal Consumption Expenditure update that "suggests a cost-effectiveness threshold of $117 000 per QALY", a welfare economics approach indicating willingness to pay tied to income ("per capita disposable income of $60 300… approximately $142 000 (range: $120 000-$175 000) for 1 QALY"), and a population-level framework using World Bank data estimating "$95 958 ($81 672-$120 181) per QALY", translating to "$112 000 ($96 000-$141 000) per QALY" after GDP growth; while "no single method… can be considered the 'gold standard'", these three approaches "produced similar results".

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^38ae679c]. Journal of the American College of Cardiology (2025). High credibility.

Selecting therapies for economic value statements in AHA/ACC guideline development is framed with explicit strength language: the authors state, "we suggest that clinical guidelines include economic value statements" for all interventions with adequate-quality economic evaluations; whether a value statement is appropriate "should rely on the judgment of clinical and economic experts". To the extent feasible, committees "should consider including economic value statements" for interventions with Class 1 and 2A recommendations and for interventions where understanding economic value is likely to influence adoption, with examples including high-cost therapies or those eligible to a large number of individuals. When high-quality evaluations are scarce, value statements "may highlight evidence gaps", and the first step in developing them is a literature review and consultation with subject matter experts to identify all relevant economic evaluations.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^6ce770b5]. Journal of the American College of Cardiology (2025). High credibility.

AHA/ACC cost/value methodology — economic value statement format, placement, and threshold: Guidelines "should use the "Economic Value Statement" instead of the previously used term "Value Statement" to clarify that cost effectiveness is only 1 component of value", and because it is interpreted in context, the economic value statement "should immediately follow the clinical recommendation". Each statement "should consist of the class of recommendation, level of certainty, and recommendation", and "interventions are considered to be cost-effective at a threshold of $120 000 per QALY gained". The recommendation "should include the population, intervention, comparator, cost of the intervention, and ICER with % of simulations below the accepted threshold", and if studies examine a different population, "this should be reflected in the wording of the economic value statement".

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^362144cd]. Journal of the American College of Cardiology (2025). High credibility.

AHA/ACC cost/value methodology — therapies requiring a value statement: Consistent with the 2014 cost/value clinical practice guidelines, we suggest that clinical guidelines include economic value statements about all interventions for which economic evaluations of adequate quality are available, including preventive, diagnostic, and therapeutic strategies, and approaches to health care delivery relevant to the clinical guidelines. The decision about whether an economic value statement is appropriate should rely on the judgment of clinical and economic experts on the guideline writing committee, taking into account the clinical and population health relevance, cost, and available evidence. To the extent feasible, guideline committees should consider including economic value statements for: 1) interventions that receive Class 1 and 2A recommendations in the clinical guidelines, and 2) interventions for which an understanding of economic value is likely to influence adoption. An example of the latter would be an intervention that is expected to substantially impact total health care spending, either because it has a high cost or because a large number of individuals are likely to be eligible. When high-quality economic evaluations are scarce, economic value statements may highlight evidence gaps that can be addressed in future research (eg, indeterminate economic value due to a small number of studies). The first step in developing economic value statements is a review of the literature and consultation with subject matter experts in the field to identify all economic evaluations relevant to particular clinical guidelines.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^943345bf]. Journal of the American College of Cardiology (2025). High credibility.

Figure 3 — health opportunity cost approach to US cost-effectiveness thresholds reports 50000 simulations with varying input values, with 23902/50000 (48%) thresholds < $100000/QALY and 7006/50000 (14%) thresholds > $150000/QALY; the base-case estimate is $104,000/QALY in 2019 US dollars with a (95% UI, $51,000–$209,000/QALY), and updating to 2024 US dollars suggests a cost-effectiveness threshold of $117000 per QALY.

---

### Putting the value framework to work in surgery [^9f5a169c]. Journal of the American College of Surgeons (2015). Low credibility.

Background

Health policy experts have proposed a framework defining value as outcomes achieved per dollar spent on health care. However, few institutions quantify their delivery of care along these dimensions. Our objective was to measure the value of our surgical services over time.

Study Design

We reviewed the data of patients undergoing general and vascular surgery from 2002 through 2012 at a tertiary care university hospital as abstracted by the American College of Surgeons NSQIP. Morbidity and mortality data from the American College of Surgeons NSQIP database were risk adjusted to calculate observed-to-expected ratios, which were then inverted into a numerator as a surrogate for quality. Costs, the denominator of the value equation, were determined for each patient's hospitalization. The ratio was then transformed by a constant and analyzed with linear regression to analyze and compare values from 2002 through 2012.

Results

A total of 25,453 patients met criteria for inclusion. Overall, the value of surgical services increased from 2002 through 2012. The observed increase in value was greater in general surgery than in vascular surgery, and value actually decreased in vascular procedures. Although there was a similar increase in outcomes in vascular surgery compared with general surgery, costs rose significantly higher ($474/year vs -$302/year; p < 0.001). These increased costs were mostly observed from 2006 through 2010 with the adoption of endovascular technology.

Conclusions

Despite the challenges posed by current information systems, calculating risk-adjusted value in surgical services represents a critical first step for providers seeking to improve outcomes, avoid ill-advised cost containment, and determine the costs of innovation.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^63fa1003]. Journal of the American College of Cardiology (2025). High credibility.

Cost-effectiveness thresholds for cardiovascular cost-effectiveness analyses (CEAs) — The 2014 ACC/AHA cost-value methodology statement provided thresholds to identify high-, intermediate-, and low-value care based on U.S. per capita gross domestic product, and the writing committee determined that an intervention with an ICER < $50 000 per QALY gained should be considered high value, $50 000 to < $150 000 (1–3× per capita GDP) per QALY gained should be considered intermediate value, and ≥ $150 000 per QALY gained should be considered low value. WHO-origin GDP benchmarks suggested an intervention that costs less than 3 times the national annual GDP per capita per disability-adjusted life year averted should be considered cost-effective and that costs less than 1 times should be considered highly cost-effective, but critics note they "set such a low bar for cost effectiveness that very few interventions with evidence of efficacy can be ruled out"; WHO experts now also advise against per capita GDP-based thresholds and suggest considering cost-effectiveness alongside other contextual information in a transparent multicomponent decision process. Reflecting these concerns, the writing committee reviewed alternative approaches to incorporating CEA results into guidelines, including relying on US-based studies for identifying a cost-effectiveness threshold or thresholds for cardiovascular CEAs, and Vanness et al used a health opportunity cost approach estimating that for every $1 000 000 increase in health care expenditures, 1869 persons become uninsured, resulting in 81 QALYs lost due to mortality and 15 QALYs lost due to morbidity, implying a cost-effectiveness threshold of $104 000 per QALY ($51 000 to $209 000 per QALY) in 2019 US dollars; in the probabilistic analysis, 40% of the simulations suggested the threshold was less than $100 000 per QALY.

---

### Exploring replay [^e0cbceb2]. Nature Communications (2025). High credibility.

Model-free control

Several algorithmic approaches exist to solving the problem of optimal control in RL tasks. One popular example is Q -learning, which is an important and widely used algorithm for learning the optimal-function. It belongs to a more general class of model-free temporal difference algorithms which, after every experienced interaction with the environment, successively update their value function estimates based on the encountered reward prediction errors. Specifically for Q -learning, the update rule at iteration n is:

Here, the Q -value estimate is updated towards the difference (or prediction error) between the initial estimate, Q n (s, a), and the sum of the observed reward at the next state reached and the discounted maximal Q n -value at that state, weighted by the learning rate, α. Note that the action that optimisesat s might be different from the one used in equation (4) that optimised

The Q n +1 -values themselves can be used to determine a policy, for instance:where β > 0 is an inverse temperature parameter that controls how deterministic is π n +1. Since π n +1 (s, a) favours actions with higher Q n +1 -values, it tends to be better than π n (s, a) in terms of expected return. The remaining stochasticity is a crude method for arranging a mix of exploration and exploitation.

Model-based control

A different solution is to learn a model of the environment which can then be used to perform prospective planning of the actions to execute. Value functions can also be acquired using the recurrent Bellman equation, for instance:

Here, the recurrent relationship between the successive states allows the agent to make use of its knowledge of the transition structure of the environment (the model) to propagate the information about future rewards towards its current situation or state in the environment. If the agent does indeed know the model (also including), then various forms of planning can be used to compute the long-run consequences associated with the available actions at decision time and make a far-sighted and informed decision. Value iteration is one example planning algorithm which iteratively performs synchronous updates (for all states and actions in each sweep) specified by Equation (6). Such updates are also called Bellman backups because of the application of the Bellman equation. Given a perfect model of the environment, and, such procedure is guaranteed eventually to converge to the optimal value function.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^9d0e2219]. Journal of the American College of Cardiology (2025). High credibility.

Supporting text requirements for economic value statements specify that supporting text should include key elements: a summary of the high-quality CEAs used to generate the statement with rationale for which studies were included and details such as study population, intervention, comparator, clinical outcomes, sources of key effectiveness and safety parameters, perspective, analytic horizon, base-case treatment cost, and source of funding; point estimates and the proportion of simulations that were cost-effective at a specified threshold; and results of key sensitivity analyses, noting that a 1-way sensitivity analysis of intervention cost variation can be helpful, that additional information about sensitivity to intervention cost should be provided, and that inclusion of a figure similar to Figure 4 is encouraged if available.

---

### Optimal policy for value-based decision-making [^e881f37b]. Nature Communications (2016). Medium credibility.

Optimal decisions with DDMs with collapsing boundaries

To find the optimal policy, we borrow tools from dynamic programming (DP). One of these tools is the 'value function', which can be defined recursively through Bellman's equation. In what follows, we show that the optimal policy resulting from this value function is described by two time-dependent parallel bounds in the two-dimensional space of current estimates of the true option rewards. These bounds are parallel with unity slopes, approach each other over time and together form a bound on the difference of reward estimates. This difference is efficiently inferred by diffusion models, such that DDMs can implement the optimal strategy for value-based decision-making.

Bellman's equation for optimal value-based decision-making. To define the value function, assume that the decision maker has accumulated some evidence about the option rewards for some time t. Given this accumulated evidence, the value function returns the total reward the decision maker expects to receive when following the optimal policy. This value includes both the cost for evidence accumulation from time t onwards and the reward resulting from the final choice. The expected rewards, and elapsed time t are sufficient statistics of the accumulated evidence (see Methods section), such that the value function is defined over these quantities. At each point in time t during evidence accumulation we can either commit to a choice or accumulate more evidence and choose later. When committing to a choice, it is best to choose the option associated with the higher expected reward, such that the total expected rewardfor choosing immediately is given by the value for 'deciding',(Fig. 3a). When accumulating more evidence for a small duration δt, in contrast, the decision maker observes additional evidence on which she updates her belief about the true rewards while paying accumulation cost cδt. At this stage, she expects to receive a total reward of. Therefore, the total expected reward for accumulating more evidence is given by the value for 'waiting',(Fig. 3b), where the expectation is over the distribution of future expected rewards, and, given that they areandat time t (see Methods section for an expression of this distribution). The decision maker ought to only accumulate more evidence if doing so promises more total reward, such that the value function can be written recursively in a form called Bellman's equation (Fig. 3a-c, e; see Supplementary Note 1 for formal derivation)

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^a83ec36b]. Journal of the American College of Cardiology (2025). High credibility.

Health opportunity cost approach — United States cost-effectiveness threshold estimation indicates that, across 50000 simulations, 23902/50000 (48%) of thresholds were < $100000/QALY and 7006/50000 (14%) were > $150000/QALY; the base-case estimate was $104,000/QALY in 2019 US dollars with a 95% uncertainty interval of $51,000–$209,000/QALY, and updating to 2024 US dollars suggests a threshold of $117000 per QALY.

---

### Incorporating economic evidence in clinical guidelines: a framework from the clinical guidelines committee of the American College of Physicians [^902eae12]. Annals of Internal Medicine (2025). High credibility.

Appendix figure 3 — sample summary of findings table provides a template for reporting economic evaluations, with columns for Outcome, Number of Studies (Reference), Population, Perspective, Incremental Cost (Range), Incremental Benefit (quality-adjusted life-year [QALY], patient-centered outcomes) (Range), Reported incremental cost-effectiveness ratio (ICER) per outcome (Range), Certainty of Body of Evidence, Adjusted ICER per U.S. Currency/Inflation, and Value Threshold†; the rows include Intervention A vs. Intervention B with placeholders ICER per QALY at X years and ICER per QALY at Y years, and footnotes clarify CGC = Clinical Guidelines Committee; ICER = incremental cost-effectiveness ratio; QALY = quality-adjusted life-year, note it was prepared with GRADEpro and modified by the authors, and that economic value is defined by the CGC (willingness-to-pay thresholds).

---

### Optimal policy for value-based decision-making [^1c939df9]. Nature Communications (2016). Medium credibility.

For decades now, normative theories of perceptual decisions, and their implementation as drift diffusion models, have driven and significantly improved our understanding of human and animal behaviour and the underlying neural processes. While similar processes seem to govern value-based decisions, we still lack the theoretical understanding of why this ought to be the case. Here, we show that, similar to perceptual decisions, drift diffusion models implement the optimal strategy for value-based decisions. Such optimal decisions require the models' decision boundaries to collapse over time, and to depend on the a priori knowledge about reward contingencies. Diffusion models only implement the optimal strategy under specific task assumptions, and cease to be optimal once we start relaxing these assumptions, by, for example, using non-linear utility functions. Our findings thus provide the much-needed theory for value-based decisions, explain the apparent similarity to perceptual decisions, and predict conditions under which this similarity should break down.

---

### Optimal policy for value-based decision-making [^aa6efafd]. Nature Communications (2016). Medium credibility.

Bellman's equation for reward rate maximization

In order to find Bellman's equation and the associated optimal policy that maximizes the reward rate, we borrow concepts from average-reward DP (refs). We do so to avoid that the value function associated with the first trial becomes infinite if this trial is followed by an infinite number of trials that, in total, promise infinite reward. Average-reward DP penalizes the passage of some time δt by cost ρδt, where ρ is the reward rate, equation (4), which equals the average expected reward per unit time. With this additional cost, and the value function turns into the 'average-adjusted value' function, which is the same for each trial in the sequence, and is defined as follows. Immediate decisions are expected to be rewarded by, followed by some waiting time t w that comes at cost ρt w. After this waiting time, the decision maker holds belief(recall thatdenotes the prior mean for option j) at the onset of the next trial, and therefore expects rewardin this trial. Thus, the value for decision immediately is given by. The value for accumulating more evidence is the same as for single, isolated trials (see previous section), only that the cost increases from cδt to (c + ρ) δt. Bellman's equation is again given by taking the maximum over all values. In contrast to single, isolated trials, the policy arising from Bellman's equation is invariant to global shifts in the value function. That is, we can add some constant C to the average-adjusted value associated with all sufficient statistics, such that, and would recover the same policy. As a result, we can arbitrarily fix the average-adjusted value for one such statistic, and all other values follow accordingly. For convenience, we choose, which results in Bellman's Equation

whereis given by. This also gives us a recipe to findwill only hold for the correct ρ, such that we can computefor some arbitrary ρ, and then adjust ρ untilholds. This is guaranteed to provide the desired solution, asis strictly decreasing in ρ as long as t w > 0 (rather than t w = 0; see Supplementary Note 1).

---

### Optimal policy for value-based decision-making [^d61b4583]. Nature Communications (2016). Medium credibility.

where the expectation is, as for equation (2), across choices j and evidence accumulation times T, given the flow of evidence. Here, it is critical that we fix the time period while leaving open the number of choices that can be performed. If we instead were to fix the number of choices while leaving open the time to make them, it again becomes optimal to maximize the total expected reward for each of these choices separately, such that the optimal policy for each such choice is the same as that for single, isolated choices.

Infinite choice sequences make using the standard value function difficult. This value function returns the total expected reward for all current and future choices when starting from the current state. For an infinite number of such future choices, the value function might thus become infinite. One way to avoid this is to use instead the 'average-adjusted value' function, which — in addition to an accumulation cost — penalizes the passage of some time duration δt by − ρδt, where ρ is the reward rate. This reward rate is by equation (4) the total reward received (including accumulation costs) per second, averaged over the whole choice sequence. Penalizing the value function by this reward rate makes explicit the implicit loss of rewards due to potential future choices that the decision maker misses out on when accumulating too much evidence for the current choice. This penalization allows us to treat all choices in the sequence as if they were the same, unique choice. A further consequence of this penalization is that the value function for accumulating more evidence for some duration δt undergoes a more significant change, as accumulating this evidence now comes at a cost −(c + ρ) δt instead of the previous − cδt (see Methods section for the associated Bellman equation). For positive reward rates, ρ > 0, this cost augmentation implies more costly evidence accumulation such that it becomes advantageous to accumulate less evidence than for single, isolated choices. This change is implemented by decision boundaries that collapse more rapidly (shown formally in Supplementary Note 1, see also Supplementary Fig. 1). Thus, collapsing decision boundaries implement the optimal policy for both single choices and sequences of choices, with the only difference that these boundaries collapse more rapidly for the latter. The duration of inter-choice waiting t w modulates this difference, as with t w →∞, the reward rate described by equation (4) reduces to the expected reward for single, isolated choices, equation (2). Therefore the policy for single trials is a special case of that for maximizing the reward rate in which the waiting time between consecutive choices becomes close-to-infinite.

---

### Biased expectations about future choice options predict sequential economic decisions [^49921c9c]. Communications Psychology (2024). Medium credibility.

Here, we set the prior values of μ and σ 2 in two possible ways: objective value and subjective values versions. In some previous studies of optimal stopping for price decisions, the mean and variance of the generating distribution has been fixed in advance by the mean and variance of the distribution of objective prices. We implemented an objective values version of the Ideal Observer in this way for all the study conditions reported herein. This objective values procedure for the Ideal Observer assumes that the raw prices can be treated as a proxy for participants' subjective value of the prices, so an Ideal Observer that optimises only the raw prices when making decisions would therefore be an appropriate basis for comparison with participants. However, we also had direct access to participants' subjective values of options in some conditions (Pilot full, Study 1 full condition, Study 1 ratings condition, Study 2 and both sequence length conditions of Study 3), due to the presence of the initial rating phase, and so we could also build a subjective values version of the Ideal Observer. This second way of computing the Ideal Observer assumes that participants' subjective valuation of prices may not necessarily exactly equal the raw price values, especially in their scaling, which may be relevant to full information problems. We used each participants' individualised ratings (subjective valuations) of the prices as option values input to the subjective values version of the Ideal Observer, and we used the mean and variance of individual participants' ratings distributions when initialising the prior of the generating distribution of the Ideal Observer.

Because conditions with an initial rating phase had objective and subjective values versions of the Ideal Observer, with each version providing separate optimality estimates, we were able to test the hypotheses that the use of objective or subjective values when modelling (a) affects the strategy taken by the optimality model and (b) changes the assessment of participant bias. We ensured for both objective values and subjective values versions of the models that better options were always more positively-valued such that the models were always solving a maximisation problem. We further ensured that estimated parameters for both objective values and subjective values versions of the models would be on the same scales by reflecting the objective prices around their mean. Then we rescaled those values to span 1 (the highest/worst price) to 100 (the best price). These reflected and rescaled objective values were then used in objective values models when computing the prior generating distribution, and when inputting price values to the model as option values. Subjective values were already rated by participants on this same 1 to 100 scale.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^68e2e74a]. Journal of the American College of Cardiology (2025). High credibility.

Cost-effectiveness plane (Figure 1) — when a new intervention produces less health and lower costs compared with the comparator, it may be considered cost-effective if the incremental cost-effectiveness ratio (ICER) is greater than the cost-effectiveness threshold; however, this situation does not arise often because patients, clinicians, and health systems rarely accept worse health outcomes even if it reduces spending, and the figure includes labels "Intervention is cost-saving ("dominant") or always acceptable" and "Intervention is inferior ("dominated") or never acceptable".

---

### Incorporating economic evidence in clinical guidelines: a framework from the clinical guidelines committee of the American College of Physicians [^4483eea4]. Annals of Internal Medicine (2025). High credibility.

Figure 1 — comparative value of interventions — categorizes value by clinical net benefit and incremental cost for quality-adjusted life-year (QALY) with intervention versus comparator, where the incremental cost dimension reflects the incremental cost-effectiveness ratio per QALY gained. For favorable clinical net benefit, higher cost corresponds to high value (< $100 000), intermediate value ($100 000 to $200 000), or low value (> $200 000) with the intervention more effective and more costly; lower cost corresponds to high value with the intervention more effective and less costly (cost-saving). For unfavorable clinical net benefit, higher cost indicates no value with the intervention less effective and more costly (cost-dominated), and lower cost indicates no value with the intervention less effective and less costly.

---

### Biased expectations about future choice options predict sequential economic decisions [^9b0d2bac]. Communications Psychology (2024). Medium credibility.

Next, the model works backwards through the sequence, iteratively using the aforementioned formula forwhen computing each respective action value Q for taking the option and declining the option for each t. Whenever the reward value of taking the current option is considered, the reward function R assigns reward values to options based on their ranks. h represents the relative rank of the current option.

In contrast, the reward value of sampling again is simply the cost to sample C.

This customisable R function allowed us to examine how the Ideal Observer changes its sampling strategy under the different reward payoff schemes used in our studies. Pilot full, Study 1 full, Study 2 and both conditions in Study 3 all involved instructing participants to try to choose the best price possible. In study conditions using these instructions, we implemented a continuous payoff function (resembling that of the classic Gilbert & Mosteller formulation), in which the relative rank of each choice would be rewarded commensurate with the value of its associated option. In Pilot baseline and the baseline, squares, timing, and prior conditions of Study 1, we adapted the payoff scheme to match participants' instructions that they would be paid £0.12 for the best rank, £0.08 for the second-best rank, £0.04 for the third best rank and £0 for any other ranks. Lastly, in the payoff condition of Study 1, we programmed the reward payoff function to match participants' reward of 5 stars for the best rank, 3 stars for the second-best rank, one star for the third-best rank and zero stars for any other ranks.

Another feature added to our implementation of the Ideal Observer, compared to the Gilbert & Mosteller base model, is the ability to update the model's generating distribution from its experience with new samples in a Bayesian fashion, instead of this generating distribution being specified in advance and then fixed throughout the paradigm. This Bayesian version of the optimality model treats option values as samples from a Gaussian distribution with a normal-inverse- χ2 prior. The prior distribution is initialised before experiencing any options with four parameters: the prior mean μ 0, the degrees of freedom of the prior mean κ, the prior variance σ 2 0 and the degrees of freedom of the prior variance ν. The μ 0 and σ 2 0 parameters of this prior distribution are then updated by the model following presentation of each newly sampled option value as each sequence progresses.

---

### Clinical trial endpoints for the approval of cancer drugs… [^f284dacf]. FDA (2025). Medium credibility.

Investigational Anticancer Agents in Clinical Trials, J Clin Oncol, 9: 2225–2232. Contains Nonbinding Recommendations 7 A. Overall Survival Overall survival is defined as the time from randomization until death from any cause and is measured in the intent-to-treat population. Survival is considered the most reliable cancer endpoint, and when studies can be conducted to adequately assess survival, it is usually the. preferred endpoint. This endpoint is precise and easy to measure, documented by the date of death. Bias is not a factor in endpoint measurement. Survival improvement should be analyzed as a risk-benefit analysis to assess clinical benefit. Overall survival should be evaluated in randomized controlled studies. Data derived from. recurrence as patients with noncensored observations who have not yet experienced the event.
2. Objective Response Rate ORR is defined as the proportion of patients with tumor size reduction of a predefined amount and for a minimum time period.

Response duration usually is measured from the time of initial response until documented tumor progression. Generally, the FDA has defined ORR as the. sum of partial responses plus CRs. When defined in this manner, ORR is a direct measure of a drug antitumor activity, which can be evaluated in a single-arm study. Stable disease should not be a component of ORR. Stable disease can reflect the natural history of disease, whereas. magnitude of the effect, the number of CRs, the durability of response, the disease setting, the location of the tumors, available therapy, and the risk-benefit relationship.
3. Complete Response CR is defined as no detectable evidence of tumor. CR is generally measured through imaging. used as a surrogate endpoint for accelerated approval.
4. Time to Progression and Progression-Free Survival TTP and PFS have served as primary endpoints for drug approval. TTP is defined as the time from randomization until objective tumor progression; TTP does not include deaths.

PFS is. effect. 22 The most reliable method for demonstrating efficacy is to show a statistically significant improvement in a clinically meaningful endpoint in randomized controlled trials. The following sections discuss other approaches that may be indicated when a randomized controlled trial demonstrating superiority is not feasible or ethical. If a sponsor.

---

### Sources of confidence in value-based choice [^6819ecee]. Nature Communications (2021). High credibility.

First, we investigated which of the two models (heuristic or normative) can better predict future confidence reports assuming that attentional effort θ and evidence gain k have fixed values (i.e. no trial-to-trial fluctuations in the values of these parameters as it is usually assumed in the literature). While both models were monotonically related to the confidence reports (β heuristic = 0.45 ± 0.04, P < 0.001; β norm = 0.53 ± 0.06, P < 0.001), we found overwhelming evidence that the normative model provided more reliable predictions of confidence via model comparison (BF ≫ 1000 → ∞; also confirmed via leave-one-out (LOO) cross-validation metrics: ΔLOO = 29; Fig. 3 c).

---

### Optimal policy for value-based decision-making [^dbef88ae]. Nature Communications (2016). Medium credibility.

Methods

Structure of evidence and evidence accumulation

Here, we assume a slightly more general version of the task than the one we discuss throughout most of the main text, with a correlated prior and a correlated likelihood. Further below we describe how this version relates to the one in the main text. In particular, we assume the prior over true rewards, given by vector, to be a bivariate Gaussian, with meanand covariance Σ z. In each small time step i of duration δt, the decision maker observes some momentary evidencethat informs her about these true rewards. After accumulating evidence for some time t = nδt, her posterior belief about the true rewards is found by Bayes' rule, and results in

where we have definedas the sum of all momentary evidence up to time t, andas the posterior covariance (hereafter, when Σ (t) is a function of time it denote the posterior covariance, rather than the covariance of evidence, Σ). For the case that experienced reward r ≡(r 1, r 2) T equals true reward z, that is r = z, the mean estimated option rewardis the mean of the above posterior.

Expected future reward estimates

Finding the optimal policy by solving Bellman's equation requires computing the distribution of expected future rewardsgiven the current expected rewards. Assuming a small δt such that the probability of an eventual boundary crossing becomes negligible, we can find this distribution by the marginalization

Asis the mean of the posterior of z after having accumulated evidence up to time t + δt, it is given by

where we have used x (t + δt) = x (t)+ δ x (t + δt) and, following from the definition of. Furthermore, by the generative model for the momentary evidence we have, and our current posterior is, which, together, gives. With these components, the marginalization results in

where we have only kept terms of order δt or lower. An extended version of this derivation is given in Supplementary Note 1.

---

### Incorporating economic evidence in clinical guidelines: a framework from the clinical guidelines committee of the American College of Physicians [^428e0ea2]. Annals of Internal Medicine (2025). High credibility.

American College of Physicians Clinical Guidelines Committee (CGC) — discussion on integrating economic evidence explains that the CGC aims to improve health and health care by providing clinicians with recommendations based on the best available evidence and includes evaluating the cost of care, assessing the value of an intervention, incorporating economic evidence into recommendations, and discussing corresponding clinical considerations; it highlights limitations of cost-effectiveness analyses (CEAs), noting that willingness-to-pay thresholds commonly used in the United States do not reflect clinical, social, individual economic, and inflation considerations, economic evidence is sparse and poorly reported in the United States and analyses from outside the United States have low applicability, the certainty of economic evidence is often limited due to dynamic pricing and modeling assumptions, industry funding of CEAs is common and results cannot be easily repurposed in quantitative meta-analytic syntheses, many CEAs rely on surrogate outcomes and analyze medications individually rather than by class, and certainty in CEA results should be based on critically appraised certainty of clinical benefits and harms and model credibility.

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^b40fce01]. Kidney International (2024). High credibility.

Selection of GFR estimating equations — use of validated eGFR: We recommend using a validated GFR estimating equation to derive GFR from serum filtration markers (eGFR) rather than relying on the serum filtration markers alone (1D). Practice Point 1.2.4.1 advises to use the same equation within geographical regions (as defined locally [e.g., continent, country, and region] and as large as possible), noting that within such regions, equations may differ for adults and children. The recommendation places a high value on using an estimating equation validated in the population of interest, and the key points are to use an equation validated and most suited to the population of interest; there is potential for harm if people get different eGFR values when receiving care in different settings, and there is benefit to clinical care, research, and public health with the use of validated equations such that decisions, research findings, and public policy are informed by accurate estimates of CKD.

---

### Allometric cascade as a unifying principle of body mass effects on metabolism [^0bbbcb77]. Nature (2002). Excellent credibility.

The power function of basal metabolic rate scaling is expressed as aM(b), where a corresponds to a scaling constant (intercept), M is body mass, and b is the scaling exponent. The 3/4 power law (the best-fit b value for mammals) was developed from Kleiber's original analysis and, since then, most workers have searched for a single cause to explain the observed allometry. Here we present a multiple-causes model of allometry, where the exponent b is the sum of the influences of multiple contributors to metabolism and control. The relative strength of each contributor, with its own characteristic exponent value, is determined by the control contribution. To illustrate its use, we apply this model to maximum versus basal metabolic rates to explain the differing scaling behaviour of these two biological states in mammals. The main difference in scaling is that, for the basal metabolic rate, the O(2) delivery steps contribute almost nothing to the global b scaling exponent, whereas for the maximum metabolic rate, the O(2) delivery steps significantly increase the global b value.

---

### Assessment of clinical activity of PD-1 checkpoint inhibitor combination therapies reported in clinical trials [^9c277e2f]. JAMA Network Open (2020). High credibility.

The Bliss independent action modelis shown diagrammatically in Figure 3 A and B. Using the Bliss independent action model, we calculated the predicted ORR for the 100 trials (90.1%) in which the ORRs for PD-1 pathway monotherapy and the combination agent or regimen were known. A regression plot comparing the actual observed ORR with the Bliss predicted ORR is shown in Figure 3 C. The slope of the nonlinear regression was 1.073 (95% CI, 1.00–1.14; R 2 = 0.675).

Figure 3.
Contribution of Bliss Independent Combination Outcomes to Combination Trial Response Rates

A, The Bliss model posits that the combination of 2 agents with independent activities will be estimated by the following equation: Y ab, P = Y a + Y b – Y a × Y b, in which Y ab, P represents the estimated proportion of patients responding to agents in combination, Y a represents the observed proportion responding to agent or regimen 1, and Y b represents the observed proportion responding to agent or regimen 2. B, Z (yellow) is the difference between the observed objective response rate (ORR) for a combination and the estimated ORR from the Bliss equation. Z can be positive or negative. C, The regression plot (solid line) describes the association between the Bliss-estimated ORR based on independent contributions and the ORR of combinations determined in clinical trials. The dashed lines indicate 95% prediction intervals, and the dots represent individual trials. D, The histogram describes the frequency distribution of Z scores beyond the ORRs estimated by the Bliss model for combination efficacy.

---

### Memristive bellman solver for decision-making [^e0401d22]. Nature Communications (2025). High credibility.

Methods

Recurrent dot product Bellman equation

The Bellman equation is a fundamental equation in dynamic programming and reinforcement learning, used to compute the value function, which represents the expected cumulative reward starting from state S. The Bellman equation is expressed as:

Here, the V (S n) is the value function of the current state S n, R (S n) is current reward function, γ is a discount constant, P is the state transition probability from previous states to current state, S is the set of all possible states (state space), S n represents the current state and S n −1 represents previous states.

This equation is iterative, meaning it requires repeated calculations to converge to the optimal value function. However, this iterative nature makes it challenging to implement efficiently on MCIM systems. To make the Bellman equation compatible with MCIM systems, we introduce a time dimension to describe the relationship between the current state and previous states. Let S t and S t −1 represent the state at time t and t −1, respectively. The Bellman equation can then be rewritten as:

Here, S n −1 represents all possible previous states, while S t −1 represents the state at the previous time t −1. Hence, in equation (2), S n −1 cannot be directly replaced by S t −1 because S n −1 refers to all previous states, whereas S t −1 refers to a single state at time t − 1.

To simplify the equation, we make two key assumptions based on the temporal difference (TD) algorithm and the local property of the state space.

Temporal smoothness assumption

When the learning process is close to convergence, the value function at two adjacent time steps t and t − 1 is approximately equal. That is:

---

### Incorporating economic evidence in clinical guidelines: a framework from the clinical guidelines committee of the American College of Physicians [^537f28fa]. Annals of Internal Medicine (2025). High credibility.

Clinical Guidelines Committee (CGC) value thresholds for economic evidence in cost‑effectiveness analyses categorize interventions by incremental cost‑effectiveness ratio (ICER) per quality‑adjusted life‑year (QALY) gained as high value when cost‑saving or < $100 000, intermediate value at $100 000-$200 000, low value at > $200 000, and no value when dominated. The CGC states these thresholds are those most commonly referenced in U.S.-based cost‑effectiveness analyses, may be adjusted on a topic‑by‑topic basis, and that an intervention is dominated by strict dominance or extended dominance.

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^197efc53]. Kidney International (2024). High credibility.

Values and preferences, resource use, and implementation — Using validated eGFR equations improves the accuracy of assessment of true GFR but remains imperfect, and no single equation performs consistently across all populations; the Work Group judged that people with CKD and their healthcare providers would want GFR estimated using the equation providing the greatest accuracy in the population of their geographical region, and there are several valid equations that can reasonably be used in local settings. Each region should have a mechanism for review and selection of equations for implementation by laboratories, and decisions at this level by continental or national organizations are likely to minimize the likelihood that decisions for equation use will be made within small geographical areas governed by local decisions, leading to greater variation in eGFR and uncertainty by people with CKD and healthcare providers. There are likely to be tradeoffs between optimal accuracy in local regions versus uniformity; equations optimized for a specific region can help to ensure that the GFR thresholds for disease definition, classification, and risk estimation have the same implications across regions; however, it would lead to barriers to implementation, as it will not be possible for all regions to conduct a sufficiently large and representative study to evaluate these equations and develop modifications. If not possible, or in the interim, we advise using equations that were developed in populations most similar to the available populations. Resource use includes initial costs such as human resource costs and education for providers, which incurs both direct and indirect costs.

---

### Enhancing the value of PCSK9 monoclonal antibodies by identifying patients most likely to benefit. A consensus statement from the National Lipid Association [^71b52af0]. Journal of Clinical Lipidology (2019). High credibility.

Cost-effectiveness modeling and assumptions — Event-rate and NNT estimates were derived by considering patient subgroups and limiting the horizon of benefit to 5 years with a focus on "hard" ASCVD events; examples referenced specific 10-year absolute risk levels (eg, 45%, 30%, and 20%). Annualized placebo event rates were extrapolated to 10-year risk consistent with linear rates over 5 to 7 years, while NNT benefits were calculated for a 5-year time period. Higher ASCVD risk and greater LDL-C–lowering efficacy are anticipated to yield lower NNTs, and conservative ICER-based modeling indicated reasonable to high value at approximately $5400/y.

---

### Assessment of clinical activity of PD-1 checkpoint inhibitor combination therapies reported in clinical trials [^c3225341]. JAMA Network Open (2020). High credibility.

Statistical Analysis

The fold change from monotherapy to combination activity was calculated in the database by division when both values were available. Individual values were plotted in a column plot using Excel Office 365 (Microsoft Corp). Histograms assessing the aggregate data, together with calculation of normal curve parameters, was performed in Sigmaplot version 14.0 (Systat Software).

A calculated combination ORR based on the Bliss independent activity modelfor each combination was recorded as Y ab, P = Y a + Y b − Y a × Y b, in which Y ab, P indicates the estimated proportion of patients responding to agents in combination, Y a indicates the observed proportion responding to agent or regimen 1, and Y b indicates the observed proportion responding to agent or regimen 2.

Observed ORRs were compared with Bliss-estimated ORRs using a linear regression plot in Prism version 8 (GraphPad), together with best fit calculations. The difference between the observed ORR and the Bliss-estimated ORR was calculated as a measure of clinical synergy using the following equation: Z = ORR − (Y a + Y b − Y a × Y b), in which the Z score was defined as the difference between the observed ORR for a combination and the estimated combination ORR according to the Bliss equation. Because the Z score measures deviation from additivity, it constitutes a measure of clinical synergy. Individual values were plotted in a column plot using Excel Office 365 (Microsoft Corp). Histograms assessing the aggregate data as well as descriptive statistics were performed in Sigmaplot (Systat Software).

For platinum chemotherapies, vascular endothelial growth factor or vascular endothelial growth factor receptor (VEGF/R) inhibitors, indoleamine 2,3-dioxygenase (IDO) inhibitors, and cytotoxic T-lymphocyte–associated protein 4 (CTLA-4) inhibitors, all measures were determined for individual combinations and plotted using Sigmaplot (Systat Software). No tests of statistical significance were conducted, and therefore, no prespecified level of statistical significance was set.

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^01ae28bc]. Kidney International (2024). High credibility.

CKD staging by glomerular filtration rate (GFR) — use eGFRcr first and combine with cystatin C when available: Recommendation 1.1.2.1 states, "In adults at risk for CKD, we recommend using creatinine-based estimated glomerular filtration rate (eGFRcr). If cystatin C is available, the GFR category should be estimated from the combination of creatinine and cystatin C (creatinine and cystatin C–based estimated glomerular filtration rate [eGFRcr-cys]) (1B)". This recommendation places a high value on data that the most accurate estimation uses 2 biomarkers and that equations using both markers afford greater accuracy, while placing a lower value on the resource utilization and cost of assessing eGFRcr-cys.

---

### A framework to predict the price of energy for the end-users with applications to monetary and energy policies [^8ac11c8b]. Nature Communications (2021). High credibility.

Energy affects every single individual and entity in the world. Therefore, it is crucial to precisely quantify the "price of energy" and study how it evolves through time, through major political and social events, and through changes in energy and monetary policies. Here, we develop a predictive framework, an index to calculate the average price of energy in the United States. The complex energy landscape is thoroughly analysed to accurately determine the two key factors of this framework: the total demand of the energy products directed to the end-use sectors, and the corresponding price of each product. A rolling horizon predictive methodology is introduced to estimate future energy demands, with excellent predictive capability, shown over a period of 174 months. The effectiveness of the framework is demonstrated by addressing two policy questions of significant public interest.

---

### SCAI / ACVP expert consensus statement on cardiovascular catheterization laboratory economics: If the cath lab is your home you should understand its finances: this statement was endorsed by the alliance of cardiovascular professionals (ACVP) in April 2019 [^b8a4d743]. Catheterization and Cardiovascular Interventions (2019). High credibility.

Pro forma for watchman procedure revenue/cost impact — across MS-DRG scenarios, the table reports "Annual watchman implants" of 48, 48, 1, 48, and 1; "Average length of stay" values of 1.3, 2, 2, 3, and 3; "Annual procedure reimbursement" values of $ 1,212,729, $ 1,123,008, $ 23,396, $ 1,123,008, and $ 23,396; "Annual procedural cost" values of $ 903,936, $ 946,752, $ 19,724, $ 993,360, and $ 20,695; and "Annual net margin" values of $ 230,745, $ 43,824, $ 913, $ (29,376), and $ (612). A footnote notes that the estimate of 48 cases/year is optimistic and that if actual volume is < 48/year, the hospital would not receive the rebate and the program would lose about $124,000 even with a two-day length of stay.

---

### Modelling the species-area relationship using extreme value theory [^10b0aaff]. Nature Communications (2025). High credibility.

The nested species-area relationship, obtained by counting species in increasingly larger areas in a nested fashion, exhibits robust and recurring qualitative and quantitative patterns. When plotted in double logarithmic scales it shows three phases: rapid species increase at small areas, slower growth at intermediate scales, and faster rise at large scales. Despite its significance, the theoretical foundations of this pattern remain incompletely understood. Here, we develop a theory for the species-area relationship using extreme value theory, and show that the species-area relationship is a mixture of the distributions of minimum distances to a starting sampling focal point for each individual species. A key insight of our study is that each phase is determined by the geographical distributions of the species, i.e., their ranges, relative to the focal point, enabling us to develop a formula for estimating the number of species at phase transitions. We test our approach by comparing empirical species-area relationships for different continents and taxa with our predictions using Global Biodiversity Information Facility data. Although a SAR reflects the underlying biological attributes of the constituent species, our interpretations and use of the extreme value theory are general and can be widely applicable to systems with similar spatial features.

---

### Expansion of the human mu-opioid receptor gene architecture: novel functional variants [^219db72c]. Human Molecular Genetics (2009). Low credibility.

Note the similarity of the two equations. The terms of d c would add up to d h exactly, if the term f 6 (g 6 − g)/2 that corresponds to the cis -heterozygote, Ab/aB, was replaced by the trans -heterozygote (AB/ab) term, f 5 (g 5 − g)/2. When AB is a susceptibility haplotype, the term d h is positive, and so is d c. In other words, the haplotypic and the composite frequency differences are in the same direction for the 'haplotype-driven' models. We define haplotype-driven models to include recessive, dominant, as well as intermediate models, notably the additive model, where susceptibilities of AB heterozygotes are between those for the genotypes with 0 and 2 copies of AB. Whether the sign of d c is in the same direction as that for d h is determined by the magnitude of the terms that corresponds to the cis - and trans -genotypes, Ab/aB and AB/ab. The condition that the d c is non-negative is satisfied for the 'haplotype-driven' models because of the constraints on the population frequencies and the model susceptibilities. Consider the recessive model: g 1 > g 2; g 2 = g 3… = g 10. Under this model, the difference that defines the sign, is always non-negative, therefore, the signs of d h and d c are in the same direction. This difference is similarly non-negative for other haplotype-driven models. Thus, the composite difference can be used as a basis for testing haplotypic associations. More generally, the composite difference provides a direct test of association between sets of alleles across genetic loci and the phenotype, without assuming HWE. Multilocus, multiallelic composite extension is obtained very simply. There are as many composite frequencies as there are haplotypes, and the notation for the composite classes is the same as that for the haplotypes, e.g. ' A 2 B 1 C 1 D 1 ' may refer to either a haplotypic or a composite set of alleles (A 2, B 1, C 1, D 1) at four loci. Denote a particular set of alleles such as this by S k. The composite sample frequency of this four loci allele set iswhere H (G i) is the number of single-locus heterozygotes in the multilocus genotype G i of the i th individual, i = 1,…, n, and I (·) is the indicator function that is equal to 1 if the i th individual has alleles (S k), and 0 otherwise.

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^b7edfee7]. Kidney International (2024). High credibility.

Selection of GFR estimating equations — We recommend using a validated GFR estimating equation to derive GFR from serum filtration markers (eGFR) rather than relying on the serum filtration markers alone (1D). Use the same equation within geographical regions (as defined locally [e.g., continent, country, and region] and as large as possible); within such regions, equations may differ for adults and children. This recommendation recognizes that there are now a number of validated GFR estimating equations available and places a high value on the use of an estimating equation for GFR that has been validated in the population of interest and which has been shown to be most accurate in comparison with mGFR. There is potential for harm if people get different eGFR values when receiving care in different settings, and using the same equation within the same geographical region can eliminate the source of variation that is related to the specific parameters of the GFR estimating equation. There is benefit to clinical care, research, and public health with the use of validated equations such that decisions, research findings, and public policy are informed by accurate estimates of CKD. Certainty of evidence: This recommendation is based on Work Group consensus regarding good clinical practice to use a GFR estimating equation validated in the population of interest.

---

### KDIGO 2025 clinical practice guideline for the evaluation, management, and treatment of autosomal dominant polycystic kidney disease (ADPKD) [^94201e43]. Kidney International (2025). High credibility.

ADPKD predicted GFR by class and age (polynomial model) shows that for Class A, predicted glomerular filtration rate (GFR) values with 95% confidence intervals are 109 (95–123) at age 20–30 years, 110 (99–121) at 30–40, 97 (83–110) at 40–50, and 69 (49–90) at 50–60, with corresponding slopes 0.77, –0.63, –2.03, and –3.42; units are ml/min per 1.73 m2 for GFR and ml/min per 1.73 m2 per year for slopes, and positive values mean GFR increase.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^dee6cacc]. CDC (2011). Medium credibility.

Community viral load sample size calculations — sample size to detect differences in geometric mean (GM) viral load depends on power and standard deviation (S). The table specifies "α = 0.05 and W = 0.8", with S columns 1 to 1.5; for k = 3 the minimum sample sizes by S are 54, 66, 78, 92, 106, and 122, and "1.2 is the standard deviation of national VL data", so at S = 1.2 the needed sample size is 78.

---

### 2013 ACC / AHA guideline on the assessment of cardiovascular risk: a report of the American college of cardiology / American Heart Association task force on practice guidelines [^38029cee]. Journal of the American College of Cardiology (2014). Medium credibility.

ACC/AHA cardiovascular risk assessment — Table 8 describes estimating an individual's 10-year risk of incident hard atherosclerotic cardiovascular disease (ASCVD) using race-sex group–specific coefficients and a worked example. The example profile assumes an individual 55 years of age (for which the Ln[Age] = 4.01), with a total cholesterol of 213 mg/dL, HDL-C (high-density lipoprotein cholesterol) of 50 mg/dL, and an untreated systolic BP (blood pressure) of 120 mm Hg who is not a current smoker and does not have diabetes. The calculation is performed in steps: the natural log (Ln) of age, total cholesterol, HDL-C, and systolic BP is calculated; appropriate interaction terms are derived (for example, Ln[Age]×Ln[Total Cholesterol]); the resulting values are multiplied by coefficients from the equation for the specific race-sex group to yield "Coefficient × Value" terms that are summed as an "Individual Sum". The estimated risk is formally calculated as "1 minus the survival rate at 10 years ("Baseline Survival" in Table A), raised to the power of the exponent of the "Coefficient × Value" sum minus the race- and sex-specific overall mean "Coefficient × Value" sum", and the white men example equates to a 5.3% probability of a first hard ASCVD event within 10 years.

---

### Mathematical modeling is more than fitting equations [^994275ea]. The American Psychologist (2014). Low credibility.

Comments on the comments made by Brown et al. (see record 2013-24609-001). The article by Brown et al. regarding the Fredrickson and Losada (see record 2005-11834-001) article discussed the use of differential equations in science and repeated our earlier observation (Luoma, Hämäläinen, & Saarinen, 2008) that there is lack of justification for the use of the Lorenz equations in the latter article. In this comment we want to point out that Brown et al. presented a very narrow view on mathematical modeling in behavioral research. We describe how the conceptual use of mathematical models is essential in many fields.

---

### National Lipid Association recommendations for patient-centered management of dyslipidemia: part 1 – full report [^bf28a1a1]. Journal of Clinical Lipidology (2015). Medium credibility.

Atherogenic cholesterol and lipoprotein metrics — The NLA Expert Panel concluded that "An elevated level of cholesterol carried by circulating apolipoprotein (apo) B–containing lipoproteins (non–HDL-C and LDL-C, termed atherogenic cholesterol) is a root cause of atherosclerosis, the key underlying process contributing to most clinical ASCVD events", and identified HDL, LDL, intermediate-density lipoprotein (IDL), very low-density lipoprotein (VLDL), and chylomicrons as "the 5 major classes of lipoproteins". LDL is described as the predominant cholesterol carrier, "comprising ∼75% of cholesterol carried by non-HDL particles, with the remaining ∼25% of non–HDL-C in triglyceride-rich particles". Clinical laboratories "typically report the LDL-C concentration as a calculated value using the Friedewald equation (LDL-C = total cholesterol [total-C] – HDL-C – triglycerides/5 with all values in mg/dL) as long as the triglyceride level is below ∼400 mg/dL", and "This calculated value includes cholesterol carried by true LDL particles, as well as IDL particles"; "LDL-C estimated by the Friedwald equation also includes cholesterol carried by these lipoprotein (a) [Lp (a)] particles". Non–HDL-C is "calculated as total-C – HDL-C" and "represents the sum of cholesterol carried by all potentially atherogenic, apo B–containing lipoprotein particles", and the document states that "non–HDL-C is more strongly related to risk for ASCVD than LDL-C".

---

### Evolution of dominance mechanisms at a butterfly mimicry supergene [^0628b03c]. Nature Communications (2014). Medium credibility.

Quantification of dominance

For a given quantitative trait T, the dominance (h) of allele a relative to allele b was computed using this equation:where T ab, T aa and T bb represent the average trait values for heterozygotes ab, and homozygotes aa and bb, respectively. Strict dominance of a with respect to b corresponds to h = 1 and intermediate values (h ~0.5) represent co-dominance. The trait T used here to quantify colour pattern variation was derived from the relative proportion of wing area shared between the heterozygote and either homozygote. For a given homozygous genotype, a modal wing pattern was built, calculated by setting each pixel to its modal colour value, that is, shared by the most specimens with this genotype. For each pair of alleles, the trait T was then calculated as the number of pixels in the heterozygotes that were similar to one homozygote modal pattern and different from the other, normalized by the wing surface (in pixels). This calculation could be performed on 93.1% of the wing on average, because a small proportion of the wings of heterozygotes matched neither homozygote modal wing colours. All dominance coefficients measured were normalized so that allele a (equation above) corresponded to the more dominant allele, constraining h values to range between 0.5 and 1. An alternative estimate of the colour pattern trait was computed based on a linear discriminant analysis, and it gave values that were highly correlated with the surface-based estimate used here (Supplementary Figs 7 and 8).

---

### Approximations to the expectations and variances of ratios of tree properties under the coalescent [^cf6c6a02]. G3 (2022). Medium credibility.

We have found that approximations for fixed n and in the limit asare quite accurate in predicting the expected values seen in coalescent simulations of the ratios (Fig. 2). For the variances, the approximations are generally less accurate, although in most cases, graphs of the approximations and simulated values have similar shape (Fig. 4). These approximations are obtained from a Taylor approximation for the variance of a ratio (equation 4), and higher-order approximations of this variance could potentially be applied by use of Taylor's theorem; as the order of the approximation increases, however, the complexity of the resulting formula also increases. For those variances for which the approximation and simulation are not close in Fig. 4, we advise caution in using the variances in settings in which a precise approximation is needed.

---

### APT drug R&D: the right active ingredient in the right presentation for the right therapeutic use [^135e6a1c]. Nature Reviews: Drug Discovery (2009). Medium credibility.

Drug repurposing, in which an established active pharmaceutical ingredient is applied in a new way - for example, for a new indication, and often combined with an alternative method of presentation, such as a novel delivery route - is an evolving strategy for pharmaceutical R&D. This article discusses examples of the success of this strategy, and presents an analysis of sales of US pharmaceutical products that suggests that this low-risk approach to new product development retains substantial commercial value.

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^ddfd2f17]. Kidney International (2024). High credibility.

Chronic kidney disease — standardized estimated glomerular filtration rate (eGFR) reporting outlines laboratory practices for equation selection, documentation, units, and demographic inputs. The guideline states, "Laboratories should only use GFR estimating equations that have been sufficiently validated… and that are appropriate for the creatinine and cystatin C assays in use", ensure end-to-end reporting is "subject to regular EQA", and that reports "should indicate the filtration marker" with documentation of "which equation was used". For consistency, "a standardized approach in relation to reporting units of GFR, creatinine, and cystatin C should be implemented", and "Input age may be rounded to whole numbers or as a fractional year because the influence on eGFR is small". Regarding body size, "mGFR is commonly adjusted for body surface area (BSA), with a population average BSA value of 1.73 m2 being used", and "eGFR values derived using most equations are already adjusted for BSA". In electronic medical records (EMRs), "eGFR is mostly computed using the information recorded in the sex variable", and when sex/gender data are missing or nonbinary, "eGFR values cannot be computed and will be displayed as a missing value"; in such cases, "Laboratories should add a comment" directing users to online calculators and "The comment may also include a suggestion to use cystatin C… where there is an option for computing eGFR without the use of sex".

---

### How dieting might make some fatter: modeling weight cycling toward obesity from a perspective of body composition autoregulation [^490093c3]. International Journal of Obesity (2020). Medium credibility.

As shown in Fig. 4, the parameter γ is well associated with the initial fat percentage % FAT 0. Indeed, the data points clearly show that (γ − 1) decreases with % FAT 0. In subjects going through a weight cycle under "ordinary" conditions, we expect the FAT overshoot to be positive for all values of % FAT 0. Recalling equation 6, we thus expect that γ is greater than 1, or equivalently that (γ − 1) is greater than 0 for all values of % FAT 0. These considerations motivate us to model (γ − 1) as an exponential function of % FAT 0 :where the constants a and b are determined by fitting this model to the data.

Fig. 4
The values for (γ − 1) are plotted vs. the initial fat percentage % FAT 0.

---

### Primer on binary logistic regression [^8c5f1975]. Family Medicine and Community Health (2021). Medium credibility.

Family medicine has traditionally prioritised patient care over research. However, recent recommendations to strengthen family medicine include calls to focus more on research including improving research methods used in the field. Binary logistic regression is one method frequently used in family medicine research to classify, explain or predict the values of some characteristic, behaviour or outcome. The binary logistic regression model relies on assumptions including independent observations, no perfect multicollinearity and linearity. The model produces ORs, which suggest increased, decreased or no change in odds of being in one category of the outcome with an increase in the value of the predictor. Model significance quantifies whether the model is better than the baseline value (ie, the percentage of people with the outcome) at explaining or predicting whether the observed cases in the data set have the outcome. One model fit measure is the count- [Formula: see text], which is the percentage of observations where the model correctly predicted the outcome variable value. Related to the count- [Formula: see text] are model sensitivity-the percentage of those with the outcome who were correctly predicted to have the outcome-and specificity-the percentage of those without the outcome who were correctly predicted to not have the outcome. Complete model reporting for binary logistic regression includes descriptive statistics, a statement on whether assumptions were checked and met, ORs and CIs for each predictor, overall model significance and overall model fit.

---

### Incorporating economic evidence in clinical guidelines: a framework from the clinical guidelines committee of the American College of Physicians [^e53f1cf5]. Annals of Internal Medicine (2025). High credibility.

GRADE Evidence-to-Decision summary of judgments — A sample blank framework outlines judgment scale options, including "No clinically meaningful", "Small", "Medium", "Large", "Varies", "Uncertain", and "No included studies". Type of recommendation categories listed are "Strong recommendation against the intervention", "Conditional recommendation against the intervention", "Conditional recommendation for either the intervention or the comparator", "Conditional recommendation for the intervention", and "Strong recommendation for the intervention". The figure clarifies "GRADE = Grading of Recommendations Assessment, Development and Evaluation" and notes it was "Prepared with GRADEpro (https://gradepro.org) and modified by the authors".

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^705122bc]. Kidney International (2024). High credibility.

KDIGO 2024 CKD risk prediction models — evidence certainty, use, and cautions: To assess certainty, the ERT examined 2 existing systematic reviews, and a 2021 NICE review concluded there was high-quality evidence that chosen risk prediction equations accurately predict kidney failure; the Work Group agreed with this assessment. The Work Group judged that the published externally validated models all had sufficient accuracy to be used in clinical settings, and patients and healthcare providers should be encouraged to use these tools. Potential harms could result from inappropriate use in AKI or AKD or in younger individuals with CKD G1–G2 who may be at high risk of progression but low risk of kidney failure in the next 5 years; in these people, more proximal outcomes such as 40% decline in eGFR or lifetime risk were judged to be more appropriate. Given their value, healthcare providers should consider how to integrate risk prediction models into clinical practice, either in EMRs, laboratory information systems, or other mechanisms.

---

### A multi-step model of Parkinson's disease pathogenesis [^e2cef97a]. Movement Disorders (2021). Medium credibility.

Box 1
Armitage and Doll Multistep Model – Heuristic Argument*

If disease development depends on one step, incidence in a given year will be proportional to the chance of undergoing that step:If two‐steps are required, then incidence is the product of the chance of undergoing the first step by age t and the rate of undergoing the second step:And for n‐steps:Taking log of both sides returns the equation for a straight line:The slope is one less than the number of steps required to develop the disease, and the intercept represents the combined probability of undergoing these steps.

*see Webster 2019 for full derivation.

A multistep model of pathogenesis could account for many of the epidemiological observations made in PD. These include the variability in the expression of disease and age of onset in carriers of disease‐causing mutations, and the multiple environmental and genetic associations that confer a risk of developing PD. A multistep model could also explain the phenotypic variability seen in PD, if it is assumed that at least some steps apply to specific neuronal populations rather than the nervous system as a whole. Furthermore, the predictions arising from such a model can be used to test specific hypotheses about basic observations in PD, such as whether the higher incidence and prevalence of PD in males observed in most parts of the world relates to differential environmental exposures by sex.

---

### Developing risk prediction models for type 2 diabetes: a systematic review of methodology and reporting [^fa562e41]. BMC Medicine (2011). Low credibility.

Appendix 1: Search strings

PubMed search string

'diabetes'[ti] AND ('risk prediction model'[tiab] OR 'predictive model'[tiab] OR 'predictive equation'[tiab] OR 'prediction model'[tiab] OR 'risk calculator'[tiab] OR 'prediction rule'[tiab] OR 'risk model'[tiab] OR 'statistical model'[tiab] OR 'cox model'[tiab] OR 'multivariable'[tiab]) NOT (review[Publication Type] OR Bibliography[Publication Type] OR Editorial[Publication Type] OR Letter[Publication Type] OR Meta-analysis[Publication Type] OR News[Publication Type]).

EMBASE search string

risk prediction model.ab. or risk prediction model.ti. or predictive model.ab. or predictive model.ti. or predictive equation.ab. or predictive equation.ti. or prediction model.ab. or prediction model.ti. or risk calculator.ab. or risk calculator.ti. or prediction rule.ab. or prediction rule.ti. or risk model.ab. or risk model.ti. or statistical model.ab. or statistical model.ti. or cox model.ab. or cox model.ti. or multivariable.ab. or multivariable.ti. and diabetes.ti not letter.pt not review.pt not editorial.pt not conference.pt not book.pt.

---

### Prediction of creatinine clearance from serum creatinine [^4f4cf260]. Nephron (1976). Low credibility.

The clinical calculator "Creatinine Clearance (Cockcroft-Gault Equation)" for diabetic nephropathy, chronic kidney disease, immunoglobulin A nephropathy, membranous nephropathy, focal segmental glomerulosclerosis, anemia of chronic kidney disease, anti-glomerular basement membrane disease, hepatorenal syndrome, immunoglobulin light chain amyloidosis, infection-related glomerulonephritis, kidney transplantation and membranoproliferative glomerulonephritis.

The Cockcroft-Gault equation calculates creatinine clearance to estimate kidney function and guide medication dosing. It considers age, weight, gender, and serum creatinine, incorporating adjustments for body weight when necessary. This widely-used formula helps healthcare providers assess renal function and adjust medication doses accordingly.

The Creatinine Clearance (Cockcroft-Gault Equation) calculator estimates kidney function through the creatinine clearance rate, reflecting how effectively the kidneys filter waste. This tool requires input on age, gender, weight, height, and serum creatinine level.

Key parameters:

- **Age (years)**: 18 to 120
- **Gender**: Male or Female
- **Weight**: in kilograms (20–200 kg) or pounds (44–440 lbs)
- **Height**: in centimeters (120–220 cm) or inches (48–87 in)
- **Creatinine**: in mg/dL (0.1–20) or µmol/L (8.84–1768.4)

The process involves:

1. **Unit Conversion**:
- Convert weight from pounds to kilograms, if necessary, using 1 kg = 2.20462 lbs.
- Convert height from centimeters to inches, if necessary, using 1 inch = 2.54 cm.
- Convert creatinine from µmol/L to mg/dL, if necessary, using 1 mg/dL = 88.4 µmol/L.

2. **Ideal Body Weight (IBW) Calculation**:
- **For males**: IBW = 50 + 2.3 * (height in inches - 60)
- **For females**: IBW = 45.5 + 2.3 * (height in inches - 60)

3. **Adjusted Body Weight (ABW) Calculation**:
- ABW = IBW + 0.4 * (actual weight - IBW)

4. **Creatinine Clearance Calculation**:
- **Original CrCl (using actual weight)**: ((140 - age) * weight) / (72 * creatinine)
- **IBW CrCl (using ideal weight)**: ((140 - age) * IBW) / (72 * creatinine)
- **ABW CrCl (using adjusted weight)**: ((140 - age) * ABW) / (72 * creatinine)

5. **Gender Adjustment**:
- For females, each calculated CrCl value needs multiplying by 0.85.

Final outputs include:

- Original CrCl, reflecting estimation with actual weight.
- IBW CrCl, using ideal weight.
- ABW CrCl, calculated with adjusted weight.
- Weight used for the computation, displayed in kilograms.

These outputs, rendered in mL/min and rounded to one decimal place, facilitate the assessment of kidney function and inform clinical decisions regarding medication dosing. Better kidney filtration capabilities correspond to higher clearance scores, guiding clinicians in interpreting renal health.

---

### Cryo-EM structure of the bacteriophage T4 portal protein assembly at near-atomic resolution [^774d8747]. Nature Communications (2015). Medium credibility.

Determining the most likely phylogenetic tree

The portal protein structures were compared pairwise using the HOMOLOGY program. The results were used to produce manually a table giving the sequence alignment of all four known portal structures (Supplementary Fig. 4). The number of residues that could be equivalenced between any two structures was used to evaluate all possible rooted trees that might represent the evolution of portal proteins. The different rooted trees that could represent the divergence of the portal proteins for the tailed phages A, B, C or D are shown in Fig. 7 and Supplementary Table 7. The evolutionary distance between any pair of these structures can be represented by AB, AC, AD, BC, BD and CD. Two different schemes (P − r) and (100 P / r) were explored for defining evolutionary distance, where r is the number of residues that could be spatially equivalenced between any two structures and P is a constant representing the number of residues in the primordial protein. The lengths of the tree branches were represented by the six variables a, b, c, d, e and f. Six linear observational equations can be written for any one tree representing the distance between any pair of structures. For instance, the six observational equations for tree 2 (Fig. 7 and Supplementary Table 7) would be

The rate of evolutionary change is likely to be similar for each viral portal protein since its divergence from a common primordial structure. Thus, the distance (g) from the tree's root (R) to any one of the current structures (A, B, C or D) should be the same. Hence, four additional observational equations can be written expressing this constraint, resulting in a total of 10 observational equations to determine seven parameters. The additional equations for tree 2 are:

From these 10 observational equations, seven normal equations were calculated and solved for a, b, c, d, e, f and g. The resultant values can be substituted into the 10 observational equations to calculate values for AB, AC and so on in equations (1) and (2). An 'R' factor was then calculated between the observed and calculated distances (Dist) (AB, AC, AD, BC, BD and CD) according to

---

### National Lipid Association recommendations for patient-centered management of dyslipidemia: part 2 [^3f54197f]. Journal of Clinical Lipidology (2015). Medium credibility.

Other major guideline documents — older patients: The 2013 ACC/AHA Guideline includes different treatment regimens for individuals > 75 years of age compared to younger persons, recommending moderate intensity statin therapy for secondary prevention in those > 75 years versus high intensity in younger individuals, using the Pooled Cohort Risk Equations and provider–patient discussion for primary prevention without a specific intensity recommendation for those > 75 years. The International Atherosclerosis Society recommends for persons > 65 years the use of short-term (10-year) Framingham risk scoring (recalibrated for country) to estimate CHD risk and elevation of the estimated value by 1/3 to estimate total ASCVD risk, suggesting statins for moderately-high or high estimated risk while considering polypharmacy, drug–drug interactions, and cost. The European Atherosclerosis Society/European Society of Cardiology advocate secondary prevention in the same manner as in younger patients (class I, level of evidence B), starting at low dosage and titrating to the same targets (class I, level of evidence C), and recommend primary prevention for those with 1 or more additional risk factors aside from age (class IIb, level of evidence B). The Canadian Cardiovascular Society recommends statins without specific upper age cutoffs for secondary prevention and, for primary prevention, 10-year Framingham scoring for men ages 40–75 years and for women ages 50–75 years.

---

### General statistical model shows that macroevolutionary patterns and processes are consistent with darwinian gradualism [^8492f49b]. Nature Communications (2022). High credibility.

Methods

Model

Write the value of some trait Y after an amount of time dt as the outcome of multiplicative diffusion from its starting position at time t and a change term incorporating possible directional and evolvability effects:where β is a directional change (per unit time), random changes ε are time-independent and homogeneous such that, and υ transforms the variance of ε to υσ 2. These parameters correspond to the directional and evolvability changes as described in Fig. 1. By definition, directional changes occur along phylogenetic branches, introducing a mean offset to all 'downstream' species, but with no change to the Brownian variance. Evolvability effects occur at phylogenetic nodes, altering the Brownian variance σ 2 of the descendant clade.

The model of Eq. (1) captures the commonly observed dependency in morphological data between a trait's value, Y, and its variance. Writing the model in logarithmic form yieldsand Eq. (2) defines a linear model with constant and normally distributed errors ε, independent of the value of Y. For traits with variance independent of Y on the natural (un-transformed) scale, the model of Eq. (2) is still applicable, but Y is not logarithmically transformed.

Positive values of β denote increases in the value of the trait, negative values denote reductions. When the trait's change along a branch is compatible with that which is likely under neutral drift, β = 0, its default value. The default value of υ is 1; values of υ > 1 signal an increase in the potential for evolutionary exploration, those < 1 indicate reduced exploration of the trait-space. The existence and magnitude of directional and evolvability parameters that differ from their default values will vary throughout the tree according to the macroevolutionary signals retained in the species.

The model of Eq. (2), when applied to the branches leading from the root of the phylogenetic tree to the tips, yields a description of each species as the sum of the common ancestral state at the root, α, any directional changes that have occurred along the branches leading to that species, and a normally distributed error. Writing the i th species' value as Y i, and treating Y i as having been logarithmically transformed where necessary, thenwhere the β ij are directional changes occurring in the branches of length t j (replacing the dt of Eq. (2)) leading to species i, and the error term has variance.

---

### A computational theory of the subjective experience of flow [^8fc4ed10]. Nature Communications (2022). High credibility.

Flow is a subjective state characterized by immersion and engagement in one's current activity. The benefits of flow for productivity and health are well-documented, but a rigorous description of the flow-generating process remains elusive. Here we develop and empirically test a theory of flow's computational substrates: the informational theory of flow. Our theory draws on the concept of mutual information, a fundamental quantity in information theory that quantifies the strength of association between two variables. We propose that the mutual information between desired end states and means of attaining them - [Formula: see text] - gives rise to flow. We support our theory across five experiments (four preregistered) by showing, across multiple activities, that increasing [Formula: see text] increases flow and has important downstream benefits, including enhanced attention and enjoyment. We rule out alternative constructs including alternative metrics of associative strength, psychological constructs previously shown to predict flow, and various forms of instrumental value.

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^ff5a6a30]. Kidney International (2024). High credibility.

KDIGO 2024 CKD — Practice points for GFR assessment and interpretation include the following. Practice Point 1.2.2.1: Use serum creatinine (SCr) and an estimating equation for initial assessment of GFR (Figure 11). Practice Point 1.2.2.2: Where more accurate ascertainment of GFR will impact treatment decisions, measure GFR using plasma or urinary clearance of an exogenous filtration marker (Table 9). Practice Point 1.2.2.3: Understand the value and limitations in both eGFR and measured glomerular filtration rate (mGFR) as well as the variability and factors that influence SCr and cystatin C measurements. Practice Point 1.2.2.4: Interpretation of SCr level requires consideration of dietary intake.

---

### Correction [^26cbbc41]. Journal of Radiology Case Reports (2017). Low credibility.

[This corrects the article on p. 8 in vol. 10.].

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^bb3ac457]. Kidney International (2024). High credibility.

KDIGO 2024 CKD — selection of GFR estimating equations: Recommendation 1.2.4.1 states, "We recommend using a validated GFR estimating equation to derive GFR from serum filtration markers (eGFR) rather than relying on the serum filtration markers alone (1D)". Practice points specify to "Use the same equation within geographical regions (as defined locally [e.g., continent, country, region] and as large as possible). Within such regions, equations may differ for adults and children", to "Use of race in the computation of eGFR should be avoided", and to "Estimate GFR in children using validated equations that have been developed or validated in comparable populations".

---

### KDIGO 2022 clinical practice guideline for diabetes management in chronic kidney disease [^bfaebbd4]. Kidney International (2022). High credibility.

Figure 5 — assessment of kidney function in glomerular disease — uses ml/min per 1.73 m^2 units and notes that the correction coefficient for race in GFR estimating equations is controversial and discussions are ongoing, referring readers to the KDIGO CKD guideline for more information.

---

### CORRECTION [^a0bf88a0]. Annals of Family Medicine (2017). Low credibility.

[This corrects the article on p. 14 in vol. 15.].

---

### VA / DoD clinical practice guideline for the primary care management of chronic kidney disease [^b486c3f3]. DoD/VA (2025). High credibility.

Chronic kidney disease (CKD) risk prediction recommendation — the Work Group specified the risk prediction models that have been validated, delineated their clinical utility, and clarified the populations studied; the recommendation is categorized as Reviewed, Amended, the confidence in the quality of evidence was Low, the benefit of conducting a risk prediction equation slightly outweighed potential harms such as anxiety or uncertainty about kidney disease progression, patient values and preferences aligned with interest in knowing CKD progression risk, and the Work Group decided upon a Weak for recommendation.

---

### Correction to2021; 3: e744-47 [^f0d86561]. The Lancet: Rheumatology (2022). High credibility.

[This corrects the article DOI: 10.1016/S2665-9913(21)00248–4.].

---

### A continuous-time maxSAT solver with high analog performance [^87d3d16d]. Nature Communications (2018). Medium credibility.

Algorithm description

Here, we give a simple, nonoptimized variant of the algorithm (see flowchart in Supplementary Fig. 2). Better implementations can be devised, for example with better fitting routines, however the description below is easier to follow and works well. Given a SAT problem, we first determine the b parameter as described previously. Step 1: initially we set, Γ min, = and t max. Unless specified otherwise, in our simulations we used Γ min = 100, Γ max = 2 × 10 6, t max = 50. Step 2: to initialize our statistics, we run Γ min trajectories up to t max, each from a random initial condition. For every such trajectory ω we update the p (E, t) distributions as function of the energies of the orthants visited by ω. We record the lowest energy value found. Step 3: starting from Γ = Γ min + 1 and up to Γ max, we continue running trajectories in the same way and for each one of them check: (a) If, set, update p (E, t) and go to Step 4. (b) If Γ just reached, go to Step 4. (c) If Γ = Γ max, output "Maximum number of steps reached, increase Γ max ", output the lowest energy value found, the predictedand the quality of fit for, then halt. Step 4: using the p (E, t) distributions, estimate the escape rates κ (E) as described in the corresponding Methods section. Step 5: the κ (E) curve is extrapolated to the E − 1 value obtaining κ (E − 1) and then using this we predict(as described in another Methods section). Further extrapolating the κ (E) curve to κ = 0 we obtain(see the corresponding Methods section). Step 6: we check the consistency of the prediction defined here as saturation of the predicted values. We call it consistent, ifhas not changed during the last 5 predictions. If it is not consistent yet, we continue running new trajectories (Step 4). If the prediction is consistent, we check for the following halting conditions: (i) Ifthen we decide the global optimum has been found:and skip to Step 7. (ii) If the fitting is consistently predicting(usually it is very close,) we check the number of trajectories that has attained states with, i.e. = . If it is large enough (e.g. > 100), we decide to stop running new trajectories and setand go to Step 7. (iii) Ifthen we most probably have not found the global optimum yet and we go to Step 4. We added additional stopping conditions that can shorten the algorithm in case of easy problems, see Methods corresponding section, but these are not so relevant. Step 7: the algorithm ends and outputs, values, the Boolean variables corresponding to the optimal state found, along with the quality of fit.

---

### Using the animal model to accelerate response to selection in a self-pollinating crop [^f980e2c2]. G3 (2015). Low credibility.

Accuracy of predicted breeding values and response to selection

Average accuracy of prediction increased from the base, second to full model (Table 3). In the full model, predicted breeding values for ABS on 430 S 0 progeny in cycle 2 ranged from −3.5 to +1.7 and the accuracy of predicted breeding values from equation [2] ranged from 0.731 to 0.854 (average 0.805) (Table 4). The average accuracy of predicted breeding values of 160 S 1 parent plants, for which no records were available, was 0.878 (Table 4). High accuracy was also achieved on 575 S 2 self progeny of parent plants (average 0.851) (Table 4).

Table 4
Mean and range of BLUP of predicted breeding values and accuracy of predictions for ascochyta blight score a

The SD of additive effects (predicted ABS breeding values) for 430 S 0 progeny in cycle 2 was 1.01. With a selection proportion of 20% of S 0 lines (selection intensity of 1.40) and average accuracy of predicted breeding values 0.805, the response to selection based on equation [1] in the next cycle is forecast to be −1.1 leaves or −11.2% of average ABS in cycle 2 (10.2 leaves).

Predicted breeding values and their accuracy varied among S 0 progeny of one cross, 13P020E, evaluated in cycle 2 (Figure 2). The fourth S 0 progeny of cross 13P020E with predicted breeding value −1.6 was selected for crossing when the selection proportion was 25%. Further investigation revealed that the S 1 parent plants of 13P020E had the lowest predicted breeding values of all possible S 1 parent plants in this pair-wise combination. Parent plant 10P086 > S0A6-S1A2 had a predicted breeding value of −1.8 (Figure 2), but its sister parent plant 10P086 > S0A6-S1A1 was significantly more susceptible, with predicted breeding value of +0.3. As a result, no other S 0 progeny of crosses 13P020A, 13P020B, 13P020C, or 13P020D were within the 25% selection proportion.

---

### Correction to2021; 3: e71-82 [^90fffdf5]. The Lancet: Rheumatology (2021). High credibility.

[This corrects the article DOI: 10.1016/S2665-9913(20)30386–6.].

---

### Correction to2022; 3: e253-62 [^875bf057]. The Lancet: Healthy Longevity (2022). High credibility.

[This corrects the article DOI: 10.1016/S2666-7568(22)00038–1.].

---

### Correction to2021; 3: e789-97 [^23cfa633]. The Lancet: Rheumatology (2022). High credibility.

[This corrects the article DOI: 10.1016/S2665-9913(21)00251–4.].

---

### Summary benchmarks-full set – 2024 [^c9abe316]. AAO (2024). High credibility.

Preferred Practice Pattern (PPP) guidelines — GRADE evidence quality ratings are defined for forming recommendations for care as follows: "Good quality (GQ): Further research is very unlikely to change our confidence in the estimate of effect", "Moderate quality (MQ): Further research is likely to have an important impact on our confidence in the estimate of effect and may change the estimate", and "Insufficient quality (IQ): Further research is very likely to have an important impact on our confidence in the estimate of effect and is likely to change the estimate; any estimate of effect is very uncertain".

---

### A space-time tradeoff for implementing a function with master equation dynamics [^57fa10b0]. Nature Communications (2019). High credibility.

Master equations are commonly used to model the dynamics of physical systems, including systems that implement single-valued functions like a computer's update step. However, many such functions cannot be implemented by any master equation, even approximately, which raises the question of how they can occur in the real world. Here we show how any function over some "visible" states can be implemented with master equation dynamics-if the dynamics exploits additional, "hidden" states at intermediate times. We also show that any master equation implementing a function can be decomposed into a sequence of "hidden" timesteps, demarcated by changes in what state-to-state transitions have nonzero probability. In many real-world situations there is a cost both for more hidden states and for more hidden timesteps. Accordingly, we derive a "space-time" tradeoff between the number of hidden states and the number of hidden timesteps needed to implement any given function.

---

### Evidence of direct and indirect reciprocity in network-structured economic games [^ae74945a]. Communications Psychology (2024). Medium credibility.

Individuals exploit and punish those in bad standing

Following prediction P1(b), we find that participants are less likely to exploit individuals that they rate as generous (ρ l = -0.53, CI: -0.59, -0.46; ρ c = -0.74, CI: -0.80, -0.68; ρ h = -0.71, CI: -0.83, -0.58; ρ a = -0.81, CI: -0.87, -0.73) and are more likely to exploit individuals whom they rate as selfish (ρ l = 0.43, CI: 0.36, 0.51; ρ c = 0.27, CI: 0.20, 0.33; ρ h = 0.49, CI: 0.31, 0.67; ρ a = 0.24, CI: 0.14, 0.33). Likewise, following prediction P1(c), we find that participants are less likely to punish individuals whom they rate as generous (ρ l = -0.28, CI: -0.39, -0.16; ρ c = -0.51, CI: -0.64, -0.37; ρ h = -0.12, CI: -0.47, 0.27; ρ a = -0.34, CI: -0.49, -0.18) and are more likely to punish individuals whom they rate as selfish (ρ l = 0.73, CI: 0.64, 0.82; ρ c = 0.77, CI: 0.67, 0.85; ρ h = 0.16, CI: -0.25, 0.52; ρ a = 0.82, CI: 0.72, 0.90). Note, however, that although the direction of effects at the highland site are consistent with other sites, the credible intervals are much wider (and do not exclude zero) since punishment was rare there, and the sample size was smaller.

---

### A framework to predict the price of energy for the end-users with applications to monetary and energy policies [^5b5689a1]. Nature Communications (2021). High credibility.

Weight prediction results

The validity of our proposed methodology is tested over a period of 174 months from January 2006 to June 2020, by comparing the predicted value of the monthly weight of each product's demand with its actual, known value. For this comparison, the sum of the squared prediction error for each month is computed over the testing period (see "Methods") and the results in the form of an average sum of squared error, minimum sum of squared error, and maximum sum of squared error are summarized in Table 1. It should be noted that the number of months to be compared decreases as the year of prediction increases. For example, the predictions of the second year require the predicted weights of the first year, so there are less actual monthly values to compare.

Table 1
Weight prediction results up to 4 years from January 2006 to June 2020.

As shown in Table 1, the predictive ability of our proposed methodology is quite remarkable since the reported error values are extremely low. This is true even if we consider the square root of the average sum of the squared errors which is 1.8808%, 2.0874%, 2.2329%, and 2.3641% for the first, second, third, and fourth year, respectively. The very low predictive error (2.3641%) in the case of the fourth year, where only unknown (predicted) values have been used, is of significant importance. As expected, the average sum of the squared error increases, as the year of prediction increases due to the decreasing number of months with known values. The accuracy of the proposed methodology is also verified from the fact that even the maximum sum of squared error over the tested period is rather low, i.e. 0.006685 or 8.1764% when we consider the square root of the sum of the squared errors.

This excellent predictive ability along with the unique inherent characteristics of EPIC that captures both the demands and the prices of the products over the entire energy landscape in the United States justifies our opinion that EPIC is the ideal tool for designing, assessing, and optimizing various policy decisions of public interest. Two prime, representative policy case studies are presented in the next sections.

---

### Correction to2022; 3: e242-52 [^7db8011a]. The Lancet: Healthy Longevity (2022). High credibility.

[This corrects the article DOI: 10.1016/S2666-7568(22)00035–6.].

---

### KDOQI US commentary on the KDIGO 2024 clinical practice guideline for the evaluation and management of CKD [^2e68dce4]. American Journal of Kidney Diseases (2025). High credibility.

KDIGO 2024 CKD — guidance to physicians and other health care providers outlines actionable points: "Practice Point 1.2.2.1: Use serum creatinine (SCr) and an estimating equation for initial assessment of GFR". "Recommendation 1.2.2.1: We recommend use of eGFRcr-cys in clinical situations when eGFRcr is less accurate and GFR affects clinical decision-making (original guideline Table 8) (1C)". "Practice Point 1.2.2.2: Where more accurate ascertainment of GFR will impact treatment decisions, measure GFR using plasma or urinary clearance of an exogenous filtration marker". "Practice Point 1.2.2.3: Understand the value and limitations in both eGFR and measured glomerular filtration rate (mGFR) as well as the variability and factors that influence SCr and cystatin C measurements". "Practice Point 1.2.2.4: Interpretation of SCr levels requires consideration of dietary intake". "Practice Point 1.2.2.5: Assess the potential for error in eGFR when using SCr-based estimating equations and cystatin C–based estimated glomerular filtration rate (eGFRcys) in some specific circumstances". "Practice Point 1.2.2.7: Understand the implications of differences between eGFRcr and eGFRcys, as these may be informative, in both direction and magnitude of those differences". "Practice Point 1.2.2.8: Consider timed urine collections for measured creatinine clearance if mGFR is not available and eGFRcr-cys is thought to be inaccurate".

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^f5577b79]. Kidney International (2024). High credibility.

KDIGO 2024 — Selection of GFR estimating equations — We recommend using a validated GFR estimating equation to derive GFR from serum filtration markers (eGFR) rather than relying on the serum filtration markers alone (1D). Use the same equation within geographical regions (as defined locally [e.g., continent, country, region] and as large as possible). Within such regions, equations may differ for adults and children. Use of race in the computation of eGFR should be avoided, and estimate GFR in children using validated equations that have been developed or validated in comparable populations.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^b1513dd5]. CDC (2011). Medium credibility.

Table 1b — Minimum sample size for detecting geometric mean (GM) ratio k with α = 0.05 and W = 0.9 — presents required sample sizes by standard deviation (S) strata and defines parameters; α is significance level, W is power, GM is geometric mean, and S is standard deviation, noting that 1.2 is the standard deviation of national viral load (VL) data. Each jurisdiction will need to assess the standard deviation of their local VL data and then determine the appropriate sample size needed to assess VL, and if the sample size is inadequate to meet the recommended case inclusion criterion, an alternate method may need to be used, such as combining multiple years of data. For k = 3, sample sizes across S = 1, 1.1, 1.2, 1.3, 1.4, 1.5 are 75, 91, 108, 127, 147, 169, and Table 1b uses power = 90%; jurisdictions may also explore differences in means of viral loads, including categorical differences in the proportion with undetectable or very low VL.

---

### Magnetic field strength dependent SNR gain at the center of a spherical phantom and up to 11.7T [^8fa2a403]. Magnetic Resonance in Medicine (2022). Medium credibility.

TABLE 1
Exponent results of the SNR = aB 0 n fit for untransformed and log–log data

Figure 4 illustrates surface plots of uiSNR with respect to ε r and σ at 3 T, 7 T and 11.7 T, normalized to the value found in our phantom with ε r = 76 and σ = 1 S/m, and obtained from Equation 2. It illustrates the deviations of the uiSNR results with respect to changes in electrical properties. At low fields, one recovers approximately adependence of SNR. At high fields, SNR becomes more sensitive to changes of electrical properties and can particularly affect the results of the nonlinear fits. A Monte‐Carlo numerical test was performed with the uiSNR formula by disturbing the electrical property values randomly 10 000 times between 0% and 5% and independently for the different field strengths, repeating the uiSNR calculation of Equation 2 and the fits. The results are provided in the second row of Table 1 (min and max exponent values found over the repetitions), indicating again more robustness of the log–log fit. The surface plots of Figure 4 can convey how so few changes in the electrical properties can affect the B 0 exponent: An increase (decrease) and decrease (increase), respectively, of σ and ε r at low (high) fields, for instance, can pull the exponent up by increasing the gap between the SNR at low and high fields.

FIGURE 4
ultimate intrinsic SNR (uiSNR) versus electrical properties. The values are reported for the center of the sphere and are normalized with respect to the values found with the phantom properties (ε r = 76 and σ = 1 S/m) at 3 T (A), 7 T (B) and 11.7 T (C)

---

### Real-time forecast of multiphase outbreak [^55ae2ab1]. Emerging Infectious Diseases (2006). Low credibility.

Methods

The Richards model is logistic and is described by a single differential equation. The equation is given below, where I(t) is the cumulative number of infected cases at time t in days:The solution is:

The model parameters are as follows: K is the carrying capacity or total case number, r is the per capita growth rate of the infected population, and a is the exponent of deviation from the standard logistic curve. Because the Richards model typically exhibits a single S-shaped curve, it is not suitable for the SARS epidemic in Canada illustrated in Figure 1.

Figure 1
Cumulative severe acute respiratory syndrome cases by onset of symptoms for 250 cases in Canada, February 23– June 12, 2003 (1 case had unknown onset). All except 1 of the 250 cases were in Toronto area.

---

### KDIGO 2021 clinical practice guideline for the management of glomerular diseases [^a2767dfa]. Kidney International (2021). High credibility.

KDIGO methods — GRADE system for grading quality of evidence outlines a stepwise process with "Step 1: Starting grade for quality of evidence based on study design", "Step 2: reduce grade", and "Step 3: raise grade", followed by "Final grade for quality of evidence and definition" that provides the standard GRADE definitions: "High — Further research is unlikely to change confidence in the estimate of the effect", "Moderate — Further research is likely to have an important impact on confidence in the estimate, and may change the estimate", "Low — Further research is very likely to have an important impact on confidence in the estimate, and may change the estimate", and "Very Low — Any estimate of effect is very uncertain".

---

### Goldmann's equation and clinical measures of aqueous dynamics [^7600d7db]. Experimental Eye Research (2004). Low credibility.

Goldmann's equation has served for over 50 years as an adequate description of aqueous humor dynamics for clinical applications. Recent advances in therapeutics for glaucoma have made it necessary to revise the equation and to reinterpret the meanings of its parameters.

---

### An empirical ratio in search of a theory [^211a72ea]. The American Psychologist (2014). Low credibility.

Comments on the article by Frederickson and Losada (see record 2005-11834-001). In this comment, we show how to account for the phenomenon of the 3:1 ratio using a mathematical model of reflexive awareness (Lefebvre, 1977, 1992; Schwartz, 1997) that captures the property of the mind to model self and other at increasing levels of awareness. The model has successfully predicted the frequency of positive choices in people's evaluations of self and others (Grice, McDaniel & Thompsen, 2005) and distinguished pathological, normal, and optimal states in children (Ronan & Kendall, 1997) and adults (Schwartz et al., 2002). We apply this model to represent an individual who can be happy or unhappy and is capable of making a choice between the positive and negative poles.

---

### Correction to2022; 4: e163-66 [^d47711b2]. The Lancet: Rheumatology (2023). High credibility.

[This corrects the article DOI: 10.1016/S2665-9913(21)00393–3.].

---

### International consensus recommendations for the use of prolonged-infusion β-lactam antibiotics: endorsed by the American college of clinical pharmacy, British Society for Antimicrobial Chemotherapy, Cystic Fibrosis Foundation, European society of clinical microbiology and infectious diseases, Infectious Diseases Society of America, Society of Critical Care Medicine, and Society of Infectious Diseases Pharmacists [^ff931c1c]. Pharmacotherapy (2023). High credibility.

International consensus recommendations for the use of prolonged-infusion beta-lactam antibiotics — database search strategy details are enumerated, including Cochrane (Wiley) – October 18, 2020 queries and line-based term counts. The Cochrane queries include "#1 (beta lactam* or b-lactam*):ti, ab, kw 1313" and "#3 (carbapen* or carba-pen*):ti, ab, kw 537". Population and renal filters are reflected by lines such as "83 exp pediatrics/ or exp adolescent/ or exp child/ or exp infant/ 3458214", animal-study exclusions "86 85 not (63 or 64) [Exclude Animal Studies] 4867471" and "101 100 not (63 or 64) [Exclude Animal Studies] 682583", and kidney and dialysis terms "97 (ckd or esrd):ti, kw 77491", "98 (IHD or SLED or CRRT):tw, kw 13653", and "99 exp renal replacement therapy/ 190897".

---

### A two-drug combination simulation study for metastatic castrate resistant prostate cancer [^6ecb88d2]. The Prostate (2018). Low credibility.

2 METHOD

To compute a probability of eradication, P erad, the model determines four independent events:where P 1b is the probability that no 1‐step resistant lineage arises before treatment, P 1t is the probability that no 1‐step lineages arise during treatment, P 2b is the probability that no 2‐step lineages arise before treatment, and P 2t is the probability that no 2‐step lineages arise during treatment. Each is determined as follows:where M is the number of cells in the tumor, u is the mutation rate, s = 1−d/b, where b and d are birth and death rates, s ′ is the survival rate of sensitive cells, n 1 and n 2 are the number of mutations conferring resistance to drugs 1 and 2, and n 12 is the number of mutations conferring cross‐resistance to both drugs. Parameter values were determined from literature curation and estimation as described in the section 2. Derivation of model equations is given in the supplementary information to the original publication.

2.1 Parameterization of equations

To parameterize model Equations (1) ‐4 we used publicly available patient data that was carefully compiled by the cancer research community across multiple research studies, see Table 1. Tumor sizes of mCRPC derive from radiography. 11 The number of tumor cells per cubic cm was obtained from Lutz et al. 12 Growth rates were obtained from median values reported by Wilkerson et al. from a meta‐analysis using the median growth rate of resistant tumors (see Figure 3a and sensitive Figure 3b). 13 There are approximately 50 known mechanisms of resistance to androgen deprivation therapy and approximately 50 mechanisms for other targeted inhibitors. 10 Point mutation rates were assumed to follow the typical value for human cancers of 1 × 10 −9 per base pair per division. 14 Conversion between tumor population and tumor volume assumes spherical tumor with a density of 2 × 10 8 cells/cm 3. 12

Table 1
Baseline model parameters, values, and sources

---

### Correction to2021; 2: e436-43 [^a80662b6]. The Lancet: Healthy Longevity (2021). High credibility.

[This corrects the article DOI: 10.1016/S2666-7568(21)00115-X.].

---

### Clinical practice guidelines for hemodialysis adequacy, update 2006 [^4165d96c]. American Journal of Kidney Diseases (2006). Medium credibility.

Appendix — methods for adding residual clearance to hemodialyzer clearance notes that dialyzer clearances (spKt/V) required to achieve a stdKt/V of 2.0 volumes per week are tabulated across treatment times from 2 to 8 hours and schedules from 2 to 7 treatments per week, with values determined using a formal 2-compartment mathematical model of urea kinetics and similar results obtainable using a simplified equation; the approach gives results similar to the third data column of Table 18.

---

### Genome-enabled estimates of additive and nonadditive genetic variances and prediction of apple phenotypes across environments [^dad7fc90]. G3 (2015). Low credibility.

The genomic relationship matrices (G a, G d, and G aa) were constructed using SNP marker information according to methods from previous studies (Vanraden 2008;). Briefly, G a = , where M is an n × m matrix (n = number of individual, m = number of SNP loci) representing genotypes at each locus. The coefficient of i th column of the M matrix are (0–2 p i), (1–2 p i) and (2–2 p i) for genotypes AA, AB and BB respectively; p i and q i are the frequencies of allele A and B at i th SNP locus, respectively. Similarly, G d = , where H is a n × m matrix of heterozygosity coefficients with elements (0–2 p i q i) and (1–2 p i q i) for homozygous (AA, BB) and heterozygous (AB) individuals at i th SNP locus, respectively. The epistatic genomic relationship matrix (G aa) was obtained as G#G, where # denotes the Hadamard product operation. Pedigree-based relationship matrices, accounting for genetic relationships between the 25 parents, were also used for comparison purposes. Equation 1 was implemented in software ASReml v3.0.

In the subsequent text, Equation 1 will be termed as Model ADE, which includes three genetic components (a, d, and i). BLUP-GV (= a + d + i) of all 247 individuals were obtained from Equation 1 using all available data. Estimates of variance components derived from Equation 1 were used for calculating narrow-sense (h 2) and broad-sense (H 2) heritability, as the ratio of additive to phenotypic variance (sum of all variance components in the model), and the ratio of total genetic variance (= ++) to phenotypic variance, respectively. The method ofwas followed to calculate between-site genotypic correlations using estimates of variance components from Equation 1. Reduced forms of Equation 1, by including only the additive component (Model A), and additive and dominance components (Model AD), were also tested. Goodness-of-fit for each model (i.e. with and without nonadditive genetic effects) was evaluated by the log-likelihood value. The superiority of an alternative model over an additive model, obtained using all available data, was tested using a likelihood ratio test.

---

### Primer on binary logistic regression [^a6422ae6]. Family Medicine and Community Health (2021). Medium credibility.

Step 4: compute ORs and report the results

While the predicted probabilities from the logistic function can be useful in measuring how well the model is predicting or explaining the outcome, the results of logistic regression are usually reported with ORs and CIs. Similar to the interpretation of a coefficient in linear regression, ORs quantify the change in the odds of having the outcome (ie, the odds that an observation has the value of 1 for the outcome variable) with a one-unit change in the predictor. Odds are computed using probabilities (equation 3).

Equation 3. Computing odds from probabilities.

Because the logistic function is used to compute probabilities (see figure 1), add the logistic model from equation 1 into equation 3 to get equation 4 showing how odds are computed for a logistic regression model.

Equation 4. Computing odds from a logistic regression model.

Once theandare estimated using a statistical software package like SAS, R or SPSS, these values can be substituted into the simplified version of equation 4 to compute odds. This is not the final step, however, since odds and ORs are different. An OR is a ratio of two odds and is computed by dividing the odds of the outcome at one value of a predictor by the odds of the outcome at the previous value. So, for example, to compute the OR for lung cancer in our previous example, divide the odds of someone who has smoked for 15 years by the odds for someone who has smoked for 14 years. The result will be the increased or decreased odds of lung cancer with every 1 year increase in age. Equation 5 shows the statistical form of this computation.

Equation 5. Using odds to compute ORs from a logistic regression model.

As an example, consider the output from R showing the estimates for the regression model used in figure 2.

The coefficient for years smoking is 0.4304. Substitute this value into equation 5, to get an OR of 1.54. So, for every 1 year increase in time spent as a smoker, the odds of lung cancer for a participant in our sample are approximately 1.54 times higher. While the OR is useful to understand the direction and magnitude of the relationship between a predictor and the outcome, more information is needed to understand whether the OR for the sample suggests a relationship in the population that the sample came from. To understand this, a 95% CI is typically computed and reported with each OR.

---

### Thinking outside the curve, part I: modeling birthweight distribution [^b60d1510]. BMC Pregnancy and Childbirth (2010). Low credibility.

b. Simulation study on calibrating confidence intervals

For our second simulation study we generated 25 overlapping data sets of size 50,000 from design C in Table 3, the degree of overlap consistent with a population of 200,000. For each of various C between 2.0 and 5.0, we used Equation (7) to form confidence intervals for the mixture parameters p 1, p 2, p 3, p 4, μ 1, μ 2, μ 3, μ 4, σ 1, σ 2, σ 3, σ 4. We recorded how many of the mixture parameters were contained in their respective confidence intervals. This was repeated nine more times, and we tabulated how many of the 120 = 12 × 10 confidence intervals contained their targets. Confidence intervals were also formed using Equation (6) for comparative purposes. The above steps were repeated with overlapping data sets consistent with a population of 1,000,000 and with nonoverlapping data sets consistent with an effectively infinite population.

The results are summarized in Table 5. With an effectively infinite population, only 81.7% of the confidence intervals formed using Equation (6) contained their targets at C = 5.0. The confidence intervals formed using Equation (7) contained their targets 95.0% of the time at C = 2.5. The adjustment suggested by Equation (8) appears reasonable: φ = .05 = 50,000/1,000,000 and N rep = 25 yield C φ = 1.315 C 0, which accords with the 95.8% capture of mixture parameters at C = 3.5 ≈ 1.315 × 2.5 with a population of 1,000,000.

Table 5
Confidence Interval Coverage Probabilities in Simulation Studies

The row with " C " = 2 and "Population size" = 200,000 identifies the numbers and percentages of confidence intervals containing their targets of mixture parameters, based on 10 repetitions in each of which 25 samples of size 50000 were simulated from a 4-component normal mixture with 12 parameters; results under the heading of "Bias adjustment included" are based on Equation (7) with C = 2, results under the heading of "Bias adjustment omitted" are based on Equation (6) with C = 2, and the 25 samples of size 50000 had overlap consistent with a population size of 200,000. Other rows correspond to different choices of C and/or population sizes.

---

### WRN helicase safeguards deprotected replication forks in BRCA2-mutated cancer cells [^e1726834]. Nature Communications (2021). High credibility.

Drug interaction analysis

The CDI was determined using the following equation: CDI = AB/(A × B) where AB is the ratio of the viability of cells treated with both NSC617145 and Olaparib to the no treatment cells; A (NSC617145) or B (Olaparib) is the ratio of the cell viability of the cells treated with either NSC617145 or Olaparib to the no treatment cells. A CDI values can be separated into several categories: CDI > 1 (antagonistic), CDI = 1 (additive), CDI < 1 (synergistic), or CDI < 0.7 (significantly synergistic). CDI values were calculated at different concentrations of Olaparib with a single concentration of NSC617145. Bliss index was calculated using the following equation: BI = (E A + E B − E A * E B)/ E AB. The Bliss index was calculated at each Olaparib concentration with constant NSC617145 concentration. The excess over Bliss (EOB) was calculated by subtracting the expected effect of the drug combination (E A + E B − E A * E B) from the observed effect (E AB) and multiplying that difference by 100. Here, E A and E B are the calculated effects of NSC617145 and Olaparib individually where the E = 1–% cell viability, and E AB is the actual effect of the two inhibitors in combination. More positive EOB values indicate stronger synergism.

Statistics and reproducibility

Statistical significance was determined by Student's two-tailed t -test, one-way or two-way ANOVA, and Mann–Whitney test using GraphPad Prism as indicated in individual figure legends. All experiments were performed at least twice unless otherwise specified. Sample size and p values are indicated in figure legends. Figures were prepared in Microsoft PowerPoint (Version 2108, Build 14326.20404).

Reporting summary

Further information on research design is available in the Nature Research Reporting Summary linked to this article.

---

### Corrections [^e34f1524]. The Lancet: Respiratory Medicine (2016). Medium credibility.

[This corrects the article DOI: 10.1016/S2213-2600(15)00283–0.].

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^4c4b615d]. Kidney International (2024). High credibility.

Initial assessment recommendation and caveats — Practice Point 1.2.2.1: Practice Point 1.2.2.1: Use serum creatinine (SCr) and an estimating equation for initial assessment of GFR. For most clinical circumstances, estimating GFR from SCr is appropriate; equations are available that estimate GFR using SCr and adjusting for sex and age, and professional societies have recommended that GFR estimates should be used in association with SCr reporting; key sources of error include non–steady-state conditions, non-GFR determinants of SCr, measurement error at higher GFR, and interferences with creatinine assays, and GFR estimates are less precise at higher GFR levels, so healthcare providers should remain aware of caveats that may influence accuracy in an individual person.

---