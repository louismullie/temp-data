# Medical Question & Answer

**Sample ID**: 04940ab5-9a32-50b8-3809-f366d2dc5706
**Dataset Index**: 371487

---

## Question

3. The graph of the function f(x) = A cos(ωx + φ) is symmetric with respect to the origin if and only if ()(where k ∈ Z).
A. φ = 2kπ + [π/2]
B. [φ/ω] = 2kπ ± [π/2]
C. φ = kπ + [π/2]
D. φ = kπ + [π/2] or ωx = kπ

---

## Answer

> Let's see… What do we have here? The user is asking which condition on the phase constant φ makes the graph of f(x) = A cos(ωx + φ) symmetric with respect to the origin, and to choose the correct option among the given choices. Let's break this down step-by-step. First, I need to think about what "symmetry with respect to the origin" means mathematically for a function. Then, I should translate that symmetry condition into an equation involving the cosine function and the phase φ. Next, I will solve that equation for φ in terms of integers k. After that, I should verify which of the provided options matches the derived condition. Finally, I will double-check edge cases and make sure there are no hidden constraints on ω or x that would invalidate the result.

> Let me first confirm the definition. A function f is symmetric with respect to the origin if it is odd, meaning f(−x) = −f(x) for all x in the domain. For f(x) = A cos(ωx + φ), that translates to requiring A cos(−ωx + φ) = −A cos(ωx + φ) for all x, which simplifies to cos(φ − ωx) = −cos(ωx + φ) since cosine is even and A ≠ 0 [^notfound].

> Wait, let me verify the trigonometric identity I will use. I initially thought to apply the angle-subtraction formula, but hold on, that would complicate things. The cleaner path is to use the identity cos(θ) = −cos(θ ± π), which tells me that cos(φ − ωx) = −cos(ωx + φ) if and only if φ − ωx differs from ωx + φ by an odd multiple of π, i.e., φ − ωx = ωx + φ + (2k + 1)π for some integer k, or equivalently φ − ωx = −(ωx + φ) + (2k + 1)π. Let me reconsider: both forms lead to the same conclusion, but the second form is more direct for isolating φ [^notfound].

> I will now examine the second form: φ − ωx = −(ωx + φ) + (2k + 1)π. Simplifying, φ − ωx = −ωx − φ + (2k + 1)π, so the −ωx terms cancel and I get 2φ = (2k + 1)π, which means φ = [(2k + 1)π/2] for any integer k. That is exactly φ = kπ + π/2, since [(2k + 1)π/2] = kπ + π/2 when k is an integer [^notfound].

> Hold on, I should verify that this condition is both necessary and sufficient. If φ = kπ + π/2, then f(−x) = A cos(−ωx + kπ + π/2) = A cos(ωx − kπ − π/2) = A cos(ωx + kπ + π/2) because cosine is even, and cos(θ + kπ) = (−1)ᵏ cos(θ), so this becomes A (−1)ᵏ cos(ωx + π/2) = A (−1)ᵏ (−sin(ωx)) = −A (−1)ᵏ sin(ωx), while −f(x) = −A cos(ωx + kπ + π/2) = −A (−1)ᵏ cos(ωx + π/2) = −A (−1)ᵏ (−sin(ωx)) = A (−1)ᵏ sin(ωx). Hmm, wait a minute, I have a sign mismatch here; let me correct that. I should have f(−x) = A cos(−ωx + φ) = A cos(ωx − φ) = A cos(ωx − (kπ + π/2)) = A cos(ωx − kπ − π/2) = A cos(ωx + kπ + π/2) because cosine is even, and then cos(ωx + kπ + π/2) = cos(ωx + kπ)cos(π/2) − sin(ωx + kπ)sin(π/2) = −sin(ωx + kπ) = −(−1)^k sin(ωx) = (−1)^{k+1} sin(ωx), whereas −f(x) = −A cos(ωx + kπ + π/2) = −A (−1)^k cos(ωx + π/2) = −A (−1)^k (−sin(ωx)) = A (−1)^k sin(ωx). To reconcile, I need (−1)^{k+1} sin(ωx) = (−1)^k sin(ωx), which implies (−1)^{k+1} = (−1)^k, which is impossible. Hold on, let's not jump to conclusions; I made an error in the sign chain. Let me re-derive more carefully: f(−x) = A cos(−ωx + φ) = A cos(ωx − φ) = A cos(ωx − (kπ + π/2)) = A cos(ωx − kπ − π/2) = A cos(ωx + kπ + π/2) because cos is even, and then cos(ωx + kπ + π/2) = cos(ωx + kπ)cos(π/2) − sin(ωx + kπ)sin(π/2) = −sin(ωx + kπ) = −(−1)^k sin(ωx) = (−1)^{k+1} sin(ωx), while −f(x) = −A cos(ωx + kπ + π/2) = −A (−1)^k cos(ωx + π/2) = −A (−1)^k (−sin(ωx)) = A (−1)^k sin(ωx). For these to be equal, I need (−1)^{k+1} = (−1)^k, which is never true. I should double-check the original derivation: the correct implication from cos(φ − ωx) = −cos(ωx + φ) is that φ − ωx = ± (ωx + φ) + (2m + 1)π for integer m. Taking the negative sign gives φ − ωx = −ωx − φ + (2m + 1)π, so 2φ = (2m + 1)π, hence φ = (2m + 1)π/2 = mπ + π/2, which is correct. The sufficiency check I just attempted is algebraically messy; let me instead verify with a concrete example. If φ = π/2, then f(x) = A cos(ωx + π/2) = −A sin(ωx), which is odd because sin is odd, so f(−x) = −A sin(−ωx) = A sin(ωx) = −f(x). Similarly, if φ = 3π/2, f(x) = A cos(ωx + 3π/2) = A sin(ωx), which is also odd. Thus, φ = kπ + π/2 indeed makes f odd, confirming sufficiency [^notfound].

> Next, I should review the options and match the derived condition. Option C states φ = kπ + π/2, which matches exactly what I derived. Option A is a special case of C with k even, so it is too restrictive. Option B introduces ω in the denominator, which does not arise from the symmetry condition and would incorrectly imply the phase depends on frequency in a way that is not required for oddness. Option D mixes a condition on φ with a condition on x, but the symmetry must hold for all x, so constraining x to discrete values is inappropriate here [^notfound].

> But wait, what if ω is zero or negative? I need to ensure the derivation does not implicitly assume ω ≠ 0. The symmetry condition f(−x) = −f(x) is a functional equation that must hold for all x; the algebra to isolate φ does not depend on the sign or magnitude of ω, so the result φ = kπ + π/2 remains valid for any nonzero ω. If ω were zero, the function would be constant and could not be odd unless A = 0, which is a trivial case outside the scope of the question, so the answer stands for ω ≠ 0 [^notfound].

> Final answer: The graph of f(x) = A cos(ωx + φ) is symmetric with respect to the origin if and only if φ = kπ + π/2 for integer k, which corresponds to option C [^notfound].

---

The graph of (f(x) = A cos(ωx + φ)) is symmetric with respect to the origin if and only if the function is odd, i.e. (f(−x) = −f(x)) for all (x). This requires (cos(−ωx + φ) = −cos(ωx + φ)), which simplifies to (cos(φ) = 0). Therefore, (φ = kπ + [π/2]) for any integer (k), which corresponds to option C.

---

## Mathematical condition for origin symmetry

A function (f(x)) is symmetric with respect to the origin if it is **odd**, meaning:

f(−x) = −f(x) for all x

For (f(x) = A cos(ωx + φ)), this becomes:

A cos(−ωx + φ) = −A cos(ωx + φ)

Since (cos(−θ) = cos(θ)), we have:

cos(ωx − φ) = −cos(ωx + φ)

---

## Solving the trigonometric equation

Using the identity (cos(α) = −cos(β)) when (α = β + (2k + 1)π), we set:

ωx − φ = ωx + φ + (2k + 1)π

Simplifying:

−2φ = (2k + 1)π

φ = −[(2k + 1)π/2]

Since (k) is any integer, this is equivalent to:

φ = kπ + [π/2]

---

## Verification of the solution

Substitute (φ = kπ + [π/2]) back into (f(x)):

f(x) = A cos(ωx + kπ + [π/2])

Using (cos(θ + kπ) = (−1)ᵏ cos(θ)):

f(x) = A (−1)ᵏ cos(ωx + [π/2]) = −A (−1)ᵏ sin(ωx)

Now, check (f(-x)):

f(−x) = −A (−1)ᵏ sin(−ωx) = A (−1)ᵏ sin(ωx) = −f(x)

Thus, the condition holds.

---

## Analysis of the options

- **Option A**: (φ = 2kπ + [π/2]) is a subset of the correct solution (only even (k)), so it is incomplete.
- **Option B**: ([φ/ω] = 2kπ ± [π/2]) introduces (ω) incorrectly; the condition depends only on (φ), not (ω).
- **Option C**: (φ = kπ + [π/2]) matches our derived condition exactly.
- **Option D**: Introduces (ωx = kπ), which is not a condition on (φ) and is irrelevant to origin symmetry.

---

## Conclusion

The correct answer is **option C**: (φ = kπ + [π/2]), where (k ∈ ℤ). This is the necessary and sufficient condition for the graph of (f(x) = A cos(ωx + φ)) to be symmetric with respect to the origin.

---

## References

### Graphs [^c6c6d5a7]. Chest (2006). Low credibility.

Two rules of good graphs are presented and explicated.

---

### Functional control of oscillator networks [^dcce93a0]. Nature Communications (2022). High credibility.

Oscillatory activity is ubiquitous in natural and engineered network systems. The interaction scheme underlying interdependent oscillatory components governs the emergence of network-wide patterns of synchrony that regulate and enable complex functions. Yet, understanding, and ultimately harnessing, the structure-function relationship in oscillator networks remains an outstanding challenge of modern science. Here, we address this challenge by presenting a principled method to prescribe exact and robust functional configurations from local network interactions through optimal tuning of the oscillators' parameters. To quantify the behavioral synchrony between coupled oscillators, we introduce the notion of functional pattern, which encodes the pairwise relationships between the oscillators' phases. Our procedure is computationally efficient and provably correct, accounts for constrained interaction types, and allows to concurrently assign multiple desired functional patterns. Further, we derive algebraic and graph-theoretic conditions to guarantee the feasibility and stability of target functional patterns. These conditions provide an interpretable mapping between the structural constraints and their functional implications in oscillator networks. As a proof of concept, we apply the proposed method to replicate empirically recorded functional relationships from cortical oscillations in a human brain, and to redistribute the active power flow in different models of electrical grids.

---

### Duality between predictability and reconstructability in complex systems [^6b5cb4e2]. Nature Communications (2024). High credibility.

Results

Information theory of dynamics on random graphs

Let us consider a random graph G whose support, consists in the set of all graphs of N vertices, each of which has its respective nonzero probability P (G = g) with. In our framework, P (G) can be any graph distribution and reflects, from a Bayesian perspective, our prior knowledge of the structure of the system. We also consider a general discrete-time stochastic process (also called dynamics hereafter) with T time steps evolving on a realization of G and representing the possible states of the system. More precisely, we denote P (X ∣ G) the probability of a random and discrete-state time seriesconditioned on G, where X i, t is the random state, with discrete support Ω, of vertex i ∈ {1. N } at time t ∈ {1. T }. We stress that X is at this point any stochastic process be it Markovian or not. The initial condition of the process is. While we only exposed our framework in terms of discrete-time and discrete-state processes, it can be used for continuous-state deterministic dynamics (see Supplementary Note III) and in principle, it can also be generalized to continuous-state stochastic processes by considering a probability density function ρ (X ∣ G).

The variables X and G form themselves a Bayesian network G → X, where the arrow indicates conditional dependence. From this model, we are interested in the mutual information between X and G — denoted I (X; G) — which is a symmetric measure that quantifies the codependence between the dynamics X and the structure G, where I (X; G) = 0 when they are independent. It is equivalently given bywhereandare respectively the marginal entropies of G and X, andandare their corresponding conditional entropies. In the previous equations, the marginal distribution for X, the evidence, is defined as, and the posterior is obtained from Bayes' theorem as P (G ∣ X) = P (G) P (X ∣ G)/ P (X), using the given graph prior P (G) and the dynamics likelihood P (X ∣ G). I (X; G) is a non-negative measure bounded by. Figure 1 a provides an illustration of Eq. (1) in terms of information diagrams.

---

### Input-output maps are strongly biased towards simple outputs [^38aa07d9]. Nature Communications (2018). Medium credibility.

On its own, Eq. (2) may not be that useful, as K (x | f, n) can depend in a complex way on the details of the map f and the input space size n. To make progress towards map independent statements, we restrict the class of maps. The most important restriction is to consider only (1) limited complexity maps for whichin the asymptotic limit of large x (Supplementary Note 3). Using standard inequalities for conditional Kolmogorov complexity, such asand, it follows for limited complexity maps that. Thus, importantly, Eq. (2) becomes asymptotically independent of the map f, and only depends on the complexity of the output.

We include three further simple restrictions, namely (2) Redundancy: if N I and N O are the number of inputs and outputs respectively then we require, so that P (x) can in principle vary significantly, (3) Finite size: we imposeto avoid finite size effects, and (4) Nonlinearity: We require the map f to be a nonlinear function, as linear transformations of the inputs cannot show bias towards any outputs (Supplementary Note 4). These four conditions are not so onerous. We expect that many real-world maps will naturally satisfy them.

---

### Quantifying randomness in real networks [^818b9618]. Nature Communications (2015). Medium credibility.

The problem of interdependencies among network properties has been long understood. The standard way to address it, is to generate many graphs that have property Y and that are random in all other respects — let us call them Y -random graphs — and then to check if property X is a typical property of these Y -random graphs. In other words, this procedure checks if graphs that are sampled uniformly at random from the set of all graphs that have property Y, also have property X with high probability. For example, if graphs are sampled from the set of graphs with high enough edge density, then all sampled graphs will be small worlds. If this is the case, then X is not an interesting property of the considered network, because the fact that the network has property X is a statistical consequence of that it also has property Y. In this case we should attempt to explain Y rather than X. In case X is not a typical property of Y -random graphs, one cannot really conclude that property X is interesting or important (for some network functions). The only conclusion one can make is that Y cannot explain X, which does not mean however that there is no other property Z from which X follows.

In view of this inherent and unavoidable relativism with respect to a null model, the problem of structure–function relationship requires an answer to the following question in the first place: what is the right base property or properties Y in the null model (Y -random graphs) that we should choose to study the (statistical) significance of a given property X in a given network? For most properties X including motifs, the choice of Y is often just the degree distribution. That is, one usually checks if X is present in random graphs with the same degree distribution as in the real network. Given that scale-free degree distributions are indeed the striking and important features of many real networks, this null model choice seems natural, but there are no rigorous and successful attempts to justify it. The reason is simple: the choice cannot be rigorously justified because there is nothing special about the degree distribution — it is one of infinitely many ways to specify a null model.

---

### Recovery coupling in multilayer networks [^c0323da7]. Nature Communications (2022). High credibility.

Recovery coupling simulations and phase space

To understand the implications of recovery coupling for multilayer network resilience, we consider the symmetric case in which the network structure, damage, and recovery parameters are the same in both systems. Since the two systems support each other, we let the repair rate of Y be influenced by the state of X in the same manner as Eq. (5): In the symmetric case f x = f y = f, leading to a single equation that governs the state of the system. If the failures are uniformly distributed, we can use percolation theory, to analytically derive the equation that governs the expected fraction of primary failures in the coupled system, where u (x) is the probability that a link does not lead to the largest connected component when a random fraction 1 − x of the nodes are removed, and is determined by the network topology. Equation (6) has one or two stable solutions depending on the value of the control parameter. The non-symmetric case has similar results, as we shown in supplementary note 1 and Supplementary Fig. 1. In contrast, the uncoupled case (2), which we recover from (6) for α = 0, has a single stable solution. The new solution describes a stable fixed point at f = 1 (all nodes failed), which persists even for high recovery rates(see Fig. 4 a). The existence of two stable solutions for f for the same recovery rateindicates that for a wide range of conditions, recovery coupled networks are resilient: they display functionality comparable to the uncoupled case and return to full functionality following small perturbations. However, a sufficiently large perturbation can force the system to cross the unstable branch, pushing it into a dynamically stable non-functional state (Fig. 4 a). This is more likely with correlated perturbations across layers, as we show in Supplementary Fig. 2. The existence of this behavior analytically predicts a "catch 22" phase that follows a sufficiently large disaster: infrastructure system X cannot be repaired because it requires resources from Y, and Y cannot be repaired because it requires resources from X. The fact that the collapsed state persists even for high repair rates and low damage rates predicts that it is harder to bootstrap a broken system than it is to maintain the functionality of one that is damaged but still working. Synthesizing elastic residual curves (Fig. 4 c) like the observations in Fig. 2 d, we find that the full coupling α = 1 reproduces the shape of the curve, while lower values of α do not, providing further evidence that the general deviation from elasticity is consistent with recovery coupling.

---

### Energy scaling of targeted optimal control of complex networks [^71d2a8c5]. Nature Communications (2017). Medium credibility.

where we are free to choose u (t) such that it satisfies the prescribed initial state, x (t 0) = x 0 and desired final output, y (t f) = y f. Note that if we set C = I n, where I n is the n × n identity matrix, then y (t) = x (t).

The minimum energy control input, well known from linear systems theory, minimizes the cost functionand satisfies an arbitrary initial condition and an arbitrary final condition if the system is controllable. A similar control input is optimal when the final condition is imposed on only some of the states, that is, on the target nodes (see the derivation in Supplementary Note 2)

The real, symmetric, semi-positive definite matrixis the controllability Gramian. Note that in deriving equation (3) we must assume that the triplet (A, B, C) is output controllable, which can be determined if the matrix rank(CB | CAB |… | CA n −1 B) = p. If the triplet is output controllable, it implies that the matrix CWC T is invertible. This suggests the possibility that while the entire network may not be controllable (that is, C = I n and W is singular), for a given B (of the form described above) there may be a controllable subspace (subset of nodes) within the network. On the other hand, every subspace of the controllable subspace is also controllable. In the following discussions we proceed under the assumption that the pair (A, B) is controllable by following the methodology in ref. and focus on the effect that the choice of the matrix C has on the control energy.

---

### Variability of functional and biodiversity responses to perturbations is predictable and informative [^8121b229]. Nature Communications (2024). High credibility.

Next, we combine these two levels of abstraction to model how functions "observe" perturbations. We recenter the state space so that the axes now represent the response of each species, with the origin consequently being the initial state of the community (Fig. 2 C). Projecting the displacement vector (multi-dimensional vector describing species responses to a perturbation) onto the direction of an ecosystem function (one dimensional vector made up of species contributions to the function) gives the "observation" of that function (see blue and red lines coming from perturbed states A and B in Fig. 2 C). For each function, drawing a line through the origin and perpendicular to the direction of the function delineates two zones. One where the projection is negative, and thus the function observes a negative response and the other where the projection is positive and thus the function observes a positive response. If the two directions associated to the two functions are not perfectly collinear, there will be zones of state-space where responses to perturbations will be qualitatively different when observed by one function or the other. These zones are the two symmetrical cones centred on the origin, formed by the delineation lines of the functions, perpendicular to their respective directions (red zones in Fig. 2 D). The larger the angle between two functions, the larger the zones of mismatches. Consequently, if species' responses were random and unbiased, the probability of finding a qualitative mismatch between two functions is:where θ is the angle between the two functions measured in radians. This collinearity of functions allows us to quantify their similarity. The similarity between functions, defined in this way, is related to their respective broadness, which quantifies the evenness of species per-capita functional contributions (Box 2 Eq 6). Indeed, in a community of S species and functions f and g :where 1/ S ≤ 2 D (f)/ S ≤ 1 is the broadness of the function f (same for function g), defined here as the Gini–Simpson diversity indexof the vector of species contributions to the function, and normalized by species richness S. Expression (2) quantifies the intuitive expectation that two broad functions ought to be highly collinear, whereas two narrow functions can be independent (i.e. orthogonal to one another) if they are not performed by the same set of species.

---

### Epidemic graph diagrams as analytics for epidemic control in the data-rich era [^bc56ad97]. Nature Communications (2023). High credibility.

We use the Markov chain formulation in the quenched mean-field approximation, whereby the network appears in its explicit contact structure represented by the adjacency matrix A (t), and the dynamical states of the nodes are independent of each others and follow a system of deterministic differential equations. For a generic compartmental model these equations can be written as:whereis the probability that node i is in compartment b at time t, and b runs over all compartments, except the susceptible S. μ c, γ b c, λ b c are the rates of the transitions between compartments depicted in Fig. 1 a: μ correspond to spontaneous transitions to S (e.g. recovery with no immunity); γ correspond to spontaneous transitions between any two compartments except S (e.g. exposed hosts becoming infectious); λ correspond to transmission events causing a susceptible node to enter another compartment (e.g. a susceptible becoming infectious). Transmissions are generated by infectious hosts of any kind (e.g. asymptomatic or symptomatic infectious individuals) when they are in contact with susceptible nodes. The component f (x) in Eq. (1) contains all terms that are nonlinear in x (quadratic or higher). It may be complex, but its derivatives vanish in the disease-free state, therefore f does not contribute to the epidemic threshold and can be dropped. Eq. (1) can then be conveniently rewritten in operator form:In this formalism, x is a vector on, where N is the number of hosts, and N C is the number of compartments (excluding S). μ, γ, λ are operators on, and A is an operator on. The term J (t) = γ − μ + λ A (t) is the Jacobian of the system, itself an operator on. The component λ A (t) generates the interaction between the contact network structure and the structure of the compartmental model, so that nodes that are neighbors at a given time t affect each other's probabilities to find themselves in given compartments.

---

### Duality between predictability and reconstructability in complex systems [^a024a032]. Nature Communications (2024). High credibility.

Methods

Binary Markov chains on graphs

The models used throughout the paper are for the most part Markov chains X = (X 1, X 2. X T), that are governed by a conditional probability P (X ∣ G) that can be factored as follows:The probability P (X t +1 ∣ X t, G) is the global transition probability from state X t to state X t +1, and P (X 1) represents the probability distribution of the initial conditions, which is independent of G in our case. More specifically, we assume that X i is a random binary vector of size N, and that the global transition probability can be factored in terms of local transition probabilities as follows:

As mentioned in " θ -duality between predictability and reconstructability" section, the functions α and β correspond to the activation and deactivation probabilities. In the general case, they are dependent on the number of active neighbors m i, and inactive neighbors n i of a node i such that m i + n i = k i where k i is the degree of this node.

Performance of prediction and reconstruction algorithms

To substantiate our claim about the interpretation of I (X; G), we used different prediction and reconstruction algorithms and compared in Fig. 2 their performance with I (X; G). In this section, we elaborate on this analysis.

---

### Inferring time derivatives including cell growth rates using gaussian processes [^d99eaf3f]. Nature Communications (2016). Medium credibility.

Inferring the first and second time derivatives

To determine the time derivative of the data, we use that the derivative of a Gaussian process is another Gaussian process. We can therefore adapt standard techniques for Gaussian process to allow time derivatives to be sampled too.

Building on the work of Boyle, we let g (x) and h (x) be the first and second derivatives with respect to x of the latent function f (x). If f (x) is a Gaussian process then so are both g (x) and h (x). Writing ∂ 1 and ∂ 2 for the partial derivatives with respect to the first and second arguments of a bivariate function, we have

and that

as well as

following ref.

Consequently, the joint probability distribution for y and f *, g * and h * evaluated at points X * is again Gaussian (cf. equation (7)):

where we write K = K (X, X) and K ✱ = K (X *, X *) for clarity.

The covariance function is by definition symmetric: k (x i, x j) = k (x j, x i) from equation (1). Therefore, and so

for all positive integers k and. Consequently, the covariance matrix in equation (13) is also symmetric.

Conditioning on y now gives that the distribution P (f *, g *, h *| X, y, θ, X *) is Gaussian with mean

and covariance matrix

Equation (16) includes equation (9) and shows that

which gives the error in the estimate of the first derivative. Similarly,

is the error in estimating the second derivative.

Using an empirically estimated measurement noise

Although our derivation is given for a Gaussian process where the measurement errors in the data are independent and identically distributed with a Gaussian distribution of mean zero, the derivations are unchanged if the measurement noise has a different s.d. for each time point.

When the magnitude of the measurement noise appears to change with time, we first empirically estimate the relative magnitude of the measurement noise by the variance across all replicates at each time point. We then smooth this estimate over time (with a Gaussian filter with a width of 10% of the total time of the experiment, but the exact choice is not important) and replace the identity matrix, I, in equations (6), (15) and (16) by a diagonal matrix with the relative measurement noise on the diagonal in order to make predictions.

---

### Functional control of oscillator networks [^c51bd823]. Nature Communications (2022). High credibility.

If the functional pattern x yields a structurally balanced cosine-scaled network, then x is unstable.

The above condition allows us to immediately assess the instability of functional patterns for the special cases of line and cycle networks. In fact, for a line network with positive weights, x is unstable wheneverfor any i, j. Instead, for a cycle network with positive weights, the pattern x can be stable only if it contains at most one phase difference, where γ ≈ 1.789776 solves(see Supplementary Information). In the next section, we propose a heuristic procedure to correct the interconnection weights in positive networks to promote stability of a functional pattern.

Optimal interventions for desired functional patterns

Armed with conditions to guarantee the existence of positive interconnections that enable a desired functional pattern, we now show that the problem of adjusting the network weights to generate a desired functional pattern can be cast as a convex optimization problem. Formally, for a desired functional pattern x and network weights δ, we seek to solvewhereare the controllable modifications of the network weights, and ∥ ⋅ ∥2 denotes the ℓ 2 -norm. Figure 6 a illustrates the control of a functional pattern in a line network of n = 4 oscillators.

Fig. 6
Optimal interventions for desired functional patterns.

a For the line network in Fig. 2 a, we solve Problem (11) to assign the desired pattern. The starting patternis associated with interconnection weights δ = [3.4026 3.4641 6.4721] T. Applying the optimal correction α * yields positive interconnection weights δ + α ✱ = [6.4721 3.4026 3.4641] T that achieve the desired functional patterns x desired. b Joint allocation of two compatible equilibria for the phase difference dynamics. By taking θ 1 as a reference, we choose two points for the phase differences x 1 i = θ i − θ 1, i ∈ {2,…, 7}, to be imposed as equilibria in a network of n = 7 oscillators:and. In this example, we find a set of interconnection weights (δ + α *) that solves the minimization problem (11) with constraint (12). The trajectories start at the (unstable) equilibrium pointat time t = 0, and converge to the pointafter a small perturbation, with π ∈ [0 0.05], is applied to the phase difference trajectories at time t = 50.

---

### Cyclic quantum causal models [^e4214509]. Nature Communications (2021). High credibility.

A classical process, defined over classical split-nodes X 1. X n, corresponds to a map, such that, for any set of classical channels. A local intervention at a node X, with outcome k X, corresponds to a classical instrument P (k X, X out ∣ X in). Given a local intervention at each node, the joint probability distribution over the outcomes is

A special case of a classical process is a deterministic process, for which, whereis a function. When f is bijective, we call such a process reversible. It was shown in ref.that the set of classical processes over nodes X 1. X n forms a polytope, and that the deterministic polytope, defined as all convex mixtures of deterministic processes, is in general a strict subset of it. While all classical processes on two nodes are causally separable, on three or more nodes there exist classical processes, including deterministic classical processes, that are causally nonseparable — the AF process from ref. described above, is an example.

Definition 9 (CSM — generalized) A CSM is given by:
a causal structure represented by a directed graph G with vertices corresponding to classical split-nodes X 1. X n,
for each X i, a classical channel, where P a (X i) denotes the set of parents of X i according to G, such thatis a classical process over X 1. X n.

This definition generalizes that of ref.to include the case of cyclic graphs, and classical split nodes where the input and output variables have different cardinalities. Referencepresents detailed discussion of the relationship between (acyclic) CSMs and standard classical causal models.

In the classical case, causal structure (defined for unitary processes in the quantum case) can be defined for deterministic processes.

---

### Quantification of network structural dissimilarities [^3cf663e0]. Nature Communications (2017). Medium credibility.

Identifying and quantifying dissimilarities among graphs is a fundamental and challenging problem of practical importance in many fields of science. Current methods of network comparison are limited to extract only partial information or are computationally very demanding. Here we propose an efficient and precise measure for network comparison, which is based on quantifying differences among distance probability distributions extracted from the networks. Extensive experiments on synthetic and real-world networks show that this measure returns non-zero values only when the graphs are non-isomorphic. Most importantly, the measure proposed here can identify and quantify structural topological differences that have a practical impact on the information flow through the network, such as the presence or absence of critical links that connect or disconnect connected components.

---

### Evolutionary dynamics on graphs [^c49db24d]. Nature (2005). Excellent credibility.

Evolutionary dynamics have been traditionally studied in the context of homogeneous or spatially extended populations. Here we generalize population structure by arranging individuals on a graph. Each vertex represents an individual. The weighted edges denote reproductive rates which govern how often individuals place offspring into adjacent vertices. The homogeneous population, described by the Moran process, is the special case of a fully connected graph with evenly weighted edges. Spatial structures are described by graphs where vertices are connected with their nearest neighbours. We also explore evolution on random and scale-free networks. We determine the fixation probability of mutants, and characterize those graphs for which fixation behaviour is identical to that of a homogeneous population. Furthermore, some graphs act as suppressors and others as amplifiers of selection. It is even possible to find graphs that guarantee the fixation of any advantageous mutant. We also study frequency-dependent selection and show that the outcome of evolutionary games can depend entirely on the structure of the underlying graph. Evolutionary graph theory has many fascinating applications ranging from ecology to multi-cellular organization and economics.

---

### Limits on the computational expressivity of non-equilibrium biophysical processes [^37daae40]. Nature Communications (2025). High credibility.

Fig. 2
The matrix-tree theorem.

A Computing the steady-state occupancy π 1 by summing weights over directed spanning trees. Directed spanning trees are subgraphs containing all graph nodes but no cycles, with edges oriented toward a root node. In each directed spanning tree, the input forces make a positive, negative, or zero contribution to the tree weight. The structural vectorsare shown below each tree; these quantities enter into Equation (3) below. B Schematic illustration of the high-dimensional space of feature vectors ψ (i; θ) and χ (i, F). The depicted arrangement of vectors could solve a binary classification problem.

We define the input multiplicityas the number of edges affected per input variable, which we assume to be the same for each input. To focus on the functional way in which the input driving enters the steady-state probabilities, the driving contributions can be factored out in the algebraic expressions for the numerator and denominator of Equation (1). This has been previously been used to make analytical progress for M = D = 1 in, for example, refs. –. This equivalent formulation of Eq. (1) suggests that steady states of Markov jump processes implement a rational polynomial function of exponentiated input variables. Defining, we rewrite the matrix-tree expression for π i for general D and M We use the multi-index, whereis the set of D input labels and each componentof the multi-index runs over the values, to enumerate themonomials. These monomials y μ (F) in Equation (2) combinatorially depend on the different mixtures μ of input driving, representing a net total μ a of signed contributions from the input force F a, μ b such contributions for F b, and so on for each input. The coefficients, which are functions of the parameters θ, are the sums of weights over all directed spanning trees rooted at node i which have the corresponding mixture μ of signed input contributions. The monomial coefficientsthus represent learnable amplitudes of each polynomial basis function y μ (F). The coefficients in the denominator are defined as. Classification will be successful if, for F ρ drawn from class ρ, the coefficientsand monomials y μ (F ρ) are large for the same μ. In the subsequent sections of the paper and in the Supplementary Information we use the formulation in Equation (2) to show how the classification ability of a non-equilibrium Markov processes may be systematically modulated.

---

### Symmetry breaking in space-time hierarchies shapes brain dynamics and behavior [^fb994ea9]. Neuron (2017). Low credibility.

In order to maintain brain function, neural activity needs to be tightly coordinated within the brain network. How this coordination is achieved and related to behavior is largely unknown. It has been previously argued that the study of the link between brain and behavior is impossible without a guiding vision. Here we propose behavioral-level concepts and mechanisms embodied as structured flows on manifold (SFM) that provide a formal description of behavior as a low-dimensional process emerging from a network's dynamics dependent on the symmetry and invariance properties of the network connectivity. Specifically, we demonstrate that the symmetry breaking of network connectivity constitutes a timescale hierarchy resulting in the emergence of an attractive functional subspace. We show that behavior emerges when appropriate conditions imposed upon the couplings are satisfied, justifying the conductance-based nature of synaptic couplings. Our concepts propose design principles for networks predicting how behavior and task rules are represented in real neural circuits and open new avenues for the analyses of neural data.

---

### A graph homomorphism approach for unraveling histories of metastatic cancers and viral outbreaks under evolutionary constraints [^8b29c354]. Nature Communications (2025). High credibility.

In the constructed graph, sets of partial homomorphism tokens that satisfy Lemma 1 can be identified as k -vertex cliques. We employ the Bron-Kerbosch algorithmto generate these cliques. For each identified clique, we use conditions (f1) and (g1) to construct a new token (v, X, C) for the node α.

In addition, for each token (v, X, C) ∈ H α, we maintain pointers p (v, X, C) that link to the children tokens used in its construction. These pointers are used in the subsequent phase of the algorithm, which aims to reconstruct full C-feasible homomorphisms f.

During this phase, the algorithm executes a pre-order traversal of Ψ. As it progresses, it recursively assigns a specific token to each node. When a token t = (v, X, C) is assigned to node α, the algorithm sets f (α) = v. It then retrieves tokens for t via the pointers p (t) and assigns them to children, β 1,…, β k. This ensures that by the end of the traversal, each node in Ψ has been assigned a homomorphic image, completing the construction of the homomorphism f.

The outlined method is formalized as Supplementary Algorithm 2 and illustrated by Fig. 6. Its efficiency can be improved in several ways, with specific details discussed in Supplementary Note 3. It should be noted that, strictly speaking, the described algorithm is not polynomial, since the number of tokens for a node of Ψ theoretically can be exponential. In practical settings, however, the algorithm is extremely fast, and require split seconds to finish.

---

### Duality between predictability and reconstructability in complex systems [^f6a93270]. Nature Communications (2024). High credibility.

Variational mean-field approximation

In this approach, we estimate the posterior probability instead of the evidence probability. According to Bayes' theorem, the posterior probability isBehind this estimator is a variational mean-field (MF) approximation that assumes the conditional independence of the edges. For simple graphs, the MF posterior iswhere π i j (X): = P (A i j = 1∣ X) is the marginal conditional probability of the existence of the edge (i, j) given X. For multigraphs, a similar expression can be obtained, but instead involves a probability π i j (m ∣ X): = P (M i j = m ∣ X) that there are m multiedges between i and j. In this case, the MF posterior becomeswhere δ x, y is the Kronecker delta. The MF approximation allows to compute a lower bound of the true posterior entropy, such thatas a consequence of the conditional independence between the edges, Theorem 2.6.5. Using the MF approximation and a strategy similar to the exact estimator, we compute the MF estimator of the mutual information as follows:To compute, we sample a setof Q graphs from the posterior distribution P (G ∣ X = x (m)). Then, we estimate the probabilitiesusing their corresponding maximum likelihood estimate, whereis the number of times the edge (i, j) is seen in. An analogous maximum likelihood estimate is made in the multigraph case, whereandcounts the number of times there were ω multiedges between i and j in. This estimator is a lower bound of the mutual information — a consequence of Eq. (30). Hence, it is biased, and the extent of this bias is dependent on the quality of the conditional independence assumption with respect to the true random graph. Note that the MF estimator can yield negative estimates of the mutual information (see Section VIII of the Supplementary Information).

In Fig. 6, we fix the number of graphs sampled from the posterior distribution to Q = 1000, and propose 5 N moves between each sample (see also "Markov chain Monte Carlo algorithm" section for more detail).

---

### Epidemic graph diagrams as analytics for epidemic control in the data-rich era [^6066c7c5]. Nature Communications (2023). High credibility.

Proof of ZIP

We use the notationfor the mathematical representation of the diagram. Let us assume that weak-commutation condition holds, and the epidemic graph diagramis made of a node D and a subdiagram. Moreover, let us assume thatcontains only single links (its Jacobian is γ X − μ X). Single links may exist from D, to any node in: We callthe weight of the single link from D to the r -th node of. Single links may also exist from any node into D: We callthe weight of the single link from the r -th node ofto D. The index r runs on the N c − 1 nodes of. D may have both single and double self loops, whose weights we call − μ 0 and, respectively. Double links may exist from any node into D (λ r). The resulting J of the full EGD iswith. The threshold condition in timescale separation is. Using block matrix determinant rules, this simplifies to a determinant in:with γ X − μ X − d is always invertible if we assume that the model is below the epidemic threshold in the absence of transmission. If it were not the case, the epidemic would be a trivial spontaneous generation of infected individuals. Or, in epidemiological terms, there would be only primary disease introductions. This means that J (λ 0 = 0, λ r = 0) is negative definite. By virtue of Sylvester's criterion, this in turn implies that γ X − μ X − d is also negative definite, because all the leading principal minors of the latter are also leading principal minors of J. And since γ X − μ X does not depend on transmission, γ X − μ X − d is always negative definite, and so invertible. We complete the proof of ZIP by noting that Eq. (13) is equivalent to an SIS model with renormalized recovery and transmission rates μ e f f, λ e f f.

---

### Anticipating regime shifts by mixing early warning signals from different nodes [^4c2ed7d1]. Nature Communications (2024). High credibility.

Two nodes connected by a directed edge

We consider a network composed of two nodes and a directed edge of weight w (≥ 0); see Fig. 1 a for a schematic. We assume that node 1 influences node 2 but not vice versa. We also assume that, as a bifurcation parameter, denoted by r, gradually increases, node 1 undergoes a saddle-node bifurcation and that node 2 also undergoes a saddle-node bifurcation either almost at the same time as node 1 or after r has further increased. The model is given bywhere Δ r (≥ 0) is a constant, σ 1 and σ 2 are the intensities of dynamical noise applied to nodes 1 and 2, respectively, and f (x) satisfies the following conditions. First, we assume f (x, r) = r + x 2 when r ≤ 0 and, where Δ x (> 0) is a small constant. This condition guarantees that, in the absence of coupling and dynamical noise, Eqs. (8) and (9) are both the topological normal form of the saddle-node bifurcation. In other words, d x /d t = f (x, r) with r < 0 has a stable equilibriumand an unstable equilibrium, which collide at x ✱ = 0 when r = 0. In Fig. 2, we show an example bifurcation diagram of single-node deterministic dynamics given by d x /d t = f (x, r). If σ 1 = 0, then x 1 (t) undergoes a saddle-node bifurcation at r = 0 as r increases starting with a negative value. If σ 2 = 0 and w = 0, then x 2 (t) undergoes a saddle-node bifurcation at r = Δ r. Second, we assume that f (x, r) is continuous in terms of x and r for simplicity. Third, we assume that f (c, r) = 0 for ∀ r ≥ 0 for a unique positive value of c, which is larger than Δ x. This implies that, in the absence of noise, x = c is the unique stable equilibrium after a node undergoes a saddle-node bifurcation as r gradually increases. This assumption in combination with the continuity assumption for f (x, r) also implies that the stable equilibrium apart frompersists for some r < 0 although its position changes from x = c in general. Therefore, there are two stable equilibria at least in some range of x < 0 near x = 0, as shown in Fig. 2.

---

### Trametinib (Mekinist) [^cae3e3eb]. FDA (2025). Medium credibility.

Warnings and precautions regarding the use of trametinib PO (also known as Mekinist):
- **Bleeding**: use extreme caution in patients with risk factors for Bleeding events (e.g., intracranial bleeding and GI bleeding). Monitor patients who receive trametinib for signs or symptoms of bleeding. Interruption of therapy, a dose reduction, or permanent therapy discontinuation may be necessary in patients who develop grade 3 or 4 bleeding.
- **Cardiomyopathy, LV dysfunction**: use extreme caution with BRAF V600 mutation-positive, unresectable or metastatic melanoma who received trametinib as monotherapy or in combination with dabrafenib. Evaluate cardiac function prior to starting trametinib (e.g., echocardiogram). Interruption of therapy, a dose reduction, and/or permanent discontinuation may be necessary in patients who develop LV dysfunction.
- **DVT, PE**: use extreme caution in patients with a history of venous thromboembolic disease. Implement appropriate thromboprophylaxis measures and closely monitor patients for signs of DVT and PE during Trametinib treatment. Initiate prompt medical intervention, including anticoagulant therapy, for the management of DVT or PE. Seek immediate medical attention.
- **Gastrointestinal perforation, colitis**: use caution in patients with inflammation of the colon. Monitor patients for symptoms of colitis and promptly manage any gastrointestinal adverse effects during Trametinib treatment. Discontinue Trametinib and provide appropriate medical intervention, which may include corticosteroids or surgical intervention.
- **Hyperglycemia**: use caution in patients with a history of diabetes mellitus. Monitor serum glucose levels at baseline and as clinically indicated during therapy. Initiate or optimize anti-hyperglycemic agents in these patients as necessary.
- **ILD, pneumonitis**: use extreme caution in patients with a history of pulmonary illness. Monitor patients regularly for signs and symptoms of ILD and pneumonitis during Trametinib treatment. Discontinue Trametinib and initiate appropriate medical intervention, which may include systemic corticosteroids, to manage ILD and pneumonitis.
- **Retinal detachment, central retinal vein occlusion**: use caution in patients with a history of vision problems. Ophthalmological exams should be performed periodically and promptly in patients who report vision problems. Interruption of therapy, a dose reduction, or permanent therapy discontinuation may be necessary for patients who develop retinal detachments and retinal vein occlusion.

---

### Graph dynamical networks for unsupervised learning of atomic scale dynamics in materials [^71b89926]. Nature Communications (2019). High credibility.

Learning feature map function with graph dynamical networks

In this work, we use GCN to learn the feature map function χ (x). GCN provides a general framework to encode the structure of materials that is invariant to permutation, rotation, and reflection. As shown in Fig. 1, for each time step in the MD trajectory, a graphis constructed based on its current configuration with each node v i representing an atom and each edge u i, j representing a bond connecting nearby atoms. We connect M nearest neighbors considering periodic boundary conditions while constructing the graph, and a gated architectureis used in GCN to reweigh the strength of each connection (see Supplementary Note 1 for details). Note that the graphs are constructed separately for each step, so the topology of each graph may be different. Also, the 3-dimensional information is preserved in the graphs since the bond length is encoded in u i, j. Then, each graph is input to the same GCN to learn an embedding for each atom through graph convolution (or neural message passing) that incorporates the information of its surrounding environments. After K convolution operations, information from the K th neighbors will be propagated to each atom, resulting in an embeddingthat encodes its local environment.

---

### Duality between predictability and reconstructability in complex systems [^d875b340]. Nature Communications (2024). High credibility.

Figure 5 illustrates the universality of the T -duality using the special case of binary Markov chains (i.e. see "Binary Markov chains on graphs" section). These systems are parametrized by their activation (0 → 1) and deactivation (1 → 0) probability functions, denoted α (n i, t, m i, t) and β (n i, t, m i, t), respectively. In general, the activation and deactivation functions depends solely on n i, t and m i, t, i.e. the number of active and inactive neighbors of vertex i at time t. We present multiple examples of binary Markov processes with different origins in Table 1: The Glauber dynamics, the Suspcetible-Infectious-Susceptible (SIS) dynamics, and the Cowan dynamics.

Fig. 5
T -duality in binary dynamics evolving on small Erdős-Rényi random graphs.

a, d Glauber dynamics, b, e SIS dynamics, and c, f Cowan dynamics. Each panel shows the reconstructability U (G ∣ X) ∈ [0, 1] (blue) and the predictability coefficient U (X ∣ G) ∈ [0, 1] (orange) as a function of the number of time steps T. We used graphs of N = 5 vertices and E = 5 edges, meaning an average degree of 〈 k 〉 = 2; we fixed τ = 1 in the top row, and τ = T /2 in the bottom row. Each symbol corresponds to the average value measured over 1000 samples. We also show different values of the coupling parameters using different symbols: a, d for Glauber, b, e for SIS, and c, f for Cowan.

---

### Asymmetry underlies stability in power grids [^e786496a]. Nature Communications (2021). High credibility.

Behavioral homogeneity is often critical for the functioning of network systems of interacting entities. In power grids, whose stable operation requires generator frequencies to be synchronized-and thus homogeneous-across the network, previous work suggests that the stability of synchronous states can be improved by making the generators homogeneous. Here, we show that a substantial additional improvement is possible by instead making the generators suitably heterogeneous. We develop a general method for attributing this counterintuitive effect to converse symmetry breaking, a recently established phenomenon in which the system must be asymmetric to maintain a stable symmetric state. These findings constitute the first demonstration of converse symmetry breaking in real-world systems, and our method promises to enable identification of this phenomenon in other networks whose functions rely on behavioral homogeneity.

---

### Stochastic representation of many-body quantum States [^2a1a211a]. Nature Communications (2023). High credibility.

Stochastic projection

Generically, a spatial wavefunction with some stochastic component that undergoes imaginary time evolution will go to its bosonic ground state, which is symmetric to particle exchanges. For the algorithm to be useful in electronic problems, it is crucial that we be able to target both symmetric/bosonic states and antisymmetric/fermionic states. A very useful property of the stochastic representation is that it is possible to project out the undesired components by directly acting on the data. This obviates the need for explicitly enforcing symmetry conditions within the ansatz. Alternatively, symmetric ansatzes can still be used instead.

The main idea is that, given the set of samples, one can — at negligible expense — take advantage of the exchange symmetry/antisymmetry to generate some or all of the new samplesHere, P is one of the n! possible permutation operators that can act on the n single-particle coordinates r 1, i,…, r n, i composing R i; is its parity; and the value ± 1 is used for bosons and fermions, respectively. For example, in a fermionic three particle system and for, sampleproduces the new sample. Since the number of possible new samples grows factorially with the number of particles in the system, it will generally be better to generate a random subset of them as required, rather than obtaining and storing them all. The set of original samples, together with the new samples, describes a function with more particle exchange symmetry or antisymmetry, depending on the choice of sign and compared to the original samples alone. Therefore, when stochastic projection is performed before every time propagation step, it drives the algorithm to converge to a solution with the desired exchange property.

---

### Carbachol (Miostat) [^da222cd1]. FDA (2023). Medium credibility.

Warnings and precautions regarding the use of carbachol intraocular (also known as Miostat):
- **AF**: use caution in patients with hyperthyroidism. To prevent AF in hyperthyroid patients, closely monitor cardiac function and thyroid status before using Carbachol. Discontinue the medication, manage the cardiac condition, and collaborate with a cardiologist for targeted intervention and treatment adjustments.
- **Airway obstruction**: use extreme caution in patients with bronchial asthma. Carefully assess patients for bronchial asthma history before use and consider alternative treatments if indicated. Discontinue the medication, administer bronchodilators, and seek immediate medical intervention to manage the complication in patients with bronchial asthma.
- **Exacerbation of bladder outflow obstruction**: use caution in patients with pre-existing urinary tract obstruction. To avert worsening of urinary tract obstruction, exercise caution with Carbachol use, assess urinary tract health, and consider alternative treatments for patients with obstruction risk. Discontinue the medication, relieve obstruction, and collaborate with a urologist for appropriate intervention.
- **Exacerbation of corneal abrasion**: use caution in patients with pre-existing corneal abrasion. Exercise caution when using Carbachol ophthalmic solution in patients with corneal abrasions, ensuring minimal drug penetration and considering alternative treatments if needed. If systemic toxicity occurs due to excessive Carbachol penetration in patients with corneal abrasions, discontinue its use, manage systemic symptoms, and consult a medical professional for appropriate intervention.
- **Exacerbation of Parkinson's disease**: use caution in patients with pre-existing Parkinson's disease. Use Carbachol cautiously, assess for Parkinson's history, and consider alternative treatments if indicated. Discontinue the medication, manage Parkinson's symptoms, and consult a neurologist for specialized guidance.
- **Exacerbation of peptic ulcer disease**: use caution in patients with active peptic ulcer disease or gastrointestinal spasm. Screen patients for ulcer history, employ gastroprotective measures and consider alternative therapies if needed. Discontinue the medication, administer ulcer-healing treatments, and consult a gastroenterologist for specialized guidance.
- **Hypotension, cardiac arrhythmias, hypertension**: use extreme caution in patients with a history of cardiac disease. Carefully assess patients for cardiac conditions, administer the lowest effective dose, and monitor cardiovascular function during treatment. Discontinue the medication, provide appropriate cardiac support, and consult a cardiologist for tailored management.

---

### A mathematical approach to human pterygium shape [^a8e2767f]. Clinical Ophthalmology (2016). Low credibility.

Results

We examined the pictures of each pterygium taken at the initial ophthalmological examination using a camera. On the contour plane curves which were seen, we measured the coordinates of five points (Table 1). For some patients, a few points were too close to enable us to estimate curve's type. Hence, we used the software to determine four more points on the contour curve.

We applied the spline approximations through those nine points which successfully reconstructed the curve. Reconstructed graphs of contour curve by spline approximation are shown in Figure 2. Since the original curves were very similar to conics, we took five points: the first is the point which is the nearest to the origin of supposed conic; a further two points distinguished from one side and two from the other side. The most simple class of curves which pass through five plane points is the class of conic sections which satisfies the equation of the form (Figure 3):

The previous equation given by the determinant can be written in the form Ax 2 + 2 Bxy + Cy 2 + 2 Dx + 2 Ey + F = 0.

Denote

According to the analytical geometry, this equation determines:
Ellipse if δ > 0 ∧ s Δ < 0
Hyperbola if δ < 0 ∧ Δ≠0
Parabola if δ = 0 ∧ Δ≠0

By plotting original curve, spline, and conics, we obtained very close graphs for every patient (Table 2). So, we can conclude that the shape of pterygia is of conic form.

Equations of conics for five patients were calculated (Table 3). These equations show that the conics are slightly rotated around X-axis; therefore, the graphs are not symmetrically located by X-axis (Figure 4).

---

### Structure and inference in annotated networks [^a755e71f]. Nature Communications (2016). Medium credibility.

Given metadata x = { x u } and degree d = { d u } for all nodes, a network is generated from the model as follows. First, each node u is assigned to a community s with a probability depending on u 's metadata x u. The probability of assignment we denote γ sx for each combination s, x of community and metadata, so the full prior probability on community assignments is, where Γ denotes the k × K matrix of parameters γ sx. (More complex forms of the prior are appropriate in other cases, as we will see.) Once every node has been assigned to a community, edges are placed independently at random between nodes, with the probability of an edge between nodes u and v being

where θ st are parameters that we specify, with θ st = θ ts. The factor d u d v allows the model to fit arbitrary degree sequences as described above. Models of this kind have been found to fit community structure in real networks well.

Community detection then consists of fitting the model to observed network data using the method of maximum likelihood. Given an observed network, we define its adjacency matrix A to be the n × n real symmetric matrix with elements a uv = 1, if there is an edge between nodes u and v and 0 otherwise. Then the probability, or likelihood, that this network was generated by our model, given the parameters and metadata, is

where Θ is the k × k matrix with elements θ st and the sum is over all possible community assignments s.

Fitting the model involves maximizing this likelihood with respect to Θ and Γ to determine the most likely values of the parameters, which we do using an expectation-maximization (EM) algorithm. Typically, rather than maximizing (2) itself, we maximize instead its logarithm

---

### Distal symmetric polyneuropathy: a definition for clinical research: report of the American Academy of Neurology, the American association of electrodiagnostic medicine, and the American Academy of Physical Medicine and Rehabilitation [^06cd71bb]. Neurology (2005). Medium credibility.

AAN/AAEM/AAPM&R distal symmetric polyneuropathy — diagnostic glossary standardizes key terms for case definition and evidence assessment: a predictor (diagnostic predictor) is a symptom, examination finding, or test result presumably predicting the presence of a distal symmetric polyneuropathy; the target disorder is the condition or disease being sought and, in this context, is a specific type of distal symmetric polyneuropathy (e.g., diabetic peripheral neuropathy); the reference standard (the gold standard) is the test or procedure performed to determine the actual presence or absence of a distal symmetric polyneuropathy; the nominal group process is a formalized, iterative method for achieving expert consensus while preserving individual input; and the ROC (receiver-operating-characteristic) curve is a standardized graph of sensitivity (true positive rate) by specificity (true negative rate) designed to depict diagnostic accuracy and the trade-off between increasing sensitivity and decreasing specificity.

---

### A mechanoelectrical mechanism for detection of sound envelopes in the hearing organ [^87fb4667]. Nature Communications (2018). Medium credibility.

Fig. 7
Origin of the envelope signals. a When pushed sideways, electrical currents flow into sensory cell stereocilia as mechanically sensitive ion channels open. These currents have a sigmoidal relation to the bundle displacement (lower graph). b, c Example hair cell currents evoked by three-tone stimulation of stereocilia, using a stiff stimulus probe. The thin lines are low-pass filtered versions of each trace (filter cutoff, 500 Hz). At center-tone phase 0°, the magnitude spectra (c) revealed peaks at f e and 2 f e. The f e peak disappeared at center-tone phase 90°. d Averaged data from 10 cells in 10 different animals (± sem). The frequencies represent the center frequency of each stimulus. e Hair cell mechanoelectrical transduction channels have sigmoidal activation curves described by first-order Boltzmann functions. The sideways shift of the curves is a consequence of adaptation and is described by the model parameter X 0. f Frequency spectra of model receptor currents evoked by three-component stimuli. A large peak at f e is observed when the center-tone phase is zero (blue waveform); this peak is abolished at center-tone phase 90° (red waveform). The peak at 2 f e corresponds to the 1-ms periodicity present regardless of center phase. Parameters: I max, 2.5 nA; X 0, 5.5 nm; gating force, Z, 1.05 pN; Temperature, 310.15 K; K b, 1.381 × 10 −23 J K −1; stimulus frequencies (f 1, f 2, f 3), 14.5, 15, 15.5 kHz; stimulus amplitude, 1 nm. The model contains no temporal parameters, hence assuming MET channels are infinitely fast. g At X 0 = 0 no envelope coding is possible. As soon as the resting position of the stereocilia deviates from this value, the receptor current contains a signal corresponding to the envelope. The maximum is at 7 nm. At large values of X 0, the overall amplitude of the receptor current is reduced, because this causes the stimulus to be applied near the flat portion of the Boltzmann function, where the slope is small. Except for X 0, parameters identical to those for panel f were used. f e, frequency of envelope variations. 2 f e, component at twice f e

---

### The causal pivot: a structural approach to genetic heterogeneity and variant discovery in complex diseases [^76b51639]. American Journal of Human Genetics (2025). Medium credibility.

Conditional analysis

Here, we present an overview of the mathematical derivation of the CP approach; more details are in the supplemental methods. In what follows, we refer to the variables PRS as X, RV as G, and disease outcome as Y. The CP derives from manipulation of the probabilistic factorization determined by the graphical model (Figures 1 A and 1E). The joint density under the model isIn the expression, represents the respective probability density functions for their arguments, and the bar symbol expresses conditioning on variables to the right-hand side of the bar. The parameter vector θ represents the unknown parameters governing the probabilistic structure of the system; for clarity, we emphasize that the parameter θ comprises the parameters θ R that determine the forward conditional relationship between Y and X, G — also known as the outcome model; the separate parameters θ XG determine the distributions of X and G, which in the simple model are exogenous and independent and can be represented separately as θ X and θ G.

The CP procedure follows from application of Bayes' rule to the probabilistic factorization implied by the graphical model. In notation, application of Bayes' rule and independence of X and G Equation 1 leads to

For G representing RV status, this expression states that the conditional probability for a sampled individual to bear an RV — denoted by G = 1 — or to not have an RV — denoted G = 0 — when X, Y are conditioned upon is given by the ratio of the forward conditional probability of their phenotype Y = y given PRS X = x and G = g divided by the average probability of Y integrating out G multiplied against the prior probability of G = g. This factorization is general and does not depend on the model specification of f(y | x, g) or f(x) or f(g); moreover, the factorizations in Equations 1 and 2 do not depend on a univariate restriction on X, G, or Y, nor does it depend on the binary character of G or the distributional character of X. The form holds under the model in Figure 1.

---

### Isolation by distance in populations with power-law dispersal [^7afc353f]. G3 (2023). Medium credibility.

We can estimate the discrete-time value of ψ (x ≪ c) from a heuristic argument, at least when ψ ≪ 1. In the absence of coalescence, the probability of the lineages being within coalescence range of each other in generation t ≥ 1 is ≈(2 δ) K (x | t) ≈ (2 δ) K (0 | t). For ψ ≪ 1, including the possibility of coalescence will only slightly decrease this probability. Given that the lineages are in coalescence range, they coalesce with probability 1/(2 δρ). So in any one generation the probability of coalescence is ≈ K (0 | t)/ ρ and we can find ψ by summing over all generations:

where ζ is the Riemann zeta function. Fig. 8 shows that (72) accurately describes the simulations.

---

### Standardization of spirometry 2019 update. An official American Thoracic Society and European Respiratory Society technical statement [^7290ab6b]. American Journal of Respiratory and Critical Care Medicine (2019). High credibility.

Standardization of spirometry — display and digitization requirements specify acquisition, graph scaling, and start-of-test display. For digitization of the flow or volume signal, the sampling rate must be ≥ 100 Hz with a minimum resolution of 12 bits. For the flow–volume graph, expiratory flow must be plotted upward and expiratory volume toward the right, and a 2:1 aspect ratio must be maintained so that 2 L/s of flow and 1 L of volume are the same distance on their respective axes. For the start of test display, the volume–time graph must begin at the point of maximum inspiration or 1 second before Time 0, whichever occurs first, and should continue to the end of the plateau or the beginning of inspiration. Displays of flow versus volume provide more detail than volume–time graphs for the first 1 second of the FVC maneuver, whereas volume–time graphs provide more detail for the latter part of the maneuver.

---

### Structure and inference in annotated networks [^8fbc66a4]. Nature Communications (2016). Medium credibility.

For many networks of scientific interest we know both the connections of the network and information about the network nodes, such as the age or gender of individuals in a social network. Here we demonstrate how this 'metadata' can be used to improve our understanding of network structure. We focus in particular on the problem of community detection in networks and develop a mathematically principled approach that combines a network and its metadata to detect communities more accurately than can be done with either alone. Crucially, the method does not assume that the metadata are correlated with the communities we are trying to find. Instead, the method learns whether a correlation exists and correctly uses or ignores the metadata depending on whether they contain useful information. We demonstrate our method on synthetic networks with known structure and on real-world networks, large and small, drawn from social, biological and technological domains.

---

### Input-output maps are strongly biased towards simple outputs [^659947d0]. Nature Communications (2018). Medium credibility.

Random matrix map with bias but not simplicity bias

Finally, we provide an example of a map that exhibits strong bias that is not simplicity bias. We define the matrix map by having binary input vectors p of length n that map to binary output vectors x of same length though x i = Θ ((M ⋅ p) i), where M is a matrix and the Heaviside thresholding function Θ (y) = 0 if y < 0 and Θ (y) = 1 if y ≥ 0. This last nonlinear step, which resembles the thresholding function in simple neural networks, is important since linear maps do not show simplicity bias. In Fig. 1e, we illustrate this map for a matrix made with entries randomly chosen to be −1 or +1. The rank plot (Supplementary Fig. 17) shows strong bias, but in marked contrast to the other maps, the probability P (x) does not correlate with the complexity of the outputs. Simplicity bias does not occur because the n × n independent matrix elements mean that the mapping's complexity grows rapidly with increasing n so that the map violates our limited complexity condition (1). Intuitively: the pattern of 1s and 0s in output x is strongly determined by the particular details of the map M, and so does not correlate with the complexity of the output.

To explore in more detail how simplicity bias develops or disappears with limited complexity condition (1), we also constructed a circulant matrix where we can systematically vary the complexity of the map. It starts with a row of p positive 1 s and q − 1 s, randomly placed. The next row has the same sequence, but permuted by one. This permutation process is repeated to create a square n × n matrix. Thus the map is completely specified by defining the first row together with the procedure to fill out the rest of the matrix. In Fig. 2, we plot the ratio of the mean complexity sampled over outputs divided by the mean complexity sampled over all inputs, as a function of the complexity of the first row that that defines the matrix. If the ratiois significantly larger than one, then the map shows simplicity bias. Simplicity bias only occurs whenis very small, i.e. for relatively simple maps that respect condition (1). The output of one such simple matrix maps is shown in Fig. 1f. In Supplementary Note 12, we investigate these trends in more detail as a function of matrix type, size n, and also investigate the role of matrix rank and sparsity.

---

### Recommendations for a standardized pulmonary function report. An official American Thoracic Society technical statement [^d6d8fcbc]. American Journal of Respiratory and Critical Care Medicine (2017). Medium credibility.

Spirometry reporting specifies that numerical values are given for the FEV1, the FVC, and the FEV1/FVC ratio; the latter should be reported as a decimal fraction and the space for percent predicted value left blank, and if bronchodilators are given the LLN column need not be repeated with absolute and percent change given only for FEV1 and FVC. Other numerical values such as the forced inspiratory flow at 75% of FVC (FEF75%) and FEF25–75% are not recommended for routine use. Graph requirements include that for the volume–time curve the volume scale should be at least 10 mm/L, the time scale at least 20 mm/s, and 1 second prior to the start of expiration should be displayed; on the flow–volume plot the flow display should be at least 5 l/min/L/s, and the ratio of flow to volume should be 2 L/s to 1 L, and linear and log scales where values are plotted as z-scores relative to the predicted value (z = 0) give an intuitive sense of severity.

---

### Quantitative mappings between symmetry and topology in solids [^ce1ff365]. Nature Communications (2018). Medium credibility.

The study of spatial symmetries was accomplished during the last century and had greatly improved our understanding of the properties of solids. Nowadays, the symmetry data of any crystal can be readily extracted from standard first-principles calculation. On the other hand, the topological data (topological invariants), the defining quantities of nontrivial topological states, are in general considerably difficult to obtain, and this difficulty has critically slowed down the search for topological materials. Here we provide explicit and exhaustive mappings from symmetry data to topological data for arbitrary gapped band structure in the presence of time-reversal symmetry and any one of the 230 space groups. The mappings are completed using the theoretical tools of layer construction and symmetry-based indicators. With these results, finding topological invariants in any given gapped band structure reduces to a simple search in the mapping tables provided.

---

### The promise and challenge of spatial inference with the full ancestral recombination graph under brownian motion [^093b202d]. G3 (2025). Medium credibility.

Spatial patterns of genetic relatedness among samples reflect the past movements of their ancestors. Our ability to untangle this history has the potential to improve dramatically, given that we can now infer the ultimate description of genetic relatedness, the ancestral recombination graph (ARG). By extending spatial theory previously applied to trees, we generalize the common model of Brownian motion to full ARGs, thereby accounting for correlations in trees along a chromosome while efficiently computing likelihood-based estimates of dispersal rate and genetic ancestor locations, with associated uncertainties. We evaluate this model's ability to reconstruct spatial histories using individual-based simulations and unfortunately, find a clear bias in the estimates of dispersal rate and ancestor locations. We investigate the causes of this bias, pinpointing a discrepancy between the model and the true spatial process at recombination events. This highlights a key hurdle in extending the ubiquitous and analytically-tractable model of Brownian motion from trees to ARGs, which otherwise has the potential to provide an efficient method for spatial inference, with uncertainties, using all the information available in the full ARG.

---

### Evaluation of the evenness score in next-generation sequencing [^1f5f1936]. Journal of Human Genetics (2016). Low credibility.

The evenness score (E) in next-generation sequencing (NGS) quantifies the homogeneity in coverage of the NGS targets. Here I clarify the mathematical description of E, which is 1 minus the integral from 0 to 1 over the cumulative distribution function F(x) of the normalized coverage x, where normalization means division by the mean, and derive a computationally more efficient formula; that is, 1 minus the integral from 0 to 1 over the probability density distribution f(x) times 1-x. An analogous formula for empirical coverage data is provided as well as fast R command line scripts. This new formula allows for a general comparison of E with the coefficient of variation (= standard deviation σ of normalized data) which is the conventional measure of the relative width of a distribution. For symmetrical distributions, including the Gaussian, E can be predicted closely as 1-σ(2)/2⩾E⩾1-σ/2 with σ ≤ 1 owing to normalization and symmetry. In case of the log-normal distribution as a typical representative of positively skewed biological data, the analysis yields E≈exp(-σ*/2) with σ*(2) = ln(σ(2)+1) up to large σ (≤ 3), and E≈1-F(exp(-1)) for very large σ (⩾2.5). In the latter kind of rather uneven coverage, E can provide direct information on the fraction of well-covered targets that is not immediately delivered by the normalized σ. Otherwise, E does not appear to have major advantages over σ or over a simple score exp(-σ) based on it. Actually, exp(-σ) exploits a much larger part of its range for the evaluation of realistic NGS outputs.

---

### Different population dynamics in the supplementary motor area and motor cortex during reaching [^5386a3e2]. Nature Communications (2018). Medium credibility.

We consider the data matrix, A, where each column contains the firing rate of one neuron across times and conditions. We estimate the latent variables as a projection, X = AW T, where each column of X contains the values of one latent variable across times and conditions. The rows of the orthogonal matrix W are the "neural dimensions", found by minimizing a cost function f (W). Because the above hypothesis contains three components, we employ a tripartite cost function:The first term, f rec (W), is identical to the PCA cost function, and is small if the latent variables capture considerable variance (i.e. if the firing rates in A are accurately reconstructed by A rec = XW). The second two terms relate to the hypothesis that there exists condition-invariant structure in some dimensions and dynamical structure in other, orthogonal dimensions. If so, an appropriate W will result in latent variables X = [X invar, X dyn]. X invar are latent variables that vary with time but not condition. X dyn are latent variables whose evolution obeys linear dynamics. f invar (W) is small if X invar varies strongly with time but not condition. f dyn (W) is small if the fitis good for some choice of D. Equations for f rec (W), f invar (W), and f dyn (W) are provided in the Methods. By minimizing f (W) we ask the question: does there exist a projection of the population response that captures considerable variance and has the hypothesized condition-invariant and dynamical structure?

---

### Recovery after stroke: not so proportional after all? [^d3259e7a]. Brain (2019). Medium credibility.

Spurious r(X,Δ) are likely when σ Y /σ X is small

For any X and Y, it can be shown that:

A formal proof of Equation 1 is provided in the Supplementary material, Appendix A [proposition 4 and theorem 1; also see]; its consequence is that r(X,Δ) is a function of r(X, Y) and σ Y /σ X. To illustrate that function, we performed a series of simulations (Supplementary material, Appendix B) in which r(X, Y) and σ Y /σ X were varied independently. Figure 2 illustrates the results: a surface relating r(X,Δ) to r(X, Y) and σ Y /σ X. Figure 3 shows example recovery data at six points of interest on that surface.

Figure 2
The relationship between r(X, Y), r(X,Δ) and σ Y /σ X. Note that the x -axis is log-transformed to ensure symmetry around 1; when X and Y are equally variable, log(σ Y /σ X) = 0. Supplementary material, proposition 7 in Appendix A, provides a justification for unambiguously using a ratio of standard deviations in this figure, rather than σ Y and σ X as separate axes. The two major regimes of Equation 1 are also marked in red. In Regime 1, Y is more variable than X, so contributes more variance to Δ, and r(X,Δ) ≈ r(X, Y). In Regime 2, X is more variable than Y, so X contributes more variance to Δ, and r(X,Δ) ≈ r(X,−X) (i.e. −1). The transition between the two regimes, when the variability ratio is not dramatically skewed either way, also allows for spurious r(X,Δ). For the purposes of illustration, the figure also highlights six points of interest on the surface, marked A–F; examples of simulated recovery data corresponding to these points are provided in Fig. 3.

---

### Multidimensional hyperspin machine [^82c9bb00]. Nature Communications (2022). High credibility.

Fig. 4
Network of D × N POs simulating N, D -dimensional hyperspins.

The coupling represents here a random complete K graph. The network is shown with N = 10 and embedded in a circular geometry. a, b, c, d Full PO network for D = 1, 2, 3, 4 as in the legends. Green and red lines represent positive end negative entries of the adjacency matrix J, respectively. e, f, g, h Hyperspin representation in the x y z -space of the PO network, where hyperspins are represented as in Fig. 1. The steady-state values of the real-part of the PO amplitudes dynamics X j (t) from the numerical integration of Eq. (5) determine the state of the spins (see Supplementary Note 2 and Supplementary Movie 1).

In Fig. 5, we show a hyperspin glass, i.e. a solid three-dimensional system of N spins in the x y z -space in dimension D = 3 and D = 4 with nearest-neighbor interaction, arranged as a lattice of N = N x × N y × N z hyperspins. Panels a, e and c, g consider a uniform antiferromagnetic interaction, while panels b, f and d, h are with a random binary interaction, where as for the K graphs ∣ J q p ∣ is fixed and its sign is randomly chosen with equal probability. The spin state is obtained as in Fig. 4. For the antiferromagnetic interaction, we obtain from our simulations an antiferromagnetically oriented spin structure, represented by the arrows both for D = 3 and D = 4 with additional alternating sphere colors. For the other cases (panels b, f and d, h), as for the K graph in Fig. 4, the spin orientation is random due to the disordered interaction. It is important to remark that general spin models have impact in many fields. Notable examples include the Isingand the Heisenberg spin glassfor D = 1 and D = 3, respectively, and the finite-temperature phase transition in QCD with two light-quark flavors for D = 4.

---

### An embedding-based distance for temporal graphs [^3493f5a4]. Nature Communications (2024). High credibility.

Temporal graphs are commonly used to represent time-resolved relations between entities in many natural and artificial systems. Many techniques were devised to investigate the evolution of temporal graphs by comparing their state at different time points. However, quantifying the similarity between temporal graphs as a whole is an open problem. Here, we use embeddings based on time-respecting random walks to introduce a new notion of distance between temporal graphs. This distance is well-defined for pairs of temporal graphs with different numbers of nodes and different time spans. We study the case of a matched pair of graphs, when a known relation exists between their nodes, and the case of unmatched graphs, when such a relation is unavailable and the graphs may be of different sizes. We use empirical and synthetic temporal network data to show that the distance we introduce discriminates graphs with different topological and temporal properties. We provide an efficient implementation of the distance computation suitable for large-scale temporal graphs.

---

### Predicting metabolic adaptation from networks of mutational paths [^fbb850cd]. Nature Communications (2017). Medium credibility.

Centrality convergence (error) for incomplete networks

To characterize how a statistic of a centrality converges to its value when the network is complete as a function of the degree of a network's completion, we used a scale-free measure of error. Let x (c, Δ S max) be the value of the statistic for networks at completion c (fraction of edges of the complete network included in the incomplete network) and maximum size of mutation Δ S max. Then letbe the normalized value of x (c, Δ S max). The minimum and maximum are taken over all values of completion, c, and over all samples and so establish the observed range of values of the statistic. This normalization ensures that y (c, Δ S max) ∈ [0, 1] for all samples. We defined the normalized error for this sample process aswhere y (1, Δ S max) is the normalized value of the statistic when the entire graph is discovered (i.e. when graph completion is 1 and all edges are known). We define the feature convergence error as the mean of e (c, Δ S max) taken over all samples in the data set of partial graphs. We repeat this procedure for all twelve centrality statistics (Supplementary Fig. 9).

---

### Decoupling of brain function from structure reveals regional behavioral specialization in humans [^c806d5b1]. Nature Communications (2019). High credibility.

Results

Harmonics of the structural connectome

The structural connectome (Fig. 1 a) can be modeled as a graph from which the harmonic components can be computed by the eigendecomposition of the Laplacian. Harmonic components, as illustrated in Fig. 1 b, are graph signals — values associated to nodes — that maximally preserve distances on the graph. Therefore, they provide a natural spectral representation of any graph signal in terms of increasing complexity, which corresponds to the notion of frequency. To confirm this intuition, Supplementary Fig. 1 reports the weighted zero crossings along the graph structure for each harmonic component. Low-frequency ones (examples shown in Fig. 1 b) capture brain patterns of global and slow variations along the main geometrical axes (e.g. anterior–posterior, left–right), while higher frequencies encode increasingly complex and localized patterns. This type of cortical decomposition is similar to results obtained with the same technique on different parcellations, as well as with different approaches; e.g. neural field theory.

Fig. 1
Method pipeline. a Structural connectome (SC) betweenatlas regions, displayed in logarithmic scale. b SC eigendecomposition leads to structural harmonics with increasing spatial frequency. c Brain activity at every time point is written as a linear combination of harmonics (by using coefficients). The median-split criterium on the activity energy spectral density(inset) is used to split the spectrum and decompose brain activity into coupled/decoupled portionsand(using low/high-frequency harmonics, respectively; = harmonic frequency). The ratio between decoupled/coupled signal norms is defined as structural-decoupling index. d Surrogate functional signals are generated with/without knowledge of SC, by spectral coefficient randomization. Average functional connectomes (FC) obtained from correlating pairs of empirical/surrogate functional signals are compared

Brain activity couples with the structural connectome

Resting-state activity is then projected on the structural-connectome harmonics –; i.e. for each timepoint, the spatial pattern of activation is represented as a weighted linear combination of harmonic components (Fig. 1 c). The time-averaged squared weights form the energy spectral density of the resting-state activity, as shown in Fig. 1 c (inset) and Supplementary Fig. 2. One can notice that brain activity is expressed preferentially by lower-frequency components, following a trend that is reminiscent of power-law behavior.

---

### The making of the standard model [^0fc9a4ce]. Nature (2007). Excellent credibility.

A seemingly temporary solution to almost a century of questions has become one of physics' greatest successes.

---

### Adaptive erasure of spurious sequences in sensory cortical circuits [^7c7d3e5f]. Neuron (2022). Medium credibility.

A theory of spurious sequences

Given the ubiquity of spurious sequences, as indicated by our simulations, we wondered what mechanisms explained their appearance even under conditions that seemed to maximally work against them (i.e. non-sequential input and symmetric connections). For this, we began by considering a minimal, symmetrically connected circuit motif with only two units, representing individual neurons or small populations. We found that sequentiality arose mainly from two independent properties of the model. First, when these two units received inputs that were unequal in their magnitudes, such that unit 1 received much larger inputs than unit 2, unit 2 became mainly entrained (with some lag) by unit 1 rather than by its own external input (Figure 2 A). As a result, the activity of unit 2 trailed that of unit 1. Second, even with balanced input magnitudes, systematic lags between units could also develop due to unequal self-connection strengths (Figure 2 B). Self-connections alter the effective time constant with which neural populations integrate their inputs, such that larger self-connections result in slower input integration. Thus, in our example, unit 2 with excitatory self-connections trailed unit 1 with inhibitory self-connections. We were able to show (Figure 2 D; Note S2) that the presence and magnitude of these two basic motifs together accurately predict the appearance of spurious sequences (i.e. the total amount of temporal anti-symmetry, quantified by the numerator of our sequentiality measure, Equation 3) in a simple mathematical form:whereis the instantaneous covariance of the inputs of units i and j. The two motifs described above respectively correspond to the first and second terms of this sum.

Figure 2
A theory of spurious sequences

(A) A two-unit network with symmetric excitatory connections (, middle left), receiving inputs of unequal magnitude (variances, far left), produces outputs (shown as normalized firing rates, middle right) such that unit 2 (gray) trails unit 1 (black), as also shown by their CC function and the resulting sequentiality (far right).

(B) Same as (A), for a network of two units with only self-connections of opposite signs (, middle left), receiving strongly correlated inputs (covariance, far left).

(C) Same as (B), after adding specific asymmetric connections between the two units of the network (middle left), making its output temporally symmetric (middle and far right).

---

### The geometric nature of weights in real complex networks [^32082f38]. Nature Communications (2017). Medium credibility.

The topology of many real complex networks has been conjectured to be embedded in hidden metric spaces, where distances between nodes encode their likelihood of being connected. Besides of providing a natural geometrical interpretation of their complex topologies, this hypothesis yields the recipe for sustainable Internet's routing protocols, sheds light on the hierarchical organization of biochemical pathways in cells, and allows for a rich characterization of the evolution of international trade. Here we present empirical evidence that this geometric interpretation also applies to the weighted organization of real complex networks. We introduce a very general and versatile model and use it to quantify the level of coupling between their topology, their weights and an underlying metric space. Our model accurately reproduces both their topology and their weights, and our results suggest that the formation of connections and the assignment of their magnitude are ruled by different processes.

---

### Fluctuation-learning relationship in recurrent neural networks [^fcdc7cd4]. Nature Communications (2025). High credibility.

The spontaneous fluctuations along the target and input directions determine the learning speed

Generally, Δ J is determined by the neural state through a learning rule. To understand the relationship between the neural dynamics and Δ x * further, we adopt a Hebb-type learning ruleas this analysis. τ J is a time scale of the change in the connectivity. f (x) and g (x) are arbitrary N -dimensional functions determining the post- and pre-synaptic contributions in the Hebb-type learning, respectively. For simplicity, we consider the case of g(x) = x. Still, even for an arbitrary function g (x), the following analysis holds by replacing ∣ x ∣ 2 by g T (x) x.

This form widely covers various types of learning rules, e.g. those for associative memoryand I/O (η / ξ) mapping. For auto-associative memory, such as Hopfield model, the input pattern η is set to be identical to the target pattern ξ with f(x) = x, that is, the target itself is applied to the network as input. The associative memory with the Hopfield network is not the main concern of the paper, but, the theoretical relation between the spontaneous fluctuations and the learning speed is still valid, as shown in Supplementary Information.

---

### The snm procedure guideline for general imaging 6.0 [^fe5858aa]. SNMMI (2010). Medium credibility.

Single photon planar imaging — scintillation camera peaking should be performed correctly for the energy or energies to be used at least daily, typically using a 15 or 20% energy window; the window is placed symmetrically about the peak, or asymmetrically if an appropriate energy correction is available, and a physicist can help determine limits of asymmetry for a range of energies.

---

### Identifying domains of applicability of machine learning models for materials science [^9c5f816f]. Nature Communications (2020). High credibility.

A predictive ML model is then a functionaiming to minimize the expected error (also called prediction risk)measured by some non-negative loss function l that quantifies the cost incurred by predicting the actual property value y with f (x). Examples for loss functions are the squared error, the absolute error, and, for non-zero properties, the relative error. Here P denotes some fixed probability distribution that captures how candidate materials are assumed to be sampled from the materials class (this concept, while commonly assumed in ML, is an unnecessary restriction for high-throughput screening as we discuss in more detail below). Since the true prediction risk is impossible to compute directly without perfect knowledge of the investigated materials class, models are evaluated by the test error (or empirical risk)defined as the average of the individual errors (losses) e i (f) = l (f (x i), y i) on some test set of m reference data points. The samples in this test set are drawn independently and identically distributed according to P and are also independent of the model — which means in practice that it is a random subset of all available reference data that has been withheld from the ML algorithm. In order to reduce the variance of this estimate, a common strategy is cross-validation, where this process is repeated multiple times based on partitioning the data into a number of non-overlapping "folds" and then to use each of these folds as test sets and the remaining data as a training set to fit the model.

This test error properly estimates the model performance globally over the whole representation space X (weighted by the distribution P used to generate the test points). This is an appropriate evaluation metric for selecting a model that is required to work well on average for arbitrary new input materials that are sampled according to the same distribution P. This is, however, not the condition of high-throughput screening. Here, rather than being presented with random inputs, we can decide which candidate materials to screen next. This observation leads to the central idea enabled by the DA analysis proposed in this work: if the employed model is particularly applicable in a specific subdomain of the materials class, and if that subdomain has a simple and interpretable shape that permits to generate new materials from it, then we can directly focus the screening there.

---

### Input-output maps are strongly biased towards simple outputs [^50fca0dd]. Nature Communications (2018). Medium credibility.

Many systems in nature can be described using discrete input-output maps. Without knowing details about a map, there may seem to be no a priori reason to expect that a randomly chosen input would be more likely to generate one output over another. Here, by extending fundamental results from algorithmic information theory, we show instead that for many real-world maps, the a priori probability P(x) that randomly sampled inputs generate a particular output x decays exponentially with the approximate Kolmogorov complexity [Formula: see text] of that output. These input-output maps are biased towards simplicity. We derive an upper bound P(x)≲[Formula: see text], which is tight for most inputs. The constants a and b, as well as many properties of P(x), can be predicted with minimal knowledge of the map. We explore this strong bias towards simple outputs in systems ranging from the folding of RNA secondary structures to systems of coupled ordinary differential equations to a stochastic financial trading model.

---

### Bifurcation behaviors shape how continuous physical dynamics solves discrete ising optimization [^5aeb0a89]. Nature Communications (2023). High credibility.

Fig. 3
Trapped nodes and swing nodes that emerge during Ising dynamics and their impact on optimization.

a, b Schematic illustrations of the evolution of the state corresponding to a global minimum point x * (p) following Eq. (5) in Ising problems for which (a) p ✱ = p 0 (exact mapping arises right after first bifurcation), and (b) p * > p 0 (outlier). Outliers are accompanied by swing nodes, which bifurcate at higher pump rates (p 1. p *) during the evolution (retarded bifurcations). In the corresponding graphs blue(red) edges denote G i j = −1(+1), respectively. The nodes are colored according to the sign and magnitude of the steady-state components of the CIM dynamics. c, d Normalized counts of the magnitudes of the components of the maximum eigenvectors for models with (c) p ✱ = p 0 and (d) p * > p 0, computed from statistics of 1000 random instances with n = 5 variables. The brown curves are the kernel density estimations of the probabilities. e The plot shows the probability that a variable with magnitude proportional toat the first bifurcation changes its sign during subsequent evolutions of the CIM, sampled from 100 fully connected graphs with n = 100 variables, and edge weights picked at random from a Gaussian distribution with zero mean and standard deviation. The inset (similar to Fig. 2) visualizes the evolution of several nodes in a typical 100-node graph with trapping and oscillations explicitly shown.

The empirical observations made in Fig. 3 a, b guide us toward rigorous analytical results which we present in the following. Given the first non-trivial stable state, we quantify the degree of synchronization bywhere we denote σ 1 = sign(x 1). Note thatand if the components of x 1 are more centralized away from zero, the larger the value of α 2 (x 1). Then for any Ising Hamiltonian H (σ) (Eq. (1)), we have the following theorem.

---

### Dominance vs epistasis: the biophysical origins and plasticity of genetic interactions within and between alleles [^ad933d9a]. Nature Communications (2023). High credibility.

Model 1: protein folding

Phenotype is determined by the total concentration of folded protein. In this model, the protein of interest (X) expressed from each allele (α i, i ∈{1, 2} – one maternal and the other paternal copy respectively, and the alleles are allowed to be the wild type) has two configuration states: unfolded (X U, α i) and folded (X F, α i). The free energy difference between folded and unfolded protein states is ∆ G Folding, α i (kcal per mol). Mutations on each allele can affect folding energy (∆ G Folding), which is described as the sum of wild-type folding energy and the energy differences (mutations) ∆ G Folding, wt + ∆∆ G Folding, α i. Equilibrium between the two states follows Eq. (10).

In the above and following equations, R is the gas constant (R = 1.98 × 10 −3 kcal per mol), T is the absolute temperature for 37 °C (310.15 Kelvin) and the wild-type ∆ G Folding, wt is set to −2 kcal per mol unless stated otherwise.

The total concentration of the protein (X T) follows Eq. (11).

Expression levels from each allele were considered to be equal and therefore, [X T,1] = [X T,2] = 0.5 [X T] in all our models. Using Eqs. (10) and (11) with [X T] as a constant, we can calculate the functional molecule [X F, α i] as a function of energy terms and total protein concentration in the following way:

---

### Discovery of the exact 3D one-way wave equation [^74e3fd0c]. Nature Communications (2025). High credibility.

Discussion

As an example of the power of the above discovery, we shall now systematically design and engineer a 3D one-way device using Eq. (7) and (8), for which we can be certain – right from the beginning, owing to the above properties of Eq. (7) – that it is a topological one. Indeed, from the 'generator' Eq. (7), let us be steered by the properties of the sigma matrices (above Eq. (7)), and, in a targeted way, modify, e.g. k z to, say, b 0 – b 1 cos(k z), where b 0, b 1 are simply two arbitrary constants. We want our 3D one-way material to be made of multiple layers, and for each layer we want to have, say, a 2D honeycomb lattice structure, where each unit cell has two inequivalent sites (A and B sublattices). The so-designed 3D crystal structure consists of repeating the above 2D layers periodically along the z-axis. The in-plane lattice vectors are then:

---

### Resolving discrepancies between chimeric and multiplicative measures of higher-order epistasis [^7747af71]. Nature Communications (2025). High credibility.

Equation (21) demonstrates that X = (X 1, X 2) follows an exponential family distribution, a wide class of distributions that includes many common distributions including normal distributions or Poisson distributions. In particular, using the terminology of exponential families, equation (21) shows that the sufficient statistics of X are X 1, X 2, and X 1 X 2, with corresponding canonical parameters β 1, β 2, and β 12. As a result, the distribution P (X) is uniquely defined by the expected values E [X 1], E [X 2], E [X 1 X 2] of the sufficient statistics, sometimes called the moments or the mean parameters of the distribution. Thus, we obtain a third parametrization of the distribution P (X) using the moments μ 0 = 1, μ 1 = E [X 1], μ 2 = E [X 2], μ 12 = E [X 1 X 2]. The elements of the vector μ = (1, μ 1, μ 2, μ 12) of moments are sometimes called the mean parameters of the distribution.

---

### Using an ordinary differential equation model to separate rest and task signals in fMRI [^09e232d2]. Nature Communications (2025). High credibility.

Structural

To construct a network model for fMRI, it is assumed that the measured data is composed of both structured network activity and unstructured residual activity, as illustrated in Fig. 1 A. The network activity represents structured interactions and is modeled as relationships between distinct nodes. To construct this network, we fit a separate function for each edge in the network using a Taylor series polynomial p n via ridge regression and define the change in activity in a node as the sum of all its edges. A sparsity parameter determines the number of edges used to represent the ODE. To test whether these estimated edges are biophysically relevant, we examine the distribution of edge strengths with other measures of network connectivity using Structural Connectivity (S C) estimated from Diffusion Tensor Imaging (DTI). The coefficients are highly correlated (> 0.5 on average) for the odd orders of the polynomial for the edges within a hemisphere (intrahemisphere) while the even orders are smaller in magnitude and have low correlations (< 0.05 on average) with S C as shown in Fig. 1 C. We plotted the resulting odd edge functions using a derivative plot in Fig. 1 D. They are divided into four categories: (1) diagonal (self edges), (2) intrahemispheric, (3) contralateral (edges between homologous brain regions), and interhemispheric (excluding contralateral edges) in Fig. 1 D. They all consist of sigmoid functions, where the relationship is linear around the origin and plateaus at the extrema. The intrahemispheric and contralateral edges are positive sigmoid functions, but the interhemispheric connections (non-contralateral) have an opposite sign. The main difference between our identified network ODE and previously published BNMs is that our model has negative interhemispheric (non-contralateral) edges, while previously, all positive functions were used for edges to describe the network structure. The diagonal represents the decay term, and is a hyperparameter in our model, and affects the HRF (see Methods Sparse Identification of Nonlinear Dynamics). Setting values for this parameter, as well as other hyperparameters that control the sparsity of the overall network, are discussed in detail in Methods Optimization and Hyperparameters The identified network ODE depends on the data used for the ridge regression and is unique for the different Tasks and Rest (see Methods Differences between Task Models). In general, they exhibit similar properties as they all consist of sigmoidal edges with the relation shown above and are similar to previously used BNM constructed from S C, with the exception of interhemispheric inhibition due to the negative interhemispheric edge functions.

---

### Xenon (xenon, Xe-133) [^382e5366]. FDA (2024). Medium credibility.

PHYSICAL CHARACTERISTICS

Xenon Xe 133 decays by beta and gamma emissions with a physical half-life of 5.245 days. Photons that are useful for detection and imaging studies as well as the principal beta emission are listed in Table 2.

Table 2. Principal Radiation Emission Data

---

### Isolation by distance in populations with power-law dispersal [^8e2438e8]. G3 (2023). Medium credibility.

Wethen convert this to a two-dimensional vector y by drawing a direction uniformly at random. Finally, to keep lineages on a discrete lattice of demes, we round y to the nearest pair of integers, i.e. the closest point in, to obtain Δ X t. In the GNU Scientific Library, the scale of the Lévy alpha-stable distribution is parameterized not by D α but rather by c ≡ (D α) 1/ α, the characteristic spread c of each lineage after one generation (t = 1). We use c = 10 for all two-dimensional simulations with α < 2. Notice that (12) does not match the two-dimensional Lévy alpha-stable distribution ((47) below) that we use for our analytical approximations, so the match between the analytical results and the simulations shows that the results are robust to the details of the dispersal kernel.

To simulate steeper tails with α > 2, we follow the same procedure as in the previous paragraph, but instead of drawing the initial continuous dispersal distance y from (12), we draw it from a degenerate F-distribution:

where ω scales the characteristic single-generation dispersal distance. (Technically, we obtain y by drawing from the GNU Scientific Library F-distribution with degrees of freedom ν 1 = 2 and ν 2 = 2 α and scaling the result by ω.) Because this kernel has finite variance, the central limit theorem implies that at long times the bulk of the displacement distribution approaches that of a diffusive kernel, with dispersal constant D given by one-quarter the single-generation variance in position:

Weuse D = 200 for all two-dimensional simulations with α > 2.

For each pair of simulated dispersal trajectories { x t }, we then compute the path-specific distribution of coalescence times p ({ x t ′ ≤ t }), i.e. the probability of coalescing at and not before time t, and the path-specific mean homozygosity ψ ({ x t ′ ≤ ∞ }), i.e. the probability that lineages following these exact trajectories have not mutated before coalescence:

---

### Functional protein mining with conformal guarantees [^282fc321]. Nature Communications (2025). High credibility.

Our main tool will be to index some family of sets by a one-dimensional parameter. We will refer to this family of sets as. An example would bewhere f is a pre-trained machine learning model trained to predict whether x and y match. The methodologies exposed herein allow us to pick the parameter λ such that these sets have a small loss in a probabilistic sense, The parameteris picked based on a calibration procedure which uses a small dataset of proteins the model has not seen during training. We will call this calibration dataset X 1,…, X n, and we assume we can evaluate ℓ against any of the possible responses in. Then, we will deploy thethat is picked using this calibration data on a new, exchangeable protein X test.

The critical assumption in all the forthcoming techniques is the exchangeability of the calibration data and the test point. Exchangeability means that the joint distribution function of the calibration data and the test data point is invariant to permutations. As an example, i.i.d. data points are exchangeable; exchangeability is a weaker condition than this. Intuitively, this means that the calibration data must be representative of the test data, and not involve any deleterious distribution shifts. The particular technical condition required for our theory is that the vector of lossesis exchangeable for all λ — the exchangeability of the data points implies this fact, but it is technically weaker. In other words, exchangeability matters only insofar as the risk is concerned.

For clarity, we define some of the commonly utilized loss functions for our retrieved sets, false discovery rate (FDR) and false negative rate (FNR). Motivated by the desire to control against false significant hits, we define false discovery rate first. FDR measures the ratio between false positive hits (false discoveries) in our retrieved set of model-derived significant hits to the total number of hits (the size of our retrieved set). This is expressed as. The FNR, similarly, is the number of false negative significant hits (annotated hits not in the retrieval set) as a fraction of the total pool of possible hits, expressed as. For further literature relating to controlling FDR, we refer readers to.

---

### Scale-free networks are rare [^9c1c1630]. Nature Communications (2019). High credibility.

Real-world networks are often claimed to be scale free, meaning that the fraction of nodes with degree k follows a power law k -α, a pattern with broad implications for the structure and dynamics of complex systems. However, the universality of scale-free networks remains controversial. Here, we organize different definitions of scale-free networks and construct a severe test of their empirical prevalence using state-of-the-art statistical tools applied to nearly 1000 social, biological, technological, transportation, and information networks. Across these networks, we find robust evidence that strongly scale-free structure is empirically rare, while for most networks, log-normal distributions fit the data as well or better than power laws. Furthermore, social networks are at best weakly scale free, while a handful of technological and biological networks appear strongly scale free. These findings highlight the structural diversity of real-world networks and the need for new theoretical explanations of these non-scale-free patterns.

---

### Somatic symptom disorder [^28fa8cf4]. American Family Physician (2016). Medium credibility.

Regarding screening and diagnosis for somatic symptom disorder, more specifically with respect to diagnostic criteria, AAFP 2016 guidelines recommend to use the DSM-5 criteria to diagnose somatic symptom disorder.

---

### Automatic network structure discovery of physics informed neural networks via knowledge distillation [^ee0c8851]. Nature Communications (2025). High credibility.

Similarly, we construct a low-frequency solution to the PDEs (27) with the source term f = 0, ensuring the permutation property of the solution. The permutation property can be simplified using the permutation equivariant groupas ∀ h ∈ H e :The constructed solution is. The low-rank parameter matrix extracted for this low-frequency function is:

Similarly, the relationship between the two-dimensional input x = (x 1, x 2) and the node outputs u a, u b of the final hidden layer can be obtained:From the expressions of both, it follows that:Since the expression of the final output u (x 1, x 2) is:this result contains the symmetry defined in (30).

In order to match the network structure results with the characteristics of the high-frequency solution, by setting the sign of the values in b 1 to be the same, we can obtain:from which we have:thus, the final expression:which satisfies the symmetry of the high-frequency solution.

Moreover, the structure can be adjusted by sign to satisfy other forms of symmetry. For example, after (36), adjusting the sign of the weights in the last hidden layer can yield:that is, the Poisson equation result can be adjusted by sign to satisfy the central symmetry u r (x 1, x 2) = u r (− x 1, − x 2).

The numerical results are shown in Fig. 4 c. The iteration step size used in this problem is 1e−3, which is reduced to 0.2 times the original value at steps 5e3 and 1.5e4. The Ψ -NN re-constructed NN outperforms both PINN and PINN-post models in terms of speed and accuracy. Their L2 errors are summarized in Table 1. All three models exhibit peak errors along the line x 2 = − x 1 + 1, but Ψ -NN maintains a lower overall error, particularly at the boundaries. In contrast, the other models in the control group show large gradient errors at local boundaries, highlighting Ψ -NN's superior performance in high-frequency fitting.

---

### Global strategy for the diagnosis, management, and prevention of chronic obstructive pulmonary disease (2025 report) [^6788fdd0]. GOLD (2025). High credibility.

Regarding screening and diagnosis for chronic obstructive pulmonary disease, more specifically with respect to diagnosis, GOLD 2025 guidelines recommend to obtain spirometry to establish the diagnosis of COPD by eliciting a post-bronchodilator FEV1/FVC < 0.70 confirming the presence of persistent airflow limitation.

---

### Ultrafast photonic micro-systems to manipulate hard X-rays at 300 picoseconds [^21d9e8b4]. Nature Communications (2019). High credibility.

Since MEMS devices are based on single-crystal silicon (see Methods), X-ray diffraction occurs at the Bragg angle, θ B, at which the incident X-rays satisfy the Bragg condition. Due to the dynamical diffraction process, the angular width of the diffraction condition is not zero, but has a finite value (Δ θ B, or rocking curve width), as illustrated in Fig. 1b. As the MEMS device oscillates around θ B (Fig. 1a), the single-crystal element will diffract the X-rays for the short amount of time in which the Bragg condition is satisfied, and the element will transmit and absorb the X-rays over the rest of the cycle. The oscillatory device transforms the static rocking curve into a dynamic one in the time domain, i.e. DTW (Fig. 1c). The maximum angular speed of the MEMS device determines the width of the DTW over which the Bragg condition is fulfilled. For use as a monochromatic X-ray optic, the width of the DTW, Δ t w, is given bywhere f and α are the MEMS oscillation frequency and amplitude, respectively. In order to interact with X-ray pulses while preserving their spatiotemporal correlation, a MEMS device must perform as an X-ray diffractive element with the highest reflectivity while maintaining this performance at high speeds without introducing any distortion to the incident X-ray wavefront.

---

### Memristor-based adaptive neuromorphic perception in unstructured environments [^7ca8eda4]. Nature Communications (2024). High credibility.

Notably, in our tactile experiments, the scalar used to determine to the memristive modulation schemes is the memristor resistance, thus M (x (t- 1)) refers to the observed memristor resistance value after the last modulation. V is a condition function based on current stimulus strength f (t) and memristor resistance value M (x (t- 1)) to generate the modulation voltages v (t), as shown in Supplementary Table 1. In visual experiments, the memristor state is not used to stimulate the memristor, and V is a condition function based on the current frequency of light stimuli f light as below:Where f high and f low represent high-frequency and low-frequency change features, respectively, and the remaining parameters are constant coefficients.

As explained, the proposed method provides a human-like information processing pipeline, which extracts key features of undergoing stimuli in real-time, opening the possibility for intelligent machines to operate in unstructured environments efficiently.

---

### Elagolix (Orilissa) [^ecfdd123]. FDA (2023). Medium credibility.

2 DOSAGE AND ADMINISTRATION

Normal liver function or mild hepatic impairment: 150 mg once daily for up to 24 months or 200 mg twice daily for up to 6 months. (2.1)

Moderate hepatic impairment: 150 mg once daily for up to 6 months. (2.1)

2.1 Important Dosing Information

Exclude pregnancy before starting ORILISSA or start ORILISSA within 7 days from the onset of menses.
Take ORILISSA at approximately the same time each day, with or without food.
Use the lowest effective dose, taking into account the severity of symptoms and treatment objectives [see Warnings and Precautions (5.1, 5.3, 5.4) and Clinical Studies (14)].
Limit the duration of use because of bone loss (Table 1) [see Warnings and Precautions (5.1)].

2.2 Hepatic Impairment

No dosage adjustment of ORILISSA is required in women with mild hepatic impairment (Child-Pugh A).

Compared to women with normal liver function, those with moderate hepatic impairment had approximately 3-fold higher elagolix exposures and those with severe hepatic impairment had approximately 7-fold higher elagolix exposures. Because of these increased exposures and risk for bone loss:

ORILISSA 150 mg once daily is recommended for women with moderate hepatic impairment (Child-Pugh B) with the duration of treatment limited to 6 months. Use of ORILISSA 200 mg twice daily is not recommended for women with moderate hepatic impairment [see Use in Specific Populations (8.7) and Clinical Pharmacology (12.3)].
ORILISSA is contraindicated in women with severe hepatic impairment (Child-Pugh C) [see Contraindications (4), Use in Specific Populations (8.7) and Clinical Pharmacology (12.3)].

2.3 Missed Dose

Instruct the patient to take a missed dose of ORILISSA on the same day as soon as she remembers and then resume the regular dosing schedule.

150 mg once daily: take no more than 1 tablet each day.
200 mg twice daily: take no more than 2 tablets each day.

---

### 2023 ESC guidelines for the management of cardiomyopathies [^3f25e9a4]. European Heart Journal (2023). High credibility.

Regarding screening and diagnosis for hypertrophic cardiomyopathy, more specifically with respect to screening of family relatives, follow-up, ESC 2023 guidelines recommend to obtain clinical evaluation using a multiparametric approach, including ECG, cardiac imaging, and long-term follow-up, in first-degree relatives with the same disease-causing variant as the proband after cascade genetic testing.

---

### In situ single-shot diffractive fluence mapping for X-ray free-electron laser pulses [^fecead05]. Nature Communications (2018). Medium credibility.

Fig. 3
Schematic evolution of our grating design from regular gratings. The images show the real-space structures a – c and respective diffraction pattern d – f. a A regular grating diffracts incoming light to two symmetric points in Fourier-space d and hence reveals no spatial information on the illumination function. b A two-by-two segmented grating yields two symmetric sets of four diffraction spots e. The intensity of each spot is proportional to the illumination of the corresponding sample quadrant. This constitutes the most basic form of a spatially resolving beam profile monitor based on an integrated grating. c A grating with suitably varying period and orientation forms a magnified image of its own illumination in Fourier-space f. The colors in the real-space images indicate the local grating period and mark the corresponding points in the diffraction images

We start with the following sinusoidal transmission function for a regular grating:Here, ξ and η are spatial coordinates in the sample plane, while p and φ are the grating period and orientation angle, respectively. They are given by the position (x, y, z det) of the grating's first diffraction order in the detector plane:

We turn φ and p into functions of the sample coordinates by setting

When inserted into Eq. (1), the result is a grating, the pitch and orientation of which varies continuously and that diffracts an image of its own illumination function, magnified by the dimensionless parameter m and centered at (x 0, y 0), to the detector. We note that the thereby obtained structures constitute segments of Fresnel zone plates (Supplementary Note 1).

Since Eqs (2) and (3) relate to far-field diffraction, the mapping is only valid if the detector is sufficiently far away from the sample to be in the Fraunhofer regime. Specifically, this requireswhere w 0 is the beam's waist size on the sample.

In simulations with Gaussian beams, we observe that the following condition must simultaneously be satisfied:

This relation enforces that the illumination does not change drastically within a small number of grating periods, which would lead to errors in the diffracted fluence maps (see Supplementary Notes 1 and 2 for a detailed discussion).

---

### Phase-encoded fMRI tracks down brainstorms of natural language processing with subsecond precision [^7d590922]. Human Brain Mapping (2024). Medium credibility.

2.8 Functional image analyses

For each BRIK file of a functional scan containing (x, y, z, t) = 64 × 64 × 55 × 256 data points, a 256‐point discrete Fourier transform was applied to the time series x m (t) of each voxel m at location (x, y, z) by:where X (ω) is the Fourier component at each frequency ω between 0 and 127 cycles per scan, and | X m (ω)| and θ m (ω) represents the amplitude and phase angle, respectively. The task frequency is defined as ω s (16 cycles per scan), denoting the frequency of periodic fluctuations of blood flow in response to periodic stimuli and tasks. The remaining nontask frequencies are defined as ω n. The signal and noise are defined as the Fourier components X m (ω) at frequencies ω s and ω n, respectively. The statistical significance of periodic fluctuations of blood flow is evaluated by the signal‐to‐noise ratio, an F ‐ratio (Chen et al; Huang et al; Sereno et al; Sereno & Huang; Sood & Sereno,), in each voxel m by:where df s = 2 and df n = 230 are the degrees of freedom of the signal and noise, respectively. The p ‐value in each voxel m is estimated by the cumulative distribution function F (2,230) = F (F m; df s, df n) (Chen et al; Huang et al; Press et al.). A complex F ‐value, (F m_r, F m_i), incorporating both the F ‐statistic value and the phase angle, θ m (ω s), of each voxel was computed by F m_r = f m cos(θ m (ω s)) and F m_i = f m sin(θ m (ω s)), where f m is the square root of F m. Voxels containing strong periodic signals at the task frequency (ω s = 16 cycles per scan) with F (2,230) > 4.7 (p < .01, uncorrected), F (2,230) > 7.1 (p < .001, uncorrected), or F (2,230) > 9.6 (p < .0001, uncorrected) were retained and their phase angles were color‐coded in a range between 0 and 2π (0–16 s) and painted on each individual subject's cortical surfaces for each scan using csurf (Figure 3). The complex F ‐values of corresponding voxels m were vector‐averaged (voxel‐wise) across two scans k = {1, 2} of the same task in each session for each subject S using:which was performed by the "Combine 3D Phase Stats" function of csurf. The resulting average complex F ‐valueswere then painted on individual subject's cortical surfaces.

---

### A cochlear-bone wave can yield a hearing sensation as well as otoacoustic emission [^4a2d305b]. Nature Communications (2014). Medium credibility.

The coefficients G 1 (k) and G 2 (k) are defined as follows:

Here we have used the abbreviation L (k) = [2 i ω ρ (F 1 + F 2) w bm +3 F 1 F 2 Z bm (x)]/[3 A 1 A 2 Z bm (x)] with F 1/2 = A 1/2 k 2 − cω 2 ρ. The dispersion relation L(k) = 0 has been derived from the eigenvalues of the matrix equation (10).

The Green's functions for bone stimulation can be derived analogously. Assume that both cochlear chambers, at a certain longitudinal location x 0, are sinusoidally compressed and expanded:

We make the following ansatz for the Greens functions:

which yields the amplitude equations

The solutions are

with L (k) as given above. In the symmetric case of equal chamber areas, A 1 = A 2, we obtain W 1 (k) = W 2 (k). No basilar-membrane displacement then arises, because the pressures in both chambers are equal.

When attempting to compute the integral in the ansatz for the Green's functions (equations (25) and (29)), we encounter a problem: the integrand has a singularity at the wave vectors k for which L (k) = 0, that is, at those wave vectors that obey the dispersion relation. However, we can employ the residue theorem of complex analysis to compute the integrals. Indeed, for propagation apical of the generation site, that is at a location x < x 0, we can close the contour in the upper-half plane because the integrand there is exponentially suppressed. The integral then only involves a contribution from the poles in the upper-half plane. In the case of basilar-membrane stimulation, we obtain a contribution proportional to. The pressures p 1/2 (− k bm, ω, x 0) represent the pressures of the basilar membrane mode in the two chambers

Analogous results can be obtained for the cochlear-bone wave with k cb (x).

In the opposite case, for a cochlear location basal to the generation site, x > x 0, the integration path can be closed in the lower-half plane.

---

### Learning molecular dynamics with simple language model built upon long short-term memory neural network [^1a5f59be]. Nature Communications (2020). High credibility.

Embedding layer captures kinetic distances

In word embedding theory, the embedding layer provides a measure of similarity between words. However, from the path probability representation, it is unclear how the embedding layer works since the derivation can be done without embedding vectors x. To have an understanding to Q l m in the first-order Markov process, we first write the conditional probabilityexplicitly with softmax defined in Eq. (8) and embedding vectors x defined in Eq. (1):where f is the recursive function h (t) = f θ (x (t), h (t −1)) ≈ f θ (x (t)) which is defined with the update equation in Eq. (2)–(7). In Eq. (17), θ denotes various parameters including all weight matrices and biases, and the summation index k runs over all possible states. Now we can use multivariable Taylor's theorem to approximate f θ as the linear term around a point a as long as a is not at any local minimum of f θ :where A θ is the L by M matrix defined to be. Then Eq. (17) becomeswhere. We can see in Eq. (19) how the embedding vectors come into the transition probability. Specifically, there is a symmetric form between output one-hot vectorsand the input one-hot vectors s (t), in which x (t) = Λ s (t) and Λ is the input embedding matrix, D d A θ can be seen as the output embedding matrix, andis the correction of time lag effect. While we do not have an explicit way to calculate the output embedding matrix so defined, Eq. (19) motivates us to define the following ansatz for the transition probability:where x m and x l are both calculated by the input embedding matrix Λ. The expression in Eq. (20) is thus a tractable approximation to the more exact transition probability in Eq. (19). Furthermore, we show through numerical examples of test systems that our ansatz for Q l m does correspond to the kinetic connectivity between states. That is, the LSTM embedding layer with the transition probability through Eq. (20) can capture the average commute time between two states in the original physical system, irrespective of the quality of low-dimensional projection fed to the LSTM –.

---

### Isolation by distance in populations with power-law dispersal [^0d61ac37]. G3 (2023). Medium credibility.

Generic dispersal

For generic dispersal, the solution for ψ in two dimensions can again be found from (28), now with the integral over two spatial dimensions. The Fourier transformhas the same form as the one-dimensional equation (31):

whereagain we make the approximation that 1 − ψ (x) is approximately constant over the x values whereis non-negligible. This is again accurate for ψ (0) ≪ 1, but may need to be adjusted for 1 − ψ (0) ≪ 1. While (46) looks exactly like the one-dimensional expression (31), its interpretation is different: k is now the magnitude (wavenumber) of the two-dimensional spatial frequency vector (wave vector), k = | k |. Note that because dispersal is isotropic, (46) has no angular dependence. The key point is that if we want to transform (46) back to real space, we now must use the two-dimensional inverse Fourier transform. For pairs that are far outside coalescence range, x ≫ δ, the simple relation (30) between ψ (x) andstill holds.

Lévy flight dispersal

For a two-dimensional Lévy flight, the dispersal kernel of a single lineage takes the form of an isotropic stable distribution:

where K (y | t) is the probability density of being at a particular point a distance y away from the initial position at time t, and J 0 is the zeroth Bessel function of the first kind. As in one dimension, the density for the displacement between the two Lévy flights is the same, but with twice the dispersal constant:

(48) is the two-dimensional inverse Fourier transform (equivalently, the inverse zeroth-order Hankel transform) of the characteristic function. The Fourier–Laplace transform is again. At large distances, y ≫ (D α t) 1/ α, K has a power-law tail:

Intwo dimensions, we must allow coalescence to take place at a finite distance for all α. For the coalescence kernel, we use an isotropic normal distributionwith mean zero and standard deviation δ, with coalescence taking place at rate. Inverting the Fourier transform in (46) then gives:

Theanalysis of (51) parallels that of the one-dimensional case, but all α < 2 can be treated together for all distances x, not just, and so we can conduct one unified analysis moving from short distances to long ones.

---

### Defining functional interactions during biogenesis of epithelial junctions [^72a1481a]. Nature Communications (2016). Medium credibility.

Phenotypic clustering

As the data set do not follow a Gaussian distribution (see Statistic section), we optimized the methodology to classify the candidate proteins into distinct groups with functional relevance for the regulation of E-cadherin and F-actin at junctions. Each of 156 data points in the candidate protein data set is a three-dimensional vector that contains the Z -scores for E-cad, Jun-A and Cyt-A. Using MATLAB (The MathWorks), we evaluated three different methods(K-means, hierarchical or spectral clustering) and two different distances (Euclidean and Mahalonobis). The Mahalanobis distancebetween any two data points X and Y is computed here by d M (X, Y), which is transformed into a similarity measure via s(X, Y) = exp (−(d M (X, Y)) 2 / (2 σ 2)), where we set σ = 1. For spectral clustering, we used the mutual k-nearest neighbour graph with 30 neighbours and computed the normalized graph Laplacian. For optimization of the parameters, we used a modified version of MatLab GUI (Graph Demo), which can be assessed in.

---

### 2023 ESC guidelines for the management of cardiomyopathies [^88aecf89]. European Heart Journal (2023). High credibility.

Regarding screening and diagnosis for hypertrophic cardiomyopathy, more specifically with respect to screening of family relatives, follow-up, ESC 2023 guidelines recommend to obtain initial clinical evaluation using a multiparametric approach, including ECG and cardiac imaging, in first-degree relatives when no pathogenic/likely pathogenic variant is identified in the proband or genetic testing is not obtained.

---

### Symmetry group factorization reveals the structure-function relation in the neural connectome of caenorhabditis elegans [^ccfe5340]. Nature Communications (2019). High credibility.

Discussion

Overall, the structure-function relation in the connectome can be seen as a refining process of nested symmetry building blocks. The primary building blocks are defined through the mechanism of direct product factorization of normal subgroups and provide a rigorous characterization of the network connectivity structure, and a simple interpretation of its major functions into neural classes. These major sectors are comprised of secondary topological structures involved in signal processing which refine the primary normal subgroups into irreducible blocks of imprimitivity.

The factorization of the symmetry groups of the connectome has its analogy with integers and primes as every integer can be factorized into a unique product of prime numbers as stated in the fundamental theorem of arithmetic. This factorization is also analogous to that of the Standard Model of particle physics. In theoretical physics, automorphisms describe the symmetries of elementary particles and forces, as well as atoms, molecules and phases of matter. For example, fundamental forces in particle physics are based on symmetry principles incorporated through a description of the gauge symmetry group of the Lagrangian factorized into three subgroups as, whereis the special unitary group ofunitary matrices with determinant 1, andis the group consisting of all complex numbers with absolute value 1. In this case, each subgroup determines a different force, namely the electroweak and strong forces, and the generators of these symmetry subgroups are the particles. Analogously, the functions of locomotion are based on the symmetries of the connectome through the symmetry group which is factorized in general aswhere each symmetry subgroup determines a different function. For instance, the symmetry group of the chemical forward circuit splits as:

In a milestone in the history of mathematics, all finite simple groups have been discovered and classified into 3 major classes: cyclic, alternating or Lie type plus 26 extra classes of rare sporadic groups. Out this variety, the locomotion connectome contains only cyclic groups. It would be fascinating to discover other naturally occurring simple groups for other functions in different biological networks. Results presented elsewhere indicate that symmetries extend to the full connectome and also to genetic networks, and they are naturally related to neural synchronization. Thus, the principle of symmetry provides a rigorous mathematical characterization of the structural and functional organization of connectomes down to their information-processing units. This hierarchical symmetric architecture may also serve as guidance to design more efficient artificial neural networks inspired by natural systems.

---

### Standards of care in diabetes – 2025 [^31be65a6]. Diabetes Care (2025). High credibility.

Regarding diagnostic investigations for hypoglycemia, more specifically with respect to screening for cognitive impairment, ADA 2025 guidelines recommend to simplify diabetes treatment plans as much as possible for patients with cognitive impairment and tailor to minimize the risk of hypoglycemia.

---

### Using synchronized oscillators to compute the maximum independent set [^c5524e12]. Nature Communications (2020). High credibility.

Not all computing problems are created equal. The inherent complexity of processing certain classes of problems using digital computers has inspired the exploration of alternate computing paradigms. Coupled oscillators exhibiting rich spatio-temporal dynamics have been proposed for solving hard optimization problems. However, the physical implementation of such systems has been constrained to small prototypes. Consequently, the computational properties of this paradigm remain inadequately explored. Here, we demonstrate an integrated circuit of thirty oscillators with highly reconfigurable coupling to compute optimal/near-optimal solutions to the archetypally hard Maximum Independent Set problem with over 90% accuracy. This platform uniquely enables us to characterize the dynamical and computational properties of this hardware approach. We show that the Maximum Independent Set is more challenging to compute in sparser graphs than in denser ones. Finally, using simulations we evaluate the scalability of the proposed approach. Our work marks an important step towards enabling application-specific analog computing platforms to solve computationally hard problems.

---

### Higher-order connectomics of human brain function reveals local topological signatures of task decoding, individual identification, and behavior [^936ab2a1]. Nature Communications (2024). High credibility.

Results

We rely on a recent topological methodthat combines topological data analysis, and time series analysis to reveal instantaneous higher-order patterns in fMRI data. This approach builds upon prior work involving edge-level signals and the extension of functional connectivity research beyond pairs, leveraging low-order signals to define higher-order ones (a reconstruction task that is in general an ill-posed inverse problem). The approach consists of four key steps, as depicted in Fig. 1 a–d. (i) We start by standardizing the N original fMRI signals through z -scoring (Fig. 1 a). (ii) We then compute all possible k -order time series as the element-wise products of k + 1 of these z -scored time series, which are further z -scored for cross- k -order comparability (Fig. 1 b). These k -order time series represent the instantaneous co-fluctuation magnitude of the associated (k + 1)-node interactions, such as edges and triangles. We finally assign a sign to the resulting k -order time series at each time based on a strict parity rule: positive for fully concordant group interactions (nodes times series have all positive or all negative values at that timepoint), and negative for discordant interactions (a mixture of positive and negative values). Notice that this sign remapping allows us to explicitly focus on perfectly coherent contributions, which are always marked as positive (see also Methods for the analytical formulation). (iii) For each time t, we encode all instantaneous k -order (co-fluctuation) time series into a single mathematical object: a weighted simplicial complex (Fig. 1 c). We define the weight of each simplex as the value of the associated k -order time series at that timepoint. (iv) Finally, at each time t, we apply computational topology tools to analyze the weights of the simplicial complex and extract two global and two local indicators (see Methods). The rationale for this is that we are interested in assessing the capacity of higher-order indicators to encode human brain function along two axes: the first one, along the spatial gradient (i.e. whole-brain versus local connectivity structures); the second, along the complexity gradient (i.e. low- versus higher-order functional interactions).

---

### CREB controls cortical circuit plasticity and functional recovery after stroke [^f81fac82]. Nature Communications (2018). Medium credibility.

Fig. 6
Quantitative mapping of motor system connections after stroke and with CREB induction. a, c, e Each map represents all of the digitally mapped connections from all the animals in each condition (n = 4 for each condition) from M1 anterior to the stroke site, collapsed onto a representative tangential section through the mouse cortical hemisphere. The Y and X axes show mm distance from the center of the tracer injection site. The dark blobs on the maps are the location of the primary somatosensory vibrissal field (the "barrel" field). Light blue label corresponds to the condition in the light blue labeled text at the top of each panel; red corresponds to the condition in the red label at the top of each panel; and dark blue is dense overlap. b, d, f In polar plots of connections of forelimb motor cortex projections the plot is made relative to the tracer injection in forelimb motor cortex as the origin. Each filled polygon (blue and red) is the 70th percentile of the distances of all BDA-labeled connections from the injection site in each segment of the graph. The lines in these plots are the median vector of that segment of the plot, multiplied by the median of the normal distribution of the number of points in a given segment of the graph. P value is Hotelling's T 2. g Schematic summary of axonal sprouting after stroke with CREB induction

New connections in peri-infarct cortex in stroke can be detected in both genetic approaches in delivery of CREB; in particular we observed a significant increase in BDA-labeled projections after stroke in motor cortex in lenti-CREB (n = 4, Hotelling's t 2 test P < 0.021) mice with stroke when compared, respectively, with their controls (CREB virus alone, Fig. 6c, d) or with the control virus (control (non-CREB) virus plus stroke, P < 0.029) (Fig. 6e, f). Lenti-CREB alone in the normal, non-stroke brain does not promote axonal sprouting (lenti-CREB alone vs control virus: n = 4, P = 0.25, Fig. 6a, b). These data indicate that induction of CREB in forelimb motor cortex produces axonal sprouting, particularly in motor-to-premotor connections, a pattern that is associated with functional recovery –.

---

### Colorectal cancer screening and prevention [^390b568a]. American Family Physician (2025). High credibility.

Regarding screening and diagnosis for colon cancer, more specifically with respect to indications for screening, high-risk individuals, family history, AAFP 2025 guidelines recommend to obtain CRC screening in patients with ≥ 1 first-degree relatives with CRC or adenomatous polyps, starting at 40 years of age or 10 years before the age of the youngest relative at the time of their diagnosis.

---

### X-ray holography with a customizable reference [^a6520a89]. Nature Communications (2014). Medium credibility.

In X-ray Fourier-transform holography, images are formed by exploiting the interference pattern between the X-rays scattered from the sample and a known reference wave. To date, this technique has only been possible with a limited set of special reference waves. We demonstrate X-ray Fourier-transform holography with an almost unrestricted choice for the reference wave, permitting experimental geometries to be designed according to the needs of each experiment and opening up new avenues to optimize signal-to-noise and resolution. The optimization of holographic references can aid the development of holographic techniques to meet the demands of resolution and fidelity required for single-shot imaging applications with X-ray lasers.

---

### Environmental conditions and community evenness determine the outcome of biological invasion [^9014480d]. Nature Communications (2013). Medium credibility.

Biological invasion is widely studied, however, conclusions on the outcome of this process mainly originate from observations in systems that leave a large number of experimental variables uncontrolled. Here using a fully controlled system consisting of assembled bacterial communities, we evaluate the degree of invasion and the effect on the community functionality in relation to the initial community evenness under specific environmental stressors. We show that evenness influences the level of invasion and that the introduced species can promote functionality under stress. The evenness-invasibility relationship is negative in the absence and neutral in the presence of stress. Under these conditions, the introduced species is able to maintain the functionality of uneven communities. These results indicate that communities, initially having the same genetic background, in the presence of the same invader, react in a different way with respect to invasibility and functionality depending on specific environmental conditions and community evenness.

---

### Frequency spectra and the color of cellular noise [^9455c8ec]. Nature Communications (2022). High credibility.

It is known from ref.that the combined closed-loop dynamics is ergodic and mean steady-state protein copy-number is μ / θ

As discussed in ref. this ergodicity is preserved under certain conditions when an extra negative feedback from protein X 2 to the production of mRNA X 1 is added. Letting z 1 and x 2 denote the copy-numbers of Z 1 and X 2, respectively, we add the extra feedback by changing the rate of the actuation reaction from k z 1 to (k z 1 + F b (x 2)) where F b is a monotonically decreasing feedback function which takes non-negative values. As in ref. we consider two types of feedback. Lettingto be the reference point, the first is Hill feedback of the formwhich is based on the actual output copy-number x 2, while the second is the proportional feedback that is essentially the linearisation of the Hill feedback at the reference pointOne can easily see that at the reference point, the values of this feedback functionand its derivative(equal to − k fb) are the same for both types of feedback. We can view k fb as the feedback gain parameter. The Hill feedback is biologically more realisable, while the proportional feedback captures the classical controller where the feedback strength depends linearly on the deviation of the output x 2 from the reference point, in the output range. In our analysis, we set the reference pointas the set-point μ / θ.

---

### Coagulation factor X human (Coagadex) [^d1005563]. FDA (2024). Medium credibility.

Labeled indications for Factor X (also known as Coagadex) include:

- Prevention of bleeding episodes in adults with factor X deficiency
- Treatment of bleeding episodes in adults with factor X deficiency

---

### Colorectal cancer screening and prevention [^953f9e55]. American Family Physician (2025). High credibility.

Regarding screening and diagnosis for rectal cancer, more specifically with respect to indications for screening, general population, aged 45–49 years, AAFP 2025 guidelines recommend to obtain periodic screening for CRC in adults aged 45–49 years at average risk with no signs or symptoms of the condition.

---

### ACC appropriate use criteria methodology: 2018 update: a report of the American college of cardiology appropriate use criteria task force [^cbffef90]. Journal of the American College of Cardiology (2018). Medium credibility.

ACC Appropriate Use Criteria methodology — rating process initiates with an independent first round in which each rating panel member submits numerical ratings independently.

---

### 2018 ESC guidelines for the diagnosis and management of syncope [^a595c754]. European Heart Journal (2018). Medium credibility.

Regarding screening and diagnosis for syncope, more specifically with respect to diagnostic criteria (cardiac syncope, structural), ESC 2018 guidelines recommend to confirm cardiac ischemia-related syncope when syncope presents with evidence of acute myocardial ischemia with or without myocardial infarction.

---

### Inhibitory interactions promote frequent bistability among competing bacteria [^ffecc008]. Nature Communications (2016). Medium credibility.

Proving requirement of pairwise bistability for coexistence

We will show that coexistence through the interplay between antibiotic production and degradation requires at least one bistable pair in the 'Mixed Inhibition-Zone Model' introduced in ref.for the case where antibiotic producers do not derive immediate benefit from inhibiting neighbours.

Coexistence requires the fastest growing species to be inhibited by another community member. If this were not the case, it would have the highest fitness for any combination of species abundances, and therefore will unconditionally outcompete all other species. Let species 1 be the species with the highest growth rate and species 2 be the species that inhibits it most strongly. We will show that if species 1 and 2 are a part of a coexisting community, then they are in a bistable relationship.

To calculate the invasibility relationships between species 1 and 2, we set the abundances of all other species to zero and obtain the following equations for the dynamics (in accordance with the notation used in ref.):

where { X i } are the relative species abundances, { g i } are the growth rates, { f i } are the fitness values for given species abundances, K P 1 ⩾0 and K P 2 > 0 are the areas of inhibition caused by species 1 and 2.

To determine if species i can invade species j, we set X i →0 and X j →1. The conditions for bistability (mutual non-invasion) of 1 and 2 are therefore:

g 2 e − K P 1 < g 1 and g 1 e − K P 2 < g 2.

The first condition is satisfied by construction because g 2 < g 1. Therefore, species 1 and 2 are not bistable if g 1 e − K P 2 > g 2.

The minimum fitness of species 1 over all possible abundances { X i } of the coexisting species is min f 1 = g 1 e − K P 2 because by construction species 2 is the species that inhibits species 1 the strongest. At the same time, the maximum fitness of species 2 over all possible abundances { X i } of the coexisting species is max f 2 = g 2. Therefore, lack of bistability between species 1 and 2 implies min f 1 > max f 2, which means that species 1 is unconditionally outcompeting species 2 in contradiction to our assumption that the species are part of a coexisting community.

Therefore, every coexisting community has at least one bistable pair. The proof does not depend on the exact functional form of antibiotic inhibition.

---

### Statistical laws of stick-slip friction at mesoscale [^4b032716]. Nature Communications (2023). High credibility.

Discussion

To explain the above experimental results, we now consider the force release δ f for a slip, which can be written as, where σ (x, y; x s) is the asperity-induced heterogeneous interfacial shear stress at the contact surface of area A = L x L y and Cartesian coordinates (x, y), and x s is the center-of-mass position of the contact surface with δ x s being its displacement during the slip. By introducing an effective heterogeneous interfacial tension, we havewhere the second relation of Eq. (3) is obtained by taking Taylor expansion of the integrand to the first order andis averaged over the region between x s and x s + δ x s. The third relation of Eq. (3) results from the onset condition for a local slip to occur, when the slope k 0 of the external elastic pulling force, F e (x 0; x s) = k 0 (x 0 − x s), becomes equal to the local (downward) slopeof the asperity-induced pinning force field, Indeed, we find that this onset condition is satisfied during the slip (see SI Section III. A for more details). Equation (3), therefore, establishes a direct connection between the force release δ f and slip length δ x s.

The interface motion is stuck on the uphill of the pinning force field F i (x s) when the local (upward) slope. In this case, the elastic pulling force F e (x 0; x s) is balanced by the local pinning force F i (x s), from which we obtain (see SI Section III. A for more details)where k is the dynamic spring constant measured when the scanning probe undergoes a steady stick-slip motion, as shown in Fig. 1 f. Equation (5) states that the interface is often partially pinned, and its local (microscopic) slip allows the scanning probe to feel a local force gradient. As the scanning probe sweeps over the sandpaper, it feels different values ofand the measured k varies correspondingly.

---

### Characterizing allelic associations from unphased diploid data by graphical modeling [^7644c763]. Genetic Epidemiology (2005). Low credibility.

A method for estimating a graphical model to describe allelic associations between genetic loci is extended to use diploid genotypes rather than haploid data. It also provides haplotype frequency estimates, estimates of phase for sampled individuals, allows for missing or partial information, genotyping errors, and arbitrary penetrance functions. A data set of 688 unrelated individuals genotyped on 25 genetic loci is used to illustrate haplotype frequency estimation. The frequencies obtained are shown to be similar to those obtained by the PHASE program. We also illustrate how putative loci for traits can be included in the analysis in order to detect allele-phenotype associations. Haplotype reconstruction is illustrated on a standard set of 40 male X-chromosome haplotypes, randomly paired to simulate diploid genotype data. The novel method is shown to be comparable to most existing ones, though the PHASE method does consistently better on this problem. The graphical model approach is shown to have some advantages in terms of tractability and can be used to select informative subsets of loci and to map loci influencing phenotypes.

---

### Intriguing role of water in protein-ligand binding studied by neutron crystallography on trypsin complexes [^e3771409]. Nature Communications (2018). Medium credibility.

After the reference frame coordinate system was defined, the Cartesian coordinates of the oxygen and hydrogen atoms of these bound water molecules were transformed to the reference frame coordinate system. Furthermore, the rotational coordinate space spanned by the water molecules was described by applying an internal coordinate system to each water molecule within the hydration layer cutoffs: The O atom was defined as the origin of the water internal coordinate system. Then, the x -axis, R x, was set to be the O–H1 bond vector and the z -axis, R z, was defined as being orthogonal to the O–H1 and the O–H2 bond vectors. Finally, the y -axis, R y, was obtained as the cross product of x and z -axes vectors. Please note that the water internal coordinate system was constructed from the Cartesian coordinates of the water molecules in the respective frame of reference as outlined above.

The lifetime of a particular state (with respect to the translational or rotational degrees of freedom) that a specific water molecule can occupy was defined as the time span the water molecule is present in that state. For the sake of simplicity, only a single translational state was defined. This state was considered occupied when the oxygen atom of a water molecule was within the cutoff distance to the origin of the reference frame of the amino acid. In that manner, for each water molecule j that occupies the site, a survival function B j was defined, that is summed over a number of N f frames, where N f is the number of frames along the entire or a chunk of the MD trajectory. This function was assigned 1 at position t' if the state is occupied during the t' th frame and the t + t' th frame of the trajectory and 0 otherwise. Since only a fully continuous series of occupied states is of interest for the calculation of the lifetime, the state must not be unoccupied in between frames t' and t + t'. Consequently, the following pseudo-autocorrelation functional, which runs over all water molecules, N W that occupy the site, was defined for the purpose of translational states:

---

### Fluctuation spectra of large random dynamical systems reveal hidden structure in ecological networks [^a92321c9]. Nature Communications (2021). High credibility.

Computing the power spectral density

In the following, we use features of the bipartite interaction network. For instance, all nodes that are connected to e.g. node x i, will be prey nodes y j, and thus are not connected with each other (see Fig. 6). This allows us to write the following recursion formulas for the mean power spectral densities according to Eq. (42),

Recall that the top left entries of Ψ x and Ψ y deliver the mean power spectral densities for predators ϕ x and prey ϕ y respectively. For the bipartite model, the helping matrices χ i, χ i j (as defined in Eq. (23)) are given by,

Inserting and writing out Eq. (59) gives, where c x, c y are the number of connections per predator and prey species respectively. Analogous to Eq. (38) we now derive a system of equations and solve for r x, r y and ϕ x, ϕ y. In the main text we describe the features of the power spectral density deduced from this system of equations.

Interpreting the power spectral density in the context of temporal stability

For orientation, we here provide some interpretation of the power spectral density in the context of temporal stability. Essentially when we talk about temporal stability, we can be referring to one of two measures. The first is how far stochastic trajectories tend to stray from their equilibrium value over long time horizons. We refer to this as 'variability'. The second is how quickly population abundances tend to change over finite time horizons. We will characterise this by the 'temporal autocorrelation'.

The variability can be characterised by the variance in time-averaged trajectories around the mean. For a system such as Eq. (2), which we recall can be a linear approximation for a nonlinear system such as Eq. (1), we find that ξ is normally distributed with zero mean and a covariance matrix, Σ, that solves the following Lyapunov equation;

---

### X-linked hypophosphatemia management in adults: an international working group clinical practice guideline [^cac17aab]. The Journal of Clinical Endocrinology and Metabolism (2025). High credibility.

Regarding follow-up and surveillance for X-linked hypophosphatemia, more specifically with respect to follow-up, adults, XLH-IWG 2025 guidelines recommend to consider performing a comprehensive neurological clinical examination in the presence of neurological deficit.