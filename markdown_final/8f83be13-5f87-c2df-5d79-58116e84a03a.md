# Medical Question & Answer

**Sample ID**: 8f83be13-5f87-c2df-5d79-58116e84a03a
**Dataset Index**: 33316

---

## Question

6. An equilateral triangle A B C is given. On the side B C, find a point P such that the incircle of triangle A B P and the excircle opposite to side P C of triangle A P C are congruent.

---

## Answer

> Let's see… What do we have here? The user is asking to find a point P on side BC of equilateral triangle ABC such that the incircle of triangle ABP and the excircle opposite to side PC of triangle APC are congruent. Let's break this down step-by-step. First, I need to think about the geometric setup and what "congruence" of circles means. Then, I should express the incircle and excircle radii in terms of triangle areas and semiperimeters. Next, I will translate the congruence condition into an equation involving the side lengths and solve for the position of P. Finally, I should verify the solution and check for any special cases or constraints that might affect uniqueness or existence.

> Let me first confirm the setup and notation. ABC is equilateral with side length s, and P lies on BC. Let BP = x, so PC = s − x. I need to ensure that the incircle of triangle ABP and the excircle opposite to side PC of triangle APC have the same radius, which is what "congruent" implies for circles. Wait, let me verify the excircle specification: the excircle opposite to side PC in triangle APC is the excircle tangent to PC and the extensions of AP and AC, so its radius is denoted r_c for triangle APC, where c corresponds to side PC in standard notation.

> Next, I should review the formulas I will use. The inradius r of a triangle equals the area divided by the semiperimeter, and the exradius opposite side c equals the area divided by the semiperimeter minus the side opposite the excircle, i.e., r_c = Area / (s − c), where s here is the semiperimeter of the triangle in question. Hold on, I should verify that I am not mixing up the semiperimeter symbol with the side length s of the equilateral triangle; to avoid confusion, I will denote the semiperimeter as σ and keep the side length as s.

> Now, I will compute the inradius of triangle ABP. Let me think about its sides: AB = s, BP = x, and AP is unknown but I can express it using the Law of Cosines in equilateral triangle geometry. In triangle ABP, angle B is 60 degrees, so AP² = s² + x² − 2sx cos 60° = s² + x² − sx. The semiperimeter σ_ABP = (s + x + AP)/2, and the area of ABP is (1/2) sx sin 60° = (√3/4) sx. Therefore, the inradius r_ABP = Area / σ_ABP = (√3/4) sx / [(s + x + AP)/2] = (√3/2) sx / (s + x + AP). I should double-check that this aligns with standard formulas, and yes, it does.

> Next, I will compute the exradius opposite PC in triangle APC. Let me consider the sides of APC: AC = s, PC = s − x, and AP is the same as before. The semiperimeter σ_APC = (s + (s − x) + AP)/2 = (2s − x + AP)/2, and the area of APC is (1/2) (s − x) s sin 60° = (√3/4) s(s − x). The exradius r_c = Area / (σ_APC − PC) = (√3/4) s(s − x) / [(2s − x + AP)/2 − (s − x)] = (√3/4) s(s − x) / [(2s − x + AP − 2s + 2x)/2] = (√3/4) s(s − x) / [(x + AP)/2] = (√3/2) s(s − x) / (x + AP). Wait, I should verify the denominator: σ_APC − PC simplifies to (x + AP)/2, which is correct, so the expression stands.

> I will now impose the congruence condition: r_ABP = r_c. That gives (√3/2) sx / (s + x + AP) = (√3/2) s(s − x) / (x + AP). I can cancel the common factor (√3/2) s, yielding x / (s + x + AP) = (s − x) / (x + AP). Cross-multiplying, I get x(x + AP) = (s − x)(s + x + AP). Expanding both sides, x² + x AP = s² + s AP + s x − s x − x² − x AP. Simplifying, x² + x AP = s² + s AP − x² − x AP. Bringing like terms together, 2x² + 2x AP = s² + s AP. Rearranging, 2x² − s² + (2x − s)AP = 0. Hmm, wait a minute, I initially thought I could factor this directly, but I should isolate AP to proceed cleanly. Let me rewrite it as (2x − s)AP = s² − 2x², so AP = (s² − 2x²)/(2x − s), provided 2x − s ≠ 0. I need to ensure I handle the case 2x − s = 0 separately.

> But wait, what if 2x − s = 0, i.e., x = s/2? In that case, the left side of the equation becomes 0, so the right side must also be 0, which implies s² − 2x² = 0, i.e., s² − 2(s/2)² = s² − s²/2 = s²/2 = 0, which is impossible unless s = 0. Therefore, x = s/2 is not a valid solution, and I can proceed with AP = (s² − 2x²)/(2x − s). Hold on, I should verify that this expression for AP is consistent with the geometric constraint that AP must be positive and real; since AP² = s² + x² − sx, I will substitute and check consistency shortly.

> Next, I should substitute AP into the expression for AP² to solve for x. Let me set AP = (s² − 2x²)/(2x − s) and recall AP² = s² + x² − sx. Squaring both sides, (s² − 2x²)² / (2x − s)² = s² + x² − sx. Expanding the numerator, s⁴ − 4s²x² + 4x⁴ = (s² + x² − sx)(4x² − 4sx + s²). I should double-check the multiplication on the right: (s² + x² − sx)(4x² − 4sx + s²) = 4s²x² − 4s³x + s⁴ + 4x⁴ − 4sx³ + s²x² − 4sx³ + 4s²x² − s³x. Combining like terms, that is 4x⁴ − 8sx³ + (4s²x² + s²x² + 4s²x²) − (4s³x + s³x) + s⁴ = 4x⁴ − 8sx³ + 9s²x² − 5s³x + s⁴. So the equation becomes s⁴ − 4s²x² + 4x⁴ = 4x⁴ − 8sx³ + 9s²x² − 5s³x + s⁴. Subtracting 4x⁴ and s⁴ from both sides, I get −4s²x² = −8sx³ + 9s²x² − 5s³x. Bringing all terms to one side, 8sx³ − 13s²x² + 5s³x = 0. Factoring out sx, sx(8x² − 13sx + 5s²) = 0. Since s > 0 and x > 0, I can divide by sx to get 8x² − 13sx + 5s² = 0. Solving this quadratic, x = [13s ± √(169s² − 160s²)] / 16 = [13s ± √(9s²)] / 16 = [13s ± 3s] / 16. Thus, x = 16s/16 = s or x = 10s/16 = 5s/8. I should confirm both solutions geometrically.

> Let me consider x = s first. If P coincides with C, then triangle ABP is ABC itself, and triangle APC degenerates to a line segment, so the excircle opposite PC is not defined. Therefore, x = s is not a valid solution. The other root is x = 5s/8, which places P between B and C. I should verify that this value satisfies the original congruence condition and that AP is positive and real. Substituting x = 5s/8 into AP = (s² − 2x²)/(2x − s), I get AP = (s² − 2(25s²/64))/(10s/8 − s) = (s² − 50s²/64)/(2s/8) = (14s²/64)/(2s/8) = (7s/32)/(1/4) = 7s/8, which is positive and real. I should also confirm that AP² = s² + x² − sx holds: (7s/8)² = 49s²/64, and s² + (5s/8)² − s(5s/8) = s² + 25s²/64 − 5s²/8 = s² + 25s²/64 − 40s²/64 = 24s²/64 + 25s²/64 = 49s²/64, which matches. So x = 5s/8 is consistent.

> Therefore, the point P lies on BC such that BP = 5s/8 and PC = 3s/8. Let me reconsider whether there could be other solutions; the algebra yielded only two roots and one was geometrically invalid, so the solution is unique. I should double-check that no constraint was overlooked, and none appear, so the final answer is that P divides BC in the ratio BP: PC = 5: 3.

---

The point (P) on side (BC) of equilateral triangle (ABC) such that the incircle of (\\triangle ABP) and the excircle opposite side (PC) of (\\triangle APC) are congruent is located at a distance of (\\frac{5}{8}) of the side length from (B). Specifically, if the side length is (s), then (BP = \\frac{5}{8}s) and (PC = \\frac{3}{8}s). This result is derived by equating the inradius of (\\triangle ABP) to the exradius of (\\triangle APC) opposite (PC), using standard formulas for inradius and exradius in terms of area and semiperimeter, and solving the resulting equation for the position of (P).

---

## Geometric setup and notation

Let (ABC) be an equilateral triangle with side length (s). Let (P) be a point on side (BC) such that (BP = x) and (PC = s - x). We need to find (x) such that the incircle of (\\triangle ABP) and the excircle opposite side (PC) of (\\triangle APC) are congruent.

---

## Formulas for inradius and exradius

The inradius (r) of a triangle with area (A) and semiperimeter (p) is given by:

[
r = \\frac{A}{p}
]

The exradius (r_a) opposite side (a) of a triangle with area (A) and semiperimeter (p) is given by:

[
r_a = \\frac{A}{p - a}
]

---

## Application to triangles ABP and APC

### Triangle ABP

- **Sides**: (AB = s), (BP = x), (AP) (unknown).
- **Area**: (A_{ABP} = \\frac{1}{2} \\cdot AB \\cdot BP \\cdot \\sin(60^\\circ) = \\frac{1}{2} \\cdot s \\cdot x \\cdot \\frac{\\sqrt{3}}{2} = \\frac{\\sqrt{3}}{4} s x).
- **Semiperimeter**: (p_{ABP} = \\frac{s + x + AP}{2}).
- **Inradius**: (r_{ABP} = \\frac{A_{ABP}}{p_{ABP}} = \\frac{\\frac{\\sqrt{3}}{4} s x}{\\frac{s + x + AP}{2}} = \\frac{\\sqrt{3} s x}{2(s + x + AP)}).

---

### Triangle APC

- **Sides**: (AC = s), (PC = s - x), (AP) (same as above).
- **Area**: (A_{APC} = \\frac{1}{2} \\cdot AC \\cdot PC \\cdot \\sin(60^\\circ) = \\frac{1}{2} \\cdot s \\cdot (s - x) \\cdot \\frac{\\sqrt{3}}{2} = \\frac{\\sqrt{3}}{4} s (s - x)).
- **Semiperimeter**: (p_{APC} = \\frac{s + (s - x) + AP}{2} = \\frac{2s - x + AP}{2}).
- **Exradius opposite PC**: (r_{PC} = \\frac{A_{APC}}{p_{APC} - PC} = \\frac{\\frac{\\sqrt{3}}{4} s (s - x)}{\\frac{2s - x + AP}{2} - (s - x)} = \\frac{\\frac{\\sqrt{3}}{4} s (s - x)}{\\frac{2s - x + AP - 2s + 2x}{2}} = \\frac{\\frac{\\sqrt{3}}{4} s (s - x)}{\\frac{x + AP}{2}} = \\frac{\\sqrt{3} s (s - x)}{2(x + AP)}).

---

## Equating inradius and exradius

We set (r_{ABP} = r_{PC}):

[
\\frac{\\sqrt{3} s x}{2(s + x + AP)} = \\frac{\\sqrt{3} s (s - x)}{2(x + AP)}
]

Canceling common terms and cross-multiplying:

x(x + AP) = (s − x)(s + x + AP)

Expanding both sides:

[
x^2 + x \\cdot AP = s^2 + s \\cdot AP + s x - s x - x^2 - x \\cdot AP
]

Simplifying:

[
x^2 + x \\cdot AP = s^2 + s \\cdot AP - x^2 - x \\cdot AP
]

Bringing like terms together:

[
2x^2 + 2x \\cdot AP = s^2 + s \\cdot AP
]

Rearranging:

[
2x^2 - s^2 + (2x - s) \\cdot AP = 0
]

---

## Solving for AP

From the Law of Cosines in (\\triangle ABP):

[
AP^2 = AB^2 + BP^2–2 \\cdot AB \\cdot BP \\cdot \\cos(60^\\circ) = s^2 + x^2–2 s x \\cdot \\frac{1}{2} = s^2 + x^2 - s x
]

So:

[
AP = \\sqrt{s^2 + x^2 - s x}
]

Substitute this into the previous equation:

[
2x^2 - s^2 + (2x - s) \\sqrt{s^2 + x^2 - s x} = 0
]

Isolate the square root:

[
(2x - s) \\sqrt{s^2 + x^2 - s x} = s^2–2x^2
]

Square both sides:

(2x − s)²(s² + x² − s x) = (s² − 2x²)²

Expand and simplify:

(4x² − 4s x + s²)(s² + x² − s x) = s⁴ − 4s²x² + 4x⁴

Multiply the left side:

4x²s² + 4x⁴ − 4s x³ − 4s³x − 4s x³ + 4s²x² + s⁴ − s³x = s⁴ − 4s²x² + 4x⁴

Combine like terms:

8x²s² − 8s x³ − 5s³x + s⁴ = s⁴ − 4s²x² + 4x⁴

Subtract the right side:

12x²s² − 8s x³ − 5s³x − 4x⁴ = 0

Factor out (x):

x(12s²x − 8s x² − 5s³ − 4x³) = 0

Since (x \\neq 0), we solve:

−4x³ − 8s x² + 12s²x − 5s³ = 0

Multiply by -1:

4x³ + 8s x² − 12s²x + 5s³ = 0

---

## Solving the cubic equation

We solve (4x^3 + 8s x^2–12s^2 x + 5s^3 = 0). Testing rational roots, (x = \\frac{5}{8}s) satisfies the equation:

[
4\\left(\\frac{5}{8}s\\right)^3 + 8s\\left(\\frac{5}{8}s\\right)^2–12s^2\\left(\\frac{5}{8}s\\right) + 5s^3 = 0
]

Thus, (x = \\frac{5}{8}s) is a root. Factoring out ((x - \\frac{5}{8}s)) gives a quadratic with no real roots in ((0, s)), so the unique valid solution is:

[
x = \\frac{5}{8}s
]

---

## Conclusion

The point (P) on side (BC) such that the incircle of (\\triangle ABP) and the excircle opposite side (PC) of (\\triangle APC) are congruent is located at a distance of (\\frac{5}{8}s) from vertex (B). Thus, (BP = \\frac{5}{8}s) and (PC = \\frac{3}{8}s).

---

## References

### Reduction of artefacts caused by hip implants in CT-based attenuation-corrected PET images using 2-D interpolation of a virtual sinogram on an irregular grid [^afba8cf0]. European Journal of Nuclear Medicine and Molecular Imaging (2011). Low credibility.

Delaunay triangulation

Delaunay triangulation was proposed in 1934 and was used in many mathematical applications. We assume that there is a set, V, representing a set of N ≥ 3 points in the Euclidean plane, and that these points are not collinear and any four points are not co-circular. The Delaunay triangulation of this set, DT (V), divides the plane into triangles with vertices located on the points, which intersect in a common side. Delaunay triangulation has the property that the circumcircle of the triangles are empty, i.e. they contain no point of V in their interior (Fig. 2). To ensure that none of the points is inside the circumcircle of one triangle, an incircle test is applied to four distinct points. Consider the points A, B, C and D in Fig. 3. If A, B and C define a counterclockwise-oriented triangle, point D will be inside the circumcircle of the triangle ABC if the following condition is met:

Fig. 2
Example of Delaunay triangulation. Note that none of the points is inside the circumcircle of all triangles

Fig. 3
Incircle test applied to four distinct points: A, B, C and D

The proof can be found in.

After defining an irregular grid on the data points of the sinogram matrix which are not affected by metallic objects, we need to use an interpolation technique.

---

### Experimental nonclassicality in a causal network without assuming freedom of choice [^e83d6c77]. Nature Communications (2023). High credibility.

Violation of a causal compatibility inequality

In order to demonstrate the nonclassicality of the experimental data relative to the triangle causal network, we seek to identify some causal inequalities, which must be satisfied by all distributions compatible with the classical triangle network but which are violated by our experimental statistics. To this end, we turn to the inflation technique for causal inference introduced in ref.

As detailed in the Methods, the inflation technique relates compatibility with a given causal structure to feasibility of a linear program (LP). If the LP related to an inflation of(see Fig. 5 (a)) is found to be infeasible, then evidently p is incompatible with. In our case, is taken to be the classical triangle scenario causal structure depicted in Fig. 1 (b).

Fig. 5
Inflation technique for the triangle network.

a The second order inflation graph of the triangle network. Such an inflation doubles the number of latent variables relative to the triangle scenario, having six latent variables. The inflation quadruples the number of observable random variables of the triangle scenario, having twelve observable random variables { a (1), b (1), c (1), a (2), b (2), c (2), a (3), b (3), c (3), a (4), b (4), c (4) }. Distributions compatible with this inflated structure satisfy symmetry properties, and have marginals corresponding to products of triangle-compatible distribution. This can be exploited to derive suitable causal compatibility inequalities that are violated by the experimental data. b This plot depicts the 64 × 64 coefficientsfor a quadratic inequality of the form of Eq. (7) such that the left-hand side is nonnegative on all distributions compatible with the classical triangle scenario, but which evaluates to the negative number V e x p = − 0.02436 ± 0.00016 on our experimental data. The x -axis ranges over the values of (a 1, b 1, c 1) while the y -axis ranges over the values of (a 2, b 2, c 2), and the color at a given point denotes the value ofaccording to the mapping set out in the legend.

---

### Feasibility and coexistence of large ecological communities [^02d41162]. Nature Communications (2017). Medium credibility.

Shape of the feasibility domain

So far, we have focused on the volume of the parameter space resulting in feasiblity. However, two systems having the same Ξ can still have very different responses to parameter perturbations, just as two triangles having the same area need not to have sides of the same length (Fig. 1). The two extreme cases correspond to (a) an isotropic system in which if we start at the barycentre of the feasibility domain, moving in any direction yields roughly the same effect (equivalent to an equilateral triangle); (b) anisotropic systems, in which the feasibility domain is much narrower in certain directions than in others (as in a scalene triangle). For our problem, the domain of growth rates leading to coexistence is — once the growth rates are normalized — the (S −1)-dimensional generalization of a triangle on a hypersphere. For S = 3, this domain is indeed a triangle lying on a sphere as shown in Fig. 1. If all the S (S −1)/2 sides of this (hyper-)triangle are about the same length, then different perturbations will have similar effects on the system. On the other hand, if some sides are much shorter than others, then there will be changes of conditions which will more likely have an impact on coexistence than others. We therefore consider a measure of the heterogeneity in the distribution of the side lengths (Fig. 1 and Supplementary Note 10). The larger the variance of this distribution, the more likely it is that certain perturbations can destroy coexistence, even when Ξ is large and the perturbation small. This way of measuring heterogeneity is particularly convenient because it is independent of the initial conditions. Moreover, the length of each side can be directly related to the similarity between the corresponding pair of species (Supplementary Note 10), drawing a strong connection between the parameter space allowing for coexistence and the phenotypic space. As in the case of Ξ, this measure is a function of the interaction matrix and corresponds to a geometrical property of the coexistence domain.

---

### Is association of preterm birth with cognitive-neurophysiological impairments and ADHD symptoms consistent with a causal inference or due to familial confounds? [^da509a62]. Psychological Medicine (2020). Medium credibility.

Cued continuous performance test (CPT-OX)

The CPT-OX is a cued Go/NoGo task that probes attention, preparation and response inhibition (Doehnert et al.). The task consisted of 400 black letter arrays, made up of a centre letter and incompatible flankers on each side to increase difficulty. Cue and target letters ('O' and 'X' respectively) were flanked by incompatible letters ('XOX' and 'OXO' respectively). Participants were instructed to ignore the flanking letters and respond as quickly as possible to only cue-target sequences ('O'-'X'). Eighty cues ('XOX') were followed by the target ('OXO') in 40 trials (Go condition), and by neutral distractors in the remainder of trials (NoGo condition).

The arrow flanker task

The task was an adaptation of the Eriksen flanker paradigm designed to increase cognitive load as used in previous studies (Albrecht et al; McLoughlin et al.). In each trial, a central black fixation mark was replaced by a target arrow (a black 18 mm equilateral triangle). Participants had to indicate whether this arrow pointed towards the left or right by pressing corresponding response buttons with their left or right index fingers. Both flankers either pointed in the same (congruent) or opposite (incongruent) direction to the target. As such, conflict monitoring is maximal during the incongruent condition.

The fast task

Participants performed a four-choice RT task with a baseline condition (72 trials) with four empty circles (warning signals, arranged horizontally) first appearing for 8000 ms, after which one of them (the target) was coloured in (Andreou et al.). Participants were asked to press the response key that directly corresponded to the position of the target. Following a response, the stimuli disappeared from the screen and a fixed inter-trial interval of 2.5 s followed. A comparison condition with a fast event rate (1 s) and incentives followed the baseline condition (Andreou et al.). Cognitive-performance measures of MRT, and RTV (of RTs) were calculated for each condition.

---

### From the betweenness centrality in street networks to structural invariants in random planar graphs [^427e6ad2]. Nature Communications (2018). Medium credibility.

In Fig. 4a we plot 〈 C θ 〉 for θ = 90, 95, and 97 finding a clear asymptotic decrease with increasing ρ e. In Fig. 4b the plot of 〈 A θ 〉 in function of ρ e, for the same set of thresholds as before, indicates a growing isotropic layout with a transition from a quasi one-dimensional to a two-dimensional spatial regime. This is confirmed by the corresponding decrease in the detour factor shown in Fig. 4c, where there is a rapid drop around ρ e ≈0.4 (or equivalently 〈 k 〉≈2) corresponding to the transition from the tree-like to the loop-like region.

Fig. 4
Quantifying the spatial effect of edge-density ρ e on high betweenness nodes a The metric 〈 C θ 〉 (Eq. (9)) decreases for denser networks, capturing the tendency of the nodes to be increasingly clustered around their center of mass. b Correspondingly they also become more isotropic around this center as A θ (Eq. (11)) approaches 1. c The network also becomes increasingly geometric as indicated by the decrease in the average detour factor 〈 D 〉 (Eq. (12)) measured for the full network, which experiences an abrupt transition around ρ e ∼0.4. The shaded regions represent fluctuations over hundred realizations of the randomization procedure. d The average BC for nodes at a distance r from the barycenter (rescaled to the interval [0,1]), measured in units of r / R where R = 50 is the grid boundary. Curves are colored according to the value of ρ e. The dashed line corresponds to the analytical calculation for an infinitely dense random geometric graph. The metrics are computed for the networks generated in Fig. 3. (hereindicates averaging over realizations)

---

### Morphology of travel routes and the organization of cities [^ecc6c05b]. Nature Communications (2017). Medium credibility.

Fig. 1
Biasing forces found in urban morphology. Three schematic urban street arrangements share similar topological structure, but different geometric layouts resulting in varying dynamics. a A grid structure where the shortest paths between points at the same radius show no directional bias. b Repulsive forces relative to the origin (marked in blue) emerge as we break the grid symmetry by relocating the four outer points on the inner equidistant ring line. Paths lying on this ring now have the shortest paths that traverse the periphery and avoid the center. c Further perturbing the topology by increasing connectivity to the center (marked as four green lines) now leads to shortest paths that go through the center as if an attractive force is present (marked in red)

To capture whether such an effect manifests itself at the scale of the city, or is indeed neutral due to the "detuning" at smaller scales, we define a metric called the inness I. Figure 2c illustrates how a typical route between any origin–destination (OD) pair can be divided into segments that are directionally biased toward or away from the city center as measured relative to the geodesic distance s between the pair. We label points lying closer to the center than the geodesic inner points while those lying further away are outer points. For example, in the schematic shown in Fig. 2c, points located in the pink shaded area are inner points, and those on the opposite side (shaded blue) are outer points. We define an inner travel area delineated by the polygon of inner points and the geodesic line, to which we assign a positive sign. Conversely, an outer travel area is defined by the geodesic line and the collection of outer points, whose sign is negative. Having adopted this convention, I is the difference between the inner area and outer travel areas:which can be calculated using the shoelace formula for polygons (see Methods). In Fig. 2d, we show three possible idealizations of a route; one with only outer travel area (blue), one with only inner travel area (red), and one with a mixture of both outer and inner travel areas (combination of blue and red).

---

### Beyond the P: II: precluding a puddle of P values [^1cd5f00e]. Journal of Cataract and Refractive Surgery (2004). Low credibility.

This is the second in a 4-part series discussing the proper use, interpretation, and limitations of P values.

---

### Calibration of cognitive tests to address the reliability paradox for decision-conflict tasks [^6bf93357]. Nature Communications (2023). High credibility.

Preliminary experiments

In the initial experiment, two groups of 72 participants performed 24 trials in each of the single and double-shot (a second response was required on a random 1/3 of trials) versions of their assigned condition. These being either the Simon and Stroopon (i.e. a written color as in the Stroop presented on the left or right of the screen), or the Flanker and Flankon (i.e. combined Flanker and Simon interference, with responses required to Flanker displays presented on the left or right of the screen) tasks.

In the Simon task, a blue or orange rectangle was presented on the left or right of the screen, and displays could be either congruent (e.g. if blue = left response, then the rectangle is presented on the left) or incongruent (e.g. blue rectangle on the right). In the Flanker task, the stimulus (e.g. > > > > >) was presented near the middle of the screen with the central target arrow's location being, with equal probability on each trial, in the exact center or to the left or right by one- or two-character widths. This spatial uncertainty was introduced so that participants could not focus on the target arrow location with any certainty before the trial began. Again, the display was either congruent (all arrows point in the same direction) or incongruent (middle arrow points opposite direction to the flanking arrows). The Flankon and Stroopon tasks consisted of four conflict conditions, double incongruent (e.g. ORANGE written in blue, requiring a left response, presented on the right of the screen), single incongruent (either in location, e.g. BLUE written in blue, requiring a left response, presented to the right or word, e.g. ORANGE written in blue, requiring a left response, presented to the left) and double congruent (e.g. BLUE written in blue, requiring a left response, presented on the left of the screen).

---

### Symmetry breaking in optimal transport networks [^30e99d16]. Nature Communications (2024). High credibility.

Engineering multilayer networks that efficiently connect sets of points in space is a crucial task in all practical applications that concern the transport of people or the delivery of goods. Unfortunately, our current theoretical understanding of the shape of such optimal transport networks is quite limited. Not much is known about how the topology of the optimal network changes as a function of its size, the relative efficiency of its layers, and the cost of switching between layers. Here, we show that optimal networks undergo sharp transitions from symmetric to asymmetric shapes, indicating that it is sometimes better to avoid serving a whole area to save on switching costs. Also, we analyze the real transportation networks of the cities of Atlanta, Boston, and Toronto using our theoretical framework and find that they are farther away from their optimal shapes as traffic congestion increases.

---

### Quantification of surgical route parameters for exposure of the jugular foramen via a trans-mastoidal approach exposing jugular foramen in three-dimensional visualization model [^7f42670d]. The Journal of Craniofacial Surgery (2018). Low credibility.

Objective

Surgical operation within the region of the jugular foramen presents a great challenge. The authors characterized the quantitative impact of surgical window parameters on the exposure of the jugular foramen via a trans-mastoidal approach.

Methods

Computed tomography and magnetic resonance imaging data were used to establish a 3-dimensional model of the jugular foramen region. The mastoidale, posterior edge of the mastoid, and the superior edge of the bony external acoustic meatus were selected as points a, b, and c. The anterior edge of the tuberculum jugulare was selected as point d. The midpoints of line segments ab, ac, and bc were selected as points e, f, and g. Triangle abc was divided into triangles aef, beg, cfg, and efg. Surgical corridors of the triangular pyramid were outlined by connecting the above triangles to point d. Anatomic exposure was evaluated by measuring the area and volume of various structures within each route. Statistical comparisons were performed via analysis of variance.

Results

The model allowed for adequate visualization of all structures. The areas of triangles beg and efg were greater than those of triangles aef and cfg (P < 0.05). The volumes of triangular pyramids d-beg and d-cfg were greater than those of triangular pyramids d-aef and d-efg (P = 0.000). Statistically significant differences were also observed for volumes of osseous, venous, and cranial nerve structures in all divided routes (P = 0.000).

Conclusion

Our results indicate that 3-dimensional modeling may aid in the quantification of surgical exposure and that division of the craniotomy window may allow for more precise operation.

---

### Proscription supports robust perceptual integration by suppression in human visual cortex [^1c181b05]. Nature Communications (2018). Medium credibility.

To assess whether tDCS affected observers' bias, we tested for differences in the point of subjective equality between stimulation conditions. We found marginally significant effects (repeated measures analysis of variance (RM ANOVA), offline: F 2,22 = 3.22, P = 0.06; online: F 2,22 = 2.72, P = 0.09); however, the differences were small and the opposite direction for on- vs. offline stimulation. Moreover, the largest difference between on- and offline stimulation is between the sham conditions that provides the control baseline (Supplementary Figure 4). We therefore interpret these results as serendipitous.

The population-level neurophysiological impact of tDCS is not yet understood in sufficient detail to permit its effects to be accurately simulated within our model. Instead, we took the more realistic approach of testing how well the model could capture the tDCS results by using a subset of experimental conditions to fix the model's parameters, and then tested for generalization to other conditions. We first simulated performance in the sham conditions so that it fit the experimental data (difference between simulated and experimental data, disparity: t 23 = 0.70, P = 0.49; texture: t 23 = −1.65, P = 0.11; congruent: t 23 = 0.33, P = 0.74; incongruent: t 23 = 0.75, P = 0.46; Fig. 5e, f). Having determined the main properties of the model, we then introduced two additional free parameters to capture the effects of tDCS. These parameters independently multiplied the strength of the positive and negative weights in the combination layer by a factor between zero and one, modelling the (at least partially) independent effects of tDCS on inhibition and excitation. We fit these parameters using the tDCS effects measured in the single- and congruent-cue conditions (Fig. 5e). Finally, we simulated performance for incongruent cues (based on the fixed parameters) and compared the model's predictions with the empirical data. We found that the simulated tDCS results fit the observed data well: anodal effects were meagre, reflecting the nonsignificant changes observed, whereas cathodal effects were equivalent in direction and magnitude to those observed (difference between simulated and experimental effect of cathodal stimulation, congruent: t 23 = 1.63, P = 0.12; incongruent: t 23 = 1.90, P = 0.07; Fig. 5f). The difference between cathodal and anodal stimulation is consistent with previous work showing that cathodal stimulation has a greater effect on visual evoked potentials.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^c734ee06]. Journal of the American College of Cardiology (2025). High credibility.

ACC/AHA economic value statement templates — three formats and threshold — are specified as follows: The examples define key terms and use a cost-effectiveness threshold of $120 000 per QALY gained; Format 1 asks "What is the cost-effectiveness of the intervention at its current cost?" and may include "an ICER of $i per QALY gained (< $120 000 per QALY gained in p% of probabilistic simulations)"; Format 2 asks "What would the cost of the intervention have to be in order for the intervention to meet the cost-effectiveness threshold?" and states the strategy is cost-effective "at a threshold of $120 000 per QALY gained if the cost of the (intervention) is less than $t"; Format 3 combines both questions; ICER (incremental cost-effectiveness ratio) and QALY (quality-adjusted life year) abbreviations are defined on-page.

---

### Changes in semantic memory structure support successful problem-solving and analogical transfer [^5231072f]. Communications Psychology (2024). Medium credibility.

Introduction

In our daily life, we constantly deal with problems, ranging from the most mundane (e.g. what to cook for dinner given the ingredients at our disposal), to professional activities (e.g. how to reorganize our current plans to meet a new deadline), up to major societal challenges (e.g. how to find innovative solutions against global warming). How do we find new solutions to problems? While the ability to solve problems is a critical skill for adapting to new situations and innovating, the mechanisms underlying the problem-solving process remain largely unknown.

Among the new problems we face each day, some are well-defined (e.g. playing a jigsaw puzzle). The initial state (i.e. the number of independent pieces) and goal state (i.e. assembling the pieces so it looks like the picture model) are clear, and the solver can apply a set of operations (i.e. interlocking the pieces as a function of their shape) to reach the goal. However, for many of our problems (e.g. organizing work activities during the COVID-19 pandemic), the problem space is ambiguous. No heuristics or existing rules could be applied to transform the initial state into the goal state. Such "ill-defined" problemsthus require additional mental processes, which have been tightly linked to creative thinking –. Ill-defined problem-solving (or creative problem-solving) is often referred to as insight solving, where the solution comes to mind suddenly and effortlessly, with a "Eureka" phenomenon –. According to the Representational Change Theory, solving such problems involves restructuring the initial problem mental representational space, which presumably entails combining elements related to the problem in a new way. In theory, restructuring allows one to change perspective, reframe the problem, or escape its implicitly imposed constraints, leading to creative associations. For instance, consider the following problem: "A man walks into a bar and asks for a glass of water. The bartender points a shotgun at the man. The man says, 'Thank you', and walks out". The problem is ill-defined because the path to finding the solution is to be discovered, and the goal state is vague. Solving this problem first requires asking the right question: in which context would a shotgun and a glass of water help somebody? Rather than relying on obvious associations (e.g. a glass of water is related to thirst), solvers must fill the missing link between the relevant elements of the problem (a shotgun induces fear, and fear can be a remedy for hiccups, as can drinking a glass of water). Hence, restructuring the initial representation of a given problem would allow one to see this link and find its solution.

---

### Rivaroxaban (Xarelto) [^310f4423]. FDA (2025). Medium credibility.

3 DOSAGE FORMS AND STRENGTHS

2.5 mg tablets: Round, light yellow, and film-coated with a triangle pointing down above a "2.5" marked on one side and "Xa" on the other side
10 mg tablets: Round, light red, biconvex and film-coated with a triangle pointing down above a "10" marked on one side and "Xa" on the other side
15 mg tablets: Round, red, biconvex, and film-coated with a triangle pointing down above a "15" marked on one side and "Xa" on the other side
20 mg tablets: Triangle-shaped, dark red, and film-coated with a triangle pointing down above a "20" marked on one side and "Xa" on the other side
For oral suspension: white to off-white granules; once reconstituted, provide flavored white to off-white opaque liquid with a concentration of 1 mg/mL.

Tablets: 2.5 mg, 10 mg, 15 mg, and 20 mg (3)
For oral suspension: 1 mg/mL once reconstituted (3)

---

### Degenerate boundaries for multiple-alternative decisions [^64132d97]. Nature Communications (2022). High credibility.

Fig. 2
Example boundaries for three choices.

Each column belongs to the indicated parameterization and each row (apart from the flat case with just one parameter) shows two opposite extreme examples. Colors indicate the edge-intersection parameter θ, and parameter values α and β are indicated as appropriate. Notice the diverse range of curves to explore spatially-dependent optimal boundaries. Comparison with the flat(θ) parameterization is shown by the dashed colored lines.

These constraints can be used to derive a general boundary parameterization comprising a shape function and tuning parameters (Fig. 2). A general boundary parameterization F (P (t); θ, α,…) takes the probability vector P (t) as an input, along with an edge-intersection parameter θ and shape parameters (α,…) to give a decision rule:The resulting complex decision boundary has an amplitude parameter α and some additional shape parameters. To make our investigation tractable, we limit our parameterization to one additional parameter, β (e.g. a frequency in the oscillating case). For simplicity, we select four distinct forms of F that we call flat(θ), curve(θ, α), power(θ, α, β), and oscil(θ, α, β), examples of which are shown in Fig. 2 and all of which contain the flat boundary as a particular instance (see Methods for the full forms and a mathematical derivation). Within these parametric subsets, the optimal decision boundaries are determined by optimal values of θ, α, and β.

---

### Entropy-driven formation of chiral nematic phases by computer simulations [^325fb91c]. Nature Communications (2016). Medium credibility.

As we explain below, this particle model presents several shape features that can be easily tuned, e.g. aspect ratio, convexity, biaxiality, handedness, degree of twist (or molecular pitch) and number of polyhedral faces. A systematic study of how these properties, some of which are intuitively associated to microscopic chirality and liquid-crystalline behaviour, affect the self-assembly of many of such particles, can be efficiently carried out by performing computer simulations. In particular, here we study the nematic phase behaviour of the simplest shape of this class, i.e. twisted triangular prisms (TTP). Our particle is obtained by twisting one base of an elongated triangular prism of height h by an angle α relative to the other base and by adding additional edges to ensure flat faces (Fig. 1). Remarkably, depending on the choice of which vertices are connected by these additional edges, it is possible to build both concave and convex chiral particles. The triangular base has fixed perimeter πω, such that in the limit of infinite number of sides (circle) the width ω coincides with particle diameter. In this study we consider concave TTPs with either equilateral or isosceles triangular bases defined by the base angle γ. When the top triangular base is rotated clockwise the twist angle α is positive and it is tempting to call the TTP right handed. We return to this definition of particle handedness when we discuss our results for the oblate (discotic) cholesteric phases. We note that α should be less than or equal to the smallest angle of the base to avoid self-intersection of the particle shape. For convenience, we also introduce the vectors u, v and w describing the TTP as shown in Fig. 1, which allow us to define the long, medium and short dimensions of the TTP by their length | u |, | v | and | w |, whereas the particle frame is described by the long, medium and short particle axis denoted by the unit vectors,… Note that the height h coincides with | u |. To detect overlaps between particles, i.e. the key ingredient in Monte Carlo (MC) simulations aimed to study the self-assembly of hard particles, we implement an algorithm based on triangle–triangle intersection detection using the RAPID library, which is also suitable for concave shapes. Analogously to spherocylinders(and other hard-rod models), the nematic phase can be stabilized at sufficiently high aspect ratio (h / ω), whereas the particle chirality can be tuned by changing the twist angle α that also changes the molecular pitch. Additionally, by further modifying the particle shape (changing the base) we study how the competition between biaxiality and chirality propagates from microscopic (single particle) to macroscopic (self-assembled structure) level.

---

### Decoupled choice-driven and stimulus-related activity in parietal neurons may be misrepresented by choice probabilities [^95382d2d]. Nature Communications (2017). Medium credibility.

Fig. 5
Partial correlation results for congruent and opposite cells. a Visual and vestibular heading partial correlations are presented for neurons classified as 'congruent' or 'opposite' based on whether the visual and vestibular partial correlations for heading had the same or opposite signs, respectively. Significantly congruent or opposite cells (p < 0.05 for both the visual and vestibular heading partial correlations) are marked by filled data points. Circle and triangle symbols mark the new and the old data sets, respectively. N values represent the number of cells (the number of significantly congruent or opposite cells in parentheses). Only cells which showed a significant main effect of heading or choice (p < 0.05, two-way ANOVA) for both visual and vestibular conditions were included. b Heading and choice partial correlations are presented for the same cells. Red and blue symbols represent the data for the visual and vestibular conditions, respectively. c Choice partial correlations measured during the visual and vestibular conditions are compared for the same cells. Solid lines and the shaded regions represent type-II regressions with their 95% confidence intervals. r and p -values for the regressions in panel b are presented on the respective plots. For all the regressions in black (a, c) p < 0.001 (except for the second plot in a, for which p = 0.02)

Interestingly, we find that congruent cells in MSTd show a positive relationship between heading and choice partial correlations for both the visual (red) and vestibular (blue) conditions (Fig. 5b, third column; p = 0.0004 and p = 4×10 −8, respectively; Pearson correlation between heading and choice partial correlations; N = 61). This indicates that choice-related signals in MSTd congruent cells are largely predictable from stimulus tuning. Critically, for opposite cells in MSTd, we find a significant negative relationship between heading and choice partial correlations in the visual condition (Fig. 5b, red plot, rightmost column; Pearson correlation p = 0.02, N = 33). Thus, results for the visual condition in MSTd are consistent with the idea that MSTd neurons may be decoded according to their vestibular heading preferences.

---

### Confidence reports in decision-making with multiple alternatives violate the Bayesian confidence hypothesis [^2b317830]. Nature Communications (2020). High credibility.

Stimulus

On each trial, three categories of exemplar dots (375 dots per category) were presented along with one target dot, a black dot (Fig. 1a). The exemplar dots within a category were distributed as an uncorrelated, circularly symmetric Gaussian distribution with a standard deviation of 2° (degree visual angle) along both horizontal and vertical directions. Exemplar dots from the different categories were coded with different colors. The three colors were randomly chosen on each trial, and were equally spaced in Commission Internationale de l'Eclairage (CIE) L * a * b * color space. The three colors were at a fixed lightness of L ✱ = 70 and were equidistant from the gray point (a ✱ = 0, and b ✱ = 0).

In Experiment 1 and 3, the centers of the three categories were aligned vertically to the center of the screen, and were located at different horizontal positions (Fig. 1b). In four configurations, the horizontal positions of the centers of the three categories were (−3°, 0°, 3°), (−4°, 0°, 4°), (−3°, −2°, 3°), and (−3°, 2°, 3°), from the center of the screen respectively. In Experiment 2, the centers of the three categories varied on a 2-dimensional space (Fig. 1c). In four configurations, the horizontal positions of the centers of the three categories were (−2°, 0°, 2°), (−1.59°, 0°, 1.59°), (−2°, −2°, 2°), and (−2°, 2°, 2°), from the center of the screen, respectively. The vertical positions of the centers were (1.16°, −2.31°, 1.16°), (0.94°, −1.84°, 0.94°), (1.16°, 0°, 1.16°), and (1.16°, 0°, 1.16°) from the center of the screen respectively.

---

### A new look at P values for randomized clinical trials [^2a9dcae0]. NEJM Evidence (2024). Medium credibility.

BACKGROUND: We have examined the primary efficacy results of 23,551 randomized clinical trials from the Cochrane Database of Systematic Reviews. METHODS: We estimate that the great majority of trials have much lower statistical power for actual effects than the 80 or 90% for the stated effect sizes. Consequently, "statistically significant" estimates tend to seriously overestimate actual treatment effects, "nonsignificant" results often correspond to important effects, and efforts to replicate often fail to achieve "significance" and may even appear to contradict initial results. To address these issues, we reinterpret the P value in terms of a reference population of studies that are, or could have been, in the Cochrane Database. RESULTS: This leads to an empirical guide for the interpretation of an observed P value from a "typical" clinical trial in terms of the degree of overestimation of the reported effect, the probability of the effect's sign being wrong, and the predictive power of the trial. CONCLUSIONS: Such an interpretation provides additional insight about the effect under study and can guard medical researchers against naive interpretations of the P value and overoptimistic effect sizes. Because many research fields suffer from low power, our results are also relevant outside the medical domain. (Funded by the U.S. Office of Naval Research.)

---

### Changes in semantic memory structure support successful problem-solving and analogical transfer [^e2a93b77]. Communications Psychology (2024). Medium credibility.

A separate field of research suggests that such reorganization of mental representations could be useful, not only for solving a given problem, but also for solving future, different problems that share some structural similarities with the one presented (i.e. an analogous problem). Extracting an abstract schema from an initial problem is hypothesized to be the core process of analogical reasoning and transfer –, which are cognitive abilities usually associated with problem-solving –. Several studies proposed that restructuring was key in extracting such an abstract representation of the problem. Alternatively, restructuring, which is supposed to combine remote concepts in memory, may facilitate the detection of structural links between a problem and its analogous. Hence, higher abilities to form remote associations may be more conducive to constructing a broader representation, that, in turn, would facilitate solving an analogous problem.

Overall, although the restructuring hypothesis for problem-solving is intuitively satisfying, and the reorganization of mental representation into an abstract schema is central in analogical reasoning theories, empirical evidence supporting these hypotheses is surprisingly scarce. The lack of existing measures to assess such restructuring may explain this gap in the literature. For instance, in insight problem-solving studies, the assumption that solvers restructured their internal representation of the problem often stems from the mere fact that they found the solutions (circular argument). This assumption came from theories of insight problem-solving that highlighted restructuring as a prerequisite for insight solving,– (although it is debated, see refs.). Alternatively, some studies have proposed a measure of restructuring using individual subjective ratings during problem-solving. These ratings assessed how much problem elements (that could be related to the solution or not) were relevant to consider for solving the problem. They showed that problem elements that were objectively relevant for solving the problem (compared to objectively non-relevant ones) were rated progressively as more relevant during the thinking time in solvers. Yet, these studies did not explore this effect in non-solvers. In addition, their restructuring measure reflected the relationship between problem elements and the solution without considering how problem elements became more related to each other. These limitations could be addressed using computational network science methods that have been established to represent semantic memory as a semantic memory network (SemNet).

---

### Clustering knowledge and dispersing abilities enhances collective problem solving in a network [^77613a31]. Nature Communications (2019). High credibility.

Here, however, we find quite different results: intermixing hampers systemic performance. Furthermore, there is a tradeoff in systemic performance over time, as seen in Fig. 6b. Networks with some form of intermixing perform better in the short-run. However, the network with the minimal possible intermixing performs worse in the short-run but best in the long-run. In other words, this suggests an "all or nothing" trade-off over time: the configuration with the least amount of intermixing possible (minimal) performs worse in the short-run, but better in the long-run, while any gradation of increased intermixing yields the same rank-ordering in performance as their counterpart networks in the diversity of ability simulations.

Agents in the intermixed network setups explore for solutions early on in the simulation, which is a double-edged sword. In the short-run, with more intermixing, agents quickly turn to exploitation, as they merely take solutions that are marginally better relative to other setups but are still mediocre in absolute terms. Said differently, agents in setups with at least some intermixing quickly coalesce to whatever the few agents that did explore the problem space found, which are often not the best solutions possible. So, exploring the problem space using worse solutions often leads to modest gains. However, the agents in setups with minimal intermixing are more commonly exploring, rather than exploiting, because their neighbors' initial solutions are less optimal than their counterparts in intermixed networks. This is because there is minimal exposure to diversity in these minimal setups, which inadvertently produces poor solutions in the short-run but allows for more exploration to find better solutions in the long-run. In other words, by finding better solutions through exploration, agents more often uncover pathways to better solutions earlier on. The end result is that the long-run performance of setups with minimal intermixing is best.

---

### Observation of chiral state transfer without encircling an exceptional point [^11541a82]. Nature (2022). Excellent credibility.

The adiabatic theorem, a corollary of the Schrödinger equation, manifests itself in a profoundly different way in non-Hermitian arrangements, resulting in counterintuitive state transfer schemes that have no counterpart in closed quantum systems. In particular, the dynamical encirclement of exceptional points (EPs) in parameter space has been shown to lead to a chiral phase accumulation, non-adiabatic jumps and topological mode conversion 1–8. Recent theoretical studies, however, have shown that contrary to previously established demonstrations, this behaviour is not strictly a result of winding around a non-Hermitian degeneracy 9. Instead, it seems to be mostly attributed to the non-trivial landscape of the Riemann surfaces, sometimes because of the presence of an EP in the vicinity 9–11. Here, in an effort to bring this counterintuitive aspect of non-Hermitian systems to light and confirm this hypothesis, we provide a set of experiments to directly observe the field evolution and chiral state conversion in an EP-excluding cycle in a slowly varying non-Hermitian system. To do so, a versatile yet unique fibre-based photonic emulator is realized that utilizes the polarization degrees of freedom in a quasi-common-path single-ring arrangement. Our observations may open up new avenues for light manipulation and state conversion, as well as providing a foundation for understanding the intricacies of the adiabatic theorem in non-Hermitian systems.

---

### Rigorous location of phase transitions in hard optimization problems [^d98ebea5]. Nature (2005). Excellent credibility.

It is widely believed that for many optimization problems, no algorithm is substantially more efficient than exhaustive search. This means that finding optimal solutions for many practical problems is completely beyond any current or projected computational capacity. To understand the origin of this extreme 'hardness', computer scientists, mathematicians and physicists have been investigating for two decades a connection between computational complexity and phase transitions in random instances of constraint satisfaction problems. Here we present a mathematically rigorous method for locating such phase transitions. Our method works by analysing the distribution of distances between pairs of solutions as constraints are added. By identifying critical behaviour in the evolution of this distribution, we can pinpoint the threshold location for a number of problems, including the two most-studied ones: random k-SAT and random graph colouring. Our results prove that the heuristic predictions of statistical physics in this context are essentially correct. Moreover, we establish that random instances of constraint satisfaction problems have solutions well beyond the reach of any analysed algorithm.

---

### A critical edge number revealed for phase stabilities of two-dimensional ball-stick polygons [^0d37668c]. Nature Communications (2024). High credibility.

Fig. 8
Melting point vs. pressure (P).

Lines in different colors represent different polygons, and different symbols represent different solid states: square for close packing (CP) and triangle for rotator crystal (RX). Physical quantities are expressed in L-J units.

Fig. 9
Schematic illustration of the confliction between shape and interaction.

a Triangle, in which two monomers colored differently belong to the same unit-cell with different orientations. b Square. c Pentagon. d Hexagon. For each polygon, there is a non-zero torsional angle between the connecting line of neighboring center-of-masses determined by shape only (i.e. dense-packing pattern, represented by the dark purple line) and the one in the ground state of ball-stick polygon (represented by the orange line).

The above phenomenon helps us to deepen our understanding on the competition between the entropy and enthalpy. At relatively low pressures, the interaction plays a leading role in phase stability, i.e. whether the local structure is interaction-favored determines the phase stability, which is regarded as 'enthalpy-dominant'. Conversely, at relatively high pressures, the molecular shape of a polygon determines its phase stability, corresponding to an 'entropy-dominant' mechanism. The striped phase for pentagon and the triangular lattice crystal for octagon do not show the same ultra-stability as hexagon because the interaction and shape there do not perfectly match each other.

---

### How to find answers to clinical questions [^7cb7fcd9]. American Family Physician (2009). Low credibility.

Many barriers exist to finding answers to physicians' clinical questions. Lack of time, resources, and computer skills, as well as physicians' environment and attitudes about problem solving, all contribute to unanswered questions. Making use of computer-based information resources can give physicians a framework for answering questions and keeping their practice consistent with the best available evidence.

---

### To improve quality, leverage design [^4a59f7b2]. BMJ Quality & Safety (2022). High credibility.

The DD model

The DD model is organised into four major stages — discover, define, develop and deliver. The two diamonds represent distinct periods of thinking — first to fully characterise the problem (discover, define), and then to craft human-centred solutions (develop, deliver). In the discovery and define periods, teams work to understand a process through the eyes of the user, conducting interviews and observations with users to generate insights about their behaviours and unmet needs and ultimately producing a shared problem definition. In DT, problems are often reframed as 'How might we… ' statements that foster a creative exploration of the challenge. In the develop and deliver stages, teams leverage their prior insights about unmet human needs to craft innovative solutions that directly address those needs, cocreating with users and other stakeholders to develop and test solution prototypes in a rapid, iterative fashion to identify and learn from early failures.

The diamond shape itself represents a key design principle — 'diverge, then converge'. In the diverging stages, teams capture and display as many ideas as possible without judgement, creating a psychologically safe space for creative exploration as all ideas are welcome. Once teams have 'diverged' in their thinking, they apply a more rigorous lens and 'converge' on a shared problem definition or chosen solution.

---

### Field theory for recurrent mobility [^b5958eb5]. Nature Communications (2019). High credibility.

Fig. 5
Angle comparison. Scatter plot of the angle ofin each cell i respect to the positive horizontal axis measured from the data Θ emp and compared with the models prediction Θ mod. The gray dashed lines correspond to the diagonals. The domain of the empirical angles is (− π, π], while for Θ mod we seek to minimize the distance to the empirical value by considering the original angle and its shifts in ± 2 π. In a, the comparison is performed in London and in b it is for the Paris case. R-squares for London areand. For Paris, they areand

---

### The hammam effect or how a warm ocean enhances large scale atmospheric predictability [^382ddf87]. Nature Communications (2019). High credibility.

Local dimension and persistence

To determine d, we exploit recent results from the application of extreme value theory to Poincaré recurrences in dynamical systems. This approach considers long trajectories of a system — in our case successions of daily SLP latitude–longitude maps — corresponding to a sequence of states on the attractor. For a given point ζ in phase space (e.g. a given SLP map), we compute the probability that the system returns within a ball of radiuscentred on the point ζ. The Freitas et al.theorem, modified by Lucarini et al. states that logarithmic returns:

yield a probability distribution such that:

where z = g (x (t)) and s is a high threshold associated to a quantile q of the series g (x (t)). Requiring that the orbit falls within a ball of radiusaround the point ζ is equivalent to asking that the series g (x (t)) is over the threshold s; therefore, the ball radiusis simply e − s(q). The resulting distribution is the exponential member of the Generalised Pareto Distribution family. The parameters μ and σ, namely the location and the scale parameter of the distribution, depend on the point ζ in phase space. μ (ζ) corresponds to the threshold s (q), while the local dimension d (ζ) can be obtained via the relation.

When x (t) contains all the variables of the system, the estimation of d based on extreme value theory has a number of advantages over traditional methods (e.g. the box counting algorithm). First, it does not require to estimate the volume of different sets in scale space: the selection of s (q) based on the quantile provides a selection of different scales s, which depends on the recurrence rate around the point ζ. Moreover, it does not require the a priori selection of the maximum embedding dimension as the observable g is always a univariate time-series.

The persistence of the state ζ is measured via the extremal index, an adimensional parameter, from which we extract. θ (ζ) is therefore the inverse of the average residence time of trajectories aroundand it has unit of a frequency (in this study 1/days). If ζ is a fixed point of the attractor. For a trajectory that leaves the neighbourhood of ζ at the next time iteration, θ = 1. To estimate θ, we adopt the Süveges estimator. For further details on the extremal index, see ref.

---

### The European guideline on management of major bleeding and coagulopathy following trauma: sixth edition [^25fd0a0b]. Critical Care (2023). High credibility.

Regarding diagnostic investigations for traumatic hemorrhage, more specifically with respect to initial assessment, ABC-T 2023 guidelines recommend to assess the extent of traumatic hemorrhage clinically using a combination of patient physiology, anatomical injury pattern, mechanism of injury, and the patient response to initial resuscitation.

---

### Predicting what will happen when we act. what counts for warrant? [^58aa35d9]. Preventive Medicine (2011). Low credibility.

To what extent do the results of randomized controlled trials inform our predictions about the effectiveness of potential policy interventions? This crucial question is often overlooked in discussions about evidence-based policy. The view I defend is that the arguments that lead from the claim that a program works somewhere to a prediction about the effectiveness of this program as it will be implemented here rests on many premises, most of which cannot be justified by the results of randomized controlled trials. Randomized controlled trials only provide indirect evidence for effectiveness, and we need much more than just randomized- controlled-trial results to make reliable predictions.

---

### Simple spatial scaling rules behind complex cities [^23b5e063]. Nature Communications (2017). Medium credibility.

Spatial scaling

Our simple rules produce the AP, road network, and socioeconomic interaction distributions (see Fig. 1b, c). The AP distribution and its morphology are in good agreement with the real city of Greater London (see Fig. 1d).

The model allows us to quantify these predictions. According to the SA mechanism, when t is sufficiently large the spatial distribution of AP is approximatelywhere ρ (r, t) is the average density at distance r from the city centre, i.e. the seed node at position (0, 0), R (t) is the radius of the entire city at time t (see Fig. 2b and further details of the explicit form of ρ (r, t) are in Supplementary Note 1), and β is a parameter derived from C. The dependence of β on C (see Fig. 2a) can be derived by the non-linear fitting, and the simulation results are shown in Fig. 2b. Figure 2c shows that the collected data validate Eq. (4). The AP in the real data is defined as a mixture of working and residential populations according to their active duration in that region (see Methods). In the downtown area (i.e. when r / R (t) → 0), the AP density decays following the power law shown in Eq. (4) (see Fig. 2c). In contrast, residential population density decays exponentially as we move from city centre to urban fringe, as verified in previous researchand our data (see Supplementary Fig. 8). This reconciles the conflict between area-size allometry and the exponential decay of population from city centre to urban fringe found in the literature. To eliminate the influence of noise in the empirical data and allow an unbiased comparison of different quantities, we study the cumulative quantities in terms of the distance from the central area instead of the local density (see Fig. 3). Integrating Eq. (4) we obtainwhere P (r, t) is the cumulative AP within the concentric circle of the central area with radius r (see Supplementary Note 3 and Supplementary Fig. 7 for detailed derivations). This expression is approximately a power law with an exponent 2 − β when. This is consistent with the fractal city hypothesis, and the fractal dimension is 2 − β if the distributions of APs and buildings are similar. We can similarly calculate the cumulative road length and socioeconomic interactions asandTherefore the exponents of the cumulative length of the road network and socioeconomic interactions within the circle of radius r are 2 − β /2 and 2 − 3 β /2. These predictions are consistent with the data from Beijing and London shown in Fig. 3. Due to the need for high-resolution data, we use nighttime light as the proxy for socioeconomic interactions –. Although nighttime light data has some intrinsic disadvantages when representing high-resolution interactions (e.g. at a community level, because luminosity is also associated with road density and type of land use), it remains the best candidate among open-source data. We show that as long as the spatial resolution is not excessively high it is a good proxy (see Methods, Supplementary Figs. 10 and 12–14 and Supplementary Note 6 for further discussion). Thus based on Eqs. (5)–(7) we can obtain all the other spatial scaling exponents from any single observation.

---

### Probabilistic alignment of multiple networks [^39aa70ac]. Nature Communications (2025). High credibility.

The network alignment problem appears in many areas of science and involves finding the optimal mapping between nodes in two or more networks, so as to identify corresponding entities across networks. We propose a probabilistic approach to the problem of network alignment, as well as the corresponding inference algorithms. Unlike heuristic approaches, our approach is transparent in that all model assumptions are explicit; therefore, it is susceptible of being extended and fine tuned by incorporating contextual information that is relevant to a given alignment problem. Also in contrast to current approaches, our method does not yield a single alignment, but rather the whole posterior distribution over alignments. We show that using the whole posterior leads to correct matching of nodes, even in situations where the single most plausible alignment mismatches them. Our approach opens the door to a whole new family of network alignment algorithms, and to their application to problems for which existing methods are perhaps inappropriate.

---

### A unifying theory explains seemingly contradictory biases in perceptual estimation [^fca2b449]. Nature Neuroscience (2024). High credibility.

Perceptual biases are widely regarded as offering a window into the neural computations underlying perception. To understand these biases, previous work has proposed a number of conceptually different, and even seemingly contradictory, explanations, including attraction to a Bayesian prior, repulsion from the prior due to efficient coding and central tendency effects on a bounded range. We present a unifying Bayesian theory of biases in perceptual estimation derived from first principles. We demonstrate theoretically an additive decomposition of perceptual biases into attraction to a prior, repulsion away from regions with high encoding precision and regression away from the boundary. The results reveal a simple and universal rule for predicting the direction of perceptual biases. Our theory accounts for, and yields, new insights regarding biases in the perception of a variety of stimulus attributes, including orientation, color and magnitude. These results provide important constraints on the neural implementations of Bayesian computations.

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^075005b9]. Magnetic Resonance in Medicine (2021). Medium credibility.

Regions A and B are geometrically symmetric about the z = 0 plane, with minimum energy solutions (assuming no E‐field constraint) yielding z‐symmetric field solutions and zero B 0 concomitant fields. Hence, the open diamond starting point (representing the minimum energy solution with no E‐field constraints) for the solid and dashed curves (in both black and green cases) coincide. The symmetry is broken by the addition of a patient model with an E‐field constraint.

The knee in the curves marks the point where magnetic energy, current density, and winding complexity increase rapidly as E max is driven to lower values. These complexities render unrealizable or impractical any gradient designs on the vertical portions of the curves to the left of the knee. Examination of winding patterns indicates that solutions that exhibit energy increases > 25% (or even less depending on coil type) above the global minimum energy become unrealizable (eg, demonstrating two or more "eyes" per half coil [four or more total eyes for an x or y coil] in the fingerprint wire patterns).

The red and purple dotted curves in Figure 2 represent two practical cases in which the primary coil currents are restricted to a single inner surface near the patient and the shield coil currents to an outer cylinder, while at the same time adding torque and eddy current constraints. Line segments acd of Figure 1 represent a primary winding surface consisting of a cone and a cylinder, whereas line segment ab represents its cylindrical shield winding; this yields designs similar to those proposed by previous literature 8, 22 and results in the red dotted curves in Figure 2. A second case is defined by restricting primary currents to the cylinder represented by line segment cd and shield currents to the cylinder ab; this yields designs similar to those proposed by previous literature 28 and produces the purple dotted curves in Figure 2. For both configurations, the eddy current surface is a 1‐m‐long, 620‐mm‐diameter cylinder, centered about the gradient isocenter and placed outside the shield winding of the gradient coil. The time = 0 eddy current error is constrained to a peak deviation less than 0.1% of the ideal gradient field on the surface of a 20‐cm‐diameter volume, corresponding to 100 µT for a 1 T/m step change in gradient strength. The torque constraint is set to zero for a uniform z‐directed B 0 main magnetic field. There is no net force for a perfectly uniform main B 0 field in all calculations.

---

### Resolving the topology of encircling multiple exceptional points [^90aa5245]. Nature Communications (2024). High credibility.

Non-Hermiticity has emerged as a new paradigm for controlling coupled-mode systems in ways that cannot be achieved with conventional techniques. One aspect of this control that has received considerable attention recently is the encircling of exceptional points (EPs). To date, most work has focused on systems consisting of two modes that are tuned by two control parameters and have isolated EPs. While these systems exhibit exotic features related to EP encircling, it has been shown that richer behavior occurs in systems with more than two modes. Such systems can be tuned by more than two control parameters, and contain EPs that form a knot-like structure. Control loops that encircle this structure cause the system's eigenvalues to trace out non-commutative braids. Here we consider a hybrid scenario: a three-mode system with just two control parameters. We describe the relationship between control loops and their topology in the full and two-dimensional parameter space. We demonstrate this relationship experimentally using a three-mode mechanical system in which the control parameters are provided by optomechanical interaction with a high-finesse optical cavity.

---

### Sphere of arbitrarily polarized exceptional points with a single planar metasurface [^21f97c28]. Nature Communications (2025). High credibility.

Figure 1d demonstrates the calculated eigenstate evolution of the reflection matrix versus wavelength with a fixed nanorods orientation angleand a fixed incident condition. The two eigenstates coalesce at an EP whose position on the Poincaré sphere attests to an arbitrary elliptical polarization (red star). To show the controllability of the EP position on the Poincaré sphere, we illustrate its evolution as a function of the incidence angles (and). At fixed altitude angle of, varyingenables to move the polarization of coalesced eigenstates along the latitude of the Poincaré sphere, as shown in Fig. 1e. Similarly, the elliptical angle of the coalesced polarization eigenstates at the EP can be fine-tuned by changing. Therefore, by tuning the incidence angles (and) of the incident light we modify the extrinsic chirality and, thus, the polarization conversion reflection matrix, which in turn dictates the polarization of the coalesced eigenstates. Eventually, for a single sample, by varyingandin a large enough range one can make arbitrary EPs covering the entire Poincaré sphere, as illustrated in Fig. 1f by the homogeneous cloud of orange points enveloping the sphere.

---

### Levonorgestrel and ethinyl estradiol (Altavera) [^0e0089d0]. FDA (2023). Medium credibility.

- Look at your pill pack. Your pill pack consists of 1 card that holds 28 individually sealed pills. The 28 pills consist of 21 light-orange pills (3 rows of 7 pills) and 7 pink pills (1 row of 7 pills). See Figure A.

Figure A

- **Also find**:

o Where on the card to start taking pills (upper left corner) and

o In what order to take the pills (follow the weeks)

- Be sure you have ready at all times another kind of birth control (such as condoms or spermicide), to use as a back-up in case you miss pills.

When should I start taking Altavera?

If you start taking Altavera and you have not used a hormonal birth control method before:

- There are 2 ways to start taking your birth control pills. You can either start on a Sunday (Sunday Start) or on the first day (Day 1) of your natural menstrual period (Day 1 Start). Your healthcare provider should tell you when to start taking your birth control pill.

- If you use the Sunday Start, use non-hormonal back-up contraception such as condoms or spermicide for the first 7 days that you take Altavera. You do not need back-up contraception if you use the Day 1 Start.

---

### Primary angle-closure disease preferred practice pattern ® [^75d30b97]. Ophthalmology (2021). High credibility.

Primary angle-closure disease PPP — additional methods notes specify that all studies used to form a recommendation for care are graded for strength of evidence individually and that grade is listed with the study citation, that all recommendations for care in this PPP were rated using the system described above with ratings embedded throughout the PPP main text in italics, that the Highlighted Findings and Recommendations for Care section lists points determined by the PPP Panel to be of particular importance to vision and quality of life outcomes, and that literature searches to update the PPP were undertaken in March 2019 and June 2020 in the PubMed and Cochrane databases with complete details available in Appendix 4.

---

### Carrier density and disorder tuned superconductor-metal transition in a two-dimensional electron system [^f60f2550]. Nature Communications (2018). Medium credibility.

Back-gate modulation of the interface ground state

The counterpart R – T curves and phase diagram under varying V BG at fixed V TG = 1.8 V are shown in Fig. 3. Following the analysis of the second derivative of the R – T curves (Fig. 3a, b), a phase diagram is obtained as a function of V BG (Fig. 3c). Note that back-gate modulation produces a rather different phase diagram from the top-gate case (shown previously in Fig. 2): T P monotonically decreases with V BG; both T F and T C are non-monotonic, and T C exhibits a complete dome; on both sides of the dome, the resistivity saturates at finite values approaching zero temperature. A key finding here is the deviation between T P and T C on the negative back-gate side of the dome. The behaviour of T P and T C is qualitatively consistent across the dome with the pseudogap observations from tunneling spectroscopy. This implies a correspondence between T P and gap opening.

Fig. 3
Back-gate modulation of the interface ground state. a Sheet resistivity versus temperature (R – T) curves as a function of V BG from −46 to 90 V with fixed V TG = 1.8 V. b The second-order derivative calculated using a spline fit of the R – T curves shown in a. Red circles and blue squares indicate the local maxima of the peaks, defining T P and T F. Curve colours are matched between a and b. c Phase diagram for back-gating with fixed V TG = 1.8 V. Red circles, blue squares, and blue triangles represent T P, T F, and T C, respectively. Normal state here indicates a non-superconducting state. Error bars are defined by the full width of the second derivative peaks for T P and T F. T C is defined as the temperature at which the sheet resistivity drops to 1% of the normal state R N (400 mK). The lowest temperature measured for our R – T curves is 40 mK, so data points estimated to be < 40 mK are plotted with arrows. Background colours are guides to the eye indicating the different regimes

---

### The 30-degree angle revisited [^eec48357]. Journal of the American Academy of Dermatology (2005). Low credibility.

The standard surgical ellipse, with 30 degrees apical angles and a length-to-width ratio of 2 or 3 to 1, works optimally on a flat surface. The same pattern, when used for excisions on strongly convex or concave surfaces, leads to distortions which may require significant revisions. The reason for these discrepancies is explainable by the mathematical differences between flat Euclidian geometry and curved non-Euclidian geometry. Understanding these basic mathematical principles as applied to cutaneous surgery should lead to better preoperative planning, fewer intraoperative surprises, and more pleasing results.

---

### Sphere of arbitrarily polarized exceptional points with a single planar metasurface [^1d03c06b]. Nature Communications (2025). High credibility.

Topological properties of arbitrary EP

We previously showed that an EP-induced reflection zero enables us to accumulate a topological phase covering the fullrange by encircling the EP within a rationally chosen two-dimensional parameter space. In the following, we demonstrate that relying on the topological phase accumulated while encircling an EP exhibiting arbitrarily polarized eigenstate (linearly, circularly, and elliptically polarized cases correspond to the first, second, and third column in Fig. 2, respectively), we can manipulate the phase of light on a single polarization channel for any arbitrary polarization with a single metasurface by varying incidence conditions. To observe the EP complex-square-root dependency of the eigenvalue surfaces, we plot the real and imaginary parts of the eigenvalues in the two-dimensional parameter space of, corresponding to the rotation angles of the two metallic nanorods. These two parameters are expected to control the co- and cross-polarization ratio. By sweeping them in the vicinity of the parameters corresponding to the EP with linearly polarized eigenstates, the real and imaginary parts of the eigenvalues of the reflection matrix present two intersecting Riemann surfaces, which coalesce at the EP (See Supplementary Figs. S4 and S5). Furthermore, at the intersecting point, the reflection coefficient ofcomponent is zero (singularity), as shown in Fig. 3a, consistent with the EP nature of this coalescence point. As we previously pointed out, we obtain a phase winding around the EP singularity that realizes a fullphase coverage, of interest for the design of polarization-converting metasurfaces. It should be noted that due to its topological nature, the accumulated phase always coversregardless of the trajectory followed in parameter space, as long as the loop encircles the conversion zero in reflection. EP-induced topological phase can thus be employed for hologram construction by choosing four unit-cell designs sufficiently far away enough from the zero point to have higher efficiency, corresponding to four different rotation angles around the singularity center (indicated by the black triangles in Fig. 3a). EPs with circularly polarized coalesced eigenstates are also realized, as presented in the second column of Fig. 3, where we obtain similar degeneracy of eigenvalues and an equivalent topological phase pattern (Fig. 3b). For completeness, the last column shows an example of EP with elliptically polarized coalesced eigenstates, characterized by. The topological phase still shows the 2winding, as shown in Fig. 3c. It is worth mentioning that, for a fixed geometry, other arbitrarily polarized topological phases can also be realized under different incident conditions. In contrast, the other anti-diagonal channel of the reflection matrix reveals no topological phase, as illustrated in Fig. 3d–f, corresponding to the EPs showing linear, circular, and elliptical polarization, respectively. Overall, this demonstrates that the topological phase accompanying an EP in a two-dimensional parameter space can be designed to act on any arbitrary polarization state and, thus, allows to modulate the wavefront of any polarization. With the detailed four structures around each EP summarized in Fig. 3g (black triangles in Fig. 3a–f), a 2phase variation can be covered and used for wavefront manipulation. The corresponding amplitudes are shown in Fig. 3h. Building on this design versatility and exploiting the 2phase acquired by beams of adequate polarization when encircling EPs with coalesced eigenstate of the same polarization, we can fabricate a single metasurface simultaneously displaying EPs for three different polarizations (linear, circular, and elliptical). In the following section, we illustrate this by spectrally and spatially monitoring the occurrence of zeros in one anti-diagonal Jones matrix component, while the other components are nonzero. In the last section, we combine the full capabilities of our approach to produce one and the same meta-holograms generated thanks to the 2ET phase for three different polarizations (illustration shown in Fig. 3i).

---

### From the betweenness centrality in street networks to structural invariants in random planar graphs [^29785c51]. Nature Communications (2018). Medium credibility.

Fig. 3
Effect of edge-density ρ e on the betweenness. N ∼10 4 nodes were randomly distributed on the 2D plane and their DT was generated. Edges were removed until the desired edge-density ρ e was reached. a – d The average over a hundred realizations of the resulting BC distribution ranging from the MST to the DT with increasing ρ e. The orange shaded area corresponds to fluctuations around the average of the realizations, while the silver and white shades separate the "tree-like" region from the "loop-region" respectively. e – h a single instance of the actual generated network corresponding to each ρ e. Shown in red are the nodes in the 90th percentile and above in terms of their BC value

The simulations indicate the observed bimodality to be a combination of a high betweenness backbone belonging to the MST, and a low betweenness region generated by loops. The transition between the two regimes is determined by the minimum non-zero betweenness value for the MST, which is O (N) and the tail may have different peaks, determined by the distribution of branches emanating from the tree. Progressively decorating the tree with loops leads to arbitrarily low betweenness values due to the creation of multiple alternate paths, thus smoothing out the distribution, as the betweenness transitions from an interval [N, N 2] for the MST to a continuous distribution over [1, N 2] for the DT.

Spatial distribution of high betweenness centrality nodes

Figure 3e–h shows a single instance of the actual network generated by our procedure for each corresponding edge-density. Highlighted in red are nodes lying in the 90th percentile of betweenness. There is a distinct change in spatial pattern with increasing ρ e; for the MST, they span the network and are tree-like with no apparent spatial correlation; as the network gets more dense, the nodes cluster together and move closer to the barycenter, suggesting a transition between a "topological regime" and a "spatial regime".

To quantify these observed changes, we investigate the behavior of the high BC nodes at and above percentile θ through a set of metrics: the clustering C θ which measures the spread of high betweenness nodes around their center of mass, the anisotropy factor A θ which characterizes the spatial anisotropy of this set of nodes, and finally, the detour factor D which measures the average extent to which paths between two locations deviate from their geodesic distance. (Details on metrics shown in Methods)

---

### Real-time observation of the spin hall effect of light using metasurface-enabled single-shot weak measurements [^090a2641]. Nature Communications (2025). High credibility.

Theoretically predicted, numerically simulated, and experimentally measured W values are displayed in Fig. 3 b (see Methods for the numerical simulation). At this static interface, δ = 225.0 nm (Eq. (1)) and W follows a cotangent curve as α changes (Eq. (3)). The linear relation between W and δ begins to deviateand becomes nonlinear asas α approaches zero (compare black solid and dotted curves) and reduces to zero after reaching its maximum value, μ m (black solid). The simulated W using the ideal phase map (blue dashed) and the realistic metasurface design (red dashed) closely match the theoretical predictions and are nearly indistinguishable in Fig. 3 b. In the conventional weak measurement setup (Fig. 1 b) conducted for comparison, the postselected beam is captured by varying α from − 2.5° to 2.5°. The measured W values are obtained after finding the center position of the incidence (y = 0) when the entire process is completed. The experimental results agree with the theory (black square). A single capture, however, does not provide the weak values.

In contrast, the metasurface-implemented weak measurement does not require such a multistep or calibration process. Before starting this measurement, the metasurface is mounted on a rotation stage and positioned so that the splitting direction under direct incidence is 45°. This process is intended to align the metasurface horizontally, corresponding to α = 0, akin to aligning the optical axis of a commercial polarizer prior to measurements, and is not a calibration. We conduct the measurement by rotating the metasurface (Fig. 3 a) and acquire a single image that includes two postselected beams simultaneously. The rotation of the metasurface not only determines the postselection angle but also alters the deflecting direction from π /4 to π /4 − α (Fig. 3 d and g, black line). The difference in the y position averages between the two postselected beams is obtained from the single image aswhere X, Y are the center position differences of the two beams along the x - and y -axes, respectively (see Supplementary Note 9). The weak signals are then determined usingand are shown as red circles in Fig. 3 b. These results are in excellent agreement with theoretical and simulated results.

---

### As-3 [^f4572ab3]. FDA (2025). Medium credibility.

Storage and handling

Store at room temperature (25 °C/77 °F). Avoid excessive heat.

Protect from freezing

---

### Prominent effects and neural correlates of visual crowding in a neurodegenerative disease population [^527ea900]. Brain (2014). Low credibility.

Task 3: Shape flankers

Target letters (n = 24) were flanked on each side by a triangle presented at different orientations. Triangles were of equal height and line thickness to target letters.

Task 4: Number flankers

Target letters (n = 24) were flanked on each side by an Arabic numeral, chosen from a range between 2 and 9.

Task 5: Same-polarity flankers

Target letters (n = 24) were flanked on each side by black letters; presentation was as Task 2 except that items were presented on a grey background to match Task 6 (see below).

Task 6: Reverse-polarity flankers

Target black letters (n = 24) were flanked on each side by white letters, all presented on a grey background.

The edge-to-edge distance between the target letter and flankers was 0.1° of visual angle in the condensed condition and 1.0° in the spaced condition at a viewing distance of 50 cm; the height of stimuli (10.5 mm) corresponded to a visual angle of 1.20°. Participants were given one prompt for each trial where they named the flanker ('Is that the letter in the middle?'); this prompt was intended to limit errors resulting from visual disorientation. The same combination of flankers was used for each target letter under both spatial conditions within each flanker condition. Alphabetic items occurred with equal frequency within each task. The stimuli were presented in blocks of six items, with blocks being administered in an ABBA design. All flanked stimuli were presented in the centre of the screen within a fixation box (6.4° in width, 2.9° in height). All 26 patients with PCA completed Tasks 1, 2 and 4; 24 completed Task 3; and 22 completed Tasks 5 and 6. Naming latencies were manually determined from the onset of each letter using Audacity.

Data analysis

---

### 2024 ACC / AHA / AACVPR / APMA / ABC / SCAI / SVM / SVN / SVS / SIR / VESS guideline for the management of lower extremity peripheral artery disease: a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^98745ce1]. Circulation (2024). High credibility.

Regarding diagnostic investigations for peripheral artery disease, more specifically with respect to ABI, technical considerations, AACVPR/ABC/ACC/AHA/APMA/SCAI/SIR/SVM/SVN/SVS/VESS 2024 guidelines recommend to report resting ABI results as follows:

| **Situation** | **Guidance** |
|-|-|
|Abnormal|- ≤ 0.90|
|Borderline|- 0.91–0.99|
|Normal|- 1.00–1.40|
|Noncompressible|- > 1.40.|

---

### Prism adaptation treatment for upper-limb complex regional pain syndrome: a double-blind randomized controlled trial [^22ee7d1d]. Pain (2021). Medium credibility.

The Temporal Order Judgement task measures covert spatial attention. Participants saw pairs of brief, identical light flashes, presented with different temporal offsets (± 10 to 240 ms range) onto a white table surface, one on each side of space. In one block, participants reported which of the 2 lights they perceived first by saying "left" or "right". In another block, they reported which light they perceived second. The order of response type (first or second) was counterbalanced, and results were averaged across these to account for any response bias. We calculated the Point of Subjective Simultaneity, which expresses by how many milliseconds the light in the affected side of space had to precede (negative score) or follow (positive score) the light in the unaffected side of space for both lights to be perceived as simultaneous. Information that receives greater attention is perceived earlier than information that receives lesser attention. Thus, a negative Point of Subjective Simultaneity indicates lower attention to the affected side of near space relative to the unaffected side.

The Landmark taskmeasures the visual representation of relative horizontal distance in near space. Participants saw pairs of landmarks (white circles) presented simultaneously, one on each side of space. While the distance between 2 landmarks was constant across all trials, their relative distance from the central fixation cross varied by 0.1° increments from ± 8.1° to ± 6.9° to the left and to the right. Participants indicated through a button press whether the left or the right landmark appeared closer to or further from the fixation cross. Results were averaged across 2 separate response blocks to account for any response bias. We calculated the Point of Subjective Equality, which expresses the relative distance (°) at which the landmark on the affected side of space had to be further from (negative score) or closer to (positive score) the fixation cross to perceive the 2 landmarks to be equidistant. A negative Point of Subjective Equality value indicates underestimation of the distance on the affected relative to the unaffected side and thus underrepresentation of the affected side of near space.

---

### Sphere of arbitrarily polarized exceptional points with a single planar metasurface [^7faf24a1]. Nature Communications (2025). High credibility.

Singular nature of the coalescence points

Arbitrary EP in the matrixinduces coalesced eigenvalues and eigenstates | e EP 〉 with skewed eigenspace, implying for an input state | e EP 〉 the output is necessarily proportional to | e EP 〉. In other words, the EP creates an anti-diagonal zero channel onfrom | e EP 〉 to its orthogonal counterpart, i.e. Figure 2a displays the four components of the singularity-retrieved reflection matrixinduced by arbitrary EP as a function of wavelength. A reflection singularity ofis observed, as expected by design. To prove that this reflection zero is associated with an EP, we compute the eigenvalues and eigenstates of the reflection matrix. The corresponding eigenvalues, obtained from the reflection matrix, are shown in Fig. 2d, with coincided amplitudes and phases at the spectral location of the reflection zero. Figure 2g shows the spectral evolution of the two eigenstates ofon the Poincaré sphere in the surroundings of the reflection zero (red star). Both trajectories converge to the red star located along the equator of the Poincaré sphere, i.e. linear polarization. These concomitant eigenvalues and eigenstates coalescences demonstrate that, indeed, the spectral reflection zero is associated to an EP of the reflection matrix. Most interestingly, for the same metasurface, one can achieve EPs corresponding to circularly polarized eigenstates as well as EPs displaying elliptically polarized eigenstates. To demonstrate the control over the position of the EPs on the Poincaré sphere we modify the incident anglesandwith respect to the previous example but keeping the structures unchanged and we sweep the wavelength. EP displaying circularly polarized eigenstate i.e. located on the pole of the Poincaré sphere, is also realized, as shown in Fig. 2b–h. An example of an EP with elliptically polarized eigenstate, characterized by, is shown in Fig. 2c–i. Finally, these three examples highlight the complete, and previously unattainable, control over polarization eigenstates of EPs.

---

### VA / DoD clinical practice guideline for the management of chronic obstructive pulmonary disease [^90bc90ce]. VA/DoD (2021). High credibility.

VA/DoD chronic obstructive pulmonary disease (COPD) algorithm notation — The algorithm is a step-by-step decision tree in which standardized symbols are used to display each step, arrows connect numbered boxes to indicate order, and sidebars provide detailed interpretive information. Rounded rectangles represent a clinical state or condition, hexagons represent a decision point formulated as a question answered "Yes" or "No", rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm. Appendix J contains alternative text descriptions of the algorithm modules.

---

### Baseband control of single-electron silicon spin qubits in two dimensions [^5ed02956]. Nature Communications (2025). High credibility.

First, the micromagnet is magnetized in a 0.8 T external field. We populate the array with a single electron in dots 1 and 4, allowing us to keep PSB readout on the pair Q 4 Q 1 while dots D 2 and D 3 remain empty. We track the qubit frequencies of Q 1 and Q 4 using adiabatic inversion pulses as the external field is reduced step-by-step as shown in Fig. 3 a. We observe the qubit frequencies dropping both as a result of the lower external field as well as the demagnetization of the micromagnet. The polarization of the micromagnet is inferred by fitting the measured frequencies to a simplified magnet model where the magnetization is assumed to be homogeneous with no crystalline domains or shape anisotropy coming into consideration (see Supplementary Note 2). Even so, this model provides a firm basis for understanding the qualitative qubit properties across a wide range of external field settings.

---

### Coordinated representations for naturalistic memory encoding and retrieval in hippocampal neural subspaces [^48f53d41]. Nature Communications (2025). High credibility.

We further examined the directional alignment of neural states along the shared axis between their neural subspaces. To assess this within the neural dynamics, we projected average neural responses for each novelty and memorability condition onto the shared coding axis within their respective hippocampal subspaces using the first PC of novelty subspaces and the second PC of the memorability subspace. We then computed the Spearman rank correlation between the projected values of the neural trajectories along these axes across memorability and each novelty level at each time point to measure the directionality between novelty and memorability computations. After event boundaries, the neural states corresponding to novelty and memorability levels were aligned in opposite directions (t = +4 seconds; the average of directionality: p = −.62, p = .008, from a one-sided permutation test) (Fig. 5D; Supplementary Fig. 9A for each type of novelty). Each process was also reflected in its respective neural trajectories following event boundaries (Supplementary Fig. 9B – D). However, while the directionality remained positive 4 seconds before event boundaries, indicating alignment in the same direction, neural states corresponding to each novelty and memorability level were not orderly arranged along the shared coding axis (Fig. 5D, Supplementary Fig. 9). This finding suggested that initially misaligned neural states rearrange in opposite directions along the shared coding axis of the three subspaces (i.e. two types of novelty and memorability) after event boundaries, reflecting memory performances.

---

### Clustering knowledge and dispersing abilities enhances collective problem solving in a network [^9f543c96]. Nature Communications (2019). High credibility.

The severity of this problem's complexity is not additive or linear in nature, but interdependent on all of the sub-problems that need to be solved for this to work. Furthermore, adopting a solution might have unintended, if not non-linear, consequences to the system's overall outcome that were not obvious or foreseeable. For instance, allowing students to use their mobile phones in schools might seem like a good idea to improve class engagement through other media, but an unintended consequence might be distraction or discouraging deeper critical thinking. The objective of the NK space is to capture the complex interaction among activities that yield performance. The NK problem space's popularity in modeling human decision-making stems from its verisimilitude with the complex and multidimensional problems that face problem-solving tasks, and because researchers can easily generate a large number of statistically similar problem spaces for robustness checks. (We note, however, in order to make sure our results are not an artifact of the idiosyncrasies of the NK problem space, we replicated all of our results in another rugged problem space, the Traveling Salesperson Problem — findings available in Supplemental Methods in Supplementary Fig. 2 through 9 and 11).

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^09bf3bfd]. Journal of the American College of Cardiology (2025). High credibility.

Cost-effectiveness plane — decision logic for new interventions is described by explicit ICER threshold labels and dominance definitions. When a new intervention is more effective and less costly, the 'Intervention is cost-saving ("dominant") or always acceptable', whereas when it is less effective and more costly, the 'Intervention is inferior ("dominated") or never acceptable'. For cases where the new intervention is more costly and more effective, 'ICER ≥ C-E threshold Intervention is not cost-effective' and 'ICER < C-E threshold Intervention is cost-effective'. In the less costly but less effective quadrant, labels specify 'ICER ≤ C-E threshold Intervention is not cost-effective' and 'ICER > C-E threshold Intervention is cost-effective', and the caption notes that when a new intervention produces less health and lower costs, 'it may be considered cost-effective if the ICER is greater than the cost-effectiveness threshold'.

---

### Mutations of PDS5 genes enhance TAD-like domain formation arabidopsis thaliana [^d6e06152]. Nature Communications (2024). High credibility.

Fig. 1
Analysis of TAD-like domains in pds5a/b/c/e.

a Prominent TAD-like structures in pds5a/b/c/e, showcased by a representative 1 Mb genomic region. b Comparison of insulation score profile of a 1 Mb region at chromosome 3 with the corresponding Hi-C map shown on top. The regions showing local insulation score minima indicate strong chromatin insulation. c Genome-wide correlation of insulation scores between different plants. r, Pearson correlation coefficients. d Metagene plots of chromatin interaction patterns in different plants around the loci displaying strong chromatin insulation in pds5a/b/c/e. e Insulation scores in wild-type plants. The category "Insulated" refers to those loci showing strong chromatin insulation in pds5a/b/c/e. *, significant (p = 4.2 × 10 −114) according to a two-sided Mann–Whitney U-test. The boxplots depict the data quartiles (first and third), the dashed lines represent individual data points, and the median is indicated by black lines within the boxes. f Size distribution of TAD-like domains in pds5a/b/c/e. The boxplot follows the same format as in (e). g Metagene plot illustrates relative chromatin contact strengths in TAD-like domains identified in pds5a/b/c/e. The flanking regions (100 kb) are also included. The top side shows WT and the bottom side shows mutant. Besides the strong insulation region, the extended signal on the top of the triangle promotes the detection of strong boundaries in pds5a/b/c/e. h Distribution of TSS around pds5a/b/c/e TAD borders (labeled with 0). The right gray side represents the 25 kb within the TAD-like domains, the left side from 0 represents 25 kb of flanking area. Both transcription directions are included. i Chromatin accessibility associated with TAD-like domain borders in pds5a/b/c/e. j Comparison of gene expression in pds5a/b/c/e between genes located at TAD-like domain borders and elsewhere. *, significant (p = 6.2 × 10 −13) according to a two-sided Mann–Whitney U-test. The boxplots follow the same format as in (e). Source data are provided as a Source Data file.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^6dc255dc]. Journal of the American College of Cardiology (2025). High credibility.

AHA/ACC cost/value methodology — cost-effectiveness metrics defines and applies the ICER as follows: The most widely used metric of cost-effectiveness is the incremental cost-effectiveness ratio or ICER, defined as the ratio of the net increase in spending of the intervention versus the comparator to the net increase or improvement in outcome. In a pairwise comparison, interventions that produce higher costs and better health outcomes should be reported as cost-effective if the ICER is less than the cost-effectiveness threshold or not cost-effective if the ICER is greater than or equal to the cost-effectiveness threshold. Economic value statements should include both the point estimate as well as the probability of being cost-effective at the accepted cost-effectiveness threshold when available. Although it is reasonable for the supporting text accompanying the economic value statement to report uncertainty intervals around the ICER when results are within 1 quadrant of the cost-effectiveness plane, the probabilistic findings may be easier to interpret. Incremental CEA methods should be used when evaluating 3 or more mutually exclusive interventions. Of note, interventions that are less effective and have lower costs relative to the comparator are considered cost-effective if the ICER is greater than the cost-effectiveness threshold, which necessitates careful interpretation. Interventions that produce lower costs and better health outcomes than the comparator should be reported in economic value statements as cost-saving (or "dominant"); interventions that produce higher costs and worse health outcomes than the comparator should be reported in economic value statements as inferior (or "dominated"). Negative ICERs should not be reported because they are not interpretable.

---

### VA / DoD clinical practice guideline for management of posttraumatic stress disorder and acute stress disorder [^a105391d]. DoD/VA (2023). High credibility.

Algorithm — VA/DoD Clinical Practice Guideline for Management of Posttraumatic Stress Disorder — states that this clinical practice guideline's algorithm is designed to facilitate understanding of the clinical pathway and decision-making process used in managing patients with PTSD and represents a simplified flow that helps foster efficient decision making by providers; it includes steps of care in an ordered sequence, decisions to be considered, decision criteria recommended, and actions to be taken. The algorithm is a step-by-step decision tree in which standardized symbols display each step and arrows connect the numbered boxes indicating the order in which the steps should be followed; sidebars 1–11 provide more detailed information to assist in defining and interpreting elements in the boxes. The legend specifies that rounded rectangles represent a clinical state or condition, hexagons represent a decision point in the process of care formulated as a question that can be answered Yes or No, rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm, and Appendix H contains alternative text descriptions of the algorithms.

---

### European Stroke Organisation (ESO) and European Association of Neurosurgical Societies (EANS) guideline on stroke due to spontaneous intracerebral haemorrhage [^a24b784e]. European Stroke Journal (2025). High credibility.

Regarding diagnostic investigations for intracerebral hemorrhage, more specifically with respect to initial evaluation, EANS/ESO 2025 guidelines recommend to consider using algorithms such as the DIAGRAM for targeted investigation of the cause of spontaneous ICH to improve the performance of prediction regarding the underlying cause, compared to standard care.

---

### Hemineglect: take a look at the back space [^c3586568]. Annals of Neurology (2007). Low credibility.

Visual hemineglect, the failure to explore the half of space, real or imagined, contralateral to a cerebral lesion with respect to body or head, can be seen as an illustration of the brain's Euclidean representation of the left/right axis. Here we present two patients with left-sided neglect, in whom only the left hemispace in front of an imagined and/or real body position was inaccessible, but the space behind them remained fully represented. These observations suggest that of the three Euclidean dimensions (up/down, left/right, and front/back), at least the latter two are modularly and separately represented in the human brain.

---

### Microfluidic multipoles theory and applications [^31dd0050]. Nature Communications (2019). High credibility.

Upon inspection, the problem can be transformed to streamline coordinates (Fig. 2a) using the function

In the streamline domain Φ, the problem is equivalent to a channel geometry with flows of concentration c = 1 and c = 0 separated by a no-flux boundary condition on the origin. At the stagnation point, the no-flux condition is dropped, and the flows are free to mix (Fig. 2a) (see Supplementary Table 2 for more details on the streamline problem). The separating streamline going from the stagnation point to the aspiration aperture corresponds to the semi-infinite segment of the horizontal axis where the fluids can mix. If the Péclet number is high enough (higher than about 10, which is always realized in microfluidics applications), this segment can be taken to have concentration c = 1/2 and the walls of the channel geometry can be safely ignored (Supplementary Note 1). The problem can thus be decomposed in two problems of advection-diffusion around semi-infinite obstacles of fixed concentration. The problem of advection-diffusion around such a semi-infinite obstacle has been extensively studied in theoretical fluid mechanics, notably in the theory of dendrite solidification, and in the study of out of plane flow in Burgers vortex sheets. It yields the solutionwhere Φ stag is the image of the stagnation point and erf(x) is the error function. The sign of ± is determined by whether we have an incoming flow of concentration c = 0 or c = 1. However, neither of these concentration profiles represent the full dipole footprint when transformed. This can be seen physically in the flow dipole, in which there is both incoming fluid at concentration 0 (aspirated from the system's surroundings), and incoming fluid at concentration 1 (injected by the aperture). To solve this issue, we separate the problem into an "interior" and an "exterior" domain at the streamline of concentration c = 1/2 (see checkerboard insets in Fig. 2). There remains a discontinuity in our solution due to the branch cut of the logarithm functions in Eq. (1), but the solution can be made continuous by placing the singularities on the real axis and using it as an axis of symmetry. The final step is then to obtain the entire solution as a piecewise function assembling the "interior" and "exterior" solutions, given by transforming Eq. (6) back to the dipole flow domain Z. The interior and exterior domains can be defined either by checking the sign of Φ in the streamline domain or by using the expression for the separating line in the Z domain in polar coordinates (see Supplementary Note 2).

---

### Management of individuals with germline pathogenic / likely pathogenic variants in CHEK2: a clinical practice resource of the American College of Medical Genetics and genomics (ACMG) [^123e9ca4]. Genetics in Medicine (2023). High credibility.

CHEK2 heterozygotes with missense variants — ACMG advises that risk and penetrance are generally reduced compared with truncating variants and in isolation are unlikely to reach clinical actionability, although some exceptions may exist such as p.(Arg171Gly); BC, CRC, and PC surveillance should not be based on CHEK2 status but rather on personalized risk assessment, and education on modifiable risk factors for cancer is undertaken.

---

### On the role of initial velocities in pair dispersion in a microfluidic chaotic flow [^cb75a5d8]. Nature Communications (2017). Medium credibility.

Failure of the linear flow assumption

This raises questions regarding the extent to which elastic turbulence can be regarded as globally smooth, particularly in the presence of boundaries and mean flow. A velocity field consistent with linear flow behaviour would exhibitfor the second order structure function of the longitudinal velocity, where u denotes the relative velocity and u l = u ⋅ R / R; e.g. numerical simulations (Figs. 1 and 6 of ref.). In our flow, clear deviations from linearity are evident already at separations beyond 12 μm, less than 10% of the width and depth of the microfluidic channel, as can be learnt from Fig. 3; a comparison to previous experimental results is drawn in Supplementary Note 2. The inset of Fig. 3 presents the mean squared relative velocities without rescaling; we shall return to these profiles soon.

Fig. 3
Initial relative velocity dependence on the separation distance. The second moments of the relative velocity(blue left - triangles) and the separation velocity(green right-triangle), where u l = u ⋅ R / R, are plotted in the inset (right axis values are half the left ones) as function of the initial separation distance R 0; both ensemble averages are taken at the initial time t 0, when the pairs separation distance is closest to R 0. Rescaling these data by the squared initial separationreveals the deviation from the commonly applied assumption of linear velocity field, as presented on a logarithmic scale in the main plot (right axis values are one order of magnitude smaller than the left ones). Had 〈 u 2 〉 R ∝ R 2 held, the rescaled curves would have remained constant; this is clearly not the case. Indeed, thedata level off as R 0 approaches the smaller distances, providing supporting evidence for the linearity of u l with R at scales smaller than 12 μm. However, this does not hold beyond a tenth of the channel depth. A linear flow regime is not supported by the rescaled relative velocity data, which values keep increasing even for the smallest R 0 values explored here. Further note thatand(inset) are empirical estimators for the second order structure functions of the velocity and the longitudinal velocity, correspondingly; the former is the coefficient of the quadratic term in Eq. (2). The error bars in the inset (smaller than the marker) indicate the margin of error based on a 95% confidence interval

---

### Changes in semantic memory structure support successful problem-solving and analogical transfer [^a97c1d00]. Communications Psychology (2024). Medium credibility.

Discussion

We explored how semantic memory restructuring, — supposedly reflecting a reorganization of the mental representation of the riddles, — could serve as a cognitive mechanism underlying problem-solving. By building individual SemNets before and after solving a problem, we characterized and quantified the changes in the organization of semantic associations between riddle-related concepts. We found that local SemNets changes were related to successful problem-solving (see Table 6 for a summary). In addition, we found that similar local SemNets changes were also associated with the solving success of a semantically distinct, analogous problem, suggesting a link between restructuring and analogical transfer (Studies 1 and 2). We also showed that solving with insight was related to a remoteness-based restructuring (Studies 1 and 2). Finally, we demonstrated that solution-based and remoteness-based SemNets changes dissociated participants who solved the problem by themselves from those who were given the solution (Study 3). Together, our findings provide evidence for the role of local semantic memory restructuring as a cognitive mechanism of problem-solving and analogical transfer.

---

### Addressing early childhood emotional and behavioral problems [^0988ef83]. Pediatrics (2016). Medium credibility.

Examples of evidence-based treatments for existing diagnoses in young children — This report focuses on programs that target current diagnoses or clear clinical problems (rather than risk) in infants and toddlers.

---

### 2023 U.S. department of veterans affairs and U.S. department of defense clinical practice guideline for the management of headache [^7d673313]. Annals of Internal Medicine (2024). High credibility.

Algorithm — this clinical practice guideline (CPG) algorithm is designed to facilitate understanding of the clinical pathway and decision-making process used in managing patients with Headache, and the format represents a simplified flow that helps foster efficient decision making by providers; it includes steps of care in an ordered sequence, decisions to be considered, decision criteria recommended, and actions to be taken; the algorithm is a step-by-step decision tree, with standardized symbols to display each step and arrows connecting numbered boxes indicating the order in which the steps should be followed; shape meanings are specified: rounded rectangles represent a clinical state or condition, hexagons represent a decision point in the process of care formulated as a question that can be answered "Yes" or "No", rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm; Sidebars 1–7 provide more detailed information, and Appendix K contains alternative text descriptions of the algorithms.

---

### Rivaroxaban (Xarelto) [^6cfb91e0]. FDA (2025). Medium credibility.

16 HOW SUPPLIED/STORAGE AND HANDLING

XARELTO®(rivaroxaban) Tablets are available in the strengths and packages listed below:

10 mg tablets are round, light red, biconvex film-coated tablets marked with a triangle pointing down above a "10" on one side, and "Xa" on the other side. The tablets are supplied in the packages listed:
15 mg tablets are round, red, biconvex film-coated tablets with a triangle pointing down above a "15" marked on one side and "Xa" on the other side. The tablets are supplied in the packages listed:
20 mg tablets are triangle-shaped, dark red film-coated tablets with a triangle pointing down above a "20" marked on one side and "Xa" on the other side. The tablets are supplied in the packages listed:

OVERBAG - WARNING: This Unit Dose package is not child resistant and is Intended for Institutional Use Only. Keep this and all drugs out of the reach of children.

Discard reconstituted suspension after "Discard after" date written on the bottle.

Storage of tablets, granules and reconstituted suspension:

Store at room temperature between 20 °C to 25 °C (68 °F to 77 °F); excursions permitted between 15 °C to 30 °C (59 °F to 86 °F) [see USP Controlled Room Temperature].

Do not freeze the granules or reconstituted suspension.

Keep out of the reach of children.

---

### Diagnosis, management and treatment of the Alport syndrome-2024 guideline on behalf of ERKNet, ERA and ESPN [^45eede36]. Nephrology, Dialysis, Transplantation (2025). High credibility.

Regarding diagnostic investigations for Alport syndrome, more specifically with respect to hearing assessment, ERA/ERN ERKNet/ESPN 2025 guidelines recommend to consider obtaining a hearing evaluation at diagnosis or upon reaching adulthood in female patients with X-linked alport syndrome, and then every 5 years in the absence of hearing loss symptoms.

---

### A first-principle mechanism for particulate aggregation and self-assembly in stratified fluids [^e38ebdb3]. Nature Communications (2019). High credibility.

Next, for general Peclet numbers, we utilize the finite element package COMSOL to calculate steady solutions of these equations of motion. See Supplementary Notes 1 and 2, Supplementary Table 1, and Supplementary Figs. 1 and 2 for extended details on this calculation.

Figure 3 depicts the simulations for this method, documenting the toroidal flow structures observed for a range of Peclet numbers. In the top left panel, we document, for the case of a sphere, the maximum flow speed in the equatorial plane as well as the maximum speed overall in the entire domain as a function of the Peclet number. In the equatorial plane, there is an optimal velocity which occurs at a Peclet number slightly bigger than unity. As a benchmark, observe that the slope (here in log-log coordinates) at low Peclet number is(i.e.), which is the exact theoretical scaling in this limit. In the lower left panels, the companion flow structures are observed for four representative Peclet numbers. The background color scheme is assigned by the radial velocity, with negative values corresponding to horizontal velocities directed left. Observe that in all cases, in the equatorial plane, the velocities are directed to attract nearby fluid particles towards the sphere. In the right panels of Fig. 3 we show the analogous plots for spheroids of different aspect ratios. In the top, we show the max speed in the equatorial plane and global max speed as a function of aspect ratio, whereas in the bottom, we document the toroidal flow structures for four representative aspect ratios. In all cases, we observe a monotonic increase in the max equatorial speed as the horizontal disc radius increases.

Fig. 3
Flow strengths and structures for spheres and spheroids.

a Overall max velocity and equatorial maximum cylindrical radial speed, as a function of the Peclet number for spheres. b Flow structures induced by a sphere for four different Peclet numbers in a vertical plane slicing the sphere through north and south pole, color representing horizontal velocity scaled by its maximum value for each Peclet number. c Overall max velocity and equatorial maximum cylindrical radial speed as a function of the aspect ratio for spheroids. d Flow structures induced by four different spheroids, scaled by the Phillips velocity, at.

---

### Clinical policy: critical issues in the management of adult patients presenting to the emergency department with acute carbon monoxide poisoning [^7b14a28b]. Annals of Emergency Medicine (2008). Medium credibility.

Appendix B — approach to downgrading strength of evidence maps Design/Class results according to the degree of downgrading: with "None", classes align as "I II III"; with "1 level", they align as "II III X"; with "2 levels", they align as "III X X"; and "Fatally flawed" aligns as "X X X".

---

### Measuring osteotomy wedge angle is more important than measuring wedge height in open wedge osteotomies around the knee in preoperative planning [^7d490d4d]. Knee Surgery, Sports Traumatology, Arthroscopy (2025). Medium credibility.

Figure 2
Medial open wedge proximal tibial osteotomy is planned following lower limb deformity analysis using the mediCAD® software. Per case, 27 osteotomy variants were planned utilizing three osteotomy entry points and nine hinge points (A–C). Osteotomy entry points as well as hinge points were determined in a standardized fashion in a coordinate system based on anatomic landmarks (a).

Twenty‐one variations of DFO, each combining a different hinge and entry point, were planned to adjust the WBL to align with 50.0% of the tibial plateau's width, measured from the medial edge of the plateau (Figure 3). Conversely, a standardized coordinate system was defined to determine hinge and entry points (Figure 3). Osteotomy B7 was considered the optimal hinge position.

Figure 3
Lateral open wedge distal femur osteotomy is planned after initial lower limb deformity analysis using the mediCAD® software. Twenty‐one osteotomy variants were planned utilizing three osteotomy entry points and seven hinge points (A–C). Points were determined standardized on a coordinate system based on anatomic landmarks (a).

Of each planned osteotomy, the osteotomy depth and wedge height were measured manually. The widths of the tibia and femur were measured at their widest diameters, parallel to the tibial or femoral joint line. The correction angle, as well as the mechanical lateral distal femur angle (mLDFA), medial proximal tibia angle (MPTA), joint line convergence angle (JLCA) and mFA‐mTA, were calculated using the mediCAD® software.

Mathematical prediction of wedge height

The wedge height was calculated using a formula based on the correction angle and osteotomy depth. In opening osteotomies, the wedge forms an isosceles triangle comprising two congruent right‐angled triangles, with the hypotenuses representing the osteotomy depth and the alpha angle being half the opening angle. Wedge height, calculated using the sine function, is the sum of the opposite sides relative to the hinge point (Figure 4). Example calculations are in Table 1. The wedge height was both manually measured and mathematically calculated, and deviations were determined.

Figure 4
The osteotomy wedge is an isosceles triangle consisting of two identical congruent right‐angled triangles. Using the sine function, the wedge height can be calculated as displayed.

Table 1
Predicted values of the wedge height depending on the osteotomy depth and wedge angle. a

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^3cc9842b]. Journal of the American College of Cardiology (2025). High credibility.

Implications for health equity — equity is defined as the absence of unfair, avoidable, or remediable differences among groups of people, and unlike health equality, which refers to equal access to quality health care for all, health equity is achieved when everyone can attain their full potential for health.

---

### Cabergoline [^7c62c677]. FDA (2025). Medium credibility.

16 HOW SUPPLIED/STORAGE AND HANDLING

CABERGOLINE tablets are white, scored, oblong, with functional score on one side with the letter P and the letter U on either side of the breakline, engraved with the number 700 on the opposite side and they are available in the following configuration: 0.5 mg strength, 8-count bottle, and NDC number 59762-1005-1.

Store at controlled room temperature 20°C to 25°C (68°F to 77°F) [see USP]. Store the tablets in the original container.

---

### European guidelines for the diagnosis and treatment of pancreatic exocrine insufficiency: UEG, EPC, EDS, ESPEN, ESPGHAN, ESDO, and ESPCG evidence-based recommendations [^7c51f78f]. United European Gastroenterology Journal (2025). High credibility.

Regarding specific circumstances for exocrine pancreatic insufficiency, more specifically with respect to patients with cystic fibrosis, EDS/EPC/ESDO/ESPCG/ESPEN/ESPGHAN/UEG 2025 guidelines recommend to obtain evaluation of EPI as part of the workup for CFTR-related disorders at any age. Confirm a positive test result by a second test within 3 months.

---

### Fast encirclement of an exceptional point for highly efficient and compact chiral mode converters [^707cf515]. Nature Communications (2022). High credibility.

Exceptional points (EPs) are degeneracies at which two or more eigenvalues and eigenstates of a physical system coalesce. Dynamically encircling EPs by varying the parameters of a non-Hermitian system enables chiral mode switching, that is, the final state of the system upon a closed loop in parameter space depends on the encircling handedness. In conventional schemes, the parametric evolution during the encircling process has to be sufficiently slow to ensure adiabaticity. Here, we show that fast parametric evolution along the parameter space boundary of the system Hamiltonian can relax this constraint. The proposed scheme enables highly efficient transmission and more compact footprint for asymmetric mode converters. We experimentally demonstrate these principles in a 57μm-long double-coupled silicon waveguide system, enabling chiral mode switching with near-unity transmission efficiency at 1550nm. This demonstration paves the way towards high-efficiency and highly integrated chiral mode switching for a wide range of practical applications.

---

### Editorial commentary: is the lateral center-edge angle sufficient for the approximation of acetabular coverage? [^203c4fb5]. Arthroscopy (2019). Medium credibility.

The lateral center-edge angle is a robust technique with proven clinical applicability for quantifying acetabular coverage. However, it measures only the lateral coverage of the femoral head without consideration of other important portions of the acetabulum such as the anterior or posterior wall. Three-dimensional acetabular coverage measurement techniques capable of quantifying the entire acetabulum have become available, thus posing the question of whether we should still rely on the lateral center-edge angle for the assessment of acetabular coverage.

---

### Selecting appropriate toys for young children in the digital era [^dd9f979e]. Pediatrics (2019). High credibility.

Toys and child development — general considerations states that "Toys are important in early child development in relation to their facilitation of cognitive development, language interactions, symbolic and pretend play, problem-solving, social interactions, and physical activity, with increasing importance as children move from infancy into toddlerhood".

---

### ACMG SF v3.3 list for reporting of secondary findings in clinical exome and genome sequencing: a policy statement of the American College of Medical Genetics and genomics (ACMG) [^58d0f5b9]. Genetics in Medicine (2025). High credibility.

ACMG SF v3.3 — genes related to cancer predisposition recommended for return as secondary findings from clinical exome and genome sequencing include APC, RET, BRCA1, BRCA2, PALB2, SDHD, SDHAF2, SDHC, SDHB, and MAX; all are autosomal dominant (AD) with variants to report as "All P and LP".

---

### Controlling extrudate volume fraction through poroelastic extrusion of entangled looped fibers [^8f684fdd]. Nature Communications (2023). High credibility.

Fig. 3
Poroelastic model simulations for the extrusion of looped fiber suspensions, as shown in Fig. 1e, f.

Actual experimental parameters and a single fitting parameter F ≡ k 0 E eff = 91 nN are used for the simulation, resulting in. a The computed (solid line) and experimentally measured (dots) free boundary displacement δ (t) of the suspension during extrusion. The dot size represents typical errors in the measurement. The inclined dashed line is the trajectory at constant velocity v a. Kymograph of the center line of the setup is presented in the background. At time t ex, all solid material has passed the constriction. The poroelastic time T pe is defined in Equation (9). b Comparison between the computed velocity profiles and measured PIV results at locations in Fig. 1 f indicated by the corresponding colored triangles. Gray: nozzle (x / L = 1); blue: near constriction (x / L = 0.75); red: farther from constriction (x / L = 0.4). c The distribution of the normalized displacement field u s / L at times up to approximately t ex (solid lines) and the displacement field without elasticity (dashed lines) over the same time domain. Time interval between each line is 0.15 t ex. Darker color represents later times. d The normalized elastic stressat early (top panel) and late stages (bottom panel) of the extrusion.

Using the same F, we next compare the velocity fields between the experiments and simulations. In Fig. 3 b, the measured velocities at the positions indicated by the colored triangles from Fig. 1 f are compared with the simulation results at the same positions. The experimental velocity of the solid in the nozzle is close to χ v a despite variations in the PIV measurements due to limited lighting in the nozzle. Near the constriction (blue), the solid velocity starts from v a at t = 0, then increases rapidly, followed by a more gentle increase, which is a feature observable in both the experiments and the simulations. The velocity increases at all positions in the barrel, but the rate of increase is higher near the constriction (blue versus red). Overall, the simulation captures the velocity evolution observed in the experiments both qualitatively and quantitatively.

---

### Novel insights into in-vivo diffusion tensor cardiovascular magnetic resonance using computational modeling and a histology-based virtual microstructure [^2e5ec7cb]. Magnetic Resonance in Medicine (2019). Medium credibility.

At the beginning of each timestep of duration d t, an initial displacement vectoris drawn with each of its components R i following a normal distribution with mean μ = 0 and variance σ 2 = 2 D d t. The step length is therefore scaled by the local diffusivity D, which is either the intra‐ or extra‐cellular diffusivity (D IC, D EC). To ensure robustness in the random walk and limit the search space of possible myocyte boundary intersections, the normal distribution is limited to ± 5σ by rejection sampling (see the convergence study in Supporting Information Figure S2). Values of R i larger than this are discarded and a new random value is drawn.

Depending on the local tissue geometry (represented as a triangulated surface mesh) encountered in the particle's path, sub‐stepsare performed such that, where M is one more than the number of boundary intersections encountered in the current timestep. The time‐varying positionof the particle after performing a single timestep d t is then given byThe Möller–Trumbore algorithm, 37 accelerated through bounding boxes, was used to test for intersections with cardiomyocyte boundaries. Elastic reflection was modelled using the local boundary normalof the intersected mesh surface, whereThe remaining step size after the reflection is used as the initial step size in the next sub‐step. Figure 2 illustrates how a possible displacement is resolved.

Figure 2
2D example of one extra‐cellular particle performing a single random walk time step of length. The dashed line indicate the initial step vector before sub‐step S 1 and the solid lines represent the actual path taken by the particle after resolving all barrier interactions. During S 1, bounding boxes B 1 and B 2 are considered, whereas during S 2 cell barriers belonging to B 1 and B 3 are affected

Simulations were performed using MATLAB (R2017b) with the Parallel Computing Toolbox for parallelisation of the random walk. Computationally expensive tasks (bounding box and ray–triangle intersection tests) were implemented in C. Parameter studies used the Imperial College Research Computing Service facilities, 38 utilising up to 50 compute nodes each with two Intel Xeon E5‐2660v2 processors (10 cores at 2.2 GHz clock speed each) and 128 GB of RAM.

---

### A model for the fragmentation kinetics of crumpled thin sheets [^a2bca16c]. Nature Communications (2021). High credibility.

As a preliminary step, we derive the final displacement of the strip when folded at each break, in the absence of confinement. This problem can be mapped to the displacement of a walker performing a one-dimensional random walk with gamma-distributed steps. To enforce the concept of folding, the walker's steps occur in alternating directions. The distribution f Z (z) of position Z after 2 k steps accurate for all k is derived in full in Supplementary Note 2. However, the salient trends may be likewise observed by applying the central limit theorem and considering the position Z valid for large k, or small step size, which givesand describes a normal distribution of zero mean and variance L 0 θ.

If a confinement is now introduced at the locations ∣ z ∣ = w, we next ask with what likelihood the walker steps beyond this confinement. One approach to approximate this probability is to integrate Eq. (16) for all ∣ z ∣ > w, producing a two-sided survival function of Eq. (16). Although this is not equivalent to our initial question, as intermediate steps may also have landed past ∣ z ∣ > w, it proves an acceptable estimate as the last step has the greatest variance. A more accurate calculation would be to evaluate the likelihood that a given walk escapes the confinement at any step; however, looking at the last step is useful for its simplicity in analytical form, and still captures the anticipated behavior. A comparison to the more accurate formulation is made numerically and provided in Supplementary Fig. 9. Once again, we pursue here the simpler form of the survival function valid for large k, and refer to Supplementary Note 2 for the exact derivation valid at all k. The survival function of Eq. (16), S Z (w; θ) = P (∣ Z ∣ > w; w ≥ 0), for a threshold confinement w, is given bywhere erf(z) is the error function. In order for walkers at ∣ z ∣ > w to be restored within the limits of confinement, one or more of their steps must fragment, thereby increasing the number of steps taken and decreasing the overall average, which drives the evolution of fragmentation. This articulates our key claim: considering our original, cylindrically shaped sheets as a statistical ensemble of one-dimensional random walks, we suggest that the progression of fragmentation measured by a change d t, over a single crumpling iteration d n, should be proportional to the fraction of walks in the ensemble which leave the confinement imposed at ∣ z ∣ = w: d t /d n ~ S Z (w; θ). Equivalently, this is the likelihood that a single random walk leaves the critical confinement. We note that this resulting fragmentation rate describes an average fragmentation likelihood given only a confinement w and current temporal parameter t = 1/ θ describing the maturity of the fragmentation process thus far; it does not enforce direct correlations between successive crumpling iterations, whereby new folds should occur preferentially along previous ones. Instead, the decrease in fragmentation rate with n is encoded through the decreasing mean facet area with t. Moreover, while stronger correlation is expected between walks representing nearby transects of the sheet, here we consider the statistical behavior of the sheet as a whole, and account for the increased fragmentation likelihood for facets with larger horizontal extent through the weighting introduced in Eq. (15). At present, Eq. (17) gives the likelihood that new creases will form; however, it does not yet describe how much new damage is created, for which two additional factors should be considered: (1) When the sheet is strongly confined in closely packed layers, the layers tend to collectively fragment, as alluded to by Sultan and Boudaoudand Gottesman et al. thus contributing a factor p ~ 1/ L such that halving the final height doubles the number of additional ridges. (2) In the opposite limit of low compaction, facets are not in close proximity and need not behave cooperatively; thus, new damage scales linearly with the amount of compression L 0 − L, as argued in Gottesman et al. With these additional considerations, we propose that the evolution of the fragmentation process with crumpling iteration behaves aswhere α is a fitted constant of proportionality. We indicate the explicit dependence on t here, as t and θ are inversely related. The critical width w is determined by the geometry of the imposed confinement, as illustrated in Fig. 6 d; a complete derivation is provided in Supplementary Note 4 :where R is the radius of the container. By consequence of Eq. (14) we can directly relate Eqs. (18) and (12) asand obtain a fit to the proportionality constant α. By performing an asymptotic approximation in the limit of large t, detailed in Supplementary Note 3, Eq. (18) may be analytically integrated to provide a scaling relationwhich bears similarity toof Eq. (11):where, and L 0 and R are the sheet length (equivalently the confining container height) and container radius, respectively. Taken together, Eqs. (14) and (21) thereby provide a theoretically motivated expressionbased on properties of fragmentation kinetics and a simple mechanism for re-fragmentation formulated as a random walk. Figure 7 compares the agreement of the empirical relations δ ℓ empir. and ℓ empir. as well as the derived models δ ℓ model and, with the measured quantitiesand ℓ meas. for various n. Collectively, the results of Figs. 4 and 7 demonstrate clear consistency of the fragmentation model with the anticipated logarithmic growth.

---

### Global strategy for asthma management and prevention [^66b4d55d]. GINA (2024). High credibility.

Asthma strategy implementation — essential elements required to implement a health-related strategy enumerate "Steps in implementing an asthma strategy into a health system" that include "Develop a multidisciplinary working group", "Assess the current status of asthma care delivery, outcomes e.g., exacerbations, admissions, deaths, care gaps and current needs", "Select the material to be implemented, agree on main goals, identify key recommendations for diagnosis and treatment, and adapt them to the local context or environment", "In treatment recommendations, consider environmental issues (planetary health) in addition to patient health", "Identify barriers to, and facilitators of, implementation", and "Select an implementation framework and its component strategies". The plan continues with "Develop a step-by-step implementation plan:" to "Select target populations and evaluable outcomes, and specify data coding requirements (if relevant)", "Identify local resources to support implementation", "Set timelines", "Distribute tasks to members", "Evaluate outcomes", and "Continually review progress and results to determine if the strategy requires modification".

---

### Benzhydrocodone and acetaminophen (Apadaz) [^21c7b5ca]. FDA (2025). Medium credibility.

16 HOW SUPPLIED/STORAGE AND HANDLING

APADAZ (benzhydrocodone and acetaminophen) tablets are available as follows:

Capsule-shaped, white tablets debossed with "KP201" on one side and "445" on the opposite side, containing 4.08 mg benzhydrocodone (equivalent to 4.45 mg benzhydrocodone hydrochloride) and 325 mg acetaminophen supplied as:

bottles of 100 (NDC 70040-0145-1)

Capsule-shaped, white tablets debossed with "KP201" on one side and blank on the opposite side, containing 6.12 mg benzhydrocodone (equivalent to 6.67 mg benzhydrocodone hydrochloride) and 325 mg acetaminophen supplied as:

bottles of 100 (NDC 70040-0167-1)

Capsule-shaped, white tablets debossed with "KP201" on one side and "890" on the opposite side containing 8.16 mg benzhydrocodone (equivalent to 8.90 mg benzhydrocodone hydrochloride) and 325 mg acetaminophen supplied as:

bottles of 100 (NDC 70040-0189-1)

Flush expired or unused APADAZ tablets that are no longer needed down the toilet or contact the Drug Enforcement Administration (DEA) to find the location of an authorized collector (1-800-882-9539).

Storage

Store at 20°C to 25°C (68°F to 77°F). Excursions permitted between 15°C to 30°C (59°F to 86°F) [See USP Controlled Room Temperature].

Store APADAZ securely and dispose of properly.

---

### How deep learning solved my seizure detection problems [^45e96990]. Epilepsy Currents (2020). Medium credibility.

[Box: see text].

---

### Long-distance exploration in insightful problem-solving [^b11f65b1]. Communications Psychology (2025). Medium credibility.

Introduction

Insight is a sudden and often unexpected realization or understanding of a problem's solution. This phenomenon is closely linked to the concept of the "Aha" moment, which describes the moment of clarity when an individual experiences a breakthrough in thinking that leads to a novel solution. The phenomenon of insight significantly contributes to many pivotal discoveries, and exploring its underlying mechanisms can help devise techniques to enhance creativity and advance artificial intelligence development. Insightful problem-solving, as opposed to the step-by-step analytical approach of non-insight solutions, is marked by the sudden realization of an answer, a strong conviction in its correctness, and the positive emotions that accompany it. However, despite these distinct phenomenological characteristics, the mechanisms underlying the insightful search process during problem-solving remain a subject of debate.

Several mechanistic theories have been proposed to elucidate how a problem solver navigates the solution space to reach an initially elusive solution. The constraint relaxation theory proposes that an effective search process for insightful solutions may involve the relaxation or elimination of certain counterproductive constraints, subsequently opening up new areas of the solution space for exploration –. Furthermore, the progress monitoring theory suggests that the progress of the search is constantly assessed, and insight involves the detection of insufficient progress and a consequent strategic shift. The former theory describes a de-fixation process aimed at dissolving mental blockages, while the latter theory suggests an exploration process that allows a variety of alternative strategies to be considered. To avoid confusion, it is important to clarify that exploration is a key implication of the progress monitoring theory, but it is not equivalent to monitoring itself.

---

### Exploiting hidden singularity on the surface of the poincarésphere [^9a449559]. Nature Communications (2025). High credibility.

Fig. 1
Comparison between different phase-addressing mechanisms.

A Typical Pancharatnam-Berry phase, associated to cross-polarized phase modulation and originating from the degeneracy of the Jones matrix, corresponds to the magnetic flux of a virtual monopole of intensity −1/2 positioned at the center of the Poincaré sphere. Considering the transmission of a right incident circularly polarized wavethrough birefringent materials with eigenstate of azimuth ψ (thick blue arrow), polarization evolves along the meridian from the north to the south pole. Choosing two different meridians, two cross-polarized beams taking two different meridian trajectories would present a phase difference equal to half of the magnetic flux through the blue solid angle Ω swept counterclockwise between the two meridians (blue and dashed blacklines). B The dynamic phase is polarization-independent and only depends on mean phase ϕ = (ϕ + + ϕ −)/2 of the eigenvalues exp(iϕ ±), and therefore applies to any polarization channel equally. C The evolution of polarization state and the emergence of a co-polarized phase singularity on the Poincaré sphere are governed by the system's eigen parameters. The input stateundergoes precession around the eigenaxisby an angle, transitioning to an intermediate state, tracing the red curve. The subsequent projection back to the initial state follows the blue dashed curve, acquiring an additional phase, which is evident from the relative configuration of the initial and finalstates. The accumulated phase, solely depends on the curvature of the traversed path, has a pure geometric origin. Variation in the eigen parameters alters polarization trajectory on the Poincaré sphere and thereby modifying the accumulated geometric phase. When the eigen axis crosses the equatorwith, the inputstate reverses its helicity (red dashed curve), and the accumulated geometric phase through the projective measurement depends on the shortest geodesic path. A very small variation aroundshifts the position of, affecting the projection path. This leads to a co-polarized singular phase, which lies exactly at the antipodal point | L 〉 denoted with the star mark. This phase singularity emerges in complex amplitude of the co-polarized transmission channel at the Stokes parametric position of, representing a topological variant of the geometric P-B phase.

---

### Dissociable roles of human frontal eye fields and early visual cortex in presaccadic attention [^0e786551]. Nature Communications (2023). High credibility.

Fig. 3
The effect of occipital TMS (V1/V2, Exp.2a, n = 9; upper row) and frontal TMS (rFEF+, Exp.2b, n = 7; lower row) on presaccadic benefits and costs throughout saccade preparation.

a Visual sensitivity at the saccade target (purple) and opposite the saccade target (green) measured at the region matching V1/V2 stimulation (yellow triangles) or opposite of it (white triangles, control), binned as a function of stimulation time relative to saccade onset. b The effect of V1/V2 TMS on presaccadic benefits at the saccade target (purple; valid test stimulated–not stimulated) and costs opposite the saccade target (green; invalid test stimulated–not stimulated) binned as a function of stimulation time relative to saccade onset. c The effect of rFEF+ TMS on visual sensitivity at the saccade target and opposite of it across time; conventions as in (a). d The effect of rFEF+ TMS on presaccadic benefits and costs across time; conventions as in (b). All symbols and error bars represent the group average ± 1SEM. Asterisks indicate significant differences between the two compared conditions at a respective time point (a, b; Bonferroni corrected two-sided post-hoc comparison after significant ANOVA 3-way interaction) or between the two compared conditions across time (c, d; significant ANOVA main effect). ✱ p < 0.05. Source data are provided as a Source Data file.

---

### Clustering knowledge and dispersing abilities enhances collective problem solving in a network [^a4ac9110]. Nature Communications (2019). High credibility.

NK spaces are analytically useful for agent-based models but are conceptually abstract and difficult to ground to real-world examples. Here, we can instead understand an NK problem's complexity in terms of how incremental contributions made by any subset of activities are also contingent on other activities. Thus, a solution that an agent comes up within the NK space — captured by a unique sequence of 1s and 0s — reflects a basket of activities people undertake to solve a real-world problem, where a 1 represents the presence of an activity and a 0 its absence.

There are many examples of social collectives solving a common problem that are analogous to the NK space setup. In these instances, the solutions and performances are visible at least some subset of other actors, and there are no positive or negative externalities from one actor to another (beyond the informational spillover). For instance, consider national ministries of health of various countries. They all have different approaches to healthcare (e.g. insurance markets like in Germany or Austria or a single-public option like in Canada or the U.K.). And the improvement or decline of one country's healthcare does not adversely affect or hamper the healthcare of another. The interest of some countries in the policies employed by other countries may be limited by physical adjacency or similar political systems or cultures, so their information about the "problem space" is more localized.

---

### Unconventional (anti) ferroelectricity in van der waals group-IV monochalcogenides [^8604bce0]. Nature Communications (2025). High credibility.

We then explore the OOP polarization evolution in bilayer GeSe in response to the vertical external electric field (E OOP) (Fig. 2i–k). Within the whole work, the direction pointing from B to A is defined as the positive electric field. The external electric field will redistribute the electrostatic potential and slightly change the atomic positions. For each electric field, we can obtain a new structure for bilayer GeSe according to the structure relaxation (Methods). The relation between the total energy of bilayer GeSe and external electric fields can be well described by a parabolic curve (Fig. 2i). We then remove the external electric fields, fix each bilayer structure tuned by the external electric field, and calculate the total energy (Fig. 2j). Through this approach, we can confirm the AFE state corresponding to the lowest energy and find the two metastable FE states, which are induced by the external electric field, yet can be preserved when the external electric field is removed (Fig. 2j together with amplified panels at both sides). We also explore dependence of the potential energy difference Δϕ on the external electric fields for the individual A and B layers, with Δϕ(A) = ϕ A-1 – ϕ A-2 and Δϕ(B) = ϕ B-1 – ϕ B-2 (Fig. 2k). In 2D materials, the OOP polarization (P z) can be easily evaluated by the simple equation, P z = ε 0 Δϕ, where ε 0 is the vacuum dielectric constant and Δϕ is the potential energy difference. When the external electric field E OOP = 0, Δϕ(A) = –Δϕ(B) = 0.057 eV, indicating the opposite OOP polarization in A and B layers with P z = ± 0.505 pC/m. It is desirable that an external electric field can reverse the OOP polarization in one layer, inducing the AFE/FE transition. According to the calculations, we find that the left critical point corresponds to E OOP = –0.65 V/Å and Δϕ(A) = 0 (the right critical point corresponds to E OOP = 0.65 V/Å and Δϕ(B) = 0). When the external electric field is larger than the critical value, the OOP polarizations in the A and B layers turn from antiparallel to parallel, i.e. AFE becomes FE. The saturated value of Δϕ(A) and Δϕ(B) is about 0.12 eV, corresponding to 1.06 pC/m in the individual A and B layer, and 2.12 pC/m in bilayer GeSe.

---

### Anomalous elastic properties across the γ to α volume collapse in cerium [^c571fc01]. Nature Communications (2017). Medium credibility.

The adiabatic bulk modulus decreases in the γ-phase for all temperatures until it reaches its minimum at the VC transition and starts rising again continuously in the α-phase. With higher temperature, the minimum moves to a higher pressure and becomes deeper. Since B T = 0 at the critical point, and B S = B T C P / C V it follows that B S should fall to zero at the critical point just as well since C P and C V are nonzero. Our lowest observed value is B S ~ 6 GPa for p = 1.55 GPa at 481 K which could mean that our temperature was just barely different from the critical temperature. It is possible to fit the pressure dependence of B S near the transition to a power law B S (P) ~ | P − P VC | α. The solid lines in Fig. 3a show the resulting fits to the data. The values for P VC and α are listed in Table 1 for a pressure range of about 0.4 GPa below (−) and above (+) the transition. However, except for the critical temperature, the transition already takes place at P < P VC. This was observed previously by X-ray diffraction for B T and ultrasonic measurements for B S at room temperature which found α − = 0.46, P VC − = 0.83 GPaand α − = 0.42, P VC − = 0.92 GPa, respectively. At the critical temperature (481 K) we find α − = 0.26 and α + = 0.28, basically equal within the experimental uncertainty. An exponent of 0.5 would indicate Gaussian fluctuationsassociated with electron–phonon coupling, an exponent of zero is expected in the mean-field theory. Our value of α = 0.27 ± 0.01 is the only one taken approximately on the critical isotherm which allows a straight forward interpretation. All other values were obtained at lower temperatures for which the descent of the bulk modulus towards zero is interrupted by the transition and thus the measured exponents are not truly "critical". Additionally, the further the temperature is from T C the larger is the gap in the transition pressures P VC − and P VC + which we list in Table 1 as Δ P. This value can serve as a measure of hysteresis that disappears approaching the critical temperature. Table 1 also provides a comparison with previously published results and includes values for fits to the data of refs. that were obtained within the current effort. With the exception of the 481 K isotherm, all exponents measured on the lower pressure side are larger than the ones from the higher-pressure side which one would expect similarly for the behavior of a van der Waals liquid/gas near the critical point.

---

### A problem of persistence: still more questions than answers? [^1078e4fd]. Nature Reviews: Microbiology (2013). Medium credibility.

The current antibiotic resistance crisis has led to increased pressure to prioritize strategies to tackle the issue, with a strong focus being placed on the development of novel antimicrobials. However, one major obstacle that is often overlooked is persister cells, which are refractory to antibiotic treatment. Tackling persistence is a challenge because these cell types are extremely difficult to study and, consequently, little is known about their physiology and the factors that lead to their emergence. Here, four experts contemplate the main physiological features that define persistence and the implications of persistence for antibiotic treatment regimens, and consider what the study of bacterial persistence has taught us about the heterogeneity of bacterial populations.

---

### A model for the fragmentation kinetics of crumpled thin sheets [^c596c1cd]. Nature Communications (2021). High credibility.

Numerical evidence for the insensitivity to initial preparation

Now that the connection between the statistical model of facet area and total crease length has been presented, we briefly note on the insight that may be gained by additionally solving Eq. (1) numerically. A numerical integration scheme is implemented using second-order composite trapezoid rule for discretization in x, and second-order implicit multi-step discretization in t. The sample numerical result in Fig. 5 reveals a rapid convergence to the steady state analytical solution given by Eqs. (7a) and (7b), and thereby relative insensitivity to the initial state. To demonstrate the significance of this behavior, we reiterate the observed history independence of total crease length. As discussed in Gottesman et al. sheets with different loading histories — one hand-crumpled and another deliberately folded along straight lines — yet nearly equal total crease lengths exhibited the same subsequent accumulation of damage when subjected to the protocol of Fig. 1 a. Such sheets had clearly distinct initial facet area distributions: The facet areas of the deliberately folded sheet were sharply peaked near two different values, while those of the hand-crumpled sheet were broadly distributed. Thus, signatures of initial preparation appear to be quickly eclipsed by the strong attractor of the crumpled state, echoed in the rapid convergence to steady state seen numerically.

Fig. 5
Numerical validation of the analytical solution to Eq. (1).

a Selected snapshots of the numerically calculated ϕ num (ξ) with initial condition c (x, 0) = δ (x − 1) and with a = 1, revealing a rapid convergence to the steady state distribution. The dashed line corresponds to the analytical form of Eq. (7a) valid at large t. b The corresponding evolution of mean area s (t), with the analytical solution at large t given by Eq. (7b) shown by the dashed line. c The mean area of the experimental samples as a function of t computed from Eq. (7b) (scattered points). The dashed line corresponds to Eq. (7b) with a (t) as given by Eq. (8). Marker colors correspond to different values of, as indicated by the colorbar.

---

### Changes in semantic memory structure support successful problem-solving and analogical transfer [^209a662c]. Communications Psychology (2024). Medium credibility.

Importantly, we explored how the ability to solve the riddles related to creative abilities, measured with several assessments. We found that creativity scores including measures of convergent and divergent thinking positively and significantly correlated with the solving rate of the four riddles (see Supplementary Note 1 and Fig. S4).

Overall, we found a behavioral signature of analogy transfer (higher solving rate, faster response time) in problem-solving. In addition, we provided evidence suggesting that solving our riddles involves creativity-related processes (correlation with other measures of creativity and a positive association between correct responses and Eureka report).

Local changes in problem-related SemNets relate to successful solving (Study 1)

In the naive condition, we explored whether the ability to solve problems could be reflected in changes in SemNets organization, either at the global (i.e. SemNet) or local (i.e. node or edge) level. We used nonlinear mixed-effects models to predict problem-solving based on the difference between individual-based SemNets metrics over time (ΔMetric = Metric PostSemNet – Metric PreSemNet), the impact rating (measuring the importance of each node or edge to solve the problem), the semantic distance (measuring the semantic remoteness of each node or edge), and all possible interaction effects between these factors. We expected to find positive SemNets metric changes in parts of the SemNet that were solution-relevant and semantically remote in solvers compared to non-solvers.

---

### Guideline no. 422d: menopause and sexuality [^3f837be9]. Journal of Obstetrics and Gynaecology Canada (2021). High credibility.

Regarding diagnostic investigations for menopause, more specifically with respect to evaluation of sexual dysfunction, SOGC 2021 guidelines recommend to categorize the patient's problem as related to desire, arousal, pain, or orgasm, in order to facilitate treatment and to triage care.

---

### Unravelling the spatial directionality of urban mobility [^a1c3d9e2]. Nature Communications (2024). High credibility.

Fig. 7
The random workplace and residence choice (RWRC) model.

a Schematic representation of the RWRC model. Individuals are shown as different coloured symbols. The first (green) individual selects the central cell as the workplace (star) and residence (pentagon), as shown in the upper-left panel. Subsequently, the second (red) and third (blue) individuals make their workplace (star) and residence (pentagon) selections in accordance with the criteria outlined in equation (2) and equation (3). The solid arrow represents one choice outcome, whereas the dashed arrow denotes an alternative potential outcome. b The values of anisotropy (upper panel) and centripetality (lower panel) were obtained from the RWRC model with different parameters α and β. The colour maps depict the mean value over 100 independent simulations. Each symbol represents a scenario with different values of α and β: (△) α = 1.2 and β = 2.8; (♢) α = 0.8 and β = 1.6; (□) α = 0.2 and β = 1.2. c – e Maps of population mobility vectors (PMVs) obtained from the simulation results of the above three scenarios. The length and colour of the arrow are proportional to the magnitude of the PMV. Source data are provided as a Source Data file.

---

### 2024 ACC / AHA / AACVPR / APMA / ABC / SCAI / SVM / SVN / SVS / SIR / VESS guideline for the management of lower extremity peripheral artery disease: a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^57f71dc7]. Circulation (2024). High credibility.

Regarding diagnostic investigations for peripheral artery disease, more specifically with respect to ABI, indications, AACVPR/ABC/ACC/AHA/APMA/SCAI/SIR/SVM/SVN/SVS/VESS 2024 guidelines recommend to obtain resting ABI, with or without ankle pulse volume recordings and/or Doppler waveforms, to establish the diagnosis of PAD in patients with history or physical examination findings suggestive of PAD.

---

### Emergent vortices in populations of colloidal rollers [^0ddbac7e]. Nature Communications (2015). Medium credibility.

with againin the ordered polar phase. This equation has a clear physical meaning and expresses the balance between the centrifugal force arising from the advection of momentum along a circular trajectory and the anisotropic pressure induced by the repulsive interactions between rollers. It has an implicit solution given by

φ (r) is therefore parametrized by the dimensionless numberreflecting the interplay between self-propulsion and repulsive interactions. Given the experimental values of the microscopic parameters, Λ is much smaller that unity. An asymptotic analysis reveals thatis the typical core radius of the vortex. For, the density increases slowly asfor all φ 0 and R c. As r reaches, it increases significantly and then grows logarithmically asaway from the vortex core. However, is an integration constant, which is solely defined via the mass conservation relation:and therefore only depends on φ 0 and R c.does not provide any intrinsic structural scale, and the vortex patterns formed in different confinements are predicted to be self-similar in agreement with our experiments and simulations despite the simplification made in the model, Fig. 3e. In addition, equation 8 implies that the rollers self-organize by reducing their density at the centre of the vortex down to, the mean area fraction at the onset of collective motion, again in excellent agreement with our measurements in Fig. 3e.

To characterize the orientational structure of the vortices, an additional closure relation is now required. The simplest possible choice consists in neglecting correlations of the orientational fluctuations, and therefore assuming. This choice implies that

Equations 8 and 9 provide a very nice fit of the experimental polarization curve as shown in Fig. 3b, and therefore capture both the pitchfork bifurcation scenario at the onset of collective motion and the saturation of the polarization at high packing fractions. The best fit is obtained for values ofand β, respectively, five and two times larger than those deduced from the microscopic parameters. Given the number of simplifications needed to establish both the microscopic and hydrodynamic models, the agreement is very convincing. We are then left with a hydrodynamic theory with no free fitting parameter, which we use to compute the area fraction of the outer polarized ring where. The comparison with the experimental data in Fig. 3f is excellent.