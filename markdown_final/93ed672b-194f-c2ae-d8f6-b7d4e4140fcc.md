# Medical Question & Answer

**Sample ID**: 93ed672b-194f-c2ae-d8f6-b7d4e4140fcc
**Dataset Index**: 254291

---

## Question

Example 2. In acute triangle ΔABC, the distance from vertex A to the circumcenter O is equal to the distance to the orthocenter H. Find the possible value of ∠A.

 untranslated text remains in its original format and line breaks are preserved.

---

## Answer

> Let's see… What do we have here? The user is asking for the possible value of angle A in an acute triangle ABC where the distance from vertex A to the circumcenter O equals the distance from A to the orthocenter H. Let's break this down step-by-step. First, I need to think about the geometric setup and the key triangle centers involved. Then, I should verify the distance formulas for AO and AH in terms of the circumradius R and the angles of the triangle. Next, I will set AO equal to AH and derive the trigonometric equation that results. After that, I need to solve the equation for angle A, making sure to respect the constraint that the triangle is acute. Finally, I should double-check for extraneous solutions and confirm uniqueness within the acute range.

> Let me first confirm the setup and notation. In triangle ABC, O is the circumcenter and H is the orthocenter. The triangle is acute, so O and H lie inside the triangle, and I need to find angle A such that AO = AH. I will use standard notation where R is the circumradius and angles are A, B, C with A + B + C = 180°.

> Now, I need to recall the distance formulas. The distance from a vertex to the circumcenter is simply the circumradius, so AO = R. For the distance from a vertex to the orthocenter, I should verify the formula. The standard expression is AH = 2R cos A, so the condition AO = AH becomes R = 2R cos A. Wait, let me verify that formula before proceeding; yes, in an acute triangle, the distance from vertex A to the orthocenter is indeed 2R cos A, which I can derive from vector geometry or trigonometric identities involving the Euler line and circumradius.

> Setting AO equal to AH, I get R = 2R cos A. I can divide both sides by R (since R > 0) to obtain 1 = 2 cos A, which simplifies to cos A = 1/2. Hold on, I should verify that this division is valid; yes, R is positive, so dividing by R preserves equivalence. Solving cos A = 1/2 gives A = 60° within the principal range, but I need to ensure this satisfies the acute triangle constraint.

> Next, I should review the acute condition. An acute triangle requires that each angle is less than 90°, so I need to check whether A = 60° is compatible with B and C also being acute. Since A = 60°, the remaining sum B + C = 120°, and both B and C can be chosen less than 90° (for example, B = C = 60° gives an equilateral triangle, which is acute), so A = 60° is valid. I should confirm that no other solutions exist within the acute range; because cos A is strictly decreasing on (0°, 90°), cos A = 1/2 has only one solution in that interval, namely A = 60°.

> But wait, what if I misremembered the orthocenter distance formula? Let me reconsider and double-check. The derivation of AH = 2R cos A relies on the fact that the reflection of H across BC lies on the circumcircle and on trigonometric relations along the altitude; I can also cross-check with coordinate examples or known identities, and consistently AH = 2R cos A holds for any triangle, with the sign ensuring the correct directed distance, so in an acute triangle the magnitude is 2R cos A. Therefore, my earlier application of the formula is correct.

> Final answer: The only possible value of angle A in an acute triangle satisfying AO = AH is 60 degrees.

---

The only possible value of (∠A) is **60°**. This follows from the condition (AO = AH), which implies (cos A = [1/2]), and since the triangle is acute, (A = 60°) is the unique solution.

---

## Geometric setup and key properties

Let (ΔABC) be an acute triangle with circumcenter (O) and orthocenter (H). We are given that the distance from vertex (A) to (O) equals the distance from (A) to (H), i.e. (AO = AH).

- **Circumradius**: The distance from any vertex to the circumcenter is the circumradius (R), so (AO = R).
- **Orthocenter distance**: The distance from a vertex to the orthocenter is given by (AH = 2R cos A).

Thus, the condition (AO = AH) becomes:

R = 2R cos A

---

## Solving the equation

Divide both sides by (R) (since (R ≠ 0)):

1 = 2 cos A

cos A = [1/2]

The general solution is (A = 60° + 360°k) or (A = 300° + 360°k) for integer (k). Since (ΔABC) is acute, (0° < A < 90°), so the only valid solution is:

A = 60°

---

## Verification of the solution

We verify that (A = 60°) satisfies the original condition and the acute constraint:

- **Condition**: (cos 60° = [1/2]), so (AH = 2R × [1/2] = R = AO).
- **Acute constraint**: (60° < 90°), so the triangle remains acute.

---

## Uniqueness of the solution

Within the acute range, (cos A) is strictly decreasing, so (cos A = [1/2]) has only one solution. Therefore, **(A = 60°) is the unique possible value**.

---

## Conclusion

The only possible value of (∠A) in an acute triangle where (AO = AH) is **60°**.

---

## References

### 14_FunctionsAndOperators.docx… [^6e5fcfed]. CDC (2025). Medium credibility.

Example READ {C: \My_Project_Folder\Sample\Sample. prj}: Oswego DEFINE NoVanilla YN IF NOT Vanilla = THEN NoVanilla = ELSE NoVanilla = END FREQ NoVanilla Vanilla OR Description This operator returns True if one or the other or both expressions are True. If either expression evaluates to True, OR returns True. If neither expression evaluates to True, OR returns False. Example READ {C: \My_Project_Folder\Sample\Sample. prj}: Oswego DEFINE Random1 NUMERIC DEFINE Random2 NUMERIC DEFINE Random3 NUMERIC ASSIGN Random1 = RND ASSIGN Random2 = RND ASSIGN Random3 = RND LIST Random1 Random2 Random3 ROUND. Syntax SECONDS < var1 > and < var2 > represent variables in time or date/time format. Comments If the time stored in < var1 > is later than the time in < var2 >, the result will be the difference in seconds expressed as a negative number. Both variables must contain data in date, time or date/time format.

If any of the variables or values included in the formula is not a date, the result is null. Example READ {C: \My_Project_Folder\Sample\Sample. prj}: Oswego DEFINE Sec1 NUMERIC ASSIGN Sec1 = SECONDS LIST Timesupper DateOnset Sec1 SIN, COS, TAN Description These functions return the respective trigonometric value for the specified variable. Comments The variable is interpreted as the angle in radians. To convert degrees to radians, multiply by pi divided by 180. Example READ {C: \My_Project_Folder\Sample\Sample. prj}: Oswego DEFINE SinA NUMERIC DEFINE SinB NUMERIC. Description This function removes decimals from a numeric variable, returning the integer part of the number. This follows the same logic as rounding toward zero. Syntax TRUNC The < variable > can be an existing numeric variable, a defined variable containing numbers, or a numeric constant. Comments The result will be returned in numeric format.

---

### Controlled packing and single-droplet resolution of 3D-printed functional synthetic tissues [^3b7915f7]. Nature Communications (2020). High credibility.

Classifying packing types

To estimate the proportion of packing types within each network, we first generated a mesh over the print by performing a Delaunay triangulation using the centres of all regions classified as droplets as the input points. A convenient property of this triangulation method is that the circumcircle of each triangle contains no other points; each triangle therefore represents a triplet of neighbouring droplets and provides localised geometrical information about their arrangements.

The plot of the bivariate distribution of the largest angle of each triangle vs the triangle area normalised by the average droplet area for all prints revealed two distinct clusters of triangles, one corresponding to hexagonally packed droplet regions, and one corresponding to square-packed droplet regions (Supplementary Fig. 3 d). Reasoning that these represented stable configurations of droplets for certain printing parameters, we classified each triangle using these clusters. Four packing categories were used: 'hexagonal' (closely packed triplets of droplets arranged as equilateral triangles), 'square' (closely packed triplets of droplets arranged as right-angled triangles), 'amorphous' (closely packed triplets of droplets of intermediate arrangement) and 'no packing' (triplets of droplets that are not close-packed). For a hexagonal classification. For an amorphous classification. For a square classification. In addition, for all of these classes. Triangles that fell outside of these ranges were classified as no packing (Supplementary Fig. 3 d).

Some elongated 'sliver' triangles were classified as being a member of one of the closely packed classes, despite being composed of widely spaced droplets. Closer analysis of these triangles revealed that they were generally composed of two closely packed droplets and a single more distant droplet, together forming a skinny near-isosceles triangle. We therefore applied an additional constraint based on the perimeter of each triangle normalised by the average droplet radius. Since for perfect hexagonal packing, and for a perfect square packing, we set the constraintfor the closely packed classes based on a linear interpolation between these two points. Our chosen y -intercept for this constraint is slightly greater than the theoretical y -intercept from the interpolation, allowing triangles with small deviations from the perfect packing geometry to be classified as closely packed while still ensuring classification of sliver triangles as no packing.

---

### The geometric nature of weights in real complex networks [^16d6fe49]. Nature Communications (2017). Medium credibility.

Hidden metric spaces underlying real weighted networks

At the beginning of this section, we showed that the normalized weights of links participating in triangles are higher, thus suggesting a coupling between the weighted organization of real weighted complex networks and an underlying metric space. We then presented a model that has the critical ability to fix the joint degree–strength distribution, while independently varying the level of coupling between the weights and the metric space (parameter α). This opens the way to a definite proof of the geometric nature of weights in real complex networks, which inevitably must involve the triangle inequality: the most fundamental property of any metric space.

For unweighted networks, a direct verification of the triangle inequality based on the topology without an embedding in a metric space is not possible, due to the probabilistic nature of the relationship between the binary structure and the distance between nodes. In contrast, weights do contain information about their distances in the metric space (via equation (2)) such that a direct verification of the triangle inequality is possible. To ensure that the metric properties of triples in the network are in correspondence to the metric properties of the corresponding triangles in the underlying space, only triples of nodes forming triangles in the network are taken into account to evaluate the triangle inequality. There are however two main challenges when one tries to apply this methodology. The first one is related to the fact that connections in the weightedmodel depend not only on angular distances but also on hidden degrees, such that we need a purely geometrical formulation of the weighted hidden metric space network model, in which angular distances and degrees are combined into a single distance measure. The second issue is related to the intrinsic noise present in the system due to the stochastic nature of the processes conforming it, which may blur the evaluation of the triangle inequality. Below, we propose a way to overcome these two issues.

---

### The geometric nature of weights in real complex networks [^42ad36a1]. Nature Communications (2017). Medium credibility.

Results

Interplay between weights and triangles in real networks

Clustering, as a reflection of the triangle inequality, is the key topological property coupling the bare topology of a complex system and its effective underlying metric space. In this context, the triangle inequality stipulates that if nodes A and B are close, and nodes A and C are also close, we expect nodes B and C to be close as well; triangles are therefore more likely to exist between nodes that are nearby. Consequently, we expect that if the weights of connections depend on the distance between the connected nodes in the underlying metric space, they should be quantitatively different depending on the clustering properties of the connections. However, weights and clustering are known to be strongly influenced by the degrees of end point nodes, which prevents from a direct detection of the metric properties of weights due to the typical heterogeneity in the degrees of nodes in real networks. Thus, to compare links on an equal footing, we define the normalized weight of an existing link connecting nodes i and j as, whereis the average weight of links as a function of the product of degrees of their end point nodes. By doing so, we decouple the weights and the topology, leaving the normalized weights seemingly randomly fluctuating around 1 (see uniform sampling on Fig. 1).

Figure 1 shows, however, that these fluctuations are not uniform as links involved in triangles tend to have larger normalized weights than the average link. Indeed, in some cases the difference can reach > 30%. Sampling links over triangles is equivalent to sampling links proportionally to their multiplicity m (the number of triangles to which a link participates). Therefore, the results in Fig. 1 indicate that ω norm and m are positively correlated variables, as corroborated by their Pearson correlation coefficient (Supplementary Table 1). In ref. the authors also found local correlations between the multiplicity of links and the weights for different real networks. However, note that in that study weights were not normalized to discount the effects of the heterogeneity in the degrees of the nodes, so that the detected weighted organization cannot be taken as a signature of underlying metric properties.

---

### From the betweenness centrality in street networks to structural invariants in random planar graphs [^f2be3b03]. Nature Communications (2018). Medium credibility.

Plotting the rescaled average betweenness of nodes as a function of the distance r from the barycenter (Methods), demonstrates a monotonic decrease with distance in the high density regime (Fig. 4d). For low values of ρ e there appears no distance dependence of the nodes, whereas for ρ e > 0.4, a clear dependence emerges with the curves converging to the form seen for maximally dense random geometric graphs as calculated in. (Note that while both planar and geometric graphs are embedded in space, the latter allows for edge-crossings and therefore broader degree distributions and larger number of edges for the same N. In light of this difference, the similarity between the two ostensibly different classes of graphs is notable.) In combination, the structural metrics suggest that while the spatial position of a node is decoupled from its BC value in sparse networks, a strong correlation emerges for increasingly dense networks.

---

### Universality in long-distance geometry and quantum complexity [^e343ca2d]. Nature (2023). Excellent credibility.

This implies that we can approximate the operatorwith a total cost of about. This operator agrees with our target operatorat leading order in z, and has an inner-product error of about z². This can be improved to z³ by using the next order in the Suzuki–Trotter expansion, but going to even higher orders becomes prohibitively expensive. It is at this point that we make our heuristic step. In the Euclidean group example, we saw that the complexity geometry has so many degrees of freedom that by making minor deformations of the path we can correct small errors at small extra cost, in a way that is not captured by any finite order of the Suzuki–Trotter expansion, and is instead an emergent feature in the IR. Compared with the SU(2) example in the section ' Berger sphere ', the task of compiling in U(2 N) is complicated by the fact that there are many more directions in which to err; on the other hand, there are correspondingly more directions in which we can wiggle the path to eliminate the error, and as a statistical matter, we expect that to dominate. If the small inner-product errors can be corrected by wiggling the path, then we can synthesizefor z < 1 at cost k n 2 (k). To generateat larger values of z, the triangle inequality (for any) guarantees that the complexity grows no faster than linearly with coefficient k n 2 (k). This argument heuristically shows that the binomial metric is in the same universality class as the infinite-cliff metric, and therefore upper-bounds the critical schedule:The upper-bound equation (17) holds at all but the largest k, where the analysis becomes unreliable. Note also that although the binomial metric does not have a curvature as small as the exponential metric, it is still very moderate ∣ κ ∣ ≤ O (N) compared to the cliff metric. The reasoning that leads to equation (17) is heuristic, because to eliminate error it appeals to a statistical argument. In ref. it is shown that there is a weaker result that can be proved. The study also shows that any unitary that can be reached with a path that in the binomial metric has a lengthcan be approximated to within inner-product error ϵ by a path that in the infinite-cliff metric has a lengthOur conjectures imply that this can be improved from polynomial to linear-with-additive-constant and from approximate to exact.

---

### Rapid active zone remodeling consolidates presynaptic potentiation [^13e85582]. Nature Communications (2019). High credibility.

To investigate the AZ structure in an approach independent of the cluster-distance minimization procedure described above, we repeated the averaging in a different way as follows. We developed a MATLAB code for AZ centering and alignment by rotation of the highest intensity pixel to identical angles and therefore similar positions, which yielded qualitatively similar results (Supplementary Fig. 3a). Again, high-intensity clusters were detected in AZ images cleaned from clusters belonging to bordering AZs, and all translations and rotations were then performed on unretouched images. The center of mass of the found cluster coordinates was calculated and the image shifted so that the center of mass of the coordinates was in the center of the 51 by 51 pixel space (x = y = 26; see Eqs. (1) to (6)). Only the position of the brightest pixel was then considered for rotation. To determine the angle by which to rotate each image to place this highest intensity pixel to the same fixed position (on the vertical midline between the two top image quadrants — the "twelve o'clock" position), the x and y distances to the center of rotation (equal to the center pixel of the image x = y = 26) were calculated to find the length (l) of the hypotenuse and the opposite side of the right triangle using pdist. The angle α in degrees was then calculated by taking the inverse sine in degrees of this value (MATLAB function asind), as shown in Eq. (9). In cases where the brightest peak was located above the horizontal midline, the adjacent side of the triangle was the vertical midline. In cases where the brightest peak was located below the horizontal midline, the angle was calculated with the horizontal midline being the adjacent side, and 90° were added to the final angle value. Additionally, in cases where the brightest peak was located to the right of the vertical midline, the angle was multiplied with −1. To generate the results shown in Supplementary Fig. 3b, which shows the averaging of AZ images within randomly assigned categories, we generated a number of random category values and then proceeded with the averaging procedure described above. For this, we reproduced the distribution of category values from the AZ dataset according to the histogram values of the category vector as follows. A histogram of the category vector was generated (MATLAB function histogram) with a bin width of 1, yielding the absolute amount of AZs per category. A cumulative sum vector was calculated from these histogram values (MATLAB function cumsum). For each position in the category vector, we then chose a random number between 0 and 1 and multiplied it by the number of images. We then found the first position in the cumulative sum vector that was larger than this random value. The position found was equal to the assigned category. This resulted in a randomly assigned category vector with a similar distribution of categories as the original vector.

---

### Scaling and logic in the colour code on a superconducting quantum processor [^2f347a8c]. Nature (2025). Excellent credibility.

Fig. 4
Arbitrary state injection in a distance-3 colour code.

a, Schematic of a distance-3 colour code. The arbitrary state | ψ ⟩ is prepared on the data qubit indicated by a black arrow. The black line indicates the logical operators of the colour code, and the purple ellipses indicate Bell pairs, see the main text. b, Simplified circuit diagram for the state injection. Each line corresponds to one of the data qubits, on which we apply single-qubit Y - and Z -rotations (yellow boxes), Bell pair preparation circuits (purple boxes), a QEC cycle and a measurement in the X, Y or Z basis (MXYZ) for logical state tomography. c, Decoded (semi-transparent circles) and post-selected (solid dots) expectation value of the logical Pauli operators X L (blue), Y L (red) and Z L (green) when sweeping the polar angle θ. The solid lines correspond to ideal expectation values. d, Decoded (semi-transparent circles) and post-selected (solid dots) infidelities for the prepared logical state | ψ L ⟩. e, Magic state | m L ⟩ infidelity as a function of rejected data fraction for | A L ⟩ (green squares), | H L ⟩ (blue diamonds) and | T L ⟩ (red triangles), see the main text and Supplementary Information section G. The dashed lines serve as a guide to the eye, and the error bars indicate a 95% bootstrapped confidence interval. Each state is shown on the Bloch sphere by an arrow of the corresponding colour.

---

### Neurophysiological encoding of aversive prediction errors [^43b0e9e0]. Pain (2025). Medium credibility.

For evoked analysis, spatial smoothing using a Gaussian kernel (FWHM = 3 mm) was performed on the resulting source time-series to further reduce interindividual variability. The absolute value of the estimated source evoked time-series (source space × time) for each trial from [0, 1000] milliseconds w.r.t outcome delivery was time-averaged in steps of 35 milliseconds and exported to surface source GIfTI (.gii) files for further processing in SPM12(see Statistical Analyses). For oscillatory (TF) analysis, source time-series were subjected to a complex Morlet wavelet decomposition (central frequency = 1 Hz and FWHM = 3 seconds) with continuous time bins and frequency grouped into canonical bands (alpha [8, 12] Hz, beta [13, 30] Hz, low gamma [30, 60] Hz, and high gamma [61, 90 Hz]). The source TF maps (source space × time × frequency) were further normalized by performing a decibel (dB) conversion at each frequency band that is, taking the log of the ratio of total power value with respect to the mean total power over the baseline period (defined as the 1-second period before the appearance of 2 visual objects — refer to Fig. 1 A). The absolute value of the estimated source TF maps for each trial and frequency band from [0, 1000] milliseconds w.r.t outcome delivery was time-averaged in steps of 35 milliseconds and exported to surface source GIfTI (.gii) files for further processing in SPM12.

2.8. Head movement compensation

The estimated head movements from 6 quaternion data channels define 3 head rotations and 3 translations with respect to initial head position from the data set. Using this information, the position and orientation of the circumcenter with respect to the x-, y-, and z-axis were computed. Further, these estimates were demeaned to obtain the normalized deviants, that is, translations and rotations from the average head position/orientation during the entire data set. Trial-by-trial estimates of head position were computed in the time window [−1500, 1500] milliseconds around outcome onset. To account for the nonlinear effects of head motion on the signal, we also computed the squares, cubes, and all their derivatives of the head movement parameters (resulting in a total of 36 estimates plus one constant), which were used as additional nuisance regressors in the Generalized Linear Model (GLM) analysis described below.

---

### Impact of hierarchical water dipole orderings on the dynamics of aqueous salt solutions [^d1c30359]. Nature Communications (2023). High credibility.

Fig. 1
Structure of the ion solvation shell.

a Coordination number n of ions on the q − d plane. The Colour bar represents the value of n. b, c Snapshots of instantaneous solvation shell (coloured clouds) above and below the structural transformation line, respectively. Here the structural transformation line is located at the maximal derivative of n with respect to q. d, e Ion-oxygen RDFs, g (r) (solid black line), running coordination number n (green dash-dot-dot line), water dipolar order parameter,(red dash line), and number of H-bonds,(blue dash-dot line) as a function of ion–water distance for ions with d = 2.675 Å, q = 0.68 e (d) and q = 0.17 e (e). Here θ denotes the angle formed by water dipole and ion-oxygen vectors (Supplementary Fig. 3 a).is the number of H-bonds per hydrated water formed with other water molecules inside the same hydration shell. Following the Luzar-Chandler criterion, two water molecules are regarded as H-bonded if their oxygen-oxygen distance is shorter than 3.5 Å, and the H-O ⋯ O angle is smaller than 30 ∘. f, g Structural transformation line (inverted triangle) coincides with the iso-dipolar-order (, green curve) line (f) and the iso-H-bond-number (, green curve) line (g). h Schematic for the ionic solvation shell (blue shade) characterised by a thin, symmetric, dipolar ordered and no-bridging-H-bonded hydration shell. i Schematic for the VDW solvation shell (red shade) characterised by a thick, asymmetric, dipolar disordered and bridging-H-bonded hydration shell. In (i), the bridging H-bonds are shown by dot lines. Molecular graphics in (b, c) and (h, i) were produced using VMD 1.9.3.

---

### A modified reverse right-angled triangle osteotomy using the lateral approach for the treatment of posttraumatic cubitus varus deformity in children [^e4e7ab3c]. Journal of Pediatric Orthopedics (2023). Medium credibility.

FIGURE 3
A, HEW angle is formed at intersecting point of longitudinal axis of humerus and both bone of forearm. B, Usually lateral condylar prominence index is negative. It is measured by — lateral distance — medial distance/ transepicondylar distance. Calculated as AB−BC/AC. HEW indicates Humerus-elbow-wrist.

Statistical Analyses

All values were presented as the mean. ROM and HEW angle measurements before surgery and at the final follow-up were compared using paired t test. P value < 0.05 was considered significant. Statistical analyses were performed using SPSS statistical analysis software.

---

### The 30-degree angle revisited [^eec48357]. Journal of the American Academy of Dermatology (2005). Low credibility.

The standard surgical ellipse, with 30 degrees apical angles and a length-to-width ratio of 2 or 3 to 1, works optimally on a flat surface. The same pattern, when used for excisions on strongly convex or concave surfaces, leads to distortions which may require significant revisions. The reason for these discrepancies is explainable by the mathematical differences between flat Euclidian geometry and curved non-Euclidian geometry. Understanding these basic mathematical principles as applied to cutaneous surgery should lead to better preoperative planning, fewer intraoperative surprises, and more pleasing results.

---

### From the betweenness centrality in street networks to structural invariants in random planar graphs [^29785c51]. Nature Communications (2018). Medium credibility.

Fig. 3
Effect of edge-density ρ e on the betweenness. N ∼ 10⁴ nodes were randomly distributed on the 2D plane and their DT was generated. Edges were removed until the desired edge-density ρ e was reached. a – d The average over a hundred realizations of the resulting BC distribution ranging from the MST to the DT with increasing ρ e. The orange shaded area corresponds to fluctuations around the average of the realizations, while the silver and white shades separate the "tree-like" region from the "loop-region" respectively. e – h a single instance of the actual generated network corresponding to each ρ e. Shown in red are the nodes in the 90th percentile and above in terms of their BC value

The simulations indicate the observed bimodality to be a combination of a high betweenness backbone belonging to the MST, and a low betweenness region generated by loops. The transition between the two regimes is determined by the minimum non-zero betweenness value for the MST, which is O (N) and the tail may have different peaks, determined by the distribution of branches emanating from the tree. Progressively decorating the tree with loops leads to arbitrarily low betweenness values due to the creation of multiple alternate paths, thus smoothing out the distribution, as the betweenness transitions from an interval [N, N²] for the MST to a continuous distribution over [1, N²] for the DT.

Spatial distribution of high betweenness centrality nodes

Figure 3e–h shows a single instance of the actual network generated by our procedure for each corresponding edge-density. Highlighted in red are nodes lying in the 90th percentile of betweenness. There is a distinct change in spatial pattern with increasing ρ e; for the MST, they span the network and are tree-like with no apparent spatial correlation; as the network gets more dense, the nodes cluster together and move closer to the barycenter, suggesting a transition between a "topological regime" and a "spatial regime".

To quantify these observed changes, we investigate the behavior of the high BC nodes at and above percentile θ through a set of metrics: the clustering C θ which measures the spread of high betweenness nodes around their center of mass, the anisotropy factor A θ which characterizes the spatial anisotropy of this set of nodes, and finally, the detour factor D which measures the average extent to which paths between two locations deviate from their geodesic distance. (Details on metrics shown in Methods)

---

### Graphs [^c6c6d5a7]. Chest (2006). Low credibility.

Two rules of good graphs are presented and explicated.

---

### Subicular neurons encode concave and convex geometries [^bb5297df]. Nature (2024). Excellent credibility.

Corner coding is specific to environmental corners

To investigate the degree to which corner cells specifically encode environmental corners, we considered three properties that comprise a corner: (1) the angle of the corner, (2) the height of the walls and (3) the connection between two walls. First, we imaged as animals explored two asymmetric environments: a right triangle (30-60-90° corners) or a trapezoid (55-90-125° corners) (Fig. 2a). In these asymmetric environments, corner cells composed 3.6 ± 0.3% and 2.1 ± 0.3% of all neurons recorded in the right triangle and the trapezoid, respectively (Fig. 2b, c; n = 8 mice). By comparison, there were essentially no neurons classified as corner cells when points on the wall were assigned as the 'corners' of these environments (Extended Data Fig. 1n). In the right triangle, corner cell peak spike rates were significantly higher for the 30° (2.32 ± 0.14, mean ± s.e.m.) corner compared to the 60° (1.67 ± 0.16) and 90° (1.76 ± 0.16) corners, but did not differ between the 60° and 90° corners (Fig. 2b, d). To rule out the possibility that this was due to the limited angular range of these acute angles, we compared the peak spike rates at the corners of the trapezoid and found that the peak spike rates of corner cells increased from 125° (1.49 ± 0.12, mean ± s.e.m.) to 90° (1.90 ± 0.10) to 55° (2.23 ± 0.12) (Fig. 2e). We also compared the peak spike rates at the corners using the aforementioned across-session corner cells in the triangle (60°, 1.76 ± 0.12, mean ± s.e.m. n = 9 mice), square (90°, 1.47 ± 0.11) and hexagon (120°, 1.44 ± 0.13), and found the peak spike rate was higher in the triangle compared to the square and hexagon (Fig. 2f). Together, these results suggest that corner cells encode information regarding corner angles, particularly within asymmetric environments.

---

### Trigonometry in daily ultrasound practice [^c806ac21]. Critical Care (2018). Low credibility.

We have read with interest the editorial by Piton et al. regarding application of Pythagoras' theorem in central venous cannulation. Geometry is at the base of our daily life and we should apply his theorems and axioms to obtain the best result in our daily practice.

We believe that trigonometry is another important branch of geometry in addition to Pythagoras' theorem that has to be taken into consideration while performing invasive procedures under ultrasound guidance. Sine, cosine and tangent are the basis of trigonometry, they represent the ratio between the sides of a right-angled triangle. Sin(α) is the ratio between side B and the hypotenuse (H) (Fig. 1), Cos(α) is the ratio between side A and the hypotenuse (H), and Tan(α) is the ratio between side B and side A. It is important to note that, for a given angle α, the ratio between the sides is unconnected from the triangle size.

Fig. 1
Internal jugular vein ultrasound anatomy. H hypotenuse; A and B are catheti of the triangle

As already stated by Piton, in our ultrasound daily practice, we constantly build right-angled triangles: the hypotenuse is the needle route, side A is the distance measured on the skin between needle insertion point and target projection on the skin, and side B is the depth of the target.

Side B is determined by the patient's anatomy and the operator cannot modify it. As reported by Schulman et al. needle/skin angulation between 30° and 45° is considered to be ideal while performing ultrasound procedure.

Trigonometry is helpful in determining which targets can be reached with such needle angulation. At 45° angulation tan(α) is equal to 1, meaning that side A and side B have to be equal. For example, if our target jugular internal vein is 2 cm deep, the needle has to be inserted 2 cm from the target. Generalizing, we have a good needle visualization whenever Tan(α) ≤ 1 with side B equal to or shorter than side A.

In conclusion, physicians have to take into account target depth while choosing the ultrasound linear probe of appropriate size to be able to visualize all needle routes and the needle skin entrance site.

---

### Improving genomic prediction in cassava field experiments using spatial analysis [^6cd4b77e]. G3 (2018). Low credibility.

Figure 1
Spatial correlation with distance (meters) using different structures and standardizing parameters — an illustration. (A) Power; (B) Spherical; (C) Gaussian.

The distance matrix was calculated taking into consideration the plot dimension. Therefore, the distance between plots in any two Ranges (range distance) and Columns (column distance) was calculated as the number of Ranges multiplied by the width of the plot, and the number of Columns multiplied by the length of the plot. The distance between plots that were diagonal to each other was calculated as the hypotenuse of a triangle based on the Pythagorean theorem:We considered three scenarios of potential spatial correlation. First, the correlation was assumed to be isotropic, and the distance was calculated in Range, Column, and diagonal directions. In the second and third scenarios, correlation was assumed to be Range or Column directional as special cases of anisotropy. Here, either Range or Column distance was taken into consideration while calculating the distance matrix. The model used was:where Y is the response variable (e.g. DM); μ is the general mean; Z is the design matrix for genotypic effect, n is the number of observations, and g is the number of unique genotypes in the data; g is the vector of genotypic effect; s and r are the vectors of spatial effect and residual error; K is the genomic relationship matrix (here, the additive relationship matrix); and S is the spatial correlation matrix; I is the identity matrix.

---

### Reconstruction after rotational motion [^366eae52]. Magnetic Resonance in Medicine (2003). Low credibility.

Patient rotational motion during a scan causes the k-space sampling to be both irregular and undersampled. Conventional regridding requires an estimate of the sampling density at each measured point and is not strictly consistent with sampling theory. Here, a 2D problem is converted to a series of 1D regriddings by exact interpolation along the measured readouts. Each 1D regridding, expressed in matrix form, requires a matrix inversion to gain an exact solution. Undersampled regions make the matrix ill-conditioned but summing the matrix columns (without inversion) indicates the undersampled regions. The missing data could be reacquired, but in this study it is estimated using a Delaunay triangle-based linear interpolation on the original 2D data. The matrix conditioning is improved, leading to images with reduced artifacts compared to other regridding schemes. Furthermore, there is no requirement to estimate a density compensation function at each of the measured points.

---

### The European guideline on management of major bleeding and coagulopathy following trauma: sixth edition [^25fd0a0b]. Critical Care (2023). High credibility.

Regarding diagnostic investigations for traumatic hemorrhage, more specifically with respect to initial assessment, ABC-T 2023 guidelines recommend to assess the extent of traumatic hemorrhage clinically using a combination of patient physiology, anatomical injury pattern, mechanism of injury, and the patient response to initial resuscitation.

---

### An embedding-based distance for temporal graphs [^ba9a09cf]. Nature Communications (2024). High credibility.

Matched distance definition

From Eq. (5), we havewhere in (a) we exploited that M X and M Y are symmetric, in (b) we used the definition of M X, M Y, in (c) we used that property of the trace stating that, and finally in (d) we applied the definition of the Frobenius norm.

Properties of the unmatched distance

In this section, we show that the unmatched distance is invariant with respect to node permutations, and, more generally, to any orthogonal transformation applied to the columns of the embedding matrix. We then show that the unmatched distance is also invariant with respect to any orthogonal transformation applied to the rows of the embedding matrix. This is necessary because the EDRep loss function is invariant under this type of transformation.

We consider a bijective node mapping. We letbe the permutation matrix defined as Q i j = δ j, π (i). In the matrix multiplication, Q swaps the entry i with π (i):The matrix Q is orthogonal, in factwhere the last equality follows from π being a bijective mapping. As a consequence, Q Q T = Q T Q = I n. The distance d u depends on the embedding matrix X only through X T X. We now show that this expression is invariant under node permutation of the embedding matrix, or any orthogonal matrix Q. Indeed, let, thenWe now show that the distance d u is also invariant under the orthogonal transformation applied to the embedding matrix rows. Letbe an orthogonal matrix and let. Letting λ i (M) be the i -th smallest eigenvalue of M, then, for all i, λ i (A B) = λ i (B A) [Theorem 1.3.22]. It followsthus proving the claim.

---

### Re-interpreting mesenteric vascular anatomy on 3D virtual and / or physical models, part II: anatomy of relevance to surgeons operating splenic flexure cancer [^1235c168]. Surgical Endoscopy (2022). Medium credibility.

Morphological and morphometric analyses

All distances were measured on 3D virtual models in Osirix using a length tool.

The difference in level between the MCA origin and the IMA origin was named a mesenteric inter-arterial stair. The values measured and the relationship between the values are clarified in Fig. 1.

Fig. 1
Distance A: From the MCA origin to the IMA origin. Distance B: Parallel to the aorta axis from the IMA origin to the transverse plane through the MCA origin. Distance C: In the transverse plane from the MCA origin to the intersection with Distance B. The angle between the Distance A and Distance B intersection was named Angle AB Vessels MCA middle colic artery, SMA superior mesenteric artery, IMA inferior mesenteric artery

Distance A (oblique distance) was measured from the MCA origin to the IMA origin. Distance B (longitudinal distance) was measured parallel to the aorta axis from the IMA origin to the intersection with the transverse plane through the MCA origin. Distance C (lateral distance) and the angle AB were calculated using the Pythagorean theorem. These lines form a right-angled triangle with the MCA origin in one and the IMA origin in the other vertex.

The angle AB represents the direction, distance A (oblique distance) represents the length, and distance C (lateral distance) represents the height of the mesenteric inter-arterial stair.

The distance from the IMA origin to the LCA origin was measured on the IMA in a stepwise manner along the vessel. Calibres of the vessels were measured at their base, using a length tool, and measuring the largest diameter.

---

### [DOC] EPLC test plan-HHS.gov… [^6c0ec430]. HHS (2025). Medium credibility.

* Notes to the Author [This document is a template of a Test Plan document for a project. The template includes instructions to the author, boilerplate text, and fields that should be replaced with the values specific to the project. · Blue italicized text enclosed in square brackets provides instructions to the document author, or describes the intent, assumptions and context for content included in this document. · Blue italicized text enclosed in angle brackets indicates a field that should be replaced with information specific to a particular project. · Text and tables in black are provided as boilerplate examples of wording and formats that may be used or modified as appropriate to a specific project. These are offered only as suggestions to assist in developing project documents; they are not mandatory formats. When using this template, the following steps are recommended:

1. Replace all text enclosed in angle brackets with the correct field document values. These angle brackets appear in both the body of the document and in headers and footers. To customize fields in Microsoft Word select File- > Properties- > Summary and fill in the appropriate fields within the Summary and Custom tabs. After clicking OK to close the dialog box, update all fields throughout the document selecting Edit > Select All and pressing F9. Or you can update each field individually by clicking on it and pressing F9. These actions must be done separately for any fields contained with the document's Header and Footer.
2. Modify boilerplate text as appropriate for the specific project.
3. To add any new sections to the document, ensure that the appropriate header and body text styles are maintained. Styles used for the Section Headings are Heading 1, Heading 2 and Heading 3. Style used for boilerplate text is Body Text. *. 10 4.

3 Test Milestones 10
4. 4 Test Data 10 4. 5 Recording Results 10
4. 6 Analyzing Results 10 4. 7 Defect and Bug Resolution.

---

### Universality in long-distance geometry and quantum complexity [^47f080b3]. Nature (2023). Excellent credibility.

A careful analysis, confirms this picture and shows that the very largest additive discrepancy from thedistance is found near the cut locus, so for all U and, As, theandBerger spheres agree on distances to within a picometre. (A two-dimensional example that shows the same phenomenon is given in Supplementary Information 3).

Finally, let us examine the role of curvature. At large, the metric becomes strongly curved: the easy–easy section becomes very negatively curved, and the easy–hard sections become very positively curved. We call the σ x and σ y directions easy because they are cheap to move it, whereas the σ z direction is hard to move in for. The curvature length, which is also the distance to the cut locus in the hard direction, becomes very short. The high curvature explains how the metric can hide lots of volume at short distances that are invisible at long distances. Consider an operational definition of volume that counts how many marbles can be packed into the space: if we can cram in n (r) marbles each of radius r, then the volume is proportional to. Although the volume grows without bound as, the effective volume n (r) r³ at any finite value of r does not. Instead, the effective volume grows like r⁻¹ as we take r smaller and only levels off atonce r is less than the curvature length. Thus even asthe effective volume, as probed by experiments with finite resolution, stays finite.

Euclidean group

Consider parallel parking a unicycle.

The unicycle starts facing parallel to the curb and ends facing parallel to the curb but displaced sideways by z. The configuration space of the unicycle is its possible locations { y, z } and orientations { θ }, forming the Euclidean group SE(2). There are three primitive operations: roll forwards or backwards; turn; or drift sideways (perpendicular to the rolling direction). We model the difficulty of any parking manoeuvre withThe cost of parkingis the length ∫d s of the shortest path that connects our starting configuration { θ, y, z } = {0, 0, 0} to our parking spot {0, 0, z }.

---

### Dyke intrusion between neighbouring arc volcanoes responsible for 2017 pre-eruptive seismic swarm at agung [^e9bfdf68]. Nature Communications (2019). High credibility.

Markov Chain Monte-Carlo (MCMC) inversions currently are too computationally expensive to be used with Finite Element Models as about 100,000 simulations are typically required to characterize the a-posteriori probability density function for each model parameter. For an analytical model (1 simulation per second), this requires about a day, but for a 3D FEM (1 simulation per minute), this would require about 70 days of computation. We therefore use hybrid optimization scheme combining (1) a random search (Monte-Carlo) for the initialization of the parameter values and (2) a downhill simplex method (Nelder−Mead) for convergence towards the optimal parameters. The downhill simplex (Nelder−Mead) method is applicable to non-linear optimization problems for which the derivatives are unknown. The method uses the concept of a simplex, which is a polytope of n + 1 vertices in n dimensions (e.g. a triangle on a plane or a tetrahedron in 3D) to find the minimum of the objective function. The optimization consists of a series of steps where the point of the simplex with the largest objective function moves towards a lower point. The limitation of the Nelder−Mead technique is that it may converge to a local minimum and the result can be strongly dependent on the set of parameters chosen for the first simplex. To avoid this, we run a series of Nelder−Mead optimizations with initializations defined by a Monte-Carlo exploration of the parameter space.

We initially perform 1000 random-search simulations and the models with the smallest objective function are selected and used for the initial simplex. After each Nelder−Mead optimization, we calculate the mean and the standard deviation between the final values obtained for each parameter (red circles in Fig. 9). A new Nelder−Mead optimization is performed as long as the standard deviation remains above 10% of the mean value, and only 20 Nelder−Mead simulations are required for most of the model parameters to meet the criterion (Supplementary Table 3). Our hybrid approach significantly reduces the computing time compared to an MCMC approach, as in total only 4000 forward models were required for the optimization. For the inversion of the temporal subdivisions, we reduce the time even further by using the best-fitting dyke intrusion model for the cumulative displacement to initialize the inversion and a downhill simplex approach to search for nearby minima.

---

### Interaction of functional brain networks is associated with k-clique percolation in the human structural connectome [^340c6533]. Human Brain Mapping (2025). Medium credibility.

2.3 The Edge Confidence

To quantify the reliability of connections across subjects, we used an edge confidence measure, similar to the methodology proposed in (Szalkai et al.). The weight of an edge was calculated as its probability of occurrence across the entire set of networks. This approach helps to distinguish between common connections in the brain network and more individual‐specific ones.

2.4 Network Decomposition and Inverse Decomposition

To investigate how structural properties depend on edge confidence, we used two complementary approaches: network decomposition and inverse decomposition. In network decomposition, we applied a cutoff thresholdfor edge confidence, removing all links with weights below this threshold. Conversely, in inverse decomposition, we removed connections with weights greater than or equal to a threshold, allowing us to analyze subgraphs of weak (individual) links. The network decomposition and inverse decomposition techniques allow analyzing how different structural properties shape the organization of the connectome.

2.5 Network Model of High‐Order Clique Formation

We developed a generative model to examine whether high‐order‐clique percolation can arise under anatomical constraints of human connectomes. The model can be viewed as a modification of exponential random graph models under metric constraints. We initialize the system as a random graph with 100 nodes and 1000 edges, parameters selected to approximate the average edge density observed across empirical connectomes. Each node is placed randomly but uniformly within a unit‐radius sphere inEuclidean space. The positions of nodes are fixed throughout the simulation, establishing a stable anatomical embedding in which edge lengths correspond to Euclidean distances. This framework enables us to apply connection‐length constraints, reflecting the biological cost of long‐range axonal projections.

The network then evolves through an edge‐rewiring process that increases the frequency of triangular motifs, driving local clustering while preserving both the number of nodes and the total number of edges (i.e. constant network size and density). Edge rewiring was implemented as a stochastic process guided by network transitivity. At each iteration, a randomly selected edge is rewired, and the new network configuration is accepted according to one of two criteria: (1) if the new transitivity is greater than the current one (i.e.); or (2) via a Metropolis‐like condition governed by a chemical potential parameter:

---

### Dynamical barrier and isotope effects in the simplest substitution reaction via walden inversion mechanism [^6e8ca53f]. Nature Communications (2017). Medium credibility.

In contrast to the H′+H₂O→H′OH+H and H′+HOD→H′OD+H reactions, the reaction probability for reactions (1) and (3), with the same newly formed bond and cleaved bond, decreases substantially as the non-reacting group changes from CH₃ to CD₃, manifesting strong secondary isotope effects. As these two reactions process on the same PES with their variational bottlenecks located at the saddle point and their zero point energies (ZPEs) corrected barrier heights differ < 0.01 eV (1.591 versus 1.585 for reactions (1) and (3)), the substantial difference between two reactions apparently cannot be explained by the barrier height or the topography of the PES.

To explore the dynamics difference between these two isotopic reactions, we calculated the average value of the umbrella angle χ for methyl from the scattering wavefunction at the translational energy E = 1.8 eV. Figure 2a shows the average value of the umbrella angle, < χ >, as a function of R (the distance between incoming H and the centre of mass of CHD 3) and r (the bond length of breaking CH bond) for the H+CHD₃ substitution reaction, together with the potential energy contour obtained by minimizing the other degrees of freedom. The static saddle point locates at R = 2.7 Bohr and r = 2.5 Bohr with the corresponding umbrella angle χ = 90°. However, the calculated < χ > equals to 108.5° at the static saddle point, close to the corresponding vibrationally averaged value for CHD₃ reagent of 109.36°. With the increase of r (elongation of CH bond) or as the wavefunction proceeding to the product region from the static saddle point, < χ > decreases in an accelerated way, eventually passes through the 90° line at r ∼3.1 Bohr, which is considerably larger than the value at the saddle point. This means that the reaction does not proceed along the minimum-energy path on which the umbrella angle < χ > changes synchronously during the reaction with the incoming of H atom and elongation of the breaking CH bond to reach a value close to 90° at the static saddle point. Instead, it essentially does not vary while the incoming H atom approaches to the C atom and the breaking bond CH bond is elongated to their corresponding desired values for reaction. Only after that, the umbrella angle χ starts to decrease, initially slowly, then increasingly fast. Therefore, in reality, the reaction proceeds not on the potential shown in Fig. 2a, but on a potential shown in Fig. 2b, which is obtained by taking the umbrella angle at the calculated average value for every combination of R and r. In Fig. 2b, the 'saddle point' moves to R ∼2.85, r ∼3.1 Bohr. This is the very dynamical saddle point for the reaction with a corresponding barrier height of ∼1.93 eV, higher than the original barrier height by 0.32 eV, also locating much later than the original barrier in term of C–H bond length.

---

### Irrational choices via a curvilinear representational geometry for value [^c572fdcb]. Nature Communications (2024). High credibility.

Fig. 4
Curvilinear manifolds predict systematic biases in decoding.

a A curvilinear geometry would produce biases in the accuracy of a linear decoder. This cartoon illustrates how the projection of an arc onto a line compresses the values at the tails of the range. b A linear decoder trained on the vmPFC population and used to predict value. Note that predicted low values are higher than the true values and predicted high values are lower. c (top) Comparing the accuracy of a decoder trained on the real vmPFC data (vertical line) with decoders trained on linearized control populations (purple bars), 3.49 vs 2.82, 95% CI = [2.64, 2.99], bootstrapped test, p < 0.001. RMSE: root mean square error, higher = less accurate. c (bottom) Points projected from an arc onto a line, as visualized in (a), would have residual errors that follow a sine function. Difference in the quality of a fit of a linear and sine function to the residuals from vmPFC (vertical line) and the linearized controls (purple bars), 0.001 vs −0.003, 95% CI = [−0.006, 0.002], bootstrapped test, p = 0.057. SSE - sum of squared estimate of errors. d Another bias predicted by a curved–but not by a linear–manifold affects out-of-range observations. A decoder trained on a portion of the curved function would not make accurate predictions about the values in the other portion of the curve. e Decoders trained on the population response to one-half of the values (filled circles) and used to predict values outside of this range (open circles). Red = trained on high values; blue = trained on low values. f (top) The angle between the high- and low-value-trained decoders in real vmPFC population (vertical line) and in linearized controls (purple bars), 22.33 vs 13.97, 95% CI = [12.27, 15.76], bootstrapped test, p < 0.001. f (bottom) The change in slope in (e) between within-range and out-of-range values for each decoder (red = trained on high values; blue = trained on low), high-trained: 0.37 vs 0.12, 95% CI = [0.06, 0.18], bootstrapped test, p < 0.001; low-trained: 0.36 vs 0.1, 95% CI = [0.04, 0.17], bootstrapped test, p < 0.001. Vertical lines correspond to the vmPFC data and distributions to the control populations. Error bars indicate ± standard error of the mean across neurons (SEM), n = 121. ✱✱ p < 0.001.

---

### Places and health [^d3b243bf]. Journal of Epidemiology and Community Health (2004). Low credibility.

This glossary aims to provide readers with some key conceptual tools with which to address the issue of place and health; it is hoped that it will provoke thought and debate on the range of ways that places are connected to health.

---

### The hidden structure of human enamel [^ecc343d2]. Nature Communications (2019). High credibility.

Angular distances

The RGB values of every pixel in the image in Fig. 2 were recorded to a file using the Save XY Coordinates function in ImageJ (ImageJ, Bethesda, MD). A program we developed in Xcode took the RGB value of each pixel and converted it to HSB. The hue (H) was related to the in-plane angle and the brightness (B) to the out-of-plane angle, so each pixel was represented as a unit vector with its HB angles. The angular distance between each pixel and its neighbors to the right and below was calculated using the dot product in component form set equal to the cosine of the angle between the two unit-vectors. All angular distances were saved and plotted as a histogram with a bin size of 0.5° to produce the histograms in Fig. 6 and Supplementary Fig. 11. Histograms were plotted in Kaleidagraph® 4.5 for Mac for every pixel, every other pixel, every 4th, and so forth doubling the distance in each histogram up to 256. After importing all histograms into Adobe Photoshop® CC 2017, the 10,000 frequency was chosen arbitrarily, then the angular distance at this frequency was measured in each histogram, and plotted at the bottom of Supplementary Fig. 11, again using Kaleidagraph®, and importing into Photoshop®.

---

### Primary angle-closure disease preferred practice pattern ® [^f4deec88]. Ophthalmology (2021). High credibility.

Primary angle-closure disease PPP — SIGN individual study evidence levels used to rate studies are: I++ High-quality meta-analyses, systematic reviews of randomized controlled trials (RCTs), or RCTs with a very low risk of bias; I+ Well-conducted meta-analyses, systematic reviews of RCTs, or RCTs with a low risk of bias; I- Meta-analyses, systematic reviews of RCTs, or RCTs with a high risk of bias; II++ High-quality systematic reviews of case-control or cohort studies; high-quality case-control or cohort studies with a very low risk of confounding or bias and a high probability that the relationship is causal; II+ Well-conducted case-control or cohort studies with a low risk of confounding or bias and a moderate probability that the relationship is causal; II- Case-control or cohort studies with a high risk of confounding or bias and a significant risk that the relationship is not causal; and III Nonanalytic studies (e.g., case reports, case series).

---

### The alpha angle [^ed31883c]. The Journal of Bone and Joint Surgery: American Volume (2024). Medium credibility.

What Is the Utility of the Alpha Angle?

Alpha angle measurements from skeletal samples since the fourth centurysuggest an exponential growth in the prevalence of FAI, attributed to increases in height, weight, and body mass index. One proposed etiology of cam lesions is developmental, being related to high levels of physical activity during skeletal development. The most common reason for revision hip arthroscopy is residual FAI, specifically residual cam-type FAI.

Lohan et al. found that using the alpha angle in a retrospective, blinded manner to evaluate patients with known treatment pathways offered no value in predicting the presence of cam lesions that would require surgical treatment. They proposed 2 other measurements, 1 of which (the anterior femoral distance) did perform better than the alpha angle, although none of the measurements performed well enough to be considered useful in routine clinical practice. This is likely because cam lesions are 3D deformities, and no single angle, or even combination of angles on planar imaging, can adequately capture the deformity.

In the practical, clinical setting, particularly when it comes to diagnosis and decision-making, the alpha angle value itself is likely less important than the presence or absence of a pathologic cam deformity. In this context, the presence or absence of a cam lesion, and the accurate determination of whether such a lesion is a source of the patient's symptoms, is the most important question to be answered. From an academic perspective, the wide variability in accuracy, reliability, and techniques used to measure the alpha angle limits its interpretability and our ability to compare results across different studies.

It is clear that if the alpha angle is to be measured, it should ideally be measured on 3D imaging or, at the very least, on multiple different radiographic views, with an understanding of which anatomic locations are best visualized on each view. Measurement methods should use a circle of best-fit method rather than a simple angle, and (semi)automated measurements hold the promise of improved accuracy and reliability in a time-efficient manner. Table III summarizes our recommendations with corresponding grades of recommendation.

---

### Human V4 size predicts crowding distance [^9cb19c89]. Nature Communications (2025). High credibility.

Bootstrapping and confidence intervals

We quantified variability in the data with confidence intervals derived from bootstrapping over participants. Bootstrapping has the advantage over parametric statistical measures in that it does not make assumptions about the shape of the distributions. In a normal distribution, 68% of the data fall within one standard deviation of the mean, and 95% within two standard deviations. Hence by analogy, we report 68% and 95% CIs from bootstrapping. While we do not report formal null hypothesis significance tests (their scientific value is controversial,), the provided CIs allow for such inferences: when the 68% CIs of two groups do not overlap, this is similar to rejecting a null hypothesis that the two groups do not differ with an alpha parameter of 0.05. When the 95% CIs do not include 0, this is similar to rejecting the null hypothesis that the measure does not differ from 0 with an alpha of 0.05.

Correlation coefficient

All reported correlation coefficients are Pearson's correlation coefficients, and the associated p-values are from two-tailed tests.

Reporting summary

Further information on research design is available in the Nature Portfolio Reporting Summary linked to this article.

---

### A novel theory for rapid localization of the transverse-sigmoid sinus junction and "keyhole" in the retrosigmoid keyhole approach: micro-anatomical study, technique nuances, and clinical application [^8c695663]. Neurosurgical Review (2024). Medium credibility.

Results

The distances between the keypoint (D) and the relevant anatomical landmarks are listed in Table 1. The values of AD, BD, and CD were 17.42 ± 2.15 mm, 36.33 ± 2.90 mm, and 15.99 ± 3.99 mm, respectively, on the left and 18.13 ± 2.13 mm, 36.75 ± 2.66 mm, and 16.34 ± 3.96 mm, respectively, on the right (P > 0.05). The value of ∠α was 73.49 ± 8.22° on the left and 73.93 ± 7.16° on the right (P > 0.05). The values of a and b were 16.60 ± 2.53 mm and 4.75 ± 1.99 mm, respectively, on the left and 17.34 ± 2.46 mm and 4.85 ± 1.75 mm, respectively, on the right (P > 0.05)(Table 2). The value of AE was 15.82 ± 2.02 mm on the left and 16.51 ± 2.01 mm on the right (P > 0.05). The values of x and y were 14.20 ± 2.63 mm and 6.54 ± 1.83 mm, respectively, on the left and 14.95 ± 2.53 mm and 6.65 ± 1.61 mm, respectively, on the right, (P > 0.05) (Table 3).

Table 2
Relationship between the keypoint and relevant anatomical markers (mm, °)

AD: distance between the keypoint and the top point of the digastric groove; BD, distance between the keypoint and the mastoidale; CD, distance between the keypoint and the asterion; ∠α: anterior-inferior angle between AD and the baseline; a: perpendicular distance between D and A in the coordinate system; b: horizontal distance between D and A in the coordinate system

Table 3
Relationship between the borehole and relevant anatomical markers (mm)

AE: straight distance from the top point of the digastric groove to the center of the burr hole; x: perpendicular distance between E and A in the coordinate system; y: horizontal distance between E and A in the coordinate system

---

### Network curvature as a hallmark of brain structural connectivity [^c6a8063b]. Nature Communications (2019). High credibility.

Ollivier–Ricci curvature

Ollivier–Ricci curvature or coarse Ricci curvature is the discrete analog of the Ricci curvature –. Letbe a geodesic metric space equipped with a family of probability measures. We define the Ollivier–Ricci curvaturealong the geodesic connectingandaswheredenotes the earth mover's distance (Wasserstein 1-metric), andthe geodesic distance on the space. Note the similarity to Eq. (7).

For the case of an undirected weighted graph (e.g. a brain structural connectivity network), whereis the set of vertices (nodes), the set of edges, andthe set of edge weights, we letwheredenotes the set of nodes that are adjacent to; throughout, we assume that all the edge weightsand thatif, or equivalently, if. Note here that the geodesic distanceis taken to be the hop distance between nodeand, i.e. the minimum number of steps it takes to go fromto.

Node curvature

The (scalar) node curvature for node in the graph is computed by summing the curvature between nodeand all its neighboring nodes, i.e. We also note that an alternative "weighted" version of the node curvature may be defined as

Robustness and the Fluctuation Theorem

We now turn to the notion of robustness, which we employ in this paper, and subsequently make the link between robustness and curvature. It is based on ideas from statistical mechanics and, in particular, the Fluctuation Theorem formulated in Demetrius et al. The Fluctuation Theorem measures the ability of a network to maintain its functionality in the face of perturbations (internal or external).

Letbe the probability that the mean value of an observation (for a given network) deviates from its original value, by more thatat time, due to some perturbation. The rateat which the system returns back to its original state is defined as

Note that largemeans not much deviation and smallimplies a large deviation. In statistical mechanics, it is well-known that entropy and rate functions from large deviations are very closely related. The Fluctuation Theorem is a mathematical statement relating the positive correlation of changes in system entropyto changes in robustness:

---

### A spectral method for assessing and combining multiple data visualizations [^5aa71653]. Nature Communications (2023). High credibility.

Theorem 2

Under Conditions (C1a) (C1b) and (C2), for each i ∈ {1, 2. n }, it holds thatin probability as n → ∞. Moreover, for any constant δ ∈ (0, 1), there exist a constant C > 0 such that, whenever, we havein probability as n → ∞.

Theorem 2 is proved in Supplementary file Section B.4. In addition to the point-wise consistency ofas described byin probability, Theorem 2 also ensures that the proposed meta-distance is in general no worse than the individual candidate visualizations, suggesting a competitive performance of the meta-visualization. In particular, if in addition to Conditions (C1a) (C1b) and (C2) we also have, that is, the magnitude of the random distortions from the true structureis relatively large, then each candidate visualization necessarily has at most mediocre performance, i.e.in probability. In such cases, the proposed meta-distances is still consistent and thus strictly better than all candidate visualizations. Theorem 2 justifies the superior performance of the spectral meta-visualization demonstrated in previous sections, compared with 16 candidate visualizations.

Among the three conditions required for the consistency of the proposed meta-distance matrix, Condition (C2) is most critical as it describes the minimal SNR requirement, that is, how much information the candidate visualizations altogether should contain about the underlying true structure of the data. In this connection, our theoretical analysis indicates that, in fact, such a signal strength condition is also necessary, not only for the proposed method, but for any possible methods. More specifically, in Supplementary file Section B.6, we proved (Theorem 4) that, it's impossible to construct a meta-distance matrix that is consistent when Condition (C2) is violated. This result shows that the settings where our meta-visualization algorithm works well is essentially the most general setting possible.

---

### The use of plots in orthopaedic literature [^95fed5f5]. The Bone & Joint Journal (2015). Low credibility.

Plots are an elegant and effective way to represent data. At their best they encourage the reader and promote comprehension. A graphical representation can give a far more intuitive feel to the pattern of results in the study than a list of numerical data, or the result of a statistical calculation. The temptation to exaggerate differences or relationships between variables by using broken axes, overlaid axes, or inconsistent scaling between plots should be avoided. A plot should be self-explanatory and not complicated. It should make good use of the available space. The axes should be scaled appropriately and labelled with an appropriate dimension. Plots are recognised statistical methods of presenting data and usually require specialised statistical software to create them. The statistical analysis and methods to generate the plots are as important as the methodology of the study itself. The software, including dates and version numbers, as well as statistical tests should be appropriately referenced. Following some of the guidance provided in this article will enhance a manuscript.

---

### Ultra-high dynamic range quantum measurement retaining its sensitivity [^6f9c90ae]. Nature Communications (2021). High credibility.

To improve the sensitivity for a large range, initially, a number of measurements with different areas are combined to uniquely define the magnetic field amplitude in a range limited by the measurement with the smallest area (Fig. 1d). Consequently, only part of the measurement time is spent on the largest area, which has the best sensitivity (but a small range), while the remainder of the time is spent on areas with a worse sensitivity. Therefore, the sensitivity of the combined measurement is strictly worse than this best sensitivity. Using halved areas (hence requiring at leastadditional areas) and the same number of iterations for each area and using no optimisations, for roughly the same σ B, the measurement time for the combined sequence. Thus, the sensitivity would becometimes worse, which is already a significant improvement compared to the straightforward case in the last paragraph.

The measurements resulting from different areas are combined via Bayes' theorem. For area A n, the measurement gives signal S n (for example the crosses/circles/triangles on the sinusoids in Fig. 1a, d for three areas). The posterior probability distribution for the magnetic field B given measured signal S n iswiththe prior distribution, independent of B, andwiththe relation between the signal S and the applied field B (the sinusoids in Fig. 1a, d, e). Fig. 1e visualises these equations.is a Poisson distribution (counting photons), but it can be approximated by a normal distribution (green line along y -axis in Fig. 1e) when more than ~10 photons arrive (with continuity correction). This is generally the case when the uncertainty is below the maximum uncertainty, as described later. For the first measurement, the prior distribution is flat since there is no initial knowledge about the field, and for the remainder of the measurements, the previous posterior is the new prior distribution. This results in a combined distribution as demonstrated in Fig. 1f.

---

### Mono-planar T-Hex: speed and flexibility for high-resolution 3D imaging [^e6b14d76]. Magnetic Resonance in Medicine (2022). Medium credibility.

FIGURE 1
A, Gray dots depict part of the hexagonal grid in a transverse section of a stack of spirals or echo‐planar readouts. Blue dots mark the revolutions acquired within a shot for N = 1, 2, and 3 shots per k‐space plane. B, The hexagonal grid is described by oblique coordinates. All existing distances between grid points are represented in distances of the origin to points in one dodecant (yellow wedge), including its edges. Blue rings mark the distances reflected in (A), and the red ring highlights a distance not available with integer N. C, This distance is used when tilting the grid with respect to the rotational axis of the stack. The FE lines or spiral revolutions acquired in three subsequent shots are highlighted in red, orange, and yellow. D, The hexagonal grid is tilted as shown in (C). Red and yellow dots mark the points of the hexagonal grid that are covered by two subsequent shots. Green lines in the background show that all points of the hexagonal grid lie on nodes of a finer, rectilinear lattice, from which the starting angle of each spiral shot can be derived. Subsequent shots start with linearly progressing angles. The pattern is repetitive. E, Background: An entire mono‐planar T‐Hex stack of spirals cut open. The uppermost shot and the sites of puncture of the spirals are marked in dark gray. The resulting hexagonal grid shows the tilt as visualized in (C) and (D). In a representative patch, grid points that belong to spiral shots with the same phasing are colored the same. Foreground: Cross‐section corresponding to the stack in the upper panel, the acquisition time point is color‐coded, indicating a smoothfilter. Owing to the cross‐sectional depiction, "holes" appear on the central k‐space axis. In fact, this region is equally uniformly sampled, since all spirals start from the rotational axis of the cylinder

---

### Principles and open questions in functional brain network reconstruction [^36d64999]. Human Brain Mapping (2021). Medium credibility.

2.1 From brain dynamics to functional brain activity

Perhaps the most common way of representing system‐level brain activity and therefore the time‐varying data produced by standard neuroimaging techniques is as the output of an underlying spatially‐extended dynamical system embedded in the 3D anatomical space. The space Φ associated with the dynamics is typically treated as scalar, vector, or tensor field, 1 either in the time domain, ranging from experimental to developmental or evolutionary time scales or, in somehow equivalently ways, in the frequency domain or in phase space.

Whatever the domain in which it is defined, the space has in general some additional structure, that is, some relationship among its elements. The space Φ is often identified with the anatomical space itself and treated as a smooth Euclidean space. This means that on such a space a distance is defined, that is, a rule to calculate the length of curves connecting points of the space, and that the tools of standard calculus can be used to carry out operations within the space, and comparing or evaluating differences across conditions. However, when considered at the whole brain spatial scale, neither anatomy nor global dynamics can in general be thought of as a simple Euclidean space. The folded structure resulting from brain gyrification produces an object with non‐trivial geometry. Perhaps more importantly, anatomically contiguous brain areas may radically differ in terms of dynamics and function. Φ can nonetheless be equipped with some geometry providing a way of defining distances. This can be done by assuming the anatomically‐embedded dynamical space to be locally Euclidean, an approximation typically adopted in anatomical data analysis. The resulting space is a manifold M, that is, a geometric object consisting of a collection of Euclidean patches, which are local descriptions of Φ covering the space. Such a construct is akin to a standard geographical atlas, which is nothing else but a collection of local charts projected on the plane. Overall, the resulting geometry is Euclidean within patches, but of a different nature at longer spatial scales (cf. Section 3.3.1). The main problems with such a space are understanding the conditions under which its parts are distinguishable, how the charts are related to each other, how to treat overlaps between two separate charts and changes in the description of the same set in different coordinates (Robinson, 2013a) (see Figure 1).

---

### Hyperuniformity and phase enrichment in vortex and rotor assemblies [^df102ec5]. Nature Communications (2022). High credibility.

In the limit of small distances, r ≪ λ, the stream function is, i.e. exactly the same as for an ideal point vortex. In the opposite limit, r ≫ λ, the stream function becomesas in quasigeostrophic (QG) flows — atmospheric or oceanic flows coming from gradients in pressure coupled to the Coriolis force, or driven rotors on the surface of a fluid. A membrane rotor, therefore, transitions from a point vortex for Euler at small distances to that of QG flow at large distances. Thus, the velocity diverges (decays) as 1/r (1/r²) in the limit of small (large) distances (see Fig. 2 B, C). For simplicity, we work primarily in the limit of small distances, r ≪ λ, since in this limit the dynamics in a membrane converge with those of point vortices (many results still apply to the more general case as shown in the Supplementary Figs. 5 and 6). In what follows, we will use the term point vortices when there are only hydrodynamic interactions and the term rotors when the particles have steric interactions in addition to hydrodynamic ones.

---

### Emergence of self-affine surfaces during adhesive wear [^14744a45]. Nature Communications (2019). High credibility.

Spectral analysis

Let us consider a surface of length L, whose height is defined by the continuous function h (x), where x is a spatial coordinate. We refer to the PSD of such a surface in terms of PSD per unit length Φ h (q), q being the wavevector, defined aswhere the integral is the continuous Fourier transform of h (x). The PSD defined in Eq. (2) is equivalent to the PSD of a continuous function h (x) that is zero everywhere except over a distance L, normalized by L. (Note that the specification 'per unit length' is often dropped in surface roughness analyses,.) In particular, we estimate Φ h aswhere P h (q n) is the classical periodogram, :the summation being the discrete Fourier transform of the surface. In fact, h (x) is known only at a discrete set of N points x k (k = 0, 1, …, N − 1), regularly sampled at an interval Δ x, such that h k = h (k Δ x) are the known values of h (x). In our case, Δ x = L / N, N being the number of atoms belonging to a surface of length L, and is approximately 1 r 0.

It can be shown that both the PSD Φ h per unit length and the periodogram P h are normalized such thatandare equal to the mean squared amplitude σ² of h (x) and h k, respectively.

Note that the derivative of both P h and Φ h is the same in the log–log plane, as their estimation differs only by a multiplicative factor Δ x (see Eq. (3)): the estimated self-affine exponent does not change if one or the other is considered.

Height–height correlation analysis

Another suitable method to estimate the Hurst exponent H is to investigate the height–height correlation function, which describes the change of heights Δ h between two points at distance δx horizontally:where the angle brackets indicate spatial average. The height–height correlation function scales as Δ h (δx) ~ δx H: it is therefore possible to determine the Hurst exponent H from its log–log plot. It is also possible to observe potential upper and lower cut-off values of δx limiting the scaling regime.

---

### Voxel volume overlap: voxel-size sensitive indicators of subject motion in functional MRI [^5d16f703]. Human Brain Mapping (2025). Medium credibility.

When calculating subject motion, it is important to be precise about the respective reference frame. If motion is calculated w.r.t. the first image in a timeseries, this measure is known as total displacement (TD). It describes how far away from the original position a subject moved in the course of the session. This, however, is not necessarily the most relevant measure, as slow movements are more easily accounted for than rapid motion spikes (Maknojia et al.). For the latter in particular, scan‐to‐scan displacement (STS) is more relevant, which uses the individually preceding volume as the reference frame. The way these two indicators are calculated is similar, using a 3D expansion of Pythagoras theorem (Wilke) to calculate the joint displacement resulting from all shifts and all rotations.

2.1 Open Questions

While it is trivial to estimate the volumetric effects of simple shifts (see example in the introduction), it is far from trivial to account for rotations as there is a multitude of possible rotatory effects, and their combinations, on a 3D volume. Computing the exact overlap between two arbitrarily‐rotated cubic volumes, therefore, is mathematically highly challenging. However, while no elegant algebraic solution exists, it is possible to assess the overlap by using a geometric approach. Here, the reference voxel is defined as the intersection of six planar boundaries, with each plane dividing space into two categories: "definitely outside" and "potentially inside"; the intersection of all "potentially inside" volumes then unequivocally defines the cube. For example, consider a dice on a table and its top surface showing, for example, "1". Everything above that surface is outside of the dice, while everything below may be inside. The lower (opposite) surface will then be defined by the face of the dice showing "6", which in our example is facing the table. Again, everything below that surface is outside. Repeating this process of exclusion with the "4 & 3" and the "2 & 5" faces will unequivocally define the space, and hence, the volume of the dice. The intersection of a moved cube with a reference cube can therefore be calculated by iteratively looping over all six planes (of the reference cube) and by therewith removing all "definitely outside" sections (of the moved cube). The remaining part constitutes the overlapping remnant of the moved cube, the volume of which can then be computed.

---

### Ultra-high dynamic range quantum measurement retaining its sensitivity [^63f3f730]. Nature Communications (2021). High credibility.

Algorithm design

To design our eventual algorithm, its principle is explored in more detail with additional simulations. Fig. 3a shows the result for changing the relative number of iterations for each area, which reveals that there is a trade-off between the lowest uncertainty reached for measurement times at the steep region and at long measurement times. In other words, depending on T meas, a different relative number of iterations gives the lowest uncertainty. When fixing these (Figs. 2a and 3a), the uncertainty is not optimised, and thus it can display very steep curves that can be tuned to even sub-Heisenberg-like scaling (for examplein Fig. 3a).

Fig. 3
Simulation analyses.

a For different relative numbers of iterations of the subsequences (written directly left of each curve) of areas A, the uncertainty σ B with respect to measurement time T meas changes. Depending on the measurement time, a different combination gives the lowest uncertainty. b Minimised uncertainty for a large-range sequence by optimally combining the subsequences (red line). The dashed lines give the uncertainty for single-area sequences (A₀ blue, A₀/2 magenta, A₀/4 olive, A₀/8 grey). See Supplementary Note 1 for maximum uncertainty ∝ range. c The relative number of iterations for each area (A₀ blue crosses, A₀/2 magenta circles, A₀/4 olive triangles, A₀/8 grey diamonds kept at 10⁰) for each measurement time to minimise the uncertainty, which results in the red line in b. The vertical arrows indicate when a subsequence for its area turns on, since its relative number of iterations becomes significant. The green dashed line gives the relative difference between the most-sensitive small-range sequence (blue dashed line in b) compared to the optimally combined large-range sequence. This difference scales inversely with the measurement time. d When looking at the turning-on points (yellow crosses, fit with black dotted line) for many sequences with different areas (largest area blue line, smallest area red line), it scales asfor short measurement times. Please note that the optimally combined result in b scales as, since it includes relatively large areas only, equivalent to the lowest lines in this plot.

---

### Editorial commentary: is the lateral center-edge angle sufficient for the approximation of acetabular coverage? [^203c4fb5]. Arthroscopy (2019). Medium credibility.

The lateral center-edge angle is a robust technique with proven clinical applicability for quantifying acetabular coverage. However, it measures only the lateral coverage of the femoral head without consideration of other important portions of the acetabulum such as the anterior or posterior wall. Three-dimensional acetabular coverage measurement techniques capable of quantifying the entire acetabulum have become available, thus posing the question of whether we should still rely on the lateral center-edge angle for the assessment of acetabular coverage.

---

### Corrections [^e34f1524]. The Lancet: Respiratory Medicine (2016). Medium credibility.

[This corrects the article DOI: 10.1016/S2213-2600(15)00283–0.].

---

### The uncertainty principle enables non-classical dynamics in an interferometer [^3eb32508]. Nature Communications (2014). Medium credibility.

The quantum uncertainty principle stipulates that when one observable is predictable there must be some other observables that are unpredictable. The principle is viewed as holding the key to many quantum phenomena and understanding it deeper is of great interest in the study of the foundations of quantum theory. Here we show that apart from being restrictive, the principle also plays a positive role as the enabler of non-classical dynamics in an interferometer. First we note that instantaneous action at a distance should not be possible. We show that for general probabilistic theories this heavily curtails the non-classical dynamics. We prove that there is a trade-off with the uncertainty principle that allows theories to evade this restriction. On one extreme, non-classical theories with maximal certainty have their non-classical dynamics absolutely restricted to only the identity operation. On the other extreme, quantum theory minimizes certainty in return for maximal non-classical dynamics.

---

### Overcurvature describes the buckling and folding of rings from curved origami to foldable tents [^3f942d9a]. Nature Communications (2012). Medium credibility.

Creased paper rings are a third example of overcurved structures (Fig. 2c). In curved origami, paper is creased along closed curved paths, resulting in the out-of-plane bending of the folding path due to torsion. Simultaneously, the conservation of arc length by the two sides of the crease imposes an increase of the curvature of the crease by a factor Oₚ = 1/cos(δ/2), where δ is the angle between the normals to the two sides of the crease (Supplementary Methods; Supplementary Figs S2 and S3; Supplementary equation S19). We creased a flat circular ring of paper along its median circle, and adjusted the degree of overcurvature by tuning the crease angle δ and holding it constant. After observations, the paper ring was cut and the number of turns in the formed coil was quantified to compute O p. This overcurvation process corresponds to increasing the local pre-set curvature while keeping the length constant.

Finally, to give a human-scale example of overcurved structures, arcs of wood of radius of curvature R = 1 m were combined with clamping collars to form closed continuous rings of square cross-section, with different magnitudes of the pre-set overcurvature. Representative images are shown in Fig. 2d and in Supplementary Fig. S4.

The overcurvation scenario is similar for all observed systems: the conformation starts from a circle at O p = 1 and buckles to a saddle shape with two pairs of upper and lower lobes for larger pre-set overcurvatures. The opposite lobes of the saddle then overlap close to O p = 2.5, and the ring finally debuckles to form a triple-coiled loop for O p = 3. All conformations have D 2d symmetry (for creased paper, this holds true only for the crease line). Although some issues are specific to each case, such as the cross-section rotation angle or the formation of wrinkles and lateral creases, the general scenario is identical for these systems, which cover almost five orders of magnitude in spatial scale, and for which the physical origin of overcurving differs sensibly. In the sequel, we concentrate on the general conformation of the centre lines of the rings (or of the crease lines for paper strips), and ignore details such as small wrinkles and lateral creases.

---

### The H-index of a network node and its relation to degree and coreness [^37fd096e]. Nature Communications (2016). Medium credibility.

Identifying influential nodes in dynamical processes is crucial in understanding network structure and function. Degree, H-index and coreness are widely used metrics, but previously treated as unrelated. Here we show their relation by constructing an operator, in terms of which degree, H-index and coreness are the initial, intermediate and steady states of the sequences, respectively. We obtain a family of H-indices that can be used to measure a node's importance. We also prove that the convergence to coreness can be guaranteed even under an asynchronous updating process, allowing a decentralized local method of calculating a node's coreness in large-scale evolving networks. Numerical analyses of the susceptible-infected-removed spreading dynamics on disparate real networks suggest that the H-index is a good tradeoff that in many cases can better quantify node influence than either degree or coreness.

---

### The alpha angle [^b49a0091]. The Journal of Bone and Joint Surgery: American Volume (2024). Medium credibility.

➢ The alpha angle was originally defined on magnetic resonance imaging (MRI) scans, using a plane, parallel to the axis of the femoral neck. However, much of the literature on the alpha angle has used radiographs or other imaging modalities to quantify the alpha angle.
➢ The measurement of the alpha angle can be unreliable, particularly on radiographs and ultrasound.
➢ If radiographs are used to measure the alpha angle, the circle of best-fit method should be used on multiple different views to capture various locations of the cam lesion, and "eyeballing" or estimating the alpha angle should be avoided.
➢ The cam lesion is a dynamic and 3-dimensional (3D) problem and is unlikely to be adequately defined or captured by a single angle.
➢ Modern technology, including readily available 3D imaging modalities, as well as intraoperative and dynamic imaging options, provides novel, and potentially more clinically relevant, ways to quantify the alpha angle.

---

### An embedding-based distance for temporal graphs [^3493f5a4]. Nature Communications (2024). High credibility.

Temporal graphs are commonly used to represent time-resolved relations between entities in many natural and artificial systems. Many techniques were devised to investigate the evolution of temporal graphs by comparing their state at different time points. However, quantifying the similarity between temporal graphs as a whole is an open problem. Here, we use embeddings based on time-respecting random walks to introduce a new notion of distance between temporal graphs. This distance is well-defined for pairs of temporal graphs with different numbers of nodes and different time spans. We study the case of a matched pair of graphs, when a known relation exists between their nodes, and the case of unmatched graphs, when such a relation is unavailable and the graphs may be of different sizes. We use empirical and synthetic temporal network data to show that the distance we introduce discriminates graphs with different topological and temporal properties. We provide an efficient implementation of the distance computation suitable for large-scale temporal graphs.

---

### Ultrasound-guided peripheral vascular catheterization in pediatric patients: a narrative review [^deee6017]. Critical Care (2020). Medium credibility.

Given that the insertion angle is actually between approximately 30° and 45° when performing catheterization in pediatric settings, the minimum required catheter length is presumed to be the catheter travel distance from skin to vessel, which is the perpendicular distance corrected by the actual insertion angle (Additional file 1 A). An insertion angle of 45° is the main and most convenient way to presume approximate catheter travel distance because it is calculated as the perpendicular depth × 1.4 using the Pythagorean theorem (Additional file 1 B) Therefore, the catheter travel distance is 0.7 cm when approaching a vessel of 0.5 cm perpendicular depth at an insertion angle of 45°, which requires a catheter length of 2.0 cm under the presumption that 65% of the catheter length is inside the vessel. If the insertion angle is set at less than 45°, the minimum required catheter length will be longer. A standard-length 24G or 22G catheter is approximately 19 mm or 25 mm, respectively. Thus, when approaching vessels that are deeper than 0.5 cm below the skin surface, longer catheters should be considered.

---

### The European guideline on management of major bleeding and coagulopathy following trauma: sixth edition [^af207056]. Critical Care (2023). High credibility.

Regarding medical management for traumatic hemorrhage, more specifically with respect to general principles, ABC-T 2023 guidelines recommend to continue resuscitation measures using a goal-directed strategy guided by standard laboratory coagulation values and/or viscoelastic measures.

---

### Universality in long-distance geometry and quantum complexity [^87f13894]. Nature (2023). Excellent credibility.

Wilsonian connections

We make explicit the analogy between our findings in geometry and the Wilsonian theory of renormalization.

A starting point for complexity geometry, both logically and historically, is Nielsen's cliff metric with a huge penalty factor for the non-easy directions(see section ' Main conjectures '). In terms of renormalization, we might call this a bare theory of complexity. For this theory, the behaviours of the UV (that is, short distances) and the IR (that is, long distances) are very different. The UV has violently large curvatures and a very short distance to the cut locus. Using the bare theory, computing complexity growth in the UV (short-distance behaviour) is straightforward. We find a linear growth with a very large slope. However, the calculation breaks down once the geodesic we are following passes the cut locus, in which non-perturbative effects become important. These effects slow the growth of complexity, and if our conjectures are correct, eventually the complexity growth becomes linear again, but with a much-reduced slope. A new schedule of penalty factors — the critical schedule — defines an effective theory that is easy to use in the IR.

In statistical mechanics and quantum field theory, this is analogous to the statement that a field theory is a flow between a UV conformal field theory and an IR conformal field theory. This means (among other things) that certain correlation functions in field theories exhibit a power-law decay in the UV and a power-law decay in the IR, but with different (anomalous) logarithmic slopes (referred to as critical exponents) in the UV and IR. Here the slopes of the linear growth of distances play the part of the logarithmic slopes in statistical physics. Our conjecture that the IR slopes differ dramatically from the UV slopes is analogous to the statement that in a strongly coupled field theory, anomalous dimensions are typically large.

The values of the penalty factorsare the parameters of the theory, playing the role of the set of (inverse) coupling constants in a quantum field theory. If a given penalty factor is greater than the value it attains in the critical schedule, then that parameter is irrelevant — that is, perturbing it does not affect the IR behaviour. The penalty factor becomes relevant only when it has the same value it would have had on the critical schedule, and any further decrease inbeyond this point then changes the distance function in the IR.

---

### Quantifying hydrogen bonding using electrically tunable nanoconfined water [^4c98155f]. Nature Communications (2025). High credibility.

Introduction

Hydrogen bonds (HBs) are unique intermolecular interactions that are stronger and more directional than weak and isotropic van der Waals forces, yet weaker and less directional than covalent bonds –. HBs are typically defined as attractive interactions between a hydrogen atom (H) and an acceptor group (A) in a system represented as D-H···A, where H is covalently bonded to an electronegative donor group (D), while H carries a partial positive charge δ +. A key feature of HBs is their directionality, often with a D-H···A angle close to 180°. In water and similar systems, where distance between D and A is typically greater than 2.5 Å, the electrostatic attraction between H (δ +) and A (δ −) is believed to be the primary factor contributing to the strength of HBs –.

HBs could significantly alter the properties of residing system. For instance, the formation of HBs in water has a pronounced impact on the physical properties of its condensed phases — ice. Often, hydrogen-bonded systems form extensive networks of HBs that extend over long ranges and in various directions, as seen in liquid water, ices, hydrogels, proteins, and DNA molecules. The complexity of these networks, along with the presence of interfaces or external electric fields in realistic heterogeneous systems, makes it difficult to analyze them using classic definition of HBs or to predict the properties of such systems. To address these challenges, the electrostatic model of HBs, initially proposed decades ago that based on point charge approximation, has been refined with various treatments, such as electron distribution calculationsand orbital hybridization theory, leading to a more sophisticated description of HBs. Despite advancements in modeling and the introduction of spectroscopic methods, which provide direct information on molecular vibrations of hydrogen-bonded species, a practical and efficient experimental approach to quantitatively predict the properties of HBs is still lacking.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^6e0f31e7]. Journal of the American College of Cardiology (2025). High credibility.

Implications for health equity — working definitions: Equity is the absence of unfair, avoidable, or remediable differences among groups of people, whether defined socially, economically, demographically, geographically, or by characteristics such as sex, gender, ethnicity, disability, or sexual orientation. Unlike health equality, which refers to equal access to quality health care for all, health equity is achieved when everyone can attain their full potential for health.

---

### Uterocervical angle versus cervical length in the prediction of spontaneous preterm birth in women with history of spontaneous preterm birth: a prospective observational study [^330a4956]. BMC Pregnancy and Childbirth (2023). Medium credibility.

Table 3
Cervical length among the study participants

SD Standard deviation, t Student t-test, p p value, *: statistically significant at p ≤ 0.05

1 st visit: 16 0/7 weeks – 24 0/7 weeks

2 nd visit: 24 1/7 weeks – 32 0/7 weeks

3 rd visit: 32 1/7 weeks – 36 6/7 weeks

Table 4
Uterocervical angle among the study participants:

SD Standard deviation, t Student t-test, p p value, *: statistically significant at p ≤ 0.05

1 st visit: 16 0/7 weeks – 24 0/7 weeks

2 nd visit: 24 1/7 weeks – 32 0/7 weeks

3 rd visit: 32 1/7 weeks – 36 6/7 weeks

Table 5
Mode of delivery among the study participants

χ 2 Chi-square test, MC Monte carlo, p p value

Table 6 compared both arms of the study regarding gestational age when delivery occurred; there was a significant difference between the two arms favoring the term arm. Table 7 showed the neonatal outcome among the study participants; 45 neonates were discharged within the first 24 h after delivery (41 neonates from the term arm and 4 neonates from the preterm arm), 7 neonates from the preterm arm died at the NICU while 18 neonates were discharged after NICU admission (11 from the preterm arm and 7 from the term arm).

---

### Spontaneous buckling of contractile poroelastic actomyosin sheets [^2e60473f]. Nature Communications (2018). Medium credibility.

Fig. 4
Acto-myosin sheets are poroelastic II. a Subsequent epifluorescence micrographs of a contracting gel with embedded fluorescent beads with a diameter of 200 nm at high magnification. Red circle marks one bead in subsequent micrographs. Gray line indicates the gel boundary. Actin is labeled with Alexa-Fluor 488. Beads are Fluoresbrite Yellow-Green. Scale bars: 100 μm. b Local speed of the gel (gray dots) and of the bead (white circles) at nearby positions in a. Dashed line represents the time, when the bead left the gel. c Distribution of angles θ between the local gel and bead velocities from N pairs = 25 velocity pairs. d Solvent viscosity η and relaxation time τ divided byas a function of glycerol percentage in the solvent. Quantities are normalized to their values at 0% glycerol. For each % of glycerol values are averaged over N gels = 3 gels with initial radii of R = 1.4 mm and height h = 140 μm (drop volume is 0.87 μL). Error bars indicate standard deviation of experimental values. e Numerical solution to the dynamic equations. Green: gel volume fraction φ, arrows: solvent velocity field. Parameters are given in Supplementary Table 1. f Gel contraction speed v and fraction of bound motors Q as a function of time for the solution in e.g. The distance d traveled by the density from the gel boundary inwards in the reference frame of the laboratory as a function of time for the gel shown in Fig. 5. Black dots, gray triangles, hollow circles, hollow diamonds, and hollow triangles correspond to increasing values of the density. Black dots and gray triangles correspond to time courses that start before t = t max. h As in g for the solution of the dynamic equations shown in f for volume fractions 0.007 (blue), 0.034 (red), 0.151 (green), and 0.271 (cyan)

---

### Work-relatedness [^cdc774cb]. Journal of Occupational and Environmental Medicine (2018). Medium credibility.

Work-relatedness — summary states that "The determination of work-relatedness should utilize a reproducible method".

---

### Testing the speed of' spooky action at a distance' [^01e7fd14]. Nature (2008). Excellent credibility.

Correlations are generally described by one of two mechanisms: either a first event influences a second one by sending information encoded in bosons or other physical carriers, or the correlated events have some common causes in their shared history. Quantum physics predicts an entirely different kind of cause for some correlations, named entanglement. This reveals itself in correlations that violate Bell inequalities (implying that they cannot be described by common causes) between space-like separated events (implying that they cannot be described by classical communication). Many Bell tests have been performed, and loopholes related to locality and detection have been closed in several independent experiments. It is still possible that a first event could influence a second, but the speed of this hypothetical influence (Einstein's 'spooky action at a distance') would need to be defined in some universal privileged reference frame and be greater than the speed of light. Here we put stringent experimental bounds on the speed of all such hypothetical influences. We performed a Bell test over more than 24 hours between two villages separated by 18 km and approximately east-west oriented, with the source located precisely in the middle. We continuously observed two-photon interferences well above the Bell inequality threshold. Taking advantage of the Earth's rotation, the configuration of our experiment allowed us to determine, for any hypothetically privileged frame, a lower bound for the speed of the influence. For example, if such a privileged reference frame exists and is such that the Earth's speed in this frame is less than 10⁻³ times that of the speed of light, then the speed of the influence would have to exceed that of light by at least four orders of magnitude.

---

### Structure and chemistry of graphene oxide in liquid water from first principles [^a94f3869]. Nature Communications (2020). High credibility.

Structural properties

In the following, we analyze the structural properties of the selected semiordered and random GO configurations, first in vacuum, and then in presence of liquid water. These properties were obtained through ab AIMD at room temperature (see Supplementary Fig. 2 and the "Methods" for details). The size of the simulation box along the z -axis, perpendicular to the GO sheet, imposes the scale of confinement of the water. We chose a value (c ≃ 14.5 Å) in good agreement with the typical interlayer spacing for GO laminates that swell in water (~14 Å). Extending first the stability analysis in the presence of water, the conclusions obtained in vacuum hold true: on average the stability of semiordered GO layers compared with random GO ones is increased, from 2.4 eV in vacuum to 3.3 eV in water (see details in Supplementary Table 1). Next, we looked at four characteristic distances and angles, displayed in Fig. 2. In a nutshell, the histograms of C–C distances and theangles indicate how the original graphene layer is perturbed by the presence of chemical functions (alcohols and epoxides). Moreover, the distribution of theand theangles allows us to look at the structure of the functional groups themselves, and to see how the GO interacts with the surrounding H₂O molecules.

Fig. 2
Structural properties of graphene oxide.

Histograms of the C–C distance d C–C (a), theangle (b), and theangle (c) for semiordered (black) and random (red) graphene oxide models. Blue dashed lines correspond to the values in reference systems: d C–C = 1.42 Å in graphene, andfor epoxide. d Histogram of theangle for the GO in vacuum (dashed lines) and GO solvated in water (solid lines). e Snapshots of the different H bonds (visualized as blue dashed lines) types classified in Table 3. The atoms of each type of chemical function (hydroxyl group or epoxide) involved in the H bonds between the surface and H 2 O are highlighted in orange.

---

### An inherently infinite-dimensional quantum correlation [^d51a7298]. Nature Communications (2020). High credibility.

Bell's theorem, a landmark result in the foundations of physics, establishes that quantum mechanics is a non-local theory. It asserts, in particular, that two spatially separated, but entangled, quantum systems can be correlated in a way that cannot be mimicked by classical systems. A direct operational consequence of Bell's theorem is the existence of statistical tests which can detect the presence of entanglement. Remarkably, certain correlations not only witness entanglement, but they give quantitative bounds on the minimum dimension of quantum systems attaining them. In this work, we show that there exists a correlation which is not attainable by quantum systems of any arbitrary finite dimension, but is attained exclusively by infinite-dimensional quantum systems (such as infinite-level systems arising from quantum harmonic oscillators). This answers the long-standing open question about the existence of a finite correlation witnessing infinite entanglement.

---

### A different time for tubal surgery [^a6dd451d]. Fertility and Sterility (2019). Medium credibility.

"An object in motion tends to remain in motion along a straight line unless acted upon by an outside force". -Isaac Newton.

---

### Primary angle-closure disease preferred practice pattern ® [^75d30b97]. Ophthalmology (2021). High credibility.

Primary angle-closure disease PPP — additional methods notes specify that all studies used to form a recommendation for care are graded for strength of evidence individually and that grade is listed with the study citation, that all recommendations for care in this PPP were rated using the system described above with ratings embedded throughout the PPP main text in italics, that the Highlighted Findings and Recommendations for Care section lists points determined by the PPP Panel to be of particular importance to vision and quality of life outcomes, and that literature searches to update the PPP were undertaken in March 2019 and June 2020 in the PubMed and Cochrane databases with complete details available in Appendix 4.

---

### Just humor Me [^a54a7918]. Journal of Clinical Oncology (2024). Medium credibility.

Cancer isn't funny but sometimes a cancer clinic can be a surprisingly funny place.

---

### Distance-dependent distribution thresholding in probabilistic tractography [^c6eb381a]. Human Brain Mapping (2023). Medium credibility.

The distance between ROI pairs could be measured using different approaches. One simplest way was to compute the Euclidean distance between the centres of the ROI coordinates. Alternatively, one could use streamline length between ROIs pairs as a measure of distance. Compared to the Euclidean distance, the streamline approach could be more realistic in reflecting how the two ROIs were connected; however, the computation is more complex and sometimes there is a null connection between the ROI pairs. Here, we computed the distance between ROI pairs using both approaches and compared the results.

For each ROI pair, the Euclidean distance between the centres of the ROI coordinates was computed and rounded to the nearest integer, resulting in 87 unique distances. As there were varying numbers of connection samples for each distance, the distance values were further grouped into 26 distance bins to ensure that each had at least 1000 samples. The procedure for generating the ROI distance based on streamline length was not straightforward because the streamline length for a given ROI pair for each participant varied widely. Thus, for each participant, we first obtained all the streamlines of each of the ROI pairs in native space and projected them onto MNI space by using warpcovert and tcknormalise functions in the MRtrix3. Then, for each ROI pair, we took the average of the minimum streamline lengths across all the participants as the measure of the distance. If, in any of the participants' data, there was an absence of streamlines between the ROI pairs, it was treated as missing data and discarded from the averaging process. In this way, the streamline distance between ROI pairs was quantified by the average of minimum streamline length across participants. Again, the streamline distance was rounded to the nearest integer, resulting in 237 unique distances, and the distance values were further grouped into 26 distance bins to ensure that each had at least 1500 samples.

To generate a sampling distribution of connectivity, we adopted the Monte‐Carlo simulation technique. That was for each distance bin, we randomly drew a sample from all the candidate samples with replacement for 100,000 times, resulting in 26 distance‐dependent sampling distributions of connectivity. For each distribution, we set three alpha levels of 0.1, 0.2, and 0.3, which meant that thresholds where 10%, 20%, or 30% of the sampling distribution, respectively, were above the threshold. The same procedures were applied to generate sampling distributions of connectivity for both distance bins generated from the two distance measures.

---

### Chemical shift encoding using asymmetric readout waveforms [^4b419a89]. Magnetic Resonance in Medicine (2021). Medium credibility.

2 THEORY

2.1 Designing the asymmetric waveform

The simplest asymmetrical waveform is the asymmetric triangle, described by the durations, and slew ratesof the two segments a and b shown in Figure 1 A. The time‐to‐center, available acquisition time, and area M of the asymmetric triangle are given by the desired shift, echo spacing, and resolution, respectively. With the introduction of the auxiliary variable, the first segment durationis equal toin the case of a positive shift. The triangle amplitude is. For a negative shift, the waveform is mirrored by swapping a and b.

FIGURE 1
Asymmetric triangle (A) and spline (B) readout waveforms for chemical shift encoding. The k‐space trajectory over time is shown in (C). The time axis (x) is shared between the plots

The asymmetric triangle achieves a maximum positive shift when. Ignoring the infinite slew rate violation, a shift of onlyis achieved. This geometrical limitation causes the asymmetric triangle waveform to only be viable in sequence with long echo spacing.

To enable larger shifts, we designed a cubic spline‐based waveform, shown in Figure 1 B. As defined in the figure, the waveform is split into a trapezoidal base with amplitudeand an asymmetric component. Sampling is started atwhich is the instant at which the momentis equal to the ramp area of the corresponding trapezoidal waveform. This is also the starting point of the first spline. The presampling durationis known from the phase encoding or crusher gradient duration, whichever is longer. The base amplitude then follows as. With, the base moments are simplyand.

Three knots are located at, and, and the waveform is described by the two interval polynomials:Further, andmeet withcontinuity. In line with natural splines. Given the desired center of mass atthe following must hold:Finally, forming the exactly determined linear problem which can be written in matrix form as:

The coefficients are available in the appendix. A consequence of enforcing the second derivative ofto be zero at its endpoint is an undershoot in the waveform for positive shifts. This is avoided by calculating the waveform for a negative shift and then mirroring the result.

---

### Discovering conservation laws using optimal transport and manifold learning [^29e27d1d]. Nature Communications (2023). High credibility.

Methods

Our proposed approach uses manifold learning to identify and embed the manifold of phase space isosurfaces sampled by the trajectories of a dynamical system. In particular, we compute a diffusion map over a set of trajectories, each of which samples a particular phase space isosurface (Fig. 1 a). The pairwise distances between these trajectories are given by the 2-Wasserstein distance (Fig. 1 b), providing the metric structure necessary for applying diffusion maps (Fig. 1 c). The manifold embedding extracted by the diffusion map corresponds directly to the space of conserved quantities (Fig. 1 d). Note that this type of analysis does not require knowledge of the equations of motion (Eq. (15)) and makes no direct reference to time.

Dynamical systems

Consider a dynamical system with statesthat live in a d -dimensional phase spaceand evolve in time according to a system of first order ODEswith n conserved quantities G 1 (x), …, G n (x).

Conserved quantities and phase space isosurfaces

A conserved quantity G i (x) is a function of the system state x that does not change over time, i.e.but may vary across different initial conditions. As a result, along a particular trajectory x (t), the n conserved quantities form a set of constraintswhich depend on the values of the conserved quantities c = { c 1, c 2, …, c n }. This set of constraint equations restricts the trajectory to lie in a phase space isosurfacewith dimension d − n. In fact, if any point of a trajectory lies on the isosurface, then all other points from the trajectory will lie on the same isosurface.

By studying the variations in shape of these isosurfaces, we are able to directly characterize the space of conserved quantities. In particular, consider the manifoldformed by the isosurfacesin shape space. This manifoldis parameterized by the conserved quantities c. Therefore, by analyzingusing manifold learning, we can extract the conservation laws of the underlying dynamical system.

Note that we are using the term "manifold" here rather loosely. Whilemay be a true manifold in many cases, it is also possible forto have non-manifold structure (e.g. see our double pendulum experiment in the section "Double pendulum").

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^075005b9]. Magnetic Resonance in Medicine (2021). Medium credibility.

Regions A and B are geometrically symmetric about the z = 0 plane, with minimum energy solutions (assuming no E‐field constraint) yielding z‐symmetric field solutions and zero B 0 concomitant fields. Hence, the open diamond starting point (representing the minimum energy solution with no E‐field constraints) for the solid and dashed curves (in both black and green cases) coincide. The symmetry is broken by the addition of a patient model with an E‐field constraint.

The knee in the curves marks the point where magnetic energy, current density, and winding complexity increase rapidly as E max is driven to lower values. These complexities render unrealizable or impractical any gradient designs on the vertical portions of the curves to the left of the knee. Examination of winding patterns indicates that solutions that exhibit energy increases > 25% (or even less depending on coil type) above the global minimum energy become unrealizable (eg, demonstrating two or more "eyes" per half coil [four or more total eyes for an x or y coil] in the fingerprint wire patterns).

The red and purple dotted curves in Figure 2 represent two practical cases in which the primary coil currents are restricted to a single inner surface near the patient and the shield coil currents to an outer cylinder, while at the same time adding torque and eddy current constraints. Line segments acd of Figure 1 represent a primary winding surface consisting of a cone and a cylinder, whereas line segment ab represents its cylindrical shield winding; this yields designs similar to those proposed by previous literature 8, 22 and results in the red dotted curves in Figure 2. A second case is defined by restricting primary currents to the cylinder represented by line segment cd and shield currents to the cylinder ab; this yields designs similar to those proposed by previous literature 28 and produces the purple dotted curves in Figure 2. For both configurations, the eddy current surface is a 1‐m‐long, 620‐mm‐diameter cylinder, centered about the gradient isocenter and placed outside the shield winding of the gradient coil. The time = 0 eddy current error is constrained to a peak deviation less than 0.1% of the ideal gradient field on the surface of a 20‐cm‐diameter volume, corresponding to 100 µT for a 1 T/m step change in gradient strength. The torque constraint is set to zero for a uniform z‐directed B 0 main magnetic field. There is no net force for a perfectly uniform main B 0 field in all calculations.

---

### Can scientifically useful hypotheses be tested with correlations? [^69db0879]. The American Psychologist (2007). Low credibility.

Historically, interesting psychological theories have been phrased in terms of correlation coefficients, which are standardized covariances, and various statistics derived from them. Methodological practice over the last 40 years, however, has suggested it is necessary to transform such theories into hypotheses on covariances and statistics derived from them. This complication turns out to be unnecessary, because the methodology now exists to test hypotheses on latent structures of correlations directly. Two examples are given. Limitations of correlation structures are also noted.

---

### Social capital [^71c40d9d]. Journal of Epidemiology and Community Health (2003). Low credibility.

This glossary aims to provide readers with some of the key terms that are relevant to a consideration of the relevance of social capital for health, and to introduce some of the debates on the concepts.

---

### Urotrauma guideline 2020: AUA guideline [^8e74460d]. The Journal of Urology (2021). High credibility.

Genital trauma — penile fracture acute management: Surgeons should perform prompt surgical exploration and repair in patients with acute signs and symptoms of penile fracture (Standard; Evidence Strength: Grade B). In patients with historical and physical signs consistent with penile fracture, surgical repair should be performed. The repair is performed by exposing the injured corpus cavernosum through either a ventral midline or circumcision incision. Tunical repair is performed with absorbable suture and should be performed at the time of presentation to improve long-term patient outcomes.

---

### Hydroxymethanesulfonate formation accelerated at the air-water interface by synergistic enthalpy-entropy effects [^3aae8a55]. Nature Communications (2025). High credibility.

Fig. 3
Water-mediated proton transfer at the air-water interface.

a Variation of COM z -positions for HCHO (red line) and(purple line) as a function of the simulation time with average density along z -axis (grey region). Two black dash lines represent the outmost (z = 13.0 Å) and the subsurface (z = 10.4 Å). b Variation of the angle between the C = O direction vector and the z -axis (at θ₁, 0–180°, red line) and the dihedral angle between C = O direction vector and the S−OH direction vector (at θ₂, 0–180°, blue line) as a function of the simulation time. Shaded areas are the corresponding angles of every frame. Bold lines are the smoothed value (2000 points) to clarify the trend. c Variation of C···O (red line) and S···OH (purple dash line) distances as a function of the simulation time. Shaded areas are the corresponding distances of every frame. Bold lines are the smoothed value (500 points) to clarify the trend. d (Top) Relevant O···H distance differences (D 1 – D 7) variation as a function of the simulation time. The symbols indicate the corresponding D value at the events (i to vii). (Middle) Definition of the distance differences (D 1 – D 7). (Bottom) Schematic representation of the water-mediated proton transfer at the air-water interface. Red and blue marks represent the O and H atoms participating the proton transfer. Relevant pathway is represented as dash lines. e Snapshots of the events (i to vii) of the water-mediated proton transfer process extracted from the metadynamics-biased AIMD simulations of the heterogeneous reaction of HCHO +.

---

### Structure and inference in hypergraphs with node attributes [^df689e32]. Nature Communications (2024). High credibility.

Results

The model

We propose a probabilistic model that incorporates both the structure of a hypergraph, i.e. the interactions observed in the data, and additional attributes (or covariates) on the nodes. These two types of information, which we call structural and attribute information, have been previously shown to be informative in modeling community structure in networks, when there is correlation to be exploited –.

We denote a hypergraph as H = (V, E, A), where V = {1, …, N } is a set of nodes, E is a set of observed hyperedges whose elements e ∈ E are arbitrary sets of two or more nodes in V, and A is a vector containing the weights of edges. In this work, we assume that weights are positive and integer quantities. Denoting Ω as the set of all possible hyperedges, we have that A e is the weight of edge e when e ∈ E, otherwise A e = 0 if e ∈ Ω ⧹ E. Given these definitions, the observed edge set E can equivalently be represented as E = { e ∈ Ω ∣ A e > 0}. We represent the covariates on nodes as a matrix, where Z is the number of attributes, with entries equal to 1 if the node i has attribute z and 0 otherwise. We note that a node can have several types of covariates, e.g. gender and age, which are then one-hot encoded as attributes.

---

### A space-time tradeoff for implementing a function with master equation dynamics [^57fa10b0]. Nature Communications (2019). High credibility.

Master equations are commonly used to model the dynamics of physical systems, including systems that implement single-valued functions like a computer's update step. However, many such functions cannot be implemented by any master equation, even approximately, which raises the question of how they can occur in the real world. Here we show how any function over some "visible" states can be implemented with master equation dynamics-if the dynamics exploits additional, "hidden" states at intermediate times. We also show that any master equation implementing a function can be decomposed into a sequence of "hidden" timesteps, demarcated by changes in what state-to-state transitions have nonzero probability. In many real-world situations there is a cost both for more hidden states and for more hidden timesteps. Accordingly, we derive a "space-time" tradeoff between the number of hidden states and the number of hidden timesteps needed to implement any given function.

---

### The volume-outcome relationship: don't believe everything you see [^a17d35d5]. World Journal of Surgery (2005). Low credibility.

This paper investigates methodological limitations of the volume-outcome relationship. A brief overview of quality measurement is followed by a discussion of two important aspects of the relationship.

---

### Sources of path integration error in young and aging humans [^9805bcd2]. Nature Communications (2020). High credibility.

Within the full model, we additionally assume that the subjects' reports of estimated distance and angle to the starting point are corrupted by reporting noise –. Given an internally estimated distance d and angle φ, we assume that the reported distancesand anglesare given bywhere σ d and σ φ are standard deviations of distance and angular noise, η d is normally distributed distance noise, and η φ is normally distributed angular noise. The parameterization of the distance reporting noise is chosen such that for fixed σ d, the magnitude of the reporting errorincreases approximately linearly with d "proportional or Weber-like reporting noise", in line with Weber's law. We find empirically (see "Results" section and Fig. 3d) that this Weber's law-type parameterization of the distance reporting error captures the data better than a linear parameterization, which we refer to as "constant reporting noise" (CRN).

Participants report their location estimates only at stopping points after moving along path segments. Before we can fit our model parameters to those estimates we first need to integrate the stochastic differential equation (1) along segments, a calculation that can be performed analytically because Eq. (1) describes an Ornstein–Uhlenbeck process. Assuming that participants walk along a trajectory segment for time t with constant velocity v, the conditional distribution of the internal location estimateat the stopping point s + 1 given the estimate at the previous stopping pointis given by the Gaussian distribution:where I₂ is the two-dimensional unity matrix and mean μ s +1 and varianceare given by

This update equation for the distribution of internal estimates can also be expressed in terms of the true length |Δ x | of the trajectory segment:where we have rescaled three of the original parameters by the magnitude of the walking velocity | v |:

---

### Passive appendages generate drift through symmetry breaking [^5aec8eaa]. Nature Communications (2014). Medium credibility.

At Re = UD / ν = 200 a steady axisymmetric wakeforms behind the sphere alone (no sheet attached). Due to symmetry, the sphere neither rotates nor drifts (Fig. 7d, e). According to the IPL model and our two-dimensional investigations, we expect that by adding an appropriate protrusion to the sphere, the object will rotate and experience a non-zero transverse force. Indeed, in the presence of the elliptic sheet, we observe that after a transient time, the sphere stabilizes at a turn angle of θ = −8.5 degrees (Fig. 7d) and drifts with a constant velocity in the zx -plane with an angle of α = 4.5 degrees (Fig. 7e). We observe a zero drift in the xy -plane, that is, γ = 0.0 degrees (Fig. 7e). The drift is a consequence of the IPL instability: any small perturbation causes the sheet to move away from the straight unstable position (θ = 0) and to settle on a skewed stable angle θ s. The new equilibrium breaks the symmetry of the wake (Fig. 7b) in the zx -plane, which in turn induces a side force on the body in the z -direction, making it drift. Note that the trait of the IPL-induced movement — the direction of drift and the direction that the appendage is titled in are the same — is present. Although the chosen three-dimensional appendage triggers the IPL instability, its size and shape have not been optimized to yield maximum drift.

---

### Deep learning extends de novo protein modelling coverage of genomes using iteratively predicted structural constraints [^e75c4cde]. Nature Communications (2019). High credibility.

Model generation using CNS

CNSis used to generate models from pseudo-NOE information derived from the DMP distance distributions, H-bond maps and torsion angles. In the first iteration of DMPfold, the contact maps and H-bonding maps (asymmetric donor-acceptor pair maps) are predicted. Upper and lower distance bounds, and predicted H-bonds are converted into NOE-like constraints. For the Cβ-Cβ distances (Cα atoms for glycines), the bounds for the maximum likelihood bin is taken as the starting point. These bounds are then grown accretively to encompass neighbouring bins in order of likelihood until the total likelihood reaches a set threshold. A total likelihood threshold of 0.4 was found to be optimal, though the overall method is relatively insensitive to changes in this threshold. This method of selecting bounds means that less confident predictions result in wider bounds. Bounds are not generated for cases where the maximum likelihood bin is the unbounded last bin, and the last bin is also excluded from the likelihood accretion procedure. This means that all upper bounds provided to CNS are < 19 Å. For the binary output H-bond prediction network, a binary likelihood threshold of 0.85 was used to decide whether to consider the predicted H-bond or not. Again, although 0.85 was found to be slightly optimal, other threshold values over 0.4 perform almost equally well. The main chain H.O and N.O distance constraints input to CNS for the predicted H-bonds are fixed according to the values observed in highly resolved crystal structures.

---

### The ambiguity of names and landmarks in radiographs of the pediatric pelvis: variations and a historical perspective [^f71b74be]. Journal of the American Academy of Orthopaedic Surgeons: Global Research & Reviews (2023). Medium credibility.

For over a century, the plain radiograph has been used to measure and predict the development of pediatric hip conditions. Classic measurements, such as the acetabular index, the center-edge angle, and the migration percentage, have stood the test of time and remain the default tools for any pediatric orthopaedic surgeons. However, in contemporary research, the terminology regarding these measurements has become markedly inconsistent. A substantial number of synonyms, acronyms, and similar, but not identical, terms are used to label measurements. This is perhaps unsurprising, considering decades of use and numerous suggested modifications. The results of treatment cannot be reliably compared if the measured parameters are not identical, and scientific analysis of disease requires consistent terminology. In this review, we aim both to provide historical definitions and identification of radiographic landmarks commonly used in three parameters of interest on pediatric AP radiographs and to examine the variability of landmarks and definitions in contemporary research.

---

### Topological acoustic triple point [^bf88af26]. Nature Communications (2021). High credibility.

Acoustic phonon is a classic example of triple degeneracy point in band structure. This triple point always appears in phonon spectrum because of the Nambu-Goldstone theorem. Here, we show that this triple point can carry a topological charge [Formula: see text] that is a property of three-band systems with space-time-inversion symmetry. The charge [Formula: see text] can equivalently be characterized by the skyrmion number of the longitudinal mode, or by the Euler number of the transverse modes. We call triple points with nontrivial [Formula: see text] the topological acoustic triple point (TATP). TATP can also appear at high-symmetry momenta in phonon and spinless electron spectrums when O h or T h groups protect it. The charge [Formula: see text] constrains the nodal structure and wavefunction texture around TATP, and can induce anomalous thermal transport of phonons and orbital Hall effect of electrons. Gapless points protected by the Nambu-Goldstone theorem form a new platform to study the topology of band degeneracies.

---

### Scalable multiple whole-genome alignment and locally collinear block construction with sibeliaZ [^8ac25707]. Nature Communications (2020). High credibility.

Once we have selected the genomic walk r by which to extend p a, we must select the extensions to our collinear walks P that will form chains with p a r. This is done by the function Update-collinear-blocks (Box 2). We extend the walks to match r by considering the vertices of r consecutively, one at a time. To extend to a vertex w, we consider all the different locations of w in the input (each such location is represented by an edge x ending at w). For each location, we check if it can be reached by a b -extension from an existing p ∈ P. If yes, then we extend p, so as to lengthen the chain that it forms with p a. If there are multiple collinear walks that reach w, we take the nearest one. If no, then we start a new collinear walk using just x. Figure 6 shows an example of updating a collinear walk and Fig. 2 shows a full run of the algorithm for a single seed.

Fig. 6
Illustration for Algorithm Update-collinear-walks (Box 2).

A collinear walk p (solid) requires an update after the carrying path p a is extended with the dashed edge (w 0, w). The path p a now ends at the vertex w, which has another incoming edge x. Since x is a part of the b -extension of p (denoted by q), p can be appended with q to form a longer chain and boost the collinearity score.

Our description here only considers extending the initial seed to the right, i.e. using out-going edges in the graph. However, we also run the procedure to extend the initial seed to the left, using the incoming edges. The case is symmetric and we, therefore, omit the details.

---

### Turbulent coherent structures and early life below the kolmogorov scale [^51bdbaf6]. Nature Communications (2020). High credibility.

Division and merging

Calculating the FTLE field is quite computationally costly, and counting elliptic LCSs without fear of error would require an extremely high spatial resolution, and therefore making full evaluation of the flow properties in a simulation is a much more involved process than a full evaluation of the biological properties. Furthermore, it is easy to predict when demographic changes are not due to the biological process from this evaluation. For instance, we can assign a minimum and maximum probability to the number of birth–death events occurring within a certain timespan given the approximate population size, and can also predict the extremal probabilities of the outcome in which all (or most) such birth–death events were either birth or death. The latter is particularly easy; the likelihood of M death events in a row before a birth must be bounded above by NB(1, d /(s i + d), M), where NB(a, b, c) denotes the value of the negative binomial distribution giving the probability of c deaths before 1 birth, given that the probability of a death in a population of size n where no individual is catalyzed (hence, the situation in which the probability of death is always maximized, giving the maximal probability of M deaths before a birth) is dn /(ns i + nd). Using our standard kinetic rates, a sequence of 10–15 deaths without a birth is already an extremely unlikely event, so that a dip in the largest cluster size of 10–15 would indicate a flow-based event (division of coherent structure) with high probability. In each of 1000 simulations, we paid attention only to monotonic changes in the size of the largest cluster with absolute value bigger than 10. The statistics of these changes are plotted in Fig. 6.

Migration and diversity

For Supplementary Fig. 1, seven vortices were used and were assigned an integer label which was maintained throughout the simulations. The curves shown were generated by simulating 1000 runs per metabolism, initializing 100 of each particle species in the vortices labeled 1–3 (therefore implicitly assuming that the metabolism had experienced some reproductive success in one vortex). Simply tracking the dynamics of particles from the three original lineages over time generated the left-hand side of Fig. 7. The right-hand side was given by counting the number of components (with 10 or more particles included) in a geometric graphinduced by drawing an edge between two particles iff they were at a distance (in the Euclidean metric) < R int.

---

### The growth of the central region by acquisition of counterrotating gas in star-forming galaxies [^e24ecfba]. Nature Communications (2016). Medium credibility.

Properties of blue star-forming counter-rotators

Among nine blue counter-rotators, six of them have strong positive gradients in the 4,000 Å break (D4000), as shown in Fig. 3, while the remaining show small D4000 across the whole galaxy body, indicating young stellar populations existing in the central regions. The map of the H α flux further shows ongoing star formation in the central region. We checked the emission line ratio diagnosticto assure that the H α radiation is dominated by star formation instead of active galactic nuclei (AGN; Fig. 5). In contrast to the blue counter-rotators, all the green and red counter-rotators have negative D4000 gradients with older stellar populations in the central regions. Although the H α flux also peaks at the center for the green and red counter rotators, it is primarily contributed by the AGN based on the emission-line diagnostic.

To further quantify the importance of the ongoing star formation in growing the central region, we introduce the star formation activity parameteras α SF = 1/(sSFR × (t H (z)−1 Gyr)), where t H (z) is the Hubble time at the redshift of the galaxy, and 1 Gyr is subtracted to account for the fact that star formation mainly occurred after reionization. If a galaxy's current SFR is equal to its past average (M * /((t H (z)−1 Gyr)) then α SF = 1; values less than one indicate that the current SFR is higher than the past average. As shown in Fig. 4, all nine galaxies present a steep rising α SF with increasing distances from the galaxy center. The grey shaded regions show the ± 1 σ range of α SF for the central 1 kpc of local star forming galaxies with Δ PA < 30°. Grey lines mark the median value of ∼0.75. Focusing on the central 1 kpc, we find six of the blue counter rotators have α SF about one order of magnitude smaller than the average value (the grey line), indicating fast growth of the central components of these galaxies.

---

### Differences between ketamine's short-term and long-term effects on brain circuitry in depression [^d8349eba]. Translational Psychiatry (2019). Medium credibility.

Fig. 3
The acute (a) and delayed (b) effects of ketamine on nodal strength in the NC and PC groups.

Here we show only the statistically significant effects of treatment (nodes without asterisk) and interaction of group and treatment (nodes with asterisk) on nodal strength from two-way ANOVA test. The effect of treatment (ketamine) had same direction in the NC and PC rats, whereas the effect of interaction of group and treatment had an opposite direction (for those cases we illustrate the direction in the NC group). Sphere color represents the F -statistic values from two-way ANOVA test for effects of treatment and interaction. The presence of connections (lines) between brain regions illustrate whether there was a change in inter-nodal correlation coefficients after ketamine in the NC rats versus saline condition. See legend of Fig. 2 for the abbreviations of brain regions

Fig. 4
The acute (a) and delayed (b) effects of ketamine on nodal clustering coefficient in the NC and PC groups.

See legend of Fig. 3 for the detailed description

Ketamine had a short-lasting strain-unspecific effect on global metrics

The change in global topological properties in response to ketamine was short-lasting (Fig. 5, Table S5), with no effects sustained 48 h later. The common response in both strains, as compared to respective control groups, was an increase in clustering coefficient (treatment, F 1,45 = 16.84, p < 0.001) and path length (treatment, F 1,45 = 36.48, p < 0.001), indicating increased network segregation and decreased integration, and a decrease in small-world index (treatment, F 1,45 = 6.41, p = 0.01) and global efficiency (treatment, F 1,45 = 45.20, p < 0.001).

Fig. 5
Effect of ketamine on global and local graph analytical properties at 30 min (Δ1) and 48 h (Δ2) post injection.

The vertical bars are F-statistic values from two-way ANOVA test. Asterisk denotes significant results (p < 0.05), triangles (∇) signify results surviving false discovery rate correction (q < 0.05). cc clustering coefficient, cpl characteristic path length, Eglob global efficiency, swi small-world index

---

### A modified reverse right-angled triangle osteotomy using the lateral approach for the treatment of posttraumatic cubitus varus deformity in children [^c98160a8]. Journal of Pediatric Orthopedics (2023). Medium credibility.

FIGURE 1
Design drawing of paper simulated osteotomy before surgery (A–C). The initial osteotomy was performed 0.5 to 1 cm superior to the olecranon fossa and perpendicular to the lateral rim of the distal end of the humerus (line AB). The proximal end of the humerus osteotomy was resected with a reverse right-angled triangle so that the DAE angle was equal to the intended angle of correction. The lateral edge of the distal fragment was moved to the apex of the proximal osteotomy site. D, The distal lateral humeral marking line (solid line). DAE refers to the included angle formed by the intersection of line DA and line AE.

The patient was supine, and the affected side was abducted and placed on the abduction operation platform. The procedure was performed under general anesthesia using a tourniquet. A 4 to 6 cm longitudinal incision was made over the lateral distal humerus and the interval between the brachioradialis and triceps muscles was developed. The distal humerus was exposed circumferentially by subperiosteal dissection. First, a longitudinal marking line was marked on the lateral edge of the distal humerus with an electric motor saw for alignment of the lateral edge after osteotomy and correction of distal humeral hyperextension on the sagittal plane (Fig. 1 D). A 2.0 mm Kirschner wire (K -wire) was inserted from the lateral edge of the humerus under fluoroscopy, 0.5 to 1 cm above the olecranon fossa, and perpendicular to the lateral edge of the distal end of the humeral osteotomy (Fig. 1 A) to locate the initial osteotomy line (line AB), and then osteotomy was performed with an electric motor saw along the direction of the K -wire. Using a goniometer and scale, all lines as preoperative planned were drawn on the proximal end of the humeral osteotomy, and osteotomy cuts were made accordingly. The right-angled triangle-shaped bone was removed (Fig. 1 B) and the lateral edge of the distal fragment was moved to the apex of the proximal osteotomy site to correct the varus on the coronal plane (Fig. 1 C). According to the longitudinal marking line of the lateral edge of the distal humerus, the distal end of the humeral osteotomy was tilted forward to correct the elbow hyperextension on the sagittal plane (Fig. 1 D). The osteotomy site was cross-pinned with 1.5 to 2.0 mm K -wires (Fig. 2). Stability of the construct was confirmed by taking fluoroscopic views under valgus and varus stress. Additional K -wires or screws could be used if required according to stability. After wound closure, a long-arm cast was applied with the elbow flexed at 90 degrees and the forearm was in a neutral position.

---

### Primary angle-closure disease preferred practice pattern ® [^80c69a44]. Ophthalmology (2021). High credibility.

Primary angle-closure disease PPP — GRADE key recommendation strengths are: Strong recommendation Used when the desirable effects of an intervention clearly outweigh the undesirable effects or clearly do not; and Discretionary recommendation Used when the trade-offs are less certain — either because of low-quality evidence or because evidence suggests that desirable and undesirable effects are closely balanced.

---

### The alpha angle [^91fe6233]. The Journal of Bone and Joint Surgery: American Volume (2024). Medium credibility.

TABLE III
Grades of Recommendation

Overall, the utility of the alpha angle as a single measurement in today's hip preservation practice is unclear. A single angle is likely inadequate to capture a complex 3D and dynamic pathologic process, and the methods for measuring this angle are rife with imprecision and variable reliability. That being said, the alpha angle is still the most commonly used and reported method for quantifying cam deformity. Also, it is important to correlate preoperative localization of the maximal alpha angle with direct intraoperative visualization of the lesion, as this can help to prevent under-resection. Although the alpha angle may continue to play a role in the diagnosis and management of FAI, the path forward will likely include much more 3D standardization, automation, and dynamic assessment of these measurements.

---

### Calcipotriene, dimethicone (nuDermRxPAK 60) [^fcb24f8c]. FDA (2021). Medium credibility.

Questions

Questions?

Call 1-800-777-4908

---

### MRNA recognition and packaging by the human transcription-export complex [^6599aae8]. Nature (2023). Excellent credibility.

TREX–TREX distance and orientation measurements

We measured for each pair the TREX–TREX distance, using the centrally located residue THOC5-K516 as reference points for the measurement. To express relative orientations of two copies of TREX (TREXA and TREXB) bound to the same mRNP, we calculated rotation matrixes that align TREX B with TREX A using the ChimeraX align command. Given the C2 symmetry of TREX which results in two equivalent ways to achieve the same alignment, we first measured pairwise distance of symmetry related copies of THOC1 between the two TREX copies TREX A and TREX B (distances from THOC1 TREXA to THOCP TREXB, THOC1 TREXA to THOC1 TREXB, THOC1 2TREXA to THOC1 TREXB, THOC1 TREXA to THOC1 TREXB) and then aligned the copies of THOC1 that where closest to each other. The obtained rotation matrices were converted to Euler angles (using the convention of intrinsic, right-handed rotations around the axis X, Y and Z) with the python package eulerangles (A. Burt). As a result, each of the 275 identified TREX pairs was annotated with their center-to-center distance and their relative orientation to another expressed in Euler angles.

Plotting of TREX–TREX orientations

In order to visualize the TREX–TREX orientation distribution in our dataset, we reduced our four-dimensional data (three angles and one distance measurement) to two dimensions using the t-Distributed Stochastic Neighbor Embedding (t-SNE)dimensionality reduction approach implemented in the R package Rtsne. To generate the heatmaps of TREX–TREX vector angles (Extended Data Fig. 10c), TREX–TREX vectors (expressed in cartesian format in the rotation matrix obtained through the ChimeraX align command) were converted to spherical coordinates using s custom python script and the angles were plotted using R and ggplot.

---

### Translational diffusion of hydration water correlates with functional motions in folded and intrinsically disordered proteins [^73169df1]. Nature Communications (2015). Medium credibility.

The water dynamics in our powder models were validated by comparing the computed and experimental water MSDs as a function of temperature, as shown in Supplementary Fig. 7. The temperature dependence of the MSD from the simulations agrees well with the experimental data, although the absolute values are different for reasons discussed in the Supplementary Information.

Two measures of protein–water HB relaxation rates were considered, to discriminate between fast (~ps) HB formation/breakage (characterized by the 'continuous' HB relaxation time τ HBC) due to water rotational/librational motion and the slower (> 10 ps) relaxation of the protein–water HB network (characterized by the 'intermittent' HB relaxation time τ HBI) due to diffusion of water on the protein surface or exchange of water molecules between hydration shells. τ HBC is defined by the decay of the time correlation function S HB (t) = ‹h(0)H(t)›/‹h› (ref.) and τ HBI by the decay of C HB (t) = ‹h(0)h(t)›/‹h› (ref.), where h (t) is equal to 1 if a given donor–acceptor (D–A) pair is hydrogen bonded at time t and zero otherwise, h(t) is equal to 1 if the D–A HB remains intact continuously from time 0 to time t and zero otherwise, and the angular brackets denote an average over all D–A pairs and time origins. The relaxation times τ_HBC and τ_HBI were defined as the times at which S_HB(t) and C_HB(t) decay, respectively, to [1/e]. When the C_HB(t) did not decay to [1/e] within 4 ns, they were fitted with a stretched exponential and extrapolated to 1/ e.

For the calculation of the correlation functions C HB (t) and S HB (t), a D–A pair was considered to be hydrogen bonded when the distance D–A was < 3.5 Å and the D–H–A angle was greater than 150°. Although the values of the HB lifetimes (τ HBC) at a given temperature depend on the details of the criterion used to define HBs, previous work on bulk water suggests that the definition is not expected to affect the qualitative temperature dependence of the lifetimes.

---

### Elastocapillary cleaning of twisted bilayer graphene interfaces [^45308e49]. Nature Communications (2021). High credibility.

Fig. 4
Coalescence of nanopockets.

a The initial configurations of nanopockets-A and -B. AFM deflection images of two neighboring nanopockets on tBLG (twist angle) without pretension, where the AFM tip sweeps on the graphene surface horizontally while moving from the bottom to the top. The black arrows correspond to the direction of the mechanical stimuli. The white dashed circle and the white arrow indicate the initial location and moving direction of nanopocket-B, respectively. The blue dashed line is taken through the centers of the two nanopockets. b The configurations of nanopockets -A and -B after the first mechanical stimulus. c The configuration of nanopocket-A+B after the second mechanical stimulus. d The effective contact angles were measured from the height profiles of 18 neighboring nanopockets with (red circle markers) and without (blue square markers) pretension. The inset shows the height profile of nanopockets-A and -B along the blue dashed line in a, where the effective contact angles (and) are calculated from the linear fitting of the edges of the height profile. The solid line here corresponds to the inner-side and outer-side effective contact angles being equal. For each nanopocket, the contact angles were taken along three directions, from which the average values ofandas well as x(y)-error bars were determined. e – g AFM deflection images of two neighboring nanopockets on tBLG with ~1% pretension, where the implications of the arrows and circle are the same with a – c. h The effective contact angles (and) measured from the height profiles of 13 single nanopockets with (red triangle markers) and without (blue rhombus markers) pretension. The inset shows the height profile of nanopocket-A+B along the red dashed line in c. Again, the solid line corresponds to the left-side and right-side effective contact angles being equal. For each nanopocket, the contact angles were taken along three directions, from which the average values ofandas well as x(y)-error bars were determined. Scale bars: 100 nm.

---

### The alpha angle [^14d4117b]. The Journal of Bone and Joint Surgery: American Volume (2024). Medium credibility.

Reliability

Numerous studies examining alpha angle calculations on different radiographic views have reported good-to-excellent interobserver and intraobserver reliability,- (Table II). Agricola et al. combined 2 large prospective studies, examining nearly 3,000 hips in > 2,000 individuals. They reported a kappa value of up to 0.99 for intraobserver reliability and of 0.89 for interobserver reliability on anteroposterior pelvic radiographs.

Clohisy et al. reported a poorer intraobserver reliability for an anteroposterior view (ICC, 0.60) when compared with a frog-leg lateral view (ICC, 0.74) and a cross-table lateral view (ICC, 0.73). Meyer et al. reported that 45° and 90° Dunn views outperformed anteroposterior and cross-table lateral views in terms of reliability. Odri et al. compared alpha angles calculated on radiographs and CT scans and reported a correlation coefficient of 0.73 and 0.8 for the 2 observers. They also demonstrated good intraobserver and interobserver reliabilities for alpha angles calculated on radiographs in the PIP.

---

### The myth of the equiangular triangle for identification of sacral hiatus in children disproved by ultrasonography [^69ff041b]. Regional Anesthesia and Pain Medicine (2013). Low credibility.

Background and Objectives

A triangle formed by the sacral hiatus and posterior superior iliac spines (PSISs) has been known as equiangular and has been proposed as a way to help identify the sacral hiatus for a caudal block. In children, however, no feasibility study of this triangle has been performed. We compared the expected sacral hiatus obtained from the equiangular triangle method and the real sacral hiatus confirmed by ultrasound.

Methods

Eighty children (aged 0.5–72 months) were placed in the left lateral decubitus position in full hip flexion. The vertex of an equiangular triangle formed inferior to PSISs was considered as the expected sacral hiatus by classic bony landmarks. The real sacral hiatus was identified by ultrasound. The angle formed by the 2 lines connecting each PSIS and the real sacral hiatus (angle θ) was also measured. The distances between the midpoint of PSISs and expected sacral hiatus (distance E) and real sacral hiatus (distance R) were measured and compared.

Results

The angle θ was greater than 60 degrees in all children (79.3 [9.3] degrees) and negatively correlated with age younger than 1 year. Distance R (3.5 [1.1] cm) was significantly shorter than distance E (4.9 [1.2] cm) (P < 0.001). The distance R positively correlated with age, weight, height, and the distance between the PSISs.

Conclusions

In children, using the equiangular triangle to identify the sacral hiatus may be inappropriate because the actual triangle formed by the sacral hiatus and PSISs is not equiangular.

---

### The expected behaviour of random fields in high dimensions: contradictions in the results of bansal and peterson [^657f9d59]. Magnetic Resonance Imaging (2022). Medium credibility.

Bansal and Peterson (2018) found that in simple stationary Gaussian simulations Random Field Theory incorrectly estimates the number of clusters of a Gaussian field that lie above a threshold. Their results contradict the existing literature and appear to have arisen due to errors in their code. Using reproducible code we demonstrate that in their simulations Random Field Theory correctly predicts the expected number of clusters and therefore that many of their results are invalid.

---

### Ultra-high dynamic range quantum measurement retaining its sensitivity [^99260d12]. Nature Communications (2021). High credibility.

For our algorithm, we optimise the relative number of iterations at each measurement time to minimise the uncertainty. The result for this measurement-time-wise optimisation is plotted in Fig. 3b. This shows that the longer T meas, the closer the sensitivity gets to its ultimate limit, where the scaling approaches. At the steep region of this optimum, the scaling is.

When we look at Fig. 3c, which depicts the relative number of iterations, we can understand how our algorithm works. For very short T meas, all measurement time is allotted to the smallest area, since the larger areas are at their maximum uncertainty and hence cannot contribute. But for longer T meas, at some time the next area becomes relevant and thus turns on, since it can receive sufficient measurement time to lower σ B below its maximum uncertainty. This continues until the largest area turns on, which then keeps increasing in relative importance, at which point the scaling of the uncertainty is about. Thus for longer T meas, the largest area receives increasingly more relative measurement time, meaning the uncertainty continuously approaches this ultimate uncertainty, as plotted by the green dashed line in Fig. 3c.

If we would increase the number of areas in the sequence, the uncertainty becomes steeper during the turning-on region (which is the steep region). Figure 3d plots the result for a large amount of areas, indicating that the uncertainty scales asup to nearby the largest area. The scaling follows from the quadratic dependence of the area on the subsequence length (see Fig. 1c). Since closer to the largest area, this is not quadratic yet, it becomes less steep (lowest yellow crosses in Fig. 3d). The decay in coherence due to the finite T₂ negatively effects the uncertainty as well in this region, further decreasing the steepness. Analogue for DC measurements, the uncertainty scales asin the steep region. Supplementary Note 3 discusses scaling in more detail beyond the indication given here. When taking any overhead time into account, the effective measurement time decreases, thus the curves would become even steeper.