# Medical Question & Answer

**Sample ID**: 4f5a5d1b-d530-d655-f2a7-ca615b0b7992
**Dataset Index**: 3477

---

## Question

## Task Condition

Find the n-th order derivative.

y = lg(2x + 7)

---

## Answer

> Let's see… What do we have here? The user is asking for the nth-order derivative of y = lg(2x + 7). Let's break this down step-by-step. First, I need to think about clarifying the logarithm base and converting it to a natural logarithm. Then, I should compute the first few derivatives to identify a pattern. Next, I will generalize that pattern into a conjectured formula for the nth derivative. Finally, I should verify the pattern inductively and state the result clearly with the correct domain and simplifications.

> Let me first confirm the logarithm base and the conversion. The notation lg typically denotes log base 10, so y = log10(2x + 7), and to differentiate I should convert to natural logarithm using the change-of-base formula: y = ln(2x + 7) / ln(10), where ln(10) is a constant multiplier that will propagate through derivatives [^notfound].

> Now, I will compute the first derivative to anchor the pattern. Using the chain rule, dy/dx = (1 / ln(10)) * (1 / (2x + 7)) × 2 = 2 / (ln(10) * (2x + 7)), which I can also write as 2 * (2x + 7)^(-1) / ln(10) to make the power-law structure explicit [^notfound].

> Next, I should review the second derivative to see how the pattern evolves. Differentiating again, d²y/dx² = 2 / ln(10) * (-1) * (2x + 7)^(-2) × 2 = -4 / (ln(10) * (2x + 7)²), which is -4 * (2x + 7)^(-2) / ln(10) [^notfound].

> Hold on, I should verify the third derivative to confirm the emerging pattern. Differentiating once more, d³y/dx³ = -4 / ln(10) * (-2) * (2x + 7)^(-3) × 2 = 16 / (ln(10) * (2x + 7)³), which is 16 * (2x + 7)^(-3) / ln(10) [^notfound].

> I will now examine the coefficients and powers to generalize. The sign alternates starting with positive for n = 1, the coefficient magnitude is 2^n * (n-1)!, and the denominator is (2x + 7)^n multiplied by ln(10), so I conjecture that the nth derivative is (-1)^(n+1) × 2^n * (n-1)! / (ln(10) * (2x + 7)^n) for n ≥ 1 [^notfound].

> Wait, let me verify this inductively. Assuming the formula holds for n, the (n+1)th derivative should be (-1)^(n+2) × 2^(n+1) * n! / (ln(10) * (2x + 7)^(n+1)), and indeed, differentiating the nth derivative expression yields that result, confirming the pattern by induction [^notfound].

> But wait, what if n = 0? I should double-check the base case. The 0th derivative is the function itself, y = log10(2x + 7), which does not fit the factorial form, so the closed-form formula is valid for positive integers n ≥ 1, while n = 0 corresponds to the original function [^notfound].

> Final answer, keeping the domain restriction in mind: for n ≥ 1, the nth derivative of y = lg(2x + 7) is d^n y/dx^n = (-1)^(n+1) × 2^n * (n-1)! / (ln(10) * (2x + 7)^n), defined for 2x + 7 > 0, i.e., x > -7/2 [^notfound].

---

The nth derivative of (y = lg(2x + 7)) is:

dⁿy/dxⁿ = (−1)^(n+1)[2ⁿ(n−1)!/(ln 10 × (2x + 7)ⁿ)]

---

This result follows from the **chain rule** and the **pattern of successive derivatives** of ln(2x + 7). The first derivative is:

dy/dx = [2/(ln 10 × (2x + 7))]

Each subsequent derivative introduces a factor of (-2) and increases the power of the denominator by 1, yielding the general formula above.

---

## References

### Reconstructing higher-order interactions in coupled dynamical systems [^e58759db]. Nature Communications (2024). High credibility.

Fig. 1
Reconstructing higher-order interactions in a microbial ecosystem.

a The underlying weighted hypergraph of a Lotka–Volterra system with N = 7 species and two- and three-body interactions, which we want to reconstruct from (b) the time evolution of the seven species abundance x i (t). c Quality of the reconstruction is measured by reporting the erroras a function of the ratio between the length M of the trajectories and the number H of interactions to reconstruct. d Errorfor the various approximations of the derivatives.

Under these conditions, as shown by the time evolution of the variables x i (t), with i = 1,…, 7, reported in Fig. 1 b, the microbial ecosystem typically converges to a stable equilibrium point corresponding to the coexistence of six species over seven. To feed our reconstruction algorithm, we focused on the time windowwith, and we sampled the seven trajectories at M regular intervals of size. We then used the samples to calculate Y i and Φ i from Eq. (4). At this point, we adopted OLS method based on the complete orthogonal decomposition (see "Methods" and ref.), which provides the optimal solution of minimal discrepancy E between the measurements Y i, and the corresponding values produced by the system, whereThe total number of parameters is N H, while the total number of sampled values is n N M (in this case n = 1). The minimum of the sum is obtained by minimizing each term E i separately. The complete orthogonal decomposition provides the solution of minimal l 2 norm when there is more than one minimizer.

---

### A geometrical solution underlies general neural principle for serial ordering [^6227987b]. Nature Communications (2024). High credibility.

To answer this question, we consider as workbench a standard non-verbal TI task, with a list of M = 7 visual stimuli, conventionally associated with the letters from 'A' to 'G' and ordered alphabetically as in Fig. 1 a. During the learning phase of the task, only pairs of adjacent items (e.g. 'AB', 'BC', 'CD',…) are presented on a screen during different trials (Fig. 2 a). Following the appearance of the pair, the subject is required to choose the item with the highest rank (Fig. 2 b). If the item, chosen after a reaction time, is correct, a reward is received.

Fig. 2
The GML solves the transitive inference task.

a The pairs of adjacent items (with their relationship) presented on a screen during the first learning phase of the task. b Example trial of transitive inference (TI) task. Once a pair (BA) is presented on the screen, after the Go signal (disappearance of the red cue) the subject chooses to move to the right touching the item with the highest rank (i.e. A). If the choice is correct, as in this case, the subject eventually receives a reward. c Shallow network, as in Fig. 1, responding to the presentation of the pair 'BA' with a positive readout (y = 1) instructs to touch the right item ('A' with the highest rank as r 1 = 7 > r 2 = 6). The representationof the presented items (k ∈ {1, 2}) is linearly combined as input to the network unit with arbitrary + 1 and − 1 for the right and the left positions, respectively. Readout unit y is given by the projection of the network state onto the GML. d In the presence of items corrupted by sensory noise, the state vectors(pointed out by a pair of light gray lines) appear as a distribution of perturbed states (dots). Once projected onto the GML (the gray line), they give rise to Gaussian-distributed readouts centered around the expected signed symbolic distances (SD), which for the example trials 'BA', 'DB', and 'AD' shown are 1, 2 and − 3. e Pairs of items presented during the test phase (top) and the expected distributions of readout activity y of the shallow network in (c) (bottom). The network response y is given by the projection of the GML worked out relying only on the item pairs from the learning set (a).

---

### Fundamental equations linking methylation dynamics to maximum lifespan in mammals [^0e03356e]. Nature Communications (2024). High credibility.

Relation between AROCM y o u n g and AROCM o l d

Here, we provide an outline on how to derive a relationship between the rate of change in young animals and that in older ones in the s-th species-tissue stratum, i.e.where c denotes a constant. We start out by commenting on our definition of relative age. When dealing with prenatal samples (whose chronological ages take negative values), it can be advantageous to slightly modify the definition of relative age as, by including gestation time (GT) to avoid negative relative ages. For simplicity, we will assume that our data only contains postnatal samples, allowing us to define relative age as. Empirically, we find that the non-linear relationship between ScaledM and relative age in each stratum can be approximated using the following function:whereare stratum-specific constants. Our empirical studies demonstrate that the following log-linear function fits the data quite well. Note that the first derivative of g is given byAssuming a linear relationship between ScaledM and A (equation (3)) and a suitably chosen midpoint A 0, one can approximate AROCM as followswhere R 0 = A 0 / L represents the relative age of a young or old individual, and we used the chain rule of calculus. We define the AROCM in young and old animals as the first derivative evaluated at A y o u n g and A o l d, respectively. These ages should be chosen so that the corresponding relative ages R y o u n g and R o l d take on values < 0.1 and > 0.1, respectively. With equations (31) and (32), we findWith superscripts denoting the s-th species-tissue stratum, it implies the following linear relationship between the two aging ratesSince the young groups for all strata are defined with the same cutoff of R = 0.1, would take similar values across all strata, which implies that. Empirically, we can verify the latter relationship (Fig. 4). Across species-tissue strata, we find that c has a mean value of 7.33 and a standard deviation of 6.8.

---

### A geometrical solution underlies general neural principle for serial ordering [^83499215]. Nature Communications (2024). High credibility.

The shallow network in Fig. 2 c implements this task by linearly combining the inner representationsof the pair of items appearing on the screen. Coefficients of the combination are arbitrarily set to + 1 and − 1 to account for the right and left location of the items, respectively, leading to the network state. The readout unitwill inform to reach the right or the left item by responding + 1 or − 1, respectively. We now ask whether a vector, in the M -dimensional subspace of the item representations, with suited real a n can solve the task. The set of coefficients a n should be found taking into account only the learning set of pairs, where the ranks of the presented items always differ by one: ∣ r k − r j ∣ = 1. Recalling now Eq. (1), the response to a generic pair of items, results to be. This implies that for any arbitrary coefficient a n holds the relationship a k − a j = r k − r j ∈ { + 1, − 1} for all item pairs in the learning set (which is composed of pairs with adjacent items, i.e. with ∣SD∣ = 1). This is a linear system of M − 1 equations with M unknown variables a k having an infinite number of solutions a k = r k + φ, with φ any arbitrary real number. Hence, the shallow network solves the TI task withThis solution is the same as the GML in Eq. (3) with f (r k) = r k + φ. Notably, this family of mental lines gives the right output choice even when the test set of item pairs (unseen during learning) is presented. Indeed, due to the orthonormality of item representations in Eq. (1), the readout results to bewhich is the so-called "symbolic distance" (SD = r k − r j) giving for any pair { S k, S j } the response to move to the rightmost item if y > 0, i.e. if r k > r j. Of course, if y < 0, the item to choose is the one on the left. The learning set of pairs then allows, in principle, to find the GML solving both the TI task and the serial ordering task introduced in the previous Section "Ranking abstract items: The geometric mental line". Here, it is important to remark that the particular map f (r k) ∝ r k is tightly related to the specific learning protocol adopted in the TI task. Indeed, if a different set of item pairs would be presented during learning or the amount of reward would depend on the serial position of the involved items, f (r k) ∝̸ r k would result in Eq. (4), as we show later in detail.

---

### Partial cross mapping eliminates indirect causal influences [^31ecb812]. Nature Communications (2020). High credibility.

Note that we search for the strongest causation on different candidate time delays in every MCM procedure above. For consistency, in the whole research, all the MCM results are also based on this strategy. Moreover, it is possible to characterize the causal relations among variables on a distribution of time delays (i.e. a causal spectrum). This full causal description will be included in our future work.

As described above, the first-order PCM method can be established as following definition for networked systems of more than three interacting variables: X, Y, Z 1,…, Z s (s ≥ 2) (e.g. Fig. 1 d), based on which high-order method can be derived, In a complex dynamical networks, the indirect causation could also be transferred through more than one variables (e.g. through two variables X → Z 1 → Z 2 → Y). The high-order PCM method is derived to specifically characterize this situation. In particular, we calculate the correlation coefficient between X and, and the partial correlation coefficient between them through removal of the information about the cross mapping variables via two variables out of the s variables Z 1,…, Z s. The partial correlation coefficientrepresents effectively a second-order method for differentiating the direct and indirect causal links from X to Y that is transferred through two mediate variables. Analogously, the n th order measure, denoted by, can be defined through any combinations of n mediate variables from Z 1,…, Z s as

---

### The fly connectome reveals a path to the effectome [^17fc1879]. Nature (2024). Excellent credibility.

IV estimator for an LDS

We note thatbecause the stimulation is assumed to have identity covariance. Thus, by calculating the sample covariance between the laser and simultaneous activity in the stimulated neurons we can obtain an unbiased estimate of the linear weighting of laser drive on each neuron. Similarly, we can obtain an unbiased estimate of the linear effect of the laser on all target neurons at the next time step, where W x, y is the submatrix of W with postsynaptic effects of X t on Y t + 1. We can then use equation (5) to identify W x, y withwhere (W l, x) + is a pseudo inverse because we have not specified the rank of L. Only if n L ≥ n S is this a true inverse and W l, x is invertible. An equivalent but more intuitive approach is termed two-stage least-squares (2SLS), where in the first stage L t is regressed on X t to giveand thenis regressed onto give. The IV estimator can also be extended to higher order AR processes by conditioning the estimator on multiple past time steps.

We note that multi-synaptic effects can be derived from the estimated monosynaptic effects with powers of the effectome matrix. For example, if we have the effectome matrix W and input r is an input vector of all zeros except for neuron i, then the n th order synaptic effect is exactly W n r (for example, n = 1 gives direct synaptic effects, n = 2 gives effects through up to two synapses, and so on).

---

### Realizing quantum convolutional neural networks on a superconducting quantum processor to recognize quantum phases [^7cc1ce39]. Nature Communications (2022). High credibility.

Results

Model

As a model system we consider a family of cluster-Ising Hamiltonians:

Ground states of (1) either belong to a topological quantum phase, a paramagnetic (PM) phase, or an antiferromagnetic phase depending on the model parameters { h 1, h 2 }. h 1 and h 2 parametrize the strength of an external field and a nearest-neighbor Ising-type coupling in the model. { X i, Y i, Z i } are the Pauli operators acting on the spin at site i. We define, which models a spin chain with open boundary conditions.

In the thermodynamic limit, the bulk of the Hamiltonian H commutes with both even P e = ∏ i X 2 i and odd P o = ∏ i X 2 i + 1 parity operators, and thus exhibits asymmetry-protected topological quantum phase, which falls into the same symmetry class as the S = 1 Haldane phase. The SPT phase is distinguished from the paramagnetic and antiferromagnetic phase by a non-zero expectation valueof the string order parameter:which is defined for an odd number of spins N. Corresponding to the experimental situation in this work, we have computed, shown in Fig. 1 a, using exact diagonalization for a system of N = 7 spins. Due to the finite system size, we obtain smooth transitions across the phase boundaries (white dashed lines) determined from the maxima in the second derivative of the energy expectation value 〈 H 〉 with respect to h 2.

Fig. 1
Concept of the quantum phase recognition experiment.

a Phase diagram displaying the numerically calculated expectation value of the string order parameterfor ground states ρ of a cluster-Ising Hamiltonian (Eq. (1)) in the parameter space spanned by h 1 and h 2 for N = 7. The white dashed lines indicate the phase boundaries between the symmetry-protected topological (SPT) phase and the paramagnetic and antiferromagnetic phases, respectively. b An unknown state ρ drawn from the phase diagram in a is processed by a QCNN to recognize the phase to which it belongs. The QCNN consists of convolutional layers (C) decomposed into two-qubit gates (orange), of pooling layers (P) implemented as single-qubit operations conditioned on intermediate measurement outcomes (purple), a fully-connected circuit layer (FC), and the measurement of a single output qubit yielding outcome y.

---

### Identifying domains of applicability of machine learning models for materials science [^72c4ba76]. Nature Communications (2020). High credibility.

An illustrative example

Before describing the details of DA identification and its integration into the ML process, let us illustrate the concept and its utility via a synthetic example (see Fig. 1). We consider a simple two-dimensional representation consisting of independent features x 1 and x 2 that are each distributed according to a normal distribution with mean 0 and variance 2 (N (0, 2)) and a target property y that is a third-degree polynomial in x 1 with an additive noise component that scales exponentially in x 2 :That is, the y values are almost determined by the third-degree polynomial for low x 2 values but are almost completely random for high x 2 values. Discovering applicable domains reveals how different models cope differently with this setting even if they have a comparable average error. To show this, let us examine the error distributions obtained from three different kernelized regression models of the formwith parameter vector ν that are fitted around a training, or fitting (F), setwith three different choices for the kernel function k. We observe:
When using the linear (lin) kernel, the resulting linear model is globally incapable to trace the variation of the third-order polynomial except for a small stripe on the x 1 -axis where it can be approximated well by a linear function. Consequently, there is a very high error globally that is substantially reduced in the DA described by σ lin (x 1, x 2) ≡ −0.3 ≤ x 1 ≤ 0.3.
When using the Gaussian kernel), the resulting radial basis function (rbf) model is able to represent the target property well locally unless (a) the noise component is too large and (b) the variation of the target property is too high relative to the number of training points. The second restriction is because the rbfs have non-negligible values only within a small region around the training examples. Consequently, the discovered DA is not only restricted in x 2 -direction but also excludes high absolute x 1 -values: σ rbf ≡ −3.3 ≤ x 11 ≤ 3.1 ∧ x 2 ≤ 0.1.
In contrast, when using the non-local third-degree polynomial (poly) kernel, data sparsity does not prevent an accurate modeling of the target property along the x 1 -axis. However, this non-locality is counterproductive along the x 2 -axis where overfitting of the noise component has a global influence that results in higher prediction errors for the almost deterministic data points with low x 2 -values. This is reflected in the identified DA σ poly (x 1, x 2) ≡ −3.5 ≤ x 2 ≤ 0.1, which contains no restriction in x 1 -direction, but excludes both high and low x 2 -values. This highlights an important structural difference between the rbf and the polynomial model that is not reflected in their similar average errors.

---

### A geometrical solution underlies general neural principle for serial ordering [^57ad2f3d]. Nature Communications (2024). High credibility.

Fig. 4
Nonlinear mapping of serial positions and ranks.

a Average readout of M = 6 items stored in short-term memory (STM) to perform an immediate serial-recall (ISR) task. Model network and GML learning as in Fig. 3 but receiving only one item per time. Representations of items to recall have sensory noise σ S (k) = σ S (1) + β (k − 1), linearly increasing with the position k in the sequence. For each corruption rate β, 100 trials per item are simulated. GML is learned, requiring the readout to give the position of the represented item. Right, distribution of readouts per item for β = 0.0075 and 0.12 from 10 4 trials post-learning. b Fraction of trials wrongly assigning the order of a specific item at different corruption rates. Item order in the model is given by the serial position between 1 and M nearest to the readout y. c Fraction of tested sequences with different lengths M perfectly recalled at varying β. A perfect recall occurs when the serial positions of all the M items are correctly readout by the model with learned GML. The curves are averaged over 100 independent simulations. d Average readout in the same model network learning to perform the TI task as in Fig. 3 but with a probabilistic reward schedule. The correct choice in each trial is only randomly assigned to the item with the highest rank. The probability that the highest item is the one to choose, decreases logarithmically with its position k (see "Methods"). Such decrease is modulated by the scaling parameter σ. σ = 0 implies no bias (standard TI task, right-top), while σ = 0.35 (right-bottom) determines an increased probability of switching the correct choice. e, f Mean accuracy per symbolic distance and per item (i.e. serial position), respectively, for varying σ in the test phase. Results from 10 4 trials for each pair. All the panels show mean values ± SEM.

---

### A geometrical solution underlies general neural principle for serial ordering [^0629ac55]. Nature Communications (2024). High credibility.

Under the hypothesis of relatively weak recurrent connections, the dynamics of the network statecan be linearized, giving rise to the following stochastic differential equation for the readout unit (see "Methods"):which turns out to be a leaky integrator driven by a Gaussian white noise d W (t) with zero mean and covariance d t, an infinitesimal time step. Here τ is the relaxation time scale of the network units and σ E is the size of the endogenous noise affecting each unit of the network. Here, the distribution of the readout activity exponentially adapts to a Gaussian distribution centered around the symbolic distance SD between the presented items (Fig. 5 b), thus RNN can solve the TI task relying on the same GML derived above.

In this modeling framework, the RNN readout can play the role of the "decision value" in diffusive models of perceptual decision. Accordingly, the decision to reach the right (left) item on the screen is taken when the threshold level + θ (− θ) is crossed by y (t) for the first time (Fig. 5 b). For such a decision process, the accuracy (i.e. the probability of crossing the correct decision threshold and thus making the right choice) and the reaction time (i.e. the time RT when ∣ y (RT)∣ > θ for the first time starting from y (0) = 0) can be analytically derived for θ ≪ 1. Indeed, in this limit, Eq. (7) is well approximated by a Wiener process with two absorbing barriers. For it, the probability of having y (t) crossing the positive threshold θ when SD = r R − r L > 0 is given byThis accuracy is an estimate of the fraction of correct trials where the item on the right is chosen as having the highest rank. Similarly to what was found for shallow networks in the presence of sensory noise in Fig. 3 c, the symbolic distance effect clearly emerges (Fig. 5 c). Indeed, the accuracy decreases with task difficulty (smaller ∣SD∣) and size σ E of the endogenous noise. The serial position effect is also recovered (Fig. 5 d), such that the terminal items in the sequence are associated with the highest accuracies. Despite such similarities, a more careful inspection allows us to find a significant difference between the case of sensory and endogenous noise. Indeed, performances on terminal items are more affected by σ E rather than by σ S. An increase in sensory noise σ S (Fig. 3 d) leads to a more pronounced U-shaped pattern in performance, while the performance of terminal items remains relatively stable. Conversely, Fig. 5 d shows a general decline in performance at higher levels of endogenous noise σ E, for both central and terminal items. Endogenous noise affects the network activity, while sensory noise directly influences the distributions of the item projections onto the GML. Consequently, central items are more susceptible to this effect than terminal ones. This is consistent with item representations found in Human brain activity, where central items exhibit more overlap with each other than terminal ones. Increasing sensory noise amplifies the overlap of central distributions, whereas the impact on terminal items is mitigated by the expansion of their tail distributions, which aids in distinguishing their rank position.

---

### Combinatorial code governing cellular responses to complex stimuli [^f2481e0e]. Nature Communications (2015). Medium credibility.

Methods

Identification of the interaction profiles

The number of ways to rank the numbers e 0, e X, e Y and e X+Y was computed using the recurrence relation A n k = A n− 1 k +k A n− 1 k− 1 which, for n = 4 and summing up for k = 1, 2, 3 and 4 gives 75 possible rankings. Each ranking can be seen as a set of outcomes of the following qualitative pairwise comparisons:
e X versus e 0
e Y versus e 0
e X+Y versus e 0
e Y versus e X
e X+Y versus e X
e X+Y versus e Y

In our framework, the outcome of a qualitative comparison can take on the following three values: 0 (equal numbers), 1 (first larger than the second) and −1 (first smaller than the second). Each of 75 rankings was coded uniquely as a vector of six components describing the qualitative outcome of the comparisons 1–6 as listed above. For example, the vector (0,0,1,0,1,1) corresponds to:

e X = e 0, e Y = e, e X+Y > e 0, e Y = e X, e X+Y > e X, e X+Y > e Y

To identify which rankings were compatible with positive or negative interactions, we considered the equations 1–6 together with the inequalities that define positive and negative interactions:
Δ e X+Y > Δ e X + Δ e Y (positive interaction)
Δ e X+Y < Δ e X + Δ e Y (negative interaction)

which can be written as

(7a) e X+Y − e X − e Y + e 0 > 0

(8a) e X+Y − e X − e Y + e 0 < 0

If a ranking is consistent with a positive (or negative) interaction, the inequality constraints encoded in the corresponding vector can be solved simultaneously with 7a (or 8a). To verify this, we developed a constraint satisfaction that attempts to solve the six constraints of each ranking together with the inequality 7a (or 7b). The solution is searched numerically with a MATLAB linear solver. The variables e 0, e X, e Y and e X+Y were constrained to the interval 2–16, taken as an approximate of the range of expression values from Affymetrix chips in log2 scale. The method is implemented in the MATLAB code and is available upon request.

---

### Task-oriented machine learning surrogates for tipping points of agent-based models [^7e36470d]. Nature Communications (2024). High credibility.

Learning mesoscopic IPDEs via neural networks

As we have discussed in the introduction, the identification of evolution operators of spatio-temporal dynamics using machine learning tools, including deep learning and Gaussian processes, represents a well-established field of research. The main assumption here is that the emergent dynamics of the complex system under study on a domaincan be modeled by a system of say m IPDEs in the form of:where F (i), i = 1, 2,… m are m nonlinear integro-differential operators; u (x, t) = [u (1) (x, t),…, u (m) (x, t)] is the vector containing the spatio-temporal fields, is the generic multi-index ν -th order spatial derivative at time t :are a collection of integral features on subdomains:are nonlinear maps anddenotes the (bifurcation) parameters of the system. The right-hand-side of the i -th IPDE depends on say, a number of γ (i) variables and on bifurcation parameters from the set of features:At each spatial point x q, q = 1, 2,…, M and time instant t s, s = 1, 2,…, N, a single sample point (an observation) in the setfor the i -th IPDE can be described by a vector, with j = q + (s − 1) M. Here, we assume that such mesoscopic IPDEs in principle exist, but they are not available in closed-form. Henceforth, we aim to learn the macroscopic laws by employing a Feedforward Neural Network (FNN), in which the effective input layer is constructed by a finite stencil (sliding over the computational domain), mimicking convolutional operations where the applied "filter" involves values of our field variable(s) u (i) on the stencil, and returns featuresof these variables at the stencil center-point, i.e. spatial derivatives as well as (local or global) integrals (see Fig. 5 a for a schematic).

---

### A geometrical solution underlies general neural principle for serial ordering [^b3d6db1f]. Nature Communications (2024). High credibility.

The second variation involves the number of learning trials in which a specific item of the sequence appears (Supplementary Fig. 1). This presentation schedule eventually leads to the number of learning trials decreasing with the serial position k of the item as N L (k) = N L (1) − β N (k − 1). The network size is the same, and the sensory noise during the testing phase is σ S = 0.3, with β N ranging from 2 to 5. Statistics were collected from 100 independent simulations.

The third variation focuses on a probabilistic reward schedule in the transitive inference task Fig. 4 d–f. For each learning trial (couples with symbolic distance ∣SD∣ = 1), the reward for a correct answer is given based on a probability that is higher for higher ranks. Specifically, given a couple of symbols { S k, S k +1 }, the probability of receiving a reward is calculated as:where CDF is the cumulative distribution function of the standard normal distribution, and σ is the scaling factor of the reward schedule. This approach is equivalent to considering the response target for a trial { S k, S k +1 } as the sign of a random value η extracted from a Gaussian distribution. For this pair of items the rewarded scenario corresponds to η > 0 (right motor choice). The probability that a Gaussian random variableis positive is given by CDF(μ / σ), leading to Eq. (27). Note that 1 − CDF(− μ / σ) = CDF(μ / σ) so that the same reward probability holds for both pairs { S k +1, S k } and { S k, S k +1 }. Even in this case, the network size is N = 100, and the number of learning and testing trials per pair was 10000. σ ranged from 0 to 0.35.

Dimensionality analysis

Figure 8 depicts the outcomes of the principal component analysis (PCA) conducted on the network activity simulated during the testing phase of the task. To perform PCA, the sampling matrix T × N is initially centered at zero by subtracting its time averages. In this context, T represents the number of time steps of the test phase, and N stands for the number of nodes in the network. Subsequently, the associated covariance matrix and its eigenvectors, which embody the principal components, are computed. Notably, the network state projected onto the eigenvector with the maximum eigenvalue is the projection onto the first principal component.

---

### Decoding task specific and task general functional architectures of the brain [^bc06bade]. Human Brain Mapping (2022). Medium credibility.

2.2 Salience of input features

Let f be neural network function mapping input x to output y. Let g be a simpler explanation model that is interpretable and an approximation of the network mapping f. Let the number of neurons in layer l be n l. Using an appropriate reference, let us assign to each neuron i at layer l its contributionto the change in the output of neuron k at layer l + 1. Then, the change Δ h i, l in the activation of the i th neuron of layer l due to the input relative to the reference is given bywhenandwhen l = L − 1.

In order to determine the feature salience scores, we evaluate three types of references; namely sample mean, sample mode, and taking a sample which has the least L 2 norm from the rest of the samples. We empirically determined the mean referenceto be the most representative of the samples. Given the reference inputand the original input x, we can substituteand g (x) = f (x), giving us an equation for the model g :where the contribution of neurons in each layer l to the output y is given by(Shrikumar et al.):wherecan be computed from the Linear, Rescale, and RevealCancel rule (Shrikumar et al.). We can get contribution of neurons in all layers 0 ≤ l < L to the output y by backpropagating contributions of layers to the input, using the chain‐rule given by Equation (7).

---

### Active carpets drive non-equilibrium diffusion and enhanced molecular fluxes [^0119199e]. Nature Communications (2021). High credibility.

The resulting velocity correlation function (VCF) and mean-squared displacement (MSD) are shown in Fig. 2 b and c, respectively. The tracer dynamics are ballistic at short times, t ≪ τ, called the Holtsmark regime. However, at long times they are diffusive with a linear relation 〈Δ x 2 〉 = 2 D x x t, and similarly in the other directions. Hence, we determine the components of the diffusion tensor as a function of z 0 (Fig. 2 d). Like the flow variances, the vertical component D z z is five times stronger than the horizontal components, leading to anisotropic diffusion, and they all decay asin all three directions.

This system can be solved analytically when considering the limit of small displacements, when the noise amplitude is small. This ensures that we determine the local diffusivity, D i j (z) with small variations in z. Using information from the variance of the active fluctuations and their temporal correlations, the motion can then be integrated (see 'Methods: Derivation of the mean-squared displacement and space-dependent diffusivity'). This gives the MSD, which captures both the short-term ballistic motion and the diffusivity after long times (Fig. 2 c, dashed red lines). Thus, for the vertical Stokeslets for example, we find the space-dependent diffusion, which is compared with the simulations in Fig. 2 d. Because our theoretical approximation is formulated for small amplitudes of active fluctuations, the expression only holds far from the surface, when(Eq. (54)). Beyond this distance we find a good agreement between the simulations and the theory.

Overall, we find that the diffusion driven by an active carpet can be much stronger than Brownian thermal diffusion. Considering a carpet of Vorticella with cell radius a ~25 μm, h ~150 μm, n ~1/(100 μm) 2, τ ~1 s and 8 π μ f ⊥ ~500 pN, the active diffusion can be dominant up to distances ofmm for small nutrient molecules of D th ~ 500 μm 2 /s. That is much larger than the cell size. Moreover, for micron-sized prey of D th ~0.5 μm 2 /s, we find z th ~7 mm, orders of magnitude larger than the organism itself. Hence, we expect these results to be highly relevant across the scales, for non-equilibrium transport from molecular to organismic sizes.

---

### Many-body localization enables iterative quantum optimization [^43c931b6]. Nature Communications (2022). High credibility.

Fig. 5
Exact diagonalization.

Low-energy spectra of Eq. (3) for different χ. System size is N = 10. Red and orange straight lines are the reference and ground-state energies, correspondingly at χ = 0. They are repeated on all panels as a guide for eye. When χ = 0, energies are straight lines with slopes (11). For larger χ, energies are curved down, due to the level repulsion. Simultaneously the gaps open up.

For χ ≫ 1, one may start assuming B z = 0. At B x / J ≪ 1, Eq. (10) is approximate byThis may be viewed as a result of the second order, in B x, perturbation of the SK model. The energy of the local minimum goes down due to the level of repulsion, and the second-order perturbation comes from the one-spin flip states. The factor 1/(2 f l J) describes the average inverse energy difference between the local minimum and one-spin flip states. The distribution of f l 's is approximated by a uniform box in the interval 1/4 < f l < 3/4. Finally at B x ≫ J, the system is fully polarized with Σ l ≈ − N B x. Equation (10) is the simplest way to interpolate between all these limits, which works extremely well for small system-size simulations.

To perform larger system-size simulations, leading to Fig. 4, we statistically generate multiple local minima energy curves according to Eqs. (9)–(13). The distribution of SK local energies, E l is taken from refs.and is assumed to be statistically independent from the other random parameters, m l and f l. We simulated system sizes up to N = 200 and verified that the qualitative features of Fig. 4 are robust against variations in specific distributions of the random parameters. The first order (red dashed) line in Fig. 1 is determined by the position offor a fixed reference state, whileis given by the last intersection of the reference state.

---

### Data-driven modeling and prediction of non-linearizable dynamics via spectral submanifolds [^909bd26c]. Nature Communications (2022). High credibility.

Embedding SSMs via generic observables

If at least some of the real parts of the eigenvalues in (2) are negative, then longer-term trajectory data for system (1) will be close to an attracting SSM, as illustrated in panel (b) of Fig. 2. This is certainly the case for data from experiments that are run until a nontrivial, attracting steady state emerges, see, e.g. in panel (e) of Fig. 1. Measurements of trajectories in the full phase space, however, are seldom available from such experiments. Hence, if data about system (1) is only available from observables, the construction of SSMs and their reduced dynamics has to be carried out in the space of those observables.

An extended version of Whitney's embedding theorem guarantees that almost all (in the sense of prevalence) smooth observable vectorsprovide an embedding of a compact subsetof a d -dimensional SSM, W (E, Ω t; ϵ), into the observable spacefor high enough p. Specifically, if we have p > 2(d + ℓ) simultaneous and independent continuous measurements, y (x), of the p observables, then almost all mapsare embeddings of, and hence the top right plot of Fig. 3 is applicable with probability one.

Fig. 3
Schematics of SSMLearn.

First, he data-driven, SSM-based model reduction algorithm implemented in SSMLearn diagnoses and approximates the dominant SSM from the input data. Next, it constructs a data-driven reduced-order model as an extended normal form on the SSM. Finally, the algorithm uses this model to predict individual unforced trajectories and the response of the system under additional forcing.

In practice, we may not have access to p > 2(d + ℓ) independent observables and hence cannot invoke Whitney's theorem. In that case, we invoke the Takens delay embedding theorem, which covers observable vectors built from p uniformly sampled, consecutive measured instances of a single observable. More precisely, if s (t) is a generic scalar quantity measured at times Δ t apart, then the observable vector for delay-embedding is formed as. We discuss the embedding, of an autonomous SSM, W (E, Ω t 0; 0), in the observable spacein more detail in the Methods section "Embedding the SSM in the observable space".

---

### High-order diffraction for optical superfocusing [^137b99e4]. Nature Communications (2024). High credibility.

Fig. 1
High-order diffraction in focusing.

a Optical diffraction from a single zone that is sketched in a polar coordinate. b Simulated amplitude (normalized to the maximum) of light diffracted from the zones with different widths Δr. By changing Δr, the simulation is implemented by using Rayleigh-Sommerfeld diffraction with a fast Fourier transform, where the pixel pitch of 0.02 λ × 0.02 λ is used to enhance the calculation accuracy. The zones have the same central position of (r n + r n-1)/2 = 75 λ for investigating the role of Δr. The diffraction orders of the zones are also labeled for better observation, where the dashed white curves (derived by using) denote the boundaries between two neighboring orders. For each Δr, the fast oscillations along the radial positions are not observed in current figure due to the large range in radial position. c On-axis (ρ = 0) intensity of diffracted light from axisymmetric zones with different widths Δr and the outermost radii r n (where the parameteris used with f = 75 λ for better data display). The on-axis intensity of each order (labeled in different colors) has been normalized to the maximum of its own order. Two cases for the destructive (A with Δr = 4.69 λ and = 0.45) and constructive (B with Δr = 7.6 λ and = 0.5) interferences have been exemplified to show its diffraction patterns (see Supplementary Fig. 1). The structural parameters of the 0 th -order (dots) and 1 st -order (triangles) FZPs are located at the region of constructive interference, implying diffraction-limited focusing similar to traditional objectives lenses. The destructive interference is indicated by white regions. d – e Simulated optical focusing via a standard 0 th -order FZP (d) and high-order (e) FZP with binary phase. Optical paths from the n th radius to the focus are R n = f + n λ /2 for standard FZP and R n = f + n (2 M + 1) λ /2 for M th -order FZP, which indicates their fundamental differences. f Analytical (gray bars) and simulated (blue-white-red bars) efficiencies of high-order FZPs with different NA s.

---

### The unusual quadruple bonding of nitrogen in ThN [^2eae9929]. Nature Communications (2023). High credibility.

Nitrogen has five valence electrons and can form a maximum of three shared electron-pair bonds to complete its octet, which suggests that its maximum bond order is three. With a joint anion photoelectron spectroscopy and quantum chemistry investigation, we report herein that nitrogen presents a quadruple bonding interaction with thorium in ThN. The quadruple Th≣N bond consists of two electron-sharing Th-N π bonds formed between the Th-6d xz /6d yz and N 2p x /2p y orbitals, one dative Th←N σ bond and one weak Th←N σ bonding interaction formed between Th-6d z 2 and N 2s/2p z orbitals. The ThC molecule has also been investigated and proven to have a similar bonding pattern as ThN. Nonetheless, due to one singly occupied σ-bond, ThC is assigned a bond order of 3.5. Moreover, ThC has a longer bond length as well as a lower vibrational frequency in comparison with ThN.

---

### Dextrose (dextrose 10%) [^eeaa183c]. FDA (2025). Medium credibility.

SPECIFICATION

（1）50ml:2.5g（2）50ml:5g（3）100ml：5g（4）100ml:10g（5）250ml:12.5g（6）250ml:25g（7）500ml:25g（8）500ml:50g（9）1000ml:50g（10）1000ml:100g

---

### Exponential concentration in quantum kernel methods [^4f8432da]. Nature Communications (2024). High credibility.

Proposition 2

Assume that the fidelity quantum kernelexponentially concentrates towards some exponentially small value as per Definition 1. Suppose anshot SWAP test is used to estimate the Gram matrix for a training datasetof size N s. Then, with probability exponentially close to 1 (i.e. probability at leastsuch thatfor some c > 1), the estimate of the Gram matrixis statistically indistinguishable from the matrixwhose diagonal elements are 1 and off-diagonal elements are instances ofwhere eachtakes either + 1 or − 1 with equal probability. We note thatdoes not contain any information about the input data.

We refer the readers to Supplementary Note II for an introduction to some preliminary tools for a hypothesis testing and Supplementary Note III A 2 for further technical details regarding the SWAP test, which includes formal definitions of statistical indistinguishability (i.e. Definition 2 for distributions and Definition 3 for outputs), and a proof of the proposition.

Although statistical estimates of the kernel behave differently depending on the choice of measurement strategy, they are both in effect independent of the input data for large n. Thus training with this estimated Gram matrix leads to a model whose predictions are independent of the input training data. We present numerical simulations to support our theoretical findings in Supplementary Note III A 3.

Crucially, this conclusion applies generally beyond kernel ridge regression to other kernel methods including both supervised learning tasks and unsupervised learning tasks. As a concrete example, we consider the optimal solution for kernel ridge regression in the presence of exponential concentration.

Corollary 1

Consider a kernel ridge regression task with a squared loss function and regularization λ using the same assumptions as Proposition 1. Denote y as a vector with its i th elements equal to y i.
For the Loschmidt Echo test, the optimal parameters are found to be

with probability at least 1 − δ withfor some b > 1.

For a test data point, the model prediction is 0 with probability at leastsuch thatfor some.
2 For the SWAP test, the optimal parameters are statistically indistinguishable from the vector

with probability at leastwithfor some. Here, is a data-independent random matrix whose diagonal elements are 1 and off-diagonal elements are instances ofin Eq. (14).

In addition, with probability exponentially close to 1, the model prediction on unseen data is statistically indistinguishable from the data-independent random variables that result from measuring.

---

### Interpretable and tractable models of transcriptional noise for the rational design of single-molecule quantification experiments [^179bce76]. Nature Communications (2022). High credibility.

Methods

The Supplementary Note contains comprehensive derivations and descriptions of analytical procedures. A complete list of major technical results is presented in Section 2. The Γ-OU and CIR models are fully motivated and solved in Section 3. Moments and autocorrelations are derived in Section 4. Limiting cases are derived in Section 5. Simulation details and validation of our exact results are presented in Section 6. Brief summaries of certain aspects of this work covered more fully in the supplement, and important miscellaneous information, are provided below.

Notation

A complete guide to our mathematical notation is presented in Section 2.2 in the Supplementary Note. The molecular species of interest are nascent transcriptsand mature transcripts. Their respective counts are denoted by random variables X N and X M. The gene locus produceswith a time-dependent rate K (t) = K t, described by a stochastic process. Therefore, the probability density of the system is given by P (X N = x N, X M = x M, K t ∈ [K, K + d K], t), i.e. the density associated with finding the system in a state with x N molecules of, x M molecules of, and a transcription rate of K at time t. Having introduced this rather formal notation, we use a shorthand that elides the random variables.

Model definitions

The Γ-OU and CIR models are mathematically defined via master equations, which describe how probability flows between different possible states. In particular,

The CME term is identical for both models, and encodes transcription, splicing, and degradation reactions as in the constitutive model(see Section 2 in the Supplementary Note). However, the Fokker-Planck equation (FPE) terms beyond first order, which encode transcription rate variation, are different.

---

### Unexpectedly minor nitrous oxide emissions from fluvial networks draining permafrost catchments of the east qinghai-tibet plateau [^be6372c6]. Nature Communications (2022). High credibility.

Upscaling technique

We upscaled the magnitude of N 2 O emissions (and uncertainty) from EQTP streams and rivers with a Monte Carlo simulation (MATLAB R2018b) that ran 1000 iterations for each sampled 3 rd - to 7 th -stream order. Each iteration randomly selected a N 2 O flux measurement and simultaneously selected a surface area based on a normal distribution surrounding the mean and standard deviation for that stream in order to generate an order-specific N 2 O flux per unit of time. This value was then summed across the ice-free season (210 d from April to October) to estimate N 2 O emission for each stream order. For 1 st - and 2 nd -order streams, a range of N 2 O fluxes that extrapolated from the relationship in Fig. 3c and the surface area for this order were used to produce total fluxes and constrain the uncertainty. We summed up the final distribution of N 2 O emissions from stream orders 1–7, including the mean value and 95% confidence intervals. Finally, we divided the ice-free season emission by 85% to obtain the annual emission. This is because early spring efflux of winter-derived N 2 O fuels ~15% of the annual emissions.

---

### Evolutionary dynamics of any multiplayer game on regular graphs [^916cb3ba]. Nature Communications (2024). High credibility.

General replicator equations

The evolution of frequencies x 1, x 2,…, x n can be deduced through the microscopic strategy update process. Specifically, in an infinite population, i.e. N → ∞, a single unit of time comprises N elementary steps, ensuring that each individual has an opportunity to update their strategy. During each elementary step, the frequency of i -players increases by 1/ N when a focal j -player (where j ≠ i) is chosen to update its strategy and is replaced by an i -player. Similarly, the frequency of i -players decreases by 1/ N when a focal i -player is selected to update its strategy and the player who takes the position is not an i -player. Based on this perception, we derive a simple form of the replicator equations for i = 1, 2,…, n in the weak selection limit (Supplementary Note 2) :We find that Eq. (4) offers an intuitive understanding, if we introduce the following two concepts: (1), the expected accumulated payoff of the i -player (zero steps away on the graph), and (2), the expected accumulated payoff of the i -player's neighbors (one step away on the graph). These concepts suggest that. Under pairwise comparison, the reproduction rate of i -players is dependent on how their accumulated payoff exceeds that of their neighbors. In essence, the evolution of x i is the competition between an individual and its first-order neighbors, which aligns with the results obtained by a different theoretical framework in two-strategy systems. We further extend it to n -strategy systems in the framework of pair approximation. We also verify that the death-birth rule is essentially the competition between an individual and its second-order neighbors for n -strategy systems (Supplementary Information).

---

### Spin dephasing under nonlinear gradients: implications for imaging and field mapping [^eaf2803c]. Magnetic Resonance in Medicine (2012). Low credibility.

This work examines the prototypical MR echo that would be expected for a voxel of spins evolving in a strong nonlinear field, specifically focusing on the quadratic z(2) - ½(x(2) + y(2)) field. Dephasing under nonlinear gradients is increasingly relevant given the growing interest in nonlinear imaging, and here, we report several notable differences from the linear case. Most notably, in addition to signal loss, intravoxel dephasing under gradients creating a wide and asymmetric frequency distribution across the voxel can cause skewed and nonlinear phase evolution. After presenting the qualitative and analytical origins of this difference, we experimentally demonstrate that neglecting these dynamics can lead to significant errors in sequences that assume phase evolution is proportional to voxel frequency, such as those used for field mapping. Finally, simplifying approximations to the signal equations are presented, which not only provide more intuitive forms of the exact expression but also result in simple rules to predict key features of the nonlinear evolution.

---

### Quantifying unobserved protein-coding variants in human populations provides a roadmap for large-scale sequencing projects [^3db7b451]. Nature Communications (2016). Medium credibility.

Methods

UnseenEst algorithm

UnseenEst uses the empirical SFS of a given class of variants in a cohort to estimate its frequency distribution in the population. The inputs into the algorithm are the number of alleles in the sample cohort, k, and the SFS, which is a set of counts, { F i }, where F i is the number of variants that are observed in exactly i out of the k alleles. A key challenge for the method is to accurately estimate the frequency distribution of variants that have empirical count of 0 (that is, they are not observed) in the cohort but are likely to have some small, non-zero frequency in the population.

More concretely, let X denote a discrete set of frequencies x in [0, 1] and let h (x) denote the fraction of all the variants with frequency x. UnseenEst estimates h (x) by finding the set of h (x) that jointly minimizes the value of the expression:

where bin(x, k, i) is the binomial probability of observing i heads in k independent flips of a coin with bias x. The intuition for minimizing this objective is as follows:is the number of variants that we expect to find in i out of k alleles in the cohort and F i is the empirical number of variants observed in i alleles. If h (x) is the true frequency distribution, then the expectation should be close to the empirical, which is why we want to find h (x) that minimizes the objective above. Given an estimate of the frequency distribution h (x), the expected number of unique variants in N alleles can be calculated by the formula.

The standard 3rd order jackknife estimator does not estimate the frequency distribution h (x). Instead, it directly estimates that the number of unique variants in N alleles is g 1 (N, k) F 1 +g 2 (N, k) F 2 +g 3 (N, k) F 3, where F 1, F 2, F 3 are the number of variants observed once, twice and three times in k alleles, and g 1, g 2, g 3 are specific functions of N and k derived from self-consistency requirements. Note that the confidence intervals of the jackknife in Supplementary Fig. 3 are very narrow because there is relatively little variation in the counts F 1, F 2, F 3, when the sample size is large.

---

### Generating conjectures on fundamental constants with the ramanujan machine [^75e8911d]. Nature (2021). Excellent credibility.

Fundamental mathematical constants such as e and π are ubiquitous in diverse fields of science, from abstract mathematics and geometry to physics, biology and chemistry 1,2. Nevertheless, for centuries new mathematical formulas relating fundamental constants have been scarce and usually discovered sporadically 3–6. Such discoveries are often considered an act of mathematical ingenuity or profound intuition by great mathematicians such as Gauss and Ramanujan 7. Here we propose a systematic approach that leverages algorithms to discover mathematical formulas for fundamental constants and helps to reveal the underlying structure of the constants. We call this approach 'the Ramanujan Machine'. Our algorithms find dozens of well known formulas as well as previously unknown ones, such as continued fraction representations of π, e, Catalan's constant, and values of the Riemann zeta function. Several conjectures found by our algorithms were (in retrospect) simple to prove, whereas others remain as yet unproved. We present two algorithms that proved useful in finding conjectures: a variant of the meet-in-the-middle algorithm and a gradient descent optimization algorithm tailored to the recurrent structure of continued fractions. Both algorithms are based on matching numerical values; consequently, they conjecture formulas without providing proofs or requiring prior knowledge of the underlying mathematical structure, making this methodology complementary to automated theorem proving 8–13. Our approach is especially attractive when applied to discover formulas for fundamental constants for which no mathematical structure is known, because it reverses the conventional usage of sequential logic in formal proofs. Instead, our work supports a different conceptual framework for research: computer algorithms use numerical data to unveil mathematical structures, thus trying to replace the mathematical intuition of great mathematicians and providing leads to further mathematical research.

---

### Approximations to the expectations and variances of ratios of tree properties under the coalescent [^8355e038]. G3 (2022). Medium credibility.

Properties of gene genealogies such as tree height (H), total branch length (L), total lengths of external (E) and internal (I) branches, mean length of basal branches (B), and the underlying coalescence times (T) can be used to study population-genetic processes and to develop statistical tests of population-genetic models. Uses of tree features in statistical tests often rely on predictions that depend on pairwise relationships among such features. For genealogies under the coalescent, we provide exact expressions for Taylor approximations to expected values and variances of ratios Xn/Yn, for all 15 pairs among the variables {Hn, Ln, En, In, Bn, Tk}, considering n leaves and 2 ≤ k ≤ n. For expected values of the ratios, the approximations match closely with empirical simulation-based values. The approximations to the variances are not as accurate, but they generally match simulations in their trends as n increases. Although En has expectation 2 and Hn has expectation 2 in the limit as n→∞, the approximation to the limiting expectation for En/Hn is not 1, instead equaling π2/3–2≈1.28987. The new approximations augment fundamental results in coalescent theory on the shapes of genealogical trees.

---

### Improved machine learning algorithm for predicting ground state properties [^61202b90]. Nature Communications (2024). High credibility.

Finding the ground state of a quantum many-body system is a fundamental problem in quantum physics. In this work, we give a classical machine learning (ML) algorithm for predicting ground state properties with an inductive bias encoding geometric locality. The proposed ML model can efficiently predict ground state properties of an n-qubit gapped local Hamiltonian after learning from only [Formula: see text] data about other Hamiltonians in the same quantum phase of matter. This improves substantially upon previous results that require [Formula: see text] data for a large constant c. Furthermore, the training and prediction time of the proposed ML model scale as [Formula: see text] in the number of qubits n. Numerical experiments on physical systems with up to 45 qubits confirm the favorable scaling in predicting ground state properties using a small training dataset.

---

### Easy-to-useshims for human brain imaging at 7 T [^fa89e01e]. Magnetic Resonance in Medicine (2025). Medium credibility.

Purpose

 < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > field inhomogeneity is a common problem in high field brain MRI (< mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:mo > > < /mml:mo > < mml:mn > 3 < /mml:mn > < /mml:mrow > < mml:annotation > $$ > 3 $$ < /mml:annotation > < /mml:semantics > < /mml:math > T). Parallel-transmit methods that adjust the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > field channelwise often require valuable scan time. Group-optimized phase shims are presented to increase or attenuate the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > field in specific brain regions, omitting personalized calibrations and potentially enabling reduced FOV acquisitions or artifact reduction.

Methods

Channelwise < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > maps were obtained for seven participants using an 8Tx/32Rx coil and a 7 T MRI scanner. Two regional shim settings (< mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > shims) were calculated: one to increase the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > field in the cerebellum and the other to increase the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > field in the occipital lobe while attenuating the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > field in the frontal lobe. < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > maps from five participants outside the design group were used to simulate the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > profiles, and seven were scanned to evaluate the implementation of the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > shims using < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > maps, 3D EPI, GRE acquisitions, and a visual fMRI experiment.

Results

Both regional shim settings successfully amplified the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > field in the selected ROIs resulting in improved < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > yield and increased tSNR in the 3D EPI images and fMRI experiments compared to the circularly polarized shim mode. The attenuating < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > shim decreased < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > in the frontal ROI, decreasing fold-over artifacts in a reduced FOV, lowering g-factors in accelerated scans with high undersampling factors and resulted in improved BOLD responses in the visual fMRI experiment.

Conclusion

Regional < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > shim settings remove the need for time-consuming, personalized < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > measurements and calibrations. The attenuating shim allows for signal reduction within the power limits of the rf-coil, reducing artifacts while improving the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {B}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > field in selected ROIs.

---

### A tweezer array with 6, 100 highly coherent atomic qubits [^da43db31]. Nature (2025). Excellent credibility.

The second method we use to characterize imaging fidelity and survival requires no assumption for the photon distribution but considers that the imaging survival and fidelity is identical for three successive images. We start by estimating the probabilityof the presence of an atom in three images being x 1 x 2 x 3, in which x i is a Boolean, equal to 1 if there is an atom and 0 if there is none,

Here S is the survival probability during imaging and F is the initial filling fraction. From this, we can estimate the probability of detecting y 1 y 2 y 3 as. The conditional probabilities on the detection categorization given the true atomic presence are, and.

We use the method of least squares to minimize the difference between the experimental frequencies of bitstrings y 1 y 2 y 3 and theby tuning the four parameters F, S,… The imaging fidelity is then defined as. The array-wide binarization threshold is chosen to maximize the imaging fidelity (Extended Data Fig. 4c). Using this method, we find an imaging fidelity, with a false-positive probabilityand a false-negative probability; we find the survival to be S = 0.999864(2), slightly lower than the steady-state imaging survival probability measured by repeated imaging. Finally, we can inject the model-free survival probability into the lossy Poisson model to increase its accuracy (trying to extract the loss directly from the lossy Poisson model would indeed be inaccurate, because losses appear as a small tail feature between the two peaks of the imaging histogram). Using this approach, and fitting each site independently, we find an average imaging fidelity of 99.992(1)%, in reasonable agreement with the model-free imaging fidelity. By setting the atom loss to zero while keeping the other five fit parameters constant for each site, we can estimate a hypothetical imaging fidelity in the absence of atomic loss of 99.999(1)%. This analysis also illustrates that fitting the imaging histogram with a Gaussian or Poissonian model without including losses leads to overestimating imaging fidelities.

---

### Optimality guarantees for crystal structure prediction [^9e5ffdc0]. Nature (2023). Excellent credibility.

Crystalline materials enable essential technologies, and their properties are determined by their structures. Crystal structure prediction can thus play a central part in the design of new functional materials 1,2. Researchers have developed efficient heuristics to identify structural minima on the potential energy surface 3–5. Although these methods can often access all configurations in principle, there is no guarantee that the lowest energy structure has been found. Here we show that the structure of a crystalline material can be predicted with energy guarantees by an algorithm that finds all the unknown atomic positions within a unit cell by combining combinatorial and continuous optimization. We encode the combinatorial task of finding the lowest energy periodic allocation of all atoms on a lattice as a mathematical optimization problem of integer programming 6,7, enabling guaranteed identification of the global optimum using well-developed algorithms. A single subsequent local minimization of the resulting atom allocations then reaches the correct structures of key inorganic materials directly, proving their energetic optimality under clear assumptions. This formulation of crystal structure prediction establishes a connection to the theory of algorithms and provides the absolute energetic status of observed or predicted materials. It provides the ground truth for heuristic or data-driven structure prediction methods and is uniquely suitable for quantum annealers 8–10, opening a path to overcome the combinatorial explosion of atomic configurations.

---

### Experimental demonstration of quantum advantage for NP verification with limited information [^776b5b5c]. Nature Communications (2021). High credibility.

Box 1 Protocol for NP verification

Input: Instance of the NP-complete problem and all its relevant parameters: N, δ, etc. after the reduction to a 2-out-of-4 SAT;

Goal: Verification of the solution;

1 Merlin and Arthur jointly perform a pre-calibration of the optical setup, finding the values of the visibility ν N and the transmittivity η;

2 Arthur computes the minimum value of the mean photon number number μ N in order to satisfy the quantum advantage conditions 1–3 and communicates it to Merlin in order to tune the amplitude of his pulses; he also computes the threshold T for accepting a proof;

3 Arthur sends a signal to Merlin to trigger the protocol;

4 Merlin encodes his proof in the phases of the pulses which are then sent to Arthur;

5 Arthur interferes Merlin's pulses with his own and assigns a value x k each time he registers a measurement in the k th pulse:

5.1 x k = 0 for a click in detector D 0 and no click in D 1;

5.2 x k = 1 for a click in detector D 1 and no click in D 0;

5.3 x k is randomly assigned if both detectors click.

6 For all the measured bits that form a clause, Arthur checks the satisfiability;

7 If the number of satisfied clauses is greater than T, Arthur accepts the proof, otherwise he rejects.

Experimental results

We now have all the ingredients to describe the experimental implementation of our verification test and the assessment of the quantum advantage for this task. As we defined previously, we need to satisfy three conditions to show quantum advantage. We need the verification procedure to take time linear in N, to have completeness and soundness such thatand, and that the number of clicks Arthur registers is much smaller than the input size N.

First, as we will see, in our experiment we use indeed a train of coherent pulses of size N and some simple classical post-processing of the measurement results, so our test satisfies condition 1. In fact, the real time to run the verification procedure for N between 5000 and 14,000 was a fraction of a second for the quantum part, a few seconds for the classical post-processing and a couple of minutes for the calibration procedure for each run.

---

### De novo motor learning creates structure in neural activity that shapes adaptation [^36954330]. Nature Communications (2024). High credibility.

Network architecture

The model dynamics were given by:where x i is the hidden state of the i th unit and r i is the corresponding firing rate following t a n h activation of x i. The networks had N = 300 units and I inputs. The time constant τ was set to 0.05 s, the integration time step d t to 0.01 s, and the noise η was randomly sampled from the Gaussian distributionfor each time step. The initial states x t = 0 were sampled from the uniform distribution. The networks were fully recurrently connected, with the recurrent weights J initially sampled from the Gaussian distribution, where g = 1.2. The time-dependent stimulus inputs s (specified below) were fed into the network, with input weights B initially sampled from the uniform distribution.

For the networks trained on the reaching task, two types of sustained inputs s were used. For the angular inputs, s was three-dimensional and consisted of a one-dimensional hold signal and a two-dimensional target signal (2 cosθ target, 2 sin θ target) that specified the reaching direction θ target of the target. For the categorical inputs, s was five-dimensional and consisted of a one-dimensional hold signal and a four-dimensional one-hot encoded target signal with the same magnitude (e.g. (0, 0, 2, 0)) that did not provide information about the target's angular direction. For the networks trained on the sinusoidal task, one type of sustained input s was used that included both continuous and categorical encoding of target movements. For this task, s was six-dimensional and consisted of a one-dimensional hold signal, a one-dimensional sine wave target signal (2 A / A max, where the maximum amplitude A max was 7) that specified the amplitude A of the sine wave, and a four-dimensional one-hot encoded cosine wave target signal with the same magnitude (e.g. (0,0,2,0)) that specified the cosine wave target without providing information about its amplitude. For all types of inputs, the hold signal started at 2 and goes to 0 at the go cue, and the target signals remained at 0 until the task cue.

The networks were trained to produce 2D outputs p corresponding to x and y positions of motor trajectories, and they were read out via the linear mapping:where the output weights W were sampled from the uniform distribution. During VR adaptation trials, p was rotated counterclockwise according to a perturbation angle θ r.

---

### Introspection confidence predicts EEG decoding of self-generated thoughts and meta-awareness [^70bc8c1c]. Human Brain Mapping (2022). Medium credibility.

The general time‐averaged MVPC was complemented with a method that allows assessing the activation patterns that describe the contribution of each channel or frequency band to the decoding of class‐related information (Haufe et al.). In the case of linear classifiers, we can obtain an estimate of the activation patterns A by projecting the extraction filters of the classifier, W, onto the channels as follows: A ∝ ∑ x W, where ∑ x is the covariance matrix of the data. This calculation can be simplified by computing the covariance between the data (x) and hidden factors (y, vector of labels of each class): A ∝ ∑ x W = Cov [x (n), y (n)], where n is the number of trials (Haufe et al.). The covariance Cov [x (n), y (n)] is computed for each pattern dimension (i.e. each channel or frequency band) across the total number of training trials n, and separately for each fold (followed up by an average across folds). The amplitude and sign of the covariance matrix Cov [x (n), y (n)] can be interpreted as the strength and polarity with which class‐related information is reflected in each pattern dimension (channel or frequency band). The interpretation of the polarity depends on the order in which data from each class is concatenated for MVPC analysis and pattern extraction: a positive polarity in a pattern dimension reflects that the activity (e.g. theta power) is greater in class 1 than in class 2 for that specific dimension (channel). In the results, we specify the order in which the class‐related data were concatenated for each analysis. Importantly, MVPC is a multivariate analysis method, and thus drawing inferences from the pattern amplitude (strength) to describe univariate effects (e.g. in individual channels) should be avoided. For multifrequency models, we averaged the activation maps across frequency bands, to obtain a single topographic representation across 64 channels. The activation patterns associated with each frequency range were assessed using the single‐frequency models.

Finally, we conducted correlation analyses between decoding accuracies derived from our time‐averaged models and participants' confidence in their respective reports. Correlation analyses were performed exclusively in a subset of the models, based on our EEG findings and previous research (see section 2.7.3).

2.7 Statistical analyses

---

### Revealing nonlinear neural decoding by analyzing choices [^d8ac9bc5]. Nature Communications (2021). High credibility.

Optimality test

Substituting the optimal weights (Eq. (12)) into Eq. (15), the optimal nonlinear choice correlation becomeswhereis the fine discriminability provided by R k (r) for a stimulus difference of Δ s. The same argument holds for coarse discrimination, wherein Eq. (17) is canceled byin the optimal weights (Eq. (16)), yielding.

For fine-scale discrimination, optimal choice correlations can be written in many equivalent ways that reflect the simple relationships between four quantities often used to represent information: discriminability d -prime is proportional to the square root of the Fisher information; estimator variance is bounded by the inverse of the Fisher information; discrimination threshold is proportional to the estimator standard deviation, with proportionality given by the threshold condition.

In different experiments (binary discrimination, continuous estimation), it can be most natural to express this optimal decoding prediction as ratios of different measured quantities:

These quantities reflect information between the stimulus and the neural or behavioral responses. Supplemental material S. 5 shows how this can be computed easily for general binary discrimination using the total correlation between the responses and the stimuli, or a continuously varying behavioral choiceand the stimuli,:and likewise for. When the behavioral choice is binary rather than continuous, the correlations are modified by a factor δ near 1 (Supplemental Information S. 6.3, Eq. (182)). For our experimental conditions, δ ≈ 1.2 ± 0.2.

Nonlinear choice correlation to analyze an unknown nonlinearity

In Fig. 5, we generated neural responses given sufficient statistics that are polynomials up to third order, R (r) = { r i, r i r j, r i r j r k } (see the "Methods" subsection "Cubic encoding"). Our model brain decodes the stimulus using a cascade of linear–nonlinear transformations, with Rectified Linear Units for the nonlinear activation functions. We used a fully connected ReLU network with two hidden layers and 30 units per hidden layer. We trained the network weights and biases with backpropagation to estimate stimuli near a reference s 0 based on 20,000 training pairs (r, s) generated by the cubic encoding model. This trained neural network extracted 91% of the information available to an optimal decoder.

---

### Targeted time-varying functional connectivity [^99cfa42b]. Human Brain Mapping (2025). Medium credibility.

2.4 Empirical Assessment

To assess the models' ability to capture task‐relevant information, we calculated classification accuracy in distinguishing task conditions over time using state time courses derived from each model. For each subject, the state time courses were epoched by trial onset and averaged across trials of the same condition, resulting in condition‐specific mean trial‐locked state time courses. At each timepoint 𝑡, these subject‐level averages, arranged in a matrix with subjects as rows and conditions as columns, were used as predictors for classification. We used logistic regression for the simulated data (two conditions); and ordinal logistic regression for the real data, given the ordered nature of the conditions (binary, ternary and quaternary). All runs of the models were unsupervised, with no prior knowledge of task timings. We applied 5‐fold subject‐wise cross‐validation, ensuring that subjects were not split between folds (i.e. a model tested on a given subject had not seen any trial of that subject during training). Within each fold, the predictive model was trained on data from four folds (training data) and used to predict task conditions for the remaining fold (test data). Classification accuracy was computed as the percentage of correctly classified task conditions across subjects in the test fold. This process was repeated for each fold, yielding an overall cross‐validated accuracy score. A perfect classification corresponds to an accuracy of 1, while 1/ N indicates random guessing among N conditions.

---

### A geometrical solution underlies general neural principle for serial ordering [^eb974788]. Nature Communications (2024). High credibility.

A general mathematical description of how the brain sequentially encodes knowledge remains elusive. We propose a linear solution for serial learning tasks, based on the concept of mixed selectivity in high-dimensional neural state spaces. In our framework, neural representations of items in a sequence are projected along a "geometric" mental line learned through classical conditioning. The model successfully solves serial position tasks and explains behaviors observed in humans and animals during transitive inference tasks amidst noisy sensory input and stochastic neural activity. This approach extends to recurrent neural networks performing motor decision tasks, where the same geometric mental line correlates with motor plans and modulates network activity according to the symbolic distance between items. Serial ordering is thus predicted to emerge as a monotonic mapping between sensory input and behavioral output, highlighting a possible pivotal role for motor-related associative cortices in transitive inference tasks.

---

### Phase-encoded fMRI tracks down brainstorms of natural language processing with subsecond precision [^7d590922]. Human Brain Mapping (2024). Medium credibility.

2.8 Functional image analyses

For each BRIK file of a functional scan containing (x, y, z, t) = 64 × 64 × 55 × 256 data points, a 256‐point discrete Fourier transform was applied to the time series x m (t) of each voxel m at location (x, y, z) by:where X (ω) is the Fourier component at each frequency ω between 0 and 127 cycles per scan, and | X m (ω)| and θ m (ω) represents the amplitude and phase angle, respectively. The task frequency is defined as ω s (16 cycles per scan), denoting the frequency of periodic fluctuations of blood flow in response to periodic stimuli and tasks. The remaining nontask frequencies are defined as ω n. The signal and noise are defined as the Fourier components X m (ω) at frequencies ω s and ω n, respectively. The statistical significance of periodic fluctuations of blood flow is evaluated by the signal‐to‐noise ratio, an F ‐ratio (Chen et al; Huang et al; Sereno et al; Sereno & Huang; Sood & Sereno,), in each voxel m by:where df s = 2 and df n = 230 are the degrees of freedom of the signal and noise, respectively. The p ‐value in each voxel m is estimated by the cumulative distribution function F (2,230) = F (F m; df s, df n) (Chen et al; Huang et al; Press et al.). A complex F ‐value, (F m_r, F m_i), incorporating both the F ‐statistic value and the phase angle, θ m (ω s), of each voxel was computed by F m_r = f m cos(θ m (ω s)) and F m_i = f m sin(θ m (ω s)), where f m is the square root of F m. Voxels containing strong periodic signals at the task frequency (ω s = 16 cycles per scan) with F (2,230) > 4.7 (p < .01, uncorrected), F (2,230) > 7.1 (p < .001, uncorrected), or F (2,230) > 9.6 (p < .0001, uncorrected) were retained and their phase angles were color‐coded in a range between 0 and 2π (0–16 s) and painted on each individual subject's cortical surfaces for each scan using csurf (Figure 3). The complex F ‐values of corresponding voxels m were vector‐averaged (voxel‐wise) across two scans k = {1, 2} of the same task in each session for each subject S using:which was performed by the "Combine 3D Phase Stats" function of csurf. The resulting average complex F ‐valueswere then painted on individual subject's cortical surfaces.

---

### Unexpectedly minor nitrous oxide emissions from fluvial networks draining permafrost catchments of the east qinghai-tibet plateau [^620ce650]. Nature Communications (2022). High credibility.

Despite large uncertainties due to a lack of observational data from 1 st - and 2 nd -order streams (Supplementary Discussion 4), the upscaling exercise enables us to place our estimates in a broader context of both regional N 2 O budgets and fluvial emissions at the global scale. The percentage of N 2 O in total GHG (CO 2 + CH 4 + N 2 O) emissions expressed as CO 2 equivalents corresponded to 1.0% for EQTP 3 rd - to 7 th -order drainages, then dwindled to 0.4% for EQTP 1 st - to 7 th -order streams and rivers, falling within the range of pristine rivers (0.2–1.2%). These values contrast those from human-impacted fluvial networks, where N 2 O percentages are generally much higher (2.8–13.9%, average 6.8%; Supplementary Table 9) due to often elevated inputs of fertilizer- or sewage-derived N that boost N 2 O emissions. Expressed as per unit stream/river and basin area, EQTP 1 st - to 7 th -order streams and rivers released a total of 0.08 t N 2 O-N km −2 yr −1 and 0.32 kg N 2 O-N km −2 yr −1, respectively, to the atmosphere, which are one order of magnitude lower than those from lotic systems worldwide [0.65 (range: 0.08–2.55) t N 2 O-N km −2 yr −1 and 2.44 (range: 0.55–5.78) kg N 2 O-N km −2 yr −1, respectively; Supplementary Table 9]. Applying the emission rate per unit stream/river and basin area to the entire QTP 1 st - to 7 th -order drainage networks, we obtained a riverine N 2 O emission of 0.432–0.463 Gg N 2 O-N yr −1, which is minor (~0.15%) given their areal contribution (0.7%) to global streams and rivers. In addition, these N 2 O estimates are probably overestimated. The emission of N 2 O accumulated underneath the ice during winter was estimated to be 15% of the annual emission. This ice-melt outgassing of winter N 2 O was included in the above annual N 2 O emissions; however, this flux may be very limited in permafrost-affected systems due to minimum N inputs from frozen soils in winter. These alpine permafrost waterways emit large amounts of CH 4, but fortunately they are currently small contributors of N 2 O delivery to the atmosphere, demonstrating CH 4 and N 2 O dynamics are uncoupled within these systems.

---

### Unexpectedly minor nitrous oxide emissions from fluvial networks draining permafrost catchments of the east qinghai-tibet plateau [^54526d2a]. Nature Communications (2022). High credibility.

Regional and global implications

Based on our flux measurements, we estimated that EQTP 3 rd - to 7 th -order streams and rivers emitted 0.206 Gg N 2 O-N yr −1 (5–95 th percentiles: 0.129–0.291 Gg N 2 O-N yr −1, 2603 km 2 of river channel area). Our upscaling did not include 1 st - and 2 nd -order streams, which can contribute disproportionately high areal fluxes to overall fluvial N 2 O emissions. Low-order streams are always well connected to continuous permafrost and hence should receive high N inputs while having reduced N 2 O solubility owing to high altitudes, and these conditions are expected to lead to high N 2 O fluxes. Based on this logic, we estimated a total emission of 0.275 Gg N 2 O-N yr −1 from 1 st - to 7 th -order streams and rivers (5–95 th percentiles: 0.162–0.400 Gg N 2 O-N yr −1, 3049 km 2) by extrapolating the relationship in Fig. 3c to include 1 st - and 2 nd -order streams.

---

### A DNA-based system for selecting and displaying the combined result of two input variables [^98a5cd1c]. Nature Communications (2015). Medium credibility.

If the method should be used to process the input of two biological sequences it would require that X and Y be decoupled to allow input of arbitrary sequences. For this purpose we have introduced a third capture–linker strand as shown in Fig. 3a. This sequence contains two 8-nt domains that are each complementary to the two inputs, and furthermore it contains the capture sequence that allows binding to the MBs. This forms an incomplete four-way junction that is completed by selecting the fully complementary result sequence on the two 8-nt domains on X and Y to form a stable four-way junction. To demonstrate the principle we have used two short synthetic input strands. As shown with native PAGE in Fig. 3b, lane 4, inputs X and Y are independent. In lane 7, inputs X, Y and the capture–linker form a stable complex. In the native PAGE result shown in Fig. 3c, lanes 3 and 4, neither X nor Y alone binds with the result strand. In lane 5, where both X and Y are present, the input complex can bind to the correct result. This means that the correct result is only selected in the presence of both inputs X and Y. In lane 6 it is demonstrated, using three results where only one of the domains is correct, that wrong results do not bind to the input complex. Finally, in lane 7 the correct result is selected in the mixture with three wrong result sequences.

Translation of the results to a seven-segmented display

The mechanism of the output generation proceeds by selection of translator strands that guide the assembled complex to the lines of the digital number that displays the result in a seven-segmented display. As illustrated in Fig. 4 for the simple calculation of 1 × 2 = 2, the result two strands can hybridize with each of the five translator strands that are required to display the number 2. After MB-mediated separation from the solution of translator strands, the result–translator complex is (in most cases) liberated from the MBs and applied to a surface containing a pattern of one or more digital numbers. Each of the lines in the digit is functionalized with a unique host sequence that is complementary to the translator stands a–g. This means that contingent on the selected set of translator strands the digit has the capacity to display all numbers from 0 to 9. The encoding required for displaying the numbers 0–9 is shown in Table 1. A total of 49 translator sequences are required for displaying the 10 numbers in a one-digit display.

---

### Quantum reservoir probing of quantum phase transitions [^30d31acd]. Nature Communications (2025). High credibility.

Statistical treatment in the QRP

From a uniform distribution [0, 1], a set of 256 input values { s k } is sampled. Each input s k produces a distinct initial state, and the dynamics of operatoris subsequently calculated. Among them, instances are designated for training, while the remaining l ts = 128 instances are reserved for testing. Using a 2D vector, the linear transformation for estimating s k is expressed as y i, k (t) = x i, k (t) w i (t), where the weight vector is defined by.

In the training phase, an -dimensional matrixis constructed by summing up the observed dynamics. The output, represented as an-dimensional vector, is calculated as. The weight vector is trained to closely match the outputwith the original input. The optimal solution, which minimizes the least squared error between these vectors, is given bywheredenotes the Moore-Penrose pseudoinverse-matrix of.

In the testing phase, an (l ts × 2)-dimensional matrixis similarly composed, yielding the outputusing the trained weights. The estimation performance is assessed by comparing this testing output with the corresponding inputusing the determination coefficientHere, cov and σ 2 denote covariance and variance, respectively. The coefficientstatistically assesses the extent to which O i (t) is influenced by the local quantum quench parameterized by s k. We have verified that a smaller dataset withand l ts = 100 produces quantitatively similar results.

As explained above, the QRP analyzes the variation of dynamics under different s k values.should ideally be zero when no systematic variations dependent on the input s k are observed. However, in numerical simulations, might accidentally exhibit nonzero values, sensitively reflecting the small deviations incomparable to numerical errors. To avoid this numerical artifact, we introduce a threshold Δ th for the deviation of the operator across different instances. We employ the average absolute deviation Δ i (t), defined asWhen Δ i (t) is negligibly small, calculated from the above 〈 O i (t)〉 should approach zero. We thus manually setwhen Δ i (t) < Δ th; we utilize Δ th = 10 −5, and Δ th dependency is presented in the Supplementary Information. This procedure does not qualitatively alter our methodology and is experimentally feasible.

---

### Estimating the strength of selection for new SARS-CoV-2 variants [^28c4a7a1]. Nature Communications (2021). High credibility.

Diffusion approximation of the epidemic model

The exact simulation of the Markov jump process (MJP) that defines our stochastic epidemic model is very computationally intensive. We therefore switch to a diffusion approximation of the MJP when population sizes become large in order to do inference more efficiently. This formalism allows us to incorporate two sources of noise. The first being the process noise inherent to the MJP, which becomes negligible when the sizes of the compartments are large. We therefore introduce a second noise term that captures other origins of stochasticity that the MJP cannot account for and acts on predominantly large population sizes.

As above, we denote the state of the n -dimensional model (where n = 7) by X i (t) with i = 1,…, n. The discrete, stochastic model is defined by k = 9 state transitionswhereis the increment of the j th transition. For instance, the transition H → R corresponds to the increment (0,…, 0, −1, 1). Using the Kramers–Moyal expansion of the master equation, the MJP is mapped to a system of stochastic differential equations (SDE) that can be derived from the transitions η j and increments ε j as follows:where B t is a 9-dimensional Brownian motion, corresponding to the 9 transitions of the MJP in Eq. (5). The SDE in Eq. (9) is of the form d X = μ (X, t)d t + σ (X, t)d B t, where μ and σ describe the drift and volatility, respectively. The volatility matrix σ (X, t) encodes the intrinsic noise of the MJP, which is negligible compared with X when X is large. We therefore add a small second noise term to the system of SDEs that is proportional to X. After this adjustment, the SDE becomeswhereis a n -dimensional Brownian motion, independent of B t. The parameter τ ≪ 1 determines the magnitude of the additional noise term.

In Supplementary Methods, we further describe in detail the algorithm used to switch from a discrete (MJP) to a continuous (SDE) model, and the way the initial condition of the system is determined.

---

### Targeted time-varying functional connectivity [^18c74ca3]. Human Brain Mapping (2025). Medium credibility.

2.2.1 Data Description

We synthetically generated two sets of timeseries, X and Y, which relate to each other through a regression model where X correspond to the regressors and Y to the responses. The nature of such regression had a changing relationship over time. With respect to the regressors, X is a matrix with p channels sampled under two different scenarios. In the first scenario, X is sampled from a covariance‐based HMM, such that the covariance across regions changes over time according to state time courses that were also sampled randomly. In our tests, the number of regions in X ranged from 1 to 25; we sampled 1000 trials (500 trials per condition) of 100 time points each trial. In the second scenario, X comprised timeseries from 11 cortical networks from resting‐state 7 T‐fMRI data, obtained from a larger dataset, used in the real data experiments (see below). Here, the number of predictor variables, p, was set to vary from 1 to 11, as we randomly selected a subset of these cortical network timeseries.

In either case, we then sampled Y, with one (q = 1) channel only, using another HMM model (of note, with different state time courses than those of the generation of X in the first scenario just described). This HMM model was a T‐TVFC model, with condition‐specific and state‐dependent regressors. The state time courses of this HMM were generated for K = 5 states, such that states followed one another in sequence for all trials (i.e. from state 1 to K), and stayed active for approximately equal time; however, we introduced some temporal variability across trials regarding the onset and offset of the states. Each state was endowed with a randomly generated matrix of (𝑝 by 𝑞) regression coefficients β, defining distinct X ‐to‐ Y relationships. To introduce variability between task conditions, we manipulated the relationship between X and Y for a specific state. In particular, we induced differences in β for state 2 by adding independent normally‐distributed noise for each condition. Finally, we added normally distributed noise to Y, to achieve various degrees of signal‐to‐noise ratio; specifically, the standard deviation of the noise was a factor ranging from 0.001 to 0.2 of the standard deviation of the signal (which is given by X β).

---

### Alternating look-locker for quantitative T, tand B3D MRI mapping [^40039e1a]. Magnetic Resonance in Medicine (2024). Medium credibility.

Purpose

To develop a new MRI method, entitled alternating Look-Locker (aLL), for quantitative < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math >, < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mrow > < mml:mn > 1 < /mml:mn > < mml:mi > ρ < /mml:mi > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_{1\uprho} $$ < /mml:annotation > < /mml:semantics > < /mml:math >, and < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > B < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {B}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > 3D mapping.

Methods

A Look-Locker scheme that alternates magnetization from +Z and -Z axes of the laboratory frame is utilized in combination with a 3D Multi-Band Sweep Imaging with Fourier Transformation (MB-SWIFT) readout. The analytical solution describing the spin evolution during aLL, as well as the correction required for segmented acquisition were derived. The simultaneous < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > B < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {B}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > and < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > mapping are demonstrated on an agar/saline phantom and on an in-vivo rat head. < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mrow > < mml:mn > 1 < /mml:mn > < mml:mi > ρ < /mml:mi > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_{1\uprho} $$ < /mml:annotation > < /mml:semantics > < /mml:math > relaxation was achieved by cyclically applying magnetization preparation (MP) modules consisting of two adiabatic pulses. < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mrow > < mml:mn > 1 < /mml:mn > < mml:mi > ρ < /mml:mi > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_{1\uprho} $$ < /mml:annotation > < /mml:semantics > < /mml:math > values in the rat brain in-vivo and in a gadobenate dimeglumine (Gd-DTPA) phantom were compared to those obtained with a previously introduced steady-state (SS) method.

Results

The accuracy and precision of the analytical solution was tested by Bloch simulations. With the application of MP modules, the aLL method provides simultaneous < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > and < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mrow > < mml:mn > 1 < /mml:mn > < mml:mi > ρ < /mml:mi > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_{1\uprho} $$ < /mml:annotation > < /mml:semantics > < /mml:math > maps. Conversely, without it, the method can be used for simultaneous < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > and < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > B < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {B}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > mapping. < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mrow > < mml:mn > 1 < /mml:mn > < mml:mi > ρ < /mml:mi > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_{1\uprho} $$ < /mml:annotation > < /mml:semantics > < /mml:math > values were similar with both aLL and SS techniques. However, the aLL method resulted in more robust quantitative mapping compared to the SS method. Unlike the SS method, the aLL method does not require additional scans for generating < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > maps.

Conclusion

The proposed method offers a new flexible tool for quantitative mapping of < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math >, < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > T < /mml:mi > < mml:mrow > < mml:mn > 1 < /mml:mn > < mml:mi > ρ < /mml:mi > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_{1\uprho} $$ < /mml:annotation > < /mml:semantics > < /mml:math >, and < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mi > B < /mml:mi > < mml:mn > 1 < /mml:mn > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {B}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math >. The aLL method can also be used with readout schemes different from MB-SWIFT.

---

### Direct measurement of large-scale quantum States via expectation values of non-hermitian matrices [^f8699c5e]. Nature Communications (2016). Medium credibility.

In quantum mechanics, predictions are made by way of calculating expectation values of observables, which take the form of Hermitian operators. Non-Hermitian operators, however, are not necessarily devoid of physical significance, and they can play a crucial role in the characterization of quantum states. Here we show that the expectation values of a particular set of non-Hermitian matrices, which we call column operators, directly yield the complex coefficients of a quantum state vector. We provide a definition of the state vector in terms of measurable quantities by decomposing these column operators into observables. The technique we propose renders very-large-scale quantum states significantly more accessible in the laboratory, as we demonstrate by experimentally characterizing a 100,000-dimensional entangled state. This represents an improvement of two orders of magnitude with respect to previous phase-and-amplitude characterizations of discrete entangled states.

---

### Protein sequence modelling with Bayesian flow networks [^7d765a30]. Nature Communications (2025). High credibility.

Box 2 Reconstructed ODE sampling

1: Input: N steps, output network

2: Output: generated sample x

3: z ~ N (0, I)

4: y (0) ← 0

5: for i = 0… N do

6:

7:

8:

9: β (s) ← β 1 s 2

10:

11: end for

12:

13:

14: return x

Inpainting

Consider the task of inpainting some sequence x according to a binary mask m ∈ [0, 1] D where m i = 0 indicates that the i th element of x should be used as conditioning information, and m i = 1 indicates that the i th element of x should be inpainted. Inspired by SMCDiff, we treat conditional generation of the inpainted regions as a sequential Monte Carlo problem which we may solve with particle filtering. Given an output network ϕ and input distribution θ (t) at time t, the KL divergence of the sender and receiver distributions, with accuracy α, for the conditioning subset x m is, which we will denote D (x, m, θ (t), α). Given q particles at time t with input distributions, we resample each particle with probability proportional to. Combining SMC with our sampling method, we arrive at the algorithm detailed in Box 3.

Box 3 Greedy SMC inpainting

1: Input: N steps, output network, q particles, conditioning information x m

2: Output: conditionally generated sample x

3:

4:

5: for i = 0… N do

6:

7:

8: β (t) ← β 1 t 2

9: β (s) ← β 1 s 2

10: α ← β (s) − β (t)

11:

12:

13:

14:

15: end for

16:

17:

18: return x

Pre-training ProtBFN

---

### Two spatiotemporally distinct value systems shape reward-based learning in the human brain [^c0840d0e]. Nature Communications (2015). Medium credibility.

We quantified the performance of the discriminator for each time window using the area under a receiver operating characteristic curve, referred to as an A z value, using a leave-one-out trial procedure. To assess the significance of the discriminator, we used a bootstrapping technique where we performed the leave-one-out test after randomizing the trial labels. We repeated this randomization procedure 1,000 times to produce a probability distribution for A z, and estimated the A z leading to a significance level of P < 0.01. In addition, we implemented a separate temporal-clustering procedure using a similar randomization test. Specifically, we repeated the procedure above, each time identifying the maximum number of continuous time steps surviving the A z significance threshold found with the original bootstrapping technique described above. This in turn enabled us to produce a null distribution for the maximum number of continuous temporal windows and estimate a temporal cluster size leading to a significance level of P < 0.05 (individually for each participant, average temporal cluster threshold: 4.7 time steps ± 2.1).

Given the linearity of our model, we also computed scalp topographies of the discriminating components resulting from equation (1) by estimating a forward model as:

where y i (τ) is now shown as a vector y (τ), where each row is from trial i, and x i (τ) is organized as a matrix, x (τ), where rows are channels and columns are trials, all for time window τ. These forward models can be viewed as scalp plots and interpreted as the coupling between the discriminating components and the observed EEG. Code for the linear discriminant analysis described above is available at:

To visualize the temporal profile of the resultant discriminating components across individual trials, we also constructed discriminant component maps (as seen in Fig. 1c). To do so, we applied the spatial weighting vectors, w (τ) from a time window, τ, which led to significant discrimination performance between positive versus negative outcomes, to an extended time window (100 ms before until 600 ms after the outcome). Each row of one such discriminant component map represents a single trial across time (see, for example, Fig. 1c).

---

### Comprehensive profiling of the ligand binding landscapes of duplexed aptamer families reveals widespread induced fit [^adede41f]. Nature Communications (2018). Medium credibility.

Design of ACE-Scan microarrays

ACE sequences on the DNA microarray were designed using MATLAB scripts (Mathworks, Natick, Massachusetts, USA, Additional Information). ACE sequences of differing lengths and/or incorporating single mismatches were designed to scan across the entire length of a desired aptamer sequence. The number of possible ACE sequences scales combinatorially; for an aptamer of length L, the number of perfect match ACEs of a given length N is:The total number of perfect match ACEs up to a length of Y (> 0 & ≤ L) scales with the product of L and Y :Likewise, the number of perfect match ACEs between lengths X (> 0 & ≤ Y) and Y (> 0 & ≤ L) scales with the product of L and (Y − X):The number of possible single mismatched ACEs for ACEs of a given length Y scales with the product of L and Y :The number of possible single mismatched ACEs for ACEs up to a length of Y scales with the product of (L − Y) and Y 2 :Likewise, the total number of single mismatched ACEs for ACEs between lengths X (> 0 & ≤ Y) and Y (> 0 & ≤ L) scales with the product of (L − Y) and (Y 2 − X 2):Microarrays were commercially fabricated by MYcroarray (Ann Arbor, Michigan, USA), based on custom 6 × 7k DNA microarrays designs and 3ʹ-to-5ʹ light-directed synthesis on glass slides with surface densities of 10 12 to 10 9 reactive amines mm −2. All ACEs on the microarray were synthesized with an additional 3ʹ T 25 spacer to minimize any influence of the slide surface on aptamer hybridization and DA dissociation. The location of synthesized ACEs on the microarray surface was randomized within a sub-array, and all sub-arrays were synthesized with identical layouts. Depending on the aptamer under study, up to 1400 ACEs varying in ACE length, location, and complementary, with 5–8 replicate probes for each ACE, were synthesized per sub-array. For some ACE-Scan microarrays, ACEs with an additional 5ʹ T 10 linker (T 35 total linker length), or 3ʹ T 10 -extended ACEs, were included in the microarray design.

---

### Physical descriptor for the gibbs energy of inorganic crystalline solids and temperature-dependent materials chemistry [^49687180]. Nature Communications (2018). Medium credibility.

Descriptor identification

The SISSO approachwas applied to identify the descriptor for G δ shown in Eq. (3) using 262 of the 309 compounds from FactSage with experimentally measured G δ. To identify this descriptor an initial feature-space, Φ 0, included 19 features — the five tabulated elemental properties mapped onto each of the three functional forms (Eqs. 5–7), along with the linear forms of atomic volume, band gap, formation enthalpy, and temperature. Two iterations of descriptor construction were performed using an operator space of [+, −, |−|, *, /, exp, ln, −1, 2, 3, 0.5]. Candidate descriptors were constructed by iteratively applying these operators to Φ 0 while conserving the units of constructed features. The first iteration of descriptor construction yielded a space, Φ 1, with ~600 candidate descriptors and the second iteration a space, Φ 2, of ~600,000 candidate descriptors. SISSO was then performed on Φ 2 with a subspace size of 2,000 and three descriptor identification iterations, thereby producing the three-dimensional (3D) descriptor (i.e. three fit coefficients not including the intercept) in Eq. (4). In the first iteration, sure independence screening (SIS) was used to select the 2,000 descriptors S 1D from Φ 2 having the highest correlation with G δ. Within S 1D,-norm regularized minimization, SO, was used to identify the best 1D descriptor. This 1D descriptor is then used to predict the training set and the array of residuals, R 1, is generated from this prediction. Now with R 1 as the target property (instead of G δ), SIS identifies a new subspace S 2D of 2,000 additional descriptors. SO then selects the best-performing 2D descriptor from S 1D ∪ S 2D and R 2 is generated as the residuals using this 2D descriptor to predict the training set. This procedure is repeated a third time to yield the 3D descriptor shown in Eq. (4). Therefore, this descriptor is selected among a space ofor ~3 × 10 10 candidate 3D descriptors.

---

### Fundamental limits to learning closed-form mathematical models from data [^a345300f]. Nature Communications (2023). High credibility.

Given a finite and noisy dataset generated with a closed-form mathematical model, when is it possible to learn the true generating model from the data alone? This is the question we investigate here. We show that this model-learning problem displays a transition from a low-noise phase in which the true model can be learned, to a phase in which the observation noise is too high for the true model to be learned by any method. Both in the low-noise phase and in the high-noise phase, probabilistic model selection leads to optimal generalization to unseen data. This is in contrast to standard machine learning approaches, including artificial neural networks, which in this particular problem are limited, in the low-noise phase, by their ability to interpolate. In the transition region between the learnable and unlearnable phases, generalization is hard for all approaches including probabilistic model selection.

---

### A.S.P.E.N. parenteral nutrition safety consensus recommendations [^88274706]. JPEN: Journal of Parenteral and Enteral Nutrition (2013). Medium credibility.

Prescribing 4 (P4) — parenteral nutrition (PN) order reordering and monitoring states that an institution-specific or organization-specific policy should be created to dictate the duration of a PN order, and when reordering PN, each PN component should be reordered in its entirety, including full generic names and doses; patients with newly initiated PN should be monitored and have their orders reviewed more frequently, and the reordering process should be structured to require accountability for reviewing the orders, laboratory findings, and patient's condition, while simple processes such as a single-step "renew order" button that lack accountability should not be used; monitoring examples are that patients who are new to PN should be monitored daily until stable (more frequently if clinically significant metabolic abnormalities are found or patient is at risk for refeeding syndrome), patients in an unstable clinical condition should be monitored daily until stable (more frequently if clinically significant abnormalities are observed), stable patients in the hospital with required changes in formulation for 1 week should be monitored every 2 to 7 days, and stable patients in a hospital, long-term care, or home setting with no changes in formulation for more than 1 week should be monitored every 1 to 4 weeks or longer in select clinically stable patients.

---

### Active discovery of organic semiconductors [^add76c20]. Nature Communications (2021). High credibility.

Fig. 2
Finite OSC test space.

Left panel: Chemical space network (CSN) representation of the finite OSC test space of 65.552 unique molecules generated by exhaustive application of all morphing operations up to 14 times. Each molecule is surrounded by morphing-related analogs (see text). Benzene as the smallest base molecule is colored in blue. All other molecular nodes are colored according to their fitness function F as calculated at the semi-empirical density-functional tight-binding level. 2438 red nodes form the target discovery group of top-performing molecules with high fitness F ≥ −0.2. Right panel: Example molecules from the top-performing group, chosen randomly from different areas of the CSN to illustrate the structural diversity contained in the test space.

The finite test space contains a total of 2438 top-performing molecules with a high fitness F ≥ −0.2. As a quantitative benchmark, we thus measure the discovery success S (N) as the fraction of these molecules that are identified after the descriptors of N molecules have been queried. With 179 queries used for the initialization, see above, the final measure S (5179) thus evaluates the discovery success after n = 50 learning steps when using N batch = 100. Supplementary Fig. 6 compiles the corresponding success curves S (N), when systematically combining N batch = 50, 100, or 200 with κ values in half-integer steps between 0 and 5, as well as for a search depth of one- or two-time exhaustive application of all morphing operations. Fortunately, we find the AML search to be highly robust with respect to the choice of N batch and κ. Only a small variation of 0.71 < S (N = 5179) < 0.80 is obtained over all tested combinations for a search depth of one, meaning that 70–80% of the top-performing molecules are consistently found after descriptors for less than 8% of the entire test space have actually been computed. For a search depth of two, this success rate becomes slightly higher, reaching up to 85% as compiled in Supplementary Fig. 7. Generally, larger batch sizes seem to implicitly increase the explorative behavior, such that an almost indistinguishably optimum performance is obtained for larger N batch in combination with successively smaller exploration weights κ in the acquisition function, cf. Eq. (2). For too small κ, the success curves become stepped though, indicating that temporarily the mainly exploitative algorithm then only meanders through identified sub-pockets of the test space. Too large κ, on the other hand, diminish the initial success of a then too explorative algorithm in the first learning steps. Overall, an intermediate value pair (N batch, κ) = (100, 2.5) thus provides a robust setting and is henceforth employed in all AML runs. For these values of (N batch, κ), we also performed a sensitivity analysis with regard to the employed weight vector w in Eq. (1) and the bond radius in the Morgan fingerprints used to assess molecular similarity. The results are summarized in Supplementary Figs. 8 and 9, respectively, and again demonstrate a high robustness with respect to these parameters.

---

### Influence maximization in boolean networks [^111568fd]. Nature Communications (2022). High credibility.

Entropy of network configurations

We measure the uncertainty of a Boolean network as the normalized entropy of the probability distribution associated to its possible configurations, namelywith h 2 (s) binary entropy function, i.e. Please note that Eq. (7) approximates the true entropy of the system from the above, as it assumes independence among the dynamical variables of the individual nodes. We note that. Maximum entropy is reached for s i = 1/2 for all i. Null entropy is measured for deterministic configurations s i = 0, 1 for all i.

Definition of seed set

We define the set of seed nodesas the set of nodes and their known, invariant, states, i.e.for alland for all t ≥ 0. Please note that we tacitly assumed that node i may contribute at max one element to the set, as eitheror.

The state of all nodes not belonging to the setis uncertain, i.e. 0 ≤ s i (t) ≤ 1 for all. Unless noted otherwise, we focus our attention to the case of maximal uncertainty for the initial state of the non-pinned nodes, i.e. s i (0) = 1/2 for all. The probability of starting from the configurationgivenstill obeys Eq. (3), with the additional constraint thatfor.

Influence maximization

We propose a greedy algorithm for the quasi-optimal selection of the smallest set of nodes that should be pinned in order to control the dynamics of a Boolean network toward zero entropy. As in standard greedy optimization techniques, our strategy consists in pinning one node at each stage of the algorithm; the selected seed is the best choice that can be made at that particular stage of the optimization algorithm.

Indicate withthe set of pinned nodes at the v -th stage of the algorithm. We initialize the algorithm at stage v = 0 with. Then, we set v = 1 and follow the procedure:
Select the best seedof stage v of the algorithm according to
Addto the set of pinned nodes, i.e.
Increase v → v + 1, and go back to point 1.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^cbffc27e]. CDC (2011). Medium credibility.

Appendix G. Mathematical formula for sample size — sample size required to detect the difference of GM between two subpopulation groups defines a z test with null hypothesis GM1 = GM2 or GMmax/GMmin = 1 and alternative GM1 ≠ GM2 or GMmax / GMmin > 1, where GMmax = max(GM1, GM2) and GMmin = min(GM1, GM2). It considers power W (say 80% chance) to detect that one group's GM is at least k fold higher and gives the p-value as p = Prob(Z ≥ z) = 1 − φ−1(z) with Z ~ Normal (0,1). Given α (e.g., 0.05) and target ratio k, power is W = Prob (Z > φ−1(1 − α) − log10(k)/(S√(1/n1 + 1/n2))), where S is the expected standard deviation of log10(VL) in the population of interest; when n1 = n2 = n, W = Prob (Z > φ−1(1 − α) − log10(k)/(S√(2/n))). The required sample size is n = 2[(φ−1(1 − α) − φ−1(1 − W))S/log10(k)]^2, and tables are provided for W = 0.8 and W = 0.9 with α = 0.05.

---

### Asymmetric synthesis of tetrazole and dihydroisoquinoline derivatives by isocyanide-based multicomponent reactions [^31da22bc]. Nature Communications (2019). High credibility.

Substrate scope of 1,2-dihydroisoquinoline derivatives

As illustrated in Fig. 1b, the nucleophilic addition of isocyanides to polar C = X or C = C bonds affords zwitterionic intermediates, which theoretically could be used as 1,3-dipoles. However, comparing with classic Passerini and Ugi reactions, where these zwitterionic intermediates were captured by carboxylic acid, the utility of these species in cycloaddition reactions is rather limited. To the best of our knowledge, only sporadic racemic versions of such reactions were reported to date –. Encouraged by the good performance of our chiral Mg II - N, N ′-dioxide Lewis acid catalyst for the synthesis of 1,5-disubstituted tetrazole derivatives, we assumed if the zwitterionic intermediate I was captured by imine, another hetereo-cyclic amidine-type of product could be obtained. Many kinds of combinations with different electrophiles, isocyanides, and dipolarophiles were tested. The trick is how to control a cascade of elementary chemical reactions occurring in a uniquely ordered manner, since two reactants are electrophiles. It should be a better choice if the reactivity of dipolarophile is lower than the electrophile for the isocyanide-initiated addition step. Finally, phenyl-substituted alkylidene malonate 3o, isoquinoline 7a, and tert -butyl isocyanide 1e were employed in the model reaction to optimize the reaction conditions. We are glad to find that by slight modification the four-component reaction conditions as Mg(OTf) 2 / L-RaPr 2 (1.2/1.0, 10 mol%) in CH 2 ClCH 2 Cl (0.5 mL) at 35 °C for 2 days, the desired cycloaddition product 8a was produced as a single diastereomer in 85% yield with 96.5:3.5 e.r. (for details, see Supplementary Tables 7–9). Under such conditions, the substrates with respect to alkylidene malonates were evaluated. As shown in Fig. 4, a broad range of alkylidene malonates bearing different ester groups or β-aryl substituents reacted smoothly to deliver the corresponding products with good yields and high enantioselectivities (8a – 8h; 79–93% yield, 92:8–97:3 e.r.). Comparatively, aliphatic aldehyde-derived alkylidene malonate was less efficient, yielding 8t in much lower yield and enantioselectivity (21% yield, 77:23 e.r.). On the other hand, other substituted isoquinolines were suitable as well regardless of electronic nature of the substitutions. The desired cycloaddition products (8i – 8p) were isolated in excellent enantioselectivities (96:4–99:1 e.r.) with slightly lower yields (40–72%). Next, the screening of isocyanides implied that the steric hindrance exhibited a considerable effect on the e.r. values of the product; the more bulk 1-adamantanyl isocyanide gave 98:2 e.r. while the less bulk isocyanides afford the product (8r and 8s) with much lower enantioselectivities. In addition, switching to aromatic isocyanide resulted in a rapid drop of e.r. value (8r). The absolute configuration of the product 8a was determined to be (2 S, 10b S, E) by single-crystal X-ray diffraction analysis. It should be noted that this transformation was a simultaneous dearomative process of isoquinolines, delivering fused polycyclic 1,2-dihydroisoquinoline-based amidine derivatives with a single diastereomer in all cases.

---

### Efficient learning for linear properties of bounded-gate quantum circuits [^eb35491d]. Nature Communications (2025). High credibility.

Fig. 2
Numerical results of predicting properties of rotational 60-qubit GHZ states.

a Two-point correlation. Exact values and ML predictions of the expectation value of the correlation function C i j = (X i X j + Y i Y j + Z i Z j)/3 for all qubit pairs of 60-qubit GHZ states. The node's color indicates the exact value and predicted value of the two subplots, respectively. b, c PREDICTION ERROR. Subplot (b) depicts the root mean squared (RMS) prediction error of the trained ML model with varied truncation Λ and number of training examples n. Subplot (c) shows the RMS prediction error of the trained ML model with varied truncation Λ and the shot number T. The setting Λ = 3 refers to the full expansion.

We next apply the proposed ML model to predict properties of the state evolved by a global Hamiltonian, where J 1 is a predefined constant and the qubit count is set to N = 60. The initial state isand U (x) is the Trotterized time evolution of. By properly selecting the evolution time at each Trotter step and J 1, the Trotterized time-evolution circuit takes the form. We set the total number of Trotter steps as d = 1. At the training stage, we constitute the datasetfollowing the same rule presented in the last simulation. The only difference is the dataset size and the shot number, which are n = 20 and T = 500. The task is predicting the magnetization with.

The comparison between the exact value and the prediction with Λ = 1 (full expansion) is shown in Fig. 3 a. We select 25 test examples evenly distributed across the interval. By increasing the number of training examples n from 10 to 20, the prediction values of the proposed ML model almost match the exact results.

---

### Guidelines for handling decedents contaminated with radioactive materials [^3c500666]. CDC (2007). Medium credibility.

Rule of Seven for radiation dose rates — fallout dose rate after a detonation can be calculated and estimated as follows: "Dose rate = Initial dose rate x t -1.2", and "the dose rate decreases by a factor of 10 for each sevenfold increase in time following a fission detonation"; this rule "is valid for only the first 2 weeks after a detonation", and "rain accelerates the decrease". Table values indicate percentage of initial dose rate remaining of 100% at 0 hour, 10% at 7 hours, 1% at 49 hours (2 days), and 0.1% at 343 hours (14 days).

---

### Unexpectedly minor nitrous oxide emissions from fluvial networks draining permafrost catchments of the east qinghai-tibet plateau [^9955211a]. Nature Communications (2022). High credibility.

Physicochemical processes governing N 2 O dynamics

To understand potential controls on N 2 O fluxes, we used stepwise regression to assess the relationships betweenand multiple environmental variables known to influence. The analysis showed that %O 2, pH, water temperature, total phosphorus, and NO 3 − all had significant but weak relationships with(P < 0.001, R 2 = 0.14; Supplementary Table 8).

Local hydrogeomorphology is, at least qualitatively, a reliable predictor ofdownstream trends. Along the longitudinal continuum, was highest in 3 rd -order (headwater) streams, declined in 4 th - and 5 th -order (medium-sized) rivers, and was slightly elevated in 6 th - and 7 th -order (large) rivers (Fig. 3c). The decline in flux from 3 rd - to 5 th -order streams may reflect the reduced perimeter-to-surface-area ratio (ratio of wetted perimeter to cross-sectional area) and hyporheic exchange rates (exchange rates of dissolved substances between surface water and groundwater beneath and alongside the river channel) with increasing stream order –, while the increase in 6 th - and 7 th -order sites might be due to increasing riverine DIN concentrations(Supplementary Fig. 4). Furthermore, increased suspended sediment loads can enhance N 2 O generation in larger turbid channels, as suspended particles provide micro-niches that support N transformations, and thus facilitate N 2 O production in the water column. Suspended sediment concentration increased with stream order for these rivers, lending support to the hypothesis that this mechanism contributes to higher fluxes observed in 6 th - and 7 th -order channels.

---

### LassoPred: a tool to predict the 3D structure of lasso peptides [^dc58e314]. Nature Communications (2025). High credibility.

To develop the isopeptide classifier, we first converted each sequence of N amino acids into N overlapping peptide fragments, resulting in a total of 905 fragments. We then labeled each dipeptide fragment as '0', '1', or '2', where '1' indicates residues within the ring, '0' marks the ring-loop boundary (i.e. the position of the isopeptide-donating residue), and '2' corresponds to residues in the loop or tail. Since the isopeptide-donating residue must be Glu or Asp that is located at the 7 th, 8 th, or 9 th positions (prior knowledge derived from all known lasso peptide structures), we leveraged only the peptide fragments containing residues between the 6 th and 10 th position of each LaP sequence for training the isopeptide classifier (Fig. 3A). Using dipeptide fragments and ESM2 L33 embedding, the isopeptide classifier achieves strong predictive performance in classifying the peptide fragments into one of the three categories, featuring a ROC AUC of 0.97 ± 0.03, a fragment classification accuracy of 0.91 ± 0.06, and a fragment classification F1 score of 0.90 ± 0.08 across 100 splits. The reconstruction process determines the isopeptide position by identifying the dipeptide fragment with the highest likelihood of being labeled as '0' (the ring-loop boundary). As a result, the isopeptide classifier achieves a nearly perfect accuracy for identifying the isopeptide-donating residue (accuracy: 1.00 ± 0.02), with only 1 out of 100 splits failing to reach 100% accuracy. The high accuracy of the isopeptide classifier is expected because the isopeptide position can be identified merely by finding Glu or Asp located at the 7 th, 8 th, or 9 th positions in 42 out of the 47 LaP sequences curated from PDB, giving a baseline accuracy of 0.89.

---

### A transient high-dimensional geometry affords stable conjunctive subspaces for efficient action selection [^e798c21c]. Nature Communications (2024). High credibility.

How the convergence of neural dynamics influences successful action selection is difficult to assess without any constraints on the encoding of neural trajectories for task computations. For example, slow responses may reflect failures of readout of task representations or strategic withholding for the stabilization of dynamics. In addition, the passage of time is often confounded with temporal stabilization of dynamics as in the cases in typical delayed maintenance tasks. The current study's use of the response-deadline procedure circumvents these issues by forcing participants to use the product of dynamic computations at premature or developed states.

By assessing the temporal generalizability of linear hyperplanes that separate conjunctions defined by the combination of task basis features, we found that neural trajectories in the conjunctive subspace became relatively stable toward the moment that responses are executed (Fig. 8). Importantly, the gradual expansion of representational dimensionality peaked while the underlying dynamics were stable when accurate and on-time responses were achieved. In contrast, such temporally stable dynamics emerged at much later time windows when responses were incorrect or too late (see Supplementary Figs. S12, S13 for the results for other task factors).

Fig. 8
Representational dynamics in the subspace of conjunctive control representations.

Temporal generalization of linear hyperplanes that separate conjunctions of task basis features summarized as a decoding matrix. The X -axis denotes time points where signals were sampled to train decoders and then submitted to single-trial RSA. The Y -axis denotes time points where the test sets were derived. Thus, the diagonal components of the matrix correspond to trajectories of time-resolved decoding analyses, as shown in Fig. 4. The off-diagonal components show the results of temporal generalization analysis. The regions surrounded by a white contour denote the significant clusters using a nonparametric permutation test (cluster-forming threshold, p < 0.01, cluster-significance threshold, p < 0.01, two-tailed). The top panel shows changes in the representational dimensionality relative to the onset of responses (Fig. 7 bottom row) merging short and medium SOA conditions. The middle panel plots temporal generalization for correct responses, and the bottom panel plots temporal generalization for incorrect or too-late responses. Shaded regions of the top panel specify within-subject standard errors.

---

### The snm procedure guideline for general imaging 6.0 [^fe5858aa]. SNMMI (2010). Medium credibility.

Single photon planar imaging — scintillation camera peaking should be performed correctly for the energy or energies to be used at least daily, typically using a 15 or 20% energy window; the window is placed symmetrically about the peak, or asymmetrically if an appropriate energy correction is available, and a physicist can help determine limits of asymmetry for a range of energies.

---

### The snm procedure guideline for general imaging 6.0 [^85398c18]. SNMMI (2010). Medium credibility.

Nuclear medicine computer system components — The camera head or associated image processing system performs functions including image size, position and zoom; energy correction; spatial distortion correction; other corrections (scatter correction, dead time correction, depth of interaction correction, sensitivity correction); and digital position computation; the interface handles the data in two basic modes: 1) Frame mode: complete images or matrices are available to the attached computer; and 2) List mode: data are passed on to the attached computer as a list of event x, y coordinates, to which time information and energy information may be also attached; for cardiac studies in particular, time lapse averaging is required, such that each image acquired at some specific time within the cardiac cycle is added to other acquired at similar times.

---

### The snm procedure guideline for general imaging 6.0 [^ca75ae44]. SNMMI (2010). Medium credibility.

Dynamic imaging — time per frame should be selected based on temporal resolution needs; for quantitative functional studies, shorter times are preferred to measure rapidly changing physiologic parameters, whereas longer times are generally used when imaging statistics for each frame are being optimized. For computer acquired images, a matrix size of 64 x 64 or 128 x 128 may be suitable depending on the type of study, and if there is any question, word mode should be used to avoid pixel saturation that may occur in byte mode after choosing between word (often two-byte) and byte mode acquisitions. For high-count rate studies, dead time effects may be important and count rate loss should be ascertained by dead time measurements.

---

### The snm procedure guideline for general imaging 6.0 [^c226f5ab]. SNMMI (2010). Medium credibility.

Pinhole imaging — smaller pinhole apertures (2 to 3 mm) provide better resolution but lower sensitivity, and the largest pinhole in routine clinical use is 5 mm; for typical collimators with a 25 cm diameter field of view, a matrix size of 256 x 256 or 128 x 128 is generally sufficient.

---

### Statistical method scDEED for detecting dubious 2D single-cell embeddings and optimizing t-SNE and UMAP hyperparameters [^aa1836c5]. Nature Communications (2024). High credibility.

Step 5. Based on the permuted data before and after the 2D embedding, scDEED applies the same procedure in Step 4 to obtain the null reliability scores of the n cells. Because of the permutation, the similarities among cells are disrupted, and no biological neighboring relationships are preserved by the 2D embedding. Hence, each cell's neighbors are purely determined by random chance, and its reliability score reflects the random agreement between its ordered neighbors before and after the 2D embedding. Leveraging the n null reliability scores, scDEED finds the thresholds for calling a cell's reliability score low or high.

Step 6. scDEED defines dubious cell embeddings as the embeddings of the cells whose reliability scores are less than or equal to the 5-th percentile of the n null reliability scores. On the other end, scDEED defines trustworthy cell embeddings as the embeddings of the cells whose reliability scores are greater than or equal to the 95-th percentile of the n null reliability scores.

After the above steps, scDEED reports the number of dubious cell embeddings given a parameter setting. From a grid search of candidate hyperparameter settings, scDEED finds the setting that minimizes the number of dubious cell embeddings.

In the scDEED R package, the following candidate hyperparameter values are set by default, but users can specify their own candidate hyperparameter values. For t-SNE, the default candidate perplexity values are 20, 50,…, 380, 410, 450, 500,…, 750, and 800. For UMAP, the default n.neighbors values are 5, 6,…, 29, 30, 35, 40, 45, and 50; the default min.dist values are 0.0125, 0.05, 0.1, 0.2,…, 0.7, and 0.8.

---

### Efficient learning of ground and thermal States within phases of matter [^c7a60b05]. Nature Communications (2024). High credibility.

We consider two related tasks: (a) estimating a parameterisation of a given Gibbs state and expectation values of Lipschitz observables on this state; (b) learning the expectation values of local observables within a thermal or quantum phase of matter. In both cases, we present sample-efficient ways to learn these properties to high precision. For the first task, we develop techniques to learn parameterisations of classes of systems, including quantum Gibbs states for classes of non-commuting Hamiltonians. We then give methods to sample-efficiently infer expectation values of extensive properties of the state, including quasi-local observables and entropies. For the second task, we exploit the locality of Hamiltonians to show that M local observables can be learned with probability 1 - δ and precision ε using < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:mi > N < /mml:mi > < mml:mo ≥ < /mml:mo > < mml:mi > O < /mml:mi > < mml:mfenced > < mml:mrow > < mml:mi > log < /mml:mi > < mml:mfenced > < mml:mrow > < mml:mfrac > < mml:mrow > < mml:mi > M < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mi > δ < /mml:mi > < /mml:mrow > < /mml:mfrac > < /mml:mrow > < /mml:mfenced > < mml:msup > < mml:mrow > < mml:mi > e < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mi > polylog < /mml:mi > < mml:mrow > < mml:mo > (< /mml:mo > < mml:mrow > < mml:msup > < mml:mrow > < mml:mi > ε < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mo > - < /mml:mo > < mml:mn > 1 < /mml:mn > < /mml:mrow > < /mml:msup > < /mml:mrow > < mml:mo >) < /mml:mo > < /mml:mrow > < /mml:mrow > < /mml:msup > < /mml:mrow > < /mml:mfenced > < /mml:math > samples - exponentially improving previous bounds. Our results apply to both families of ground states of Hamiltonians displaying local topological quantum order, and thermal phases of matter with exponentially decaying correlations.

---

### Low-dimensional encoding of decisions in parietal cortex reflects long-term training history [^3a520044]. Nature Communications (2023). High credibility.

We considered a set of four nested models of increasing complexity for the motion stimuli. For simplicity of notation, we present the linearization for a single trial. The sample stimulus onset time is t sample on and the test stimulus onset is t test on. The sample and test stimulus directions are θ sample and θ test for sample, test ∈ {1, 2,…, D } where D is the total number of stimulus directions in the task. The stimulus directions belong to categories denoted c sample, c test ∈ {1, 2}.
No category or direction model (Supplementary Fig. 3A). This model includes only two stimulus regressors/kernels: one for the sample stimulus onset and one for the test stimulus onset (Supplementary Fig. 3A): The regressors are defined as point eventsThis model captures temporal dynamics in the mean response for each neuron across all stimuli.
Category-only model (Supplementary Fig. 3B). This model includes four stimulus kernels: two for each category for the sample stimulus (x (cs1) and x (cs2)), and two separate kernels for the test stimulus categories (x (ct1) and x (ct2)). The regressors are again point events, but the points are now conditioned on stimulus category (but not specific direction). For each category k ∈ {1, 2}:Although the discrimination task does not include category, we still applied this model to those data as if there was a category boundary at 45° and 225.
Cosine direction tuning model (Supplementary Fig. 3C). The cosine-tuned model includes both stimulus category and direction tuning, but direction encoding is constrained to a parametric form with cosine tuning. The model includes six stimulus events: two for each category for the sample stimulus (x (cs1) and x (cs2)), two for the test stimulus categories (x (ct1) and x (ct2)), and two for the sine and cosine of the direction (and). The sample and test category events are defined as in the previous model. The direction regressors are weighted point events, which are shared for both sample and test stimuli:
Full model (Supplementary Fig. 3D). The full model allows for general (non-cosine) direction tuning. However, we constrained the model to have the same direction tuning for both sample and test stimuli; that is, the difference in tuning between two directions within the same category was the same for both sample and test stimuli. The model included one stimulus regressor event for each directions plus two test category events (for the categorization task with D = 6 stimulus directions, there are eight kernels) For each trial and direction θ d for d ∈ {1, 2,…, D }, the stimulus regressors areThe two stimulus events that parameterize the test category responses (x (ct1), and x (ct2)) are defined as before. This parameterization maintains identifiability: it would not be identifiable to directly expand the cosine model to have a kernel for each direction plus two sample and two test category kernels. As a result of the identifiability constraint, the interpretation of the corresponding kernels is different compared to the cosine tuning model: in this model, is the kernel for a stimulus in the θ d direction plus the response to a stimulus of the category of c d. Therefore, we view k (ct1) as the kernel to test stimuli of category 1 minus the kernel for a category 1 sample stimulus (thereby subtracting the sample category tuning away from the direction kernel and adding the test category tuning).

---

### Directly measuring mean and variance of infinite-spectrum observables such as the photon orbital angular momentum [^a1aca62f]. Nature Communications (2015). Medium credibility.

The standard method for experimentally determining the probability distribution of an observable in quantum mechanics is the measurement of the observable spectrum. However, for infinite-dimensional degrees of freedom, this approach would require ideally infinite or, more realistically, a very large number of measurements. Here we consider an alternative method which can yield the mean and variance of an observable of an infinite-dimensional system by measuring only a two-dimensional pointer weakly coupled with the system. In our demonstrative implementation, we determine both the mean and the variance of the orbital angular momentum of a light beam without acquiring the entire spectrum, but measuring the Stokes parameters of the optical polarization (acting as pointer), after the beam has suffered a suitable spin-orbit weak interaction. This example can provide a paradigm for a new class of useful weak quantum measurements.

---

### Dynamics of history-dependent perceptual judgment [^54914844]. Nature Communications (2021). High credibility.

Identical physical inputs do not always evoke identical percepts. To investigate the role of stimulus history in tactile perception, we designed a task in which rats had to judge each vibrissal vibration, in a long series, as strong or weak depending on its mean speed. After a low-speed stimulus (trial n-1), rats were more likely to report the next stimulus (trial n) as strong, and after a high-speed stimulus, they were more likely to report the next stimulus as weak, a repulsive effect that did not depend on choice or reward on trial n-1. This effect could be tracked over several preceding trials (i.e., n-2 and earlier) and was characterized by an exponential decay function, reflecting a trial-by-trial incorporation of sensory history. Surprisingly, the influence of trial n-1 strengthened as the time interval between n-1 and n grew. Human subjects receiving fingertip vibrations showed these same key findings. We are able to account for the repulsive stimulus history effect, and its detailed time scale, through a single-parameter model, wherein each new stimulus gradually updates the subject's decision criterion. This model points to mechanisms underlying how the past affects the ongoing subjective experience.

---

### Humans and LLMs rate deliberation as superior to intuition on complex reasoning tasks [^d931fae7]. Communications Psychology (2025). Medium credibility.

Table 3
Within-subject ANOVA (and sphericity) table for Studies 1–7

Study labels: 1 = original (n = 239), 2 = replication (n = 241), 3 = accuracy (n = 240), 4 = implicature (n = 240), 5 = 1-scale (n = 241), 6 = French (n = 240), 7 = Indian (n = 184). The Greenhouse-Geisser correction is only applied to df when the sphericity assumption is violated. Square brackets indicate 95% CI.

More critically, there was a main effect of Reasoning mode, F (1, 238) = 348.6, p < 0.001, η p 2 = 0.59 [0.53, 1.00], and a Reasoning mode x Accuracy interaction, F (2, 476) = 80.47, p < 0.001, η p 2 = 0.25 [0.20, 1.00], indicating a general preference for the deliberate over the intuitive reasoner that was strongest when accuracy information was absent and slightly attenuated in the high- and low-accuracy conditions. Importantly, the preference for deliberation never disappeared or reversed and remained significant across all accuracy conditions (7.6 ≤ t s ≤ 19.3, 4 × 10 − 50 ≤ p s ≤ 3.9 × 10 −13, 0.53 ≤ d s ≤ 1.58, see Supplementary Table 6 in SI G). These findings thus indicate a general preference for deliberation over intuition, regardless of accuracy.

To check for potential bias from the within-subject design, we also ran a between-subjects analysis on the first item each participant evaluated, yielding similar results (see SI H). For further validation, after participants had rated all vignettes, they were also asked to directly rank-order four core vignettes (i.e. high/low accuracy intuitor and deliberator) by perceived reasoning quality. Average ranking scores confirmed the rating scale conclusions, with deliberate reasoners ranked higher than intuitive ones (see SI I).

---

### Spiking attractor model of motor cortex explains modulation of neural and behavioral variability by prior target information [^b9d1e646]. Nature Communications (2024). High credibility.

The task conditions of one, two or three possible targets presented during the 1 s preparatory period were executed in blocks and the order of these blocks were randomized across recordings sessions. In each block, 150 trials with randomized target directions were carried out so that each of the directions appeared on average 25 times per condition. Note that to obtain the same number of possible trial types in all conditions, not all possible combinations of directions for the preparatory stimulus were used in Conditions 2 and 3. Since six combinations are possible for Condition 1, only the pairs 1–2, 3–4, and 5–6 were used in Condition 2 and for Condition 3, only two cases occurred (6-1-2, 3-4-5).

Extracellular recordings were obtained with a multielectrode microdrive (Reitböck system; Thomas Recording) to insert transdurally seven independently movable electrodes within the area of the recording chamber, which was positioned over the motor cortex close to the central sulcus in monkey M1 and slightly more anterior in monkey M2 covering in parts primary and dorsal premotor cortex. Online spike sorting resulted in up to seven simultaneously recorded single-unit spike trains. We analyzed a total of 111 (M1) and 110 (M2) single units. Not on all experimental days all three conditions could be successfully completed, resulting in N = 76 (M1) and N = 62 (M2) single units that were recorded in all three conditions.

Model

Spiking network model

Our spiking network model is composed of leaky integrate-and-fire neurons with exponential synaptic currents where the sub-threshold evolution of the membrane potential V is described by the differential equationIn the absence of input, the membrane potential decays exponentially to the resting potential E L with time constant τ m. The current I syn represents the synaptic input, I x is an externally injected current and C m is the membrane capacitance. If the potential reaches the threshold V th a spike is emitted and V is clamped to a reset voltage V r for an absolute refractory period τ r. The synaptic current to a neuron i evolves according towhereis the time of the arrival of the k th spike from presynaptic neuron j and δ is the Dirac delta function.

To facilitate comparison with previous studies that investigated excitatory cluster topologies we here use similar parameters as provided in ref.and ref.(see Table 1). We briefly explain how we derived the main parameters in the following.

---

### Design of calibration-free RF pulses for T-weighted single-slab 3D turbo-spin-echo sequences at 7T utilizing parallel transmission [^cc8febed]. Magnetic Resonance in Medicine (2024). Medium credibility.

Purpose

T < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mo > < /mml:mo > < mml:mrow > < mml:mn > 2 < /mml:mn > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {}_2 $$ < /mml:annotation > < /mml:semantics > < /mml:math > -weighted turbo-spin-echo (TSE) sequences are a fundamental technique in brain imaging but suffer from field inhomogeneities at ultra-high fields. Several methods have been proposed to mitigate the problem, but were limited so far to nonselective three-dimensional (3D) measurements, making short acquisitions difficult to achieve when targeting very high resolution images, or needed additional calibration procedures, thus complicating their application.

Methods

Slab-selective excitation pulses were designed for flexible placement utilizing the concept of k < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mo > < /mml:mo > < mml:mrow > < mml:mi > T < /mml:mi > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {}_T $$ < /mml:annotation > < /mml:semantics > < /mml:math > -spokes. Phase-coherent refocusing universal pulses were subsequently optimized with the Gradient Ascent Pulse Engineering algorithm and tested in vivo for improved signal homogeneity.

Results

Implemented within a 3D variable flip angle TSE sequence, these pulses led to a signal-to-noise ratio (SNR) improvement ranging from 10% to 30% compared to a two-dimensional (2D) T2w TSE sequence employing < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {\mathrm{B}}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > -shimmed pulses. < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msubsup > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < mml:mrow > < mml:mo > + < /mml:mo > < /mml:mrow > < /mml:msubsup > < /mml:mrow > < mml:annotation > $$ {\mathrm{B}}_1^{+} $$ < /mml:annotation > < /mml:semantics > < /mml:math > field inhomogeneities could be mitigated and artifacts from < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mrow > < mml:mi > B < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 0 < /mml:mn > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {\mathrm{B}}_0 $$ < /mml:annotation > < /mml:semantics > < /mml:math > deviations reduced. The concept of universal pulses was successfully applied.

Conclusion

We present a pulse design method which provides a set of calibration-free universal pulses (UPs) for slab-selective excitation and phase-coherent refocusing in slab-selective TSE sequences.

---

### Machine learning enables completely automatic tuning of a quantum device faster than human experts [^9e40ec3e]. Nature Communications (2020). High credibility.

For all methods in Table 1 except Pure random, the time for 2D scans is the same, t 2D−L ≈ 33 s and t 2D−H ≈ 273 s, and t others ≈ 35 s. Therefore, the difference onacross methods is given byand. In Fig. 6 b, we can see thatis similar across the different algorithms, butis different. In conclusion, in Eqs. ((1)) and ((2)) determines t 500 and μ t in Fig. 6 a.

Rearrangingyieldsand this implies that t 2D has a significant weight when P (peaks) is large, motivating the introduction of the score function.

The expected time for Full decision algorithm iswhere P (highres) is the probability of acquiring a high resolution current map given a score. The score function decision always makessmaller than, becauseand P (highres∣peaks) < 1. This is experimentally verified in Fig. 6 from the fact that t 500 of Full decision is smaller than that of Peak weighting.

Comparisons betweenandcan be affected by the dependence of P (success∣peaks) on the score function threshold. In Fig. 6 b, however, we observe that P (success∣peaks) is similar for Peak weighting and Full decision. This implies that the introduction of a score function threshold does not reduce the probability of success.

In this case, This equation confirms that that the score function reduces μ t in the case that the score function threshold does not degrade P (success∣peaks). Further analysis on the optimal threshold, i.e., the threshold that minimizes, can be found in Supplementary Methods, Optimal threshold.

---

### Decisions are expedited through multiple neural adjustments spanning the sensorimotor hierarchy [^1f6b8629]. Nature Communications (2018). Medium credibility.

Behavioral analysis

Participants' behavior was evaluated based on RT distributions for correct and incorrect responses. As an initial step, we determined whether there was a significant difference in RT distributions between the deadline and slope conditions of the two different Speed/Accuracy regimes ("Speed deadline" vs. "Speed slope", and "Accuracy deadline" vs. "Accuracy slope") using Kolmogorov–Smirnov tests. Since these tests revealed no significant differences between RT distributions in any experimental condition, all consecutive analyses were performed on data pooled across the deadline and slope methods, but separately for Speed and Accuracy emphasis. Conditional accuracy functions were computed as the proportion of correct trials within RT deciles. We examined conditional accuracy functions in order to obtain a RT-dependent measure of the amount of sensory evidence accumulated before a response was initiated, and to test for a decline in accuracy consistent with the application of a dynamic (growing) component of urgency. To statistically test for potential differences in the rate of decline of response accuracy over the slower-RT trials for which this decline was evident, as has been found previously, we estimated the negative slope of the accuracy decline beyond the point of maximum performance in each condition. Specifically, we first pooled all trials within a subject across Contrast levels and Speed/Accuracy Regimes and computed the percentage of correct responses within six RT bins. We then identified the RT bin with the greatest average response accuracy and used all trials with response times longer than the mean RT of that bin (cut-off RT). We divided those trials into eight RT bins to compute the slope of a line fit to accuracy against RT and finally computed a 3-way repeated-measures ANOVA on these slope values with factors of Speed/Accuracy Regime, Left/Right Target Type, and Contrast (see Statistical Analysis section below for justification of all statistical test choices). To verify that our conclusions did not depend on the manner in which we defined the point of maximum performance, we repeated the above analysis using 5–10 RT bins to determine the cut-off RT and also with the maximum performance point determined within each individual condition as well as across the conditions pooled, and the outcome was always the same in that there was no main effect of Speed/Accuracy Regime on the conditional accuracy function decline (peak performance determined in 5 RT bins: ANOVA, F (1,15) = 0.21, p = 0.65; 7 RT bins: F (1,15) = 0.12, p = 0.73; 8 RT bins: F (1,15) = 2.67, p = 0.12; 9 RT bins: F (1,15) = 0.15, p = 0.70; 10 RT bins: F (1,15) = 0.57, p = 0.46; individual conditions: F (1,15) = 0.59, p = 0.45).

---

### An evolutionary theory on virus mutation in COVID-19 [^4958c638]. Virus Research (2024). Medium credibility.

With the rapid evolution of SARS-CoV-2, the emergence of new strains is an intriguing question. This paper presents an evolutionary theory to analyze the mutations of the virus and identify the conditions that lead to the generation of new strains. We represent the virus variants using a 4-letter sequence based on amino acid mutations on the spike protein and employ an n-distance algorithm to derive a variant phylogenetic tree. We show that the theoretically-derived tree aligns with experimental data on virus evolution. Additionally, we propose an A-X model, utilizing the set of existing mutation sites (A) and a set of randomly generated sites (X), to calculate the emergence of new strains. Our findings demonstrate that a sufficient number of random iterations can predict the generation of new macro-lineages when the number of sites in X is large enough. These results provide a crucial theoretical basis for understanding the evolution of SARS-CoV-2.

---

### Compressed sensing acceleration of radial 3-D alternating look-lockermapping [^f9b4f060]. Magnetic Resonance in Medicine (2025). Medium credibility.

Purpose

To determine how various compressed sensing (CS) models can accelerate alternating Look-Locker < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mrow > < mml:mi > T < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > mapping.

Methods

An alternating Look-Locker acquisition was retrospectively accelerated by factors of 1–12. The data was reconstructed into 12 images with multiple CS models, which utilized combinations of spatial total variation, locally low-rank regularization, and subspace constraints. Complex non-linear least squares signal fitting was performed to obtain the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mrow > < mml:mi > T < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > maps. The accelerated < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mrow > < mml:mi > T < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > maps were compared against the < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mrow > < mml:mi > T < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > map of a full data reference reconstruction.

Results

A subspace-constrained reconstruction model with spatial total variation and locally low-rank regularization outperformed all other models as measured by < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mrow > < mml:mi > T < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > map normalized root mean squared error, structural similarity index, and normalized mean absolute deviation. The subspace constraint benefited models utilizing spatial total variation but, conversely, did not benefit models utilizing only locally low-rank regularization.

Conclusion

The radial 3-D alternating Look-Locker < mml:math xmlns:mml = "http://www.w3.org/1998/Math/MathML" > < mml:semantics > < mml:mrow > < mml:msub > < mml:mrow > < mml:mi > T < /mml:mi > < /mml:mrow > < mml:mrow > < mml:mn > 1 < /mml:mn > < /mml:mrow > < /mml:msub > < /mml:mrow > < mml:annotation > $$ {T}_1 $$ < /mml:annotation > < /mml:semantics > < /mml:math > mapping acquisition was successfully accelerated by up to a factor of 12 with various CS models. The best-performing model was a subspace-constrained reconstruction, which utilized spatial total variation and locally low-rank regularization.

---

### 2013 ACC / AHA guideline on the assessment of cardiovascular risk: a report of the American college of cardiology / American Heart Association task force on practice guidelines [^38029cee]. Journal of the American College of Cardiology (2014). Medium credibility.

ACC/AHA cardiovascular risk assessment — Table 8 describes estimating an individual's 10-year risk of incident hard atherosclerotic cardiovascular disease (ASCVD) using race-sex group–specific coefficients and a worked example. The example profile assumes an individual 55 years of age (for which the Ln[Age] = 4.01), with a total cholesterol of 213 mg/dL, HDL-C (high-density lipoprotein cholesterol) of 50 mg/dL, and an untreated systolic BP (blood pressure) of 120 mm Hg who is not a current smoker and does not have diabetes. The calculation is performed in steps: the natural log (Ln) of age, total cholesterol, HDL-C, and systolic BP is calculated; appropriate interaction terms are derived (for example, Ln[Age]×Ln[Total Cholesterol]); the resulting values are multiplied by coefficients from the equation for the specific race-sex group to yield "Coefficient × Value" terms that are summed as an "Individual Sum". The estimated risk is formally calculated as "1 minus the survival rate at 10 years ("Baseline Survival" in Table A), raised to the power of the exponent of the "Coefficient × Value" sum minus the race- and sex-specific overall mean "Coefficient × Value" sum", and the white men example equates to a 5.3% probability of a first hard ASCVD event within 10 years.

---

### Measurement of the transition frequency from 2S, F = 0 to 2P, F = 1 States in muonium [^ff804a80]. Nature Communications (2022). High credibility.

Detection system

Due to the short lifetime of the 2 P states, the atoms excited by the microwave relax to the ground state before reaching the detection setup. The remaining excited states are quenched by applying an electrical field of about 250 V cm −1 between the two grids mounted in front of the coated Ly α -MCPs (see Fig. 4) and relax back to the ground state with the emission of UV photons (2P Ly α: 121.5 nm, 3P Ly β: 102.5 nm). These photons interact with the coating and release single electrons, which are in turn detected by the Ly α -MCPs. The beam then continues onto the Stop-MCP, giving the stop time for the TOF measurement. An event is recorded only if a coincidence signal between the Tag- and Stop-MCP is seen above threshold (double coincidence). The time window for a valid event is set to 10 μs and multiple hits in the detectors are recorded.

Analysis

The signature for the detection of M(2S) atoms is defined as the double coincidence and additionally the Ly α -MCP signal in the time region of interest (triple coincidence, see also Fig. 4).

In Fig. 5, the measured TOFs between Tag- and Stop-MCP (x axis) are correlated with the TOFs between Tag- and Ly α -MCP (y axis). The energy distribution of the M atoms after the carbon foil is well-known from previous measurements at the LEM beamline and reproduced by simulation. The most-probable energy of the μ + after the foil is 5.7(2) keV. The expected TOF of an M atom from the Tag- to the Stop-MCP ranges from 90 ns to 135 ns, with a most-probable TOF of 117 ns. Applying this time cut, we extract the detected amount of M and μ +, which serves as normalization factor, accounting for variations in the beam intensity. The TOF between the tagging and the emission of a Ly α photon is calculated to be in the range of 30 ns to 75 ns. Applying both of these cuts, we identify our signal region, portrayed in Fig. 5. The amount of signal events are extracted for each frequency point (S Ly α (f)). The normalized signals per frequency point are then calculated as S (f) = S Ly α (f)/ S Norm. The summary of the statistics gathered and the rates achieved is shown in Table 4.

---

### Efficient and adaptive sensory codes [^57108333]. Nature Neuroscience (2021). High credibility.

The ability to adapt to changes in stimulus statistics is a hallmark of sensory systems. Here, we developed a theoretical framework that can account for the dynamics of adaptation from an information processing perspective. We use this framework to optimize and analyze adaptive sensory codes, and we show that codes optimized for stationary environments can suffer from prolonged periods of poor performance when the environment changes. To mitigate the adversarial effects of these environmental changes, sensory systems must navigate tradeoffs between the ability to accurately encode incoming stimuli and the ability to rapidly detect and adapt to changes in the distribution of these stimuli. We derive families of codes that balance these objectives, and we demonstrate their close match to experimentally observed neural dynamics during mean and variance adaptation. Our results provide a unifying perspective on adaptation across a range of sensory systems, environments, and sensory tasks.

---

### Orthogonal representations for robust context-dependent task performance in brains and neural networks [^f4581b0d]. Neuron (2022). Medium credibility.

How do neural populations code for multiple, potentially conflicting tasks? Here we used computational simulations involving neural networks to define "lazy" and "rich" coding solutions to this context-dependent decision-making problem, which trade off learning speed for robustness. During lazy learning the input dimensionality is expanded by random projections to the network hidden layer, whereas in rich learning hidden units acquire structured representations that privilege relevant over irrelevant features. For context-dependent decision-making, one rich solution is to project task representations onto low-dimensional and orthogonal manifolds. Using behavioral testing and neuroimaging in humans and analysis of neural signals from macaque prefrontal cortex, we report evidence for neural coding patterns in biological brains whose dimensionality and neural geometry are consistent with the rich learning regime.

---

### Quantum simulation of hawking radiation and curved spacetime with a superconducting on-chip black hole [^6f9cbf0f]. Nature Communications (2023). High credibility.

The tunneling picture of Hawking radiation here is similar to the quantum fluid model of analog horizonwith two differences in details. The first one is that the analog horizon of ref.is created by transonic flow but we here create analog horizon by inhomogeneous lattice hopping. The second is that the injected beam ofis from the subsonic region (outside horizon) so that the reflected flow stands for the flow of Hawking radiation (classically the infalling beam should be swallowed by horizon completely and there is no reflected mode), but we here create a particle inside the horizon so the transmission flow is the Hawking radiation.

To obtain the radiation probabilities, we perform the quantum state tomography (QST) on the 7 qubits (Q 4 – Q 10) outside the horizon at t = 0 and t = 1000 ns, such a final time is long enough so that the particle inside the black hole has finished its tunneling to the outside but the boundary effect is negligible to the results. Here, the initial state is, i.e. a particle in the black hole has a certain position. When t = 0 ns, no radiation can be detected and all the qubits outside the horizon are almost in, see Fig. 3 a. After a long time t = 1000 ns, one may have a small chance to probe the particle outside the horizon, see Fig. 3 b. The corresponding probabilities of radiation can be extracted from the measured 7-qubit density matrix. Assuming thatis the n -th eigenenergy of total Hamiltonian andis the density matrix outside obtained by QST, then the probability of finding a particle of energy E n outside the horizon can be obtained as, see "Methods" section. Although there are 2 10 = 1024 eigenstates for 10-qubit Hamiltonian Eq. (2) and the same number of P n, the radiation states involve only 10 single-particle excited eigenstates due to the particle number conservation. As a consequence, only those P n that are corresponding to single-particle excited eigenstates have non-zero values, as shown in Fig. 3 c. Therefore, we take the average of P n with the same positive energy E n asto describe the average probability of finding a particle outside with E n > 0. It can be expected that the relation betweenand E n will agree with the theoretical prediction in Eq. (4). In Fig. 3 d, the simulated results show that the logarithm of the average radiation probability is approximately linear in energy with Hawking temperature 1.7 × 10 −5 K. The fitted Hawking temperature of experimental data is around ~ 7.7 × 10 −5 K, showing validity with the same order of magnitude. The deviation between experimental data and ideal simulation data is mainly caused by the evolution of the imperfect initial state. The fidelity between the imperfect initial state in the experiment and the ideal initial state is 99.2%, which may derive from the experimental noises including XY crosstalk, thermal excitation, leakage, etc. We substitute such an experimental state for the ideal initial state in the numerical simulation of Hawking radiation, then the results of numerical simulation agree with experimental results better.

---

### The snm procedure guideline for general imaging 6.0 [^638aaec4]. SNMMI (2010). Medium credibility.

SNM Procedure Guideline for General Imaging — matrix size and pixel depth in nuclear medicine acquisitions notes that matrix size is almost always a power of 2 with typical values 64 x 64, 128 x 128, 256 x 256 and 512 x 512, and that non-square matrix sizes also exist for whole-body studies. Each pixel can be represented with a single byte (pixel values ranging from 0 to 255 counts) or with 16 bit words (pixel values ranging up to a maximum of 32k or 64k). Overflow occurs when the number of counts recorded at some given position exceeds the maximum number of counts, and overflow is more likely to occur when using a byte matrix.

---

### Factor VIIa (recombinant) [^363851b7]. FDA. Low credibility.

The dosage of factor VIIa (recombinant) IV for treatment of bleeding episodes in adults with congenital factor VII deficiency is 15–30 mcg/kg IV q4-6h until hemostasis is achieved

---

### Predictive learning as a network mechanism for extracting low-dimensional latent space representations [^131c0986]. Nature Communications (2021). High credibility.

Artificial neural networks have recently achieved many successes in solving sequential processing and planning tasks. Their success is often ascribed to the emergence of the task's low-dimensional latent structure in the network activity - i.e., in the learned neural representations. Here, we investigate the hypothesis that a means for generating representations with easily accessed low-dimensional latent structure, possibly reflecting an underlying semantic organization, is through learning to predict observations about the world. Specifically, we ask whether and when network mechanisms for sensory prediction coincide with those for extracting the underlying latent variables. Using a recurrent neural network model trained to predict a sequence of observations we show that network dynamics exhibit low-dimensional but nonlinearly transformed representations of sensory inputs that map the latent structure of the sensory environment. We quantify these results using nonlinear measures of intrinsic dimensionality and linear decodability of latent variables, and provide mathematical arguments for why such useful predictive representations emerge. We focus throughout on how our results can aid the analysis and interpretation of experimental data.

---

### Decoding and perturbing decision States in real time [^f76ed5e8]. Nature (2021). Excellent credibility.

In dynamic environments, subjects often integrate multiple samples of a signal and combine them to reach a categorical judgment 1. The process of deliberation can be described by a time-varying decision variable (DV), decoded from neural population activity, that predicts a subject's upcoming decision 2. Within single trials, however, there are large moment-to-moment fluctuations in the DV, the behavioural significance of which is unclear. Here, using real-time, neural feedback control of stimulus duration, we show that within-trial DV fluctuations, decoded from motor cortex, are tightly linked to decision state in macaques, predicting behavioural choices substantially better than the condition-averaged DV or the visual stimulus alone. Furthermore, robust changes in DV sign have the statistical regularities expected from behavioural studies of changes of mind 3. Probing the decision process on single trials with weak stimulus pulses, we find evidence for time-varying absorbing decision bounds, enabling us to distinguish between specific models of decision making.

---

### Disentangling signal from noise in visual contrast discrimination [^03b94848]. Nature Neuroscience (2001). Medium credibility.

Human ability to detect stimulus changes (Delta C) decreases with increasing reference level (C). Because detection performance reflects the signal-to-noise ratio within the relevant sensory brain module, this behavior can be accounted for in two extreme ways: first, the internal response change Delta R evoked by a constant Delta C decreases with C (that is, the transducer R = f(C) displays a compressive nonlinearity), whereas the internal noise is independent of R; second, Delta R is constant with C but the noise level increases with R. A newly discovered constraint on human decision-making helps solve this century-old problem: in a detection task where multiple changes occur with equal probabilities, observers use a unique response criterion to decide whether a change has occurred. For contrast discrimination, our results supported the first account above: human performance was limited by the contrast transducer nonlinearity and an almost constant noise.

---

### The timescale and direction of influence of a third inferior alternative in human value-learning [^eb7260f5]. Communications Psychology (2025). Medium credibility.

Basic performance

During the learning phase (Fig. 2B), participants were sequentially exposed to the value associated with each alternative. The value was shown by a cloud of moving dots, with the number of dots representing the reward magnitude (i.e. number of points) associated with the coin (see "Methods" section). Participants completed 99.91% (95% CI = [99.84%, 99.97%]) of all learning trials with an average reaction time of 623.66 milliseconds (ms) (95% CI = [593.56 ms, 653.76 ms]) in Experiment 1, and 99.3% (95% CI = [98.94%, 99.66%]) of all learning trials with an average reaction time of 411.92 ms (95% CI = [386.66 ms, 437.18 ms]) in Experiment 2, indicating that they properly engaged with the learning phase. We found no statistically significant evidence for differences between the reaction times across learning trials that involved the higher-value (HV), lower-value (LV), and distractor value (DV) alternatives across different contexts in either experiment (2-way ANOVA on log (RT) in Experiment 1: alternatives: F (2, 174) = 0.004, p = 0.99, partial η² < 0.01, 95% CI = [0.00, 0.02], contexts: F (1, 174) = 0.15, p = 0.69, partial η² < 0.01, 95% CI = [0.00, 0.03], interaction: F (2, 174) = 0.02, p = 0.98, partial η² = 0.00, 95% CI = [0.00, 0.02]; and in Experiment 2: alternatives: F (2, 402) = 0.03, p = 0.97, partial η² = 0.00, 95% CI = [0.00, 0.01], contexts: F (1, 402) = 0.06, p = 0.81, partial η² < 0.01, 95% CI = [0.00, 0.01], interaction: F (2, 402) = 0.04, p = 0.97, partial η² < 0.01, 95% CI = [0.00, 0.01]).

---

### Hyaluronidase (Amphadase) [^74beaaf6]. FDA (2024). Medium credibility.

PRINCIPLE DISPLAY PANEL: Carton: 1mL

NDC 0548-9090-10

Stock No 9091

Hyaluronidase Injection

Amphadase®

150 USP units/mL

Derived from bovine testicle

Not for IV use.

 See Enclosed Directions.

10 x 1 mL Single-Dose Vials.

Discard Unused Portion.

Rx Only

1 mL

Each mL contains 150 USP units of hyaluronidase with calcium chloride (0.4 mg),

edetate disodium (1.0 mg), monobasic sodium phosphate (1.7 mg), sodium chloride (8.5 mg),

not more than 0.1 mg thimerosal (mercury derivative), and Water for Injection, USP.

Sodium hydroxide may be added to adjust pH. Amphadase has an approximate pH of 6.8

Dosage and Administration: See Prescribing Informatio n.

Amphadase is ready for injection.

Must be refrigerated, store at 2°C to 8°C (36°F to 46°F).

5290916G/3–24

---

### A crystalline tri-thorium cluster with σ-aromatic metal-metal bonding [^2102fed0]. Nature (2021). Excellent credibility.

Metal-metal bonding is a widely studied area of chemistry 1–3, and has become a mature field spanning numerous d transition metal and main group complexes 4–7. By contrast, actinide-actinide bonding, which is predicted to be weak 8, is currently restricted to spectroscopically detected gas-phase U 2 and Th 2 (refs. 9,10), U 2 H 2 and U 2 H 4 in frozen matrices at 6–7 K (refs. 11,12), or fullerene-encapsulated U 2 (ref. 13). Furthermore, attempts to prepare thorium-thorium bonds in frozen matrices have produced only ThH n (n = 1–4) 14. Thus, there are no isolable actinide-actinide bonds under normal conditions. Computational investigations have explored the probable nature of actinide-actinide bonding 15, concentrating on localized σ-, π-, and δ-bonding models paralleling d transition metal analogues, but predictions in relativistic regimes are challenging and have remained experimentally unverified. Here, we report thorium-thorium bonding in a crystalline cluster, prepared and isolated under normal experimental conditions. The cluster exhibits a diamagnetic, closed-shell singlet ground state with a valence-delocalized three-centre-two-electron σ-aromatic bond 16,17 that is counter to the focus of previous theoretical predictions. The experimental discovery of actinide σ-aromatic bonding adds to main group and d transition metal analogues, extending delocalized σ-aromatic bonding to the heaviest elements in the periodic table and to principal quantum number six, and constitutes a new approach to elaborate actinide-actinide bonding.

---

### The snm procedure guideline for general imaging 6.0 [^6eaf4fa0]. SNMMI (2010). Medium credibility.

SNM Procedure Guideline for General Imaging 6.0 — spatial resolution and linearity testing specifies that spatial resolution and linearity (distortion) should be tested at least once each week, with the measurement made with the collimator on or off; if the collimator is on, it should have the highest resolution that is available and be designed for Tc-99m. If the imaging system is digital, the finest matrix that is available should be used; a coarse matrix will produce images that appear to show a loss of spatial resolution and may also show Moiré patterns, and medium and high-energy collimators will produce Moiré patterns even in analog imaging systems. The count density should be the same as for uniformity images, thus typically the bar pattern would be imaged for one-half the number of counts used for the uniformity images, and all imaging parameters should be recorded.

---

### Interpolating numerically exact many-body wave functions for accelerated molecular dynamics [^7dff026b]. Nature Communications (2025). High credibility.

While there have been many developments in computational probes of both strongly-correlated molecular systems and machine-learning accelerated molecular dynamics, there remains a significant gap in capabilities in simulating accurate non-local electronic structure over timescales on which atoms move. We develop an approach to bridge these fields with a practical interpolation scheme for the correlated many-electron state through the space of atomic configurations, whilst avoiding the exponential complexity of these underlying electronic states. With a small number of accurate correlated wave functions as a training set, we demonstrate provable convergence to near-exact potential energy surfaces for subsequent dynamics with propagation of a valid many-body wave function and inference of its variational energy whilst retaining a mean-field computational scaling. This represents a profoundly different paradigm to the direct interpolation of potential energy surfaces in established machine-learning approaches. We combine this with modern electronic structure approaches to systematically resolve molecular dynamics trajectories and converge thermodynamic quantities with a high-throughput of several million interpolated wave functions with explicit validation of their accuracy from only a few numerically exact quantum chemical calculations. We also highlight the comparison to traditional machine-learned potentials or dynamics on mean-field surfaces.

---

### Multisliced ultrafast 2D relaxometry [^a8ebc0c7]. Magnetic Resonance Imaging (2010). Low credibility.

By associating each slice in a spatially homogeneous sample with a different inversion-recovery delay time, multislice methods are used to reduce the acquisition times of 2D inversion-recovery T(1)-T(2) relaxation spectra to just a few minutes. The increased speed comes at the expense of reduced signal/noise and this is reflected most noticeably in shifts in the component longitudinal relaxation times. Nevertheless, the major features of the 2D relaxation spectra are reproduced.

---

### Network analysis of synthesizable materials discovery [^5699648a]. Nature Communications (2019). High credibility.

Discovery is a time-irreversible event and its prediction is not a standard machine-learning problem in materials science. Here we use time evolution of the aforementioned network properties of materials as features to form the basis of a sequential supervised-learning problem. We adopt a sliding-window approach to train experimental discovery classifiers and estimate likelihood of discovery, and the implied synthesis for synthetic materials (see Fig. 5 and "Methods"). We employ two classification algorithms: L 2 -norm regularized logistic regression (LR) for well-calibrated probabilities, and random forest (RF) for classification accuracy. The subclass of sequences where a material changes from undiscovered to discovered in the time domain represents the rare event of discovery in sequential data, for which we define stringent event-detection metrics for precision and recall using a prediction-period approach (see "Methods"), and found these metrics for LR and RF to be nearly 30% and 90%, respectively, for detection within ± 1 time-step and close to 50% and 95% for detection within ± 2 time-steps (where larger prediction periods make the correct classification easier), outperforming baseline detection metrics by a significant margin (Supplementary Fig. 7). As another performance evaluation for the present problem, distributions of the difference between the estimated time-step of discovery (see "Methods" for how this estimation is done from classification results) and its true value (Δ t) for the two models tested in this work are compared in Supplementary Fig. 8, along with baseline models. For both LR and RF models, distributions are centered close to zero, with LR showing a tendency to estimate slightly earlier times with a mean Δ t ≈ −1.6, whereas RF delivers more precise estimates with mean Δ t ≈ −0.2 (each time-step is 5-years long in this work). Baseline models yield distributions with means far from zero. LR has a much broader distribution than RF, however, with a standard deviation at ~3.5 time-steps, whereas that of RF is at ~1.2 time-steps.

---