# Medical Question & Answer

**Sample ID**: cc620aba-b930-6a47-c2ce-63f7f53f4e64
**Dataset Index**: 241003

---

## Question

## Task 3–300813

In a plane, seven points are given such that no three of them lie on a common line.

Determine the number of all those triangles whose vertices are three of the given points!

---

## Answer

> Let's see… What do we have here? The user is asking how many triangles can be formed from 7 points in a plane, given that no three points are collinear. Let's break this down step-by-step. First, I need to think about the combinatorial foundation for choosing 3 points out of 7. Then, I should verify that the "no three collinear" condition ensures every triple forms a valid triangle. Next, I will compute the binomial coefficient and double-check the arithmetic. Finally, I will consider whether any edge cases or alternative interpretations could change the result and confirm the answer.

> Let me first confirm the core principle: a triangle is uniquely determined by three non-collinear vertices, so the problem reduces to counting the number of ways to choose 3 distinct points from 7, with the guarantee that any such triple will form a triangle because no three are collinear.

> I need to check the combinatorial formula. The number of ways to choose 3 items from 7 without regard to order is given by the binomial coefficient C(7, 3), which equals 7! divided by (3! × (7−3)!), and that simplifies to (7 × 6 × 5)/(3 × 2 × 1).

> Wait, let me verify the arithmetic: 7 × 6 × 5 is 210, and 3 × 2 × 1 is 6, so 210 divided by 6 equals 35. Therefore, C(7, 3) = 35.

> Hold on, let's not jump to conclusions — I should confirm that the "no three collinear" clause is indeed sufficient. If any three points were collinear, the triple would not form a triangle, but the problem explicitly excludes that scenario, so every combination of three points will yield a valid triangle, and there are no exceptions to subtract.

> I will now examine whether any alternative interpretations could alter the count. Some contexts distinguish "degenerate triangles" when points are collinear, but here the condition removes degeneracy, so the straightforward combinatorial count stands; I should also note that this is a classic combinatorics problem and the result is consistent with standard treatments of combinations.

> Final answer: 35 triangles can be formed from 7 points in a plane with no three collinear, calculated as C(7, 3) = 35.

---

The number of triangles that can be formed from 7 points in a plane, with no three collinear, is **35**. This is a combination problem: we choose 3 points out of 7, and since no three are collinear, every triple forms a triangle. The calculation is C(7, 3) = 7! / (3! × 4!) = 35.

---

## Combinatorial approach

The key insight is that **each triangle is uniquely determined by selecting 3 distinct points** from the 7, and the condition that no three points are collinear ensures every such triple forms a valid triangle. Thus, the problem reduces to computing the number of ways to choose 3 points from 7, which is the binomial coefficient C(7, 3).

---

## Calculation

The binomial coefficient C(n, k) is given by:

C(n, k) = [n!/(k!(n − k)!)]

Substituting n = 7 and k = 3:

C(7, 3) = [7!/(3!(7–3)!)] = [7!/(3! × 4!)] = [5040/(6 × 24)] = [5040/144] = 35

---

## Verification

To ensure correctness, consider that **C(7, 3) counts unordered selections** of 3 points from 7, which matches the definition of a triangle as a set of three vertices. The no-three-collinear condition eliminates degenerate cases, so all 35 triples are valid triangles.

---

## Conclusion

The number of triangles that can be formed from 7 points in a plane, with no three collinear, is **35**.

---

## References

### Critical factors in achieving fine-scale functional MRI: removing sources of inadvertent spatial smoothing [^117JEyMK]. Human Brain Mapping (2022). Medium credibility.

3.4 Refinement of the surface mesh reduces the number of missed voxels

To test whether projecting fMRI data onto typical cortical surface meshes can result in lost fMRI voxels and thus missing data, and how this loss depends on both voxel grid and mesh vertex spacing, we counted the number of unique voxels projected onto the surface for various surface mesh resolutions. (Here, voxel index values, which are integers, were projected to the surface, and thus nearest‐neighbor interpolation was used to preserve their integer values.) The number of the lost voxels was then quantified by counting the number of unique values on the surface mesh.

As depicted in the schematic in Figure 4a, the mesh refinement scheme used here adds new vertices to the triangle edge mid‐points, and as the number and density of the vertices increases more unique voxels are retained during surface projection. This schematic also shows how refining the surface mesh can not only help reduce the number of missing voxels, but can also help minimize small‐scale spatial distortions or displacements that are incurred when projecting voxel values to vertices that are spatially distant from the corresponding voxel centroid. If the distance between neighboring voxels is smaller than the distance between neighboring vertex, there will be a chance that some voxels will be missed and not projected onto any vertex. As expected, Figure 4b shows, for an example subject, how the number of unique voxels projected onto the surface increases with increasing density of vertices as the mesh is iteratively refined from one to three steps. This evaluation was performed on the gray/white matter boundary surface generated by FreeSurfer from standard 1‐mm anatomical data, whose cross‐section with the image slice is represented by the black contour, because this cortical surface is more commonly used to preserve spatial specificity in BOLD fMRI studies. In order to visualize the unique voxels projected onto the surface, here we visualized the voxel index projected onto the surface as a mask in volume space. As can be seen in the zoomed‐in view, progressively more unique voxels near the gray/white matter boundary surface are retained (i.e. fewer voxels are lost) as the surface mesh is refined. Figure 4c shows quantitatively the number of unique voxels captured during surface projection with increasingly refined surface meshes, and demonstrates an increase in unique voxel count with increasing vertex resolution that is in line with what can be seen qualitatively in Figure 4b. Perhaps surprisingly, the number of unique voxels only reaches a plateau after three iterations of refinement for this example 1‐mm resolution volumetric fMRI data, suggesting that further steps of refinement may be necessary for even higher resolution fMRI data.

---

### Reduction of artefacts caused by hip implants in CT-based attenuation-corrected PET images using 2-D interpolation of a virtual sinogram on an irregular grid [^115VXVcb]. European Journal of Nuclear Medicine and Molecular Imaging (2011). Low credibility.

Delaunay triangulation

Delaunay triangulation was proposed in 1934 and was used in many mathematical applications. We assume that there is a set, V, representing a set of N ≥ 3 points in the Euclidean plane, and that these points are not collinear and any four points are not co-circular. The Delaunay triangulation of this set, DT (V), divides the plane into triangles with vertices located on the points, which intersect in a common side. Delaunay triangulation has the property that the circumcircle of the triangles are empty, i.e. they contain no point of V in their interior (Fig. 2). To ensure that none of the points is inside the circumcircle of one triangle, an incircle test is applied to four distinct points. Consider the points A, B, C and D in Fig. 3. If A, B and C define a counterclockwise-oriented triangle, point D will be inside the circumcircle of the triangle ABC if the following condition is met:

Fig. 2
Example of Delaunay triangulation. Note that none of the points is inside the circumcircle of all triangles

Fig. 3
Incircle test applied to four distinct points: A, B, C and D

The proof can be found in.

After defining an irregular grid on the data points of the sinogram matrix which are not affected by metallic objects, we need to use an interpolation technique.

---

### Topological data analysis in medical imaging: current state of the art [^116cista]. Insights Into Imaging (2023). Medium credibility.

For example, suppose we have three points in a two-dimensional point cloud, two of which are closer together than either is to the third point (Fig. 1). In this example, we can take three patients who present with malignancy, each having a different 3D tumor volume on CT imaging. For patients 1 and 2, their volumes are similar and form a simplicial complex with only a small distance threshold. If we expand our distance threshold, we can now include other values that are increasing dissimilar, connecting all three points to create a triangle. In practice, we'd have many more points and dimensions in our point cloud, but this illustrates the principle of filtration and simplicial complex hierarchies at a basic level.

Fig. 1
An example of three patients with varying 3D tumor volumes within a two-dimensional point cloud. The point from patient 1 and patient 2 for 3D tumor volume is close, therefore only requiring a small distance threshold to create a simplicial complex. As the distance threshold is expanded, the simplicial complex can include additional points with increasing variance

Once the series of simplicial complexes has been built, their structures can be analyzed. Homology, a topological tool, counts the number of holes in each dimension that exist within a space. In simplicial complexes, these are connected components, loops, voids, and higher-dimensional voids. To build the intuition around this, it is important to consider a part in a simplicial complex made of three, two-way relationships (edges in a graph) but lacking a mutual three-way relationship (to form a triangle of three points within a mutual distance of each other). This forms a loop, a part of the space with a potentially higher-dimensional interaction that does not exist in the simplicial complex but includes the lower-dimensional interactions. We can consider mutual three-way relationships that do not form a mutual four-way relationship, which would create a void. Betti numbers, which track the number of holes that exist in each dimension for a space or a simplicial complex, are a good way to summarize and quantify this information.

---

### Backmapping triangulated surfaces to coarse-grained membrane models [^114oHVJx]. Nature Communications (2020). High credibility.

Fig. 2
Three-dimensional triangulation of a triangle.

a One triangle is divided to four triangles by finding three new vertices in proximity of the mid-point of each of the edges of the original triangle. This increases the vertex number by a factor of 4. b Using the geometrical properties at two neighboring vertexes, an estimate of the geodesic connecting two neighboring vertices can be found (red curve). c By performing several consecutive operations as shown in a, enough points are generated on each triangle for lipid placement.

Step 3: CG protein placement: In this step, each CG protein structure is transferred to its given vertices using. This will guarantee a correct orientation of the proteins both along the normal and on the local plane. To avoid re-equilibration of lipid–protein interactions, instead of transferring only proteins, one can transfer a protein with its neighboring lipids (including lipids underneath for peripheral membrane proteins) from an equilibrated MD structure (Fig. 1).

Step 4: CG lipid placement: We first calculate the number of the required lipids to cover the surface of each monolayer. To do this, we first calculate the total area of the monolayer TS (is monolayer index) aswhereandare the number of proteins and projected area of the transmembrane region of the protein (protein projected area for peripheral membrane proteins). Then, we randomly select a vertex, check if it is in touch with any protein, if not, then place a lipid with a probability of. This step will be iterated untillipids are selected. Our results show a quick convergence of this algorithm (Fig. 1).

---

### Automatic data-driven design and 3D printing of custom ocular prostheses [^113rDmbj]. Nature Communications (2024). High credibility.

Correspondence generation

We compute corresponding landmarks on the mesh surface via depth maps (Supplementary Algorithm 2), using the fact that the maximum number of intersections between an aligned prosthesis shape' surface and any line parallel to the z-axis is two. The depth maps are given by the orthogonal projection of the surface along the z-Axis for front and back view (Supplementary Fig. 1f, j). To determine the corresponding points, we perform ray marching to compute lines radially from the origin to the edge of the prosthesis projection, for 48 directions at incremental angles of 7.5°. On these lines we distribute points at distinct fractions (shown in Supplementary Fig. 1g, k), points placed at the same fraction form a ring. We skip the placement at certain fractions for lines at distinct angles to achieve a more homogeneous density, and for the front we select the factions such that the limbus is always marked by the third ring. The result is a point cloudwith 838 corresponding vertices (189 vertices on the front and 649 on the back of the prosthesis shape); together with a set of 1672 triangle facesit defines the shape's mesh representation(Supplementary Fig. 1h, l), withbeing the space of the prosthesis shape vertices and faces.

Shape model generation

A selection of 173 manually produced prostheses sourced from a stock at MEH were scanned, marked, aligned, and the corresponding landmarks computed as described above. The size of the axis-aligned bounding box (width, height, and depth) of the shapes ranges from (18.5 × 15.9 × 9.7) mm 3 to (28.6 × 32.3 × 22.2) mm 3 with a mean of (24.2 × 22.5 × 15.5) mm 3. We did not perform Generalized Procrustes Analysisfor two reasons. First because the correct rotation is already given and the size is normalized implicitly by the limbus size that was very similar for these shapes. Secondly and more importantly the size of the prosthesis is related to the shape, meaning that some shapes are more likely for certain eye socket volume sizes.

---

### Scalable multiple whole-genome alignment and locally collinear block construction with sibeliaZ [^114NGoFJ]. Nature Communications (2020). High credibility.

Box 2 Update-collinear-walks

Input: A sorted set of collinear walks P, a vertex w

Output: Updated set P

1: for edges x ∈ E (G) ending at w not marked as used do

2: Let p ∈ P be a walk such that its b -extension q contains x and pos(end(p)) is maximized ⊳ Find a walk extendable with x

3: if such p exists then

4: Truncate q so that end(q) = x

5: Append p with q ⊳ Lengthen the chain that p forms with p a

6: else

7: Add a new walk consisting of the edge x to P

8: return P

Other considerations

For simplicity of presentation, we have described the algorithm in terms of the ordinary de Bruijn graph; however, it is crucial for running time and memory usage that the graph is compacted first. Informally, the compacted de Bruijn graph replaces each non-branching path with a single edge. Formally, the vertex set of the compacted graph consists of vertices of the regular de Bruijn graph that have at least two outgoing (or ingoing) edges pointing at (incoming from) different vertices. Such vertices are called junctions. Let ℓ = v 1, …, v n be the list of k -mers corresponding to junctions, in the order, they appear in the underlying string s. The edge set of the compacted graph consists of edges { v 1 → v 2, v 2 → v 3, …, v n −1 → v n }. We efficiently construct the compacted graph using our previously published algorithm TwoPaCo.

---

### Structural puzzles in virology solved with an overarching icosahedral design principle [^113SY3FU]. Nature Communications (2019). High credibility.

Methods

The construction of the polyhedral models and their duals is described below.

Construction of polyhedral designs

Consider two lines intersecting at an angle of 60° at the centre of one of the hexagons in the hexagonal (sub)lattice of a given Archimedean lattice. Counting steps between midpoints of adjacent hexagons along these lines via the integer coordinatesand, thencharacterises the positions of other hexagons in the (sub)lattice with respect to the original one, i.e. Using the line connecting the midpoints of these hexagons as the edge of an equilateral triangle of an icosahedral face (Supplementary Fig. 1), the position of the remainder of that surface is uniquely determined, andthus defines a planar embedding of an icosahedral surface into the Archimedean lattice (see examples in Fig. 2). The corresponding polyhedral shape in three dimensions is an icosahedron, obtained via identification of edges of the planar embedding. The numbers of pentagonal, hexagonal, triangular and square faces in the Archimedean lattice overlapping with this icosahedral surface for different values ofandare provided in Supplementary Tables 1–4 for the hexagonal, trihexagonal, snub hexagonal and rhombitrihexagonal lattice, respectively. In particular, an icosahedral face given bycontains either no additional face (hexagonal case), one triangle (trihexagonal case), four triangles (snub hexagonal case), or one triangle and a square (rhombitrihexagonal case), that each form the start of an infinite series of polyhedra.

Construction of the dual lattices

For each polyhedron in the above classification, we construct a dual polyhedron. For this, vertices are positioned at the centres of the polyhedral faces, and vertices associated with adjacent faces connected by straight lines. Since Archimedean lattices have a single type of vertex environment, these dual polyhedra each have a single type of face that corresponds to the fundamental domain of a Laves lattice. These faces are triangles, rhombs, florets and kites for the hexagonal, trihexagonal, snub hexagonal and rhombitrihexagonal lattice, respectively. Using again the planar embedding of an icosahedral surface into the associated Archimedean lattice, we determine the numbers of each such face for polyhedra characterised byandas above; their numbers are listed in Supplementary Table 5.

---

### Controlled packing and single-droplet resolution of 3D-printed functional synthetic tissues [^112XAwZx]. Nature Communications (2020). High credibility.

Classifying packing types

To estimate the proportion of packing types within each network, we first generated a mesh over the print by performing a Delaunay triangulation using the centres of all regions classified as droplets as the input points. A convenient property of this triangulation method is that the circumcircle of each triangle contains no other points; each triangle therefore represents a triplet of neighbouring droplets and provides localised geometrical information about their arrangements.

The plot of the bivariate distribution of the largest angle of each triangle vs the triangle area normalised by the average droplet area for all prints revealed two distinct clusters of triangles, one corresponding to hexagonally packed droplet regions, and one corresponding to square-packed droplet regions (Supplementary Fig. 3 d). Reasoning that these represented stable configurations of droplets for certain printing parameters, we classified each triangle using these clusters. Four packing categories were used: 'hexagonal' (closely packed triplets of droplets arranged as equilateral triangles), 'square' (closely packed triplets of droplets arranged as right-angled triangles), 'amorphous' (closely packed triplets of droplets of intermediate arrangement) and 'no packing' (triplets of droplets that are not close-packed). For a hexagonal classification. For an amorphous classification. For a square classification. In addition, for all of these classes. Triangles that fell outside of these ranges were classified as no packing (Supplementary Fig. 3 d).

Some elongated 'sliver' triangles were classified as being a member of one of the closely packed classes, despite being composed of widely spaced droplets. Closer analysis of these triangles revealed that they were generally composed of two closely packed droplets and a single more distant droplet, together forming a skinny near-isosceles triangle. We therefore applied an additional constraint based on the perimeter of each triangle normalised by the average droplet radius. Since for perfect hexagonal packing, and for a perfect square packing, we set the constraintfor the closely packed classes based on a linear interpolation between these two points. Our chosen y -intercept for this constraint is slightly greater than the theoretical y -intercept from the interpolation, allowing triangles with small deviations from the perfect packing geometry to be classified as closely packed while still ensuring classification of sliver triangles as no packing.

---

### Clustering by measuring local direction centrality for data with heterogeneous density and weak connectivity [^117TtPc8]. Nature Communications (2022). High credibility.

Estimation of the number of boundary points for determining T DCM

As shown in Supplementary Fig. 12a, we constructed a Triangulated Irregular Network (TIN) to connect all points. In graph theory, the degree of a vertex is defined as the number of edges incident to the vertex and each edge connects two vertexes. Based on this law, we can obtain:where deg(v i) represents the degree of vertex v i, V denotes the total number of vertexes, and E represents the total number of edges. In a graph, each triangle has three edges and each edge is shared by two triangles except the outermost edges. Actually, for a TIN that has a single connected component, the total number of boundary points is equal to that of the outermost edges, since all the outermost edges are connected end to end by boundary points and form a closed polygon. This law can be summarized as:where F and B refer to the total number of triangles and boundary points respectively. Meanwhile, 2D Euler's formula can be considered as follows:

By combining these formulas, we can infer the solution of B as follows:

However, the number of initial boundary points in the whole TIN is not equal to the total number of boundary points in the separated clusters. To conduct an accurate estimation, the whole TIN should be treated as multiple sub-networks (Supplementary Fig. 12b). Given C clusters, the number of boundary points in clusters can be solved as follows:where F is the total number of intra-cluster triangles in the multiple separated networks. V is known in a given dataset (i.e. n), but F and C are not. The initial F is the total number of triangles in the whole TIN, which includes the triangles connecting different clusters, i.e. cross-cluster triangles whose three vertices are not all in the same cluster (otherwise is intra-cluster triangle). Using the excessive number of triangles would make the number of boundary points B smaller than the true value. To identify the cross-cluster triangles, we set a judgment rule:where v 1, v 2, v 3 are the three vertices of a triangle, and σ (v i, v j) is an indicator function:

---

### Critical factors in achieving fine-scale functional MRI: removing sources of inadvertent spatial smoothing [^114k6jo3]. Human Brain Mapping (2022). Medium credibility.

4.4 Disadvantages of nearest‐neighbor interpolation

Although we demonstrated through simulations based on synthetic noise data that nearest‐neighbor interpolation may be advantageous since it induces the smallest spatial blur (Figures 2 and 3), we chose not to use nearest‐neighbor interpolation in our V2 stripe analysis, rather we opted to use trilinear interpolation. Our reasoning behind this decision to not use nearest‐neighbor interpolation is that it also causes displacement and local distortion artifacts, both in the context of volume transformations and surface projections.

Nearest‐neighbor interpolation applied to when transforming volumetric data is known to does not correctly account for subvoxel displacements (Grootoonk et al.) because it is a nonlinear interpolation — small displacements relative to the voxel grid may cause no changes in intensity after interpolation, and if the magnitude of displacement increases steadily there can be sudden jumps in intensity after interpolation.

Nearest‐neighbor interpolation applied to volume‐to‐surface projection when using coarse grid spacing on surface mesh relative to a dense volume grid can cause displacement artifacts (i.e. fine‐scale distortion) and missing voxels (Figure 4). This can lead to artifactual truncated appearance of the data projected onto the surface; this manifests as an aliased appearance of the activation pattern and artifactual edges, which may give misleading fine‐scale structure in the activation pattern. Nevertheless, we note that nearest‐neighbor surface interpolation can be beneficial provided that the surface mesh spacing is sufficiently fine relative to the volume resolution.

4.5 Other methods exist for representing voxel data on surface

Our results show that surface refinement can help decrease the number of missing fMRI voxels when projecting data onto cortical surfaces. However, our tests demonstrate that the number of unique voxels does not plateau until three iterations of refinement have been performed. If we were to require that all fMRI voxels intersecting the cortex are included in the projection, an even denser vertex mesh might be needed, however, each step of refinement dramatically increases the computational load of the analysis while providing diminishing returns. We note that the number and density of vertices are dependent upon the algorithm used to reconstruct the surface mesh, and in the method used by FreeSurfer these are a function of the voxel grid used in the anatomical data, which in our case was a 1‐mm MPRAGE. As higher‐resolution anatomical data, which have been shown to provide improved surface reconstruction accuracy, become more common, so will higher density surfaces, which will require less refinement.

---

### From molecular to macroscopic via the rational design of a self-assembled 3D DNA crystal [^1149uWFg]. Nature (2009). Excellent credibility.

We live in a macroscopic three-dimensional (3D) world, but our best description of the structure of matter is at the atomic and molecular scale. Understanding the relationship between the two scales requires a bridge from the molecular world to the macroscopic world. Connecting these two domains with atomic precision is a central goal of the natural sciences, but it requires high spatial control of the 3D structure of matter. The simplest practical route to producing precisely designed 3D macroscopic objects is to form a crystalline arrangement by self-assembly, because such a periodic array has only conceptually simple requirements: a motif that has a robust 3D structure, dominant affinity interactions between parts of the motif when it self-associates, and predictable structures for these affinity interactions. Fulfilling these three criteria to produce a 3D periodic system is not easy, but should readily be achieved with well-structured branched DNA motifs tailed by sticky ends. Complementary sticky ends associate with each other preferentially and assume the well-known B-DNA structure when they do so; the helically repeating nature of DNA facilitates the construction of a periodic array. It is essential that the directions of propagation associated with the sticky ends do not share the same plane, but extend to form a 3D arrangement of matter. Here we report the crystal structure at 4 A resolution of a designed, self-assembled, 3D crystal based on the DNA tensegrity triangle. The data demonstrate clearly that it is possible to design and self-assemble a well-ordered macromolecular 3D crystalline lattice with precise control.

---

### GRAF-pop: a fast distance-based method to infer subject ancestry from multiple genotype datasets without principal components analysis [^114V6quL]. G3 (2019). Medium credibility.

In GRAF-pop, we use the expected D values calculated using Equation (3) to find the vertices of ΔEFA, and use it as the reference triangle to calculate barycentric coordinates. When there are missing genotypes, we first calculate the barycentric coordinates using the SNPs with genotypes, then map the coordinates onto the reference triangle when no genotypes are missing. Specifically, we do the following steps to normalize the genetic distances and plot the results:

For each subject group U {E, F, A}, calculate the expected genetic distances D U1, D U2, D U3, to the first three reference populations, using Equation (3) for the full set of 10,000 fingerprint SNPs.
Represent each group with a 3-D point in space by treating D U1, D U2, D U3 as the x, y, z Cartesian coordinates. Build a triangle by connecting the three points representing the three subject groups.
Rotate and translate the triangle so that it is in the plane z = 0, and side FA is parallel to the x -axis. Denote this triangle as ΔEFA 0, to be used as the reference triangle for calculating barycentric coordinates.
Given a subject i, find the subset, T, of fingerprint SNPs with genotypes for this subject.
For each subject group U {E, F, A}, calculate the expected genetic distances D U1T, D U2T, D U3T, to the first three reference populations using Equation (4) for subset T. Represent each group with a 3-D point in the space.
Calculate the genetic distances D i1, D i2 and D i3 from subject i to the first three reference populations. Represent subject i as a 3-D point, Q, by treating D i1, D i2, D i3 as the x, y, z Cartesian coordinates.
Build a triangle by connecting the three points representing the three subject groups. Rotate and translate the three points, together with point Q, so that the triangle is in the plane z = 0. Denote this triangle as ΔEFA T.
Using the x, y coordinates of point Q after transformation, calculate the barycentric coordinates (λ ie, λ if, λ ia) for subject i with respect to ΔEFA T, using Equations (5) and (6).
Convert the barycentric coordinates back to the Cartesian coordinates (x i0, y i0) using reference triangle ΔEFA 0: where (x e0, y e0), (x f0, y f0), (x a0, y a0) are the Cartesian coordinates of the three vertices of ΔEFA 0.
Plot the converted Cartesian coordinates of subject i, together with ΔEFA 0, on the x-y plane. The final x i0, y i0 values are the normalized genetic distances, called GD1 and GD2 scores in this article and in GRAF.
The z coordinate of point Q after transformation (step 7), called GD3 score, is also used for plotting results.
Calculate the genetic distances D i4 and D i5 from subject i to the last two reference populations South Asian and Mexican/Latino. The difference D i5 - D i4, called GD4 score, is plotted against GD1 scores to separate South Asians from Latin Americans.

---

### Complex k-uniform tilings by a simple bitopic precursor self-assembled on Ag (001) surface [^111rTnDk]. Nature Communications (2020). High credibility.

Fig. 2
XPS analysis.

Detailed O 1s spectra measured on samples with BDA with 1U- to 3U-phases and a molecular phase comprising pristine BDA molecules. Spectra were acquired in high magnification mode using the pass energy of 20 eV integrating up to 180 sweeps with 0.1 s dwell time and 0.05 eV energy step. See Supplementary Discussion, X-ray photoelectron spectroscopy analysis, for details on XPS analysis.

Fig. 3
Real space STM view of self-assembled molecular networks.

These networks comprise BDA with distinct degree of carboxylation: pristine 2H-BDA, semi-carboxylated 1H-BDA and fully carboxylated 0H-BDA. a Regular tiling associated with a molecular phase comprising only 0H-BDA with tiling overlaid. b, c Detailed view of intermolecular binding motif associated with triangular tiles. d 2-uniform tiling realized by 2:1 mixture of 1H- and 0H-BDA. e 3-uniform tiling realized by 1:2:1 mixture of 2H-, 1H-, and 0H-BDA. Scale bar 2 nm.

1U-phase

The simplest tiling is expressed by 0H-BDA molecules (1U-phase, Fig. 3a): here, six triangles meet at each vertex, therefore the notation reads [3 6]. The triangular tiles express the binding motif of three 0H-BDA molecules where molecule centers present the vertices of the tiling. Here the carboxylate groups point towards the benzene ring of neighboring BDA as depicted in Fig. 4a; this binding motif is typical for carboxylates on Ag surfaces. We can recognize two kinds of triangular tiles portrayed by distinct color in Fig. 3a. The molecular structures associated with these triangles display a distinct chirality of BDA arrangement as detailed in Fig. 3b, c. XPS reveals a single O 1s component associated with a fully carboxylated BDA molecules at 530.7 eV; in agreement with the relevant systems. The single component is consistent with a symmetric binding environment of both carboxylate oxygen atoms. This phase forms micrometer-sized single domain islands as shown in Supplementary Discussion, Long-range order over large areas.

---

### Sagittal cephalometric evaluation without point nasion: sagittal G-triangle analysis [^112eosu7]. The Journal of Craniofacial Surgery (2021). Medium credibility.

MATERIALS AND METHODS

Selection of Patients

Pretreatment cephalometric radiographs (120 men and 120 women) were selected randomly from the records of orthodontic patients in the Department of Orthodontics from January 2015 to December 2020. All patients were southern Chinese, and we obtained patient consent to use their clinical records for research purposes before starting their orthodontic treatment. All lateral cephalometric radiographs were obtained using an X550 2D (J. Morita MFG, Kyoto, Japan) machine by the same technician. Patients were positioned in the cephalostat with the sagittal plane at a right angle to the path of the X-rays and the Frankfort Horizontal (FH) plane parallel to the floor. The teeth were in centric occlusion, and the lips were sealed lightly together. The digital radiographs were saved in Joint Photographic Experts Group digital format and calibrated.

We included the lateral cephalometric radiographs of the following patients:

Age range of 18 to 30 years,
No history of orthodontic treatment, trauma, or medical complications,
No pathological lesions of the cranial bone and jaw,
All bilateral anatomical structures showed good superimposition,
Normal-sized frontal sinuses,
Landmarks listed in Supplementary Digital Content, Table 1 were well visualized, and
SN-FH angle between 6.0° and 8.0°.

The G-triangle

The G-triangle was based on the geometric location of 4 bony landmarks (Bo, Ba, Po, and Or) and 1 soft-tissue landmark (G) and was constructed according to the following steps (Fig. 1):

1 Connect Ba and G, and connect Po and Or. The intersection point of line Ba–G and line Po–Or (FH plane) is defined as point I.
2 Draw a half line from Bo to I.
3 Draw a line passing G to form a 60° angle with line Bo–I. Their intersection point is defined as point X.
4 Draw an inverted equilateral triangle using line segment Bo–X as one of its sides. The third vertex of this triangle is defined as point K.
5 The equilateral triangle Bo–X–K is named the G-triangle.

FIGURE 1
The frame of G-triangle (the equilateral triangle Bo–X–K).

---

### Shaping micro-clusters via inverse jamming and topographic close-packing of microbombs [^1142WTc2]. Nature Communications (2017). Medium credibility.

Programming the degrees of freedom in topographic clusters

Empirically, the final clusters can be programmed by the number of seeds (N = 1, 2, 3,…) and the number of vertices of the well (V = 0, 3, 4, 5, and 6 for circles, triangles, squares, pentagons, and hexagons, respectively) providing topographic confinement. As shown in Fig. 5a, we analyzed over 2000 clusters. In the confinement of N = 1, single-cell particles could be created by filling the microwell, imitating the shape of the confinement. For N > 1, the differentiated cleavages were symmetric when k = V / N yielded an integer k, i.e. (V, N) = (0, 2), (0, 3), (3, 3), (4, 2), (6, 2), and (6, 3). Otherwise, clusters with random microbomb assembly were observed. Regarding the orientation of the constituent cells, the (6, 2) combination, for example, could program two types of symmetric clusters: one with a cleavage wall normal to one of the 6 edges where the interior angle of a unit is 3 π (marked as a black line), and the other containing two isosceles trapezoids (internal angle is 2 π) shares the space diagonally (marked as a blue line). In addition, it is important to note that since there are no predictable cues for the cleavage orientation in the case of the singularity (V = 0), the perfect programming of clusters (100%) for all cases of N is warranted from the non-pinning mobility in confinement. The SEM images in Fig. 5b, c reveal the hollow nature of the clusters from a triangular prism (Fig. 5b) and a cube with a cleavage connecting four cells (Fig. 5c) after focused ion beam (FIB) milling. At room temperature, the shell became glassy again, and thus the microbombs could maintain the packed shape permanently.

Fig. 5
A library of topographic clusters. a SEM images of the clusters and the corresponding illustrations. The number of cleavages of each cell corresponds to the number of the initial seeds. b, c Close-up SEM images of the triangular prisms (b) and four-cell cubes (c). The last image of each group shows the cavity within the clusters, for which they were cut by the FIB

---

### Adaptative two-phase thermal circulation system for complex-shaped electronic device cooling [^111oQ6Ud]. Nature Communications (2025). High credibility.

Topological equivalence mapping algorithm

The implementation of the 2D topological mapping algorithm for the AHP 3D triangular sheet is conducted using commercial software MATLAB. Trajectory planning of the three-dimensional point cloud is performed in CloudCompare software to obtain point coordinates along the trajectory, forming 3D triangular meshes between points on two closely adjacent trajectories. This forms the basis for mapping the surface from 3D triangular meshes to a corresponding 2D plane, guiding the planar shape design of the aluminum-plastic film casing. The specific process for implementing the topological mapping algorithm is described as follows:

Step 1: Identified the central triangle mesh within the triangulated surface model to serve as the base triangle for mapping.

Step 2: Map the base triangle onto the plane while preserving its spatial characteristics unchanged. Mark the corresponding vertices, edges, and triangle as unmapped.

Step 3: Identified the adjacent 3D triangular mesh, that currently processing. Among the triangular meshes that are not yet marked as unmapped, select one that shares an edge with a triangle already marked as unmapped to be the current triangle under processing.

Step 4: Confirm the position of the undetermined vertex of the currently processed triangle in the 2D plane. Calculate the normal vector passing through this point in the 3D surface, and determine the normal planecorresponding to this normal vector. Select a vertex adjacent to the vertex currently being processed, and determine the projection of this adjacent vertex on the normal planeof the 3D surface. Then, calculate the curvatureat the processed vertex. In the 2D plane, ensure that the curvatureof the undetermined point is the same as. This approach can allow determine the direction between the undetermined point and its adjacent point. To determine the 2D position of the currently processed point, ensure that the areaof the triangle in the 2D plane matches the areaof its counterpart in 3D space.

Step 5: Mark the currently processed point and the triangular surface as unmapped, record the number of unmapped triangles, and repeat steps 3 and 4.

---

### The function of the extraocular muscles, the theory of the coplanarity of the fixation planes [^112YVNRc]. Journal of the Neurological Sciences (2009). Low credibility.

Unlabelled

A theory of visuomotor kinematics is derived from evidence obtained by a video method that allows the eyes to gaze freely in any direction with the head stabilized in any position in space, allows the head to move freely while the eyes are stabilized in different gaze directions, and allows the eyes to move in sync with the head. Frame by frame analysis reveals no wheel-rotation (torsion) around the visual line in any gaze direction. There is dynamic rolling around the visual line during head tilt but no static counter-rolling when the head is held steady in any position. Lateral rotations are wheel-rotations around a vertical polar axes fixed in the eyes. Vertical rotations occur around collinear axes fixed in the orbits. Oblique rotations consist of successive arcs of longitude and latitude, which project as slopes (the tangent to a point on a curve). All eye movements are commutative. Head movements enable the eyes to fixate any point at any angle in 3-D space.

Conclusion

The extraocular muscles are programmed by the brain to maintain the fixation planes of the two eyes coplanar in all stable head positions and in all gaze directions. The retinas are in dynamic equilibrium with the brain and with each other in all head positions. The extraocular muscles function to maintain conjugacy, retinal correspondence, and retinotopy. The retinas are oriented to the brain and not to the horizon.

---

### Mono-planar T-Hex: speed and flexibility for high-resolution 3D imaging [^116u1hx1]. Magnetic Resonance in Medicine (2022). Medium credibility.

FIGURE 1
A, Gray dots depict part of the hexagonal grid in a transverse section of a stack of spirals or echo‐planar readouts. Blue dots mark the revolutions acquired within a shot for N = 1, 2, and 3 shots per k‐space plane. B, The hexagonal grid is described by oblique coordinates. All existing distances between grid points are represented in distances of the origin to points in one dodecant (yellow wedge), including its edges. Blue rings mark the distances reflected in (A), and the red ring highlights a distance not available with integer N. C, This distance is used when tilting the grid with respect to the rotational axis of the stack. The FE lines or spiral revolutions acquired in three subsequent shots are highlighted in red, orange, and yellow. D, The hexagonal grid is tilted as shown in (C). Red and yellow dots mark the points of the hexagonal grid that are covered by two subsequent shots. Green lines in the background show that all points of the hexagonal grid lie on nodes of a finer, rectilinear lattice, from which the starting angle of each spiral shot can be derived. Subsequent shots start with linearly progressing angles. The pattern is repetitive. E, Background: An entire mono‐planar T‐Hex stack of spirals cut open. The uppermost shot and the sites of puncture of the spirals are marked in dark gray. The resulting hexagonal grid shows the tilt as visualized in (C) and (D). In a representative patch, grid points that belong to spiral shots with the same phasing are colored the same. Foreground: Cross‐section corresponding to the stack in the upper panel, the acquisition time point is color‐coded, indicating a smoothfilter. Owing to the cross‐sectional depiction, "holes" appear on the central k‐space axis. In fact, this region is equally uniformly sampled, since all spirals start from the rotational axis of the cylinder

---

### Computed tomography imaging in the context of transcatheter aortic valve implantation (TAVI) / transcatheter aortic valve replacement (TAVR): an expert consensus document of the Society of Cardiovascular Computed Tomography [^115S9A7Z]. Journal of Cardiovascular Computed Tomography (2019). High credibility.

Aortic root and annulus definitions — TAVI/TAVR anatomical sizing defines the aortic annulus as the luminal contour within a virtual plane aligned with the most basal attachment points of the three aortic valve cusps, and quantitative assessments require accurate identification of each of these points to create a plane that transects all three. The aortic root is described as an extension of the left ventricular outflow tract from the basal attachment of the aortic valve cusps within the LVOT to their peripheral attachment at the sinotubular junction, comprising the sinuses of Valsalva, the fibrous interleaflet triangles and the valvular cusps.

---

### Evaluating brain parcellations using the distance-controlled boundary coefficient [^112NZivc]. Human Brain Mapping (2022). Medium credibility.

2.5.2 Averaging across bins

Parcellations can be compared by investigating the difference in within‐parcels and between‐parcels as a function of the spatial distance (see King et al. figs. 3 and 4). However, for many applications we would like a single evaluation criterion for each parcellation, which necessitates the averaging across a range of spatial distances. This raises the question of what range of spatial distances to consider, and how to weight the distances within that range. A rational solution to this problem is to find the weighting that, for any given parcellation, provides us with the best estimate of the average difference between within‐parcel and between‐parcel correlations, assuming that this difference is constant across the desired range of distances. The variance of the estimate of the correlation difference for bincan be approximated by assuming the independence of the different vertex pairs. In this case, the variance of the estimate depends on the number of within‐parcel and between‐parcel vertex pairs in each spatial bin:

For averaging, we define a weight that is proportional to the precision (inverse of the variance) of each estimator:

For example, Figure 1c shows the weighting factor for each spatial bin of Icosahedron 162 random parcellation using a 1 mm bin width. The DCBC is then the weighted average of the correlation difference across bins.

2.6 Random parcellations

To evaluate the DCBC for parcellations that on average do not align with real functional boundaries, we generated a set of random parcellations. If our method successfully controls for the spatial smoothness of the functional profiles, the average DCBC for such random parcellations should be zero, that is, there should be no difference between within‐parcel and between‐parcel correlations. To test this claim for parcellations at different spatial scales, we used a regular hexagonal parcellations of a sphere (Icosahedron) with 42, 162, 362, 642, and 1002 parcels (see Figure 2). To generate random alignment of this parcellation with the data, we rotated each map randomly around the x, y, and z axis. We repeated this process 100 times to obtain 100 random parcellations for each spatial scale.

FIGURE 2
Random cortical parcellations with different number of parcels

---

### Fast and sensitive mapping of nanopore sequencing reads with graphMap [^11277mHM]. Nature Communications (2016). Medium credibility.

The intuition is as follows: given a point (x, y) in Cartesian space, its parameter space representation defines a line. If multiple Cartesian space points are given, each transforms into a different line in the parameter space. Their intersections specify potential lines in the original, Cartesian space. HT defines an accumulator space, in which m and c are rasterized so as to take only a finite range of values. HT then simply counts all the potential solutions in the accumulator space by tracing all the dual lines for each point in the Cartesian space, and increasing the vote count for each (m, c) coordinate. All HT space coordinates with count above a defined threshold can then be considered as candidate lines in the original Cartesian space.

A single-seed hit can be represented with a ' k -point' (q, t) in 2D space, where q is the seed's position on the read, and t is the position of the seed hit on the reference. In the case a read is completely error-free and extracted from the exact reference, its set of k -points would be perfectly collinear in such defined space. Moreover, under these ideal conditions, they would all lie on a line tilted at a 45° angle (slope m = 1). This collinearity also corresponds to the main diagonal in the dynamic programming alignment matrix. Since m is known, only the intercept parameter c needs to be determined to find the accurate mapping position. As c corresponds to the (already discrete) coordinates on the reference sequence, a simple integer array of the length of the reference can be used for counting votes (Fig. 1c). For each k-point, its c parameter value is determined with a simple expression:

---

### Multiple tipping points and optimal repairing in interacting networks [^112rr1pt]. Nature Communications (2016). Medium credibility.

The problem of optimal repairing

Knowing and understanding the phase diagram of interacting networks enable us to answer some fundamental and practical questions. A partially or completely collapsed system of n ≥ 2 interacting networks in which some of them are in the low activity state is a scenario common in medicine, for example, when diseases or traumas affect the human body and a few organs are simultaneously damaged and need to be treated, and the interaction between the organs is critical. It is also common in economics, when two or more coupled sectors of the economyexperience simultaneous problems, or when a few geographical clusters of countries experience economic difficulties. The practical question that arises is: what is the most efficient strategy to repair such a system? Many approaches are possible if resources are unlimited, but this is usually not the case and we would like to minimize the resources that we spend in the repairing process.

For simplicity, consider two interacting networks, both damaged (low activity). Is repairing both networks simultaneously the more efficient approach, or repairing them one after the other? What is the minimum amount of repair needed to make the system fully functional again? In other words, what is the minimum number of nodes we need to repair, to bring the system to the functional 11 ('up–up') state, and how do we allocate repairs between the two networks? An optimal repairing strategy is essential when resources needed for repairing are limited or very expensive, when the time to repair the system is limited, or when the damage is still progressing through the system, threatening further collapse, and a quick and efficient intervention is needed.

We show below that this problem is equivalent to finding the minimum Manhattan distance between the point in the phase diagram where the damaged system is currently situated and the recovery transition lines to the 11 region. The Manhattan distance between two points is defined as the sum of absolute horizontal and vertical components of the vector connecting the points, with defined vertical and horizontal directions. It is a driving distance between two points in a rectangular grid of streets and avenues. In our phase diagram, it is equal to. It turns out that two triple points of the phase diagram play a very important role in this fundamental problem. We find that these special points have a direct practical meaning and are not just a topological or thermodynamic curiosity.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^113ask4c]. Annals of the American Thoracic Society (2023). High credibility.

Basic stereological measurements — first-order parameters and probes identify that "First-order parameters are volume (three-dimensional [3D]), surface (two-dimensional [2D]), length (one-dimensional [1D]), and number (zero-dimensional [0D])". Measurements "are performed using geometric test probes, such as points (0D), lines (1D), planes (2D), or volumes (3D)". These probes create countable events in the image, and "Raw counts provide ratios… that are multiplied by the reference space volume to obtain absolute measures for the lung or subcompartment".

---

### Local self-uniformity in photonic networks [^1114Eczs]. Nature Communications (2017). Medium credibility.

In Fig. 2a, b, we note that that the two trihedra and tetrahedra could be made to overlap exactly for their respective root edge permutations. In fact, pairs of either trihedra or tetrahedra will overlap exactly for all root edge permutations and have a spatial similarity statistic of unity. This property of trihedral and tetrahedral units is a corollary of work on strong isotropy. There exist only three strongly isotropic networks in three dimensions or less. In three dimensions, these networks are diamond (Fig. 1b) and single gyroid (Fig. 1e). In two dimensions, the honeycomb network is the only strongly isotropic network.

We consider now a third set of example 1-trees — two identical simple cubic network units (Fig. 2c), each with six edges about a central vertex — and calculate their spatial similarity statistic. We find that perfect overlap can be achieved for specific root edge permutations, but in most cases there is no congruent transformation to align the two trees correctly; we call such a permutation inaccessible (this is depicted in Fig. 2c). As a result, the simple cubic crystal does not possess a strong isotropy property. In the remainder of this paper, we focus on trees comprising trivalent and tetravalent vertices only.

To build a robust measure of network structural order, we require a formalism that can compare the trees of arbitrarily disordered networks. We thus build upon the measurement of tree spatial similarity statistics in the following ways. We stipulate that the CRN from which the trees are drawn comprises only vertices with a fixed number of edges. We then generalize the measurement of tree spatial similarities to n -trees of any size. In this case, the correct edge overlap pairings are not known beyond the root edges. To solve this, we have developed an algorithm which determines the natural edge overlaps; this is detailed in the Methods section. We also allow the similarities of arbitrarily disordered trees to be measured. Here we acknowledge that the root edges of two trees will not necessarily overlap perfectly. Instead, for each permutation we find a transformation that yields an approximate overlap. We then quantify the quality of this overlap according to a metric of spatial similarity (see Methods section).

---

### Symmetry breaking in optimal transport networks [^114BD1Dv]. Nature Communications (2024). High credibility.

Real-world cities

In this section, we study the properties of the subway systems in Atlanta, Boston, and Toronto under the lens of our framework. We choose monocentric cities, fairly isolated from other major urban centers, with a tree-like subway structure. We identify the intersection point of the real subway lines in all three cases as the city center. We see that this point corresponds to the downtown area in the three cities.

First, we incorporate real population data in our model. We rely on a two-dimensional triangular lattice multiplex model; we use the population data and the appropriate coordinates reference systems to impose the triangular lattice structure onto the city landscape. Details on the data and modeling of the city population distribution can be found in the Methods section. We denote all quantities relative to the real physical system using the same notation as for the multiplex model, but we add a tilde on top of the corresponding symbol. For example, R indicates the radius of the lattice model, anddenotes the radius of the city. Overlaying a city on top of the triangular lattice allows us to associate a weightto each node n in the slow layer that reflects the real population density within the city. We use those weights in the objective function of Eq. (6), and then take advantage of the greedy algorithm to obtain approximate solutions to the optimization problem of Eq. (4). Similar to the previous sections, we obtain two classes of optimal fast-layer configurations for all the considered parameters. Results for the city of Toronto are displayed in Fig. 4, where we see that optimal configurations comprise k ✱ = 1 (Fig. 4 a) or k ✱ = 2 (Fig. 4 b) branches. Similar results are valid for Atlanta and Boston, where we observe optimal configurations with k * ≤ 3 branches (see Supplementary Information Figure 11). For k * > 1, we note that the branches have no identical length; this is caused by the fact that the weight associated with the various nodes of the system is not constant. A typical phase diagram for Toronto is displayed in Fig. 4 c, where we fix η = 0.5, but vary L and c. The diagram is qualitatively similar to the one of Fig. 3 e. For fixed c, k * increases as L grows; however, for fixed L, k * decreases as c grows. The values of the parameters where the transitions between the various phases emerge differ from those of Fig. 3 e; this is due to the non-homogeneous density of the population used in the model of the city. Similar results for Atlanta and Boston can be found in the Supplementary Information Figure 11.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^114DsCEp]. Annals of the American Thoracic Society (2023). High credibility.

Basic stereological measurements for lung imaging — first-order parameters, probes, and reference space are specified. First-order parameters are volume (three-dimensional [3D]), surface (two-dimensional [2D]), length (one-dimensional [1D]), and number (zero-dimensional [0D]). Measurements are performed using geometric test probes, such as points (0D), lines (1D), planes (2D), or volumes (3D), with probe–voxel interactions generating countable events; raw counts yield ratios that are multiplied by the reference space volume to obtain absolute lung or subcompartment measures. It is crucial to define and measure a biologically meaningful reference space for analysis and reporting, because measurements expressed only as ratios are subject to "the reference trap", where changes can arise from the numerator, denominator, or both; an efficient volume measurement method, point counting, is used for acinar components by micro-CT and for extrapulmonary organ volume by CT.

---

### Metallosupramolecular self-assembly of a universal 3-ravel [^116ETJfm]. Nature Communications (2011). Medium credibility.

In the realm of supramolecular chemistry, a small number of intricately interwoven structures that bridge the boundaries between art and science have been reported. These motifs, which typically form on the nanometre scale, display both considerable beauty and complexity. However, the generation of new topologies of this type has remained a very significant synthetic challenge. Here, we describe the synthesis of a discrete highly intertwined metallosupramolecular assembly based on a universal 3-ravel motif-a topology as yet unprecedented in supramolecular chemistry. The exotic, 20-component, [Fe(8)L(12)] ravel entanglement may be considered as a 'branched knot', with individual molecules displaying either left- or right-handed chirality. The formation of this cluster was demonstrated by single-crystal and powder X-ray diffraction. The arrangement is stabilized by a favourable combination of π-π interactions and Nature's tendency to minimize voids in molecular architectures.

---

### A selection and targeting framework of cortical locations for line-scanning fMRI [^114CrfC9]. Human Brain Mapping (2023). Medium credibility.

3 RESULTS

3.1 Anatomical measures confirm accurate line‐planning

First, we used anatomical information to assess planning accuracy. We created a binarized mask representing the nominal line by taking the middle 16 voxels (indicative of the nominal 4 mm gap between saturation pulses) in the phase encoding direction along the frequency encoding direction. Of note, due to the imperfect nature of these saturation slabs, there are contaminating signals coming from outside the region‐of‐interest (Raimondo, Knapen, et al; Raimondo, Priovoulos, et al.). Because the full registration cascade from target vertex to the line through the low‐resolution image, partial FOV image, and single slice is known, we can project the nominal line image back onto the surface (Figure 3a, b). This showed that for all subjects, the line was indeed placed on the target site as per the overlap of the line (white) and target vertex (red spot) (Figure 3c).

FIGURE 3
Assessment of line‐placement accuracy using anatomical measures. The registration cascade from target vertex (a) to line‐scanning acquisition (b; outer right panel) is known after registering the anatomical image from Session 1 (high‐res) to the anatomical image from Session 2 (low‐res). Within Session 2, we acquired a partial field‐of‐view image (partial FOV), as well as the anatomical slice without OVS pulses (slice). From this slice, we created an image representing the nominal line (line). For each subject, we projected this nominal line image back to the surface from which the target vertex originated, showing sufficient overlap between the target vertex (red dot) and nominal line image (white patches) (c). The patches represent the location at which the nominal line image intersects with GM and looks scattered due to unfolding of the cortex. (d) Variation in registration outcomes after registration anatomies from Sessions 1 and 2, a hundred times for each subject. (e) Effect of subject motion by means of manual alignment of the single slice images on positional stability of the target coordinate. (f) Curvature distributions within the gray patch intersecting with the target location of (c). The curvature is measured as 1/r, where r is the radius of an inscribed circle. Since mean curvature is the average of the two principal curvatures, it has the units of 1/mm.

---

### The XZZX surface code [^114fd6hd]. Nature Communications (2021). High credibility.

This structured noise model thus leads to two distinct regimes, depending on which failure process is dominant. In the first regime where, we expect that the logical failure rate will decay like. We find this behaviour with systems of a finite size and at high bias where error rates are near to threshold. We evaluate logical failure rates using numerical simulations to demonstrate the behavior that characterises this regime; see Fig. 6 (a). Our data show good agreement with the scaling ansatz. In contrast, our data are not well described by a scaling.

Fig. 6
Sub-threshold scaling of the logical failure rate with the XZZX code.

a Logical failure rateat high bias near to threshold plotted as a function of code distance d. We use a lattice with coprime dimensions d × (d + 1) for d ∈ {7, 9, 11, 13, 15} at bias η = 300, assuming ideal measurements. The data were collected usingiterations of Monte-Carlo (MC) samples for each physical rate sampled and for each lattice dimension used. The physical error rates used are, from the bottom to the top curves in the main plot, p = 0.19, 0.20, 0.21, 0.22 and 0.23. Error bars represent one standard deviation for the Monte-Carlo simulations. The solid lines are a fit of the data to, consistent with Eq. (2), and the dashed lines a fit to, consistent with Eq. (3) where we would expect, see Methods. The data fit the former very well; for the latter, the gradients of the best fit dashed lines, as shown on the inset plot as a function of, give a linear slope of 0.61(3). Because this slope exceeds the value of 0.5, we conclude that the sub-threshold scaling is not consistent with. b Logical failure ratesat modest bias far below threshold plotted as a function of the physical error rate p. The data (markers) were collected at bias η = 3 and coprime d × (d + 1) code dimensions of d ∈ {5, 7, 9, 11, 13, 15} assuming ideal measurements. Data is collected using the Metropolis algorithm and splitting method presented in refs. The solid lines represent the prediction of Eq. (3). The data show very good agreement with the single parameter fitting for all system sizes as p tends to zero.

---

### Voxel volume overlap: voxel-size sensitive indicators of subject motion in functional MRI [^113P1Zbp]. Human Brain Mapping (2025). Medium credibility.

When calculating subject motion, it is important to be precise about the respective reference frame. If motion is calculated w.r.t. the first image in a timeseries, this measure is known as total displacement (TD). It describes how far away from the original position a subject moved in the course of the session. This, however, is not necessarily the most relevant measure, as slow movements are more easily accounted for than rapid motion spikes (Maknojia et al.). For the latter in particular, scan‐to‐scan displacement (STS) is more relevant, which uses the individually preceding volume as the reference frame. The way these two indicators are calculated is similar, using a 3D expansion of Pythagoras theorem (Wilke) to calculate the joint displacement resulting from all shifts and all rotations.

2.1 Open Questions

While it is trivial to estimate the volumetric effects of simple shifts (see example in the introduction), it is far from trivial to account for rotations as there is a multitude of possible rotatory effects, and their combinations, on a 3D volume. Computing the exact overlap between two arbitrarily‐rotated cubic volumes, therefore, is mathematically highly challenging. However, while no elegant algebraic solution exists, it is possible to assess the overlap by using a geometric approach. Here, the reference voxel is defined as the intersection of six planar boundaries, with each plane dividing space into two categories: "definitely outside" and "potentially inside"; the intersection of all "potentially inside" volumes then unequivocally defines the cube. For example, consider a dice on a table and its top surface showing, for example, "1". Everything above that surface is outside of the dice, while everything below may be inside. The lower (opposite) surface will then be defined by the face of the dice showing "6", which in our example is facing the table. Again, everything below that surface is outside. Repeating this process of exclusion with the "4 & 3" and the "2 & 5" faces will unequivocally define the space, and hence, the volume of the dice. The intersection of a moved cube with a reference cube can therefore be calculated by iteratively looping over all six planes (of the reference cube) and by therewith removing all "definitely outside" sections (of the moved cube). The remaining part constitutes the overlapping remnant of the moved cube, the volume of which can then be computed.

---

### Multiple tipping points and optimal repairing in interacting networks [^114HPnCJ]. Nature Communications (2016). Medium credibility.

To optimize repairing we need to minimize this metric. Figure 5 shows the solution to the minimization problem and a detailed discussion is provided in the Methods section. The different colours in Fig. 5 correspond to the different optimal repair strategies, which depend on the failure state of the system. If the system is initially at point S 1, both networks are in a low activity state, that is, they are non-functional. Our goal is to decreaseand, and arrive to the region where the system is fully recovered (the green region) by performing a minimal number of repairs, that is, minimal N rep. We find that for any point in the red region there are actually two closest points in the green region, at an equal Manhattan distance away from the red region point. These two points are the triple points R1 and R2 shown in Fig. 5, which also correspond to the triple points in Fig. 2b. Although R1 may be closer to point A than R2 by Euclidian distance, the Manhattan distance is the same. Thus, two equally good repairing strategies are available. One involves allocating more node repairs to network A and the other allocating more repairs to network B. For the yellow regions (points S 2 and S 3), the closest points by Manhattan distance are R1 (for point S 2) or R2 (for point S 3). Here, only one triple point represents the optimal solution. It is noteworthy that the path samples in Fig. 5 are 'zig-zag' in shape (to highlight that we are minimizing); however, even when a diagonal path (direct straight line) to a triple point is used, the Manhattan distance is the same. For the dark blue regions (points S 4 and S 7), the optimal strategy is to decreaseonly, until the system is recovered. Similarly, for the light blue regions (points S 5 and S 6), the optimal strategy is to decrease only.

From our optimal repairing strategy analysis we find that the order of repair (the specific path taken between the initial point and final point) does not affect the final result. Minimizing the Manhattan distance only determines the optimal destination point. Therefore, there is actually a set of paths corresponding to equally optimal repairing processes.

---

### Allelic complexity of KMT2A partial tandem duplications in acute myeloid leukemia and myelodysplastic syndromes [^115JPdp4]. Blood Advances (2022). Medium credibility.

Figure 2.
Emergence of KMT2A -PTD complexity during progression to AML and relapse. (A) Copy number ratios of KMT2A -PTDs at first available time points by diagnosis were unimodal in MDS (P = 0.843; dip test) and multimodal in AML (P = 0.027) with 2 main clusters presumed to correspond roughly to simple and complex KMT2A -PTDs. High ratios were accordingly enriched in AML (33/73; 45%) over MDS (3/25; 12%) (P = 0.003; Fisher's exact test) relative to a cutoff (1.6) separating pure simple KMT2A -PTD cells (area shaded light blue) from complex (area shaded pink). Red: cases with secondary AML transformation from MDS (N = 7) or PV (N = 1). Box plots within violin plots: rectangles correspond to interquartile ranges, and whiskers have length equal to 1.5 times interquartile range or end at most extreme outliers. (B) 11q23.3 gain from the PTD allele emerged in a rapidly progressing AML that transformed from MDS with simple KMT2A -PTD (P3). Panels C and D show quantitative evolution of KMT2A -PTD complexity in 2 cases of AML (P3 and P4). Complex, simple, and wild-type components are determined from total copy number (TCN) of PTD exons (y-axis) vs TCN of distal 11q23 (x-axis): vertices of the triangle represent 100% populations of wild-type diploid KMT2A (green vertex), simple PTD (blue vertex), and complex PTD with single PTD gain (red vertex); because TCN is linear, line segments connecting 2 vertices represent mixtures of the 2 corresponding components, whereas the triangle (convex hull of the vertices) represents mixtures of all 3 (wild-type, simple PTD, and complex PTD). (C) 11q23.3 gain from the PTD allele emerged at d112 (blue point 2) and expanded as the dominant clone at d170 (purple point 3 corresponding to copy number profile in panel B). The complex gain at d112 was below the BR-CNV limit of detection, but its low-level presence (> 3%) was inferred from clonal hierarchy, based on an NRAS variant that appeared at d112 but was subsequently deduced as subclonal to the complex PTD at d170 (supplemental Figure 13A). TCN levels at d170 (distal 11q23 = 2.7, PTD exons = 4.4) implied a mixed population comprising c = 70% complex KMT2A -PTD, s = 30% simple KMT2A -PTD, and w = 0% wild-type, by solving the linear constraints (1) TCN of distal 11q23 = 2.7 = 3c + 2s + 2w, (2) TCN of PTD exons = 4.4 = 5c + 3s + 2w, and (3) 1 = c + s + w. (D) 11q23.3 gain from the PTD allele emerged at posttransplant relapse from a previously simple KMT2A -PTD before transplant. The simple KMT2A -PTD component diminished (24% to 16% to 3%) as the complex component expanded (48% to 73% to 96%) over the course of 102 days. WT, wild-type.

---

### A versatile computational algorithm for time-series data analysis and machine-learning models [^111yhXM7]. NPJ Parkinson's Disease (2021). Medium credibility.

Now consider the 3x3 neighborhood around each vector element being constructed from.represents our one-dimensional time-series vector that can be used for time-delay embedding with delay t and embedding dimension m to reconstruct the phase-space trajectory. However, instead of considering the Euclidean norm between data points:we will consider vectors V i and V j in relation to their local 3x3 neighborhood such that:where it can be seen that≠even when = (Fig. 1a). It follows then, that directional and curvature information can be captured by different inequality patterning around the 3x3 neighborhood when computed for allby constructing a new matrix that represents an 8-bit binary code for each point-pair's local neighborhood:where g 0 representsand g n = { g 1, …, g 8 } are its eight connected neighbors. Each neighbor which is larger or equal to g 0 is set to 1, while each neighbor that is smaller than g 0 is set to 0. A binary code is thus created by moving around the central point g 0 (here counterclockwise) where a single integer value is calculated based on the sum of the binary code elements (0 or 1) multiplied by the eight 2 p positional weights (increments of powers of 2: 2 0, 2 1, 2 2, 2 3, 2 4, 2 5, 2 6, 2 7) starting with the preceding points (i.e.). This represents 8-bit binary coding where there are 2 8 (256) different possible integer values, ranging from 0 to 255. This newly created matrix now allows for the identification of graded changes in phase-space trajectories that can be used to identify recurring sets of local topological features embedded within the dynamic signal (LoTRA plot; see Fig. 1b, c for example).

---

### Atomic model of vesicular stomatitis virus and mechanism of assembly [^1113mAcu]. Nature Communications (2022). High credibility.

Fig. 5
The super-complexes of G trimers visualized by subtomogram averaging and the relationship between the spatial organization of OM and G.

a Averaged density maps of G trimer in prefusion conformation. Images in the second and third row are orthogonal slice views; locations are indicated by green and magenta dashed lines in the first image. No adjacent densities show in the orthogonal views. b, c Averaged density maps of G trimer in postfusion conformation before classification and G trimers classified by different numbers of neighboring G trimers (super-complexes). b The averaged density map of all subtomograms. c The averaged density maps of G trimer with 0 (first column), 1 (second column), 2 (third column) and 3 (fourth column) neighboring G trimers. Images in the first row are side views of the averages; images in the second and third row are orthogonal slice views; locations are indicated by blue and golden dashed lines in the first image. d Distribution of the distances of the first five nearest neighbors for each G trimer. The dashed curve shows the fitting of a three-term Gaussian model. The second peak (113.4 Å) is between the widths of hexagon (117.6 Å) and pentagon (109.8 Å), which have an identical side length (67.9 Å, the first peak), indicating a mixture of hexagonal and pentagonal tiles. Distances between neighboring subunits (e) and different hexagons at different radial positions based on geometric consideration (f). Each dot on a hexagon represents the intersection point on the N, IM or OM cylinder by the radial projection line connecting the center of the VSV cylinder to a G subunit on the VSV envelope. Note that the indicated distance between G subunits matches those observed in our tomogram shown in (Fig. 4d) and in the crystal structure (Supplementary Fig. 3d). g, h Hexagonal arrangement of G trimers in both prefusion and postfusion conformations. The distances between OMs underneath the membrane match the distances between neighboring DIV pairs of prefusion G trimers outside the membrane.

---

### Lunar rock investigation and tri-aspect characterization of lunar farside regolith by a digital twin [^115P6zYk]. Nature Communications (2024). High credibility.

Wheel-terrain interaction states solution

For a grouser wheel moving on deformable terrains, its wheel-terrain interaction area is shown as the left red box in Supplementary Fig. 4. In this figure, {Σ I } is the inertial frame; {Σ e } is the wheel-terrain interaction frame. {Σ c } is the wheel center frame, and its origin is on the wheel center and its orientation is the same as the interaction frame. To determine the wheel-terrain interaction plane, three points (P 1 (x 1, y 1, z 1), P 2 (x 2, y 2, z 2), and P 3 (x 3, y 3, z 3)) both on the plane and at the edge of the wheel surface are selected for calculation. P 2, and P 3 are on the outer hoops of the wheel and coincide with the entrance angle, while P 1 is on the middle hoop of the wheel coinciding with the exit angle. The positions of P 1, P 2, and P 3 are calculated using the rotation matrix R e of the wheel-terrain interaction frame {Σ e } relative to the inertial frame {Σ I } at the last time step, and the position of the wheel center p c at this time step. Therefore, the corresponding homogeneous transform matrix T c for calculation is represented inwhereis a zero matrix with one row and three columns.

The terrain map is usually divided into triangle meshes, such as A 1 - A 2 - A 3, A 1 - A 3 - A 4. Each node of the triangular mesh has associated geometric and mechanical parameters. If the contact point P i (i = 1, 2, 3) lies in such a mesh, then the normal coordinate information of point P i can be obtained by linearizing and interpolating asin which (1- u - v), u, and v are the weight coefficients of nodes A 1, A 2, and A 3, respectively, ranging from 0 to 1.

With these determined points on the wheel-terrain interaction plane, the wheel sinkage z, and the rotation matrix of {Σ e } relative to the initial frame {Σ I } at this time step used for the next iteration can be calculated according ref.

---

### The burden of proof studies: assessing the evidence of risk [^111DkJmb]. Nature Medicine (2022). Excellent credibility.

Spline ensemble

To make the risk function estimates robust to knot placement, we created 50 models based on random knot placement samples. Spline estimates depend on the choice of spline parameters, including spline degree, number of knots and knot placement. To mitigate the effect of spline parameter selection on results, we developed an ensemble approach over knot placement, so that the modeler only had to specify the spline degree and number of knots.

Given the degree and number of knots, we automatically sampled a set of knot placements for a feasible knot distribution. For each knot placement, we fit a spline (including nonlinear measurements, shape constraints and trimming), evaluated each resulting model by computing its fit and curvature, and aggregated the final model as a weighted combination of the ensemble.

Sampling knots from simplex

We prefixed a minimal set of rules that describe a feasible set from which to sample knots, and uniformly sample from this set. Given a number of knots, the rules specify feasible ranges for each knot and feasible gaps between knots. Given an intervaldelimited by terminal knots (which are always the minimum and maximum of the data), the feasible region of the interior knotsis denoted by

We enforced the rules

The set of knot placements that satisfy these four rules form a closed polyhedron (a volume in high-dimensional space delineated by hyperplanes). We calculated the vertices of the polyhedron using the double description method in ref. and uniformly sampled knot placements from within the polyhedron. Each knot placement yielded a model, fit using the trimmed constrained spline approach.

Ensemble performance evaluation

Once the ensemble was created, we scored the resulting risk curves using two criteria: model fit (measured using the log-likelihood) and total variation (measured using the highest order derivative). These scores balanced competing objectives of fit and generalizability. Once we had these scores, denoted as s 1 and s 2, we normalized them to the range [0,1]:and applied a logistic transformation. The transformation was used to make the scoring meaningful even in the presence of spurious curves in a large ensemble. We then multiplied the scores to down-weight models that are low under either criterion (fit or total variation). The final weights are normalized to sum to 1.

Using a weighted combination of these metrics, we weighted the 50 models to create the ensemble model.

---

### Quantitative mappings between symmetry and topology in solids [^116GbBWC]. Nature Communications (2018). Medium credibility.

The study of spatial symmetries was accomplished during the last century and had greatly improved our understanding of the properties of solids. Nowadays, the symmetry data of any crystal can be readily extracted from standard first-principles calculation. On the other hand, the topological data (topological invariants), the defining quantities of nontrivial topological states, are in general considerably difficult to obtain, and this difficulty has critically slowed down the search for topological materials. Here we provide explicit and exhaustive mappings from symmetry data to topological data for arbitrary gapped band structure in the presence of time-reversal symmetry and any one of the 230 space groups. The mappings are completed using the theoretical tools of layer construction and symmetry-based indicators. With these results, finding topological invariants in any given gapped band structure reduces to a simple search in the mapping tables provided.

---

### 2023 U.S. department of veterans affairs and U.S. department of defense clinical practice guideline for the management of headache [^114Cv7iS]. Annals of Internal Medicine (2024). High credibility.

Algorithm — this clinical practice guideline (CPG) algorithm is designed to facilitate understanding of the clinical pathway and decision-making process used in managing patients with Headache, and the format represents a simplified flow that helps foster efficient decision making by providers; it includes steps of care in an ordered sequence, decisions to be considered, decision criteria recommended, and actions to be taken; the algorithm is a step-by-step decision tree, with standardized symbols to display each step and arrows connecting numbered boxes indicating the order in which the steps should be followed; shape meanings are specified: rounded rectangles represent a clinical state or condition, hexagons represent a decision point in the process of care formulated as a question that can be answered "Yes" or "No", rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm; Sidebars 1–7 provide more detailed information, and Appendix K contains alternative text descriptions of the algorithms.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^117RnEwN]. Annals of the American Thoracic Society (2023). High credibility.

Image registration and landmarks — image registration requires reliable tracking of landmarks; the accuracy of landmark identification is usually impossible to validate, and landmarks may be affected by disease, for example fissures for tracking lobar volume may be obliterated in advanced COPD or interstitial lung disease or congenitally incomplete or absent.

---

### HURP facilitates spindle assembly by stabilizing microtubules and working synergistically with TPX2 [^111HWtbi]. Nature Communications (2024). High credibility.

Analysis of in vitro γ-TuRC-mediated microtubule nucleation assay data

For each movie, we started by processing the entire field of view (81.45 μm x 81.45 μm) for the 5 min movies using Fiji. The movies were corrected for thermal drift (translation) by using the StackReg plugin(RRID:SCR_003070). To correct for severe drift, we cropped the corrected stack to a 75.09 μm x 75.09 μm square, allowing us to perform the StackReg function again. We wrote a macro in Fiji to semi-automate data analysis. The macro generates kymograph (time-space) plots, using the KymoResliceWide plugin based on manual tracing of individual MTs, and prompts the user to extract relevant parameters from the kymographs.

For each kymograph produced, the user is first prompted to determine if the MT is spontaneously nucleated or γ-TuRC mediated. MT kymographs where the tubulin signal formed a right triangle were considered γ-TuRC-mediated. Random appearances of a long MT or a MT that grew from both ends, indicating that the minus end is not capped by γ-TuRC, were marked spontaneous. The location of each MT was recorded and numbered on a separate Z-projected map to prevent double-counting. If a MT was determined to be γ-TuRC-mediated, we proceeded collecting measurements. We manually recorded the nucleation point (origin) for each MT.

Time of nucleation for each MT was analyzed using a Python script in Jupyter Notebookand averaged across all reactions for each condition. The mean and standard error of the mean (SEM) for the number of MTs over time were plotted as shown in Fig. 4b. To determine the rate of γ-TuRC-mediated MTs formed, we fit the MT number curve for each condition to the following condition as done previously:

In Eq. (1), = the number of MTs nucleated at a given timepoint (t), = maximum number of MTs at the final timepoint (360 s), and = the rate of MT formation. Fitting was done using the scipy.optimize curve_fit functionto determine theand. The standard deviations of thefit for each condition are provided in Fig. 4b. Additionally, two-tailed Student's t-test was performed on the average MTs (± SD) at the final timepoint of each condition to determine significance.

---

### Geometry analysis and systematic synthesis of highly porous isoreticular frameworks with a unique topology [^116NjDHe]. Nature Communications (2012). Medium credibility.

Porous coordination polymers are well known for their easily tailored framework structures and corresponding properties. Although systematic modulations of pore sizes of binary prototypes have gained great success, simultaneous adjustment of both pore size and shape of ternary prototypes remains unexplored, owing to the difficulty in controlling the self-assembly of multiple molecular building blocks. Here we show that simple geometry analysis can be used to estimate the influence of the linker lengths and length ratios on the synthesis/construction difficulties and framework stabilities of a highly symmetric, ternary prototype composed of a typical trinuclear metal cluster and two types of bridging carboxylate ligands. As predicted, systematic syntheses with 5×5 ligand combinations produced 13 highly porous isoreticular frameworks, which show not only systematic adjustment of pore volumes (0.49–2.04 cm(3) g(-1)) and sizes (7.8–13.0 Å; 5.2–12.0 Å; 7.4–17.4 Å), but also anisotropic modulation of the pore shapes.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^115WnyVt]. Annals of the American Thoracic Society (2023). High credibility.

Airway comparative analysis — matching approaches and caveats: Table 5 outlines selection criteria with example metrics and considerations, including designation of "Terminal bronchiole", designating a generation number for each airway, path distance (e.g., 5 cm from carina or pleura), lumen size (e.g., 2-mm-diameter airways), and airways at a stipulated inner perimeter with wall thickness of airways with inner perimeter of 10 mm (Pi10); considerations note pathology may alter airway status, anatomical variations in branching pattern, body and lung size variations, risk of bias when pathology alters airway dimension (e.g. COPD may narrow airway lumens; therefore, 2-mm airways may occur at a different generation compared with subjects without COPD), and that regression assumptions should be confirmed with potential effects of outliers assessed.

---

### Nuclear fission modes and fragment mass asymmetries in a five-dimensional deformation space [^113mm3zF]. Nature (2001). Excellent credibility.

Nuclei undergoing fission can be described by a multi-dimensional potential-energy surface that guides the nuclear shape evolution — from the ground state, through intermediate saddle points and finally to the configurations of separated fission fragments. Until now, calculations have lacked adequate exploration of the shape parameterization of sufficient dimensionality to yield features in the potential-energy surface (such as multiple minima, valleys, saddle points and ridges) that correspond to characteristic observables of the fission process. Here we calculate and analyse five-dimensional potential-energy landscapes based on a grid of 2,610,885 deformation points. We find that observed fission features — such as the distributions of fission fragment mass and kinetic energy, and the different energy thresholds for symmetric and asymmetric fission — are very closely related to topological features in the calculated five-dimensional energy landscapes.

---

### Rivaroxaban (Xarelto) [^112FjXDc]. FDA (2025). Medium credibility.

3 DOSAGE FORMS AND STRENGTHS

2.5 mg tablets: Round, light yellow, and film-coated with a triangle pointing down above a "2.5" marked on one side and "Xa" on the other side
10 mg tablets: Round, light red, biconvex and film-coated with a triangle pointing down above a "10" marked on one side and "Xa" on the other side
15 mg tablets: Round, red, biconvex, and film-coated with a triangle pointing down above a "15" marked on one side and "Xa" on the other side
20 mg tablets: Triangle-shaped, dark red, and film-coated with a triangle pointing down above a "20" marked on one side and "Xa" on the other side
For oral suspension: white to off-white granules; once reconstituted, provide flavored white to off-white opaque liquid with a concentration of 1 mg/mL.

Tablets: 2.5 mg, 10 mg, 15 mg, and 20 mg (3)
For oral suspension: 1 mg/mL once reconstituted (3)

---

### Realization of higher-order topological lattices on a quantum computer [^115QfUXC]. Nature Communications (2024). High credibility.

Fig. 5
Quantum processor measurements of HOT corner modes on a 4D tesseract lattice.

A L = 6 tesseract lattice is illustrated as six cube slices indexed by w and highlighted on a color map. The header row displays energy spectra computed numerically for the topologically trivial C0 and nontrivial C4, C8, and C16 configurations. The configurations host 0, 4, 8, and 16 midgap zero modes (black circles). Schematics on the right illustrate the locations of the topologically robust corners. Subsequent rows depict the time-evolution of three initial states on a 6 × 6 × 6 × 6 lattice mapped onto a 24-qubit chain — localized on a a corner, b an edge, and c a face. The leftmost column plots occupancy fidelity for the various lattice configurations, obtained from ED and quantum hardware (labeled HW), with insets showing the site-resolved occupancy density ρ (x, y, z, w) of the initial state. Central grid shows occupancy density measured on hardware at the final simulation time (t = 0.6), for the corresponding initial state (row) and lattice configuration (column). The color of individual sites (spheres) denotes their w -coordinate and color saturation denotes occupancy of the site; unoccupied sites are translucent. Error bars represent standard deviation across repetitions on different qubit chains and devices. Initial states with less overlap with topological corners exhibit slightly lower stability than their lower dimensional counterparts, as these states diffuse into the more spacious 4D configuration space. d Hamiltonian schematic of the interacting chain realizing a minimal 4 × 4 × 4 × 4 tesseract lattice. Sites on the chain are colored black; colored vertices connecting to multiple sites on the chain denote interaction terms. Intra- and inter-cell hoppings, mapped onto interactions, are respectively denotedandfor axes α { x, y, z, w } and parities. To limit visual clutter, onlyintra-cell couplings are shown; a corresponding set ofinter-cell couplings are present in the Hamiltonian but have been omitted from the diagram.

---

### Separability and geometry of object manifolds in deep neural networks [^111ec4MQ]. Nature Communications (2020). High credibility.

Finally, to demonstrate the causal role of center correlations on capacity, we have manipulated the manifold centers by randomizing them without changing the geometry of the manifolds, and compared the resultant capacity (Supplementary Fig. 10 b). As anticipated, center randomization improves capacity, especially in the first layers where the actual capacity exhibit high center correlations.

Fig. 10
Manifold structure perturbations effect on capacity.

a Classification capacity following manifold scaling (x -axis indicate scaling factor, with 1 corresponds to no scaling) for AlexNet at different layers along the hierarchy (top 10% point-cloud manifolds). b Comparison of classification capacity (x -axis) with the prediction from balls with the same manifold properties (y -axis) for AlexNet at different layers along the hierarchy (point-clouds of top 10% and full class manifolds). As capacity of those manifolds spans two orders of magnitude it is normalized by capacity at the pixel layer. The full cyan line indicate y = x while the dashed cyan line indicate y = 0.55 x. c Classification capacity following manifold scaling (x -axis indicate scaling factor, with 1 corresponds to no scaling) for AlexNet at different layers along the hierarchy (smooth 1-d translation manifolds). d Comparison of numerically measured capacity (x -axis) with numerically measured capacity of balls with the same manifold properties (y -axis) for AlexNet at different layers along the hierarchy and different levels of manifold variability (smooth 1-d translation manifolds). The dashed cyan line indicate y = x. Marker shape represents layer type (circle — pixel layer, square — convolution layer, right-triangle — max-pooling layer, hexagon — fully connected layer, down-triangle — local normalization layer). Color changes from dark to light along the network.

---

### Symmetry breaking in optimal transport networks [^117Er866]. Nature Communications (2024). High credibility.

The main problem in network design is fundamentally different. We are given the density of population and we are looking for the network that minimizes some objective function involving some average time, in general (although other choices are possible, see for example). In this setting, there are usually two different transport modes, a slow one representing for example cars on the road network, and a fast one representing the subway or some rapid transit network. The natural framework here is then the one of multiplex networks comprising two different transportation networks, one known while the structure of the second one is to be determined (for multiplexes in the context of optimization see for example). A practical realization of this problem concerns the specific case of subways (for a network analysis of subways, see for example,–). In most large cities, a subway system has been built and later enlarged, with current total lengths varying from a few kilometers to a few hundred kilometers. The geometry of these networks, as its total length increases, varies from simple lines to more complex shapes with loops for larger networks. In particular, for the largest networks, convergence to a structure with a well-connected central core and branches reaching out to suburbs has been observed.

Algorithmic aspects of network design have been studied within computational geometry (e.g.chapter 9) and location science (e.g.and references therein), and some simpler problems of this type have been addressed previously. For instance, the problem of the quickest access between an area and a given point was discussed in. In network science, the optimization problem is traditionally recast as a navigation problem in lattices with long-range connections. However, our specific question – optimal network topologies as a function of population distribution and network length – is largely an open problem. In, some results were obtained in two-dimensional systems by comparing a priori defined optimal network configurations. First, it was shown that, if the goal is reaching a single point in the plane, then the optimal network is necessarily a tree. Second, the paper hinted at the possibility of the existence of transitions between optimal configurations when the length of the network changes. More precisely, it has been shown that as the length of the network increases resources go preferentially to radial branches and that there is a sharp transition at a critical value of the length where a loop appears.

---

### Comparison between interactive closest point and procrustes analysis for determining the median sagittal plane of three-dimensional facial data [^112TGzE6]. The Journal of Craniofacial Surgery (2016). Low credibility.

Although for subjects with no obvious facial asymmetry the PA and ICP method can both compute the midsagittal plane from the three-dimensional facial data and the 2 midsagittal planes derived from the 2 methods shows no significant statistical difference. But for the subjects with obvious facial asymmetry, for the PA method, we can select landmarks in the relatively symmetric region, thus avoiding the unwanted landmarks that are out of the position for the calculation of the MSP. Whereas for the ICP method, the point clouds all participate in the calculation of the MSP evenly, without wiping off the point clouds in the asymmetry region. And these point clouds may lead to the inaccuracy of the median sagittal plane. So whether the ICP will be available for the asymmetric subjects remains a problem for further study. And the number and location of landmarks that can be seen as the most appropriate for MSP computing by PA method also remains to be studied.

---

### Metal-peptide rings form highly entangled topologically inequivalent frameworks with the same ring-and crossing-numbers [^113wXi4Z]. Nature Communications (2019). High credibility.

With increasing ring-crossing number (c), knot theory predicts an exponential increase in the number of topologically different links of these interlocking structures, even for structures with the same ring number (n) and c. Here, we report the selective construction of two topologies of 12-crossing peptide [4]catenanes (n = 4, c = 12) from metal ions and pyridine-appended tripeptide ligands. Two of the 100 possible topologies for this structure are selectively created from related ligands in which only the tripeptide sequence is changed: one catenane has a T 2 -tetrahedral link and the other a three-crossed tetrahedral link. Crystallographic studies illustrate that a conformational difference in only one of the three peptide residues in the ligand causes the change in the structure of the final tetrahedral link. Our results thus reveal that peptide-based folding and assembly can be used for the facile bottom-up construction of 3D molecular objects containing polyhedral links.

---

### Coherent movement of error-prone individuals through mechanical coupling [^111FhSDV]. Nature Communications (2023). High credibility.

Figure 2b–d show the trajectories taken by 1 × 1, 4 × 4 and 7 × 7 Kilobot Soft Robots, respectively, in all trials. It is apparent that the 1 × 1 robot (essentially a single Kilobot with open-loop control) is unable to move in a coherent direction. By contrast, the 7 × 7 robot deviates far less from the reference trajectory. Lacking feedback that is external to the robot, however, the robot will not stay on course indefinitely.

Figure 2e shows the length of the trajectory at the end of the trial as a function of the Kilobot Soft Robot's size S. For each size, we report on the top the number of failed trials. The mean value (blue solid line) shows that the trajectory length decreases, converging to the optimum value (green dotted line), as the robot size S increases. In other words, the motion of the Kilobot Soft Robot becomes more accurate, the more modules it has.

The performance improvement in terms of accuracy comes at the expense of a reduced average linear speed, as shown in Fig. 2f. Although accuracy tends to improve with robot size S, the speed seems to settle to a constant value of about 0.35 cm/s (successful trials only). Comparing the robot's speed with that of individual Kilobots (about 1.2 cm/s), we observe that the Kilobot Soft Robot moves at about 29% of the maximum speed of its constituent modules.

Finally, for each trial, we evaluated the extent to which the robots' shapes were distorted with respect to the reference shape, a square lattice. In the reference shape, all angles formed between adjacent links to neighbouring modules and internal to the robot have the same value of 90°. The root-mean-square distortion is computed as the mean squared error from 90° for all angles. Figure 2g reports the average of the root-mean-square distortion over time. We observe relatively small values of distortion in successful trials (green circles) for robots of any size. Large distortions are observed in the unsuccessful trials (red crosses). The latter indicate that a high proportion of elastic links ended up not being in the correct configuration, which may cause the robot to cease motion.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^116pyM1f]. Annals of the American Thoracic Society (2023). High credibility.

Figure — computational lung models for imaging metrics interpretation illustrate an imaging‑based human airway tree reconstructed from volumetric computed tomography and a branch‑filling tree generation method within a finite element mesh, alongside a Jacobian map showing regional parenchymal deformation from coregistered paired images; color gradients in the left lung indicate increasing magnitudes of deformation from apex to the costophrenic sulcus.

---

### A short primer on lung stereology [^111Cq2DW]. Respiratory Research (2021). Medium credibility.

Step 4: Sampling

Tightly interrelated with the measurement of the reference space and processing of lung tissue is the sampling of tissue blocks for microscopy. Actually, stereology is all about rigorous unbiased (and thus, truely representative equal opportunity) sampling. A bad sample will inevitably result in bad data and thus bad science. In general, sampling must be randomized for location, i.e. each part of the lung has the same chance for being selected for analysis. For anisotropic structures with a preferential orientation in space (e.g. major conducting airways), some parameters (e.g. surface area and length) also require randomization for spatial orientation.

Various stereological sampling designs have been developed. The basic principle for randomization of location is systematic uniform random sampling (SURS). The first sample is chosen randomly but determines the position of all other samples which are selected by a predefined constant sampling interval (Fig. 3). Depending on the target compartment you are interested in, you may have to follow this SURS principle along a cascade of microscopic magnifications (e.g. distinguishing parenchyma vs. non-parenchyma at a low light microscopic magnification, but distinguishing alveolar septum, alveolar airspace and alveolar duct airspace within parenchyma at a higher light microscopic magnification). This principle, where the phase of interest at a lower magnification becomes the reference phase at a higher magnification, has been termed cascade sampling (Fig. 1). Along this cascade, you must not break the SURS chain at any point. Also keep in mind that the microscopic resolution influences the data. This is of particular relevance for alveolar surface area estimation where the well-known "coast of Britain effect" leads to higher values with higher resolution because finer irregularities become visible. Selective targeting of subcompartments within the lung, which can either be defined by anatomy (e.g. individual lung lobes) or by pathology (e.g. lesioned regions), is addressed by stratified sampling where those subcompartments are sampled seperately. The basic concept of fractionator sampling is to keep track of the sampling fraction throughout the cascade of sampling stages (e.g. slices, slabs, blocks, sections, fields of view). Fractionator sampling can easily be combined with SURS (Fig. 3). Its great advantage is that particle number can be estimated without bias independent of tissue deformation by multiplying the total counts at the final sampling step by the inverse of the sampling fraction along all sampling stages.

---

### Identification of phases, symmetries and defects through local crystallography [^113SqZYJ]. Nature Communications (2015). Medium credibility.

Advances in electron and probe microscopies allow 10pm or higher precision in measurements of atomic positions. This level of fidelity is sufficient to correlate the length (and hence energy) of bonds, as well as bond angles to functional properties of materials. Traditionally, this relied on mapping locally measured parameters to macroscopic variables, for example, average unit cell. This description effectively ignores the information contained in the microscopic degrees of freedom available in a high-resolution image. Here we introduce an approach for local analysis of material structure based on statistical analysis of individual atomic neighbourhoods. Clustering and multivariate algorithms such as principal component analysis explore the connectivity of lattice and bond structure, as well as identify minute structural distortions, thus allowing for chemical description and identification of phases. This analysis lays the framework for building image genomes and structure-property libraries, based on conjoining structural and spectral realms through local atomic behaviour.

---

### Creating a library of generalized fourier sampling patterns for irregular 2D regions of support [^115SFPM4]. Magnetic Resonance in Medicine (2001). Low credibility.

Multiple-region MRI (mrMRI) represents a generalization of the Shannon sampling theorem to permit sparse k-space sampling whenever the scanned object or its high-contrast edges are confined to multiple known regions. Use of an optimal mrMRI sampling pattern produces an image with root-mean-squared (RMS) noise over the supporting regions equal to the RMS noise in a conventional Fourier image with the same total area of support. Analytical solutions for such sampling patterns have been described previously for all arrangements of two or three (noncollinear) supporting regions. This work describes a robust numerical method for creating a library of optimal and near-optimal mrMRI sampling patterns for more complicated geometries. The average noise amplification over all sampling patterns in the demonstration library was only 4%, with 30% of the sampling patterns resulting in no noise amplification whatsoever.

---

### Colorectal cancer screening and prevention [^111t6nQW]. American Family Physician (2025). High credibility.

Regarding screening and diagnosis for colon cancer, more specifically with respect to indications for screening, general population, aged 50–75 years, AAFP 2025 guidelines recommend to obtain periodic screening for CRC in adults aged 50–75 years at average risk with no signs or symptoms of the condition.

---

### Quantification and comparison of telovelar and transvermian approaches to the fourth ventricle [^111kZb1S]. Neurosurgery (2006). Low credibility.

Objective

To quantify the exposure to the fourth ventricle obtained with the telovelar and transvermian approaches.

Methods

The telovelar, with and without C1 posterior arch removal, and transvermian approaches were performed on six cadaveric heads. The area of surgical exposure was calculated from triangles formed by defined anatomic points. A robotic microscope was used to determine the "angle of approach" for the same points.

Results

The maximal allowable vertical angle of attack to the obex of the fourth ventricle was significantly greater with the telovelar approach than with the transvermian approach (P < 0.002), but there was no difference at the rostral fourth ventricle. The maximal allowable horizontal angle of attack at the level of the obex, Luschka, and rostral fourth ventricle was significantly greater with the telovelar than with the transvermian approach (P < 0.001). Removal of the C1 posterior arch with the telovelar approach significantly increased the vertical angle of approach to the obex (P < 0.001) and rostral aspect of the fourth ventricle (P = 0.005) compared with the telovelar alone. The telovelar approach with C1 arch removal offered a larger working area than the transvermian approach (P < 0.001).

Conclusion

Except for the vertical angle to the rostral aspect of the fourth ventricle, the telovelar approach provides greater angle of exposure in all planes than the transvermian approach. Removal of the C1 posterior arch obviates this sole advantage of the transvermian approach. The telovelar approach offers a corridor through noneloquent arachnoid planes and a safe and capacious working environment.

---

### Representation of the inferred relationships in a map-like space [^1149K4Gt]. Human Brain Mapping (2023). Medium credibility.

2.4.1 Behavioral training

The purpose of the behavioral training was to guide the subjects to learn the hierarchical structure of the 16 objects in two dimensions. During the first and second days of training, the subjects learned the relative ranks of the two groups separately, learning only one dimension each day. For the test phases during training, subjects need to perform transitive inferences to make the correct choice. If subjects adopted an alternative learning strategy, then they should not be able to distinguish between objects at the second and third ranks, because objects at these two ranks had an equal number of wins/losses (see Frank et al.). Following the previous study (Park et al.), we invited the subjects who successfully distinguished the second and third ranks objects above chance while achieving an accuracy of 85% or higher in each test phase to participate in the fMRI experiment. Figure S1a shows the flowchart of the behavioral training on day 1. During the learning phase, the subjects were requested to learn the relative ranks between paired objects in each group in one of two dimensions based on feedback (correct: green circle/incorrect: red cross) and needed to choose the object with the higher rank from the two objects presented on the screen for 2 s with a colored square by pressing a button. A colored square indicated the given dimension. The feedback appeared for 2 s after the subject pressed a button. After the feedback, the next trial would start. During the test phase, the subjects were required to choose the higher rank between any two objects on a given dimension by using the learned rank relationship information between objects.

Figure S1b shows the behavioral training on day 2. On that day, the subjects were trained to learn the relative ranks of 8 objects in each group in the dimension that was not learned on day 1 based on feedback. The training process on day 2 was similar to that on day 1. At the end of training on day 2, the subjects needed to perform an additional test (Test 2), which included 192 trials (half in the price dimension). The purpose of Test 2 was to examine whether the subjects could flexibly infer the rank relationship between objects in the same group in different dimensions. During Test 2, the objects in the two groups were randomly presented to subjects in the two dimensions across trials. These trials were equivalent to the trials in the test phases during training on days 1 and 2. The subjects needed to choose the higher ranked one in the task‐relevant dimension. No feedback was provided.

---

### Changes in semantic memory structure support successful problem-solving and analogical transfer [^1136rTFc]. Communications Psychology (2024). Medium credibility.

Introduction

In our daily life, we constantly deal with problems, ranging from the most mundane (e.g. what to cook for dinner given the ingredients at our disposal), to professional activities (e.g. how to reorganize our current plans to meet a new deadline), up to major societal challenges (e.g. how to find innovative solutions against global warming). How do we find new solutions to problems? While the ability to solve problems is a critical skill for adapting to new situations and innovating, the mechanisms underlying the problem-solving process remain largely unknown.

Among the new problems we face each day, some are well-defined (e.g. playing a jigsaw puzzle). The initial state (i.e. the number of independent pieces) and goal state (i.e. assembling the pieces so it looks like the picture model) are clear, and the solver can apply a set of operations (i.e. interlocking the pieces as a function of their shape) to reach the goal. However, for many of our problems (e.g. organizing work activities during the COVID-19 pandemic), the problem space is ambiguous. No heuristics or existing rules could be applied to transform the initial state into the goal state. Such "ill-defined" problemsthus require additional mental processes, which have been tightly linked to creative thinking –. Ill-defined problem-solving (or creative problem-solving) is often referred to as insight solving, where the solution comes to mind suddenly and effortlessly, with a "Eureka" phenomenon –. According to the Representational Change Theory, solving such problems involves restructuring the initial problem mental representational space, which presumably entails combining elements related to the problem in a new way. In theory, restructuring allows one to change perspective, reframe the problem, or escape its implicitly imposed constraints, leading to creative associations. For instance, consider the following problem: "A man walks into a bar and asks for a glass of water. The bartender points a shotgun at the man. The man says, 'Thank you', and walks out". The problem is ill-defined because the path to finding the solution is to be discovered, and the goal state is vague. Solving this problem first requires asking the right question: in which context would a shotgun and a glass of water help somebody? Rather than relying on obvious associations (e.g. a glass of water is related to thirst), solvers must fill the missing link between the relevant elements of the problem (a shotgun induces fear, and fear can be a remedy for hiccups, as can drinking a glass of water). Hence, restructuring the initial representation of a given problem would allow one to see this link and find its solution.

---

### Colorectal cancer screening and prevention [^114pGXNt]. American Family Physician (2025). High credibility.

Regarding screening and diagnosis for rectal cancer, more specifically with respect to indications for screening, general population, aged 45–49 years, AAFP 2025 guidelines recommend to obtain periodic screening for CRC in adults aged 45–49 years at average risk with no signs or symptoms of the condition.

---

### Acute lymphoblastic leukemia, version 2.2024, NCCN clinical practice guidelines in oncology [^1153zDs7]. Journal of the National Comprehensive Cancer Network (2024). High credibility.

Regarding diagnostic investigations for acute lymphoblastic leukemia - NCCN, more specifically with respect to molecular testing, NCCN 2024 guidelines recommend to recognize that the translocation t(12;21)(p13; q22) is typically cryptic by karyotyping and requires FISH or PCR to identify.

---

### Colorectal cancer screening and prevention [^112Ta6ws]. American Family Physician (2025). High credibility.

Regarding screening and diagnosis for colon cancer, more specifically with respect to indications for screening, high-risk individuals, family history, AAFP 2025 guidelines recommend to obtain CRC screening in patients with ≥ 1 first-degree relatives with CRC or adenomatous polyps, starting at 40 years of age or 10 years before the age of the youngest relative at the time of their diagnosis.

---

### Colorectal cancer screening and prevention [^115yGYSN]. American Family Physician (2025). High credibility.

Regarding screening and diagnosis for colon cancer, more specifically with respect to indications for screening, general population, aged 76–85 years, AAFP 2025 guidelines recommend to consider obtaining screening for CRC in adults aged 76–85 years at average risk based on overall health status, prior screening history, and patient preferences.

---

### Solving the where problem and quantifying geometric variation in neuroanatomy using generative diffeomorphic mapping [^117UV2Yv]. Nature Communications (2025). High credibility.

The statistical interpretation allows us to accommodate images with non reference signals, such as missing tissue, tracer injection sites, or other anomalies. At each pixel, the identity of the signal type is modeled as missing data, and maximum likelihood estimators are computed using an Expectation Maximization algorithm, which alternates between the E step: compute posterior probability π i (x) that each pixel corresponds to the reference image rather than one of the non-reference types, and the M step: update parameters by solving a posterior weighted version of the above:As an EM algorithm, this approach is guaranteed to be monotonically increasing in likelihood. An example of posterior weights are shown in the right hand column of Fig. 2 b.

Our approach uses mixtures of Gaussians to model variability in data, to allow large outliers to be accommodated by additional components, even though the Gaussian distribution itself does not have long tails. The Gaussian model allows for closed form expression (in terms of matrix inverse) for contrast transformation parameters. Other groups have used long tailed distributions to model variability and outliers in a robust manner, most notably the exponential distribution for l1 optimization. Techniques such as iteratively reweighted least squares can be applied as in Reuter et al. which lead lead to a weighted least squares problem which is similar to ours.

Nonconvex optimization with low to high dimensional subgroups and resolutions

This registration problem is highly nonconvex, and allows for many local minima. To provide robustness in our solution, we solve a sequence of lower dimensional subproblems, initializing the next with the solution to the previous. (i) 2D slice to slice rigid alignment maximizing similarity to neighbors(ii) 3D affine only alignment, registration using the full model at (iii) low (200 μm), (iv) medium (100 μm), and (v) high (50 μm) resolution. Time varying velocity fields are discretized into 5 timesteps and integrated using the Semi Lagrangian method. For most subproblems, spatial transformation parameters are estimated by gradient descent, and intensity transformation parameters are updated by solving a weighted least squares solution at each iteration. For subproblems that include linear registration only, parameters are estimated using Reimannian gradient descent (discussed in ref.and similar to a second order Gauss–Newton optimization scheme).

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^116UmK71]. Annals of the American Thoracic Society (2023). High credibility.

Quantitative imaging (QI) — challenges and sources of error emphasize that advances in QI are crucially dependent on technology and computational power, with massive data sets run through "black box" algorithms and distilled into selected "biomarkers" to evaluate their ability to detect, stratify, and monitor lung disease. Numerous imaging modalities, manufacturers, platforms, and algorithms may not integrate smoothly, and emergent QI metrics vary among centers in the methods of acquisition, quantification, interpretation, and extrapolation; technological advances contribute to difficulty in standardization. Systematic errors may arise at each step of image acquisition, processing, and analysis, including 1) technical issues (e.g., depth of inspiration, acquisition protocol, signal-to-noise ratio, resolution), 2) nonrepresentative sampling of parts of interest (e.g., comparing regions, lobes, or airways), and 3) lack of a well-defined reference space, as well as 4) inaccurate landmark coregistration for evaluating paired images obtained at different lung volumes and 5) failure to consider basic physiology and/or biological or spatiotemporal heterogeneity.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^114WxbTs]. Annals of the American Thoracic Society (2023). High credibility.

Quantitative imaging metrics — common sources of systematic errors in imaging and analysis include six categories with representative examples: technical issues during acquisition (differences in hardware and software, acquisition protocol, signal-to-noise ratio, and resolution), biased sampling of structure for analysis (comparison of mismatched airways), failure to define an appropriate reference space, issues with segmentation or registration, inaccurate assumptions or simplifications (assuming alveolar airspaces are spheres), and failure to consider spatiotemporal and biological heterogeneity (anatomical or gravitational gradients in tissue density, ventilation, and perfusion).

---

### Structural basis for assembly of vertical single β-barrel viruses [^111vXxft]. Nature Communications (2019). High credibility.

The vertical double β-barrel major capsid protein (MCP) fold, fingerprint of the PRD1-adeno viral lineage, is widespread in many viruses infecting organisms across the three domains of life. The discovery of PRD1-like viruses with two MCPs challenged the known assembly principles. Here, we present the cryo-electron microscopy (cryo-EM) structures of the archaeal, halophilic, internal membrane-containing Haloarcula californiae icosahedral virus 1 (HCIV-1) and Haloarcula hispanica icosahedral virus 2 (HHIV-2) at 3.7 and 3.8Å resolution, respectively. Our structures reveal proteins located beneath the morphologically distinct two- and three-tower capsomers and homopentameric membrane proteins at the vertices that orchestrate the positioning of pre-formed vertical single β-barrel MCP heterodimers. The cryo-EM based structures together with the proteomics data provide insights into the assembly mechanism of this type of viruses and into those with membrane-less double β-barrel MCPs.

---

### VA / DoD clinical practice guideline for management of bipolar disorder [^111UR7i9]. DoD/VA (2023). High credibility.

VA/DoD Clinical Practice Guideline — bipolar disorder algorithm structure and legend define a step-by-step decision tree with standardized symbols and arrows connecting numbered boxes indicating the order in which the steps should be followed; it includes steps of care in an ordered sequence, decisions to be considered, decision criteria recommended, and actions to be taken. Rounded rectangles represent a clinical state or condition; hexagons represent a decision point in the process of care, formulated as a question that can be answered "Yes" or "No".; rectangles represent an action in the process of care; and ovals represent a link to another section within the algorithm. Sidebars 1–7 provide more detailed information to assist in defining and interpreting elements in the boxes, and Appendix M contains alternative text descriptions of the algorithm.

---

### NCCN guidelines® insights: gastrointestinal stromal tumors, version 2.2022 [^113gB638]. Journal of the National Comprehensive Cancer Network (2022). High credibility.

Regarding diagnostic procedures for gastrointestinal stromal tumors - NCCN, more specifically with respect to mutation testing, NCCN 2022 guidelines recommend to consider germline KIT and platelet-derived growth factor receptor alpha testing for the following: patients with a family history of gastrointestinal stromal tumors and/or melanoma, patients with multifocal gastrointestinal stromal tumors, and/or patients with neurofibromatosis type 1 or succinate dehydrogenase-deficient gastrointestinal stromal tumors.

---

### Defective viral genomes as therapeutic interfering particles against flavivirus infection in mammalian and mosquito hosts [^113uhGvq]. Nature Communications (2021). High credibility.

Putative centers of the neighborhoods enriched by deletions were detected on the plane using a grid method. Namely, a number of deletions ("points") were randomly selected as the grid references. For all points, distances to these reference points were calculated. For every point, a product of all-rounded logs of its Euclidean distances to the reference points was used as a hashing index. The hashing indexes of all points were sorted, and big enough islands of points (threshold ≥ 7 elementary deletion points) in the sorting that have the same hash index were considered as containing putative centers of significant enrichment. Any point of the island can be used as a center for the subsequent determination of the center's neighborhood most significantly enriched by points/deletions. Let the null hypothesis assumption be that all points/deletions are uniformly distributed on the start/end plane (i.e. no enrichments assumption). Then probability for a number of points to be in a neighborhood of radius r from the center with volume (or an area if the space is a two-dimensional plane) V r can be calculated from Poisson distribution. Indeed, if points are uniformly distributed in the neighborhood with radius R, R > r of volume V R. then the number of points in a neighborhood with the same center and radius r (therefore, with volume V r) will be a random variable, having a Poisson distribution with the parameter, where k is the dimension of the space, and α is the density of the uniform distribution of n points in V R. Thus, n is proportional to Vr. The probability (P) of finding more or equal to m points in a neighborhood with radius r (pvalue) will be:All deletions/points were sorted according to closeness to the selected central point. Those regions that are most enriched by points were determined as follows. In the sorting, let us consider a transition from a neighborhood with radius r t, which is equal to a distance from the center to point t in the sorting, to a neighborhood with radius. The Poisson p value of the enrichment of the neighborhood of radius r t containing t points is calculated from the perspective of the extended neighborhood with the radiusand assumptions that its t + 1 points are uniformly distributed in this volume of space of fractal dimension: the fractal dimension is defined by the sequence of distances from the t + 1 points to the center. For non-uniform dense areas, the Hausdorff fractal dimension is higher than the geometrical dimension of the plane equal to two. This higher dimension makes a drop of p value sharper on a transition from t to t + 1 than in two-dimensional space. The t -neighborhood with the most significant Poisson p value was selected as the best neighborhood, i.e. the one that is most enriched by deletions/points.

---

### Automatic correspondence on medical images: a comparative study of four methods for allocating corresponding points [^116cBJE5]. Journal of Digital Imaging (2010). Low credibility.

The accurate estimation of point correspondences is often required in a wide variety of medical image-processing applications. Numerous point correspondence methods have been proposed in this field, each exhibiting its own characteristics, strengths, and weaknesses. This paper presents a comprehensive comparison of four automatic methods for allocating corresponding points, namely the template-matching technique, the iterative closest points approach, the correspondence by sensitivity to movement scheme, and the self-organizing maps algorithm. Initially, the four correspondence methods are described focusing on their distinct characteristics and their parameter selection for common comparisons. The performance of the four methods is then qualitatively and quantitatively compared over a total of 132 two-dimensional image pairs divided into eight sets. The sets comprise of pairs of images obtained using controlled geometry protocols (affine and sinusoidal transforms) and pairs of images subject to unknown transformations. The four methods are statistically evaluated pairwise on all image pairs and individually in terms of specific features of merit based on the correspondence accuracy as well as the registration accuracy. After assessing these evaluation criteria for each method, it was deduced that the self-organizing maps approach outperformed in most cases the other three methods in comparison.

---

### The management of major depressive disorder: synopsis of the 2022 U.S. department of veterans affairs and U.S. department of defense clinical practice guideline [^112Mp2J5]. Annals of Internal Medicine (2022). High credibility.

Algorithm for major depressive disorder (MDD) — this CPG's algorithm is designed to facilitate understanding of the clinical pathway and decision making process used in managing patients with MDD; it represents a simplified flow of the management of patients with MDD and helps foster efficient decision making by providers; it includes an ordered sequence of steps of care, decisions to be considered, recommended decision criteria, and actions to be taken; the algorithm is a step-by-step decision tree with standardized symbols and arrows connecting numbered boxes indicating the order in which steps should be followed, and sidebars provide more detailed information; shape legend: rounded rectangles represent a clinical state or condition, hexagons represent a decision point formulated as a question that can be answered "Yes" or "No", rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm; Appendix G contains alternative text descriptions of the algorithm.

---

### Initial diagnostic workup of acute leukemia: guideline from the college of American pathologists and the American Society of Hematology [^112eb2JF]. Archives of Pathology & Laboratory Medicine (2017). Medium credibility.

Regarding diagnostic procedures for acute lymphoblastic leukemia, more specifically with respect to lumbar puncture, ASH/CAP 2017 guidelines recommend to consider obtaining flow cytometry in the evaluation of CSF in patients with suspected or confirmed acute leukemia.

---

### Standards of care in diabetes – 2025 [^112GkM3T]. Diabetes Care (2025). High credibility.

Regarding diagnostic investigations for hypoglycemia, more specifically with respect to screening for cognitive impairment, ADA 2025 guidelines recommend to simplify diabetes treatment plans as much as possible for patients with cognitive impairment and tailor to minimize the risk of hypoglycemia.

---

### Ultrasound-guided vessel puncture: calling for pythagoras' help [^111qMwK3]. Critical Care (2018). Low credibility.

Vascular access is routinely performed by critical care physicians and the use of ultrasonography is recommended. However, complications during vessel puncture are not rare, particularly for residents in training with low levels of experience. Reminding about the properties of the isosceles right triangle might be of interest to teach young fellows a secure step by step technique for vessel catheterization.

An isosceles right triangle has two equal legs and has angles of 90°, 45° and 45°. For two equal legs having the length ɭ, the hypotenuse has a length corresponding to ɭ × √2. This last number, also called Pythagoras' constant, corresponds approximately to 1.4. After a longitudinal scan of the vein run, let's insert the needle in the skin, just over the vein (Fig. 1a). Let's position the probe perpendicular to the skin, just over the vein, at a length ɭ of the needle insertion point equal to the depth of the vein under the probe. Three points build an isosceles right triangle: the needle insertion point, the middle of the probe on the skin interface, and the center of the vein under the probe.

Fig. 1
Global overview of ultrasound-guided vessel puncture and use of the isosceles right triangle. a Taking a distance between the probe and the needle insertion point equal to the depth of the vessel, a probe perpendicular to the skin, and an angle between the skin and the needle of 45°, the third angle will be automatically positioned into the vein. Three points build an isosceles right triangle: the needle insertion point, the middle of the probe on the skin interface, and the center of the vein under the probe. b The long-axis plane, which passes through the length of the vessel, corresponds to the view obtained in the in-plane technique with the vessel in the long-axis. Three points determine the long-axis plane: the needle insertion point, identified by inserting the needle in the skin just above the vessel, the vessel being viewed in the long axis; the middle of the probe on the skin, the vessel being visualized at the center of the ultrasound screen in the short axis; the middle of the probe's top, the probe being perpendicular to the skin. The operator should attempt to maintain the syringe in the axis of the probe top (dotted line)

---

### Effective use of tables and figures in abstracts, presentations, and papers [^1152FgyH]. Respiratory Care (2004). Low credibility.

In some situations, tables, graphs, and figures can present certain types of information (including complicated relationships and sequences of events) more clearly and in less space than the same information would require in sentence form. However, do not use tables, graphs, and figures for small amounts of data that could be conveyed clearly and succinctly in a sentence. Also, do not reiterate in sentences the data that are shown in a table, graph, or figure: the point of creating a table or graph or figure is to eliminate that type of sentence from your manuscript. In building a data table you must balance the necessity that the table be complete with the equally important necessity that it not be too complex. Sometimes it is helpful to break a large table into several smaller ones to allow the reader to identify important information easily, but, conversely, it is a common mistake of novice authors to split up into several tables data that belong in one table. In almost all cases, only one table or graph or figure should be included in an abstract, and then only if it can convey essential information in less space and in a more easily interpretable way than the sentence form. For a poster, in almost all instances you should use only one typeface and one font in a table, graph, or figure. In general, do not use bold, italics, or color unless you are presenting a great deal of data and you need to highlight certain data values and you are certain that using bold, italics, or color will improve readability, which is rare. Do not include identical information in a table and a graph/figure. In reporting a clinical trial you will need to include a patient flow chart that identifies the number of patients initially screened for the study, the number of patients who were excluded (and why) after initial screening or in the final analysis, and how many patients entered, exited early, and completed each arm of the study. A treatment protocol should also be described with a flow chart. In preparing a graph the most common error is to include a line that suggests an unsubstantiated extrapolation between or beyond the data points. In selecting the graph's axes, avoid truncating, enlarging, or compressing the axes in ways that might make the graph confusing or misleading. To prepare clear, accurate, easily interpretable tables, graphs, and figures, rely on the rules described in authoritative guides such as the Council of Science Editors' Scientific Style and Format and the American Medical Association's Manual of Style.

---

### Machine learning meets complex networks via coalescent embedding in the hyperbolic space [^112ueL1G]. Nature Communications (2017). Medium credibility.

Physicists recently observed that realistic complex networks emerge as discrete samples from a continuous hyperbolic geometry enclosed in a circle: the radius represents the node centrality and the angular displacement between two nodes resembles their topological proximity. The hyperbolic circle aims to become a universal space of representation and analysis of many real networks. Yet, inferring the angular coordinates to map a real network back to its latent geometry remains a challenging inverse problem. Here, we show that intelligent machines for unsupervised recognition and visualization of similarities in big data can also infer the network angular coordinates of the hyperbolic model according to a geometrical organization that we term "angular coalescence". Based on this phenomenon, we propose a class of algorithms that offers fast and accurate "coalescent embedding" in the hyperbolic circle even for large networks. This computational solution to an inverse problem in physics of complex systems favors the application of network latent geometry techniques in disciplines dealing with big network data analysis including biology, medicine, and social science.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^113P3hwn]. Annals of the American Thoracic Society (2023). High credibility.

Challenges in quantitative imaging (QI) — advances in QI are crucially dependent on technology and computational power, with massive data sets run through "black box" algorithms distilled into selected "biomarkers" correlated with global function to detect, stratify, and monitor lung disease. Numerous imaging modalities, manufacturers, platforms, and algorithms may not integrate smoothly, emergent QI metrics vary among centers in acquisition, quantification, interpretation, and extrapolation, technological advances contribute to the difficulty in standardization, and the use of medical jargon makes it difficult for the less initiated to evaluate the potential and limitations of QI-derived metrics. Systematic errors may arise at each step of image acquisition, processing, and analysis, including technical issues, nonrepresentative sampling of parts of interest, lack of a well-defined reference space, inaccurate landmark coregistration for paired images obtained at different lung volumes, and failure to consider basic physiology and/or biological or spatiotemporal heterogeneity.

---

### Adapting the dejour classification of trochlear dysplasia from qualitative radiograph-and CT-based assessments to quantitative MRI-based measurements [^1125Vwgz]. Knee Surgery, Sports Traumatology, Arthroscopy (2025). Medium credibility.

Trochlear measurement protocol

Four readers (ED, TP, AG, CT; orthopaedic surgeons qualified, and trained in the reference centre) independently made seven measurements (rounded to the nearest whole number) for all knees, using Horos™ (Horos Project):
(1) PBCL (Figure 2) The PBCL is defined in three steps. Step 1: Select the axial MRI slice that crosses the centre of the medial condyle. Step 2: Select the sagittal MRI slice that crosses the most posterior point of the medial condyle. Step 3: Draw the PBCL in the axial slice, which passes through the subchondral bone at the posterior aspect of the medial and lateral femoral condyles.
(2) Trochlear shape (Figure 3) Scrolling from cranial to caudal, the first slice is selected in which the trochlear cartilage is visible, showing/covering at least the entire lateral facet. The trochlear shape is described according to the cartilage contour as (a) concave (trochlea with a sulcus, as well as medial and lateral facets), (b) flat (trochlea with no evident sulcus nor medial facet) or (c) convex (trochlea with no sulcus nor medial facet, and domed lateral facet).
(3) Sulcus angle (Figure 4) Scrolling from cranial to caudal, the first slice is selected where the trochlear cartilage is visible, showing the sulcus formation and the medial facet. If the trochlea is concave or flat, the sulcus angle is measured in three steps (for convex trochleae, the sulcus angle is noted as 'unmeasurable'). Step 1: the trochlear groove cartilage (TGC) point, the lateral trochlear cartilage (LTC) peak and the medial trochlear cartilage (MTC) peak are digitized. Step 2: A line (LTC–TGC) connecting points TGC and LTC and a line (TGC–MTC) connection points TGC and MTC are drawn. Step 3: The sulcus angle is measured as the angle between lines LTC–TGC and TGC–MTC.
(4) Lateral trochlear inclination (LTI) (Figure 5) Scrolling from cranial to caudal, the first slice is selected where the trochlear cartilage is visible, showing the sulcus formation and the medial facet. If the trochlea is concave or flat, the LTI is measured in four steps (for convex trochleae, the LTI is noted as 'unmeasurable'). Step 1: The TGC point and the LTC peak are digitized. Step 2: A line (LTC–TGC) connecting points TGC and LTC is drawn. Step 3: Copy and paste the PBCL and translate it anteriorly to intersect line LTC–TGC at point TGC. Step 4: The LTI is measured as the angle between lines LTC–TGC and PBCL. The angle is considered positive if LTC is anterior to the PBCL. The angle is considered negative if LTC is posterior to PBCL.
(5) Cranial trochlear orientation (CTO) (Figure 6) Scrolling from cranial to caudal, the first slice is selected in which the trochlear cartilage is visible, showing/covering at least the entire lateral facet. The CTO is measured in four steps. Step 1: The most lateral (L) and medial (M) points on the subchondral bone covered by cartilage are digitized. Step 2: A line (L–M) connecting point L and point M is drawn. Step 3: Copy and paste the PBCL and translate it anteriorly to intersect line L–M at point L. Step 4: The CTO is the angle between lines L–M and PBCL. The angle is considered positive if point M is anterior to the PBCL. The angle is considered negative if point M is posterior to the PBCL.
(6) Central trochlear bump in the axial plane (Figure 7) The axial plane central trochlear bump is selected in four steps. Step 1: In the sagittal plane, select the slice that passes through the TGC and choose the most cranial axial slice. Step 2: Copy and paste the PBCL in the most cranial axial slice and translate it until it becomes tangent to the anterior margin of the femoral cortex. Step 3: Copy and paste the translated PBCL in the axial slice that shows the TGC. Step 4: The central prominence in the axial plane is the distance from the 'translated PBCL' to point TGC.
(7) Central trochlear bump in the sagittal plane (Figure 8)

---

### Standards of care in diabetes – 2025 [^114waoZD]. Diabetes Care (2025). High credibility.

Regarding specific circumstances for hypoglycemia, more specifically with respect to elderly patients, ADA 2025 guidelines recommend to individualized goal levels for the treatment of hypertension in most older patients.

---

### Initial diagnostic workup of acute leukemia: guideline from the college of American pathologists and the American Society of Hematology [^1168ELd3]. Archives of Pathology & Laboratory Medicine (2017). Medium credibility.

Regarding diagnostic procedures for acute lymphoblastic leukemia, more specifically with respect to chromosomal and genetic testing, ASH/CAP 2017 guidelines recommend to obtain testing for t(9;22)(q34.1; q11.2); BCR-ABL1, and KMT2A translocations in patients with confirmed mixed phenotype acute leukemia.

---

### Clotrimazole [^115eJtJD]. FDA. Low credibility.

The dosage of clotrimazole OTIC for treatment of otomycosis in adults is 1 vial OTIC BID for 14 days (1%/0.17 mL)

---

### A statistical solution to the chaotic, non-hierarchical three-body problem [^114DoGbg]. Nature (2019). Excellent credibility.

The three-body problem is arguably the oldest open question in astrophysics and has resisted a general analytic solution for centuries. Various implementations of perturbation theory provide solutions in portions of parameter space, but only where hierarchies of masses or separations exist. Numerical integrations 1 show that bound, non-hierarchical triple systems of Newtonian point particles will almost 2 always disintegrate into a single escaping star and a stable bound binary 3,4, but the chaotic nature of the three-body problem 5 prevents the derivation of tractable 6 analytic formulae that deterministically map initial conditions to final outcomes. Chaos, however, also motivates the assumption of ergodicity 7–9, implying that the distribution of outcomes is uniform across the accessible phase volume. Here we report a statistical solution to the non-hierarchical three-body problem that is derived using the ergodic hypothesis and that provides closed-form distributions of outcomes (for example, binary orbital elements) when given the conserved integrals of motion. We compare our outcome distributions to large ensembles of numerical three-body integrations and find good agreement, so long as we restrict ourselves to 'resonant' encounters 10 (the roughly 50 per cent of scatterings that undergo chaotic evolution). In analysing our scattering experiments, we identify 'scrambles' (periods of time in which no pairwise binaries exist) as the key dynamical state that ergodicizes a non-hierarchical triple system. The generally super-thermal distributions of survivor binary eccentricity that we predict have notable applications to many astrophysical scenarios. For example, non-hierarchical triple systems produced dynamically in globular clusters are a primary formation channel for black-hole mergers 11–13, but the rates and properties 14,15 of the resulting gravitational waves depend on the distribution of post-disintegration eccentricities.

---

### 2014 ESC guidelines on diagnosis and management of hypertrophic cardiomyopathy: the task force for the diagnosis and management of hypertrophic cardiomyopathy of the European Society of Cardiology (ESC) [^111SPgTp]. European Heart Journal (2014). Medium credibility.

Regarding diagnostic investigations for syncope, more specifically with respect to initial ECG, ESC 2014 guidelines recommend to obtain a 12-lead ECG to identify the cause of symptoms in patients with unexplained syncope.

---

### Food processing sector study… [^114wPtAp]. FDA (2025). Medium credibility.

RTI International 3040 E. Cornwallis Road Research Triangle Park, NC 27709 Prepared for: Peter Vardon Angela Lasher Food and Drug Administration 5100 Paint Branch Parkway College Park, MD 20740–3835 RTI Project Number 0212926.
020.
000. 2–6. Number of Farms in the United States by Commodity According to the 2012 Ag Census. 2–35 2–7. Farm Activities Associated with Growers Who Had Produce Sales in 2012 Based on the 2012 Ag Census. 2–37. vi 3–1. Foodborne Illness Quantification and Attribution Literature. 3–3 3–2. Additional Foodborne Illness Attribution Data Sources Examined. 3–11 3–3. Product Categories Included in the Expert Elicitation. 3–17. 3–4. Pretest and Expert Panel Members, Affiliations, and Major Areas of Expertise. 3–22 3–5. Rankings of Food Categories by Their Contributions to the Annual Number of Foodborne Illness Casesa. 3–25 3–6. Rankings of Food Categories by Their Contributions to. Number of Cases of Foodborne Illness, All Food Categories Combineda. 3–36 3–13.

Importance of the Duration of Activity in Contributing to the Number of Cases of Foodborne Illness, All Food Categories Combined and by Food Categorya. 3–37. Section 1 — Introduction 1–3 is an establishment that engages in making food from one or more ingredients or synthesizing, preparing, treating, modifying, or manipulating food, including food crops or ingredients. manufacture/process food, provided that: all food used in such activities is consumed on that farm or another farm under the same management; or any manufacturing/processing of food that is not consumed on that farm or another farm under the same management consists only of:

---

### Rigorous location of phase transitions in hard optimization problems [^116ZYG3W]. Nature (2005). Excellent credibility.

It is widely believed that for many optimization problems, no algorithm is substantially more efficient than exhaustive search. This means that finding optimal solutions for many practical problems is completely beyond any current or projected computational capacity. To understand the origin of this extreme 'hardness', computer scientists, mathematicians and physicists have been investigating for two decades a connection between computational complexity and phase transitions in random instances of constraint satisfaction problems. Here we present a mathematically rigorous method for locating such phase transitions. Our method works by analysing the distribution of distances between pairs of solutions as constraints are added. By identifying critical behaviour in the evolution of this distribution, we can pinpoint the threshold location for a number of problems, including the two most-studied ones: random k-SAT and random graph colouring. Our results prove that the heuristic predictions of statistical physics in this context are essentially correct. Moreover, we establish that random instances of constraint satisfaction problems have solutions well beyond the reach of any analysed algorithm.

---

### Mapping the global design space of nanophotonic components using machine learning pattern recognition [^112esDDG]. Nature Communications (2019). High credibility.

C αβ is a constant vector that defines the reference origin on the hyperplane. Two scalar coefficients α k and β k are thus sufficient to completely describe design k. Details of vector definitions are provided in the Methods section.

Now that the area of interest in the design space is limited to a 2D hyperplane, it becomes feasible to adopt a classical design approach and perform an exhaustive mapping of this sub-space, as illustrated in Fig. 1c. First, we generate a uniform grid of 60 × 60 points covering the α – β hyperplane. Therefore, 3600 sampling points are sufficient to provide a wealth of information. As a comparison, sampling with the same resolution in the original design space would require ~1.5 million points, increasing the computation time by about over 400 times (details in the Methods section). For each point [α k, β k], we obtain the corresponding dimensions [L 1, k… L 5, k] in the original design space through Eq. (2) and compute the coupling efficiency η. The results are shown in Fig. 3a only for the designs with η > 0.7. Note that not all points on the α – β plane provide high coupling efficiency. A unit division in α or β corresponds to a Manhattan distanceof 100 nm. The 60 × 60 grid covering the α – β hyperplane has a resolution of 5 nm in Manhattan distance. This exhaustive mapping results in the discovery of a large and well-defined region of degenerate designs with η > 0.74, highlighted by the black contour line in Fig. 3a. This region encloses a continuum of designs in addition to those discovered in stage 1. Remarkably, although all the good designs have similar coupling efficiencies ranging from η = 0.74 to η = 0.76, the actual structure of the gratings can vary quite significantly, as will be detailed in the next section. Without dimensionality reduction, there is no obvious way to discover these alternative designs with similar coupling efficiency, but potentially different properties in other aspects.

---

### Initial diagnostic workup of acute leukemia: guideline from the college of American pathologists and the American Society of Hematology [^1129gUJf]. Archives of Pathology & Laboratory Medicine (2017). Medium credibility.

Regarding diagnostic procedures for acute lymphoblastic leukemia, more specifically with respect to chromosomal and genetic testing, ASH/CAP 2017 guidelines recommend to obtain testing for t(9;22)(q34.1; q11.2); BCR-ABL1 in adult patients with suspected or confirmed B-ALL. Consider also obtaining testing for KMT2A (formerly MLL) translocations.

---

### Standards of care in diabetes – 2025 [^113MRkAD]. Diabetes Care (2025). High credibility.

Regarding specific circumstances for hypertension, more specifically with respect to patients with diabetes mellitus, lifestyle modifications, ADA 2025 guidelines recommend to advise lifestyle interventions in patients with BP > 120/80 mmHg, consisting of weight loss when indicated, a DASH-style eating pattern (including reducing sodium and increasing potassium intake), moderation of alcohol intake, smoking cessation, and increased physical activity.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^113dQCSY]. Annals of the American Thoracic Society (2023). High credibility.

Quantitative imaging metrics for pulmonary assessment — precision, bias, and unbiased sampling are defined with study design implications. "Bias" refers to systematic errors leading to inaccuracy, whereas "Precision" refers to measurement reproducibility and depends mainly on sampling design and sample characteristics; bias cannot be detected or reduced by more measurements and is avoided a priori by rigorous design using unbiased methods. In a well-designed study, precision is tuned so the within-subject coefficient of error ("noise") is significantly smaller than between-subject biological variation ("signal"). Unbiased sampling designs guarantee statistically representative samples and generally must be spatially randomized, with available approaches including systematic uniform random sampling, isotropic uniform random sampling, stratified sampling, fractionator sampling, and proportionator sampling. The report cautions that voxel-by-voxel automated image analysis ensures neither accuracy nor precision and does not remove the need to follow stereological sampling principles, and illustrates applications where systematic sampling of micro-CT images has been used to compare surface versus core alveoli and to correlate ex vivo small airway gas trapping with in vivo tissue measurements in chronic obstructive pulmonary disease to characterize terminal bronchiole loss, narrowing, and obstruction.

---

### Computed tomography imaging in the context of transcatheter aortic valve implantation (TAVI) / transcatheter aortic valve replacement (TAVR): an expert consensus document of the Society of Cardiovascular Computed Tomography [^112A5MUP]. Journal of Cardiovascular Computed Tomography (2019). High credibility.

Transcatheter valve-in-valve pre-procedural assessment of virtual THV to coronary artery distance is described as a stepwise multiplanar reformat technique: Start out with multiplanar images in default axial, sagittal, and coronal orientation and center cross hairs onto the aortic valve; align the cross-hairs in the sagittal and coronal views with the long axis of the aortic root to depict the aortic valve prosthesis en face; Steps 3 to 6 apply to valves with a non-planar sewing ring, whereas for a planar sewing ring the transverse view is aligned to match the orientation of the sewing ring. Then move the double oblique transverse plane to identify the lowest insertion point of the sewing ring at the former right coronary cusp (about 1 o'clock) and position the cross-hairs at the most basal point; rotate the cross-hairs counterclockwise so the formerly coronal view transects the lowest point at the former non-coronary cusp (approximately 8 o'clock); in the formerly coronal, now double-oblique view, rotate the transverse double-oblique cross-hair to transect exactly through the most basal point so the transverse double oblique plane contains two of the three lowest sewing ring points; in the formerly sagittal view, rotate until the lowest point in the left coronary cusp position just barely appears so the formerly axial plane is exactly aligned with the three lowest points. Move the cross-hairs to the center of the sewing and, maintaining this position, move the transverse double-oblique plane to the level of the left main orifice, draw a circular region of interest with THV-specific diameter to simulate the anticipated THV, reflect the center of the sewing ring/center of cross hairs, and measure the distance from the region of interest to the left main orifice; also assess if there is close proximity above the orifice towards the STJ and repeat step 8 for the right coronary artery.

---

### A mathematical approach to human pterygium shape [^115KNzCN]. Clinical Ophthalmology (2016). Low credibility.

Results

We examined the pictures of each pterygium taken at the initial ophthalmological examination using a camera. On the contour plane curves which were seen, we measured the coordinates of five points (Table 1). For some patients, a few points were too close to enable us to estimate curve's type. Hence, we used the software to determine four more points on the contour curve.

We applied the spline approximations through those nine points which successfully reconstructed the curve. Reconstructed graphs of contour curve by spline approximation are shown in Figure 2. Since the original curves were very similar to conics, we took five points: the first is the point which is the nearest to the origin of supposed conic; a further two points distinguished from one side and two from the other side. The most simple class of curves which pass through five plane points is the class of conic sections which satisfies the equation of the form (Figure 3):

The previous equation given by the determinant can be written in the form Ax² + 2Bxy + Cy² + 2Dx + 2Ey + F = 0.

Denote

According to the analytical geometry, this equation determines:
Ellipse if δ > 0 ∧ s Δ < 0
Hyperbola if δ < 0 ∧ Δ≠0
Parabola if δ = 0 ∧ Δ≠0

By plotting original curve, spline, and conics, we obtained very close graphs for every patient (Table 2). So, we can conclude that the shape of pterygia is of conic form.

Equations of conics for five patients were calculated (Table 3). These equations show that the conics are slightly rotated around X-axis; therefore, the graphs are not symmetrically located by X-axis (Figure 4).

---

### Phase nucleation in curved space [^116wF1bb]. Nature Communications (2015). Medium credibility.

Nucleation and growth is the dominant relaxation mechanism driving first-order phase transitions. In two-dimensional flat systems, nucleation has been applied to a wide range of problems in physics, chemistry and biology. Here we study nucleation and growth of two-dimensional phases lying on curved surfaces and show that curvature modifies both critical sizes of nuclei and paths towards the equilibrium phase. In curved space, nucleation and growth becomes inherently inhomogeneous and critical nuclei form faster on regions of positive Gaussian curvature. Substrates of varying shape display complex energy landscapes with several geometry-induced local minima, where initially propagating nuclei become stabilized and trapped by the underlying curvature.

---

### Integer topological defects offer a methodology to quantify and classify active cell monolayers [^11379J3K]. Nature Communications (2025). High credibility.

Fig. 1
Neural progenitor cells (NPCs) accumulate at the centers of asters, spirals, and targets.

a Schematic of microfabricated patterns on a polydimethylsiloxane (PDMS) substrate. Four arrays of various spirals (θ 0 = ± π /12 and ± 5 π /12) are arranged on a PDMS sheet, featuring 16 micropatterns per defect type. b Micropatterns designed based on the definition of + 1 topological defects. The largest radius of patterns, is 500 μ m. The radius of the defect core without ridges, is 80 μ m. The distance between ridges is 30–120 μ m. c Types of + 1 topological defects characterized by the tilt angle θ 0. A bright-field image is shown for a target. d Cell motion on a target pattern. e Heatmap of cell densities on spirals shown in a at the beginning and after 25 h of recording. T = T 0 at the onset of confluence. f Typical phase-contrast images and typical fluorescence images at the beginning and after 35 h of recording on a spiral with θ 0 = π /4. Dashed lines depict ridges of patterns. g Time evolution of average radial density profiles on the target. Data are averaged every 1 h across 32 targets. Inset: a typical fluorescence image showing cell accumulation after 50 h of recording on a target. Dashed lines depict ridges. h Average percentage of cells Φ ρ (, where n represents cell number) assembling with time on asters, counterclockwise spirals, and targets. Different colors depict various defect types. The number (N) of each defect type is six, and all defects are designed on the single PDMS sheet. i, Radial density profiles normalized by mean density ρ 0 when ρ 0 = 0.009 / μ m 2. Inset: A log — log plot for the region with r > 100 μ m. N values for aster, each type of spiral, and target are 32, 6, and 32, respectively. Legend in h. In h and i, data are presented as mean ± standard deviation (s.d.), and s.d. values are calculated from defects in an array. Scale bars: 100 μ m.

---

### 2025 ESC guidelines for the management of myocarditis and pericarditis [^111tyu9k]. European Heart Journal (2025). High credibility.

Regarding specific circumstances for acute pericarditis, more specifically with respect to patients with post-cardiac injury syndromes, ESC 2025 guidelines recommend to initiate IL-1 antagonists in patients with refractory post-cardiotomy inflammatory syndrome to prevent recurrences and progression to constriction.

---

### VA / DoD clinical practice guideline for the primary care management of asthma [^113xMKLJ]. DoD/VA (2025). High credibility.

VA/DoD Clinical Practice Guideline for the Primary Care Management of Asthma — algorithm legend and scope: This clinical practice guideline (CPG) algorithm is designed to facilitate understanding of the clinical pathway and decision-making process used in the primary care management of asthma and represents a simplified flow that helps foster efficient decision making; it includes an ordered sequence of steps of care, recommended observations and examinations, decisions to be considered, and actions to be taken. The algorithm is a step-by-step decision tree in which standardized symbols are used to display each step and arrows connect the numbered boxes indicating the order in which the steps should be followed; Sidebars A-J provide more detailed information to assist in defining and interpreting elements in the boxes. Symbol meanings are defined as: rounded rectangles represent a clinical state or condition, hexagons represent a decision point in the guideline formulated as a question that can be answered "Yes" or "No", rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm.

---

### NCCN guidelines® insights: mesothelioma: pleural, version 1.2024 [^113iTf5L]. Journal of the National Comprehensive Cancer Network (2024). High credibility.

Regarding screening and diagnosis for pleural mesothelioma - NCCN, more specifically with respect to differential diagnosis, NCCN 2024 guidelines recommend to recognize that mesothelioma in situ is a preinvasive, single-layer surface proliferation of neoplastic mesothelial cells. Since the diagnosis of mesothelioma in situ cannot be simply made on conventional H&E stains, the diagnosis requires either the following:

- loss of BAP1 nuclear expression by immunohistochemistry

- CDKN2A homozygous deletion identified either by FISH or by MTAP immunohistochemistry (cytoplasmic staining). Furthermore, no mass lesions should be identified on imaging or thoracoscopy.