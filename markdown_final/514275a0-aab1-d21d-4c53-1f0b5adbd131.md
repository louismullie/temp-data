# Medical Question & Answer

**Sample ID**: 514275a0-aab1-d21d-4c53-1f0b5adbd131
**Dataset Index**: 99058

---

## Question

Dietary iron sources

---

## Answer

> Let's see… What do we have here? The user is asking about dietary iron sources, including the two forms of iron, their bioavailability, key food sources, enhancers and inhibitors of absorption, special population considerations, and practical strategies to optimize intake and status. Let's break this down step-by-step. First, I need to think about the two forms of dietary iron and their absorption physiology. Then, I should verify bioavailability ranges and how they vary by diet and iron status. Next, I will categorize food sources by heme and non-heme iron and quantify contributions where possible. After that, I need to examine enhancers and inhibitors and their clinical relevance. Then, I should consider special populations and life stages, including infants, children, adolescents, pregnant and premenopausal women, vegetarians/vegans, and individuals with iron overload. Finally, I will synthesize practical recommendations and highlight uncertainties or controversies that warrant caution in interpretation.

> Let me first confirm the two forms of dietary iron and their core differences. Heme iron is derived from hemoglobin and myoglobin in animal tissues and is absorbed intact via a dedicated pathway with relatively high and less variable absorption, whereas non-heme iron is present in both plant and animal foods, is predominantly ferric iron, and must be reduced to ferrous iron before transport into enterocytes, making its absorption more variable and susceptible to dietary modifiers [^111Lmd8S].

> I should double-check bioavailability figures before proceeding. Heme iron is typically absorbed at about 15–35%, while non-heme iron absorption ranges roughly 1–15% depending on diet composition and host iron status; in mixed diets, overall iron absorption is often cited around 14–18%, whereas in vegetarian diets it may be 5–12%, and absorption can be higher when iron stores are low and lower when stores are replete, reflecting hepcidin-mediated regulation [^116e429Y] [^116e429Y] [^111Lmd8S].

> Hold on, let's not jump to conclusions about "better" versus "worse" sources without context. Although heme iron is more bioavailable, non-heme iron contributes the bulk of total iron intake in many diets, and absorption can be optimized with enhancers; moreover, high heme iron intake has been associated with adverse cardiometabolic outcomes in observational studies, so balance and population context matter [^115hRLth] [^111BGEjK].

> Next, I should review heme iron sources and quantify their contributions where possible. Red meats such as beef and lamb are the richest sources, with heme iron comprising roughly 40–69% of total iron in beef depending on the cut and method of estimation; poultry and fish contain a lower proportion of heme iron but still contribute meaningfully; organ meats like liver are particularly dense in iron, though heme fractions vary by source and preparation [^114TYbzu] [^111ErsX2] [^113nbj9r].

> I will now examine non-heme iron sources and their relative importance. Plant-based sources include legumes (lentils, chickpeas, soy), dark leafy greens (spinach, kale), nuts and seeds, and whole grains; fortified cereals and breads are major contributors in many countries, with fortification supplying more than half of total dietary iron in the U.S. food supply; dried fruits and dark chocolate also provide non-heme iron, though they are typically secondary sources in the diet [^114AzdsY] [^113nbj9r] [^114pF4M5].

> Wait, let me verify the contribution of fortified foods in infants and young children. Iron-fortified infant formula and cereals are foundational sources after 6 months, and in many high-income settings, formula and fortified cereals account for the majority of iron intake in 6–12 month olds; this is crucial because human milk contains only about 0.35 mg/L iron, so complementary feeding must supply nearly all of the 11 mg/day requirement at 6–12 months [^114pF4M5] [^114u5m5k].

> I need to check enhancers of non-heme iron absorption and their practical implications. Ascorbic acid (vitamin C) is the most consistent enhancer, converting ferric iron to ferrous and forming soluble complexes; consuming vitamin C–rich foods with non-heme iron meals can markedly increase absorption, and this is especially important in plant-forward or vegetarian diets; the "meat factor" from animal protein also enhances non-heme absorption, though its magnitude is variable and may be less decisive when iron status is low or when supplements are used [^116e429Y] [^113nbj9r] [^112SsJL8].

> Hold on, I should verify inhibitors and their clinical relevance. Phytates in whole grains, legumes, and some seeds, polyphenols in tea and coffee, calcium (especially from supplements or dairy), and certain medications like proton pump inhibitors can inhibit non-heme iron absorption; separating these from iron-containing meals by 1–2 hours and using vitamin C strategically can mitigate their impact, though the effect size depends on the overall meal matrix and iron status [^113nbj9r] [^1127wX1w] [^116e429Y].

> Let me consider infants and young children carefully. Exclusively breastfed infants generally rely on endogenous stores for about 6 months, after which iron-fortified cereals and formula, along with iron-rich complementary foods, are essential; calculated absorbed iron is frequently below requirements in breastfed 6–12 month olds, underscoring the need for intentional iron sources; for formula-fed infants, standard iron-fortified formulas provide 4–12 mg/L, which helps meet needs when solid intake is limited [^114u5m5k] [^116S5jGZ] [^114AzdsY].

> I should confirm adolescent and premenopausal female-specific risks. Adolescent girls and women of reproductive age have higher iron requirements due to menstruation, and many fail to meet bioavailable iron targets despite adequate total iron intake; in European adolescents, girls' heme iron intake and ferritin tend to be lower than boys', and a high proportion have inadequate bioavailable iron, supporting counseling to include heme sources and enhancers when feasible [^112PRNzK] [^114pJ8BP].

> But wait, what if the diet is entirely plant-based? Vegetarians and vegans can meet iron needs, but they require about 1.8 times the intake of non-heme iron to compensate for lower bioavailability; strategies include emphasizing vitamin C with meals, using food preparation to reduce phytates (soaking, sprouting, fermentation), and relying on fortified foods; monitoring ferritin and hemoglobin is prudent, especially in children and premenopausal women [^111d2geM] [^112HVXqm] [^113WQKxo].

> I need to ensure I address iron overload conditions. In hereditary hemochromatosis, dietary modification is not a substitute for therapeutic phlebotomy, but patients are advised to avoid iron supplements, limit red meat, avoid iron-fortified foods when possible, and be cautious with vitamin C, especially before iron depletion; these measures reduce additional iron absorption while definitive therapy proceeds [^114hkGpu] [^1119ivHV] [^1116kq6h].

> Next, I should review pregnancy, where requirements rise substantially. Daily iron needs increase from about 0.8 mg in the first trimester to 4–5 mg in the second and 7.5–10 mg in the third trimester; universal antenatal iron supplementation is recommended in many settings, and pairing non-heme sources with enhancers and separating inhibitors can improve absorption; delayed cord clamping also preserves infant iron stores [^111Lmd8S] [^113cfvta] [^114PijQQ].

> Let me synthesize practical strategies across populations. Include a mix of heme and non-heme sources when acceptable, pair non-heme iron with vitamin C and avoid calcium, tea, or coffee within 1–2 hours of iron-rich meals, use fortified cereals or formulas in infants and young children, and tailor counseling to cultural preferences and iron status; in low-resource settings, small-quantity lipid-based nutrient supplements and targeted fortification can improve iron status when diverse diets are constrained [^113nbj9r] [^1122YMAT] [^113r9P2z].

> Hold on, I should verify a potential pitfall in my earlier thinking. I initially implied that the "meat factor" would consistently enhance absorption of supplemental non-heme iron when co-ingested with meat, but a recent randomized study in iron-deficient women found no additional benefit of consuming a supplement with beef versus plant-based meat over 8 weeks, suggesting that when iron status is low and supplemental iron is provided, the enhancement from meat may be less decisive; this does not negate the broader evidence that meat enhances non-heme absorption in dietary contexts, but it tempers assumptions when pharmacologic iron is already on board [^112SsJL8] [^111tU9B8].

> Finally, I should confirm that my guidance aligns with authoritative positions. The Academy of Nutrition and Dietetics advises vegetarians to consume nearly twice the iron and to use vitamin C strategically, pediatric guidance emphasizes iron-fortified foods and supplements when indicated, and gastroenterology and hematology sources consistently emphasize pairing non-heme iron with enhancers and avoiding inhibitors to optimize absorption in clinical practice [^111d2geM] [^114pF4M5] [^113nbj9r].

---

Dietary iron comes in two forms: **heme iron** from animal sources (red meat, poultry, fish) and **non-heme iron** from plant sources (legumes, leafy greens, fortified cereals) [^114LTQMj]. Heme iron is absorbed at 15–35%, whereas non-heme iron is absorbed at 2–20% and is strongly influenced by diet [^111Lmd8S] [^111tU9B8]. Vitamin C enhances non-heme absorption, while phytates, polyphenols, and calcium inhibit it [^113nbj9r] [^1127wX1w]. Vegetarians need about 1.8 times more iron due to lower bioavailability, and **fortified foods or supplements** are often necessary for infants, pregnant women, and those at risk of deficiency [^111d2geM] [^114pF4M5] [^1172FW3c].

---

## Forms of dietary iron

Dietary iron exists in two forms: **heme iron**, found only in animal tissues, and **non-heme iron**, found in plant and animal foods [^114LTQMj].

| **Form of iron** | **Sources** | **Absorption** |
|-|-|-|
| Heme iron | - Red meat (beef, lamb) <br/> - Poultry <br/> - Fish <br/> - Organ meats (liver) | - 15–35% <br/> - Less affected by diet [^111Lmd8S] |
| Non-heme iron | - Legumes (lentils, beans, chickpeas) <br/> - Leafy greens (spinach, kale) <br/> - Fortified cereals and breads <br/> - Nuts and seeds <br/> - Dried fruits | - 2–20% <br/> - Strongly influenced by diet [^116A11ok] |

---

## Factors influencing iron absorption

Several dietary factors influence **iron absorption**:

- **Enhancers**: Vitamin C (ascorbic acid) significantly enhances non-heme iron absorption by reducing ferric iron (Fe³⁺) to ferrous iron (Fe²⁺) and forming soluble complexes [^114LTQMj]. Meat, fish, and poultry also enhance non-heme absorption via the "meat factor" [^113nbj9r].

- **Inhibitors**: Phytates (in whole grains, legumes), polyphenols (in tea, coffee, some vegetables), and calcium can inhibit non-heme iron absorption [^113nbj9r]. Consuming these separately from iron-rich meals can improve absorption [^113nbj9r].

- **Individual factors**: Iron status, age, sex, and genetic factors influence absorption. Absorption increases when iron stores are low and decreases when stores are replete [^111tU9B8].

---

## Dietary sources of iron

### Heme iron sources

- **Red meat**: Beef, lamb, and pork are rich in heme iron and highly bioavailable [^113nbj9r].

- **Poultry and fish**: Chicken, turkey, and fish provide moderate amounts of heme iron [^113nbj9r].

- **Organ meats**: Liver and other organ meats are exceptionally high in iron [^notfound].

---

### Non-heme iron sources

- **Legumes**: Lentils, chickpeas, beans, and soy products are rich in non-heme iron [^113nbj9r].

- **Leafy greens**: Spinach, kale, and Swiss chard contain significant non-heme iron [^113nbj9r].

- **Fortified foods**: Many cereals, breads, and infant formulas are fortified with iron [^114pF4M5].

- **Nuts and seeds**: Pumpkin seeds, sesame seeds, and cashews provide non-heme iron [^113nbj9r].

- **Dried fruits**: Raisins, apricots, and prunes are good sources of non-heme iron [^113nbj9r].

---

## Special considerations

- **Vegetarians and vegans**: Non-heme iron is less bioavailable, so vegetarians need about 1.8 times more iron than non-vegetarians. Consuming vitamin C-rich foods with iron-rich meals enhances absorption [^111d2geM] [^113WQKxo].

- **Infants and young children**: Breast milk provides minimal iron after 6 months, so iron-fortified cereals or supplements are recommended [^114pF4M5] [^114u5m5k].

- **Pregnant women**: Iron requirements increase significantly during pregnancy, often necessitating supplementation [^111Lmd8S] [^113cfvta].

---

## Conclusion

Dietary iron is available as heme and non-heme forms, with heme iron being more bioavailable. Non-heme iron absorption is highly influenced by diet, with vitamin C enhancing and phytates, polyphenols, and calcium inhibiting absorption. Vegetarians, infants, and pregnant women may require **fortified foods or supplements** to meet iron needs [^111d2geM] [^114pF4M5] [^1172FW3c].

---

## References

### Increasing CO₂ threatens human nutrition [^113MXybn]. Nature (2014). Excellent credibility.

Dietary deficiencies of zinc and iron are a substantial global public health problem. An estimated two billion people suffer these deficiencies, causing a loss of 63million life-years annually. Most of these people depend on C3 grains and legumes as their primary dietary source of zinc and iron. Here we report that C3 grains and legumes have lower concentrations of zinc and iron when grown under field conditions at the elevated atmospheric CO2 concentration predicted for the middle of this century. C3 crops other than legumes also have lower concentrations of protein, whereas C4 crops seem to be less affected. Differences between cultivars of a single crop suggest that breeding for decreased sensitivity to atmospheric CO2 concentration could partly address these new challenges to global health.

---

### Iron deficiency anaemia in sub-saharan Africa: a review of current evidence and primary care recommendations for high-risk groups [^114PijQQ]. The Lancet: Haematology (2021). High credibility.

The epidemiology of iron deficiency anaemia in sub-Saharan Africa differs from that in other parts of the world. The low-quality diets prevalent in this region are a poor source of iron, the population is frequently exposed to infection, and demographic characteristics result in a greater prevalence of people at high risk of iron deficiency anaemia than in other parts of the world. We herein review the causes, disease burden, and consequences of iron deficiency anaemia in the general population in this region, and current policies and interventions for its control. The current debate is dominated by concerns about the safety of iron interventions, namely regarding its effects on malaria and other infectious diseases. However, universal antenatal iron supplementation and delayed cord clamping are safe interventions and stand out for their potential to improve maternal and infant health. Effective infection control is a precondition to safe and efficacious iron interventions in children. Greater emphasis should be given to approaches aiming to reduce iron loss due to helminth infections and menstruation, alongside interventions to increase iron intake. TRANSLATION: For the French translation of the abstract see Supplementary Materials section.

---

### Nutritional iron deficiency [^116B2Ldi]. Lancet (2007). Excellent credibility.

Iron deficiency is one of the leading risk factors for disability and death worldwide, affecting an estimated 2 billion people. Nutritional iron deficiency arises when physiological requirements cannot be met by iron absorption from diet. Dietary iron bioavailability is low in populations consuming monotonous plant-based diets. The high prevalence of iron deficiency in the developing world has substantial health and economic costs, including poor pregnancy outcome, impaired school performance, and decreased productivity. Recent studies have reported how the body regulates iron absorption and metabolism in response to changing iron status by upregulation or downregulation of key intestinal and hepatic proteins. Targeted iron supplementation, iron fortification of foods, or both, can control iron deficiency in populations. Although technical challenges limit the amount of bioavailable iron compounds that can be used in food fortification, studies show that iron fortification can be an effective strategy against nutritional iron deficiency. Specific laboratory measures of iron status should be used to assess the need for fortification and to monitor these interventions. Selective plant breeding and genetic engineering are promising new approaches to improve dietary iron nutritional quality.

---

### Screening and supplementation for iron deficiency and iron deficiency anemia during pregnancy: updated evidence report and systematic review for the US preventive services task force [^116yqCLm]. JAMA (2024). Excellent credibility.

Regarding specific circumstances for vitamins, minerals, and dietary supplements, more specifically with respect to pregnant patients, iron, USPSTF 2024 guidelines recommend to insufficient to assess the balance of benefits and harms of routine supplementation for iron deficiency and iron deficiency anemia in pregnant females to prevent adverse maternal and infant health outcomes.

---

### Iron and breastfeeding [^115biFc8]. Pediatric Clinics of North America (2001). Low credibility.

Given the importance of iron nutrition during the first year of life, there are surprisingly few true, randomized, controlled studies addressing this issue; however, it seems that iron deficiency is unlikely in full-term, breastfed infants during the first 6 months of life because these infants' body iron stores are sufficient to meet requirements. After this time, many infants exhaust their iron stores and become dependent on a secondary dietary iron supply. Although iron deficiency is a significant nutritional problem worldwide, most of the adverse effects of iron deficiency in this age group are hypothetical and rely on extrapolation from animal studies or studies at different ages. This, however, also is true of most of the adverse effects of iron excess in this age group. Given this uncertainty, it seems prudent to use the lowest dose of iron that prevents iron-deficiency anemia. Currently, the best evidence is that this is achieved by prolonged breastfeeding, avoidance of unfortified formulas and cow's milk, and the introduction of iron-fortified and vitamin C-fortified weaning foods at approximately 6 months of age. Despite much research, there are many areas of uncertainty regarding iron supplementation of infants, including that: 1. The optimal age for introducing iron-fortified supplemental foods is poorly defined and should be further evaluated. 2. The natural history of iron deficiency and iron-deficiency anemia during the first year of life is unclear, as are the possible long-term effects of this, especially on developmental outcome. 3. The biologic variability among infants and among their mothers that allows many infants who do not receive iron-fortified foods to prevent iron deficiency while receiving only human milk throughout the first year of life is intriguing and warrants additional study. 4. The iron requirements of small-for-gestational-age, term infants are unknown. Their iron requirements are likely to be higher than those of average term infants, but whether iron supplements are required is unclear. 5. The optimum amount of dietary iron in the weaning diet needs to be further defined. Similarly, the optimal source and amount of iron in infant formulas given to infants who receive a mixture of human milk and formula is unclear.

---

### Dietary iron intake, body iron stores, and the risk of type 2 diabetes: a systematic review and meta-analysis [^115hRLth]. BMC Medicine (2012). Low credibility.

Heme iron exists only in meat and meat products, where it occurs in the form of hemoglobin and myoglobin, whereas non-heme iron is present in both plant and animal foods. The regulation of the intestinal iron absorption is crucial because there is no physiologic mechanism for excretion of iron. Although heme iron is not the predominant form of dietary iron, it more readily absorbed than non-heme iron. In addition, absorption of heme iron does not change with increasing dose, is less substantially affected by iron status than non-heme iron, and is not greatly influenced by other components in diet. Therefore, heme iron contributes about 50% of the total bioavailable iron in the typical western diet. In an elderly population of the Framingham Heart Study, non-heme iron was the major source (mean 93%) of iron, yet heme iron intake was significantly and positively associated with serum ferritin concentration, whereas non-heme iron intake did not significantly influence serum ferritin concentration. Similar positive association between heme iron intake and serum ferritin concentration was reported from the Health Professionals' Follow-up Study. Therefore, the distinct effects of heme iron and non-heme iron intake on risk of T2DM that we found in the present study may be, at least partly, explained by the differences in bioavailability of the different iron types and their effects on body iron stores.

---

### Intake and dietary sources of haem and non-haem iron in flemish preschoolers [^113Q9vSm]. European Journal of Clinical Nutrition (2012). Low credibility.

Background/Objectives

In the absence of biochemical data on iron status in preschoolers, data on the adequacy of iron intake may be used to assess the possible risk of iron deficiency in this population group. Therefore, this study aims to investigate iron intake and its food sources in Flemish preschoolers.

Subjects/Methods

A total of 661 Flemish preschoolers 2.5–6.5 years old were recruited via a random cluster sampling design, using schools as primary sampling units. Three-day estimated diet records were used to assess dietary intakes. The contribution to iron intake (haem and non-haem) of 57 food groups was computed by summing the amount provided by the food group for all individuals divided by the total intake for all individuals.

Results

Mean total iron intake (s.d.) was 7.4 (± 2.3) and 6.7 (± 2.8) mg/day for boys and girls, respectively. In all 65% of the children < 4 years old and 45% of those 4–6.5 years old presented adequate iron intakes. The food groups with the highest mean proportional contribution to total iron intake were bread, meat and meat products, breakfast cereals and sweet snacks (in that order). Children from small families whose mother had a low educational level had higher iron intakes.

Conclusion

Iron intakes were similar for boys and girls and almost half of the Flemish preschoolers do not comply with the dietary iron recommendations.

---

### Iron bioavailability and dietary reference values [^116A11ok]. The American Journal of Clinical Nutrition (2010). Low credibility.

Iron differs from other minerals because iron balance in the human body is regulated by absorption only because there is no physiologic mechanism for excretion. On the basis of intake data and isotope studies, iron bioavailability has been estimated to be in the range of 14–18% for mixed diets and 5–12% for vegetarian diets in subjects with no iron stores, and these values have been used to generate dietary reference values for all population groups. Dietary factors that influence iron absorption, such as phytate, polyphenols, calcium, ascorbic acid, and muscle tissue, have been shown repeatedly to influence iron absorption in single-meal isotope studies, whereas in multimeal studies with a varied diet and multiple inhibitors and enhancers, the effect of single components has been, as expected, more modest. The importance of fortification iron and food additives such as erythorbic acid on iron bioavailability from a mixed diet needs clarification. The influence of vitamin A, carotenoids, and nondigestible carbohydrates on iron absorption and the nature of the "meat factor" remain unresolved. The iron status of the individual and other host factors, such as obesity, play a key role in iron bioavailability, and iron status generally has a greater effect than diet composition. It would therefore be timely to develop a range of iron bioavailability factors based not only on diet composition but also on subject characteristics, such as iron status and prevalence of obesity.

---

### The importance of antarctic krill in biogeochemical cycles [^1166gqEa]. Nature Communications (2019). High credibility.

Iron

Iron is an important trace element in the oceans and its low availability limits primary productivity in large areas, including much of the ice-free Southern Ocean. The largest sources of new iron to the Southern Ocean surface waters are deep winter mixingand the seasonal melting of sea ice. Following the depletion of this winter-spring iron pulse, further primary production depends increasingly on recycled iron. E. superba have an important role in oceanic iron cycling,– facilitated by the ingestion of iron-rich phytoplankton and lithogenic particles. The iron concentration in an individual whole adult krill ranges from 4.4 to 190.5 mg kg⁻¹, with the > 40-fold difference in krill iron content reflecting seasonal and regional differences in their dietary iron content. Eventually, the iron retained in individual bodies can be released back into surface waters when baleen whales and other vertebrates consume E. superba and subsequently defecate. Thus, in the iron-limited Southern Ocean iron recycled via krill and their predators is important for stimulating primary production (Fig. 3).

---

### Oral iron supplementation: new formulations, old questions [^116e429Y]. Haematologica (2024). Medium credibility.

Iron physiology, absorption and homeostasis

Most of the iron in the body (> 70%) is present in hemoglobin and only a minor fraction (< 1%) circulates in transferrin, the plasma iron carrier. The transferrin iron pool is small (~3 mg at steady state) but highly dynamic to meet the needs of erythropoiesis (25–30 mg/day). Iron supply to transferrin is maintained primarily by splenic and hepatic macrophages, which clear aged red blood cells and recycle their iron, and to a lesser extent by duodenal enterocytes, which absorb 1–2 mg/day dietary iron. If metabolic needs are unmet, iron stores are mobilized from hepatocytes. As there is no mechanism for iron excretion, dietary iron absorption is essential to compensate for non-specific losses occurring during cell desquamation or bleeding.

It is estimated that only 14–18% of ingested iron is absorbed from mixed diets and 5–12% from vegetarian diets. A reason for this is that Fe²⁺ is oxidized to virtually insoluble (at physiological pH) Fe³⁺. Even though Fe³⁺ can be solubilized in the acidic milieu of the stomach, it cannot be directly transported to enterocytes. Thus, luminal Fe³⁺ needs to be reduced to Fe²⁺ prior to its assimilation via the apical enterocyte transporter DMT1 (Figure 1). This is accomplished enzymatically or with the aid of ascorbate (vitamin C), which is thought to enhance iron absorption. Some dietary components (phytates, polyphenols, fibers, tannins) and common pharmaceuticals (calcium supplements, antacids, proton pump inhibitors) form insoluble complexes with iron and thereby inhibit its absorption.

Heme is a more efficient source of iron; however, the mechanism for heme absorption remains elusive. Internalized heme undergoes enzymatic degradation liberating its iron, which follows the fate of assimilated inorganic iron. Enterocytes release Fe²⁺ to plasma via the basolateral exporter ferroportin. Exported Fe²⁺ is re-oxidized to Fe³⁺ and captured by transferrin for delivery to tissues.

High iron levels or inflammation induce expression of the iron regulatory hormone hepcidin in the liver, which inhibits iron absorption by suppressing intestinal ferroportin. Hepcidin also prevents ferroportin-mediated iron efflux from erythrophagocytic tissue macrophages (Figure 2), acting as a negative regulator of iron entry into plasma.

---

### Anemia in pregnancy: ACOG practice bulletin, number 233 [^113cfvta]. Obstetrics and Gynecology (2021). High credibility.

Regarding specific circumstances for vitamins, minerals, and dietary supplements, more specifically with respect to pregnant patients, iron, ACOG 2021 guidelines recommend to offer low-dose iron supplementation in the first trimester to decrease the prevalence of maternal anemia at delivery.

---

### Commensal resilience: ancient ecological lessons for the modern microbiota [^115k2kPh]. Infection and Immunity (2025). Medium credibility.

While heme is the primary source of iron derived from animal-based diets, ferric iron complexes, including tannins, polyphenols, and phytates, are available from dietary plants. The importance of these compounds to microbiota iron acquisition remains unclear, but there is reason to believe they may be a relevant iron source to intestinal microbes. These complexes are not efficiently absorbed by the host, making them more likely to reach the colon. Some gut microbes, such as Bifidobacteriaceae, can digest phytate, as evidenced by the presence of phytate degradation products in the colons of conventional, but not germ-free, rats. This may represent a strategy by which to liberate phytate-bound iron. The ferric iron in these complexes may also be accessible to capture by tighter binding siderophores (see below). However, further studies are needed to determine the significance of these plant-derived compounds as an iron source to the gut microbiota.

In addition to complexed ferric iron, bacteria can directly import free ferrous iron. The major ferrous iron uptake mechanism in bacteria is the Feo system. The FeoABC system has been primarily studied in Enterobacteriaceae, but homologs exist among several intestinal bacteria phyla. FeoB is a GTP-binding membrane protein that transports ferrous iron across the membrane in a mechanism dependent on GTP hydrolysis. FeoA is likely a small cytoplasmic protein that may stabilize FeoB and facilitate iron transport. FeoC, limited to γ- Proteobacteria, is believed to be an Fe-S-dependent transcriptional repressor. Feo knockout strains of Escherichia coli are incapable of taking up ferrous iron or colonizing the murine gut. A fitness dependence on the Feo system for intestinal colonization has also been observed in Campylobacter jejuni and Helicobacter pylori. The Feo system is also present among Firmicutes, a prominent phylum encompassing several members of the commensal microbiota. Notably, Firmicutes also encode extracellular ferric iron reductases involved in extracellular electron transfer (EET). This unique flavin-based EET system shuttles electrons from the cytosol to extracellular iron and allows growth on non-fermentable carbon sources. By reducing extracellular ferric iron, this system may provide Firmicutes with a localized supply of ferrous iron amenable to Feo-mediated uptake. Together, this evidence suggests that Fe(II) is an important form of this essential metal in the homeostatic gut.

---

### Changing from a Western to a mediterranean-style diet does not affect iron or selenium status: results of the new dietary strategies addressing the specific needs of the elderly population for healthy aging in Europe (NU-AGE) 1-year randomized clinical trial in elderly Europeans [^111etM9A]. The American Journal of Clinical Nutrition (2020). Medium credibility.

The Mediterranean diet is associated with higher intakes of fish, among the richest sources of dietary selenium, and it has been reported that 15% of the variance in plasma selenium in subjects aged 69 y or over was explained by fish consumption. Low selenium intakes have been implicated in the development of sarcopenia, and selenium may modulate susceptibility to pathogens and provide immune defenses against microbes, both of which are especially important for elderly people.

We hypothesized that a Mediterranean diet with limited intakes of red and processed meat, an important supply of bioavailable iron, together with a higher consumption of whole-grain cereals and nuts containing phytate, which inhibits iron absorption, would result in lower iron status. Conversely, higher intakes of fish, a good source of selenium, could increase selenium status. It has been reported that lower serum selenium concentrations are associated with anemia in older women; therefore, we examined associations between iron and selenium status. We tested these hypotheses using dietary and biochemical data from the New Dietary Strategies Addressing the Specific Needs of the Elderly (NU-AGE) study, whose primary aim was to test the effects of consuming an MD for 1 y on inflammatory responses in elderly Europeans, with 15 prespecified secondary outcomes, including the effects of the intervention on nutritional status. In this 1-y randomized controlled trial (RCT), a total of 1294 people aged 65–79 y from 5 European countries (France, Italy, the Netherlands, Poland, and the United Kingdom) were randomly allocated to an intervention (MD) or control group.

---

### Perspective: putting the youngest among us into the nutrition "call for action" for food fortification strategies [^1125XygN]. The American Journal of Clinical Nutrition (2021). Medium credibility.

Challenges in achieving adequate iron intake by infants and young children

Iron stores at birth are generally sufficient to meet the needs of exclusively breastfed infants for ≥ 6 mo, assuming delayed umbilical cord clamping. After 6 mo, iron from non-breast-milk sources is needed. At 6–12 mo of age, estimated average iron requirements are 6.9–8.0 mg/d and the recommended dietary intake is 11 mg/d, assuming absorption of 10%. At 1–3 y, iron needs are lower than at 6–12 mo: the estimated average iron requirement is 3–5 mg/d and the recommended dietary intake is 7 mg/d. Although iron needs in these age intervals are well understood, estimates of iron absorption from different foods and under various conditions (such as iron deficiency) vary widely. Absorption from plant-based foods, particularly those with high concentrations of phytate, is likely to be < 10%.

---

### Iron intake and dietary sources of iron in flemish adolescents [^114pJ8BP]. European Journal of Clinical Nutrition (2005). Low credibility.

Objective

To investigate the dietary iron intake and food sources of iron in Flemish adolescents.

Design

Cross-sectional survey; dietary assessment method: a 7-day estimated food record.

Setting

Private and public secondary schools in Ghent, a city in the Dutch-speaking part of Belgium.

Subjects

A total of 341 adolescents (129 boys and 212 girls), 13–18 y, randomly selected by a multistage clustered sampling technique.

Results

The mean total iron intake (s.d.) for boys was 13.4 (± 2.91) mg/day and for girls 10.1 (± 2.79) mg/day. A proportion of 38.8% of the boys and 99.5% of the girls had a mean total iron intake below the Belgian Recommended Dietary Allowance and 3.1% of the boys and 71.2% of the girls below the British Estimated Average Requirement. When bioavailable iron intake is considered, 84.5% of the boys and only 16.5% of the girls met the age-specific requirement. The food groups with the highest mean proportional contribution to total iron intake in both males and females were bread, meat and meat products, cereals and potatoes. A comparison of adolescents from the highest tertile of iron intake (mg/day) with adolescents from the lowest tertile showed a significantly higher energy-adjusted intake of brown bread and a significantly lower intake of soft drinks in the former group in both boys and girls. A significantly higher energy-adjusted intake of breakfast cereals in adolescents of the highest tertile than those of the lowest tertile was seen in girls only. Analyses in consumers only did not change this overall picture.

Conclusions

One can conclude that the mean iron intake of Flemish girls is considerably lower than the current recommendations. An increased iron intake in this subgroup of the population is therefore advisable.

---

### Impact of consuming an environmentally protective diet on micronutrients: a systematic literature review [^111f5fkU]. The American Journal of Clinical Nutrition (2024). Medium credibility.

Background

A global move toward consumption of diets from sustainable sources is required to protect planetary health. As this dietary transition will result in greater reliance on plant-based protein sources, the impact on micronutrient (MN) intakes and status is unknown.

Objective

Evaluate the evidence of effects on intakes and status of selected MNs resulting from changes in dietary intakes to reduce environmental impact. Selected MNs of public health concern were vitamins A, D, and B12, folate, calcium, iron, iodine, and zinc.

Methods

We systematically searched 7 databases from January 2011 to October 2022 and followed the PRISMA guidelines. Eligible studies had to report individual MN intake and/or status data collected in free-living individuals from the year 2000 onward and environmental outcomes.

Results

From the 10,965 studies identified, 56 studies were included, mostly from high-income countries (n = 49). Iron (all 56) and iodine (n = 20) were the most and least reported MNs, respectively. There was one randomized controlled trial (RCT) that also provided the only biomarker data, 10 dietary intake studies, and 45 dietary modeling studies, including 29 diet optimization studies. Most studies sought to reduce greenhouse gas emissions or intake of animal-sourced foods. Most results suggested that intakes of zinc, calcium, iodine, and vitamins B12, A, and D would decrease, and total iron and folate would increase in a dietary transition to reduce environmental impacts. Risk of inadequate intakes of zinc, calcium, vitamins A, B12 and D were more likely to increase in the 10 studies that reported nutrient adequacy. Diet optimization (n = 29) demonstrated that meeting nutritional and environmental targets is technically feasible, although acceptability is not guaranteed.

Conclusions

Lower intakes and status of MNs of public health concern are a potential outcome of dietary changes to reduce environmental impacts. Adequate consideration of context and nutritional requirements is required to develop evidence-based recommendations. This study was registered prospectively with PROSPERO (CRD42021239713).

---

### Commonly consumed protein foods contribute to nutrient intake, diet quality, and nutrient adequacy [^116HRFYC]. The American Journal of Clinical Nutrition (2015). Low credibility.

The amount of dietary protein needed to prevent deficiency in most individuals is defined in the United States and Canada by the Recommended Dietary Allowance and is currently set at 0.8 g protein · kg⁻¹ · d⁻¹ for adults. To meet this protein recommendation, the intake of a variety of protein food sources is advised. The goal of this article is to show that commonly consumed food sources of protein are more than just protein but also significant sources of essential nutrients. Commonly consumed sources of dietary protein frequently contribute substantially to intakes of nutrients such as calcium, vitamin D, potassium, dietary fiber, iron, and folate, which have been identified as nutrients of "concern" (i.e., intakes are often lower than recommended). Despite this, dietary recommendations to reduce intakes of saturated fat and solid fats may result in dietary guidance to reduce intakes of commonly consumed food sources of protein, in particular animal-based protein. We propose that following such dietary guidance would make it difficult to meet recommended intakes for a number of nutrients, at least without marked changes in dietary consumption patterns. These apparently conflicting pieces of dietary guidance are hard to reconcile; however, we view it as prudent to advise the intake of high-quality dietary protein to ensure adequate intakes of a number of nutrients, particularly nutrients of concern.

---

### Screening and supplementation for iron deficiency and iron deficiency anemia during pregnancy: US preventive services task force recommendation statement [^1172FW3c]. JAMA (2024). Excellent credibility.

Dietary Guidelines for Americans — pregnancy iron supplementation guidance indicates that the US Department of Agriculture and US Department of Health and Human Services "Dietary Guidelines for Americans, 2020–2025" recommends that pregnant women or women planning to become pregnant take a supplement with iron when recommended by a clinician, and that women following a vegetarian or vegan dietary pattern should discuss with a clinician whether supplementation of iron, vitamin B12, other nutrients, or some combination thereof is needed.

---

### Excessive early-life dietary exposure: a potential source of elevated brain iron and a risk factor for Parkinson's disease [^115sUqTN]. NPJ Parkinson's Disease (2017). Low credibility.

This biomarker could then be applied to adult teeth to investigate associations between early-life iron intake and iron deposition in the ageing brain. Adult maxillary and mandibular first molars commence calcification at birth, and are therefore a record of iron exposure during the proposed critical window in early childhood. We suggest that adult teeth can be used to assess early-life iron intake and dietary source, and quantified using chemical microimaging without the need for deciduous teeth or patient recall. In this phase of testing our hypothesis, donated permanent teeth from healthy adults, individuals with clinically diagnosed PD and age-matched controls would be used to quantify early-life iron exposure, potential dietary sources, and to examine relationships with brain iron levels. Teeth are often extracted during routine dental procedures in older individuals; PD patients lose an average of 18 adult teeth, with age-matched controls losing 14, likely due to poor oral hygiene. Even in middle age, in the US the mean number of teeth lost or extracted during dentistry is approximately seven; tooth fragments obtained from dental crown implantation or partial extractions can also be used.

---

### Nutrition-specific interventions for preventing and controlling anaemia throughout the life cycle: an overview of systematic reviews [^113r9P2z]. The Cochrane Database of Systematic Reviews (2021). Medium credibility.

Background

Anaemia is a prevalent health problem worldwide. Some types are preventable or controllable with iron supplementation (pills or drops), fortification (sprinkles or powders containing iron added to food) or improvements to dietary diversity and quality (e.g. education or counselling).

Objectives

To summarise the evidence from systematic reviews regarding the benefits or harms of nutrition-specific interventions for preventing and controlling anaemia in anaemic or non-anaemic, apparently healthy populations throughout the life cycle.

Methods

In August 2020, we searched MEDLINE, Embase and 10 other databases for systematic reviews of randomised controlled trials (RCTs) in anaemic or non-anaemic, apparently healthy populations. We followed standard Cochrane methodology, extracting GRADE ratings where provided. The primary outcomes were haemoglobin (Hb) concentration, anaemia, and iron deficiency anaemia (IDA); secondary outcomes were iron deficiency (ID), severe anaemia and adverse effects (e.g. diarrhoea, vomiting).

Main Results

We included 75 systematic reviews, 33 of which provided GRADE assessments; these varied between high and very low. Infants (6 to 23 months; 13 reviews) Iron supplementation increased Hb levels and reduced the risk of anaemia and IDA in two reviews. Iron fortification of milk or cereals, multiple-micronutrient powder (MMNP), home fortification of complementary foods, and supplementary feeding increased Hb levels and reduced the risk of anaemia in six reviews. In one review, lipid-based nutrient supplementation (LNS) reduced the risk of anaemia. In another, caterpillar cereal increased Hb levels and IDA prevalence. Food-based strategies (red meat and fortified cow's milk, beef) showed no evidence of a difference (1 review). Preschool and school-aged children (2 to 10 years; 8 reviews) Daily or intermittent iron supplementation increased Hb levels and reduced the risk of anaemia and ID in two reviews. One review found no evidence of difference in Hb levels, but an increased risk of anaemia and ID for the intermittent regime. All suggested that zinc plus iron supplementation versus zinc alone, multiple-micronutrient (MMN)-fortified beverage versus control, and point-of-use fortification of food with iron-containing micronutrient powder (MNP) versus placebo or no intervention may increase Hb levels and reduce the risk of anaemia and ID. Fortified dairy products and cereal food showed no evidence of a difference on the incidence of anaemia (1 review). Adolescent children (11 to 18 years; 4 reviews) Compared with no supplementation or placebo, five types of iron supplementation may increase Hb levels and reduce the risk of anaemia (3 reviews). One review on prevention found no evidence of a difference in anaemia incidence on iron supplementation with or without folic acid, but Hb levels increased. Another suggested that nutritional supplementation and counselling reduced IDA. One review comparing MMN fortification with no fortification observed no evidence of a difference in Hb levels. Non-pregnant women of reproductive age (19 to 49 years; 5 reviews) Two reviews suggested that iron therapy (oral, intravenous (IV), intramuscular (IM)) increased Hb levels; one showed that iron folic acid supplementation reduced anaemia incidence; and another that daily iron supplementation with or without folic acid or vitamin C increased Hb levels and reduced the risk of anaemia and ID. No review reported interventions related to fortification or dietary diversity and quality. Pregnant women of reproductive age (15 to 49 years; 23 reviews) One review apiece suggested that: daily iron supplementation with or without folic acid increased Hb levels in the third trimester or at delivery and in the postpartum period, and reduced the risk of anaemia, IDA and ID in the third trimester or at delivery; intermittent iron supplementation had no effect on Hb levels and IDA, but increased the risk of anaemia at or near term and ID, and reduced the risk of side effects; vitamin A supplementation alone versus placebo, no intervention or other micronutrient might increase maternal Hb levels and reduce the risk of maternal anaemia; MMN with iron and folic acid versus placebo reduced the risk of anaemia; supplementation with oral bovine lactoferrin versus oral ferrous iron preparations increased Hb levels and reduced gastrointestinal side effects; MNP for point-of-use fortification of food versus iron and folic acid supplementation might decrease Hb levels at 32 weeks' gestation and increase the risk of anaemia; and LNS versus iron or folic acid and MMN increased the risk of anaemia. Mixed population (all ages; 22 reviews) Iron supplementation versus placebo or control increased Hb levels in healthy children, adults, and elderly people (4 reviews). Hb levels appeared to increase and risk of anaemia and ID decrease in two reviews investigating MMN fortification versus placebo or no treatment, iron fortified flour versus control, double fortified salt versus iodine only fortified salt, and rice fortification with iron alone or in combination with other micronutrients versus unfortified rice or no intervention. Each review suggested that fortified versus non-fortified condiments or noodles, fortified (sodium iron ethylenediaminetetraacetate; NaFeEDTA) versus non-fortified soy sauce, and double-fortified salt versus control salt may increase Hb concentration and reduce the risk of anaemia. One review indicated that Hb levels increased for children who were anaemic or had IDA and received iron supplementation, and decreased for those who received dietary interventions. Another assessed the effects of foods prepared in iron pots, and found higher Hb levels in children with low-risk malaria status in two trials, but no difference when comparing food prepared in non-cast iron pots in a high-risk malaria endemicity mixed population. There was no evidence of a difference for adverse effects. Anaemia and malaria prevalence were rarely reported. No review focused on women aged 50 to 65 years plus or men (19 to 65 years plus).

Authors' Conclusions

Compared to no treatment, daily iron supplementation may increase Hb levels and reduce the risk of anaemia and IDA in infants, preschool and school-aged children and pregnant and non-pregnant women. Iron fortification of foods in infants and use of iron pots with children may have prophylactic benefits for malaria endemicity low-risk populations. In any age group, only a limited number of reviews assessed interventions to improve dietary diversity and quality. Future trials should assess the effects of these types of interventions, and consider the requirements of different populations.

---

### Blood transfusion in obstetrics [^114GoKMn]. RCOG (2015). Medium credibility.

Regarding specific circumstances for iron deficiency anemia, more specifically with respect to pregnant patients, iron supplementation, RCOG 2015 guidelines recommend to provide patients information on improvement of dietary iron intake and factors affecting absorption of dietary iron.

---

### Excessive early-life dietary exposure: a potential source of elevated brain iron and a risk factor for Parkinson's disease [^112tBBZw]. NPJ Parkinson's Disease (2017). Low credibility.

Testing the link between early-life iron exposure and PD risk

Blood iron levels provide only a relatively short window of exposure, and thus a retrospective biomarker of iron intake is needed. Humans retain a lifelong record of early-life iron exposure in teeth, which we propose as one of four consecutive experiments to test our hypothesis and translate our findings into a biomarker of PD risk (Fig. 2). Firstly, deciduous teeth must be established as a validated biomarker of early-life iron exposure. During odontogenesis, metals are retained in hydroxyapatite deposited in enamel and dentine. Using chemical microimaging, alignment of spatial metal distribution with developmental growth lines, akin to rings in a tree trunk, can be used to quantify temporal iron exposure at time scales equivalent to 1 week. Detailed dietary data, including iron intake, for accessible cohorts of infants can be repurposed to measure postnatal iron intake as the children reach the ages of 5–8 years when teeth are shed. Temporal growth lines and tooth iron concentrations can be correlated with recorded dietary iron intakes during the 6–24-month period. Further, spatial barium levels have been validated as a biomarker of dietary sources in early life, and correlation with iron distribution can differentiate between intake sources (i.e. exclusive breastfeeding vs. fortified formula and iron-enriched complementary feeding).

---

### Screening for iron deficiency and iron deficiency anaemia in pregnancy: a structured review and gap analysis against UK national screening criteria [^115vPoc2]. BMC Pregnancy and Childbirth (2015). Low credibility.

All the cost-effective primary prevention interventions should have been implemented as far as practicable

Relevant primary prevention measures include iron fortification of foods and improved diet. Early studies have evaluated the relative effectiveness and cost per DALY of prevention strategies such as prenatal supplementation, universal supplementation and universal fortification. It is thought that diet based approaches and targeted supplementation is particularly cost-effective and that food fortification achieves the highest benefit-to-cost ratio. There is evidence from systematic reviews that fortification of foods with iron results in a statistically significant improved haemoglobin and iron status in pregnancy. Iron fortification has been implemented in the UK for a variety of foods including flour and cereals and there is a legal minimum iron level in bread and flour. Routine prophylactic iron supplementation in pregnancy has not been recommended in the UK due to concerns about side-effects, poor compliance and potential adverse effects of excess iron. There is evidence from a systematic review that nutrition education counselling improves maternal anaemia, but it is unclear how widely such counselling occurs, despite UK national guidelines encouraging improved dietary iron intake during pregnancy.

---

### A prospective study of prepregnancy dietary iron intake and risk for gestational diabetes mellitus [^111MRHdn]. Diabetes Care (2011). Low credibility.

Gestational diabetes mellitus (GDM) is one of the most common pregnancy complications affecting approximately 7% of all pregnancies and up to 14% of pregnancies in high-risk populations. Overweight and obesity are the major modifiable risk factors of GDM. However, the overall population attributable fraction among the general U.S. population because of overweight and obesity is estimated to be less than 50%, implying the need to identify additional risk factors, particularly modifiable risk factors, that may help lower GDM risk.

Although the underlying mechanism remains unclear, available evidence suggests that the main defect in the pathogenesis of GDM is relatively diminished insulin secretion coupled with pregnancy-induced insulin resistance. Iron, a redox-active transitional metal, is a strong prooxidant. Accumulating evidence from experimental studies has demonstrated that iron overload can lead to β-cell toxicity, β-cell dysfunction, and impaired glucose metabolism. Moreover, several epidemiological studies have documented a positive association of circulating levels of ferritin (a marker of body iron stores) with circulating levels of glucose and insulin, and risk of type 2 diabetes melletus (T2DM) and GDM. The major source of body iron is from the diet. Dietary iron exists as heme (mainly from meat and meat products) or nonheme iron. A positive association has been observed between dietary heme iron intake and T2DM. However, to our knowledge, there are no published studies evaluating dietary iron intake and GDM risk. Studies of supplemental iron and GDM risk are also scarce, and findings are inconsistent. The aim of this study was to evaluate the association between iron intake, including varying sources of iron (heme, nonheme, and supplemental) and GDM risk in a large prospective cohort.

---

### Intake and dietary sources of haem and non-haem iron among European adolescents and their association with iron status and different lifestyle and socio-economic factors [^112PRNzK]. European Journal of Clinical Nutrition (2013). Low credibility.

Background/Objectives

Adolescents are at risk of iron deficiency because of their high iron requirements. The aims of this study were: (1) to assess iron intake, its determinants and its most important food sources and; (2) to evaluate the relation of iron intake and status in European adolescents.

Subjects/Methods

Two non-consecutive 24-h recalls were completed by a computerised tool. The socio-demographic and socio-economic data were collected by a self-reported questionnaire. Weight and height were measured. A distinction was made between haem and non-haem iron.

Results

The total iron intake was significantly higher among boys (13.8mg/day; n = 1077) than girls (11.0mg/day; n = 1253). About 97.3% of the boys and 87.8% of the girls met the estimated average requirement, and 72.4% of the boys and 13.7% of the girls met the recommendation for bio-available iron intake. The ratio of haem/non-haem iron intake was lower for girls than boys. Meat (19.2; 76%) and bread and rolls (12.6;3.9%) contributed most to total and haem iron intake. Bread and rolls (13.8%) and meat (10.8%) contributed most to non-haem iron intake. Age, sex and body mass index were associated with iron intake. Only red blood cell concentration was significantly negatively associated with total, haem and non-haem iron intake.

Conclusion

Girls had lower iron intakes and ratio of haem/non-haem iron intake than boys. The main total iron and haem iron source was meat, while the main non-haem iron source was bread and rolls. Adolescent girls may be a group at risk for iron deficiency. Consequently, special attention and strategies are needed in order to improve iron intakes during adolescence.

---

### Iron: fact sheet for health professionals-HHS syndication storefront… [^114ZoLKx]. digitalmedia.hhs.gov (2004). Low credibility.

Iron: Fact Sheet for Health Professionals Recommended intakes and sources of iron, effects of deficiency and excess, groups at risk of inadequacy, and interactions with medications. Media Type: Html.
- SourceUrl: https: //ods. od. nih. gov/api/index. aspx? resourcename = Iron&readinglevel = Health%20Professional&outputformat = HTML-SyndicationID: 16581-Language: English-Source: OfficeofDietarySupplements-DateContentAuthored: Wednesday, July28, 2004at12: 00AM. -DateContentUpdated: Thursday, February11, 2016at12: 00AM-DateSyndicationCaptured: Thursday, January26, 2017at07: 52PM-DateSyndicationUpdated: Wednesday, October08, 2025at01: 10AM. TagsGeneral: nutritionanemiaredbloodcellsdietarysupplementfactsheethemoglobinironFerritinmultivitaminnutrientIronDeficiencymineralhememyoglobinAudience: healthprofessionalEmbedCodeSnippetTogettheembedcodesnippetpleaseLogin.

---

### Dietary iron intake, body iron stores, and the risk of type 2 diabetes: a systematic review and meta-analysis [^112U8Ytz]. BMC Medicine (2012). Low credibility.

Discussion

Summary of main findings

In this study, we found that heme iron intake and body iron stores were positively associated with an increased risk of T2DM, after adjustment for known potential confounders. Although dietary total iron intake has been associated with prevalent T2DM in a cross-sectional study, our meta-analysis of prospective studies found no significant association of dietary intakes of total iron, non-heme, and supplemental iron intake with the risk of T2DM. The positive association we found between heme iron and T2DM was consistent with previous results from prospective studies evaluating the relationships between red meat (the major source of heme iron) and the risk of T2DM. Because heme iron intake was found to be associated with higher body iron stores in previous studies, our results suggest that high levels of body iron stores may mediate the association of increased risk of T2DM with chronically high heme iron intake.

Interpretation

The positive association between excess iron and risk of T2DM is biologically plausible, although the underlying mechanisms still remain to be fully determined. First of all, iron is a powerful pro-oxidant and catalyst that promotes the formation of hydroxyl radicals, which may attack pancreatic beta cells through increasing oxidative stress and thus result in impaired insulin synthesis and excretion. Antioxidant enzymes, such as superoxide dismutase, catalase, and glutathione peroxidase, are expressed less in pancreatic islets than in other tissues, thus pancreatic islets are particularly susceptible to oxidative damage. In a mouse model of hemochromatosis, excess iron resulted in beta-cell oxidant stress and decreased insulin secretory capacity secondary to beta-cell apoptosis and desensitization of glucose-induced insulin secretion. Another study showed that even at 'normal' levels, iron exerted detrimental effects on pancreatic beta-cell function, and that these effects were reversible with dietary restriction or iron-chelation therapy. Second, excess iron may diminish glucose utilization in muscle tissue and lead to a shift from glucose to fatty acid oxidation, which may result in increased insulin resistance. In a recent study using a mouse model of hemochromatosis, although glucose uptake was increased in skeletal muscle, glucose oxidation was decreased and the ratio of fatty acid to glucose oxidation was increased, as a result of decreased pyruvate dehydrogenase (PDH) enzyme activity and increased expression of PDH kinase 4. Third, increased substrate recycling to the liver may contribute to the higher hepatic glucose production.

---

### The absorption of iron from whole diets: a systematic review [^111tU9B8]. The American Journal of Clinical Nutrition (2013). Low credibility.

Background

Absorption factors are required to convert physiologic requirements for iron into Dietary Reference Values, but the absorption from single meals cannot be used to estimate dietary iron absorption.

Objective

The objective was to conduct a systematic review of iron absorption from whole diets.

Design

A structured search was completed by using the Medline, EMBASE, and Cochrane CENTRAL databases from inception to November 2011. Formal inclusion and exclusion criteria were applied, and data extraction, validity assessment, and meta-analyses were undertaken.

Results

Nineteen studies from the United States, Europe, and Mexico were included. Absorption from diets was higher with an enhancer (standard mean difference: 0.53; 95% CI: 0.21, 0.85; P = 0.001) and was also higher when compared with low-bioavailability diets (standard mean difference: 0.96; 95% CI: 0.51, 1.41; P < 0.0001); however, single inhibitors did not reduce absorption (possibly because of the limited number of studies and participants and their heterogeneity). A regression equation to calculate iron absorption was derived by pooling data for iron status (serum and plasma ferritin) and dietary enhancers and inhibitors from 58 individuals (all from US studies): log[nonheme-iron absorption, %] = -0.73 log[ferritin, μg/L] + 0.11 [modifier] + 1.82. In individuals with serum ferritin concentrations from 6 to 80 μg/L, predicted absorption ranged from 2.1% to 23.0%.

Conclusions

Large variations were observed in mean nonheme-iron absorption (0.7–22.9%) between studies, which depended on iron status (diet had a greater effect at low serum and plasma ferritin concentrations) and dietary enhancers and inhibitors. Iron absorption was predicted from serum ferritin concentrations and dietary modifiers by using a regression equation. Extrapolation of these findings to developing countries and to men and women of different ages will require additional high-quality controlled trials.

---

### Commensal resilience: ancient ecological lessons for the modern microbiota [^116s4eCL]. Infection and Immunity (2025). Medium credibility.

INTESTINAL IRON AVAILABILITY AND ACQUISITION

Under physiological conditions, iron primarily exists in the ferrous (Fe(II)) or ferric (Fe(III)) states. The ferrous redox state predominates under anoxic or acidic conditions, while the insoluble ferric state is most prevalent under aerobic conditions. While the ferrous state can exist in its free form or in the tetrapyrrole cofactor heme, the ferric counterpart is almost always complexed within iron-chelating factors. In either form, iron cannot freely cross biological membranes. Consequently, iron transporters are widespread across phyla, with receptor systems dedicated to the uptake of either complexed ferric iron or free ferrous iron.

Dietary iron comprises heme iron, mostly derived from hemoglobin and myoglobin of animal tissues, and non-heme iron, present in both plant- and animal-based diets. In vertebrates, heme-iron is absorbed much more efficiently than non-heme iron, with approximately 15–25% of dietary heme-iron absorbed in the duodenum compared to 5–10% dietary non-heme iron. Iron is tightly sequestered in vertebrate tissues upon absorption to both restrict its acquisition by microbial cells and prevent the toxic production of ROS by the Fenton and Haber-Weiss reactions. Intracellular iron is bound within metalloproteins or stored in ferritin, while extracellular iron is complexed as heme in hemoglobin or sequestered by transferrin and calprotectin. As discussed above, host iron-chelating proteins serve as an innate defense mechanism, restricting microbial access to iron and protecting against infection. This restriction is further tightened upon inflammation onset. The expression of calprotectin significantly increases during bacterial infection, accounting for up to 50% of the total protein content of neutrophils. The combined action of these host chelators results in an exceedingly low free iron concentration within the host (10⁻²⁴ M). With access to this essential nutrient under such strict control, the host heme pool is an attractive iron source to pathogenic bacteria. Many genera encode hemolysins to mediate the lysis of erythrocytes and the consequent release of heme and hemoglobin. To counteract this, the host employs proteins like hemopexin and haptoglobin to sequester free heme and hemoglobin, respectively. This, however, is exploited by the iron-regulated surface determinant (Isd) system, a canonical mechanism for direct heme uptake in Gram-positive bacteria. The surface receptors IsdB and IsdH bind hemoglobin and hemoglobin-haptoglobin, respectively. Upon surface binding, IsdA and IsdC then transport the heme across the cell wall, and the ATP-binding cassette (ABC) transporter IsdDEF shuttles heme into the cytoplasm. Gram-negative bacteria can acquire heme through the secretion of heme-binding proteins (hemophores), followed by uptake via TonB-dependent receptors on the outer membrane.

---

### EASL clinical practice guidelines on haemochromatosis [^114hkGpu]. Journal of Hepatology (2022). High credibility.

Regarding nonpharmacologic interventions for hereditary hemochromatosis, more specifically with respect to dietary modifications, EASL 2022 guidelines recommend to advise avoiding consumption of iron-fortified food where possible.
Advise limiting red meat consumption.

---

### Approach to anaemia in gastrointestinal disease: a position paper by the ESPGHAN gastroenterology committee [^113nbj9r]. Journal of Pediatric Gastroenterology and Nutrition (2025). Medium credibility.

6.2.1 Dietary strategies

There are two forms of dietary iron: heme iron which is more effectively absorbed and non‐heme iron which has about two thirds of the bioavailability of heme iron. Foods containing heme iron include red meats, poultry and fish whereas non‐heme iron is mostly present in plant‐based foods such as legumes, fortified grains, dark chocolate, nuts, seeds and dark leafy vegetables. About 10%–15% of total dietary iron intake comes from heme iron; however, due to its higher bioavailability, it can contribute to up to 40% of total iron absorbed. Moreover, enhancers and inhibitors of iron absorption also affect the bioavailability of iron. Heme iron and ascorbic acid increase absorption of iron from non‐heme sources, while phytates (grains and legumes), polyphenols (tea and coffee), calcium (dairy products and supplements) and animal protein (milk protein, egg protein and albumin) inhibit its absorption.

Therefore, a dietary strategy to improve iron status may include the consumption of a combination of heme iron‐containing foods and non‐heme iron sources coupled with foods high in ascorbic acid, which enhances non‐heme iron absorption. Foods high in iron absorption inhibitors should be consumed separately from an iron‐containing meal. One study in adult women demonstrated that a 1 h time interval between an iron‐containing meal and tea consumption attenuated the inhibitory effect of the tea. Commonly, a 1–2 h interval between iron‐containing meal and iron inhibitors is considered sufficient to minimise the negative impact of iron inhibitors on iron absorption. Importantly, iron absorption is inversely correlated with iron status. Generally, absorption of heme iron is unaffected by an individuals' iron status, while absorption of non‐heme iron is higher in individuals with decreased body iron stores.

---

### Vital role for primary healthcare providers: urgent need to educate the community about daily nutritional self-care to support immune function and maintain health [^1111mESW]. BMJ Nutrition, Prevention & Health (2023). High credibility.

Providing adequate nutrients to support immune function is an easily modifiable, high-priority self-care measure that can help to maintain general health. Improving nutritional status helps to maximise immune protection against infections and may protect against the development of inflammatory/immune-mediated diseases. Although more research is necessary, there is a good rationale based on mechanistic data to postulate that supporting immune function through nutrition on a daily basis could have a beneficial effect on maintaining homeostatic mechanisms throughout the body and may help protect against chronic diseases.

Minimally processed, naturally nutrient-dense foods are the preferred way to fill micronutrient gaps, with fruits, berries and vegetables in particular containing numerous micronutrients and several classes of bioactive compounds (eg, polyphenols, carotenoids, etc) that have immunomodulatory effects. However, the body may not be able to obtain all the nutrients it needs from the diet alone, particularly in some subgroups of the population. Geographical, sociological and lifestyle factors, combined with constant exposure to pathogens and other immunological challenges, can contribute to insufficient micronutrient intakes. Even in high-income countries, suboptimal micronutrient levels are common throughout the life course. Data indicate that daily intakes of vitamins A, C, D, E and B12, calcium, iron and zinc — all essential for immune function — fall below recommended intakes in some adultsand throughout the life course, even in seemingly healthy people. As increasing dietary diversity to meet daily requirements is desirable but can be hard to achieve in reality for many people, particularly for certain vitamins and minerals. In such cases, a supplement containing multiple micronutrients known to support immune function could be a simple and cost-effective way of complementing the diet and closing some nutritional gaps. A healthcare provider should always be consulted first to ensure that the consumer can safely use a micronutrient supplement, that they are using a certified product, and that they are not only aware of the potential benefits but also of the upper tolerable limits. Furthermore, it is important that they are advised where they are able to access evidence-based information from credible sources, and to always check the often misleading information contained in social media posts, for example.

---

### Vegetarian dietary patterns for adults: a position paper of the Academy of Nutrition and Dietetics [^111d2geM]. Journal of the Academy of Nutrition and Dietetics (2025). High credibility.

Iron in vegetarian adults — A systematic review of presumably healthy adults indicated vegetarian, including vegan, dietary patterns may be associated with lower circulating ferritin concentrations compared with nonvegetarian diets, but results were mixed and certainty of evidence was very low, and vegetarian premenopausal women have a high prevalence of iron deficiency. The National Institutes of Health Office of Dietary Supplements suggests that vegetarians and vegans should consume nearly twice the recommended amount of iron because of low absorption from phytate-rich plant foods, and vegetarians should ingest a variety of iron-rich plant foods along with foods that are a rich source of vitamin C, which enhances absorption, while reducing intake of foods and beverages that are rich in absorption inhibitors (eg, coffee).

---

### The integral role of iron in ocean biogeochemistry [^1154dVgj]. Nature (2017). Excellent credibility.

The micronutrient iron is now recognized to be important in regulating the magnitude and dynamics of ocean primary productivity, making it an integral component of the ocean's biogeochemical cycles. In this Review, we discuss how a recent increase in observational data for this trace metal has challenged the prevailing view of the ocean iron cycle. Instead of focusing on dust as the major iron source and emphasizing iron's tight biogeochemical coupling to major nutrients, a more complex and diverse picture of the sources of iron, its cycling processes and intricate linkages with the ocean carbon and nitrogen cycles has emerged.

---

### Advantages and disadvantages of an iron-rich diet [^114ZS9yf]. European Journal of Clinical Nutrition (2002). Low credibility.

Background and Objective

A review by invitation about advantages and disadvantages of an iron-rich diet by analyzing physiological iron requirements, dietary factors influencing iron absorption and the regulatory systems available to control iron absorption according to needs.

Results

The control to prevent iron deficiency is good but not perfect, as observed in previously described studies on relationships between individual iron requirements and the probability of iron deficiency developing in relation to diet. The control to prevent iron overload seems to be perfect except in the few subjects being homozygotes for hereditary hemochromatosis.

Conclusions

A diet rich in easily available iron is important for covering basal iron losses, menstrual iron losses and the high iron requirements for growth from infancy to adolescence and for pregnancy.

---

### How I treat hemochromatosis [^112S6Yv4]. Blood (2010). Low credibility.

Hemochromatosis is a common genetic disorder in which iron may progressively accumulate in the liver, heart, and other organs. The primary goal of therapy is iron depletion to normalize body iron stores and to prevent or decrease organ dysfunction. The primary therapy to normalize iron stores is phlebotomy. In this opinion article, we discuss the indications for and monitoring of phlebotomy therapy to achieve iron depletion, maintenance therapy, dietary and pharmacologic maneuvers that could reduce iron absorption, and the role of voluntary blood donation.

---

### WHO recommendations for care of the preterm or low-birth-weight infant [^111Bkwas]. Geneva: World Health Organization (2022). High credibility.

Regarding specific circumstances for vitamins, minerals, and dietary supplements, more specifically with respect to neonatal and pediatric patients (preterm infants), WHO 2022 guidelines recommend to initiate enteral iron,
zinc, vitamin D, and vitamin A supplementation in human milk-fed preterm or low-birth-weight infants not receiving these micronutrients from other sources.

---

### Why US children use dietary supplements [^1114f7n6]. Pediatric Research (2013). Low credibility.

The most common MVM products used by children provide > 50% of the daily value for vitamins (A, C, D, E, B1, B2, B3, B6, B12; folic acid, pantothenic acid) and minerals (iron, iodine, zinc, and copper), with the exception of calcium. Of note, a recent study indicates that calcium and vitamin D intakes remain low in children (2–18 y of age), even among those who use dietary supplements. However, among children who used dietary supplements, excess nutrient intake was also observed for folic acid (49%), zinc (52%), and vitamin A (45%).

Approximately 15% the of products reported to be used by children were based on the recommendations from a physician or health care provider; stated differently, 85% of the supplements used by US children are based on either self-selection or decisions made by parents, caregivers, or others who may or may not be qualified to guide the choice of when and how much to supplement a diet. Health care providers were more likely to recommend dietary supplements to children < 2 y of age than to other age groups. This is a diverse age group: those < 1 y of age may be exclusively breast or bottle fed, whereas some infants are being introduced to food at 4–6 mo of age. The American Academy of Pediatrics recommends vitamin D and iron (after 4 mo of age) supplements to exclusively breastfed children, and the American Dental Association Council on Scientific Affairs recommends fluoride to children at high risk of developing dental caries and whose primary source of drinking water is deficient in fluoride; however, no other formal guidelines exist on the use of dietary supplements in healthy children in any other age groups.

---

### Bioavailability of iron, zinc, and other trace minerals from vegetarian diets [^113WQKxo]. The American Journal of Clinical Nutrition (2003). Low credibility.

Iron and zinc are currently the trace minerals of greatest concern when considering the nutritional value of vegetarian diets. With elimination of meat and increased intake of phytate-containing legumes and whole grains, the absorption of both iron and zinc is lower with vegetarian than with nonvegetarian, diets. The health consequences of lower iron and zinc bioavailability are not clear, especially in industrialized countries with abundant, varied food supplies, where nutrition and health research has generally supported recommendations to reduce meat and increase legume and whole-grain consumption. Although it is clear that vegetarians have lower iron stores, adverse health effects from lower iron and zinc absorption have not been demonstrated with varied vegetarian diets in developed countries, and moderately lower iron stores have even been hypothesized to reduce the risk of chronic diseases. Premenopausal women cannot easily achieve recommended iron intakes, as modified for vegetarians, with foods alone; however, the benefit of routine iron supplementation has not been demonstrated. It may be prudent to monitor the hemoglobin of vegetarian children and women of childbearing age. Improved assessment methods are required to determine whether vegetarians are at risk of zinc deficiency. In contrast with iron and zinc, elements such as copper appear to be adequately provided by vegetarian diets. Although the iron and zinc deficiencies commonly associated with plant-based diets in impoverished nations are not associated with vegetarian diets in wealthier countries, these nutrients warrant attention as nutritional assessment methods become more sensitive and plant-based diets receive greater emphasis.

---

### Effectiveness of provision of animal-source foods for supporting optimal growth and development in children 6 to 59 months of age [^114Srfgv]. The Cochrane Database of Systematic Reviews (2019). Medium credibility.

Background

Adequate nutrients early in life promote cognitive development and are critical for proper growth and functioning. The effect of individual nutrients consumed through food is often not the same as consuming the same nutrients in supplementary form due to 'food synergy', the biological and chemical interrelations that occur between nutrients. Animal-source foods, such as eggs, meat, fish, and dairy, are energy dense and contain multiple micronutrients and essential fatty acids with high bioavailability. The benefits of animal-source foods may include higher food synergy relative to fortified foods as well as decreasing dependence on external suppliers of fortified foods.

Objectives

To assess the effectiveness of animal-source foods compared to any other feeding interventions or no intervention in improving growth and developmental outcomes in children aged 6 to 59 months.

Search Methods

We searched CENTRAL, MEDLINE, Embase, CINAHL, 18 other databases, and three trials registers up to August 2018. We also contacted authors and known experts in the field for assistance in identifying ongoing or unpublished data, and searched the reference lists of included studies and reviews, and websites of relevant organizations, for other studies that may not have been captured by our electronic searches.

Selection Criteria

We included randomized controlled trials and quasi-randomized controlled trials of any duration, where children between 5 months and 59 months (6 years) of age were provided with an animal-source food (e.g. consumption of milk, meat, or eggs), prepared with any cooking method, compared with any intervention or no intervention.

Data Collection and Analysis

Two review authors independently assessed trial eligibility using prespecified criteria, extracted data, assessed risk of bias, and graded the quality of the evidence using the GRADE approach.

Main Results

Study characteristicsWe included 6 studies that analyzed data from 3036 children aged 5 to 50 months. The studies were conducted in China, the Democratic Republic of Congo, Ecuador, Guatemala, Pakistan, the USA, and Zambia, and lasted between 5 and 12 months. Three studies were funded, in part, by government entities; one study was supported by a nonprofit organization. Two studies did not report a funding source. Three studies compared the effects of feeding an animal-source food with a fortified (iron or iron and zinc), or unfortified cereal; two used a control group with no intervention; one compared a meat-based diet to a dairy-based diet. The types of animal-source foods tested included yogurt, eggs, cheese, lyophilized (freeze-dried) beef product, ground and frozen pork, puréed and jarred beef with gravy or pork, and powdered whey protein. We judged four studies to be at unclear risk of bias overall; three studies because they were funded by an industry with a plausible interest in the outcome of the intervention; and one study because there was insufficient information to assess five of the seven bias 'Risk of bias' domains. We judged two of the six studies to be at high risk of bias overall; one study because there was significant baseline imbalance in length-for-age z scores (LAZ) between groups and evidence of selective reporting; the other study because there there was both a significant baseline imbalance in LAZ and weight-for-age z scores (WAZ) between groups, and a large-scale social media campaign that may have influenced care received at home in the control group. Key resultsAnimal-source foods versus cereal-based foods or no interventionFive studies (2972 children) measured change in linear growth with either height-for-age z scores (HAZ) or LAZ. Three studies (592 children) reported a significant increase in HAZ and LAZ in the intervention group compared to the control group. Two studies (2380 children) reported a decline in LAZ in both groups. In one study (1062 children) there was no difference between the groups in the rate of decline; in the other (1318 children) the decrease in LAZ was significantly smaller in the intervention group. Five studies (2972 children) measured weight gain using WAZ. Three studies (592 children) reported a significant increase in WAZ in the intervention group compared to the control group. In two studies (2380 children), WAZ decreased in both groups. In one of these studies (1318 children), the decrease in the intervention group was significantly smaller than in the control group. In the other study (1062 children), there was no difference between the groups. Three studies (1612 children) reported impacts on all-cause morbidity, but metrics were inconsistent between studies. One study with yogurt (402 children) reported a significant reduction in duration and incidence of diarrhea and upper respiratory infections in the intervention group. One study with eggs (148 children) reported a significant increase in the incidence of diarrhea in the intervention group, but this may have been due to cultural associations with eggs and gastrointestional problems. There were no other significant differences in fever, respiratory infections, or skin conditions between groups. The third study (1062 children) found no differences between intervention and control groups across morbidity measures. No studies reported data on anemia. Meat-based diet versus dairy-based dietOne study (64 children) measured change in LAZ and WAZ in infants fed either a meat-based diet or dairy-based diet. There was a significant increase in LAZ among infants consuming the meat-based diet and a significant decrease in LAZ among infants consuming a dairy-based diet. WAZ increased in both groups, with no significant difference between groups. The study did not assess all-cause morbidity or anemia. Quality of the evidenceWe rated the quality of the evidence as very low overall due to baseline imbalances between intervention and control groups, high heterogeneity in meta-analysis, and imprecision due to wide confidence intervals and inconsistent direction of effects. We have little confidence in the results; further research is likely to change the estimate of magnitude and direction of treatment effect.

Authors' Conclusions

Given the limited quality of the evidence, we are uncertain of the effects of the provision of animal-source food versus cereal products or no intervention on the growth or development of children. More adequately powered trials with deliberately selected animal-source foods are needed.

---

### Fortification of condiments and seasonings with iron for preventing anaemia and improving health [^113HMMdH]. The Cochrane Database of Systematic Reviews (2023). Medium credibility.

(8) Selective reporting bias

We described for each included study how we investigated the possibility of selective outcome reporting bias and what we found. We assessed studies for this domain as:

low risk of bias (where it is clear that all the study's pre‐specified outcomes and all expected outcomes of interest to the review have been reported);
high risk of bias (where not all the study's pre‐specified outcomes have been reported; one or more reported primary outcomes were not pre‐specified; outcomes of interest were reported incompletely and so cannot be used; study fails to include results of a key outcome that would have been expected to have been reported); or
risk of bias unclear.

(9) Other sources of bias

We have described other possible sources of bias for each included study and given a rating of low, high, or unclear risk of bias for this item.

We used the EPOC 'Risk of bias' tool for any included ITS study designs which includes items (5), (6), (8), and (9) from the EPOC 'Risk of bias' tool above, as well as the following additional items:

Was the intervention independent of other changes? Low risk of bias if there are compelling arguments that the intervention occurred independently of other changes over time and the outcome was not influenced by other confounding variables/historic events during the study period. High risk of bias if it is reported or if there are grounds to suspect that the intervention was not independent of other changes over the time period of the study. Unclear risk of bias.
Was the shape of the intervention effect pre‐specified? Low risk of bias if the point of analysis is the point of intervention or a rational explanation for the shape of the intervention effect was provided. HIgh risk of bias if it was clear that these conditions were not met. Unclear risk of bias.
Was the intervention unlikely to affect data collection? Low risk of bias if it is reported that the intervention itself was unlikely to affect data collection (e.g. sources and methods of data collection were the same before and after the intervention). High risk of bias if the intervention itself was likely to affect data collection. Unclear risk of bias.

In addition to the above criteria, we also assessed cluster‐RCTs with the following criteria and these changes made have been described in Differences between protocol and review section

---

### Dietary intake of total, heme and non-heme iron and the risk of colorectal cancer in a European prospective cohort study [^113WucT8]. British Journal of Cancer (2023). Medium credibility.

Background

Iron is an essential micronutrient with differing intake patterns and metabolism between men and women. Epidemiologic evidence on the association of dietary iron and its heme and non-heme components with colorectal cancer (CRC) development is inconclusive.

Methods

We examined baseline dietary questionnaire-assessed intakes of total, heme, and non-heme iron and CRC risk in the EPIC cohort. Sex-specific multivariable-adjusted hazard ratios (HRs) and 95% confidence intervals (CIs) were computed using Cox regression. We modelled substitution of a 1mg/day of heme iron intake with non-heme iron using the leave one-out method.

Results

Of 450,105 participants (318,680 women) followed for 14.2 ± 4.0 years, 6162 (3511 women) developed CRC. In men, total iron intake was not associated with CRC risk (highest vs. lowest quintile, HR Q5vs.Q1 :0.88; 95%CI:0.73, 1.06). An inverse association was observed for non-heme iron (HR Q5vs.Q1 :0.80, 95%CI:0.67, 0.96) whereas heme iron showed a non-significant association (HR Q5vs.Q1 :1.10; 95%CI:0.96, 1.27). In women, CRC risk was not associated with intakes of total (HR Q5vs.Q1 :1.11, 95%CI:0.94, 1.31), heme (HR Q5vs.Q1 :0.95; 95%CI:0.84, 1.07) or non-heme iron (HR Q5vs.Q1 :1.03, 95%CI:0.88, 1.20). Substitution of heme with non-heme iron demonstrated lower CRC risk in men (HR:0.94; 95%CI: 0.89, 0.99).

Conclusions

Our findings suggest potential sex-specific CRC risk associations for higher iron consumption that may differ by dietary sources.

---

### Screening for iron deficiency anemia in young children: USPSTF recommendation statement [^114pF4M5]. Pediatrics (2015). Medium credibility.

Treatment and prevention in young children — iron deficiency anemia is usually treated with oral iron; the usual dose in infants and young children is 3 to 6 mg/kg of elemental iron per day in 2 to 3 divided doses. According to the Institute of Medicine, the Recommended Dietary Allowance for iron in infants ages 7 to 12 months is 11 mg per day, and in children ages 1 to 3 years it is 7 mg per day; nonheme iron may be less well absorbed than heme iron such that the iron requirement may be almost twice as much in children who eat a purely vegetarian diet. Fortified breads and grain products (such as cereal) are also good sources of iron for young children eating solid foods, and iron-fortified formula is another source of iron for infants; federally regulated iron fortification of food products in the United States began in 1941, and more than 50% of the iron in the US food supply comes from iron-fortified cereal grain products.

---

### A substantial proportion of 6-to 12-month-old infants have calculated daily absorbed iron below recommendations, especially those who are breastfed [^116S5jGZ]. The Journal of Pediatrics (2021). Medium credibility.

Objective

To calculate the amount of bioavailable iron consumed among 6- to 12- month-old infants considering differences in iron bioavailability among dietary iron sources and to compare this with current recommended intakes.

Study Design

We used the Feeding Infants and Toddlers Study database of dietary intakes from 2016 and the estimated bioavailability of dietary iron sources to evaluate the proportion of infants whose calculated total daily absorbed iron fell below physiologic requirements, that is, the recommended amount needed to fully support growth and erythropoiesis.

Results

The calculated daily iron absorption was below the recommended amount in 54.3% of infants evaluated ranging from 19.5% of 448 exclusively formula-fed infants, to 95.8% of 296 exclusively breastfed infants and 72.2% of 102 mixed fed infants. The calculated mean iron absorption of 6- to 9- month-old breastfed infants was 0.27 mg/day, far less than the estimated physiologic requirement of 0.69 mg/day. The most highly bioavailable iron, heme iron, was < 12% of the contributor to total iron absorbed in breastfed infants.

Conclusions

These data indicate a need for further education and public health policies to support increased iron intake in 6- to 12- month-old infants, emphasizing those receiving any breast milk. Exclusively formula-fed infants are at lower risk, but rates of low absorbed iron indicate that all infants may need monitoring for clinical evidence of low iron status. Consideration should be given to increasing the proportion of heme iron obtained from animal products in the diet where feasible.

---

### Using FIGO nutrition checklist counselling in pregnancy: a review to support healthcare professionals [^116Wwsf2]. International Journal of Gynaecology and Obstetrics (2023). Medium credibility.

11 IRON

Iron deficiency anemia is one of the most common health problems in women of reproductive age, affecting over one‐third of pregnant women globally. This anemia results in adverse outcomes such as increased maternal and infant mortality, mental and physical development issues, and impaired cognitive function in newborn babies. Dietary interventions are more effective in the long term for prevention of iron deficiency anemia than supplementation and have advantages in relation to compliance, long‐term acceptability, and cost‐effectiveness. In high‐risk populations however, supplementation may be more effective at reaching guideline‐specified optimal levels of iron in the diet. The FIGO Nutrition Checklist addresses iron intake and anemia screening. In relation to diet, it asks about the intake of meat, poultry, fish, vegetables, and fruit. Of these, red meat and other meat or fish are sources of the highly bioavailable heme iron. Other sources of iron include egg yolks, dark green leafy vegetables, beans, peas, dried fruit, and fortified cereals, although these are predominantly non‐heme iron, which is a less bioavailable form. Consuming iron‐containing foods alongside those with vitamin C, such as citrus juice or fruit or vegetables, may enhance iron absorption. Similarly, those at risk of deficiency should avoid eating foods that will inhibit iron absorption with the iron‐containing food. These include foods that are high in calcium, tannins, or phytates. The recommendations for iron vary between countries, with some including supplementation (Table 2). A morning dose of supplement may promote optimal response and alternate days could be considered to reduce gastrointestinal symptoms.

---

### Anemia, diet and therapeutic iron among children living with HIV: a prospective cohort study [^113QoDTM]. BMC Pediatrics (2015). Low credibility.

Conclusions

Our study highlights the finding that Indian children with HIV have significant presence of anemia that is orchestrated by iron deficiency, although vitamin A deficiency and chronic inflammation also play a role. Dietary sources of iron remain highly inadequate. The use of standard WHO-recommended therapeutic iron particularly for durations of up to 6 months appears to be safe in this setting, and is associated with beneficial effects on anemia, iron deficiency and HIV disease progression. Further clinical and cost-effectiveness studies of iron therapy will be useful in streamlining policy decisions on anemia management among HIV-infected children in non-malaria endemic regions.

---

### EASL clinical practice guidelines on haemochromatosis [^1119ivHV]. Journal of Hepatology (2022). High credibility.

Regarding nonpharmacologic interventions for hereditary hemochromatosis, more specifically with respect to dietary modifications, EASL 2022 guidelines recommend to avoid using iron supplementation.
Avoid using vitamin C supplementation, especially before iron depletion.

---

### Position of the Academy of Nutrition and Dietetics: micronutrient supplementation [^112vCaRv]. Journal of the Academy of Nutrition and Dietetics (2018). Medium credibility.

Micronutrient interactions — An imbalance of micronutrients can result from the consumption of high-dose or simultaneous nutrient supplements; for example, high-dose iron supplements can decrease zinc absorption and high amounts of zinc can inhibit copper absorption, and the absorption of both heme- and nonheme iron is inhibited by calcium supplements, but the clinical significance of iron status is unclear.

---

### Mediterranean diet and cardio-metabolic health: what is the role of meat? [^112A1XSP]. European Journal of Clinical Nutrition (2019). Medium credibility.

Traditional Mediterranean diet is known for its health benefits in prevention of cardio-metabolic diseases and risk factors associated with it. The role of red meat in Mediterranean diet is to some extent overlooked with the main focus on foods of plant origin. The majority of existing guidelines encourage general population to limit intakes of red meat. However, in reality, it is a significant part of the Mediterranean cuisine. Red meat is an excellent source of macro and micronutrients: high-quality protein, B vitamins, essential amino acids, omega-3 polyunsaturated fatty acids, phosphorus, zinc, iron, and selenium. Currently, there is not enough scientific evidence to suggest the strict limitation of the red meat consumption among the general population, however, there is a substantial evidence to support the advice to eliminate the consumption of processed meat from the diet.

---

### Global, regional, and national burdens of common micronutrient deficiencies from 1990 to 2019: a secondary trend analysis based on the global burden of disease 2019 study [^111W64hW]. EClinicalMedicine (2022). Medium credibility.

From 1990 to 2019, the age-standardized prevalence rate of dietary iron deficiency declined worldwide. The global increase in the consumption of animal products, dietary diversification and improved access to foods might be possible reasons. Although the availability of animal products for human consumption has increased in East and Southeast Asia, dietary iron deficiency is still an important public health problem that requires comprehensive interventions. When iron intake no longer meets the requirement of normal iron turnover and loss, iron-deficiency anemia occurs, accounting for approximately half of anemia cases globally. The current study shows a sex difference in the dietary iron deficiency burden, as the prevalence was higher in females than in males. The main reason for sex differences in the prevalence of iron deficiency is that the requirements for iron are almost double for women of reproductive age compared to men, and in pregnancy, they even triple. When diets are largely plant-based, iron requirements further increase to compensate for the lower bioavailability of iron in plant foods. Bone marrow radioactive iron studies have shown that iron absorption depends on iron stores in the body and is not sex-specific. This indicates that the global sex difference might also be explained by differences in dietary intake of iron-rich foods. In addition, menstruation might also cause a negative iron balance in apparently healthy women. The public health impact of iron deficiency is more pronounced among women than among men, as it can lead to iron deficiency in future generations unless timely measures are taken. The prevalence of dietary iron deficiency is higher among children aged under five years than among children aged over five years, which is consistent with previous estimates. This could be due to a low rate of iron supplementation during pregnancy, as many pregnant women do not attend antenatal clinics or receive sufficient doses of supplements or because there is insufficient emphasis on behavioral aspects related to regular supplement use.

---

### Meat, cancer and dietary advice to the public [^111hRYR1]. European Journal of Clinical Nutrition (2002). Low credibility.

Background

It has been claimed for many decades that meat is a risk factor for colorectal cancer, and that it has no compensating benefits in terms of cancer risk. The evidence for this has been critically reassessed.

Methods

The epidemiological evidence, particularly that produced in recent years, has been re-examined to determine whether it is sufficiently consistent to warrant giving firm advice to the general public.

Results

Far from being supportive, the epidemiological data does not justify this claim. A large mass of evidence is presented from case-control studies and prospective studies, in which the data from Europe are not consistent with those from the United States. This is because of the different contexts (in terms of meal composition) within which meat is consumed in different countries. In fact the epidemiological data are much more consistent with there being a protective role for fruit, vegetables and whole grain cereals and no role for meat in colorectal cancer, and a protective role in gastric cancer.

Conclusions

Meat is a good source of protein, readily available iron, calcium, magnesium, selenium, zinc and a range of B vitamins. Since the evidence for any role in colon carcinogenesis is so weak, and since such a high proportion of women of child-bearing age are iron deficient, the consumption of meat, as part of a balanced and varied diet, should be actively encouraged.

---

### International consensus guidelines for the diagnosis and management of food protein-induced enterocolitis syndrome: executive summary-workgroup report of the adverse reactions to foods committee, American Academy of Allergy, Asthma&Immunology [^1131yM9s]. The Journal of Allergy and Clinical Immunology (2017). Medium credibility.

Food protein–induced enterocolitis syndrome (FPIES)–implicated foods — general guidance emphasizes that 'When choosing plant-based sources of iron (nonheme iron sources), it is beneficial to include dietary sources of vitamin C to improve iron absorption' and notes that 'Breast milk alone does not provide adequate vitamin D, iron, zinc, or protein for older infants (> 6 months); consider also solid-food choices to meet these nutrient needs'.

---

### Fortification of condiments and seasonings with iron for preventing anaemia and improving health [^116hf59a]. The Cochrane Database of Systematic Reviews (2023). Medium credibility.

Anaemia and iron deficiency can only be diagnosed by laboratory tests. Anaemia is assessed by measuring haemoglobin concentration and is usually interpreted according to age, sex, pregnancy status, altitude and, if known, smoking status as these factors alter iron needs (WHO 2011a). Iron deficiency is assessed through several biochemical measurements including serum ferritin, serum iron, transferrin saturation, soluble transferrin receptor (sTfR), and erythrocyte protoporphyrin. Ferritin is the most used indicator to assess iron status and depletion, and there is a close relationship between the total amount of stored iron and the serum ferritin concentration in normal individuals, although this indicator is affected by inflammation (WHO 2011b). Assessing anaemia by measuring the haemoglobin concentration is a relatively inexpensive and feasible test, even in resource‐poor settings (WHO 2007). Global health actors have recognised addressing anaemia as a priority, and one of the global nutrition targets for 2025 is to reduce anaemia by 50% in women of reproductive age (WHO 2014).

Description of the intervention

Various strategies are employed to prevent and treat iron deficiency and anaemia in different populations. These include dietary diversification to improve iron intake and bioavailability; selective plant breeding or genetic engineering to increase the iron content or to reduce absorption inhibitors in dietary staple crops; oral iron supplementation with pharmacological doses; and fortification of industrially manufactured foods with iron (Hurrell 2010). Maintaining a varied diet that includes foods rich in bioavailable iron ‐ such as animal sources ‐ is often costly and difficult to obtain in resource‐poor settings, and may not be acceptable in vegetarian populations. Oral supplementation is probably the most used strategy, as it often improves micronutrient status quickly by providing the nutrient directly, in tablet, powder, or liquid form. However, despite potential effectiveness, such programmes face prevalent implementation challenges and may not be sustainable.

---

### A prospective study of prepregnancy dietary iron intake and risk for gestational diabetes mellitus [^116jvEYY]. Diabetes Care (2011). Low credibility.

Table 1
Baseline characteristics by quintiles of prepregnancy dietary total iron and heme iron intakes among 13,475 women

Table 2
Prepregnancy dietary iron intakes and RRs of GDM among 13,475 women

Figure 1
Smoothed histogram and spline plot displaying the RRs of GDM according to dietary heme iron intake (mg/day, continuous). RRs adjusted for age, parity, BMI, physical activity, glycemic load, polyunsaturated fat intake, cereal fiber, smoking, alcohol, total calories, and family history of diabetes. The solid lines represent point estimates; the dashed lines illustrate 95% CIs.

Because red meat is one of the primary sources of heme iron and its intake was positively associated with GDM in this cohort, other components of red meat may confound the heme iron and GDM association. When we further adjusted for other components of red meat that could be related to glucose metabolism — including saturated fat and dietary cholesterol — by adding these variables to the fully adjusted models, the RR was slightly attenuated but remained significant (RR 1.55 [95% CI 1.13–2.13] for the highest quintile vs. the lowest quintile; P trend = 0.002) (data not shown). When we additionally adjusted for red meat, the RR was further attenuated (1.29 [0.95–1.75]; P trend = 0.02) (data not shown).

In stratified analyses, the association of heme iron with GDM risk appeared to be stronger among current cigarette smokers than nonsmokers although the test for interaction was not significant (P value for interaction = 0.26). For example, the RR comparing the extreme quintiles was 3.98 (95% CI 1.55–10.23; P trend = 0.0008) among current smokers and 1.43 (1.17–1.91; P trend = 0.003) among current nonsmokers (Fig. 2). The association did not vary by BMI, physical activity, family history of diabetes, or vitamin C intake (data not shown).

Figure 2
RRs of GDM in association with prepregnancy dietary heme iron intake stratified by smoking status. RRs are adjusted for age, parity, BMI, physical activity, glycemic load, polyunsaturated fat intake, cereal fiber, alcohol, total calories, and family history of diabetes. Smokers are represented by diamonds, and nonsmokers are represented by squares. (A high-quality color representation of this figure is available in the online issue.)

---

### Dietary iron and haem iron intake and risk of endometrial cancer: a prospective cohort study [^114TYbzu]. British Journal of Cancer (2008). Low credibility.

Data from the FFQ were used to calculate total dietary iron intake using a database described elsewhere. The values for iron intake presented here are for dietary sources alone, because data on iron supplements were not collected. Total intake of meat iron was calculated from the reported intake of 22 meat items and 2 mixed dishes containing meat. Haem iron intake was computed by two methods, using different proportions for haem iron from different types of meat: 69% for beef; 39% for pork ham, bacon, pork-based luncheon meats, and veal; 26% for chicken and fish; and 21% for liver, following, and, alternatively, using 40% as the average proportion of haem iron in all meats, following. Results were similar for both methods, and we present data using the first approach. In addition, we assessed risk in association with intake of all meats, red meat, and non-haem iron. All meat- and iron-related variables were calorie-adjusted using the residuals method.

---

### Plant-based alternative proteins-are they nutritionally more advantageous? [^111H72Zm]. European Journal of Clinical Nutrition (2023). Medium credibility.

Background

The transition towards sustainable nutrition as well as the exploration of alternative sources of protein have been at the forefront of thinking in the 21st century. However, further research is required to ascertain if a diet composed of alternative plant-based proteins has similar nutritional advantages to a plant-based diet. This study aims to model the replacement of a diet consisting of animal-based proteins with plant-based alternatives (PBA), in a group of Asians.

Methods

A 4-day food record was collected from 50 individuals residing in Singapore and nutrient profiles were generated for each individual. Food records were analysed, and meat, dairy, and seafood ingredients were substituted gram-for-gram with their PBA. The original and replaced nutrient profiles were compared against each other and the differences in macro and micronutrients were analysed.

Results

A significant increase in carbohydrates, dietary fibre, as well as in micronutrients such as sodium and calcium was observed. Conversely, there was a significant decreased intake in overall energy, protein and fat (p < 0.005).

Conclusions

The significant nutritional impact of substituting animal-based proteins for PBA may present benefits for bone health and individuals on a caloric restriction diet. However, higher sodium levels may be undesirable for individuals with cardiovascular conditions and hypertension, and the low bioavailability of iron in plant-based sources may present issues for iron deficient populations. Bearing some of these key findings in mind, researchers and manufacturers need to consider these when developing alternative protein products to meet consumer demands for palatable and nutritious plant-based products.

---

### Veganism and paediatric food allergy: two increasingly prevalent dietary issues that are challenging when co-occurring [^114HuQdt]. BMC Pediatrics (2020). Medium credibility.

Iron

Typical vegan diets often include many iron-rich foods, including lentils, tofu (soy), chickpeas, nuts, seeds and grains. However, unlike iron from animal sources, termed heme iron, which is readily absorbed, non-heme iron from plants has poor bioavailability and lower absorption, due to high phytate and polyphenol levels. Non-heme, plant-based sources of iron must also be consumed in larger portions than heme, animal-based sources of iron, to meet needs. Vegans, as well as vegetarians, require 1.8 times the amount of dietary iron, compared to meat eaters, as a result of poorer bioavailability. Vitamin C may enhance the absorption of non-heme iron. However, many vegan sources of iron, particularly soy, nuts and sesame seeds, are also common food allergens. For children who are not allergic, iron-fortified foods, including packaged cereals, may be an additional source of iron. Through later infancy, iron deficiency is the most prevalent micronutrient deficiency, thus highlighting the importance of adequate iron intake. Amongst the very young, infant formulas and cereals are main sources of dietary iron. After age 12 months, iron-fortified formulas are positively associated with serum ferritin levels, independent of socio-economic status and other dietary sources of iron.

But, even in the absence of allergies to common iron-rich vegan foods, careful monitoring of these children may be advised. In a study of infants with cow's milk allergy, but otherwise well, iron deficiency anaemia was identified in 5% of children. More strikingly, a retrospective study from Taiwan provides evidence that the prevalence of cow's milk protein allergy amongst children with iron-deficiency anaemia (serum ferritin < 12 ng/mL) was at least double the prevalence that has been reported in the general Taiwanese population (13.7% vs. 3.4 to 7.7%). Although the study of children with iron-deficiency anaemia was small (N = 51), it points toward an increased risk of iron-deficiency anaemia amongst young children with cow's milk allergy. Notably, although these children were quite ill, as evidenced by failure to thrive, hypoalbuminemia and erosive and hemorrhagic colitis on colonoscopy, none had eosinophila in the lamina propria and all recovered within 7 months of cow's milk elimination and iron supplementation.

---

### The importance of bioavailability of dietary iron in relation to the expected effect from iron fortification [^113Mrzin]. European Journal of Clinical Nutrition (2008). Low credibility.

Background

The most common method of combating iron deficiency is iron fortification, especially in developing countries. However, few studies have shown a significant effect on iron status following iron fortification of low bioavailability diets.

Objective

To investigate how iron fortification and dietary modifications affect iron absorption and rates of changes in iron stores.

Methods

Research has made it possible to predict both iron absorption and the effects of iron fortification and diet modifications on iron stores using recently developed algorithms. Iron absorption and rate of change in iron stores were calculated from nine diets representing a broad range of iron bioavailability and iron contents. The calculations were related to the main target group for iron fortification, that is, women of reproductive age having empty stores but normal haemoglobin concentrations.

Results

As the only measure, iron fortification has practically no effect on iron status if the original diet has low bioavailability. However, after dietary modifications such a diet shows a positive effect on iron stores. The combined action of fortification (6 mg/day) and modest bioavailability changes in a low bioavailability diet results approximately in 40 and 70% greater increases in iron stores than through iron fortification or dietary modification alone.

Conclusions

It is difficult to achieve good effects on iron status from iron fortification as the only measure if the diet has low bioavailability. Both dietary modifications as well as iron fortification are required to improve effectively the iron status of a population.

---

### Fortification of condiments and seasonings with iron for preventing anaemia and improving health [^1115ZRe4]. The Cochrane Database of Systematic Reviews (2023). Medium credibility.

Background

Description of the condition

Vitamin and mineral deficiencies are prevalent throughout the world and contribute significantly to the global burden of disease (WHO 2009). Iron, vitamin A, and iodine deficiencies affect billions worldwide, with iron deficiency and anaemia being the most prevalent, affecting more than 30% and 15% of global population, respectively (Bailey 2015; WHO 2008; The Micronutrient Initiative 2009). As of 2019, about 1.8 billion people lived with anaemia and iron deficiency remains the leading cause of anaemia in all regions (Safiri 2021). Iron is present in a wide variety of plant‐ and animal‐based foods, but iron in plant‐based diets ‐ common in low‐ and middle‐income countries ‐ is often less well‐absorbed, hindered by dietary compounds such as phytates, tannins or phenols that are present in the same foods. Conversely, meat and meat by‐products are the best sources of bioavailable iron, but they may be inaccessible, culturally inappropriate, or unaffordable to many people.

Anaemia is a multifactorial condition. It is estimated by Safiri 2021 that about 66.1% and 56.8% of cases among males and females, respectively, are caused by dietary iron deficiency (known as iron deficiency anaemia ‐ IDA), although other estimates are lower (Petry 2016; WHO 2014) and vary across regions, age, sex, and the presence of other causes of anaemia. Other causes of anaemia include infectious diseases such as malaria, tuberculosis, HIV and parasitic infections; inherited disorders of haemoglobin structure; or other nutritional deficiencies such as that of folate, vitamin B12 and vitamin A (WHO 2022a). Those with IDA may have inadequate iron intake, inadequate iron absorption or transport within the body, and/or losses of iron associated with disease or life stage (Clark, 2008). In settings with excess burden of other diseases such as HIV, malaria, or hookworm infestations, the chances of anaemia occurrence and complications are increased.

---

### Is iron and zinc nutrition a concern for vegetarian infants and young children in industrialized countries? [^112HVXqm]. The American Journal of Clinical Nutrition (2014). Low credibility.

Well-planned vegetarian diets are considered adequate for all stages of the life cycle, despite limited data on the zinc status of vegetarians during early childhood. The bioavailability of iron and zinc in vegetarian diets is poor because of their higher content of absorption inhibitors such as phytate and polyphenols and the absence of flesh foods. Consequently, children as well as adult vegetarians often have lower serum ferritin concentrations than omnivores, which is indicative of reduced iron stores, despite comparable intakes of total iron; hemoglobin differences are small and rarely associated with anemia. However, data on serum zinc concentrations, the recommended biomarker for identifying population groups at elevated risk of zinc deficiency, are sparse and difficult to interpret because recommended collection and analytic procedures have not always been followed. Existing data indicate no differences in serum zinc or growth between young vegetarian and omnivorous children, although there is some evidence of low serum zinc concentrations in vegetarian adolescents. Some vegetarian immigrants from underprivileged households may be predisposed to iron and zinc deficiency because of nondietary factors such as chronic inflammation, parasitic infections, overweight, and genetic hemoglobin disorders. To reduce the risk of deficiency, the content and bioavailability of iron and zinc should be enhanced in vegetarian diets by consumption of fortified cereals and milk, by consumption of leavened whole grains, by soaking dried legumes before cooking and discarding the soaking water, and by replacing tea and coffee at meals with vitamin C-rich drinks, fruit, or vegetables. Additional recommended practices include using fermented soy foods and sprouting at least some of the legumes consumed. Fortified foods can reduce iron deficiency, but whether they can also reduce zinc deficiency is less certain. Supplements may be necessary for vegetarian children following very restricted vegan diets.

---

### Approach to anaemia in gastrointestinal disease: a position paper by the ESPGHAN gastroenterology committee [^117Gqy91]. Journal of Pediatric Gastroenterology and Nutrition (2025). Medium credibility.

Recommended daily intake of iron ranges from 7 to 13 mg daily (adapted from EFSA Panel on Nutrition, Novel Foods and Food Allergens) (Table 5). Many factors influence iron requirements, including age, sex and iron status, among others. Children who follow vegetarian or vegan diets require a higher iron intake since non‐heme iron is less bioavailable than heme iron. Cow's milk is low in iron (0.1–0.2 mg per 240 mL) and is, therefore, not suitable for infants. In infants who are not breastfed, the only adequate source of iron is iron‐fortified infant formula. By 6 months of age, the infant's endogenous iron stores will have been used up. Therefore, early introduction of foods rich in iron is recommended during complementary feeding period. Table 6 lists the iron content of selected foods (adapted from Iron Fact Sheet for Health Professionals).

Table 5
Summary of dietary reference values for iron.

Table 6
Iron content of selected foods.

6.2.2 Oral iron

Oral iron preparations are relatively inexpensive and easily available but may cause GI side effects such as constipation, diarrhoea, abdominal pain and nausea while also having an effect on the intestinal microbiome.

There are numerous iron preparations, most of them available as over‐the‐counter supplements with or without other vitamins or minerals, which may result in uncertainty for both patients and physicians. Ferrous sulphate is, currently, the most frequently used formulation, whereas ferrous gluconate, ferrous fumarate, and carbonyl iron have also demonstrated efficacy as iron supplements for prevention and treatment of IDA. The elemental iron content of ferrous sulphate, ferrous gluconate, and ferrous fumarate is 20%, 11.6% and 33%, respectively. Iron polysaccharide combinations are hydrated microspheres remaining in solution over a wide range of pH values, theoretically allowing for improved absorption and tolerability.

---

### Gestational diabetes mellitus in relation to maternal dietary heme iron and nonheme iron intake [^1147e44N]. Diabetes Care (2011). Low credibility.

Iron deficiency is the most common nutritional deficiency in the U.S. and worldwide. In recent years, concerns about iron overload in developed countries have spurred research designed to assess cardiometabolic risks secondary to excess body iron stores and high dietary iron intake. As a result, iron now is viewed as a double-edged sword for living systems. Increasingly, clinical and epidemiological evidence suggest that both iron deficiency and iron overload influence the production of reactive oxygen species, leading to oxidative stress, systemic inflammation, and alternations in mitochondrial function. Taken together, cellular and metabolic alterations secondary to iron overload are thought to contribute to increased risks of hypertension, cardiovascular disease, and type 2 diabetes (,–).

The two kinds of dietary iron, heme and nonheme iron, with distinct metabolic pathways and intestinal absorption potential, are thought to play distinct roles in the pathophysiology of cardiometabolic disorders. Heme iron is exclusively present in hemoglobin and myoglobin from animal sources, including red meat and poultry. Nonheme iron, which is abundant in cereals, vegetables, fruits, beans, and dairy products, accounts for > 85% of dietary iron intake. Although heme iron accounts for a smaller proportion of dietary iron, it is absorbed two to three times more readily than nonheme iron and is less affected by other dietary constituents. The bioavailability of heme and nonheme iron is influenced by dietary factors, including ascorbic acid, coffee, and whole grains. Body iron stores also are important determinants of intestinal absorption of heme and nonheme iron.

---

### Position of the Academy of Nutrition and Dietetics: micronutrient supplementation [^115iyVyQ]. Journal of the Academy of Nutrition and Dietetics (2018). Medium credibility.

Infants and young children — iron supplementation: The American Academy of Pediatrics recommends 1 mg/kg daily iron supplementation for exclusively breastfed full-term infants from age 4 months until infants begin eating iron-containing complementary foods, and also recommend 1 mg/kg/day supplemental iron beginning at age 4 months for infants who receive more than one-half of their daily feedings as human milk and who are not receiving iron-containing complementary foods.

---

### EASL clinical practice guidelines on haemochromatosis [^1116kq6h]. Journal of Hepatology (2022). High credibility.

Regarding nonpharmacologic interventions for hereditary hemochromatosis, more specifically with respect to dietary modifications, EASL 2022 guidelines recommend to do not offer dietary modifications as a substitute for iron removal therapy.

---

### A cohort study of dietary iron and heme iron intake and risk of colorectal cancer in women [^1146SCNg]. British Journal of Cancer (2007). Low credibility.

Free iron is a pro-oxidant, and may contribute to colorectal carcinogenesis by promoting free radical production and lipid peroxidation. Epidemiologic studies examining the association of iron intake and markers of body iron stores with risk of colorectal cancer or colorectal polyps have yielded some evidence of positive associations. In addition, epidemiologic studies have shown a modest association between red meat intake, the major source of dietary iron, and risk of colon and colorectal cancer. However, few studies have examined the association of intake of heme iron, derived principally from red meat, with colorectal cancer risk. Heme iron, which has greater bioavailability compared to non-heme iron, has been shown experimentally to have cytotoxic and hyperproliferative effects in the rat colon. To date, three cohort studies have reported on the association of heme iron intake and risk of colon or colorectal cancer, and suggest a possible positive association of intake with risk, which may be enhanced in consumers of alcohol. However, there are inconsistencies in the association found in these studies by subsite and by sex, as well as with regard to the role of effect modification by alcohol consumption. We used data from a large cohort study of Canadian women to assess the risk of colorectal cancer in association with total iron and heme iron intake, as well as potential effect modification by alcohol consumption and hormone replacement use.

---

### Excessive early-life dietary exposure: a potential source of elevated brain iron and a risk factor for Parkinson's disease [^114AzdsY]. NPJ Parkinson's Disease (2017). Low credibility.

Formula fortification to address IDA in infants was first endorsed by the American Academy of Paediatrics in 1969 and enacted into law in the Infant Formula Act (1980), though iron-enriched formulae were available from 1959. Current AAP recommendations suggest fortified formula with 12 mg/L of iron, in addition to complementary foods (including those manufactured from enriched grains and foods containing haem iron) from 6 months of age; most high-income countries follow this guideline to some degree. The European Society for Paediatric Gastroenterology, Hepatology, and Nutrition considers fortification of formula fed to infants from 6 months safe and appropriate; however, a specific level has not been set due to a cited lack of evidence for optimal iron levels to prevent IDA, and typical concentrations are 4–8 mg/L. When taken together, formula and iron-enriched cereal products account for a substantial portion of an infant's dietary iron intake; in Australia this constitutes 71.7% of the total iron intake for 9-month-old infantsand 87.8% for 6–12-month-old infants in the US.

---

### Iron supplementation during pregnancy-a cross-sectional study undertaken in four German States [^1152qZLw]. BMC Pregnancy and Childbirth (2018). Low credibility.

Nutritional behaviour and other iron sources

The majority of women (n = 190; 91.8%) provided information about their nutritional behaviour during pregnancy. According to this, three quarters of the study population had taken other dietary supplements (n = 155; 74.9%) in addition to iron supplements. Some of those products (n = 12; 7.7%) also contained iron with a median daily dose of 7.5 mg (range: 2–15 mg/day). Also, more than one third of the study population (n = 69; 36.3%) had consumed iron-fortified foods during pregnancy, of which fruit-based beverages were the most commonly reported (n = 60; 87.0%). The median contribution of fortified foods to iron intake was 10 mg/day. Altogether, the median iron intake of the study group estimated from various dietary sources (supplements, fortified foods, normal foods) was about 8 mg/day with no difference between women with and without ID/anaemia (p = 0.47). However, the 75th and 90th percentiles of women with and without ID/anaemia achieved intakes of 18.0 and 40.0 mg/day and 12.8 and 25.0 mg/day, respectively (Fig. 4).

Fig. 4
Nutritional iron intake, including fortified foods and dietary supplements of women with and without ID/anaemia

---

### Anemia in children with inflammatory bowel disease: a position paper by the IBD committee of the north American society of pediatric gastroenterology, hepatology and nutrition [^113Ns3BU]. Journal of Pediatric Gastroenterology and Nutrition (2020). High credibility.

Dietary management for anemia in pediatric inflammatory bowel disease (IBD) focuses on a balanced diet with iron-rich foods and pairing strategies to enhance absorption; iron is absorbed primarily from the duodenum and partially from the proximal jejunum and ileum, and dietary iron can be classified into 2 forms: heme and nonheme. Absorption from nonheme sources is more variable, but pairing nonheme iron with foods high in ascorbic acid can lead to enhanced absorption, whereas certain foods may decrease iron absorption. Children should consume at least 3 servings per day of iron-rich foods from sources such as iron fortified cereals, and recommended daily intake for healthy children ranges from 7 to 11 mg daily.

---

### Adherence to the planetary health diet index and correlation with nutrients of public health concern: an analysis of NHANES 2003–2018 [^113235x4]. The American Journal of Clinical Nutrition (2024). Medium credibility.

Introduction

Diet, climate change, and human health are closely interrelated. Global dietary shifts are associated not only with increased risk of obesity, type II diabetes, cardiovascular disease, and certain cancers, but also with intensive production methods that contribute to environmental degradation via greenhouse gas emissions, land use change, land degradation, and water pollution. A 2021 report from the Intergovernmental Panel on Climate Change warned that climate change and its effects on human health are accelerating, and there is a dire need for solutions across a variety of sectors, including the food system.

To better align nutrition and sustainability targets, in 2019, the EAT- Lancet Commission on Food, Planet, Health introduced the "universal healthy reference diet", also referred to as the Planetary Health Diet (PHD) to reduce the burden of diet-related disease and minimize the environmental impact of feeding human populations. The reference diet provides 2500 kcal/d and adequate macro- and micronutrient intakes and was evaluated against planetary boundaries for 6 key environmental indicators.

In the United States, components of the EAT- Lancet universal healthy reference diet have been compared with components of the Healthy Eating Index — which measures adherence to the Dietary Guidelines for Americans (DGAs) — but only for individual food groups rather than comparing the 2 dietary patterns overall. To the best of our knowledge, no study has applied a diet index based on evidence from the EAT- Lancet Commission to describe the health and sustainability of diets in a nationally representative United States population, nor how adherence to such a diet has changed in recent years, because awareness of the environmental impact of diet has grown.

The EAT- Lancet Commission recommends a dietary pattern high in plant-based foods, including protein foods, and low in animal-sourced products, such as meat, fish, and dairy. The typical United States diet, on the other hand, is characterized by a high intake of animal-sourced foods and a low intake of beans, legumes, and other iron-rich plant sources. Indeed, meat and poultry are the top food sources of dietary iron in the United States.

---

### Excessive early-life dietary exposure: a potential source of elevated brain iron and a risk factor for Parkinson's disease [^116kP2KC]. NPJ Parkinson's Disease (2017). Low credibility.

Parkinson's mortality and historical iron fortification policies in high-income countries

We hypothesise that individuals exposed to high dietary iron during critical periods of neural development are at risk of excessive iron accumulation in the brain. For example, in high-income countries where cereals and infant formulae have historically been fortified with iron, infants may experience increased early-life iron exposure that predisposes them to age-related iron accumulation in susceptible neurons in the midbrain, which rapidly amasses iron during early life. Combined with genetic factors that limit iron-regulatory capacity and/or dopamine metabolism, this may increase the risk of PD.

Given the association between brain iron and PD, we sought epidemiological evidence that high-income countries that were early adopters of food fortification and iron supplementation programs for infants may now be experiencing increasing rates of PD. Public health policies regarding dietary iron supplementation can be traced back nearly a century. The US began fortifying flour with iron in the 1930s to reduce IDA in the general population. This approach was reinforced by an American Medical Association policy in 1936that was adopted by most high-income countries during World War 2 and beyond, including countries receiving humanitarian aid from the US. Other than the US (wheat, maize and rice) and UK (wheat), where fortification remains mandatory, most other high-income countries either continue (e.g. Australia) or recently abandoned a voluntary fortification program (e.g. Sweden).

---

### Adherence to the planetary health diet index and correlation with nutrients of public health concern: an analysis of NHANES 2003–2018 [^115XvbmH]. The American Journal of Clinical Nutrition (2024). Medium credibility.

Because the Planetary Health Diet Index (PHDI) is a novel dietary measure, and because it has several key differences from the DGAs, we tested the correlation of PHDI with the adequacy of key micronutrients of public health concern in the United States. We decided to evaluate iron because animal-sourced foods are a major source of dietary iron and calcium in the typical American diet, whereas the PHDI recommends a low intake of most animal-sourced foods. Other micronutrients of concern that are lacking in many American diets are calcium, potassium, fiber, and vitamin D. In nationally representative data, the prevalence of inadequacy among United States adults was estimated to be 95% for fiber, 70% for potassium, and 44% for calcium. Although a shift toward the EAT- Lancet universal healthy reference diet would likely improve intakes of fiber and potassium given that vegetables, beans, legumes, and fruit are rich sources of these micronutrients, the impact on calcium and iron intakes is uncertain and evidence on the recommendation's correlation with nutrient intake in real-world settings is limited.

The objectives of this study were to assess how the United States diet aligns with the PHDI, a novel index based on the evidence presented by the EAT- Lancet Commission, and to examine changes in accordance with the PHDI between 2003 and 2018 for the entire dietary pattern and its constituent components. We further assess how PHDI correlates with inadequacy for key nutrients of public health concern in the United States (iron, fiber, potassium, and calcium).

---

### EASL clinical practice guidelines on haemochromatosis [^11443eCu]. Journal of Hepatology (2022). High credibility.

Regarding nonpharmacologic interventions for hereditary hemochromatosis, more specifically with respect to dietary modifications, EASL 2022 guidelines recommend to restrict alcohol intake during the iron depletion phase of treatment. Advise patients with iron overload and/or liver abnormalities to avoid or consume very little alcohol. Advise patients with cirrhosis to abstain from alcohol consumption.

---

### Multivitamin / multimineral supplement (Prenatal plus iron) [^115A83C8]. FDA (2016). Low credibility.

INDICATIONS

To provide Vitamin and Mineral supplementation throughout pregnancy and during the postnatal period for both the lactating and non lactating mother. It is also useful for improving nutritional status prior to conception

---

### Iron deficiency anaemia: pathophysiology, assessment, practical management [^114LTQMj]. BMJ Open Gastroenterology (2022). High credibility.

Pathophysiology

Iron is an essential element and is controlled primarily by dietary intake, intestinal absorption and iron recycling. Dietary iron can be found in two forms: haem and non-haem iron. Haem iron is easily absorbable and arises from haemoglobin (Hb) and myoglobin in the form of animal meat, poultry and fish. Non-haem iron is mostly found in plant food but is not as easily absorbable. Compounds such as phytate, oxalate, polyphenols and tannin, which are found in plants, diminish the uptake of non-haem iron, as do some drugs, such as proton pump inhibitors. Ascorbic acid, citrate and gastric acid, conversely, facilitate iron absorption. In a healthy diet, approximately 5–15 mg of elemental iron and 1–5 mg of haem iron are ingested daily although only 1–2 mg is ultimately absorbed into the intestine, predominantly in the duodenum and proximal jejunum. Please see figure 1 for details on the iron absorption pathways.

Figure 1
The two different iron absorption pathways. Non-haem absorption pathway (left): insoluble ferric iron (Fe³⁺) is reduced to absorbable ferrous iron (Fe²⁺), which is carried out by the enzyme duodenal cytochrome B (DcytB). The divalent metal transporter 1 (DMT1) imports Fe²⁺ across the apical surface and into the cell, which can then be either stored as ferritin or exported into circulation through ferroportin. Prior to exiting the enterocyte, Fe²⁺ must be oxidised back to Fe³⁺ by hephaestin or ceruloplasmin. Haem absorption pathway (right): the haem carrier protein (HCP1) transports haem iron directly into the enterocyte. Once inside the enterocyte, haem iron can either be released into plasma via the haem exporter FLVCR1 or be converted back into Fe²⁺ via the haem oxidase (HO) enzyme. The ferroportin receptor then releases Fe²⁺ into the plasma. Hepcidin, a hepatic peptide hormone, controls ferroportin, the sole iron exporter, by promoting its endocytosis. Hepcidin production and circulation are regulated by plasma iron concentration and iron stores. Hepcidin is increased in the presence of inflammation, which then promotes the degradation of ferroportin and subsequently impairs the exportation of cellular iron into plasma. Figure taken with permission from Kumar and Brookes.

---

### Dietary iron intake, body iron stores, and the risk of type 2 diabetes: a systematic review and meta-analysis [^111BGEjK]. BMC Medicine (2012). Low credibility.

Background

Excess iron has been shown to induce diabetes in animal models. However, the results from human epidemiologic studies linking body iron stores and iron intake to the risk of type 2 diabetes mellitus (T2DM) are conflicting. In this study, we aimed to systematically evaluate the available evidence for associations between iron intake, body iron stores, and the risk of T2DM.

Methods

A systematic search of the PubMed/MEDLINE and EMBASE databases to the end of 22 April 2012 was performed, and reference lists of retrieved articles were screened. Two reviewers independently evaluated the eligibility of inclusion and extracted the data. Pooled relative risks (RRs) and 95% confidence intervals (CIs) were calculated using random-effects models.

Results

We reviewed 449 potentially relevant articles, and 11 prospective studies were included in the analysis. A meta-analysis of five studies gave a pooled RR for T2DM of 1.33 (95% CI 1.19 to 1.48; P < 0.001) in individuals with the highest level of heme iron intake, compared with those with the lowest level. The pooled RR for T2DM for a daily increment of 1 mg of heme iron intake was 1.16 (1.09 to 1.23, P < 0.001). Body iron stores, as measured by ferritin, soluble transferrin receptor (sTfR) and the sTfR:ferritin ratio, were significantly associated with the risk of T2DM. The pooled RRs for T2DM in individuals with the highest versus the lowest intake of ferritin levels was 1.70 (1.27–2.27, P < 0.001) before adjustment for inflammatory markers and 1.63 (1.03–2.56, P = 0.036) after adjustment. We did not find any significant association of dietary intakes of total iron, non-heme, or supplemental iron intake with T2DM risk.

Conclusion

Higher heme iron intake and increased body iron stores were significantly associated with a greater risk of T2DM. Dietary total iron, non-heme iron, or supplemental iron intakes were not significantly associated with T2DM risk.

---

### Gestational diabetes mellitus in relation to maternal dietary heme iron and nonheme iron intake [^1124YX6s]. Diabetes Care (2011). Low credibility.

In summary, we found significant associations between dietary heme iron intake and GDM risk. Confirmation of these findings in other populations and further exploration of possible underlying biological mechanisms of observed associations are warranted. Furthermore, given emerging evidence of harmful effects for unnecessary iron supplementation, studies designed to examine ways of increasing the intake of nonheme food or supplementation of vitamins and iron should be carried out to improve the iron status of pregnant women.

---

### Modeling tool for calculating dietary iron bioavailability in iron-sufficient adults [^1171pNTo]. The American Journal of Clinical Nutrition (2017). Low credibility.

There are some limitations that should be considered when the model is used. Although the 3 data sets that were used for this study were obtained from four 7-d dietary intakes (Supplemental Table 1), the participant burden should be considered, particularly for large-scale epidemiologic studies or surveys. Data that are collected with the use of other dietary assessment methods, such as a 24-h recall or food-frequency questionnaire, may still be applied to the model, but the limitations of these intake methods should be acknowledged in the conclusions. Although we were able to exclude users of supplements that contained iron and also individuals with elevated inflammatory markers from the data sets, there was insufficient information available to assess whether any individuals were taking prescribed or over-the-counter medicines or had particular medical conditions that could have affected iron absorption or body iron status. Individuals with chronic conditions were generally excluded from participation in the studies, although the aim was to select a cohort that was representative of the population group. Furthermore, evidence for the effect of specific medical conditions and medicines on iron absorption or status has been limited, and a large proportion of the general population routinely take some form of medication; therefore, the exclusion of these individuals is not practical and would result in a very limited data set. However, it remains important to consider all of these potential issues when collecting data for the model and interpreting the results.

---

### A cohort study of dietary iron and heme iron intake and risk of colorectal cancer in women [^111ErsX2]. British Journal of Cancer (2007). Low credibility.

Computation of heme iron

Data from the FFQ were used to calculate total dietary iron intake using a database described elsewhere. The values for iron intake presented here are for dietary sources alone, because data on iron supplements were not collected. Total intake of meat iron was calculated from the reported intake of 22 meat items and two mixed dishes containing meat. Heme iron intake was computed by two methods, using different proportions for heme iron from different types of meat: 69% for beef; 39% for pork, ham, bacon, pork-based luncheon meats, and veal; 26% for chicken and fish; 21% for liver, according to, and, alternatively, using 40% as the average proportion of heme iron in all meats, according to. Results were similar for both methods, and we present data using the first approach. Total iron and heme iron intake were calorie-adjusted using the residuals method. In addition, we assessed risk in association with meat iron intake, red meat intake, and non-heme iron intake.

---

### Absolute and functional iron deficiency in the US, 2017–2020 [^113CSiSJ]. JAMA Network Open (2024). High credibility.

Iron Supplement Use and Dietary Iron Intake According to Iron Deficiency Status

eTable 5 in Supplement 1 summarizes the rates of iron supplement use among women and men with and without iron deficiency. Iron supplement use ranged from 22% (95% CI, 12%-37%) to 35% (95% CI, 29%-42%) among women with iron deficiency and from 12% (95% CI, 5%-21%) to 18% (95% CI, 8%-32%) among men with iron deficiency, depending on age. In fully adjusted models, absolute iron deficiency was associated with a nearly 3-fold higher rate of iron supplement use than iron replete status (RR, 2.91; 95% CI, 1.74–4.87; P < .001) (Table 4). There was no association between age and sex category with iron supplement use (Table 4). Estimated dietary iron intake was significantly lower among women younger than 50 years or 50 years and older compared with men younger than 50 years in fully adjusted models (Table 4). Marginal food security, but not low or very low food security, was significantly associated with lower dietary iron intake (Table 4).

Table 4.
Factors Associated With Iron Supplement Use and Dietary Iron Intake in the US, 2017–2020

Abbreviations: NA, not applicable; OR, odds ratio.

---

### American cancer society guideline for diet and physical activity for cancer prevention [^112FpNTy]. CA (2020). High credibility.

American Cancer Society diet and physical activity guideline — vegetarian and vegan dietary patterns — states that it is reasonable to suggest that vegetarian diets may be beneficial for cancer risk reduction, and many studies of vegetarians indicate a lower risk of cancer overall relative to people who also eat meat, although whether vegetarian diets confer any special benefits over diets that include smaller amounts of animal products than are typically consumed in Western diets is less clear. The available evidence supports the recommendation of a dietary pattern that consists predominantly of foods from plant sources, with limited if any intake of red and processed meats. In addition to a modest level of risk reduction for some forms of cancer relative to a more typical Western dietary pattern with higher levels of meat consumption, vegetarian dietary patterns are associated with a lower risk of cardiovascular disease and type 2 diabetes and are generally more affordable. Individuals consuming strict vegetarian diets that omit all animal products, including milk and eggs, referred to as "vegan" diets, need supplementation with vitamin B12, zinc, and iron (or foods fortified with these nutrients), especially for children and premenopausal women, and they should also aim to achieve adequate calcium intake because people consuming vegan diets with relatively low calcium content have been shown to carry a higher risk of fractures compared with people consuming vegetarian or meat-containing diets.

---

### ABM clinical protocol # 29: iron, zinc, and vitamin D supplementation during breastfeeding [^116Fz6Bz]. Breastfeeding Medicine (2018). Medium credibility.

ABM Clinical Protocol #29 — iron, zinc, and vitamin D supplementation recommendations during breastfeeding state that iron supplementation is not required for the non-anemic breastfeeding mother; iron supplementation to the 4-month-old full-term, exclusively breastfed infant is associated with improved hematologic indices, although the long-term benefit at 4–6 months is not known; if iron is provided before 6 months, it should be given as a 1 mg/kg/day distinct iron supplement until iron-fortified cereals or other iron-rich foods are initiated at 6 months of age (LOE IB). Zinc supplementation, above dietary intake, to the lactating mother or breastfeeding infant is not recommended (LOE IB). The breastfeeding infant should receive vitamin D supplementation shortly after birth in doses of 10–20 μg/day (400–800 IU/day) (LOE IB); this supplement should be cholecalciferol, vitamin D3, unless a vegetable source such as ergocalciferol vitamin D2 is desired (LOE IIA), and, when there is objection or contraindication to direct infant supplementation, vitamin D supplementation may be provided to a nursing mother, for whom a maternal dose of 160 μg/day (6,400 IU/day) is suggested.

---

### Effects of consuming an iron supplement with a meal containing animal or plant-based meat on indicators of iron status and anemia in women of reproductive age with iron deficiency: a randomized, controlled study [^112SsJL8]. The American Journal of Clinical Nutrition (2025). Medium credibility.

Background

Animal meat contains heme iron, which is more bioavailable and better absorbed than non-heme iron found in plants. Animal meat also contains a "meat factor" that stimulates absorption of non-heme iron.

Objective

To determine whether consuming an iron supplement, a source of non-heme iron, with a meal containing animal meat once a day for 8 weeks leads to improvements in iron status in females with iron deficiency compared to those consuming the same iron supplement with a meal containing plant-based meat.

Methods

In a randomized, double-blinded, parallel-arm study, non-pregnant women of reproductive age (n = 52; 24 ± 7 y; body mass index 22.9 ± 3.0 kg/m²) with low iron stores (serum ferritin < 25 μg/L) were randomized to consume an iron supplement containing 32 mg elemental iron (from ferrous sulfate) with a lunch meal containing either 4 oz. of 1) beef (Animal) or 2) Beyond Meat (Plant) once a day for 8 weeks. Meals were identical except for the addition of Animal or Plant. The primary outcomes were biochemical indicators of iron status and anemia. Data are presented as means ± standard deviation.

Results

Baseline indicators of iron status and anemia did not differ between groups. Daily consumption of an iron supplement with a lunch meal for 8 weeks improved serum ferritin (main time effect: +10.7 ± 9.6 μg/L, P < 0.0001), transferrin saturation (main time effect: +5.1 ± 18.7%, P = 0.048), soluble transferrin receptor (main time effect: -0.6 ± 1.0 mg/L, P < 0.001), body iron stores (main time effect: +2.8 ± 3.1 mg/kg, P < 0.0001), and hemoglobin (main time effect: +0.5 ± 0.9 g/dL, P = 0.0002) regardless of whether the meals contained Animal or Plant (treatment-by-time interaction: P > 0.05 for all indicators).

Conclusions

Findings suggest that the "meat factor" does not contribute substantially to improvements in iron status in women of reproductive age with iron deficiency when consumed with an iron supplement for 8 weeks.

Clinical Trial Registry

This trial was registered at clinicaltrials.gov as NCT04793906.

---

### The neglected potential of red and processed meat replacement with alternative protein sources: simulation modelling and systematic review [^113Ui35C]. EClinicalMedicine (2023). Medium credibility.

The modelling data indicate the multiple benefits of red and processed meat replacement with alternatives, however the systematic review failed to identify clear evidence of successfully implemented population-level initiatives where red and processed meat intake was replaced, which was the largest evidence gap identified. We conducted this systematic review to develop an evidence base and provide practical support for achieving population-level red and processed meat replacement. Successful strategies may have been implemented but not measured or reported in the academic literature, undermining support for future government and regional initiatives set to deliver substantial individual and planetary benefit. In the absence of evidence, research is needed on low agency strategies such as economic tools, food supply reformulation, and change to the availability of certain foods. While the modelled scenarios did not indicate a change towards sub-optimal intakes of those nutrients associated with red meat intake: protein, iron, zinc, and vitamin B6 and B12, further research is needed on saturated fat reduction strategies, as in these analyses red meat replacement was insufficient to meet dietary recommendations limiting saturated fat as a % of total dietary energy (nutrient data shown in Supplementary Material). Broader dietary changes would be required to do so. Initiatives to increase dietary fibre intakes are also needed as although all scenarios improved intakes when compared with the current diet, the population average still did not meet the current recommendations for dietary fibre intakes.

---

### Why understanding food choice is crucial to transform food systems for human and planetary health [^111iYpRW]. BMJ Global Health (2023). High credibility.

Box 1
Beef has turned into a battleground for climate and health activists. Does it need to be this way?

Demand for beef has been elevated in high-income countries for several decades. In low-income and middle-income countries, however, demand for beef has been increasing at unprecedented rates. Although there is evidence that diets high in beef may lead to NCDs, there is a considerable share of the world's population that does not receive adequate amounts of essential nutrients for proper body functioning through their diets, such as heme iron, zinc and protein. These nutrients and others are easier for the body to absorb and thus more bioavailable by consuming animal-source foods, particularly beef. How beef is produced, however, makes a difference in climate change and human health. In many cases, relatively small-scale ranches are run as 'cow-calf operations', where cattle are bred and fed on the land and then sold to feedlots, areas where hundreds of cattle are aggregated together and fed corn and/or other high-energy grains. Direct environmental impacts of the feedlot system include substantial greenhouse gas emissions, water usage and deforestation to create ample land for intensive farming of cattle feed grains. But is beef production inherently problematic? Although some argue that beef production is within acceptable limits, and can even be beneficial to the environment, many scientists assert that beef production is a serious problem given current demand. Many involved in the production of beef state that cattle have the unique ability to digest cellulose-rich plant material grown on non-arable land and convert the indigestible nutrients into meat consumable by humans. Cattle raised on pastureland (grassy areas designated for grazing) return valuable nutrients to the soil, stimulate carbon sequestration and can be integral for the germination of many deep-rooted grasses. Compared with the beef derived from their feedlot-raised cattle counterparts, beef from pasture-raised cattle contains more fatty acids and antioxidants that are known to be beneficial for human health. This system of regenerative agriculture, however, is rarely used in the commercial production of red meat and in most cases, even when regenerative agricultural methods are fully or partially employed, greenhouse gas emissions from cattle methane production is still estimated to be far greater than the potential for carbon sequestration. Currently, most beef is not produced using sustainable methods. If individual food choice were to shift to an increased demand for more nutrient dense beef in smaller quantities, a shift in agricultural practices that promote rather than harm the environment are potentially viable. This shifting of consumer expectations to higher quality beef and away from large-scale convenience consumption could potentially lead to more responsible beef production, however, this is unlikely to occur without a catalyst. As a result, beef production remains a major contributor to climate change.

---

### Dietary iron intake, body iron stores, and the risk of type 2 diabetes: a systematic review and meta-analysis [^115vg7LJ]. BMC Medicine (2012). Low credibility.

Figure 2
Associations between dietary total iron, heme iron intake and risk of type 2 diabetes mellitus (T2DM) in the included studies, comparing the highest category with the lowest. The risk estimate of dietary total iron intake for T2DM risk in the Iowa Women's Health Study (Lee et al) was not directly reported, and thus this was pooled from the results of dietary non-heme iron intake and heme iron intake in this study. M, men; W, women.

In the dose-response analyses (Figure 3), the pooled RRs of T2DM were 1.16 (1.09 to 1.23, P < 0.001) for a 1 mg/day increment of heme iron intake, with no evidence of heterogeneity (I² = 36%, P = 0.21), and 1.01 (0.99 to 1.03) for each 5 mg/day increment of dietary total iron intake, with no evidence of heterogeneity (I² = 0%, P = 0.90).

Figure 3
Dose-response analyses of dietary intakes of total iron and heme iron in relation to risk of type 2 diabetes mellitus (T2DM) in the included studies. The risk estimate of dietary total iron intake for T2DM risk in the Iowa Women's Health Study (Lee et al)) was not directly reported, and thus this was pooled from the results of dietary non-heme iron intake and heme iron intake in this study. W, women.

Sensitivity analyses using a fixed-effects model yielded similar results, and omitting one study at a time did not substantially alter the pooled results. In addition, two studies reported associations between supplemental iron intake and risk of T2DM, and one study reported an association between the sum of dietary iron intake and supplemental iron intake and risk of T2DM. However, neither of these studies found a significant association between supplemental iron or the summed iron intake and the risk of T2DM.

---

### Iron: fact sheet for health professionals… [^112zjBcn]. stage-digitalmedia.hhs.gov (2004). Low credibility.

Iron: Fact Sheet for Health Professionals Recommended intakes and sources of iron, effects of deficiency and excess, groups at risk of inadequacy, and interactions with medications. Media Type: Html.
- SourceUrl: https: //ods. od. nih. gov/api/index. aspx? resourcename = Iron&readinglevel = Health%20Professional&outputformat = HTML-SyndicationID: 16581-Language: English-Source: OfficeofDietarySupplements-DateContentAuthored: Wednesday, July28, 2004at12: 00AM. -DateContentUpdated: Thursday, February11, 2016at12: 00AM-DateSyndicationCaptured: Thursday, January26, 2017at07: 52PM-DateSyndicationUpdated: Friday, July12, 2024at01: 18AM. TagsGeneral: nutritionanemiaredbloodcellsdietarysupplementfactsheethemoglobinironFerritinmultivitaminnutrientIronDeficiencymineralhememyoglobinAudience: healthprofessionalEmbedCodeSnippetTogettheembedcodesnippetpleaseLogin.

---

### Advocacy for improving nutrition in the first 1, 000 days to support childhood development and adult health [^111BXMcQ]. Pediatrics (2018). Medium credibility.

Infant and young child nutrition counseling — Pediatricians and other child health care providers can become concerned about food sources that supply the critical nutrients necessary for brain development during particularly important times, and most pediatricians are aware that exclusive breastfeeding is the best source of nutrition for the first 6 months. As the infant's nutritional intake moves from the relative protection of breastfeeding to dependence on choices made by his or her parents, pediatrician guidance for informed food choices becomes increasingly important, and knowing which nutrients are at risk in the breastfed infant after 6 months (eg, zinc, iron, vitamin D) will guide dietary recommendations in the clinic or practice. Guidance for pediatricians is provided in existing documents but it is often without clear prescriptive recommendations; leaders in childhood nutrition can advocate for incorporating into existing nutritional advice an actionable guide to healthy eating as a positive choice rather than an avoidance of unhealthy foods, and it is important that families understand that no 1 food is alone adequate to ensure optimal neurodevelopment and health (ie, a "superfood"). Pediatricians and other child health care providers can focus the attention of existing programs on improving micro- and macronutrient offerings for infants and young children.

---

### Dietary iron intake, body iron stores, and the risk of type 2 diabetes: a systematic review and meta-analysis [^1146Cz6m]. BMC Medicine (2012). Low credibility.

Iron intake and risk of type 2 diabetes

Associations between dietary intakes of total iron, heme iron, and non-heme iron and risk of T2DM were reported in three studies, five studies and one study, respectively (Table 2). In the Iowa Women's Health Study, dietary total iron intake was largely reflective of non-heme iron intake (r = 0.995) and was not further analyzed, thus we derived the RR for association between dietary total iron intake and T2DM risk by pooling RRs of non-heme iron intake and heme iron intake in this study.

Table 2
Association between dietary and supplemental iron intakes and type 2 diabetes mellitus (T2DM) in the included studies

Abbreviations: BMI, body mass index; FH, family history of diabetes; PA, physical activity; RR, relative risk; TEI, total energy intake; WHR, waist:hip ratio.

A meta-analysis of five studies showed that higher intake of heme iron was associated with a significantly greater risk of T2DM. The pooled RR (95% CI) in individuals with the highest level of heme iron intake compared with those with the lowest levels was 1.33 (1.19 to 1.48, P < 0.001) for T2DM (Figure 2). However, no significant association was seen between dietary total iron intake and risk of T2DM; the pooled RRs and 95% CIs comparing the highest with the lowest levels of dietary total iron intake was 1.06 (0.98 to 1.14, P = 0.18) (Figure 2). There was no evidence for significant heterogeneity (heme iron intake: P = 0.24 (Q statistic), I² = 27%; dietary total iron intake: P = 0.68 (Q statistic), I² = 0%) or publication bias (heme iron intake, P = 0.08 (Egger test); dietary total iron intake, P = 0.06 (Egger test)) across the included studies (see Additional file 1, Figure S1).

---

### Anemia in infants and children: evaluation and treatment [^112emJzc]. American Family Physician (2024). High credibility.

Regarding specific circumstances for iron deficiency anemia, more specifically with respect to pediatric patients, AAFP 2024 guidelines recommend to offer iron-rich foods in infants and children with iron deficiency without anemia. Offer oral iron supplementation of 2–6 mg/kg/day of elemental iron given 1–3 times daily for 3–6 months for the treatment of iron deficiency with anemia.

---

### A path FORWARD: development of a comprehensive multidisciplinary clinic to create health and wellness for the child and adolescent with a fontan circulation [^111eCAoh]. Pediatric Cardiology (2022). Medium credibility.

Nutrition and Dietary Tips and Pearls of Wisdom

There is no special "Fontan diet". For the majority of our patients, we recommend a diet to optimize cardiovascular health that includes fruits, vegetables, whole grains, low-fat dairy, and lean protein sources in addition to limiting food sources of added sugars, sodium, and saturated/trans fats and including food sources of fiber, unsaturated fat, and omega 3 fatty acids. This dietary pattern is no different than what is recommended in the USDA's dietary guidelines.
For cyanotic individuals, maintaining sufficient iron stores to optimize hemoglobin production is important. Iron supplementation is often recommended if hemoglobin levels appear relatively low in proportion to oxygen saturation, or if laboratory data support low iron stores.
For patients with PLE, medical therapy is of primary importance, and diet alone does not treat the condition. Nevertheless, in some cases we also recommend a very low-fat (< 10% of calories, 20–30 g fat), high protein (> 2 g/kg) diet with the addition of MCT oil for extra calories and essential fatty acid supplementation. It is important to note that this low-fat diet should only be used during acute PLE flares and not long term as we have seen patients struggle to gain weight when following a low-fat diet for a prolonged period of time.

Exercise and Activity

---

### Micronutrient status in phenylketonuria [^115cxMhr]. Molecular Genetics and Metabolism (2013). Low credibility.

Patients with phenylketonuria (PKU) encompass an 'at risk' group for micronutrient imbalances. Optimal nutrient status is challenging particularly when a substantial proportion of nutrient intake is from non-natural sources. In PKU patients following dietary treatment, supplementation with micronutrients is a necessity and vitamins and minerals should either be added to supplement phenylalanine-free l-amino acids or given separately. In this literature review of papers published since 1990, the prevalence of vitamin and mineral deficiency is described, with reference to age of treatment commencement, type of treatment, dietary compliance, and dietary practices. Biological micronutrient inadequacies have been mainly reported for zinc, selenium, iron, vitamin B12 and folate. The aetiology of these results and possible clinical and biological implications are discussed. In PKU there is not a simple relationship between the dietary intake and nutritional status, and there are many independent and interrelated complex factors that should be considered other than quantitative nutritional intake.

---

### Vegan diet and nutritional status in infants, children and adolescents: a position paper based on a systematic search by the ESPGHAN nutrition committee [^112s6oEH]. Journal of Pediatric Gastroenterology and Nutrition (2025). Medium credibility.

Vegan and other plant-based diets are becoming increasingly popular in the paediatric age group. There is limited evidence in the current medical literature to determine whether a vegan diet is adequate for children, since the currently available society position papers are based on narrative reviews and expert opinion. Updated evidence-based recommendations are needed to guide clinical practice. This position paper presents findings from a literature review performed using a systematic search strategy, following the Preferred Reporting Items for Systematic Reviews and Meta-Analysis guidelines. We analyzed the current evidence on the effect of vegan diet compared to omnivorous diet on body growth, nutritional adequacy and laboratory biomarkers in infants, children and adolescents. Observational studies, cohort studies and clinical trials published over the last 15 years in MEDLINE/PubMed, EMBASE and Cochrane Library were retrieved. Our position paper aims to update the evidence for or against the adequacy of a vegan diet in infants, children and adolescents and to provide evidence-based recommendations. A total of 10 articles were accepted and included in the final review, providing information on approximately 1500 children following a vegan diet. Several articles assessed more than one outcome: seven addressed body growth, five evaluated nutritional adequacy and five examined laboratory biomarkers. To complement the primary data, three systematic reviews and meta-analyses were also included. Current evidence is inconclusive to determine whether a strictly vegan diet supports normal childhood growth, although no significant differences in height or body mass index z-scores were observed compared to omnivorous peers. We recommend that dietary intake, growth and nutritional status should be regularly monitored in vegan children. Focusing on dietary intakes (e.g., protein, omega-3, calcium and iron) and ensuring supplementation with specific micronutrients, including vitamin B12, is essential during paediatric age when following a strict vegan diet. Clinical research, well-designed prospective studies and high-quality trials are required to address current research gaps.

---

### Perspective: putting the youngest among us into the nutrition "call for action" for food fortification strategies [^114u5m5k]. The American Journal of Clinical Nutrition (2021). Medium credibility.

For breastfed infants not receiving fortified products, achieving adequate iron intake after 6 mo of age is challenging. Human milk contains relatively little iron (∼0.35 mg/L). Absorption of iron from human milk is variable, but even if 100% is absorbed, iron intake from 600 mL human milk would be only ∼0.2 mg/d. As a result, nearly 100% of the recommended intake of 11 mg/d needs to come from sources other than human milk, i.e. complementary foods. Because breastfed infants have high iron needs but consume small amounts of complementary foods (∼200–300 kcal/d), the iron density of those foods (mg Fe/100 kcal) needs to be very high — 9 times higher than required for adult men.

In many populations, iron intake from typical complementary foods is far below the amount needed. Even with "best case scenario family food menus", the iron density of the hypothetical infant diet among low-income households in Guatemala or India would be far below the target. Linear programming analyses have demonstrated that iron requirements for infants could be met without fortified foods, but only if liver were consumed daily. With more realistic (but not necessarily affordable) diverse dietary patterns that include grains, legumes, egg, green leafy vegetables, and fish or chicken, only 26%–37% of iron needs at 6–8 mo and 35%–52% of iron needs at 9–12 mo could be met. In the second year of life, inadequate iron intake is still prevalent, but with careful selection of foods it is somewhat easier to meet iron needs than is the case at 6–12 mo.

---

### Global estimation of dietary micronutrient inadequacies: a modelling analysis [^114uTrfm]. The Lancet: Global Health (2024). High credibility.

We further specified country-specific average requirements for zinc and iron on the basis of dietary factors that inhibit or enhance their absorption (appendix pp 10–11). First, phytate inhibits zinc and iron absorption, which means that average requirements for zinc and iron increase with higher phytate intakes. Second, the consumption of non-dairy animal-source foods enhances iron absorption, which means that average requirements for iron decrease with higher intakes of such foods. Although calcium absorption is also affected by dietary factors such as phytate, oxalate, and dairy intakes, we were unable to account for these effects given an absence of data on global oxalate intakes — the dominant factor affecting calcium absorption.

We derived country-specific average requirements for zinc on the basis of average country-level estimates of phytate intake from Wessels and Brown(appendix p 12) by linearly interpolating between the lowest average requirement and lowest phytate intake and the highest average requirement and highest phytate intake within each age–sex group (appendix p 10). We derived country-specific average requirements for iron accounting for the joint effects of phytate and non-dairy animal-source foods on iron absorption using a procedure similar to that of Beal and colleagues. First, we scaled the country-level phytate intakes (appendix p 12) between 0 and 1, where 0 indicates low iron absorption (high phytate intake) and 1 indicates high iron absorption (low phytate intake). Then, we scaled country-level estimates of non-dairy animal-source food intakes (ie, the sum of seafood, processed meat, unprocessed red meat, and egg intakes; unprocessed poultry meat is excluded because it is not available in the GDD; appendix pp 2, 13) from the GDD between 0 and 1, where 0 indicates low iron absorption (low non-dairy animal-source food intake) and 1 indicates high absorption (high non-dairy animal-source food intake). Next, we averaged these two indicators to create a single absorption index, in which lower values indicate lower absorption and higher values indicate higher absorption, and scaled these averages between 5% and 16% absorption, the range of real-world iron absorption values(appendix p 14). Finally, we derived the absorption-specific average requirements by linearly interpolating between the average requirements specified by Allen and colleagues(appendix p 11).

---

### AGA clinical practice update on management of iron deficiency anemia: expert review [^1127wX1w]. Clinical Gastroenterology and Hepatology (2024). High credibility.

Oral iron supplementation — product selection, adverse effects, and absorption strategies: Many formulations are available without substantial evidence that any one product is better than another, and ferrous salts (ferrous sulfate, ferrous fumarate, and ferrous gluconate) are a reasonable low-cost starting choice. Side effects are common, with a meta-analysis reporting constipation in 12%, diarrhea in 8%, and nausea in 11%. Serum hepcidin rises after oral dosing and remains increased for up to 48 hours; early data suggest every-other-day dosing appears to improve tolerance but needs better study before implementation. Absorption can be enhanced by taking iron with 80 mg ascorbic acid on an empty stomach, though evidence supporting vitamin C to improve absorption is mixed and needs further clarification. Tea and coffee are powerful inhibitors and should not be consumed within an hour after taking iron. Although absorption is better on an empty stomach, some patients will better tolerate iron with meals; if feasible, taking iron with meat protein will improve absorption, and using 500 mg vitamin C will allow absorption even if calcium or fiber is present in the meal.

---

### FIGO good practice recommendations on anemia in pregnancy, to reduce the incidence and impact of postpartum hemorrhage (PPH) [^111Lmd8S]. International Journal of Gynaecology and Obstetrics (2025). Medium credibility.

6 IRON DEFICIENCY ANEMIA

6.1 Iron requirements and absorption in pregnancy

Iron deficiency is the most common cause of anemia in pregnancy, being responsible for 50% of all cases of anemia in pregnant women worldwide. Owing to an increase in maternal red blood cell mass, placental and fetal growth, and blood loss at birth, iron requirements increase 10‐fold during pregnancy, with total requirements approximating 1200 mg. This translates to an average daily demand for iron in pregnancy of approximately 4.4 mg. Daily requirements increase from 0.8 mg/day in the first trimester to 4–5 mg/day in the second trimester and furthermore to 7.5 mg/day in the third trimester, reaching up to 10 mg/day in the last 6–8 weeks of pregnancy. Iron demands are provided by two major dietary sources, namely heme iron and non‐heme iron. Heme iron is ferrous iron (Fe²⁺) contained in animal food sources such as meat, fish, and poultry, while non‐heme iron is ferric iron (Fe³⁺) present in plant foods. Iron is absorbed in the ferrous form, whereas ferric iron needs to first be broken down to the ferrous form before absorption. Thus, the rate of absorption of heme iron (15%–35%) is higher than the absorption of non‐heme iron (1%–15%). A typical diet provides 15 mg of elemental iron per day, of which only approximately 10% is absorbed. The rate of absorption increases up to 30% during pregnancy, providing up to 5 mg of elemental iron per day. Gastric acid, vitamin C, retinol, and carotenes enhance iron absorption, while phytates in cereals, calcium, antacids, tannins in tea and coffee, soy protein, milk, egg, and red wine taken together with iron containing food, inhibit its absorption.

---

### Characteristics that modify the effect of small-quantity lipid-based nutrient supplementation on child growth: an individual participant data meta-analysis of randomized controlled trials [^1122YMAT]. The American Journal of Clinical Nutrition (2021). Medium credibility.

To our knowledge, SQ-LNS is the only nutrition intervention for children that has been documented in meta-analyses to have positive effects not only on child growth, but also on iron deficiency and anemia, child development, and child mortality. SQ-LNSs can fill key nutrient gaps and reduce the cost of a nutritionally adequate diet, thereby potentially mitigating the adverse impact of rising food insecurity on vulnerable children. Although SQ-LNS is not a substitute for a diverse diet that includes healthy foods from each of the major food groups, it can play a protective role when access to certain foods (e.g. animal-source foods) is limited owing to cost or other circumstances. A critical next step that we plan to undertake is a set of formal cost-effectiveness and cost:benefit analyses that take into account the multiple outcomes that may be influenced by SQ-LNSs, similar to the recent cost:benefit analyses of MNPs. Also needed are additional rigorously designed evaluations of large-scale programs that include SQ-LNSs, particularly in low- and middle-income countries that are considering scaling up this intervention.