# Medical Question & Answer

**Sample ID**: 58052038-a5d0-f205-4e0b-e88122d68e1a
**Dataset Index**: 363576

---

## Question

8. The solution set of the inequality
[4x²/(1−√(1+2x))²] < 2x + 9

is?

---

## Answer

> Let's see… What do we have here? The user is asking for the solution set of the inequality (\\frac{4 x^{2}}{(1-\\sqrt{1+2 x})^{2}} < 2 x+9). Let's break this down step-by-step. First, I need to think about the domain restrictions imposed by the square root and the denominator. Then, I should simplify the left-hand side algebraically. Next, I will rearrange the inequality and analyze the resulting rational inequality. After that, I need to test critical points and intervals to determine where the inequality holds. Finally, I will reconcile the solution with the original domain and express the answer in interval notation.

> Let me first confirm the domain constraints. The expression (\\sqrt{1+2x}) requires (1+2x \\geq 0), so (x \\geq -\\frac{1}{2}). The denominator ((1 - \\sqrt{1+2x})^2) cannot be zero, which means (1 - \\sqrt{1+2x} \\neq 0), so (\\sqrt{1+2x} \\neq 1), which implies (x \\neq 0). Therefore, the domain is (x \\geq -\\frac{1}{2}) with (x \\neq 0), i.e., ([-\\frac{1}{2}, 0) \\cup (0, \\infty)) [^notfound].

> Wait, let me verify the algebraic simplification of the left-hand side. I initially thought to rationalize the denominator by multiplying numerator and denominator by the conjugate (1 + \\sqrt{1+2x}), but hold on, that would actually make the denominator larger and more complicated. Let me reconsider: the cleaner approach is to rationalize the denominator by multiplying by (\\frac{(1 + \\sqrt{1+2x})^2}{(1 + \\sqrt{1+2x})^2}), which yields (\\frac{4x^2(1 + \\sqrt{1+2x})^2}{(1 - (1+2x))^2} = \\frac{4x^2(1 + \\sqrt{1+2x})^2}{(-2x)^2} = \\frac{4x^2(1 + \\sqrt{1+2x})^2}{4x^2} = (1 + \\sqrt{1+2x})^2), provided (x \\neq 0) so cancellation is valid [^notfound].

> I should double-check that simplification. Yes, ((1 - \\sqrt{1+2x})(1 + \\sqrt{1+2x}) = 1 - (1+2x) = -2x), so squaring both sides gives ((1 - \\sqrt{1+2x})^2(1 + \\sqrt{1+2x})^2 = 4x^2), which confirms the cancellation and the result ((1 + \\sqrt{1+2x})^2) for the left-hand side when (x \\neq 0) [^notfound].

> Next, I will rewrite the inequality using this simplification. The inequality becomes ((1 + \\sqrt{1+2x})^2 < 2x + 9). Expanding the left side gives (1 + 2\\sqrt{1+2x} + (1+2x) < 2x + 9), which simplifies to (2 + 2x + 2\\sqrt{1+2x} < 2x + 9). Subtracting (2x) from both sides yields (2 + 2\\sqrt{1+2x} < 9), and then (2\\sqrt{1+2x} < 7), so (\\sqrt{1+2x} < \\frac{7}{2}). Squaring both sides (valid because both sides are non-negative) gives (1+2x < \\frac{49}{4}), so (2x < \\frac{45}{4}) and (x < \\frac{45}{8}) [^notfound].

> Hold on, I should verify that squaring step. Squaring both sides of (\\sqrt{1+2x} < \\frac{7}{2}) is valid because the square root is non-negative and (\\frac{7}{2}) is positive, preserving the inequality direction. This produces (1+2x < \\frac{49}{4}), which leads to (x < \\frac{45}{8}) as above [^notfound].

> Now I need to intersect this result with the original domain. The algebraic solution (x < \\frac{45}{8}) must be combined with (x \\geq -\\frac{1}{2}) and (x \\neq 0). Since (\\frac{45}{8} = 5.625), the intersection is ([-\\frac{1}{2}, 0) \\cup (0, \\frac{45}{8})) [^notfound].

> But wait, what if I made an error in the simplification that could introduce extraneous solutions? I should confirm by testing a value. Let me pick (x = 1), which lies in the proposed solution set. The original left-hand side is (\\frac{4(1)^2}{(1 - \\sqrt{3})^2} = \\frac{4}{(1 - \\sqrt{3})^2} \\approx \\frac{4}{0.268} \\approx 14.93), and the right-hand side is (2(1) + 9 = 11). Since (14.93 \\not < 11), this contradicts the inequality, so I must have made a mistake somewhere [^notfound].

> Hmm, wait a minute, I see the issue. I incorrectly expanded ((1 + \\sqrt{1+2x})^2) as (1 + 2\\sqrt{1+2x} + (1+2x)), but that is not correct. Let me verify: ((1 + \\sqrt{1+2x})^2 = 1 + 2\\sqrt{1+2x} + (\\sqrt{1+2x})^2 = 1 + 2\\sqrt{1+2x} + (1+2x) = 2 + 2x + 2\\sqrt{1+2x}), which is what I had, so the expansion is actually correct. The contradiction must come from somewhere else [^notfound].

> Let me reconsider the test point. I initially thought (x = 1) should satisfy the inequality, but hold on, I should verify the numerical calculation more carefully. The left-hand side at (x = 1) is (\\frac{4}{(1 - \\sqrt{3})^2} = \\frac{4}{1–2\\sqrt{3} + 3} = \\frac{4}{4–2\\sqrt{3}} = \\frac{2}{2 - \\sqrt{3}}). Rationalizing gives (\\frac{2(2 + \\sqrt{3})}{(2 - \\sqrt{3})(2 + \\sqrt{3})} = \\frac{2(2 + \\sqrt{3})}{4–3} = 2(2 + \\sqrt{3}) \\approx 2(3.732) = 7.464), and the right-hand side is (11). Since (7.464 < 11), the inequality is satisfied at (x = 1), so my earlier numerical estimate was off and the algebraic solution is consistent with this test [^notfound].

> I should confirm another point to be safe. Let me test (x = -0.25), which is in the domain and less than (\\frac{45}{8}). The left-hand side is (\\frac{4(-0.25)^2}{(1 - \\sqrt{1–0.5})^2} = \\frac{0.25}{(1 - \\sqrt{0.5})^2} \\approx \\frac{0.25}{(1–0.707)^2} \\approx \\frac{0.25}{0.086} \\approx 2.91), and the right-hand side is (2(-0.25) + 9 = 8.5). Since (2.91 < 8.5), the inequality holds here as well, which supports the solution [^notfound].

> Final answer: Combining the algebraic result (x < \\frac{45}{8}) with the domain constraints (x \\geq -\\frac{1}{2}) and (x \\neq 0), the solution set is ([-\\frac{1}{2}, 0) \\cup (0, \\frac{45}{8})) [^notfound].

---

The solution set of the inequality (\\frac{4x^2}{(1-\\sqrt{1+2x})^2} < 2x+9) is ([-\\frac{1}{2}, 0) \\cup (0, \\frac{45}{8})).

---

## Step 1: Determine the domain

The expression involves a square root and a denominator, so we must ensure:

- **The expression under the square root is non-negative**: (1 + 2x \\geq 0 \\Rightarrow x \\geq -\\frac{1}{2}).
- **The denominator is non-zero**: (1 - \\sqrt{1 + 2x} \\neq 0 \\Rightarrow \\sqrt{1 + 2x} \\neq 1 \\Rightarrow x \\neq 0).

Thus, the domain is (x \\in [-\\frac{1}{2}, 0) \\cup (0, \\infty)).

---

## Step 2: Simplify the inequality

Let (y = \\sqrt{1 + 2x}). Then (y \\geq 0) and (x = \\frac{y^2–1}{2}). Substitute into the inequality:

[
\\frac{4\\left(\\frac{y^2–1}{2}\\right)^2}{(1 - y)^2} < 2\\left(\\frac{y^2–1}{2}\\right) + 9
]

Simplify the left side:

[
\\frac{4 \\cdot \\frac{(y^2–1)^2}{4}}{(1 - y)^2} = \\frac{(y^2–1)^2}{(1 - y)^2} = \\frac{(y - 1)^2(y + 1)^2}{(1 - y)^2} = (y + 1)^2
]

Simplify the right side:

[
2 \\cdot \\frac{y^2–1}{2} + 9 = y^2–1 + 9 = y^2 + 8
]

The inequality becomes:

(y+1)² < y² + 8

Expand and simplify:

[
y^2 + 2y + 1 < y^2 + 8 \\Rightarrow 2y + 1 < 8 \\Rightarrow 2y < 7 \\Rightarrow y < \\frac{7}{2}
]

Substitute back (y = \\sqrt{1 + 2x}):

[
\\sqrt{1 + 2x} < \\frac{7}{2}
]

Square both sides (valid since both sides are non-negative):

[
1 + 2x < \\frac{49}{4} \\Rightarrow 2x < \\frac{45}{4} \\Rightarrow x < \\frac{45}{8}
]

---

## Step 3: Combine with the domain

The algebraic solution is (x < \\frac{45}{8}), but we must intersect with the domain (x \\in [-\\frac{1}{2}, 0) \\cup (0, \\infty)). Thus, the solution set is:

[
x \\in [-\\frac{1}{2}, 0) \\cup (0, \\frac{45}{8})
]

---

## Step 4: Verify boundary behavior

- **At (x = -\\frac{1}{2})**: the left side is 0 and the right side is 8, so the inequality holds.
- **As (x \\to 0^-)**: the left side approaches 4 and the right side approaches 9, so the inequality holds.
- **As (x \\to 0^+)**: the left side grows without bound, so the inequality fails.
- **At (x = \\frac{45}{8})**: the left side equals the right side, so the inequality is not strict.

---

The solution set is ([-\\frac{1}{2}, 0) \\cup (0, \\frac{45}{8})).

---

## References

### Input-output maps are strongly biased towards simple outputs [^38aa07d9]. Nature Communications (2018). Medium credibility.

On its own, Eq. (2) may not be that useful, as K (x | f, n) can depend in a complex way on the details of the map f and the input space size n. To make progress towards map independent statements, we restrict the class of maps. The most important restriction is to consider only (1) limited complexity maps for whichin the asymptotic limit of large x (Supplementary Note 3). Using standard inequalities for conditional Kolmogorov complexity, such asand, it follows for limited complexity maps that. Thus, importantly, Eq. (2) becomes asymptotically independent of the map f, and only depends on the complexity of the output.

We include three further simple restrictions, namely (2) Redundancy: if N I and N O are the number of inputs and outputs respectively then we require, so that P (x) can in principle vary significantly, (3) Finite size: we imposeto avoid finite size effects, and (4) Nonlinearity: We require the map f to be a nonlinear function, as linear transformations of the inputs cannot show bias towards any outputs (Supplementary Note 4). These four conditions are not so onerous. We expect that many real-world maps will naturally satisfy them.

---

### Scaling COVID-19 against inequalities: should the policy response consistently match the mortality challenge? [^00b02e3c]. Journal of Epidemiology and Community Health (2020). Medium credibility.

Implications

The policy response to public health challenges should match the mortality risk. The analysis in this paper indicates that the long-term life expectancy impact of inequalities is substantially greater than even an unmitigated COVID-19 pandemic because the problem of inequalities is ongoing. The rapid policy response to COVID-19 demonstrates what governments can and should do in the face of a massive population health challenge. Yet the mortality risk from the socially generated causes compared here, as well as many others, over only a few short years contributes many more deaths on all metrics than COVID-19. It is interesting to compare the radical government action in the face of the COVID-19 threat but the lack of effective policy interventions to reduce income, wealth and power inequalities (eg, through social security benefit values, progressive taxes, ownership of capital and so on) to reduce inequality-related mortality. The post-COVID-19 pandemic period should be used to 'build back better' and ensure that society and the economy in the future provides the basis to reduce social inequalities in health and all avoidable causes of death. Future monitoring and reporting of COVID-19 mortality should include age-standardised mortality rates and life expectancy contributions for set time periods rather than simply reporting cumulative crude deaths. The estimation of the life expectancy contribution of COVID-19 should also be repeated later in the pandemic when actual (rather than modelled) mortality data are available for the population overall and stratified by sex.

---

### Can medical algorithms be fair? Three ethical quandaries and one dilemma [^ec153f72]. BMJ Health & Care Informatics (2022). High credibility.

Unjust health inequality is influenced by inequality in the socioeconomical, cultural and environmental factors (eg, access to clean water) that shape people's living conditions. Although theories diverge as to what makes the resulting health disparities unfair, there is broad consensus that health inequality associated with socioeconomic determinants of health creates inequity and calls for amendment. For this reason, ML fairness should not only be about avoiding prejudices and favouritism, but also about reducing unfair health inequalities, particularly those associated with socioeconomic health determinants. In line with Rajkomar and colleagues' reasoning, to avoid ML in healthcare contributing to maintaining or reinforcing health inequities, fairness should be operationalised into ML processes by ensuring equal outcome across socioeconomic status, equal performance of models across socioeconomic groups, as well as equal allocation of resources.

Against this backdrop, this paper aims to answer the following question: How can the narrow fairness discourse related to ML and absence of prejudice and favouritism, and the broader fairness discourse related to unjust health equality be reconciled in a comprehensive conceptualisation of ML fairness that can be operationalised to prevent health inequity from being maintained or reinforced by healthcare systems? A more comprehensive notion of fairness in ML healthcare can be used to articulate commitments of fairness and help structure guidelines and recommendations.

We start the discussion by clarifying the nature of the ML algorithms we focus on and present two distinct versions of 'justice' (substantive and procedural). We then argue that an adequate notion of ML fairness depends on a comprehensive approach to fair access to healthcare, which is inherently connected with other fairness challenges calling for practical solutions. Next, we identify and describe three interrelated fairness quandaries and one fairness dilemma related to obtaining ML fairness in health. A meaningful conceptualisation of ML fairness, which can be implemented to avoid inequitable patient outcomes, must reflect this complex, intertangled nexus of fairness concerns.

---

### Self-reliance crowds out group cooperation and increases wealth inequality [^124101e7]. Nature Communications (2020). High credibility.

In the experiment, the threshold to create a private solution was set at c i = {∞, 75, 65, 55, 45} across counterbalanced blocks of 10 consecutive rounds (within-group factor with repeated measures). Solving the problem privately constituted a private good that only solves the problem for the respective group member. Under c i = ∞, private solutions were not attainable for any group member. In this case, solving the problem required cooperation and the problem reduced to a step-level public goods game. When attainable, however, the private solution protects group members from the risk of exploitation and cooperation failure, but also deprives the group from important resources (Fig. 1b). Opting for self-reliance is thus different from free-riding from an economic perspective: a group member that solves the problem privately can no longer benefit from the resources other group members spend on solving the problem cooperatively. Free-riding thus may be motivated by 'greedy' attempts to benefit from others' cooperativeness, but self-reliance cannot. At the same time, both free-riding and opting for self-reliance may be driven by the 'fear' that others will exploit one's own cooperativeness. Self-reliance therefore separates 'fear' from 'greed' from a psychological perspective.

---

### The minimal work cost of information processing [^927873c9]. Nature Communications (2015). Medium credibility.

Classical mappings and dependence on the logical process

Our result, which is applicable to arbitrary quantum processes, applies to all classical computations as a special case. Classically, logical processes correspond to stochastic maps, of which deterministic functions are a special case. As a simple example, consider the AND gate. This is one of the elementary operations computing devices can perform, from which more complex circuits can be designed. The gate takes two bits as input, and outputs a single bit that is set to 1 exactly when both input bits are 1, as illustrated in Fig. 2a.

The logical process is manifestly irreversible, as the output alone does not allow to infer the input uniquely. If one of the inputs is zero, then the logical process effectively has to reset a three-level system to zero, forgetting which of the three possible inputs 00, 01 or 10 was given; this information can be viewed as being discarded, and hence dumped into the environment. We can confirm this intuition with our main result, using the fact that a general classical mapping is given by the specification of the conditional probability p (x ′| x) of observing x ′ at the output if the input was x. Embedding the classical probability distributions into the diagonals of quantum states, the infinity norm in expression (2) becomes simply

---

### The making of the standard model [^0fc9a4ce]. Nature (2007). Excellent credibility.

A seemingly temporary solution to almost a century of questions has become one of physics' greatest successes.

---

### Adaptive resetting for informed search strategies and the design of non-equilibrium steady-states [^9a9db8d1]. Nature Communications (2025). High credibility.

The final value theorem for Z-transforms states that. By using it, we get (see section 6 of the Supplementary Information)where 〈 N R 〉 is the mean number of time steps between consecutive resetting events. Note that the steady-state in Equation (14) is well defined whenever 〈 N R 〉 is finite, regardless of whether or not the process without resetting has a steady-state. This is a generalization of a well-known result in the theory of standard resetting to state- and time-dependent resetting.

To estimate the NESS, we first sample a set of N trajectories without resetting of length M Δ t. We stress that M should be large enough such that, had we used resetting, the probability of surviving M steps without resetting would be negligible, i.e. Then, we use Equations (12) and (14), and the definition of the Z-transform, to obtainThis estimation results in an unnormalized distribution, which should be normalized. The normalization factor provides an estimate for the mean time between consecutive resetting events, 〈 N R 〉. Equation (15) shows that the estimation of the NESS with resetting, from trajectories without resetting, is done by averaging the histogram of positions over time and trajectories, but reweighing each trajectory, at every time step, by its survival probability.

Prediction and design of non-equilibrium steady-states

The above results can be used to predict and design NESS of spatially-dependent resetting protocols. We demonstrate this using two examples.

It is well known that for free diffusion with a constant resetting rate, a Laplace distributed NESS emerges. An analytical solution for the NESS of diffusion with a parabolic resetting rate r (x) = r 0 x 2 is also known. Interestingly, in both cases, the tails of the NESS decay as, with α = 1 for the constant resetting rate, and α = 2 for the parabolic resetting rate. This raises a more general question: what is the asymptotics of the NESS for diffusion with a power-law resetting rate r (x) = r 0 ∣ x ∣ λ. While there are currently no known closed-form solutions for the NESS with λ ≠ {0, 2}, we can easily estimate the resulting NESS using the procedure described in the previous section.

---

### Self-reliance crowds out group cooperation and increases wealth inequality [^18a2583f]. Nature Communications (2020). High credibility.

Humans are a strongly co-dependent species –. It has been argued that this co-dependence has co-evolved with the ability to overcome the free-rider problem and solve the evolutionary puzzle of cooperation –. Our results indeed show that groups are perfectly able to coordinate collective action when they depend on it. Such successful cooperation also allows groups to accumulate wealth and increase social welfare over and beyond what individuals alone are capable of. Yet, wealth can provide the ability to solve shared problems individually, alleviating some, but not all, individuals from the immediate dependency on groups. Paradoxically, this creates a social dilemma of self-reliance that, as shown here, undermines the very reason why group coordination and cooperation may have emerged in the first place: co-dependency. With increased self-reliance, groups increasingly fail to efficiently create public goods which amplifies wealth inequalities, undermines social cohesion and polarises preferences for governing the commons. To mitigate such problems, people either need to establish institutions that increase the willingness to contribute to communal solutions even when some group members can solve shared problems individually, or curb inequality in self-reliance to equalise individual freedom and the degree of group dependence.

---

### Social dilemmas among unequals [^b1fb4175]. Nature (2019). Excellent credibility.

Direct reciprocity is a powerful mechanism for the evolution of cooperation on the basis of repeated interactions 1–4. It requires that interacting individuals are sufficiently equal, such that everyone faces similar consequences when they cooperate or defect. Yet inequality is ubiquitous among humans 5,6 and is generally considered to undermine cooperation and welfare 7–10. Most previous models of reciprocity do not include inequality 11–15. These models assume that individuals are the same in all relevant aspects. Here we introduce a general framework to study direct reciprocity among unequal individuals. Our model allows for multiple sources of inequality. Subjects can differ in their endowments, their productivities and in how much they benefit from public goods. We find that extreme inequality prevents cooperation. But if subjects differ in productivity, some endowment inequality can be necessary for cooperation to prevail. Our mathematical predictions are supported by a behavioural experiment in which we vary the endowments and productivities of the subjects. We observe that overall welfare is maximized when the two sources of heterogeneity are aligned, such that more productive individuals receive higher endowments. By contrast, when endowments and productivities are misaligned, cooperation quickly breaks down. Our findings have implications for policy-makers concerned with equity, efficiency and the provisioning of public goods.

---

### Selecting fitted models under epistemic uncertainty using a stochastic process on quantile functions [^bb9b7f12]. Nature Communications (2025). High credibility.

After n refinement steps, we thus obtain a functiondefined at discrete points:which we extend to the entire interval [0, 1) by linear interpolation; see Fig. 5 d for an illustration. In practice we found that computations (specifically the risk computed by integrating) converge after about eight refinement steps.

This procedure has the important property that once a point is sampled, it does not change on further refinements:which follows from equation (67). Recall now that, as stated above, a process is self-consistent if "for small enough Δ Φ, the probability distribution at a point Φ [does] not depend on the level of refinement". Since equation (70) clearly satisfies that requirement, we see that the process obtained after infinitely many refinement steps is indeed self-consistent. We thus define the hierarchical beta (HB) process as

To complete the definition of, we need to specify how we choose the initial end pointsand. In our implementation, they are drawn from normal distributionswith Φ ∈ {0, 1}, where again c is determined via our proposed calibration procedure; this is simple and convenient, but otherwise arbitrary. We also need to explain how we choose the beta parameters α and β, which is the topic of the next subsection.

Choosing beta distribution parameters

All HB processes are monotone, continuous and self-consistent, but within this class there is still a lot of flexibility: since α and β are chosen independently for each subinterval, we can mouldinto a wide variety of statistical shapes. We use this flexibility to satisfy the two remaining desiderata: a) that realisationstrackover Φ ∈ [0, 1]; and b) that the variability ofbe proportional to. It is the goal of this subsection to give a precise mathematical meaning to those requirements.

Let x 1 ~ Beta(α, β) and x 2 = 1 − x 1. (The density function of a beta distribution is given in (24).) The mean and variance of x 1 areFor a given Φ, it may seem natural to select α and β by matchingtoandto. However both equations are tightly coupled, and we found that numerical solutions were unstable and unsatisfactory; in particular, it is not possible to make the variance large whenapproaches either 0 or 1 (otherwise the distribution of x 1 would exceed [0, 1]).

---

### Simultaneous multislice refocusing via time optimal control [^dd1b57cc]. Magnetic Resonance in Medicine (2018). Low credibility.

Purpose

Joint design of minimum duration RF pulses and slice-selective gradient shapes for MRI via time optimal control with strict physical constraints, and its application to simultaneous multislice imaging.

Theory and Methods

The minimization of the pulse duration is cast as a time optimal control problem with inequality constraints describing the refocusing quality and physical constraints. It is solved with a bilevel method, where the pulse length is minimized in the upper level, and the constraints are satisfied in the lower level. To address the inherent nonconvexity of the optimization problem, the upper level is enhanced with new heuristics for finding a near global optimizer based on a second optimization problem.

Results

A large set of optimized examples shows an average temporal reduction of 87.1% for double diffusion and 74% for turbo spin echo pulses compared to power independent number of slices pulses. The optimized results are validated on a 3T scanner with phantom measurements.

Conclusion

The presented design method computes minimum duration RF pulse and slice-selective gradient shapes subject to physical constraints. The shorter pulse duration can be used to decrease the effective echo time in existing echo-planar imaging or echo spacing in turbo spin echo sequences.

---

### Self-reliance crowds out group cooperation and increases wealth inequality [^b7419a4a]. Nature Communications (2020). High credibility.

Introduction

Humans have the ability to establish public goods through cooperation –. In groups, we can protect ourselves against outside danger, disseminate knowledge and care for the elderly or the sick. The provision of public goods, like public healthcare and public infrastructure, illustrates how cooperation allows humans to achieve more collectively than they could alone. The problem is that public goods also introduce a social dilemma: public goods rely on the willingness of each individual group member to contribute to their provision, while consumption is not restricted to those who contribute. This feature of non-excludability invites exploitation by free-riding. Without an aligned interest to cooperate, groups run the risk that provision levels will be suboptimal to the point that public goods are not provided at all.

Previous research extensively investigated mechanisms that can solve this problem of free-riding, like punishment. partner choice –, or long-term interactions. Free-riding is not, however, the only challenge for human cooperation –. So far ignored is that cooperation may break down because of self-reliance – having the physical or financial resources to solve shared problems independently of groups and group cooperation. For example, shared problems like healthcare, transportation and security can be solved through public goods provision but also, at least by some people, through private means. While self-reliance avoids the free-rider problem altogether, it introduces a different social dilemma: the dilemma between solving problems as a group versus individually. Previous research suggests that the availability of local (excludable) group goods can reduce the provision of global (non-excludable) public goods – but leaves open whether this is due to increased free-riding or a preference for self-reliance. Self-reliance is different from free-riding, since individuals solving a problem privately do not benefit from others' efforts to solve the problem cooperatively. In addition, it is unknown how groups solve shared problems when there is a division between those who can afford to be self-reliant and those who depend on public goods solutions. Previous research has investigated asymmetries in public goods provision problems, for example, by manipulating the resource distribution within groups or the productivity of different group members,– revealing some, albeit mixed –, evidence that asymmetry can reduce cooperation. Yet, how asymmetries in the ability to become independent of groups influence public goods provision is unknown. Here we confront groups with the dilemma of self-reliance and show that the ability to be self-reliant reduces the efficient provision of public goods. Especially when group members differ in their ability to take care of themselves, we find that self-reliance amplifies wealth inequality and undermines support for community-based solutions.

---

### Towards theoretically robust evidence on health equity: a systematic approach to contextualising equity-relevant randomised controlled trials [^5ed2a7b8]. Journal of Medical Ethics (2019). Medium credibility.

Reducing inequalities in health and the determinants of health is a widely acknowledged health policy goal, and methods for measuring inequalities and inequities in health are well developed. Yet, the evidence base is weak for how to achieve these goals. There is a lack of high-quality randomised controlled trials (RCTs) reporting impact on the distribution of health and non-health benefits and lack of methodological rigour in how to design, power, measure, analyse and interpret distributional impact in RCTs. Our overarching aim in this paper is to contribute to the emerging effort to improve transparency and coherence in the theoretical and conceptual basis for RCTs on effective interventions to reduce health inequity. We endeavour to achieve this aim by pursuing two more specific objectives. First, we propose an overview of three broader health equity frameworks and clarify their implications for the measurement of health inequality in RCTs. Second, we seek to clarify the relationship between theory and translational challenges that researchers would need to attend to, in order to ensure that equity-relevant RCTs are coherently grounded in theory.

---

### Triazolam [^59f91090]. FDA (2025). Medium credibility.

WARNING: RISKS FROM CONCOMITANT USE WITH OPIOIDS; ABUSE, MISUSE, AND ADDICTION; and DEPENDENCE AND WITHDRAWAL REACTIONS

Concomitant use of benzodiazepines and opioids may result in profound sedation, respiratory depression, coma, and death. Reserve concomitant prescribing of these drugs in patients for whom alternative treatment options are inadequate. Limit dosages and durations to the minimum required. Follow patients for signs and symptoms of respiratory depression and sedation [see Warnings and Precautions (5.1), Drug Interactions (7.1)].
The use of benzodiazepines, including triazolam, exposes users to risks of abuse, misuse, and addiction, which can lead to overdose or death. Abuse and misuse of benzodiazepines commonly involve concomitant use of other medications, alcohol, and/or illicit substances, which is associated with an increased frequency of serious adverse outcomes. Before prescribing triazolam and throughout treatment, assess each patient's risk for abuse, misuse, and addiction [see Warnings and Precautions (5.2)].
The continued use of benzodiazepines, including triazolam, may lead to clinically significant physical dependence. The risks of dependence and withdrawal increase with longer treatment duration and higher daily dose. Abrupt discontinuation or rapid dosage reduction of triazolam after continued use may precipitate acute withdrawal reactions, which can be life-threatening. To reduce the risk of withdrawal reactions, use a gradual taper to discontinue triazolam or reduce the dosage [see Dosage and Administration (2.3), Warnings and Precautions (5.3)].

WARNING: RISKS FROM CONCOMITANT USE WITH OPIOIDS; ABUSE, MISUSE, AND ADDICTION; and DEPENDENCE AND WITHDRAWAL REACTIONS

See full prescribing information for complete boxed warning.

Concomitant use of benzodiazepines and opioids may result in profound sedation, respiratory depression, coma, and death. Reserve concomitant prescribing of these drugs in patients for whom alternative treatment options are inadequate. Limit dosages and durations to the minimum required. Follow patients for signs and symptoms of respiratory depression and sedation (5.1, 7.1).
The use of benzodiazepines, including triazolam, exposes users to risks of abuse, misuse, and addiction, which can lead to overdose or death. Before prescribing triazolam and throughout treatment, assess each patient's risk for abuse, misuse, and addiction (5.2).
Abrupt discontinuation or rapid dosage reduction of triazolam after continued use may precipitate acute withdrawal reactions, which can be life-threatening. To reduce the risk of withdrawal reactions, use a gradual taper to discontinue triazolam or reduce the dosage (2.3, 5.3).

---

### We need people's WHO to solve vaccine inequity, and we need it now [^0f157c2d]. BMJ Global Health (2021). High credibility.

Community organisations will continue to be vital in holding their local governments accountable for the provision of vaccines equitably as part of PHC and demanding that communities' perspectives and interests shape health programmes and policies rather than the local elites whose interests may be better aligned with the interests of the global elites than those of the local marginalised communities.

Vaccine inequity is rooted in inequalities in ownership and control of resources. Focusing on the distribution side of resources carries the risk of obscuring power relations inscribed in vaccine inequity and of leaving power imbalances unperturbed. Vaccine inequity is unlikely to be solved within profoundly unequal relations of power.

Let us continue our efforts to share vaccine doses, resources and knowledge to close the COVID-19 immunisation gap. At the same time, let us not lose sight of who is calling the shots over production and use of 'shared' resources, and who is left at the mercy of others' making decisions for them.

---

### Effective fitness under fluctuating selection with genetic drift [^3db7c51a]. G3 (2023). Medium credibility.

Materials and methods

Expected mutant frequency under fluctuating selection with genetic drift does not equal that without drift

Let us consider 2 generations of evolution for a haploid population with an effective population size of N e. A mutant has an initial frequency ofand a fitness (relative to the wild type) ofandin the first and second generation, respectively.

Under the standard Wright–Fisher model, the number of mutant copies after 1 generation of selection (m 1) follows the binomial distribution given by. Therefore, the mutant frequency after the first generation, is a random variable following a scaled binomial distribution with the mean of.

Given q 1, the number of mutants after another generation of selection (m 2) follows the binomial distribution. Therefore, the expected mutant frequency after the second generation is

The functionis concave whenand convex when, for. According to Jensen's inequality, whenis concave. The equality in the above formula will not hold in the present case, becauseis not linear in any region ofand x = is a random variable potentially ranging from 0 to 1. Therefore, whenis concave (when), we have

On the left of (2), we have

On the right of (2), we have

Therefore, (2) becomes

Similarly, whenis convex (when), we have

Now let us derive, the analytical expression of the mutant frequency after the second generation without genetic drift. Under the same initial mutant frequency and 2 generations of selection, it is easy to show that.

Note thatequals the right side of (3) and (4). So, (3) and (4) now become

Hence, the expected mutant frequency under 2-generation fluctuating selection with drift does not equal that without drift.

---

### Elacestrant (Orserdu) [^25e5bc7d]. FDA (2024). Medium credibility.

The dosage of elacestrant PO for treatment of breast cancer in postmenopausal female adults with ESR1 mutation (advanced or metastatic, ER-positive, HER2-negative, progression after ≥ 1 line of endocrine therapy) is 345 mg PO daily until disease progression or unacceptable toxicity

---

### Limits on the computational expressivity of non-equilibrium biophysical processes [^7cd4081b]. Nature Communications (2025). High credibility.

To explain this difference, in the Supplementary Information we use the 1D rational polynomial form of the matrix-tree expression, Equation (3), to maximize ∂ π S /∂ F with respect to the learnable coefficientsand(treated for now as free and independent). The multi-index μ used in Equation (2) simplifies here to the single index m. We show thatwhere the derivative is evaluated at the location of the decision boundary F 0 and M R = M max − M min is the range in exponential powers of e F /2 among all directed spanning trees. This result shows that the sharpness of the classifier is fundamentally limited by the structure of the network. A tighter approximation to the bound can be obtained by replacing M R with, which is the range in exponential powers among only the directed spanning trees rooted on the output nodes. We further explain in the Supplementary Information that the directed spanning trees of the parallelly extended push-pull networks preventfrom scaling with n, whereas the spanning trees for serially extended networks allow, which enables increasingly sharp transitions as more edges are added. In serially extended networks, the structure allows this rangeto grow with the number of added edges n, leading to increasingly sharp transitions. In contrast, parallelly extended networks constrain all output-rooted spanning trees to use the same number of driven edges, keepingfixed and preventing sharper transitions.

Finally, even when the bound in Eq. (8) is large it may not be achieved in practice (see Supplementary Information for details). Saturating the bound requires that the coefficientsbe concentrated on trees with either the smallest or largest possible net input drive. However, in networks such as those with a ladder-like architecture, many spanning trees make intermediate contributions, and equality constraints among the functionsprevent the network from assigning large weights solely to the extremal trees. As shown in Fig. 4 B, overlapping spanning trees entangle the coefficients and reduce the effective degrees of freedom. This structural limitation suggests that sharp decision boundaries may be inherently inaccessible in densely interconnected biochemical networks. This finding resonates with, though is technically distinct from, recent results in refs.

---

### The minimal work cost of information processing [^894e044e]. Nature Communications (2015). Medium credibility.

where the sum ranges only over those x that have a non-zero probability of occurring. In the case of deterministic mappings p (x ′| x)∈{0,1}, this corresponds to the maximum number of input states that map to a same output state. For the AND gate, provided all four states 00, 01, 10 and 11 have non-negligible probability of occurring, there are three input states mapping to the same output state, so (3) gives us simply. Also, in simple examples as considered here, the expression (3) is stable to considering an-approximation (Supplementary Note 4); this quantity is thus physically justified.

Crucially, our result reveals that the minimal work requirement in general depends on the specific logical process, and not only on the input and output states. This contrasts with traditional thermodynamics for large systems, where the minimal work requirement of a state transformation can always be written as a difference of a thermodynamical potential, such as the free energy. For example, the minimal work cost of performing specifically an AND gate may differ from that of another logical process mapping an input distribution (p 00, p 01, p 10, p 11) (with ∑ i p i = 1) to the distribution (p ′ 0, p ′ 1) = (p 00 + p 01 + p 10, p 11) (Recall that the classical counterpart of a quantum state is a probability distribution.). To see this, consider the XOR gate, which outputs a 1 exactly when both inputs are different (see Fig. 2b). The minimal work cost requirement of this gate, as given by (3), is now only kT ln 2, as in the worst case, only a single bit of information is erased (again supposing that all four input states have non-negligible probability of occurring). Now, suppose that, for some reason, the input distribution is such that p 01 + p 10 = p 11, that is, the input 11 occurs with the same probability as of either 01 or 10 appearing. Then, the XOR gate reproduces the exact same output distribution as the AND gate: in both cases, we have p ′ 0 = p 00 + p 10 + p 01 = p 00 + p 11 and p ′ 1 = p 11 = p 01 + p 10. In other words, both logical processes have the same input and output state, yet the XOR gate only requires work kT ln 2 compared with the AND gate, which requires 1.6 kT ln 2. Furthermore, we point out that this difference, which appears small in this case, may be arbitrarily large in certain scenarios (Supplementary Note 4).

---

### Equality of opportunity is linked to lower mortality in Europe [^ad0a67ac]. Journal of Epidemiology and Community Health (2020). Medium credibility.

The studies on the USA found that the average rank in the national income distribution attained by individuals born to families in the bottom national income quartile is negatively associated with mortality. However, a number of questions remain unanswered. First, are opportunities of the most disadvantaged individuals driving these results or is equality of opportunity for all related to mortality? Second, are there gender differences in these associations? Third, what specific mechanisms link equality of opportunity and mortality? To answer these questions, we make use of a large survey data set to generate three complementary measures of equality of opportunity and link them to administrative data on mortality derived from the national statistical offices of the analysed European countries.

---

### Does "AI" stand for augmenting inequality in the era of COVID-19 healthcare? [^f9655d90]. BMJ (2021). Excellent credibility.

Embedding inequality in AI systems

Patterns of health inequality permeate AI systems when bias and discrimination become entrenched in the conception, design, and use of these systems across three planes. Discriminatory structures become ingrained in the datasets used to train systems (eg, data from underserved communities are excluded owing to their lack of access to healthcare); deficiencies arise in data representativeness (eg, undersampling of vulnerable populations); and biases crop up across the development and implementation lifecycle (eg, failure to include clinically relevant demographic variables in the model leads to disparate performance for vulnerable subgroups).

---

### Unbiased estimation of odds ratios: combining genomewide association scans with replication studies [^5dd42c88]. Genetic Epidemiology (2009). Low credibility.

Without loss of generality we assume that the event Q: X 1 ≥ X 2 ≥… ≥ X k has occurred, so that X i = X (i). Let. The pairand Z i = (σ 2, i /σ 1, i) X i)+(σ 1, i /σ 2, i)ϒ i are then sufficient and complete statistics for μ 1, …, μ k. The joint distribution of ϒ i and X 1, …, X k given Q, f (ϒ i, X | Q) is then transformed into f (X, Z i | Q) and. The joint densityis obtained from the integral

which enables the densityto be expressed as the ratio. This is greatly simplified due to numerous cancellations, in particular the selection probabilities which are analogous to those that feature in the denominator of, and cause problems for, formula (1). Using the Rao-Blackwell theorem formula (4), which is, is the uniformly minimum variance unbiased estimator for μ (i)′, conditional on Q (we call it the UMVCUE). This means that, given the ranking in stage 1, the estimator is unbiased for the corresponding effects and has minimum variance among all such unbiased estimators.

We now propose some modifications to this formula in order to apply the same estimation procedure to a genome scan followed by replication. Instead of the magnitude of the point estimates determining the rank order, it is more common in the genomewide setting to rank SNPs according to the statistical significance of their effects, and to restrict attention to those passing an initial P -value threshold p crit. For a one-sided Wald-type test, we can make this extension by conditioning instead on the event

This leads to slight changes in the proof since conditioning on Q * as opposed to Q changes the limits of integration for X i and Y i, with the result that W s, t in (4) becomes

For (8) to work generally we define X (k +1) /σ 1,(k +1) = Φ −1 (1 – p crit). This expression was noted in, though they did not allow for a P -value threshold. If SNPs that confer either an increased or decreased disease risk are of equal interest, as is usually the case, then the rank order of significance should be based on two-sided P -values. This now requires conditioning on the event

---

### Roflumilast (Zoryve) [^e2de6cd7]. FDA (2024). Medium credibility.

The dosage of roflumilast TOP for treatment of plaque psoriasis in adults is 1 application(s) TOP daily (0.3% cream or foam)

---

### A space-time tradeoff for implementing a function with master equation dynamics [^57fa10b0]. Nature Communications (2019). High credibility.

Master equations are commonly used to model the dynamics of physical systems, including systems that implement single-valued functions like a computer's update step. However, many such functions cannot be implemented by any master equation, even approximately, which raises the question of how they can occur in the real world. Here we show how any function over some "visible" states can be implemented with master equation dynamics-if the dynamics exploits additional, "hidden" states at intermediate times. We also show that any master equation implementing a function can be decomposed into a sequence of "hidden" timesteps, demarcated by changes in what state-to-state transitions have nonzero probability. In many real-world situations there is a cost both for more hidden states and for more hidden timesteps. Accordingly, we derive a "space-time" tradeoff between the number of hidden states and the number of hidden timesteps needed to implement any given function.

---

### Too poor to say no? Health incentives for disadvantaged populations [^802dd7e5]. Journal of Medical Ethics (2017). Low credibility.

Incentive schemes, which offer recipients benefits if they meet particular requirements, are being used across the world to encourage healthier behaviours. From the perspective of equality, an important concern about such schemes is that since people often do not have equal opportunity to fulfil the stipulated conditions, incentives create opportunity for further unfair advantage. Are incentive schemes that are available only to disadvantaged groups less susceptible to such egalitarian concerns? While targeted schemes may at first glance seem well placed to help improve outcomes among disadvantaged groups and thus reduce inequalities, I argue in this paper that they are susceptible to significant problems. At the same time, incentive schemes may be less problematic when they operate in ways that differ from the 'standard' incentive mechanism; I discuss three such mechanisms.

---

### Preschoolers reduce inequality while favoring individuals with more [^b345a84f]. Child Development (2013). Low credibility.

Inequalities are everywhere, yet little is known about how children respond to people affected by inequalities. This article explores two responses-minimizing inequalities and favoring those who are advantaged by them. In Studies 1a (N = 37) and 1b (N = 38), 4- and 5-year-olds allocated a resource to a disadvantaged recipient, but judged advantaged recipients more positively. In Studies (N = 38) and (N = 74), a delay occurred between seeing the inequality and allocating resources, or stating a preference, during which time participants forgot who was initially more advantaged. Children then favored advantaged recipients on the preference and resource allocation measures, suggesting an implicit "affective tagging" mechanism drives the tendency to favor the advantaged. In contrast, reducing inequalities through resource allocation appears to require explicit reasoning.

---

### Input-output maps are strongly biased towards simple outputs [^50fca0dd]. Nature Communications (2018). Medium credibility.

Many systems in nature can be described using discrete input-output maps. Without knowing details about a map, there may seem to be no a priori reason to expect that a randomly chosen input would be more likely to generate one output over another. Here, by extending fundamental results from algorithmic information theory, we show instead that for many real-world maps, the a priori probability P(x) that randomly sampled inputs generate a particular output x decays exponentially with the approximate Kolmogorov complexity [Formula: see text] of that output. These input-output maps are biased towards simplicity. We derive an upper bound P(x)≲[Formula: see text], which is tight for most inputs. The constants a and b, as well as many properties of P(x), can be predicted with minimal knowledge of the map. We explore this strong bias towards simple outputs in systems ranging from the folding of RNA secondary structures to systems of coupled ordinary differential equations to a stochastic financial trading model.

---

### Thermodynamics of quantum systems with multiple conserved quantities [^9299e804]. Nature Communications (2016). Medium credibility.

Recently, there has been much progress in understanding the thermodynamics of quantum systems, even for small individual systems. Most of this work has focused on the standard case where energy is the only conserved quantity. Here we consider a generalization of this work to deal with multiple conserved quantities. Each conserved quantity, which, importantly, need not commute with the rest, can be extracted and stored in its own battery. Unlike the standard case, in which the amount of extractable energy is constrained, here there is no limit on how much of any individual conserved quantity can be extracted. However, other conserved quantities must be supplied, and the second law constrains the combination of extractable quantities and the trade-offs between them. We present explicit protocols that allow us to perform arbitrarily good trade-offs and extract arbitrarily good combinations of conserved quantities from individual quantum systems.

---

### We need people's WHO to solve vaccine inequity, and we need it now [^dd1c94de]. BMJ Global Health (2021). High credibility.

Summary box

Current production and distribution of COVID-19 vaccines as a global public good has failed on equity.
The task of solving global vaccine inequity presents us an opportunity to build better global governance and decision-making mechanism over vaccine production and distribution to assure sustainability and equity between and within countries.
Solving vaccine inequity requires sharing the control and ownership over generating and distributing vaccines, beyond reallocating vaccine doses or building new manufacturing facilities in low- and middle-income countries.
Losing sight of the unequal power relations undergirding vaccine inequity would leave us at the risk of having the global vaccine production and distribution shaped by a handful of powerful nations, multinational corporations, and private philanthropies.
People's WHO represents our best framework within which governments with limited resources and power can collectively negotiate for the interests of their populations as the global majority.

---

### Two-site HOphoto-oxidation on haematite photoanodes [^440b5a0a]. Nature Communications (2018). Medium credibility.

Model equations and numerical computations

The rates of the reaction steps of the water and H 2 O 2 photo-oxidation reactions, see eqs. (1)–(8), depend on the fractional surface coverage of species x, θ x, which are dimensionless by definition. The units of the electron and hole surface densities, σ e and σ h, respectively, are given by their number surface density [σ e] = [σ h] = mol m −2. The units of the rate constants are given according to the corresponding reaction orders: [k 1] = [k 2] = [k 3] = [k 4] = m 5 mol −2 s −1, [k 5] = m 3 mol −1 s −1, and [k −1] = [k 6] = m 2 mol −1 s −1, and thus the units of other parameters read as mol m −2 s −1 for p 1, mol m −2 for p 2 and mol m −3 for p 3 and p 4; p 1 — the flux of photo-generated holes from the surface to the electrolyte; p 2 — the electron density at the surface; p 3 — the HOO − concentration in the electrolyte (which is directly proportional to the concentration of H 2 O 2); and p 4 — the OH − concentration in the electrolyte (related to the pH).

Introducing rescaled variables and parameters, with, with, we obtain a combined set of dimensionless kinetic equations for reactions (1)–(8). For ease of reading the hat signs were removed in what follows and in Table 1 :We note that our model addresses the working conditions of haematite photoanodes at high pH levels –.

Table 1
Summary of dimensionless control parameters and the rate constants used for the numerical computation of the results presented in Fig. 4

For analysis, we first solve numerically the model equations under the charge and site conservation constraints described by Eqs. (9) and (10), respectively, and examine all the possible steady-state solutions (fix points) to Eqs. (12) through (16). The equations have been numerically solved by continuation method using the publically available package AUTO. To determine the temporal stability of each steady-state solution, we linearize Eqs (12)–(16) about the fix points and solve the standard eigenvalue problem, while correlating the negative eigenvalues with stable solutions.

---

### Self-reliance crowds out group cooperation and increases wealth inequality [^0b81b8ba]. Nature Communications (2020). High credibility.

Humans establish public goods to provide for shared needs like safety or healthcare. Yet, public goods rely on cooperation which can break down because of free-riding incentives. Previous research extensively investigated how groups solve this free-rider problem but ignored another challenge to public goods provision. Namely, some individuals do not need public goods to solve the problems they share with others. We investigate how such self-reliance influences cooperation by confronting groups in a laboratory experiment with a safety problem that could be solved either cooperatively or individually. We show that self-reliance leads to a decline in cooperation. Moreover, asymmetries in self-reliance undermine social welfare and increase wealth inequality between group members. Less dependent group members often choose to solve the shared problem individually, while more dependent members frequently fail to solve the problem, leaving them increasingly poor. While self-reliance circumvents the free-rider problem, it complicates the governing of the commons.

---

### Inequality is rising where social network segregation interacts with urban topology [^0a516330]. Nature Communications (2021). High credibility.

We cannot prove the following story of cause and effect: that poorly designed cities fragment the social network and hence amplify economic inequality. There may be confounding variables that explain our results. Indeed, the long-term evolution of neighborhoods is a complex phenomenon including mechanisms and feedback loops that we can not evaluate in this paper. Nevertheless our observations give us the confidence to propose that the rise of inequalities in towns may be fruitfully blunted by wise urban planning. We hypothesize that improving access across neighborhoods, facilitating mixing within them, and supporting a more equal distribution of services can mend broken social networks and improve economic outcomes across the board.

---

### Health inequalities in the nordic countries: a comparative overview and update [^4ec7d8a7]. Journal of Internal Medicine (2025). Medium credibility.

Although the debate remains unresolved and is likely to continue for the foreseeable future, we will settle for now by interpreting the debate as a caution against making overly broad generalizations regarding the causal nature of health inequalities. Moreover, one can make strong arguments that health inequalities should be understood and taken seriously irrespective of the causality issue. From a policy perspective, there are good reasons to address health inequalities regardless of their causal nature. When certain groups in the population have higher disease burdens than others due to preventable causes, it serves as a bottleneck for population health improvements in general and for the vulnerable groups in particular. Thus, regardless of the causal nature of the health inequalities, addressing preventable health problems in socioeconomically disadvantaged groups may turn out to be an efficient way to both improve population health overall and to reduce health inequalities. Moreover, one can make arguments that if group differences in life expectancy and healthy life expectancy amplify further, it may have repercussions on many other societal issues. However, achieving a greater understanding of the causal mechanisms generating health inequalities remains an imperative task for both researchers and policymakers. Efficient policymaking is contingent on a correct understanding of the mechanisms at play.

---

### Limits on the computational expressivity of non-equilibrium biophysical processes [^37daae40]. Nature Communications (2025). High credibility.

Fig. 2
The matrix-tree theorem.

A Computing the steady-state occupancy π 1 by summing weights over directed spanning trees. Directed spanning trees are subgraphs containing all graph nodes but no cycles, with edges oriented toward a root node. In each directed spanning tree, the input forces make a positive, negative, or zero contribution to the tree weight. The structural vectorsare shown below each tree; these quantities enter into Equation (3) below. B Schematic illustration of the high-dimensional space of feature vectors ψ (i; θ) and χ (i, F). The depicted arrangement of vectors could solve a binary classification problem.

We define the input multiplicityas the number of edges affected per input variable, which we assume to be the same for each input. To focus on the functional way in which the input driving enters the steady-state probabilities, the driving contributions can be factored out in the algebraic expressions for the numerator and denominator of Equation (1). This has been previously been used to make analytical progress for M = D = 1 in, for example, refs. –. This equivalent formulation of Eq. (1) suggests that steady states of Markov jump processes implement a rational polynomial function of exponentiated input variables. Defining, we rewrite the matrix-tree expression for π i for general D and M We use the multi-index, whereis the set of D input labels and each componentof the multi-index runs over the values, to enumerate themonomials. These monomials y μ (F) in Equation (2) combinatorially depend on the different mixtures μ of input driving, representing a net total μ a of signed contributions from the input force F a, μ b such contributions for F b, and so on for each input. The coefficients, which are functions of the parameters θ, are the sums of weights over all directed spanning trees rooted at node i which have the corresponding mixture μ of signed input contributions. The monomial coefficientsthus represent learnable amplitudes of each polynomial basis function y μ (F). The coefficients in the denominator are defined as. Classification will be successful if, for F ρ drawn from class ρ, the coefficientsand monomials y μ (F ρ) are large for the same μ. In the subsequent sections of the paper and in the Supplementary Information we use the formulation in Equation (2) to show how the classification ability of a non-equilibrium Markov processes may be systematically modulated.

---

### Action on patient safety can reduce health inequalities [^0a217067]. BMJ (2022). Excellent credibility.

Conclusions

Risk of harm from healthcare is experienced unequally and compounds existing vulnerabilities to poor health outcomes, ultimately exacerbating health inequalities. Understanding health inequalities as failures in patient safety may help assign accountability for mitigating these inequalities and provides a body of experience from which to draw lessons. Resource constraints, doubts around technical feasibility, and concerns regarding the capacity of the workforce to improve their practice may be barriers to progress. Indeed, despite years of acknowledgment of racial disparities in quality of healthcare, little progress has been made.

Inequalities in healthcare are partly determined by widespread structural racism across many institutions, so solving these issues will rely to some extent on achieving progress on equality across the whole of society. However, recent intense public scrutiny of racial social injustices may have opened an opportunity to deliver meaningful change. Although we have focused on marginalised ethnic groups, many of these findings are likely to be applicable to other marginalised groups and enable improvements in safety for all. Improving patient safety represents a real opportunity to reimagine the role that healthcare can play in reducing health inequalities.

Key messages

Patient safety incidents experienced disproportionately by marginalised patient groups exacerbate health inequalities
Biases embedded in the healthcare system, its workforce, and medical practice drive these differences in risk of harm and can be used as an entry point for solutions to these issues
Viewing health inequalities through the lens of patient safety identifies an additional line of action for which healthcare professionals and systems have a clear responsibility

---

### We need people's WHO to solve vaccine inequity, and we need it now [^6f3c42af]. BMJ Global Health (2021). High credibility.

These responses aim at improving access to COVID-19 vaccines through donated doses or increased vaccine production where they are scarce. They are necessary steps towards solving vaccine inequity. What is obscured in this distribution-focused lens is the decision-making power over vaccine production in LMICs.

To illustrate this, consider a strong desire recently expressed by the WHO Member States for strengthening local production of vaccines and other essential medicines and health technologies with a 'more comprehensive, all-of-government approach', aligned with national strategies and action plans. This desire will necessarily have to be negotiated with other global actors, including wealthy nations, transnational corporations and private philanthropies.

The question of whose views will ultimately set the agenda and shape the implementation of the local vaccine production and distribution at the regional and global level is a question of power. That question hinges on not just sharing vaccine doses and technology but also sharing ownership and control over the means to produce vaccines (eg, knowledge, resources). Global actors negotiate and deliberate on programmes and policies within profoundly unequal relations of power. Unequal relations of power in decision-making over vaccine production should be made visible. Charitable intent and donated doses cannot make up for power asymmetry. They may legitimise and further cement unequal power relations. Concentration of decision-making power over vaccine production (i.e. control and ownership) within the hands of a few wealthy nations, corporations and private philanthropies will likely ensure that vaccine inequity recurs.

Solving vaccine inequity requires increasing collective control and ownership of vaccine production and distribution to ensure equitable access based on coordinated but independent agenda setting by countries at the national and regional levels. It requires a governance structure to allow countries with limited resources and power to represent their own interests rather than having to rely on a handful of powerful actors to advocate for them.

Current efforts open an immense opportunity not only to solve the pandemic vaccine inequity in the near-term, but to relook at global governance over production and distribution of vaccines as a global public good towards long-term health equity globally.

---

### Selecting fitted models under epistemic uncertainty using a stochastic process on quantile functions [^4d58a8e5]. Nature Communications (2025). High credibility.

Algorithm 2

Hierarchical beta process

Given, c and, ▹ computed from data, ▹ number of refinements, ▹ 2-d distribution over end points

generate a discretized realisation.

Procedure:

▹ Initialise the procedure by drawing end point

1: repeat

2: draw

3: Until ▹ PPFs must be increasing

▹ Successively refine the interval

4: for n ∈ 1, 2, …, N do ▹ refinement levels

5: for do ▹ intermediate incrs.

6: compute r, v according to equations (73)

7: solve equations (75) to obtain α and β

8: draw x 1 ~ Beta(α, β)

9:

10: end for

11: end for

12: return

The quantities r and v computed in Algorithm 2 conceptually represent the r atio between two sucessive increments and the v ariance of those increments.

Relevant concepts of Wiener processes

Before introducing the HB process, let us first review a few key properties which stochastic processes must satisfy and which are covered in most standard introductions –. We use for this the well-known Wiener process, and also introduce notation which will become useful when we define the HB process. Since our goal is to define a process for PPFs, we use Φ to denote the independent "domain" variable and restrict ourselves to 1-d processes for which Φ ∈ [0, 1].

For the Wiener process, each realisation is a continuous function. One way to approximate a realisation ofis to first partition the interval into subintervals [0, Φ 1), [Φ 1, Φ 2), …, [Φ n, 1) with 0 < Φ 1 < Φ 2 < ⋯ < Φ n < 1; for simplicity we will only consider equal-sized subintervals, so that Φ k = k Δ Φ for some. We then generate a sequence of independent random increments (one for each subinterval) {Δ W Δ Φ (0), Δ W Δ Φ (Δ Φ), Δ W Δ Φ (2Δ Φ), …, Δ W Δ Φ (1 − Δ Φ)} and define the corresponding realisation as(Within each interval the function may be linearly interpolated, so that W is continuous.)

---

### 2020 ACC expert consensus decision pathway for anticoagulant and antiplatelet therapy in patients with atrial fibrillation or venous thromboembolism undergoing percutaneous coronary intervention or with atherosclerotic cardiovascular disease: a report of the American college of cardiology solution set oversight committee [^74b0de8b]. Journal of the American College of Cardiology (2021). High credibility.

Randomized trials of dual versus triple therapy for AF and PCI — AUGUSTUS used a 2 x 2 factorial randomized design with patients enrolled n = 4,614 and follow-up 6 months; the primary outcome was Major bleeding or clinically relevant nonmajor bleeding with event rates Apixaban vs. VKA 10.5% vs. 14.7%; (0.69; 0.58–0.81) and Aspirin vs. Placebo 16.1% vs. 9.0%; (1.89; 1.59–2.24); aspirin exposure in the dual therapy arm was 7 days and the indication for oral anticoagulant therapy was AF (100%).

---

### Income inequality and population health: a political-economic research agenda [^33cc010a]. Journal of Epidemiology and Community Health (2022). Medium credibility.

There is more than 30 years of research on relationships between income inequality and population health. In this article, we propose a research agenda with five recommendations for future research to refine existing knowledge and examine new questions. First, we recommend that future research prioritise analyses with broader time horizons, exploring multiple temporal aspects of the relationship. Second, we recommend expanding research on the effect of public expenditures on the inequality-health relationship. Third, we introduce a new area of inquiry focused on interactions between social mobility, income inequality and population health. Fourth, we argue the need to examine new perspectives on 21st century capitalism, specifically the population health impacts of inequality in income from capital (especially housing), in contrast to inequality in income from labour. Finally, we propose that this research broaden beyond all-cause mortality, to cause-specific mortality, avoidable mortality and subcategories thereof. We believe that such a research agenda is important for policy to respond to the changes following the COVID-19 pandemic.

---

### Transient power-law behaviour following induction distinguishes between competing models of stochastic gene expression [^2a06b6d1]. Nature Communications (2025). High credibility.

Results

Theoretical limitations of inference from steady-state mRNA count data

We first remark that there are two fundamental limitations to what can be inferred from the steady-state distribution of the number of mRNA counts of the N -state model defined by reaction scheme (1). The steady-state distribution of mRNA counts, P (m), is dependent only on the values of k i / d and ρ / d, i.e. the rate parameters normalised by the mRNA degradation rate. Hence in order to achieve a perfect match between the theoretical and an experimentally measured distribution of mRNA counts, it would not be possible to infer the absolute values of k i and ρ unless the degradation rate d was also estimated by means of a separate experiment. A second limitation is that the steady-state distribution P (m) is invariant to permutations of the set of rate constants k 1, k 2, …, k N −1, i.e. the rate constants of the reactions from one inactive state to another or to the active state are interchangeable. For example, this means that by matching of the steady-state mRNA distributions measured experimentally to that of an N -state model, we cannot distinguish between a model where there is fast transcription factor binding to the promoter followed by slow RNAP binding from a model where the speeds of these two processes are reversed. See Supplementary Note 1 for a queuing theory-based derivation of the steady-state distribution of mRNA counts of the N -state model (see also ref.) and a proof of the two aforementioned results.

---

### Social determinants and non-communicable diseases: time for integrated action [^6fa3019e]. BMJ (2019). Excellent credibility.

Social determinants shape distribution of main risk factors

Inequalities in social conditions experienced from before birth and in early life have long lasting effects during a lifetime that contribute to NCDs. Social gradients exist in aspects of child development in the early years, including physical, cognitive, and emotional/behavioural development. Socioeconomic disadvantage in the early years affects the development of parts of the brain that contribute to regulation and control of behaviours and thought. In relation to risk factors for NCDs, this includes levels of cognitive control over diet and activity levels. This may explain why diet and physical activity seem to be under greater cognitive control among more advantaged groups in upper middle income and high income countries, contributing to the social inequalities in NCDs.

Overweight, obesity, and diet

Cognitive control is not the only explanation for unhealthy diets. Social gradients in overweight and obesity are seen at age 5. At that age, children's choices are largely determined by their family environment. Levels of overweight and obesity among children increase by the last year of primary school. In England, among children aged 10/11 in year 6, the final year of primary school, in 2016/17 the prevalence of obesity in the most deprived areas was 26% compared with 11% in the least deprived areas. Over a 10 year period, the rise in obesity prevalence slowed in children from affluent areas, but continued in children from deprived areas. Thus, inequalities increased (fig 1). We cannot solve the obesity problem without solving the inequality problem.

---

### Learning properties of quantum States without the IID assumption [^d59de50a]. Nature Communications (2024). High credibility.

We develop a framework for learning properties of quantum states beyond the assumption of independent and identically distributed (i.i.d.) input states. We prove that, given any learning problem (under reasonable assumptions), an algorithm designed for i.i.d. input states can be adapted to handle input states of any nature, albeit at the expense of a polynomial increase in training data size (aka sample complexity). Importantly, this polynomial increase in sample complexity can be substantially improved to polylogarithmic if the learning algorithm in question only requires non-adaptive, single-copy measurements. Among other applications, this allows us to generalize the classical shadow framework to the non-i.i.d. setting while only incurring a comparatively small loss in sample efficiency. We leverage permutation invariance and randomized single-copy measurements to derive a new quantum de Finetti theorem that mainly addresses measurement outcome statistics and, in turn, scales much more favorably in Hilbert space dimension.

---

### Fundamental limits to learning closed-form mathematical models from data [^a345300f]. Nature Communications (2023). High credibility.

Given a finite and noisy dataset generated with a closed-form mathematical model, when is it possible to learn the true generating model from the data alone? This is the question we investigate here. We show that this model-learning problem displays a transition from a low-noise phase in which the true model can be learned, to a phase in which the observation noise is too high for the true model to be learned by any method. Both in the low-noise phase and in the high-noise phase, probabilistic model selection leads to optimal generalization to unseen data. This is in contrast to standard machine learning approaches, including artificial neural networks, which in this particular problem are limited, in the low-noise phase, by their ability to interpolate. In the transition region between the learnable and unlearnable phases, generalization is hard for all approaches including probabilistic model selection.

---

### A general derivation and quantification of the third law of thermodynamics [^43738480]. Nature Communications (2017). Medium credibility.

The most accepted version of the third law of thermodynamics, the unattainability principle, states that any process cannot reach absolute zero temperature in a finite number of steps and within a finite time. Here, we provide a derivation of the principle that applies to arbitrary cooling processes, even those exploiting the laws of quantum mechanics or involving an infinite-dimensional reservoir. We quantify the resources needed to cool a system to any temperature, and translate these resources into the minimal time or number of steps, by considering the notion of a thermal machine that obeys similar restrictions to universal computers. We generally find that the obtainable temperature can scale as an inverse power of the cooling time. Our results also clarify the connection between two versions of the third law (the unattainability principle and the heat theorem), and place ultimate bounds on the speed at which information can be erased.

---

### A global analysis of within-country health inequalities [^cfc81767]. JAMA Health Forum (2025). High credibility.

Introduction

Inequalities and disparities in health and health care are a defining concern of public health and health policy, made more acute during the COVID-19 pandemic. A substantial amount of health policy and epidemiology research aims to identify health inequalities and the levers that can be used to reduce them. This is particularly true in the US, where the number of publications and National Institutes of Health research grants focused on health disparities have increased exponentially between 2004 and 2024.

However, because no country has achieved perfect equality in health status, the import of any single country's inequalities depends on comparisons with other countries or over time. Are health inequalities in the US better or worse than in other high-income countries? Are health inequalities getting better, staying the same, or getting worse over time? Where in the world are health disparities greatest, and where are they smallest? To the extent that health inequalities are undesirable (all else equal) and a possible target for interventions, a comparative view can guide prioritization and help with understanding the variables associated with health disparities on a global scale.

The importance of a comparative view may seem intuitive, and yet comparative analyses of within-country health inequality are rare for a few reasons. Health inequalities can be defined as differences between groups in a health measure of interest, such as differences in average life expectancy between different racial and ethnic groups. Commonly, and especially in the US, health inequalities are defined as differences in health measures along a second dimension, such as differences in life expectancy by income, race, or education.

However, second dimensions such as income or race and ethnicity are not readily comparable across countries, posing a challenge for global perspectives on health inequalities. For instance, reporting differences in life expectancy among Hispanic, non-Hispanic Black, and non-Hispanic White populations may be valuable for the US but cannot be used where racial and ethnic group constructs are different. Similar limitations exist even for measures such as income or education, because social and economic contexts (or, for example, secondary school or top 10% of incomes) vary meaningfully across locations or are not well measured. The context-dependence of common second dimension socioeconomic stratifiers is a challenge for global comparative studies of health inequality.

---

### Partner choice and cooperation in social dilemmas can increase resource inequality [^8e8cbd72]. Nature Communications (2023). High credibility.

In line with archival and econometric analyses, and resonating with the Matthew effect of accumulated advantage, we see that even in our experiment, using small 'artificial societies', the advantaged flock together, leading others to increasingly lag behind. Segregation or assortment, which can be enhanced by partner choice, but is also dependent on various other elements of social network structures, comes with increased cooperation within groups and defection between communities and neighborhoods. Both segregation and wealth disparities have been linked to political polarization and violent conflict.

Whereas partner choice may enable individuals to build and maintain public goods from which everyone can benefit, we found that in artificially created societies in which individuals differed in endowment and productivity, partner choice can be a curse rather than cure: through partner selection, segregation endogenously emerges, and cooperation with similar others amplifies pre-existing differences between those who are advantaged and those who are not.

---

### Comment on brock and blake: debating brain drain [^7c9ccc4a]. Journal of Medical Ethics (2017). Low credibility.

In this response I focus largely on Brock's arguments for the right of developing nations to restrict emigration of health workers. Brock claims that the conditions she specifies for this restriction are fair and reasonable, but I dispute whether it is possible to meet those conditions given fundamental inequalities in power. In the end, there are far more powerful agents than health workers who are responsible for causing and solving the 'brain drain' issue.

---

### Clarity on disparity: who, what, when, where, why, and how [^8b9a069f]. Pediatric Clinics of North America (2023). Medium credibility.

This article offers a framework of who, what, when, where, why, and how of health disparities that can serve as a systematic approach to move from description to understanding causes and taking action to ensure health equity.

---

### Selecting fitted models under epistemic uncertainty using a stochastic process on quantile functions [^aeeaae45]. Nature Communications (2025). High credibility.

Fitting models to data is an important part of the practice of science. Advances in machine learning have made it possible to fit more-and more complex-models, but have also exacerbated a problem: when multiple models fit the data equally well, which one(s) should we pick? The answer depends entirely on the modelling goal. In the scientific context, the essential goal is replicability: if a model works well to describe one experiment, it should continue to do so when that experiment is replicated tomorrow, or in another laboratory. The selection criterion must therefore be robust to the variations inherent to the replication process. In this work we develop a nonparametric method for estimating uncertainty on a model's empirical risk when replications are non-stationary, thus ensuring that a model is only rejected when another is reproducibly better. We illustrate the method with two examples: one a more classical setting, where the models are structurally distinct, and a machine learning-inspired setting, where they differ only in the value of their parameters. We show how, in this context of replicability or "epistemic uncertainty", it compares favourably to existing model selection criteria, and has more satisfactory behaviour with large experimental datasets.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^3cc9842b]. Journal of the American College of Cardiology (2025). High credibility.

Implications for health equity — equity is defined as the absence of unfair, avoidable, or remediable differences among groups of people, and unlike health equality, which refers to equal access to quality health care for all, health equity is achieved when everyone can attain their full potential for health.

---

### HEADS-UP: understanding and problem-solving: seeking hands-down solutions to major inequities in stroke [^8dc69733]. Stroke (2020). Medium credibility.

There are substantial and longstanding inequities in stroke incidence, prevalence, care, and outcomes. The Health Equity and Actionable Disparities in Stroke: Understanding and Problem-Solving (HEADS-UP) symposium is an annual multidisciplinary scientific and educational forum targeting major inequities in cerebrovascular disease, with the ultimate objective of helping to bridge major inequities in stroke, and promptly translating scientific results into routine clinical practice, for the benefit of vulnerable and underserved populations. HEADS-UP is a collaborative undertaking by the National Institute of Neurological Disorders and Stroke and the American Stroke Association and is held the day before the annual International Stroke Conference. In 2020, the HEADS-UP focused on the topic of racial/ethnic disparities in stroke and comprised invited lectures on determinants of racial/ethnic inequities in stroke as well as emerging interventions or promising strategies designed to overcome these inequities. Competitively selected travel award scholarships were given to 19 early stage investigators who presented posters at professor moderated sessions; engaged in several career development activities aimed imparting grant writing skills, knowledge about climbing the academic ladder, and striving for work-life balance; and participated in networking events. This Health Equity edition of Focused Updates will feature an overview of the HEADS-UP 2020 symposium proceedings and articles covering the key scientific content of the major lectures delivered during the symposium including the presentation by the award-winning plenary speaker. Starting in 2021, HEADS-UP will expand to include 5 major inequities in stroke (racial/ethnic, sex, geographic, socioeconomic, and global) and seeks to be a viable avenue to meet the health equity goals of the American Heart Association/American Stroke Association, National Institutes of Neurological Disorders and Stroke, and World Stroke Organization.

---

### Identifiability analysis of second-order systems [^b99ab947]. Nuclear Medicine and Biology (2003). Low credibility.

Models provide a means to represent our understanding of the interaction among the components of a system. Individual instantiations of a system are captured by allowing the model to have parameters that may be different for each instantiation. Included in the model is a representation of the means to observe certain aspects of a system. Given the observations, successful estimation of the parameters requires that the parameters be identifiable. This is an important consideration for potential use of the model in diagnostic medicine or analysis and planning of experiments. Models considered here are typical of those used to describe flows and concentrations associated with ligand-receptor interactions.

---

### 2021 ACC expert consensus decision pathway on the management of ASCVD risk reduction in patients with persistent hypertriglyceridemia: a report of the American college of cardiology solution set oversight committee [^feafd6dd]. Journal of the American College of Cardiology (2021). High credibility.

REDUCE-IT secondary-prevention cohort with clinical ASCVD — IPE achieved an absolute risk reduction of 6.2% (25.5% vs 19.3%; HR: 0.73; 95% CI: 0.65–0.81) for the primary endpoint, with a number needed to treat of 16 to prevent 1 event over 4.9 years; for the key secondary endpoint, the absolute risk reduction was 4.4% (9.7% vs 5.2%; 95% CI: 0.63–0.82) with a number needed to treat of 23 over 4.9 years.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^6e0f31e7]. Journal of the American College of Cardiology (2025). High credibility.

Implications for health equity — working definitions: Equity is the absence of unfair, avoidable, or remediable differences among groups of people, whether defined socially, economically, demographically, geographically, or by characteristics such as sex, gender, ethnicity, disability, or sexual orientation. Unlike health equality, which refers to equal access to quality health care for all, health equity is achieved when everyone can attain their full potential for health.

---

### How can we decide a fair allocation of healthcare resources during a pandemic? [^68998a63]. Journal of Medical Ethics (2021). Medium credibility.

Whenever the government makes medical resource allocation choices, there will be opportunity costs associated with those choices: some patients will have treatment and live longer, while a different group of patients will die prematurely. Because of this, we have to make sure that the benefits we get from investing in treatment A are large enough to justify the benefits forgone from not investing in the next best alternative, treatment B. There has been an increase in spending and reallocation of resources during the COVID-19 pandemic that may have been warranted given the urgency of the situation. However, these actions do not bypass the opportunity cost principle although they can appear to in the short term, since spending increases cannot continue indefinitely and there are patient groups who lose out when resources are redirected to pandemic services. Therefore, policy-makers must consider who bears the cost of the displaced healthcare resources. Failure to do so runs a risk of reducing overall population health while disproportionally worsening health in socially disadvantaged groups. We give the example of ethnic minorities in England who already had the worst health and, due to structural injustices, were hardest hit by the pandemic and may stand to lose the most when services are reallocated to meet the resource demands of the crisis. How can we prevent this form of health inequity? Our proposal is forward-looking: we suggest that the government should invest our resources wisely while taking issues of equity into account-that is, introduce cost-equity analysis.

---

### Addressing the socioeconomic divide in computational modeling for infectious diseases [^202f9495]. Nature Communications (2022). High credibility.

Each of the proposed directions is of course far from trivial and underlies a clear increase in the complexity of models, some of which are already scratching the boundaries of what is computationally feasible. Furthermore, such extensions will give rise to and describe a wide range of mechanisms, dynamics, and interactions that do not have yet a solid theoretical basis. Just to offer an example, adherence to NPIs is a complex phenomenon that has been linked to age, gender, education, political beliefs, country of residence, and SES. Hence, in absence of precise data, more expressive models like those we are advocating for would need extra layers of assumptions and parameters.

Furthermore, SES is an aggregated indicator encompassing a wide range of factors that can, directly or indirectly, affect disease spreading and outcomes. Overcrowding in households and workplaces, limited access to healthcare and vaccinations, and limited ability to comply with NPIs by reducing contacts and mobility patterns due to job security or type are just a few examples. Hence, another concrete step toward including inequity in epidemic models is to focus directly on such factors and study the differences they induce across SES as an emergent phenomenon rather than input. Differences in the number of contacts and interactions across groups due to overcrowding could be investigated via compartmental models that allow for differences in the effective transmissibility of a pathogen. The effects of job security and type could be investigated in spatially aware models linking them to variations in mobility patterns. The impact of overcrowding in workplaces could be investigated via agent-based models. Such an approach targets specific causes and mechanisms associated with SES, that might lead to inequalities in disease spreading. It would allow developing a better understanding of their impact on diseases on one side while offering a natural testbed to design specific interventions on the other. As such, it is complementary with respect to what we have described above where SES is considered as an input for the models.

Epidemic models that account for SES as input or that explicitly consider specific drivers of disease transmission associated with SES in their formulation would also allow us to formulate and address new questions. For example, they would enable us to study the impact of health disparities under different (controlled) conditions, disentangle the effects of multiple, and competing, drivers of transmission on health disparities, and design intervention strategies that consider the overall burden as well as health inequality.

---

### Clotrimazole [^b5a7188a]. FDA. Low credibility.

The dosage of clotrimazole OTIC for treatment of otomycosis in adults is 1 vial OTIC BID for 14 days (1%/0.17 mL)

---

### 2019 methodology for creating expert consensus decision pathways: a report of the American college of cardiology [^3c363d65]. Journal of the American College of Cardiology (2019). High credibility.

Expert Consensus Decision Pathways methodology — purpose and scope are described as complementing Clinical Practice Guidelines by providing "the how", including practical guidance that transforms recommendations into clinically actionable information, clinical guidance to make sense of quickly-evolving evidence, and dissemination of new information not yet incorporated into guidelines. Expert Consensus Decision Pathways are situated within the American College of Cardiology's "actionable knowledge" strategy and are an important component of "solution sets", articulating concise and focused practical guidance around high-value clinical topics. Of note, the goal of an Expert Consensus Decision Pathway is not to provide a single correct answer, but to encourage clinicians to ask certain questions and consider key factors as they come to their own decision on a treatment plan to be recommended and discussed with their patients. Topics have spanned lipid disorders, antithrombotic therapy and bleeding, valvular heart disease, heart failure, coronary artery disease, cardiovascular risk reduction in type 2 diabetes, and tobacco cessation, with scope widening to include guidance on management of conduction disturbances for transcatheter aortic valve replacement (TAVR) and same-day discharge after percutaneous coronary intervention (PCI), as well as other topics.

---

### Data-driven control of complex networks [^37bb115f]. Nature Communications (2021). High credibility.

Data-driven minimum-energy control

By letting Q = 0 and R = I in Eq. (4), we recover a data-driven expression for the T -step minimum-energy control to reach y f. We remark that the family of minimum-energy controls has been extensively employed to characterize the fundamental capabilities and limitations of controlling networks, e.g. see. After some algebraic manipulations, the data-driven minimum-energy control input can be compactly rewritten as (Supplementary Note 5)The latter expression relies on the final output measurements only (matrix Y T) and, thus, it does not exploit the full output data (matrix Y 1: T −1). An alternative control expression isThis is a simple, suboptimal data-based control sequence that correctly steers the network to y f in T steps, as long as y f belongs to the range space of Y T (a condition that is normally satisfied when p randomly generated data are available). Further, and more importantly, when the input data samples are drawn randomly and independently from a Gaussian distribution with zero mean and finite variance, Eq. (6) converges to the minimum-energy control in the limit of infinite data (Supplementary Note 6).

Figure 3 a compares the performance (in terms of control effort and error in the final state) of the two data-driven expressions in Eqs. (5) and (6), and the model-based control as a function of the data size N. While the data-driven control in Eq. (5) becomes optimal for a finite number of data (precisely, for N = m T independent data), the approximate expression in Eq. (6) tends to the optimal control only asymptotically in the number of data (Fig. 3 a, left). In both cases, the error in the final state goes to zero after collecting N = p data (Fig. 3 a, right). For the approximate control in Eq. (6), we also establish upper bounds on the size of the dataset to get a prescribed deviation from the optimal control, in the case of Gaussian input data. Our nonasymptotic analysis indicates that this deviation is proportional to the worst-case control energy required to reach a unit-norm target. This, in turn, implies that networks that are easy to control require fewer trials to attain a prescribed approximation error (Supplementary Note 6).

---

### Nonlinear delay differential equations and their application to modeling biological network motifs [^a6af3eb5]. Nature Communications (2021). High credibility.

Frequency response of feedforward motifs can be solved analytically and demonstrates low- and band-pass filtering capabilities

Biological regulatory networks often encode information as the change in frequency of an oscillating input, which has been suggested to be more robust to noise than encoding information in absolute concentration –. That feedforward loops filter short square pulses suggests more general frequency-filtering capabilities. We therefore analyze feedforward frequency response to sinusoidal input (Fig. 6 d–g). We show that the response follows the outline of a universal transfer function curve, independent of the logic or delay difference.

Instead of the step input analyzed above, here we consider a sinusoidal inputwhich oscillates between zero and 2 A (twice the amplitude) at a frequency f > 0. Taking the Fourier decomposition of each Hill-regulated term 1/[1 + X n (T)] and plugging into the governing Eq. (21) (Supplementary Note 6) provides the output Z (T) in terms of its magnitude I k and phase ϕ k as a function of frequency:whereare Fourier coefficients of Hill-regulated terms 1/[1 + X n (T)] at integer multiples k of the fundamental frequency f :for all f > 0. Note that the magnitudes are symmetric to interchange of the two regulation arms (η 1 ↔ η 2, n 1 ↔ n 2), while the phases are not.

---

### Economic segregation is associated with reduced concerns about economic inequality [^7855e32a]. Nature Communications (2024). High credibility.

Introduction

Social scientists have long sought to understand why people do not seem as concerned about economic inequality as one might expect them to be. Whereas some researchers have examined this question by focusing on ideological differences –, lay beliefs about inequality –, and misperceptions about it, others have taken a more situational approach, emphasizing how exposure to inequality shapes concerns about it –. Yet, since highly unequal regions tend to be economically segregated, living in unequal areas may not be sufficient for increasing people's concern about inequality. In this paper, we suggest that economic segregation — the separation of people with different economic means — is a critical factor that shapes attitudes about inequality. Specifically, we predict that economic segregation reduces people's concerns about economic inequality.

Economic segregation shapes many aspects of our lives, affecting where we live, work, shop, pray, play, and go to school –. For instance, college students from families in the top 1% are more likely to meet similarly wealthy students at elite universities than they are to meet students from the entire bottom half of the income distribution. And, while people of different financial means are obviously aware of each other's existence, economic segregation dampens cross-class interactions and fosters class isolation. Consequently, as wealthier individuals segregate into homogeneously affluent neighborhoods, they less frequently interact with middle- and lower-class others and are thus less frequently exposed to situations where the juxtaposition of wealth and poverty is salient.

Consider, as an illustrative example from visual perception, the famous Mach Bands optical illusion, in which the contrast between bands of different shades of gray is made salient by their juxtaposition. Just as the contrast between different shades of color is more visually salient when they are directly adjacent to each other than physically separated, we argue that the economic contrast between different levels of wealth is more psychologically salient when individuals of different means are functionally close to each other than when they are segregated. And, just as comparing different shades of color is visually more difficult when they are physically separated, we suggest that comparing different levels of wealth is more psychologically difficult when economic segregation is high. Put differently, by rendering the juxtaposition between people of different means less apparent, economic segregation creates an obstacle to economic comparisons. Thus, even if people know about the existence of inequality, we argue that segregation limits their ability to fully compare differences in finances between people of different means.

---

### Spin dephasing under nonlinear gradients: implications for imaging and field mapping [^eaf2803c]. Magnetic Resonance in Medicine (2012). Low credibility.

This work examines the prototypical MR echo that would be expected for a voxel of spins evolving in a strong nonlinear field, specifically focusing on the quadratic z(2) - ½(x(2) + y(2)) field. Dephasing under nonlinear gradients is increasingly relevant given the growing interest in nonlinear imaging, and here, we report several notable differences from the linear case. Most notably, in addition to signal loss, intravoxel dephasing under gradients creating a wide and asymmetric frequency distribution across the voxel can cause skewed and nonlinear phase evolution. After presenting the qualitative and analytical origins of this difference, we experimentally demonstrate that neglecting these dynamics can lead to significant errors in sequences that assume phase evolution is proportional to voxel frequency, such as those used for field mapping. Finally, simplifying approximations to the signal equations are presented, which not only provide more intuitive forms of the exact expression but also result in simple rules to predict key features of the nonlinear evolution.

---

### We need people's WHO to solve vaccine inequity, and we need it now [^b0c77f01]. BMJ Global Health (2021). High credibility.

We need the leadership of 'people's WHO' to solve vaccine inequity towards a long-term global health equity

In the current economic order where resources and decision-making power are concentrated within HICs, multinational corporations and private philanthropies, it is inherently difficult for the global majority with less resources and power to advocate for their interests and ensure that their perspectives shape global programmes and policies. WHO via its representation of 193 Member States and a rotating, elected 343-member executive board is the world's best platform within which governments with lesser means and power can collectively negotiate for the interests of the global majority.

A collective desire of the global majority was best expressed in the vision of Health for All articulated in the Alma Ata Declaration from 1978. This vision called for a community-driven, government-led 'health for all' approach. It was distinct from the market-delivered health services championed by the USA and the highly centralised, state-controlled provision of primary healthcare (PHC) championed by the Soviet Union during the Cold War (1946–1989).

---

### Best (but oft-forgotten) practices: checking assumptions concerning regression residuals [^f2ebb771]. The American Journal of Clinical Nutrition (2015). Low credibility.

The residuals of a least squares regression model are defined as the observations minus the modeled values. For least squares regression to produce valid CIs and P values, the residuals must be independent, be normally distributed, and have a constant variance. If these assumptions are not satisfied, estimates can be biased and power can be reduced. However, there are ways to assess these assumptions and steps one can take if the assumptions are violated. Here, we discuss both assessment and appropriate responses to violation of assumptions.

---

### Inferring time derivatives including cell growth rates using gaussian processes [^d99eaf3f]. Nature Communications (2016). Medium credibility.

Inferring the first and second time derivatives

To determine the time derivative of the data, we use that the derivative of a Gaussian process is another Gaussian process. We can therefore adapt standard techniques for Gaussian process to allow time derivatives to be sampled too.

Building on the work of Boyle, we let g (x) and h (x) be the first and second derivatives with respect to x of the latent function f (x). If f (x) is a Gaussian process then so are both g (x) and h (x). Writing ∂ 1 and ∂ 2 for the partial derivatives with respect to the first and second arguments of a bivariate function, we have

and that

as well as

following ref.

Consequently, the joint probability distribution for y and f *, g * and h * evaluated at points X * is again Gaussian (cf. equation (7)):

where we write K = K (X, X) and K ✱ = K (X *, X *) for clarity.

The covariance function is by definition symmetric: k (x i, x j) = k (x j, x i) from equation (1). Therefore, and so

for all positive integers k and. Consequently, the covariance matrix in equation (13) is also symmetric.

Conditioning on y now gives that the distribution P (f *, g *, h *| X, y, θ, X *) is Gaussian with mean

and covariance matrix

Equation (16) includes equation (9) and shows that

which gives the error in the estimate of the first derivative. Similarly,

is the error in estimating the second derivative.

Using an empirically estimated measurement noise

Although our derivation is given for a Gaussian process where the measurement errors in the data are independent and identically distributed with a Gaussian distribution of mean zero, the derivations are unchanged if the measurement noise has a different s.d. for each time point.

When the magnitude of the measurement noise appears to change with time, we first empirically estimate the relative magnitude of the measurement noise by the variance across all replicates at each time point. We then smooth this estimate over time (with a Gaussian filter with a width of 10% of the total time of the experiment, but the exact choice is not important) and replace the identity matrix, I, in equations (6), (15) and (16) by a diagonal matrix with the relative measurement noise on the diagonal in order to make predictions.

---

### Resolving discrepancies between chimeric and multiplicative measures of higher-order epistasis [^8eb47c09]. Nature Communications (2025). High credibility.

Multivariate Bernoulli distribution

The three parametrizations we derived for the bivariate Bernoulli distribution extend to the multivariate Bernoulli distribution. Suppose that (X 1, …, X L) ∈ {0, 1} L is distributed according to a multivariate Bernoulli distribution. Then the distribution P (X) of the random variables X is uniquely specified by one of the three following parametrizations.
General parameters: These are 2 L non-negative valuessatisfyingFor example if L = 3, then p 010 = P (X 1 = 0, X 2 = 1, X 3 = 0) and p 110 = P (X 1 = 1, X 2 = 1, X 3 = 0). Note that since, only 2 L − 1 valuesare necessary to define the distribution.
Natural/canonical parameters: These are 2 L real numberssatisfyingSimilar to the general parameters p i, only 2 L − 1 values β S are necessary to uniquely define the distribution. Typically, the parameter, often called a normalizing constant or a partition function of the distribution, is left unspecified. As noted in the bivariate setting, equation (23) shows that the multivariate Bernoulli is an exponential family distribution with 2 L − 1 sufficient statistics of the form ∏ i ∈ S X i for subsets S with ∣ S ∣ > 0. Moreover, by rewriting (23) aswe observe that the natural parameters β correspond to interaction coefficients in a log-linear regression model with response variables p. For example, the natural parameter β 12 is the coefficient of the interaction term x 1 x 2.
Moments/mean parameters: These are 2 L real numberssatisfyingFor example if L = 3, then μ 13 = E [X 1 X 3] while μ 12 = E [X 1 X 2]. The mean parametersare sufficient statistics for the multivariate Bernoulli distribution, as seen in the exponential family form (23) of the multivariate Bernoulli distribution.

---

### 2020 ACC expert consensus decision pathway for anticoagulant and antiplatelet therapy in patients with atrial fibrillation or venous thromboembolism undergoing percutaneous coronary intervention or with atherosclerotic cardiovascular disease: a report of the American college of cardiology solution set oversight committee [^c2c4f28d]. Journal of the American College of Cardiology (2021). High credibility.

ACC antithrombotic therapy — PIONEER AF-PCI outcomes for stent thrombosis and cardiovascular death are reported with hazard ratios (HR) and 95% confidence intervals (CI): For stent thrombosis (HR; 95% CI), Group 1 vs. 3 0.8% vs. 0.7% (1.20, 0.32–4.45) and Group 2 vs. 3 0.9% vs. 0.7% (1.44, 0.40–5.09); for cardiovascular death (HR; 95% CI), Group 1 vs. 3 2.4% vs. 1.9% (1.09, 0.59–2.80) and Group 2 vs. 3 2.2% vs. 1.9% (1.19, 0.54–2.62).

---

### Gender bias in health financing methods: metrics and data [^d0f7a227]. BMJ Global Health (2025). High credibility.

Summary box

Gender inequality is responsible for a major cancer divide, not only in terms of prevention or treatment but also when it comes to the economic factors that determine exposure to risk or access to care and care outcomes.
Current and predominant economic methods and data may mask gender bias, impeding public policy and practice from addressing persistent gender injustices.
Policymakers and planners as well as researchers must question the economic evidence and data they are presented with or the methods they, as researchers, tend to apply to generate such evidence to start with if evidence-informed policymaking is to change the anti-female bias when it comes to cancer case and cancer outcomes.

---

### Changing relationship between income inequality and mortality [^da8c0f51]. Journal of Epidemiology and Community Health (2024). Medium credibility.

The recent paper by Dunn et al showed that the positive relationship between US state-level income inequality and mortality was small in the 1950s, rose to a large value around 1990 but had largely disappeared by 2019. We consider these findings in the context of the mechanisms that have been advanced for reasons why a positive relationship might be expected, and in relation to studies using alternative methods included in systematic reviews that fail to confirm an independent inequality/mortality relationship. Ecological studies, such as by Dunn et al, using subnational data have advantages compared with similar studies using cross-national data, but controls are typically confined to those available from sources such as decennial census, so scope for incorporating lagged effects and life course factors is limited. However, they are often the only studies with the statistical power to identify subnational differentials and time trends so they are complementary to rarely available sources such as high-quality long-term individual-level microdata data required for causal analyses. Income equality can arise not only due to citizens' positive preferences but also to external choices such as economic decline and globalisation, so examining the wider context is important when explaining excess levels of 'deaths of despair' in low-inequality US states. The apparent increasingly strong association between income levels and low mortality with a weakening inequality/mortality relationship has implications for policy recommendations.

---

### Society's choice: the tradeoff between efficacy and equity and the lives at stake [^ae5d44cd]. American Journal of Preventive Medicine (2004). Low credibility.

Society understands that racial and ethnic minorities experience inferior medical care and health status, but may not appreciate the seriousness of the problem. Each year the nation spends billions of dollars to perfect the "technology" of health care (e.g., development of new drugs) and modernize delivery systems, thereby saving thousands of lives. Correcting disparities in care, however, would avert five times as many deaths. If policymakers adhered to the goal of optimizing population health, greater priority would go to resolving disparities than to refining technology, but reverse priorities prevail. Adverse socioeconomic conditions-chief among the many causes of disparities-could be eased through bold socioeconomic reforms. Society has the resources to enable the disadvantaged to attain better health but pursues other priorities.

---

### Overcoming gender inequality for climate resilient development [^b7cfde5f]. Nature Communications (2020). High credibility.

Gender inequalities are reflected in differential vulnerability, and exposure to the hazards posed by climate change and addressing them is key to increase the adaptive capacities of societies. We provide trajectories of the Gender Inequality Index (GII) alongside the Shared-Socioeconomic Pathways (SSPs), a scenario framework widely used in climate science. Here we find that rapid improvements in gender inequality are possible under a sustainable development scenario already in the near-term. The share of girls growing up in countries with the highest gender inequality could be reduced to about 24% in 2030 compared to about 70% today. Largely overcoming gender inequality as assessed in the GII would be within reach by mid-century. Under less optimistic scenarios, gender inequality may persist throughout the 21st century. Our results highlight the importance of incorporating gender in scenarios assessing future climate impacts and underscore the relevance of addressing gender inequalities in policies aiming to foster climate resilient development.

---

### Actionable equality [^52857e1a]. Nature Medicine (2018). Excellent credibility.

In the past decade, many challenges faced by women seeking to advance their scientific careers have been identified. Although new policies encouraging equal opportunities in academic research are closing the gap, multipronged measures are needed in order to achieve long-lasting changes that make science gender-blind.

---

### Nonlinear delay differential equations and their application to modeling biological network motifs [^702ab11e]. Nature Communications (2021). High credibility.

The logic parameter space can be divided into AND-type, OR-type, and single-input functions

Only the 8 regulatory functions on the diagonals of Fig. 5 (excluding FALSE and TRUE) make use of both inputs. These eight can be further divided into positive or negative regulation on each arm (4 possibilities) in conjunction with an AND or OR gate (8 possibilities total). Specifically, "OR-type" logic applies when both η Z 1 > 1 and η Z 2 > 1 (OR, NAND, and both IMPLY gates), and "AND-type" logic applies when both η Z 1 < 1 and η Z 2 < 1 (AND, NOR, and both NIMPLY gates). This can be seen mathematically by using Boolean logic simplification. For example, X NOR Y = NOT X AND NOT Y. Similarly, X NAND Y = NOT X OR NOT Y.

It is important to note that this logic scheme is an approximation, and in reality the sum of two Hill terms provides a form of fuzzy logic. That is, if the inputs X or Y are close to 1, or if the regulatory strengths η Z 1,2 are close to 1, then Z will also be close to 1 for some input combinations (Supplementary Note 5).

Note that if X (T) and Y (T) are independent, they can be time-shifted in Eq. (19) by γ 1 and γ 2, respectively, showing that the dynamics do not depend on delays. This is not true if X and Y are dependent (e.g. X = Y), which leads to interesting dynamics that we examine below in feedforward loops and double feedback.

---

### Local network interaction as a mechanism for wealth inequality [^cd4ad610]. Nature Communications (2024). High credibility.

Second, most existing research has overlooked the intricate and multi-layered network structures observed in real-world social networks, including one's affiliation in groups, residency in places, and their connections to ecological spaces. The accelerated urbanisation and globalisation of modern societies have altered the ways in which people are connected, particularly in the Global South. This pattern is evident among rural populations with limited job prospects, whose livelihoods rely primarily on economic support from distant sources. These physical and geographic boundaries may have a considerable influence on a range of economic outcomes for the interconnected individuals, as well as the prosperity of these communities at large. Nevertheless, little is known about the degree to which these network interactions – spanning across diverse geographic boundaries – are associated with the economic development of rural communities. As such, an alternative, multilevel social network framework is required to better estimate the effect of these geographically defined network structures on social inequalities.

Third, several longstanding questions in social and natural sciences relate to the puzzle of whether small-scale social processes can lead to emergent phenomena at the macro level –. This micro-to-macro question, pertinent in understanding phenomena such as the recent COVID-19 pandemicand climate change responses, seeks to clarify how local social interactions might traverse into population-level dynamics. However, understanding these micro-macro linkages remains a formidable challenge, often due to the difficulties of harmonising and modelling the expected social patterns and the inherent randomness in human social interactions. Previous research has explored the association between macro-level inequality and global network properties, as well as individual-level economic outcomes and local social interactions –. Yet, the link between macro- and micro-level economic outcomes, alongside the specific types of social interactions that may strengthen returns capable of influencing economic disparities, remains poorly understood. Unpacking the varying network dynamics at play is therefore likely to contribute to a more refined understanding of how to enhance the effectiveness and efficiency of social policy interventions.

---

### Optimization of sensitivity encoding with arbitrary k-space trajectories [^c850cf75]. Magnetic Resonance Imaging (2007). Low credibility.

Sensitivity encoding (SENSE) is a magnetic resonance technique that unifies gradient and receive coil encoding. SENSE reconstructs the image by solving a large, ill-conditioned inverse problem, which generally requires regularization and preconditioning. The present study suggests a simple heuristic for determining the regularization parameter. Also discussed are the use of density weighting and intensity correction as preconditioners and the role that coil sensitivity estimation has in regularization. A modification to the intensity correction is proposed for use with a phase constraint.

---

### Nonlinear delay differential equations and their application to modeling biological network motifs [^b91959df]. Nature Communications (2021). High credibility.

A two-parameter summing function reproduces all 2-input monotonic logic gates

We first write out nondimensionalized equations corresponding to the logic gate motif as depicted in Fig. 5 a. We assume that the degradation constants (β) for Z and R are equal for simplicity, and that there is no leakage.

We describe the regulation of Z by X and Y using a sum of Hill terms. Logic gate behavior can be captured with other approaches such as a product of Hill terms, or summation within a single Hill term, each representing subtly different biology. We choose the separate Hill term approach as it describes many logic functions simply by tuning regulatory strengths, and can be extended to include multiplicative terms (Supplementary Note 5). Caveats include multiple states for Z, requiring additional binarization via R (Fig. 5 c), as well as poor response to ratiometric inputs, discussed in the next section on feedforward motifs.

Using Eq. (19), we can characterize the motif logic based on the idea of dynamic range matching. Every regulator in Eq. (19) is effectively compared against unity in the denominator of the Hill function for its corresponding output. For instance, Z provides an "on" or "off" signal to R if Z > 1 or Z < 1 respectively. Z can take on values below 1 as long asand, otherwise Z will always activate R, as indicated by the areas marked TRUE in Fig. 5.

Let us say that X and Y settle on steady-state values X * ≡ η X, Y * ≡ η Y, as inputs to our logic gate. A value of η X or η Y significantly greater than 1 is then "high" (true, 1), and "low" (false, 0) if much less than 1. We then want to determine whether Z * is greater than (true) or less than (false) 1. For example, if n 1,2 > 0 (two repressors), Table 1 gives the possible steady states of Z. If η Z 1 and η Z 2 are greater than 1, these steady states approximate a NAND gate. If they are less than 1, but sum to greater than 1, the steady states instead approximate a NOR gate.

---

### An expectation-maximization algorithm for the analysis of allelic expression imbalance [^80a63f76]. American Journal of Human Genetics (2006). Low credibility.

A significant proportion of the variation between individuals in gene expression levels is genetic, and it is likely that these differences correlate with phenotypic differences or with risk of disease. Cis-acting polymorphisms are important in determining interindividual differences in gene expression that lead to allelic expression imbalance, which is the unequal expression of homologous alleles in individuals heterozygous for such a polymorphism. This expression imbalance can be detected using a transcribed polymorphism, and, once it is established, the next step is to identify the polymorphisms that are responsible for or predictive of allelic expression levels. We present an expectation-maximization algorithm for such analyses, providing a formal statistical framework to test whether a candidate polymorphism is associated with allelic expression differences.

---

### Ethics and governance of global health inequalities [^84dcd0f1]. Journal of Epidemiology and Community Health (2006). Low credibility.

Background

A world divided by health inequalities poses ethical challenges for global health. International and national responses to health disparities must be rooted in ethical values about health and its distribution; this is because ethical claims have the power to motivate, delineate principles, duties and responsibilities, and hold global and national actors morally responsible for achieving common goals. Theories of justice are necessary to define duties and obligations of institutions and actors in reducing inequalities. The problem is the lack of a moral framework for solving problems of global health justice.

Aim

To study why global health inequalities are morally troubling, why efforts to reduce them are morally justified, how they should be measured and evaluated; how much priority disadvantaged groups should receive; and to delineate roles and responsibilities of national and international actors and institutions.

Discussion and Conclusions

Duties and obligations of international and state actors in reducing global health inequalities are outlined. The ethical principles endorsed include the intrinsic value of health to well-being and equal respect for all human life, the importance of health for individual and collective agency, the concept of a shortfall from the health status of a reference group, and the need for a disproportionate effort to help disadvantaged groups. This approach does not seek to find ways in which global and national actors address global health inequalities by virtue of their self-interest, national interest, collective security or humanitarian assistance. It endorses the more robust concept of "human flourishing" and the desire to live in a world where all people have the capability to be healthy. Unlike cosmopolitan theory, this approach places the role of the nation-state in the forefront with primary, though not sole, moral responsibility. Rather shared health governance is essential for delivering health equity on a global scale.

---

### Bulk tissue cell type deconvolution with multi-subject single-cell expression reference [^acec6bf4]. Nature Communications (2019). High credibility.

To illustrate this recursive tree-guided deconvolution procedure, we start with a simple case with four cell types and G genes. Let X 1, X 2, X 3, X 4 represent cell type-specific expression in the design matrix, obtained from scRNA-seq, and let Y be the gene expression vector in the bulk RNA-seq data. The relationship of bulk and single-cell data can be written aswhere the superscripts (1) and (2) indicate two sets of genes. Suppose the four cell types are grouped into two clusters, (X 1, X 2) and (X 3, X 4). The first set of genes are those showing small intra-cluster variance in gene expression, that is, and, whereas the second set of genes are the remaining genes.
Stage 1: Estimate cluster proportions π 1 = p 1 + p 2 and π 2 = p 3 + p 4,

The cluster proportions, and, are estimated by W-NNLS using intra-cluster homogenous genes.
Stage 2: Estimate cell type proportions (p 1, p 2, p 3, p 4),

The cell type proportions are estimated by W-NNLS using the remaining genes subject to the constraint that

Interconversion of different gene expression measures

MuSiC links bulk and single-cell gene expression by mRNA molecule counts. There are many measures of mRNA abundance, such as read counts, UMI counts, RPKM and TPM. As molecule counts are not observed in real studies, we approximate the molecule counts by read counts and estimate cell type proportions based on assumptions A1–A3. The interconversion between other gene expression measures and read count determines if MuSiC can utilize other measures as the input for deconvolution. One step in MuSiC estimation is the use of average library size as a proportional measure of average cell size for a given cell type, which is absent in normalized measurements of mRNA abundance such as RPKM and TPM. For RPKM, we would need the average library size for each cell type to be provided, or the average cell size for each cell type to be obtained from other sources. Cell type proportions cannot be estimated by MuSiC with TPM information alone. Below, we derive the relationships of various types of gene expression measures in detail.

---

### Economic segregation is associated with reduced concerns about economic inequality [^86303b3b]. Nature Communications (2024). High credibility.

Finally, although we focused on one specific pathway through which segregation reduces concerns about inequality (i.e. economic comparisons), future research could examine the relationship between different pathways. Clearly, economic segregation shapes attitudes about inequality through two independent and distinct pathways: by distorting perceptions of inequality and by reducing the comparisons people make between individuals of different means. Yet, the interplay between these pathways remains to be explored. For instance, by underestimating the level of inequality in society, people may be less prone to compare individuals of different means to each other, and thus be less concerned about it. Moreover, such obstacles to comparing people of different means may further distort perceptions of inequality, leading people to underestimate it. Thus, by examining the reciprocal relationship between these two pathways, future research could further our understanding of why economic segregation reduces concerns about inequality.

The growing interest in how people perceive, make sense, and react to inequality has mainly focused on reactions to economic disparities but has failed to account for the physical and functional distributions of such disparities. Yet inequality often hides in plain sight and can be obscured by the fault lines of segregation. As long as people of different economic means live in different areas, work at different companies, send their children to different schools, and engage in different leisure activities, they may be less likely to care about inequality.

---

### Gender differences in socioeconomic inequality in mortality [^d760385d]. Journal of Epidemiology and Community Health (2003). Low credibility.

Objectives

There is uncertainty about whether position in a socioeconomic hierarchy confers different mortality risks on men and women. The objective of this study was to conduct a systematic review of gender differences in socioeconomic inequality in risk of death.

Methods

This research systematically reviewed observational cohort studies describing all cause or cause specific mortality for populations aged 25–64 in developed countries. For inclusion in the review, mortality had to be reported stratified by gender and by one or more measures of socioeconomic status. For all eligible studies, five absolute and six relative measures of the socioeconomic inequality in mortality were computed for male and female populations separately.

Results

A total of 136 published papers were reviewed for eligibility, with 58 studies deemed eligible for inclusion. Of these eligible studies, 20 papers published data that permitted the computation of both absolute and relative measures of inequality. Absolute measures of socioeconomic mortality inequality for men and women generally agreed, with about 90% of studies indicating that male mortality was more unequal than female mortality across socioeconomic groups. In contrast, the pattern of relative inequality results across the 20 studies suggested that male and female socioeconomic inequality in mortality was equivalent.

Conclusions

Inferences about gender differences in socioeconomic inequality in mortality are sensitive to the choice of inequality measure. Wider understanding of this methodological issue would improve the clarity of the reporting and synthesis of evidence on the magnitude of health inequalities in populations.

---

### Imlunestrant [^7b5c5001]. FDA. Low credibility.

Labeled indications for Imlunestrant include:

- Treatment of breast cancer in female adults with ESR1 mutation (advanced or metastatic, ER-positive, HER2-negative, progression after ≥ 1 line of endocrine therapy)

---

### Economic segregation is associated with reduced concerns about economic inequality [^87d1b945]. Nature Communications (2024). High credibility.

Drawing from research on basic cognitive and social processes, we suggest that economic segregation decreases concerns about inequality by impeding economic comparisons. Salient economic reference groups make it easy to compare different levels of wealth to each other and thus shape support for redistributive policies. For instance, people are more supportive of redistributive policies when they personally know someone who has economic problems or are in contact with someone who is unemployed –. And, since making sense of inherently ambiguous concepts like 'financial success' requires comparing financially well-off individuals to less fortunate others –, less frequent engagement in such comparisons can affect attitudes about inequality. Thus, we predict that the dampening effect of segregation on economic comparisons reduces concerns about inequality. Since economic segregation inherently reduces the contrast between wealth and poverty, we hypothesize that it makes comparisons less salient and economic disparities appear as less troubling.

Importantly, in contrast to past research –, we examine the psychological effects of economic segregation even when people are exposed to the very same level of inequality. By sorting people of different economic means into separate groups that live in distinct areas and functionally segregated institutions, segregation reduces the available cues that people have about the actual level of inequality in society. And, since people evaluate societal inequality by sampling their immediate environments, this lack of cues of inequality in highly segregated areas may lead people to underestimate its full extent –. Yet, beyond focusing on such distorted perceptions, we propose that the effect of segregation on concerns about inequality occurs through an independent pathway: reduced economic comparisons. As is the case with the Mach Bands illusion, we suggest that caring about inequality requires more than mere exposure to different levels of wealth. Rather, we argue that the direct juxtaposition between people of different means is critical for shaping concerns about inequality.

---

### International equity in access to home dialysis [^607f22af]. Current Opinion in Nephrology and Hypertension (2025). Medium credibility.

CONCLUSION

For someone not living on dialysis, or in a low resource setting, the concept of home dialysis as the dialysis modality of choice is very appealing on many fronts both for the individual and the health system. For those living on dialysis in LMICs however, significant global inequalities and inequities exist in the availability of home dialysis across countries and regions, as well as in realistic, acceptable and sustainable access to these therapies. Simply incentivising home dialysis through reimbursements, policy change or improved education of patients and clinicians will not solve the individual level inequities, which are intricately tied to the social determinants of well being. If home dialysis is to be scaled up as a fair and viable dialysis choice around the globe, a holistic approach is needed starting with maximizing the individual capabilities of all people everywhere, by addressing the fundamental social and economic inequities, which increased risk of kidney disease and currently drastically limit choice and access to dialysis for many.

---

### Article 5. An introduction to estimation – 2: from z to T [^fb82b806]. Emergency Medicine Journal (2001). Low credibility.

Provided the sample size is large enough (that is, n greater than 100), the z statistic can be used to determine the confidence interval estimation of the population mean even when the sigma is not known. In these cases the estimation of the standard error of the mean is used. The z statistic is also valid when determining the population's proportion based upon a large sample. However, when dealing with smaller samples, the z statistic is replaced by the t statistic. This makes it possible to estimate, in a population with an unknown standard deviation: The probability of getting a sample mean greater than or equal to a particular value The value of a sample mean with a particular probability of occurring The probability of getting a sample mean between two particular values The confidence interval for the estimation of the population mean can also be determined using the t statistic.

---

### Roflumilast (Zoryve) [^11a5acd0]. FDA (2024). Medium credibility.

The dosage of roflumilast TOP for treatment of plaque psoriasis in both children (in patients 6–12 years) is 1 application(s) TOP daily (0.3% cream)

---

### Identifying domains of applicability of machine learning models for materials science [^72c4ba76]. Nature Communications (2020). High credibility.

An illustrative example

Before describing the details of DA identification and its integration into the ML process, let us illustrate the concept and its utility via a synthetic example (see Fig. 1). We consider a simple two-dimensional representation consisting of independent features x 1 and x 2 that are each distributed according to a normal distribution with mean 0 and variance 2 (N (0, 2)) and a target property y that is a third-degree polynomial in x 1 with an additive noise component that scales exponentially in x 2 :That is, the y values are almost determined by the third-degree polynomial for low x 2 values but are almost completely random for high x 2 values. Discovering applicable domains reveals how different models cope differently with this setting even if they have a comparable average error. To show this, let us examine the error distributions obtained from three different kernelized regression models of the formwith parameter vector ν that are fitted around a training, or fitting (F), setwith three different choices for the kernel function k. We observe:
When using the linear (lin) kernel, the resulting linear model is globally incapable to trace the variation of the third-order polynomial except for a small stripe on the x 1 -axis where it can be approximated well by a linear function. Consequently, there is a very high error globally that is substantially reduced in the DA described by σ lin (x 1, x 2) ≡ −0.3 ≤ x 1 ≤ 0.3.
When using the Gaussian kernel), the resulting radial basis function (rbf) model is able to represent the target property well locally unless (a) the noise component is too large and (b) the variation of the target property is too high relative to the number of training points. The second restriction is because the rbfs have non-negligible values only within a small region around the training examples. Consequently, the discovered DA is not only restricted in x 2 -direction but also excludes high absolute x 1 -values: σ rbf ≡ −3.3 ≤ x 11 ≤ 3.1 ∧ x 2 ≤ 0.1.
In contrast, when using the non-local third-degree polynomial (poly) kernel, data sparsity does not prevent an accurate modeling of the target property along the x 1 -axis. However, this non-locality is counterproductive along the x 2 -axis where overfitting of the noise component has a global influence that results in higher prediction errors for the almost deterministic data points with low x 2 -values. This is reflected in the identified DA σ poly (x 1, x 2) ≡ −3.5 ≤ x 2 ≤ 0.1, which contains no restriction in x 1 -direction, but excludes both high and low x 2 -values. This highlights an important structural difference between the rbf and the polynomial model that is not reflected in their similar average errors.

---

### Nonlinear delay differential equations and their application to modeling biological network motifs [^22bd51a1]. Nature Communications (2021). High credibility.

Motif III: logic

A general class of functions used to describe natural,– and synthetic, biological networks are logic gates, which have two inputs regulating a single output (Fig. 5). Gates exhibit either high ("on") or low ("off") output depending on whether inputs are on or off. For example, the AND gate specifies high output only if both inputs are on. In this section we provide a specific DDE-based framework that covers 14 out of 16 possible 2-input logic operations, and show that these operations form a continuous 2D parameter space.

Fig. 5
A simple approximation for digital logic using a sum of Hill terms recapitulates all monotonic logic functions in a single parameter space.

a A prototypical regulatory network involving logic where X and Y both regulate Z, which must integrate the two signals using some logic before it can in turn activate a downstream reporter R. b Parameter space showing regions where regulation approximately follows 14 of the 16 possible 2-input logic functions depending on the strength of two single-variable Hill regulation terms (η Z 1: regulation of Z by X, η Z 2: regulation of Z by Y). Network logic can be smoothly altered by varying the parameters (η Z 1, η Z 2), with a change of sign in (n 1, n 2) required to switch quadrants. The bottom-left quadrant shows that very weak regulation in both terms leads to an always-off (FALSE) function, weak regulation in one arm only leads to single-input (X, Y) functions, strong regulation in both arms leads to an OR function, and regulation too weak in either arm alone to activate an output but strong enough in sum leads to an AND function. The other three quadrants are related by applying NOT to one or both inputs, with function names related by de Morgan's lawNOT(X OR Y) = NOT X AND NOT Y. In particular, X IMPLY Y = NOT(X) OR Y, X NIMPLY Y = X AND NOT(Y), X NOR Y = NOT X AND NOT Y, and X NAND Y = NOT X OR NOT Y. Truth tables for all 16 logic gates are provided in Supplementary Table 1 for reference. The two non-monotonic logic functions, X XOR Y and X XNOR Y, are those 2 of 16 not reproduced directly using this summing approximation. They can be produced by layering, e.g. NAND gates. c Representative time traces for AND (η Z 1 = η Z 2 = 0.9) and OR (η Z 1 = η Z 2 = 1.8) gates with n 1 = n 2 = −2, n 3 = −20, η R = η Z 1 + η Z 2. The functionwhen n > 0, when n < 0.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^cbffc27e]. CDC (2011). Medium credibility.

Appendix G. Mathematical formula for sample size — sample size required to detect the difference of GM between two subpopulation groups defines a z test with null hypothesis GM1 = GM2 or GMmax/GMmin = 1 and alternative GM1 ≠ GM2 or GMmax / GMmin > 1, where GMmax = max(GM1, GM2) and GMmin = min(GM1, GM2). It considers power W (say 80% chance) to detect that one group's GM is at least k fold higher and gives the p-value as p = Prob(Z ≥ z) = 1 − φ−1(z) with Z ~ Normal (0,1). Given α (e.g., 0.05) and target ratio k, power is W = Prob (Z > φ−1(1 − α) − log10(k)/(S√(1/n1 + 1/n2))), where S is the expected standard deviation of log10(VL) in the population of interest; when n1 = n2 = n, W = Prob (Z > φ−1(1 − α) − log10(k)/(S√(2/n))). The required sample size is n = 2[(φ−1(1 − α) − φ−1(1 − W))S/log10(k)]^2, and tables are provided for W = 0.8 and W = 0.9 with α = 0.05.

---

### Evaluation and management of adult hypoglycemic disorders: an endocrine society clinical practice guideline [^8a1259e5]. The Journal of Clinical Endocrinology and Metabolism (2009). Medium credibility.

Regarding diagnostic investigations for hypoglycemia, more specifically with respect to initial evaluation, patients with diabetes, ES 2009 guidelines recommend to assess conventional risk factors and those indicative of compromised defenses against hypoglycemia in patients with recurrent treatment-induced hypoglycemia.

---

### Rising infrastructure inequalities accompany urbanization and economic development [^65387437]. Nature Communications (2025). High credibility.

Discussion

Our study uses satellite data to provide robust evidence of increasing urban infrastructure inequalities. We show a dominant trend of rising infrastructure inequalities in many countries. This trend contradicts economic geography and regional science theories that suggest a cyclical evolution of economic inequalities. The cyclical evolution has many explanations but is generally linked to economic expansion and contraction phases. Regional inequality rises in the expansion phase and diminishes in the contraction phase. Our results suggest that this is not the case with infrastructure inequality. One explanation for this inconsistency is that infrastructure changes are generally unidirectional: infrastructure, once built, is rarely removed. As a result, infrastructure inequalities rise during the growth phase and stay constant otherwise. Our results support this explanation by revealing a dominant trend of rising inequalities both between and within regions. Moreover, they set an expectation that infrastructure inequalities may be associated with regional (economic) inequalities during the divergence phase, i.e. when regional economic inequalities rise. Conversely, results show that inequalities decline with large-scale perturbations — such as war and conflict — that affect infrastructure availability.

Further, our findings show that urbanization and economic development underpin rising infrastructure inequalities in the long run. Population growth in urban areas and economic development are well-known drivers of urban land and infrastructure expansion. We find that these drivers also increase infrastructure inequalities within and between regions such that more urbanized and economically developed countries tend to have greater infrastructure inequalities. Consequently, rapidly urbanizing countries tend to show a faster increase in infrastructure inequalities. For example, we find that inequalities rapidly increased in China and some Southeast Asian countries during the 2000–2019 period. Increasing inequality can be a problem for urbanizing countries, as infrastructure inequalities due to their durable nature can perpetuate or amplify socioeconomic inequalities. This is especially concerning for lower-income countries that are either in the early stages of urbanization or have yet to urbanize. At the same time, these countries have a unique opportunity to mitigate these risks from the outset. Infrastructure development has been frequently argued to be an essential driver of global sustainable development. However, our findings challenge this view by highlighting the spatial inequalities it can entail. Instead, they stress the need for intentional infrastructure development prioritizing spatial equity in all countries regardless of their stage of urbanization or economic development, rather than focusing solely on aggregate development and assuming inequalities can be addressed later through equity measures.

---

### Nonlinear delay differential equations and their application to modeling biological network motifs [^7c1a1e89]. Nature Communications (2021). High credibility.

Motif IV: feedforward loop

Equipped with a multivariable generalization of 1-variable Hill regulation (Eq. (19)), we turn our attention to the feedforward motif (Fig. 6), a non-cyclic regulation network in which an input, X, regulates an output, Z, via two separate regulation arms. One arm is "direct", in which X regulates Z in a single step, while the second arm is "indirect", with X regulating an intermediate Y, which in turn regulates Z. In this way, the first arm "feeds forward" past the cascade (Fig. 6 a–b). The motif is found commonly in biological networks, comprising about 30% of three-gene regulatory interactions in transcriptional circuits. Feedforward loops are conventionally described as "incoherent" if X activates Z through one arm but represses through the other, and "coherent" otherwise (Supplementary Table 3). In this section, we show that the essential behaviors of feedforward loops are due to a difference in delays between the two inputs to Z and the logic function between the two inputs to the output Z.

---

### How to organise travel restrictions in the new future: lessons from the COVID-19 response in Hong Kong and Singapore [^d57191bb]. BMJ Global Health (2022). High credibility.

Concerns regarding COVID-19 vaccines

Concerns about COVID-19 vaccines persist, as evidence has shown that some novel variants of SARS-CoV-2 are more resistant to the existing vaccines. For instance, research suggested that the emerging omicron (B.1.1.529) variant of SARS-CoV-2 can threaten the efficacy of current COVID-19 vaccines. Apart from this, the profound vaccine inequality is impairing the vaccine effectiveness, as many underdeveloped areas still suffer from inadequate COVID-19 vaccine supply. The lack of COVID-19 vaccines has significantly impeded these regions' pandemic control efforts, making them persistent hot spots of COVID-19 transmission. These regions tend to incubate novel variants of SARS-CoV-2, including delta (B.1.167.2) and omicron, which can be transmitted more easily and evade the existing immunity.

To solve the vaccine inequality, worldwide governments have established many programmes, including the COVID-19 Vaccine Global Access (COVAX) programme to promote the global allocation of the COVID-19 vaccine. These programmes, however, are surrounded by many worrying uncertainties. A significant concern is that many high-income regions have bypassed the COVAX programme and have secured their vaccines directly from the developers. Although these rich countries only take up 16% of the global population, they have occupied 70% of the available COVID-19 vaccine doses. The severe vaccine inequality showed that many rich countries place their populations' vaccination process greatly ahead of the inoculation of vulnerable populations of underdeveloped countries. These policy makers should understand that solving the vaccine inequality is the best way to not only protect the people in low-income countries but also reduce the chance of emerging novel variants that can evade the established immunity for everyone.

---

### Standards of care in diabetes – 2025 [^ff359fb4]. Diabetes Care (2025). High credibility.

Regarding diagnostic investigations for hypoglycemia, more specifically with respect to initial evaluation, patients with diabetes, ADA 2025 guidelines recommend to obtain prompt reevaluation of the treatment plan, including deintensifying or switching diabetes medications if appropriate, in case of ≥ 1 episode of level 2 or 3 hypoglycemia.

---

### Standards of care in diabetes – 2025 [^31be65a6]. Diabetes Care (2025). High credibility.

Regarding diagnostic investigations for hypoglycemia, more specifically with respect to screening for cognitive impairment, ADA 2025 guidelines recommend to simplify diabetes treatment plans as much as possible for patients with cognitive impairment and tailor to minimize the risk of hypoglycemia.