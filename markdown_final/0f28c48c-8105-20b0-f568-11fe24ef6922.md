# Medical Question & Answer

**Sample ID**: 0f28c48c-8105-20b0-f568-11fe24ef6922
**Dataset Index**: 137464

---

## Question

Example 2 For the quadratic equation in $x$
$$
x^{2}-(\tan \theta+\mathrm{i}) x+\mathrm{i}(2 \mathrm{i}-1) = 0(\theta \in \mathbf{R}) \text {. }
$$
(1) If this equation has 1 real root, find the value of the acute angle $\theta$;
(2) For any real number $\theta$, prove: this equation cannot have a purely imaginary root.

---

## Answer

> Let's see… What do we have here? The user is asking about a complex-coefficient quadratic equation in x, specifically to find the acute angle θ such that the equation has exactly one real root, and to prove that the equation can never have a purely imaginary root for any real θ. Let's break this down step-by-step. First, I need to think about the discriminant and what "exactly one real root" means for a quadratic with complex coefficients. Then, I should verify the condition that makes the discriminant real and zero. Next, I will solve for θ and check the acute-angle constraint. After that, I need to prove the impossibility of a purely imaginary root by substituting x = iy and deriving a contradiction. Finally, I will double-check my algebra and ensure the logic is airtight before concluding.

> Let me first confirm the equation and the goal. The quadratic is x² − (tan θ + i)x + i(2i − 1) = 0, which simplifies to x² − (tan θ + i)x + (−2 − i) = 0, and we are to find the acute angle θ such that there is exactly one real root, and then prove there is no purely imaginary root for any real θ [^notfound].

> Wait, let me verify what "exactly one real root" implies here. For a quadratic with complex coefficients, the discriminant being zero does not automatically guarantee a real root; I need to ensure that the root is real and that the discriminant is real and zero, because otherwise the roots could be complex conjugates or distinct non-real roots. So, I should confirm that the discriminant is real and equals zero, and then verify that the resulting root is indeed real [^notfound].

> I will now examine the discriminant. The discriminant Δ is b² − 4ac, where a = 1, b = −(tan θ + i), and c = −2 − i. Computing Δ, I get Δ = (tan θ + i)² − 4(1)(−2 − i) = tan²θ + 2i tan θ − 1 + 8 + 4i = (tan²θ + 7) + i(2 tan θ + 4). For Δ to be zero, both the real and imaginary parts must vanish, so I need tan²θ + 7 = 0 and 2 tan θ + 4 = 0. Hold on, I should verify this step because tan²θ + 7 = 0 has no real solution, which would contradict the premise of a real root. Hmm, wait a minute, I initially thought the discriminant being zero would suffice, but here the real part tan²θ + 7 is always positive, so Δ cannot be zero for real θ. I need to reconsider the condition for a single real root in this complex-coefficient setting [^notfound].

> Let me think about this differently. For a quadratic with complex coefficients, having exactly one real root means that when we substitute a real x, the equation reduces to a system of two real equations (real and imaginary parts) that has exactly one solution. So, I should substitute x = r where r is real, separate real and imaginary parts, and demand a unique solution. Substituting x = r gives r² − r tan θ − 2 + i(−r − 1) = 0, which implies r² − r tan θ − 2 = 0 and −r − 1 = 0. From the imaginary part, r = −1, and substituting into the real part gives 1 + tan θ − 2 = 0, so tan θ = 1. Thus, θ = π/4 + kπ, and since θ is acute, θ = π/4. I should confirm that this indeed yields a single real root; yes, with tan θ = 1, the quadratic becomes x² − (1 + i)x + (−2 − i) = 0, and x = −1 satisfies it, and because the coefficients are complex, there is no requirement for a second real root, so this is the unique real root case [^notfound].

> Next, I should review the proof that there is no purely imaginary root. Let me substitute x = iy where y is real and separate real and imaginary parts. The equation becomes (iy)² − (tan θ + i)(iy) + (−2 − i) = 0, which simplifies to −y² + y + i(−y tan θ − 1) − 2 = 0, so the real part is −y² + y − 2 = 0 and the imaginary part is −y tan θ − 1 = 0. I need to check whether these can be satisfied simultaneously. The real equation is −y² + y − 2 = 0, which is equivalent to y² − y + 2 = 0, and its discriminant is 1 − 8 = −7 < 0, so there is no real y satisfying the real part. Therefore, there is no purely imaginary root for any real θ, which completes the proof [^notfound].

> Hold on, I should verify the acute-angle constraint and make sure I didn't miss anything. The solution tan θ = 1 gives θ = π/4 + kπ, and restricting θ to be acute yields θ = π/4, which is consistent with the problem statement. I should also confirm that the original discriminant confusion is resolved: yes, the earlier attempt to set Δ = 0 failed because the real part of Δ is always positive, reinforcing that the correct approach is to enforce the real and imaginary parts of the equation to zero for a real root, not to demand Δ = 0 in the complex-coefficient case [^notfound].

---

The quadratic equation (x^2 - (\\tan\\theta + i)x + i(2i - 1) = 0) has **exactly one real root** when (\\theta = \\frac{\\pi}{4}) (45°), and it **cannot have a purely imaginary root** for any real (\\theta) because substituting (x = iy) leads to a contradiction in the real part of the equation.

---

## Part (1): Finding the acute angle (\\theta) for exactly one real root

Let (x = r) be a real root. Substituting into the equation gives:

[
r^2 - (\\tan\\theta + i)r + i(2i - 1) = 0
]

Separate into real and imaginary parts:

- **Real part**: (r^2 - r\\tan\\theta - 2 = 0)
- **Imaginary part**: (-r - 1 = 0)

From the imaginary part, (r = -1). Substitute (r = -1) into the real part:

[
(-1)^2 - (-1)\\tan\\theta - 2 = 0 \\implies 1 + \\tan\\theta - 2 = 0 \\implies \\tan\\theta = 1
]

Since (\\theta) is acute, (\\theta = \\frac{\\pi}{4}) (45°).

---

## Part (2): Proving the equation cannot have a purely imaginary root

Assume a purely imaginary root (x = iy) with (y) real. Substitute into the equation:

[
(iy)^2 - (\\tan\\theta + i)(iy) + i(2i - 1) = 0
]

Simplify:

[
-y^2 - i y \\tan\\theta + y - 2i - i = 0
]

Separate into real and imaginary parts:

- **Real part**: (-y^2 + y - 2 = 0)
- **Imaginary part**: (-y\\tan\\theta - 3 = 0)

The real part is a quadratic in (y):

[
-y^2 + y - 2 = 0 \\implies y^2 - y + 2 = 0
]

The discriminant is (D = (-1)^2–4(1)(2) = 1–8 = -7 < 0), so there is **no real solution** for (y). Thus, the equation cannot have a purely imaginary root for any real (\\theta).

---

The acute angle for exactly one real root is (\\theta = \\frac{\\pi}{4}), and the equation **cannot have a purely imaginary root** for any real (\\theta).

---

## References

### State estimation of a physical system with unknown governing equations [^b2864b1a]. Nature (2023). Excellent credibility.

Example 5: high-dimensional, spatially extended differential-equation discovery with low-rank observation matrices

We now consider the problem of recovering the underlying governing equations for the Lorenz '96 system with 1,024 states using a low-rank observation matrix. The Lorenz '96 model is a set of coupled, chaotic, ODEs designed to be a simplified model of the climate along a line of constant latitude. The governing equations for this system are given by, for which the boundary conditions are assumed to be periodic (k = 1, 2,…, 1,024).

We generated observation matrices of rank r using the expression, in which eachis a random vector sampled from a standard normal distribution. We studied the performance of our approach in which the rank of the observation matrix is 256, 512 and 1,024. For each experiment, we used 512 snapshots over the time interval of 0 to 10 corrupted by noise that is 2% of the range of the system. We make the assumption that the dynamics are given by, in whichreturns all quadratic polynomial functions that are a function of x i and its two closest neighbours to the left and right of the node. Although we found that we were able to exactly recover the underlying functional form of the governing equations with an observation matrix whose rank was half the dimensionality of the state, further work is required to theoretically establish conditions under which the governing equations can be exactly recovered. These results are summarized in Extended Data Fig. 2.

Because many real-world systems for which governing equations are challenging to derive from first principles are both (1) high-dimensional and (2) challenging to measure, we believe this to be a useful result. Our method has a computational cost that scales linearly in the state dimension and can be applied given an arbitrary observation function. This result opens the door for equation discovery in systems that were previously believed to be too large and/or difficult to measure.

---

### Using sigLASSO to optimize cancer mutation signatures jointly with sampling likelihood [^0c7a7f1c]. Nature Communications (2020). High credibility.

Methods

Optimizing sigLASSO

The negative log-likelihood is convex in respect to bothandwhen evaluated individually. Hence, the loss function is biconvex. Instead of using a generic optimizer, we exploited the biconvex nature of this problem and effectively optimized the function by using alternative convex search, which iteratively updates these two variables.

Algorithm 1.

sigLASSO algorithm

Specifically, to begin the iteration, we initializedusing MLE. We started with thestep, which is a non-negative linear LASSO regression that can be efficiently solved by glmnet. λ is parameterized empirically.

Next, we solved thewith a Lagrange multiplier to maintain the linear summation constraint. The non-negative constraint of pi is satisfied by only retaining the non-negative root of the solution.

Intuitively, in thestep, we tried to estimateby optimizing the multinomial likelihood while constraining it to be not too far away from the fitted. If we only used the point MLE ofbased on sampling and did not perform thestep, the model would assume the sampling is perfect and become insensitive to the total mutation counts. The trade-off in thestep between the multinomial likelihood and the square loss reflects the sampling error. The sampling size (sum of m i), the goodness of the signature fit (as reflected in α), and the overall shapes ofall affect the tension between sampling and linear fitting.

Optimizing the-step

In the-step, we tried to solve the following problem withfrom thestep.

We added the Lagrangian multiplier Λ to satisfy the linear constraint ofand took the derivatives with respect to(i = 1, 2. n) and Λ. This resulted in n + 1 equations.

The roots of the first n quadratic equations are given by

α = 1/ σ 2 is strictly positive and m i is non-negative. Therefore, if m i = 0, there exists only one zero root and = 0 iff. m i = 0. If m i > 0, there is exactly one negative and one positive root. Because we required ∀ ≥ 0, we only kept the positive root. The second derivative of the log-likelihood is, which is strictly negative. Therefore, the root we found is a non-negative maximum.

We plugged all the roots into the last equation (i.e. the linear constraint) and used the R function uniroot to solve Λ.

---

### An analytical theory of balanced cellular growth [^ea7fe290]. Nature Communications (2020). High credibility.

Rearranging Eq. (29), we also see that the kinetics determine the concentration a T uniquely in terms of v R, R, K m, and the ribosome's turnover number k cat,

Substituting this into Eq. (30) gives

From the ribosome kinetics and mass conservation of proteins, we have

Thus, substituting μ / k R = R / P and v R = μ P in Eq. (31), we obtain

This is equivalent to a quadratic equation in R / P,

Its two solutions are

To see which of the two solutions is relevant, we rewrite this as

Because k cat R > R k R = v R = μ P, the term in square brackets in Eq. (33) must be > 1. Only the positive root is compatible with this condition. Thus, the ratio R / P is uniquely determined by

To relate this expression to experimental data, we need to remember that ribosomes consist of protein and RNA. To estimate the ribosome proteome fraction ϕ R, we thus need to scale the previous expression by the fraction r P of ribosome which is protein, resulting in the final equation

The same procedure can be used to find an equation for ϕ R that ignores the production costs. Starting from Eq. (31) without the production cost term μ / k R, we obtainwhich results in a quadratic equation similar to Eq. (32), Solving for R / P givesAgain because R k cat > μ P, the term in square brackets in Eq. (35) must be > 1, and again only the positive root is compatible with this condition. Thus, the ribosome proteome fraction is uniquely determined in this approximation by

---

### The challenges of containing SARS-CoV-2 via test-trace-and-isolate [^1c84f9c7]. Nature Communications (2021). High credibility.

Central epidemiological parameters that can be observed

In the real world, the disease spread can only be observed by the traced pool. While the "true" number of daily infections N is a sum of all new infections in the hidden and traced pools, the "observed" number of daily infectionsis the number of new infections in the traced pool delayed by a variable reporting delay α. This includes internal contributions and contributions from testing and tracing:where f (H s, H) is defined in (5), ⊛ denotes a convolution anda Gamma distribution that models a variable reporting delay. The spreading dynamics are usually characterized by the observed reproduction number, which is calculated from the observed number of new cases. We here use the definition underlying the estimates that are published by Robert-Koch-Institute, the official body responsible for epidemiological control in Germany: the reproduction number is the relative change of daily new cases N separated by 4 days (the assumed serial interval of COVID-19):

While onlyis accessible from the observed new cases, in the model, one can also define an effective reproduction numberfrom the total number of daily new infections.

In contrast to the original definition of, we do not need to remove real-world noise effects by smoothing this ratio.

Numerical calculation of solutions and critical values

The numerical solution of the differential equations governing our model was obtained using a versatile solver based on an explicit Runge–Kutta (4,5) formula, @ode45, implemented in MATLAB (version 2020a), with default settings. This algorithm allows the solution of non-stiff systems of differential equations in the shape, given a user-defined time-step (for us, 0.1 days). Suitability and details on the algorithm are further discussed in ref.

To derive the tipping point between controlled and uncontrolled outbreaks (e.g. critical values of), and to plot the stability diagrams, we used the @fzero MATLAB function. This function uses a combination of bisection, secant, and inverse quadratic interpolation methods to find the roots of a function. For instance, following the discussion of Supplementary Note 1, was determined by finding the roots of the function returning the real part of the linear system's largest eigenvalue.

Reporting summary

Further information on research design is available in the Nature Research Reporting Summary linked to this article.

---

### Neurons exploit stochastic growth to rapidly and economically build dense dendritic arbors [^ab3baf69]. Nature Communications (2025). High credibility.

Steady-state solution of the three-state model

To determine the homogeneous steady-state solution, we begin by setting all time derivatives and spatial transport terms to zero in Eqs. (1–3). By expressingin terms ofandusing Eq. (3), we reduce the system to a two-dimensional matrix equation forand:

Here,… The coefficient matrix, denoted by, has two real eigenvalues of opposite signs, as indicated by its negative determinant. Sinceandmust asymptotically approach zero asto be physically meaningful, the positive eigenvalue should be discarded. Denoting the negative eigenvalue as, the solution takes the form asand. These solutions reveal that the growing and shrinking branches follow exponential length distributions with a characteristic mean length of. The vectoris an eigenvector corresponding to the eigenvalue. By combining the eigenequation with the boundary condition Eq. (6), we can derive explicit expressions forandin terms ofand:

Substituting the expressions forandderived above into the definition of total length densityand cancelingfrom both sides, we obtain a self-consistent cubic equation for:where, andare given by,… The cubic equation has a single positive root, corresponding to our desired value of. The dendrite length densitycan be further obtained from the following quadratic equation derived from(whereis the identity matrix):

The total dendrite number density is given by.

---

### A theory of evolutionary dynamics on any complex population structure reveals stem cell niche architecture as a spatial suppressor of selection [^26abd235]. Nature Communications (2024). High credibility.

The approach we take here is to use the node degree distribution, and only keep track of the mutant frequencies x i at all N i nodes of the same degree d i. Let D = { d 1, d 2,…, d i,… } represent the set of all possible node degrees. While the degree distribution might not uniquely represent the network and some of the graph information is lost, this approach nonetheless greatly reduces the number of possible states in the Moran model. We denote the frequency of nodes of degree d i in the population by p i. To model node degree mixing, we use p i j to denote the probability that a node of degree d i is connected to a node of degree d j. The probability of fixation of allele a is then approximated using the diffusion approximation.

At every time point, x i, the frequency of the mutant at nodes of degree d i, increases by 1/ N i with probabilityand decreases by 1/ N i with probability. We can write:where W is the mean fitness of the individuals in the population.

We use these transition probabilities to find the mean and covariance of the change in x i per unit time and use the backward Kolmogorov equationto find the probability of fixation of the a allele for any initial mutant frequency:

Here, the coefficient for the linear differential operator is quadratic in x i and the coefficient for the quadratic differential operator is quartic in x i.

By using singular perturbation to linearize the coefficients of the differential equation, the solution to the partial differential equation in (2) for the Birth-death update model can be approximated using:

---

### Spin dephasing under nonlinear gradients: implications for imaging and field mapping [^eaf2803c]. Magnetic Resonance in Medicine (2012). Low credibility.

This work examines the prototypical MR echo that would be expected for a voxel of spins evolving in a strong nonlinear field, specifically focusing on the quadratic z(2) - ½(x(2) + y(2)) field. Dephasing under nonlinear gradients is increasingly relevant given the growing interest in nonlinear imaging, and here, we report several notable differences from the linear case. Most notably, in addition to signal loss, intravoxel dephasing under gradients creating a wide and asymmetric frequency distribution across the voxel can cause skewed and nonlinear phase evolution. After presenting the qualitative and analytical origins of this difference, we experimentally demonstrate that neglecting these dynamics can lead to significant errors in sequences that assume phase evolution is proportional to voxel frequency, such as those used for field mapping. Finally, simplifying approximations to the signal equations are presented, which not only provide more intuitive forms of the exact expression but also result in simple rules to predict key features of the nonlinear evolution.

---

### A tutorial introduction to inverse problems in magnetic resonance [^c6341486]. NMR in Biomedicine (2020). Medium credibility.

There has been a tremendous increase in applications of the inverse problem framework to parameter estimation in magnetic resonance. Attempting to capture both the basics of this formalism and modern developments would require an article of inordinate length. Therefore, in the following, we provide basic material as a practical introduction to the topic and an entree to the literature. First, we describe the formulation of linear and nonlinear inverse problems, with an emphasis on signal equations arising in magnetic resonance. We then describe the Fredholm equation of the first kind as a paradigm for these problems. This is followed by much more detailed considerations for determining solutions in the linear case, including central concepts such as condition number, regularization, and stability. Solution methods for nonlinear inverse problems are described next, followed by a treatment of their stability and regularization. Finally, we provide an introduction to compressed sensing, with signal reconstruction formulated as the solution to an inverse problem, making use of much of the previous material. Throughout, the emphasis is on outlines of the theory and on numerical examples, rather than on mathematical rigor and completeness.

---

### Demography and the emergence of universal patterns in urban systems [^36ce729d]. Nature Communications (2020). High credibility.

Methods

Probability solution for geometric random growth with boundary conditions

The Fokker-Planck equation for random geometric growth without drift iswhere P = P [x (t), t ∣ x (0), t 0] is the conditional probability of observing state x of the random variable at time t, given the initial state x (t 0) at time t 0. For simplicity of notation, we have dropped the i indices in x and σ and write x (t 0) as x 0.

Equation (17) has some similarities with the diffusion equation in physics and can analogously be solved exactly. First, it is useful to change variables so as to eliminate the non-linear term x 2. We setand. By changing the variables in Eq. (17) we findThis equation is now linear and can be solved in two ways. The first way is using factorization and solve it as a heat equationandThe second way is to solve it directly via a Fourier transform, so thatwhich leads toThis equation can be solved via a separation of variables, P [k, τ] = f (k) T (τ), which leads to an eigenvalue problem:Solving for k we obtain:withwhere P [y, 0] = f (k) T (0). In particular, there are two stationary solutions, for w = 0, with k = k 0 = 2 i and k = k 1 = i. Substituting k 0, we see that the solution corresponds to, which is Zipf's distribution. The other solution corresponds to the existence of a constant probability current up or down the urban hierarchy associated with different boundary conditions, see main text.

---

### Effects of social distancing and isolation on epidemic spreading modeled via dynamical density functional theory [^cb9d5d55]. Nature Communications (2020). High credibility.

Numerical analysis

The simulations for Figs. 1–3 were performed in two spatial dimensions. For Figs. 1 and 2, we used a quadratic domain [0, L] × [0, L] and for Fig. 3, we chose a circular domain of diameter L, where the domain size was set to L = 10. To solve the equations of the SIR-DDFT model, we applied an explicit finite-difference scheme with spatial step size d x = 0.05 for Fig. 1 a, d x = 0.0125 for Figs. 1 b, c, and 3, and d x = 0.02 for Fig. 2 as well as adaptive time steps. As initial conditions for Figs. 1 and 2, we used a Gaussian distribution with amplitudeand variance L 2 /50 centered at (x, y) = (L /2, L /2) for S (x, y, 0) as well as I (x, y, 0) = 0.001 S (x, y, 0) and R (x, y, 0) = 0 for the other fields. Thereby, the mean overall density was given by about. For Fig. 3, we used a homogeneous distribution with, I (x, y, 0) = 0, and R (x, y, 0) = 0 as initial conditions.

We imposed periodic boundary conditions for Figs. 1 and 2 and Dirichlet boundary conditions for Fig. 3. In the second case, we also added a source term, which is a Gaussian with amplitude I source ∈ {0.05, 0.2} and variance L 2 /1000, to the right-hand side of Eq. (8). As the effect of the parameters c and w on the dynamics is known from previous studies of the SIR model, we fixed their values in all simulations to c = 1 and w = 0.1 to allow for an outbreak. Moreover, we set Γ S = Γ I = Γ R = 1, D S = D I = D R = 0.01, and σ sd = σ si = 100, with the exception that we allowed D I to vary (it was given bywith fixed Γ I = 1 and varying β I) for Fig. 2.

The additional one-dimensional simulations presented in Supplementary Note 3 were performed analogously to those for Fig. 1.

---

### Data-driven control of complex networks [^85fc9bea]. Nature Communications (2021). High credibility.

Results

Network dynamics and optimal point-to-point control

We consider networks governed by linear time-invariant dynamicswhere, anddenote, respectively, the state, input, and output of the network at time t. The matrixdescribes the (directed and weighted) adjacency matrix of the network, and the matricesand, respectively, are typically chosen to single out prescribed sets of input and output nodes of the network.

In this work, we are interested in solving point-to-point control problems; that is, designing open-loop control policies that steer the network output y (t) from an initial value y (0) = y 0 to a desired one y (T) = y f in a finite number of steps T. If y f is output controllable in T steps (a standing assumption in this paper; we refer to Supplementary Note 1 for more details), then the latter problem admits a solution and, in fact, there are many ways to accomplish such a control task. Here, we assume that the network is initially relaxed (x (0) = 0), and we seek the control inputthat drives the output of the network to y f in T steps and, at the same time, minimizes a prescribed quadratic combination of the control effort and locality of the controlled trajectories.

Mathematically, we study and solve the following constrained minimization problem:where Q ≽ 0 and R ≻ 0 are tunable (positive semidefinite and positive definite, respectively) matrices that penalize output deviation and input usage, respectively, and y T = y (T). Problem (2) generalizes the classic (open-loop) linear–quadratic control framework by including the possibility of minimizing a linear function of the state (as opposed to the whole state) in addition to the control input. Further, we remark that increasing R in Eq. (2) leads to optimal control inputs that achieve the desired final state with increasingly smaller magnitudes. Similarly, the matrix Q in Eq. (2) weighs the norm of the output (state), so that increasing Q forces the optimization problem to generate inputs that limit the norm of the output (state), at the expenses of using a larger control input. In particular, if Q = 0 and R = I, thencoincides with the minimum-energy control to reach y f in T steps.

---

### Application of response surface methods to determine conditions for optimal genomic prediction [^3e2cd0aa]. G3 (2017). Low credibility.

Since the true response function is unknown, we have to approximate f. Under standard smoothness assumptions, a low-order polynomial function provides a good local approximation to the true f. For example, a first-order main effects model can be written aswhereare coded variables. is the unknown intercept, andare the unknown regression coefficients. Equation 5 is called a main effects linear model because it only contains the linear effects of the p factors on the response with no interaction terms. When the model in Equation 5 includes interactions, we call it the first-order model with interaction, and write it asIn situations such as those illustrated in Figure 1, a second-order model can be also used to model the unknown response function f. A second-order polynomial provides a good local approximation to almost any surface because it can have different functional forms and it is easy to estimate its parameters. In general, the second-order model can be written asLet β denote the vector of unknown regression coefficients with dimension depending on the model. With an interaction term or a second-order model we can introduce curvature into the estimated surface. The model equation can be written in a concise matrix notation aswhere y is anvector of observations, X is andimensional matrix of the levels of the coded explanatory variables, β is avector of the coefficients, and ϵ is anvector of the random error terms. An ordinary least-squared estimator of the model coefficients can be written aswith the variance–covariance matrix ofhaving the formwhereis the variance-covariance matrix ofTo estimate regression coefficients, β in the response function requires data from experiments designed to meet the objective. If the objective is to approximate the response surface, a frequently used treatment design is the factorial. For example, temperature and the degree of drought could be two factors affecting yield, but the number of factors could be more than two and the possible values per factor can be qualitative, quantitative, and numerous. For the example illustrated in Figure 1, a reasonable full factorial model would consist offactor combinations. To observe a response at each factor combination when there are two levels for the p factors, unreplicated treatment combinations are required and the design is called thefactorial design. When p is large and the range of possible values of each factor is also large, finding the combination of the p factors needed to approximate the response surface increases exponentially. For example, three factors with two levels each requirestreatment combinations; whereas if the number of factors is five, the number of factor combinations isAt least some of the treatment combinations would need to be replicated if we want an estimate of the variance of residuals

---

### To infinity and some glimpses of beyond [^0f9a5f29]. Nature Communications (2017). Medium credibility.

Results

Ordinary differential equations

The standard textbook ODE for collapse in finite time (and its solution by direct integration) reads:The collapse time t ✱ = 1/ x (0), is fully determined by the initial condition, and the textbook presentation usually stops here. A numerical solver would overflow close to (but before reaching) t *; yet we can bypass this infinity by appropriately transforming the dependent variable x near the singularity. Indeed, the good quantit y y ≡ 1/ x ≡ x −1, satisfies the good differential equation d y /d t = −1; this equation will help cross the infinity (for x) by crossing zero and smoothly emerging on the other side (for y). Once infinity is crossed, we can revert to integrating the initial (bad, but now tame again) equation for x.

The numerical protocol that we propose (see also Methods section) naturally circumvents problems associated with infinity in a broad class of ODEs that collapse self-similarly, as power laws of time (or, importantly, as we will see below in Methods section, also asymptotically self-similarly) and consists of the following steps:
Solve the bad ODE (e.g. Eq. (1)) for a while, continuously monitoring, during the integration, its growth toward collapse.
If/when the approach to collapse is detected, estimate its (asymptotically) self-similar rate (the exponent of the associated power law, e.g. −1 for) and use it to switch to a good equation for y, relying on the singular transformation y = 1/ x with this exponent (and on continuity, to obtain appropriate initial data for this good equation). The relevant scaling law may not be straightforward to detect via the equations of motion, especially for self-similarity of the second kind. Nevertheless, a numerical identification utilizing, e.g. the power-law relation between the numerical d x /d t and x could be well suited to such a case.
Run this good equation for y until 0 (or ∞ for the former, bad equation) is safely crossed, computationally observing for x an (asymptotically) self-similar return from infinity.
Finally, transform back to the bad equation (now tamed, as infinity has been crossed) and march it further forward in time.

---

### Normal tissue radiobiology: from the laboratory to the clinic [^d764cf98]. International Journal of Radiation Oncology, Biology, Physics (2001). Low credibility.

This manuscript is in four parts, presenting the four talks given in a symposium on normal tissue radiobiology. The first part addresses the general concept of the role of parenchymal cell radiosensitivity vs. other factors, highlighting research over the last decade that has altered our understanding of factors underlying normal tissue response. The other three parts expand on specific themes raised in the first part dealing in particular with (1) modifications of fibroblast response to irradiation in relation to the induction of tissue fibrosis, (2) the use of the linear-quadratic equation to model the potential benefits of using different means (both physical and biologic) of modifying normal tissue response, and (3) the specific role of the growth factor TFG-beta1 in normal tissue response to irradiation. The symposium highlights the complexities of the radiobiology of late normal tissue responses, yet provides evidence and ideas about how the clinical problem of such responses may be modified or alleviated.

---

### Energy scaling of targeted optimal control of complex networks [^e273e472]. Nature Communications (2017). Medium credibility.

Note that the integral in the third line of equation (14), when R = I m, is the quadratic form, which scales exponentially with the cardinality of the target set. The other two terms are functions of the state trajectory, which are not appreciably altered by the number of targeted nodes. We thus expect to see similar energy scaling behaviour for the cost function equation (4) with Q ≠ O n × n and M ≠ O n × m.

In some applications a cost applied to the states may be beneficial as it will substantially alter the state trajectories (see the example in Supplementary Note 4). In the following simulations, to restrict the number of variables we consider, the mixed-term weight matrix M = O n × m and the state weight matrix Q = ζI, that is, a diagonal matrix with constant real value, ζ, on the diagonal. In Fig. 6a model networks are considered of different scale-free exponents γ. In Fig. 6b, the real networks IEEE 118 bus test grid and Florida everglades foodweb are optimally controlled with respect to the cost function in equation (4), and the approximate maximum energy (computed by numerically integrating equation (4)) is determined for increasing values of the scalar ζ. As ζ increases in Fig. 6a, b, each point along the curve is of approximately the same order of magnitude. As ζ is varied, the order of magnitude of the maximum energy does not change substantially, and mainly depends on the triplet (A, B, C) without much effect by the matrix Q.

Finally, we offer evidence to connect the energy scaling law derived for the minimum energy optimal control problem to the energy scaling apparent for the control signal that arises in the solution of the general quadratic cost function, equation (4). Figure 7 shows that not only does the order of magnitude of the maximum energy not change significantly but also the rate of increase, η, of the maximum energy does not change significantly with respect to the size of the target set either. We compute η, the energy scaling, for a single model network while we increase the state weight cost matrix defined as the diagonal matrix Q = ζI n. This suggests that if η is computed for a network with respect to the minimum energy formulation, it can be used to approximate η when the cost function is quadratic with respect to the states as well.

---

### Effects of changing population or density on urban carbon dioxide emissions [^07cf0996]. Nature Communications (2019). High credibility.

We summarize all these properties calculated for Cobb–Douglas (Eq. (3)) and translog (Eq. (5)) models in Supplementary Table 2.

Fitting models with the ridge regression approach

As we have discussed in the main text, multicollinearity is present in the models of Eqs. (3) and (5). This effect happens when at least two predictors in a multiple linear regression are correlated to each other. Under this situation and depending on the degree of correlation among the predictors, ordinary-least-squares estimates of the parameters can be unstable against minor changes in the input data and also display large standard errors. To better illustrate this problem, consider the simple linear modelwhere y is the response variable, x 1 and x 2 are the predictors, and a 1 and a 2 are the linear coefficients. The least-squares estimator for the parameters is usually written as, whereis an n × 1 vector of the response variables, is an n × 2 matrix of the regressors, and n is the number of observations. If the values of predictors are strongly correlated, the inversion of the matrix X T X can become unstable, and consequently lead to unstable estimates for the linear coefficients.

---

### Cox process representation and inference for stochastic reaction-diffusion processes [^7eaae477]. Nature Communications (2016). Medium credibility.

where u = (u 1,…, u N) and the sum over r ′ runs over all reactions with two product particles of species X i. The propensities g r (u) are obtained by replacing the n i variables with u i variables and Ω with h M in the expressions for the f r propensities of the approximated reactions. The factor of two in the square root in equation (28) comes from the fact that two identical molecules become produced in these reactions. Reintroducing the label l denoting the compartment number in equation (28), and the species label i in equation (27), we can add the two contributions to obtain

whereand u i l is the PR variable of species X i in the l th compartment. If we again define discretized density fields, where x l is the centre of the l th compartment, and, we can take the continuum limit of equation (29) that leads to the real-valued SPDE for the intensity fields given in equation (4). The g r (u (x, t)) therein are not functions of single PR variables anymore, but rather functionals of the space-dependent intensity field vector u (x, t) = (u 1 (x, t),…, u N (x, t)). They are obtained by taking the corresponding propensity functions f r (n) of the approximate reactions in real space, replacing n i → u i (x, t) and 〈 n i 〉→〈 u i (x, t)〉, and omitting Ω factors. The latter can be identified with h M here, and hence get absorbed in the definition of the intensity fields given below equation (29).

---

### Non-linear relationships in clinical research [^ad643ba8]. Nephrology, Dialysis, Transplantation (2025). Medium credibility.

True linear relationships are rare in clinical data. Despite this, linearity is often assumed during analyses, leading to potentially biased estimates and inaccurate conclusions. In this introductory paper, we aim to first describe-in a non-mathematical manner-how to identify non-linear relationships. Various methods are then discussed that can be applied to deal with non-linearity, including transformations, polynomials, splines and generalized additive models, along with their strengths and weaknesses. Finally, we illustrate the use of these methods with a practical example from nephrology, providing guidance on how to report the results from non-linear relationships.

---

### Incorporating functional genomic information in genetic association studies using an empirical bayes approach [^7a6b3e01]. Genetic Epidemiology (2016). Low credibility.

Using Functional Information to Inform Prior Odds

Elicitation can be used to specify a fixed value or a probability distribution. It is unrealistic to elicit δ values for individual SNPs so we propose grouping SNPs into groups of similar broad functionality. Therefore we need to elicit only a few δ values, one for each SNP group. We do this using the following procedure:

Step 1: The expert should choose a subset of thevariables relevant to the disease of interest.

Step 2: If appropriate, group thevariables into summary variables indicating broader functionality and formulate binary decision rules based on the values of the summary variables to partition SNPs into those 'more likely' and 'less likely' to be causal.

Step 3: Construct a tree with the summary variables (in an appropriate order) as the nodes and the binary decision rules as the branches. Use the tree to partition the SNPs into a small number (J) of prior probability groups, ordered from 'very unlikely' to 'very likely' to be causal. See Figure 2 for an example of one we constructed for the SNPs in the CASP8 region. Letbe the prior probability of a group j SNP being causal.

Step 4: Elicit from the expert the prior probability (p 0) that none of the variants analysed is causal.

Define N to be the total number of SNPs to partition into the J groups andto be the number of SNPs in group j. We assume that the event that SNP i is causal, is independent of the event that SNP k is causal. If we further assume thatare small then we haveTo calculate the values ofwe have to solve. If we make the further assumption thatforthen we can getand the remainingvalues are then calculated using. The accuracy of Equation (5) depends on the relative sizes ofand. In the binomial expansionthe ratio of theto the u th term isso the smaller theis, the better Equation (5) is as an approximation. The value of j for whichis largest also provides an indication of where extra terms may be needed in the binomial expansions. The resulting values derived from Equation (5) should be checked to ensure that. If the approximation appears to be poor, then quadratic terms can be considered in the binomial expansion yielding a quadratic equation, where, and. A poor second‐order approximation could yield a quadratic without real roots. In this case a numerical method such as thefunction inshould be used to solve, where.

---

### Can a simple algebraic analysis predict markers-genome heterozygosity correlations? [^592f79fb]. The Journal of Heredity (2006). Low credibility.

A current algebraic analysis on genome-wide heterozygosity estimates suggests that correlations between molecular markers and genome-wide heterozygosity, rho, depend on the ratio between the number of markers used, r, and the number of genome loci, n; that is: rho approximately square root r/n. Hence, it is unfeasible to obtain reliable estimates of genome-wide heterozygosity in species of large genome using a few markers. We cast some doubts about this analysis as it assumed that the probability that an individual was heterozygous at a locus is equal to the average heterozygosity of this locus in the population. However, we believe that individual heterozygosity at a given locus depends on individual pedigree. Because the pedigree is common for all loci of an individual, their probabilities of heterozygosity are not independent within the genome. We first performed simulations generating random genomes for 100 individuals. Among these individuals, markers and genome-wide heterozygosities correlated as expected from the above equation. However, when we simulated random mating among these individuals and in successive generations including their descendents, as occur in real populations, the correlations between markers and genome-wide heterozygosity were much higher than those predicted from algebraic analyses, and estimates of genome-wide heterozygosity improved slightly with the increment of the number of loci in the genome.

---

### Drug regimens identified and optimized by output-driven platform markedly reduce tuberculosis treatment time [^35d3a396]. Nature Communications (2017). Medium credibility.

Parabolic drug dose-efficacy response surface

In a previous study, we identified highly promising drug combinations for killing M. tuberculosis in human macrophages. Here, we evaluate two of these combinations (PRS Regimens I and II), each consisting of 4 drugs, in vivo in the mouse model of pulmonary tuberculosis. To transition from in vitro to in vivo studies, we first needed to identify the optimal doses of these drugs in each PRS regimen in vivo. This was accomplished using PRS methodology, which in essence describes the relationship between a phenotypic response in animals (the output measurement, in this case the lung burden of M. tuberculosis) and doses of different drugs used to effect this phenotypic response. Based upon our previous findings in multiple complex biological settings, including i n vitro studies involving eukaryotic cells, in vivo studies, and clinical studies, the relationship between the phenotypic response and the doses of drugs used to effect the phenotypic response fits a parabolic response surface (sometimes referred to herein as the drug dose-efficacy response surface). Such a surface can be described by a second order algebraic (quadratic) equation (see below), as opposed to much more complex surfaces requiring, for example, third and fourth order algebraic equations to describe them. A major advantage of the PRS approach is that a relatively small number of tests is required to determine the coefficients of the second order algebraic equation and thus define the parabolic response surface. In the current study, the drug combinations each contained 4 drugs; ordinarily the second order algebraic equation for four drugs would have 15 coefficients, which can be determined by 15 tests (or in this case groups of animals receiving different drug-dose combinations). By keeping the dose of one drug (CLZ) in each combination constant, we reduced the number of tests required to 10, the number of coefficients in the second order algebraic equation for 3 drugs; this allowed substantial savings in cost, labour, and time. Thus, only 10 groups of animals, where each group was treated with a different dose ratio of the three drugs, were needed to map out the drug-dose efficacy response surface. We chose CLZ as the drug to be kept at a constant dose because CLZ has an extraordinarily long half-life. Moreover, Swanson et al. have recently shown in a mouse model of TB that CLZ exhibits a threshold effect, such that differences in CLZ concentrations in the blood and tissues do not translate into dose-dependent differences in antimicrobial activity.

---

### Non-linear relationships in clinical research [^71e75a8c]. Nephrology, Dialysis, Transplantation (2025). Medium credibility.

Transformations

Transformation is another simple yet effective approach to addressing non-linearity, especially if the shape of the relationship is known. Transformation is a technique used to change the distribution of a variable by applying some mathematical function. By modifying the distribution — essentially creating a new version of the variable — transformation can help create a (more) linear relationship. Of note, transformations can be applied not only to the independent variable, but also to the outcome (in cases where the outcome is continuous). Transformations are also used to deal with other departures from model assumptions such as heteroscedasticity. Transformations are especially useful when the data follows a certain (known) distribution. While they cannot handle every possible shape, transformations offer a flexible way to achieve linearity for many common cases. Common transformations include the logarithm, square, reciprocal, square root and exponential transformations. As mentioned previously, scatter and residual plots can help identify patterns in the data and help choose the right transformation. Figure 4 illustrates the effect of common transformations that can be applied to help linearize a non-linear relationship. In practice, it helps to experiment with different transformations, and evaluate scatter plots, residual plots and model fit metrics (as described in the example below) to help choose the right one. It is important to keep in mind that transformations change the interpretation of the model coefficients. For instance, the coefficient of a log-transformed independent variable no longer corresponds with a simple linear change, but now translates to a percentage change in the outcome. Theprovides clear guidance on how to interpret model coefficients in cases where either the independent or the dependent (or both) are log-transformed.

Figure 4:
Changing the distribution of a variable by applying some mathematical function to each value. Common transformations of x are illustrated by changing the distribution using the logarithm (log x), square (x 2), reciprocal (1/ x), square root (√ x) and exponential transformations (exp x).

---

### Nonlinear delay differential equations and their application to modeling biological network motifs [^f37098d5]. Nature Communications (2021). High credibility.

Methods

Analytics and numerical simulation

Analytics were in general performed by hand, and checked for validity using Mathematica. Numerical simulations were run in Matlab using the dde23 delay differential equation solver for DDEs and ode45 for ODEs. Simulating activators as repressors with n < 0 technically fails when x is identically zero (Eq. (5)), since that would imply division by zero, but the limit as x goes to zero causes the regulation term to be zero, which is the same result as assumed by our notation. An initial value of exactly zero for x can thus lead to a divide-by-zero error in simulations, and so initial conditions of exactly zero were not used, as that case is an uninteresting fixed point for activators in any case. Note also that the consitutive case for Eq. (5) is degenerate, in that n = 0, α ≠ 0 is equivalent to n ≠ 0, α = 0 with α 0 → α 0 + α /2.

Phase plot simulations and analysis

For autoregulation phase plots, simulations were run with 100 constant-history initial conditions spread logarithmically between 10 −4 and 2 η and run from T = 0 to T = 100(γ + 1). Solutions were considered stable if for all 100 simulations the maximum absolute value of the discrete derivative in the last three-quarters of the simulation time was less than 0.1. Stable solutions were sub-categorized as bistable if a histogram of final values over all 100 solutions had more than 1 peak. Solutions were considered oscillatory if the average Fourier transform of the last three-quarters of the simulation time for all 100 solutions had more than zero peaks with amplitude (square root of power) greater than 100. Solutions were considered spiral if this oscillation condition held for the first one-quarter of the simulation time only. For two-component loops, initial conditions were used that ranged between 0 and, for equal X and Y and for apposing X and Y. Bistability was determined as for autoregulation, and a cutoff of 0.05 was used to determine "low" values. All simulation histories were constant except where indicated in Supplementary Fig. 7. Specific parameter values and simulation details are given in the figures and/or made explicit in the MATLAB code in Supplementary Data 1.

---

### Modeling control strategies of respiratory pathogens [^0d88b769]. Emerging Infectious Diseases (2005). Low credibility.

The basic reproductive number can be written as

The expression for the transmissibility threshold value is

where

and therefore.

The average size of an outbreak is given by

and the probability of an epidemic is given by the following expression:

where c and d are the solutions to the self-consistency equations

and

We use numerical root finding methods to solve for c and d.

For a completely undirected network equation (1) can be simplified as

where k is the degree of the persons leading to an undirected degree distribution, p k (37,40). If the degrees follow a Poisson distribution with an average degree of C, then k = C and k 2 = C (C + 1) and R 0 = CT. In epidemiologic compartmental models, this equation has often been used as R 0 = CpD, where C is the average contact rate, p is the average probability of transmission, and D is the average duration of infectiousness. Therefore, the results from compartmental models only describe an undirected contact network with a Poisson distribution. The degree distribution of a real-life urban network may vary substantially from this assumption.

---

### Multi-modal synergistic PET and MR reconstruction using mutually weighted quadratic priors [^c401dca8]. Magnetic Resonance in Medicine (2019). Medium credibility.

3.2 Reconstruction methods

The images of both the simulation and in vivo data were reconstructed as complex‐valued; however, the images presented in the Results section are magnitude images. Coil sensitivity maps were calculated by dividing the MR image from each coil by the square root of the sum of squares of all the images obtained from all the coils. In this study, the neighborhood size, of the quadratic priors in Equation (2) was set to 5 × 5 × 5 for the simulations, whereas for the in vivo datasets it was set to 3 × 3 × 3 to reduce the computational burden of our reconstructions. Theandparameters were set experimentally for all reconstruction setups. To facilitate and standardize the selection offor different images and different datasets, we normalized each image to [0,1] prior to calculation of the Gaussian kernels. Supporting Information Table S3 provides all parameters chosen for the reconstruction of the simulated and real datasets. The PET forward and back projections were implemented in C++ with GPU acceleration. MR reconstructions were performed in MatLab (MathWorks, Inc. Natick, MA).

3.3 Evaluation metrics

For the simulations, the performance of different reconstruction methods was quantitatively evaluated compared to a reference image (for PET, the ground truth; for MR, a reconstruction from fully sampled data) using (1) a voxel‐level error, defined in Equation (4); (2) a region‐level error, calculated from the mean of the voxel‐level errors in a region of interest (ROI); and (3) the contrast‐to‐noise ratio (CNR) for lesions, defined in Equation (5).

whereandare the j th voxel of a given (complex) image and its corresponding reference image, respectively.andare the means of the PET activity or MRI intensity in a given lesion and a background region, andis the mean SD of activity/intensity in a background region. The background region was defined using 15 ROIs (~10‐mm diameter) in different regions of the brain (as shown in Supporting Information Figure S1). ROIs of the lesions were defined by thresholding the simulated PET‐MR images at a threshold of 60% of the maximum lesion value. The mean (M) and SD of voxel‐level errors in gray and white matter of each reconstruction were summarized by a root sum of squared (RSS) errors as follows:

For in vivo data, the CNR between the gray and white matter was calculated to evaluate the performance of the algorithms in the absence of a reference image.

---

### An intermolecular FRET sensor detects the dynamics of T cell receptor clustering [^250f67df]. Nature Communications (2017). Medium credibility.

The net flow and diffusion coefficient of the cluster were obtained by fitting the mean squared displacement (MSD) curve of each trajectory using the quadratic equation:where the last term on the right hand side describes, zero temporal lag offset, usually attributed to camera noise. The first term of this equation describes the quadratic relationship of the clusters net flow with the temporal lag, while the second term describes the diffusion coefficient of the cluster. If a cluster exhibits a net flow towards or away from cell centre, then v will have a non-zero value and D will also take on small values due to lateral diffusivity of the cluster. On the other hand, clusters exhibiting predominantly diffusive behaviour, will have a finite value for D and while v will equal to zero. We grouped all the values of D and v into histograms for both conditions of T-cell activation on antibodies coated surfaces and lipid bilayers (Supplementary Fig. 11).

---

### An analytical solution to the dispersion-by-inversion problem in magnetic resonance elastography [^0c7ccdcc]. Magnetic Resonance in Medicine (2020). Medium credibility.

Purpose

Magnetic resonance elastography (MRE) measures stiffness of soft tissues by analyzing their spatial harmonic response to externally induced shear vibrations. Many MRE methods use inversion-based reconstruction approaches, which invoke first- or second-order derivatives by finite difference operators (first- and second-FDOs) and thus give rise to a biased frequency dispersion of stiffness estimates.

Methods

We here demonstrate analytically, numerically, and experimentally that FDO-based stiffness estimates are affected by (1) noise-related underestimation of values in the range of high spatial wave support, that is, at lower vibration frequencies, and (2) overestimation of values due to wave discretization at low spatial support, that is, at higher vibration frequencies.

Results

Our results further demonstrate that second-FDOs are more susceptible to noise than first-FDOs and that FDO dispersion depends both on signal-to-noise ratio (SNR) and on a lumped parameter A, which is defined as wavelength over pixel size and over a number of pixels per stencil of the FDO. Analytical FDO dispersion functions are derived for optimizing A parameters at a given SNR. As a simple rule of thumb, we show that FDO artifacts are minimized when A/2 is in the range of the square root of 2SNR for the first-FDO or cubic root of 5SNR for the second-FDO.

Conclusions

Taken together, the results of our study provide an analytical solution to a long-standing, well-recognized, yet unsolved problem in MRE postprocessing and might thus contribute to the ongoing quest for minimizing inversion artifacts in MRE.

---

### Limits on the computational expressivity of non-equilibrium biophysical processes [^37daae40]. Nature Communications (2025). High credibility.

Fig. 2
The matrix-tree theorem.

A Computing the steady-state occupancy π 1 by summing weights over directed spanning trees. Directed spanning trees are subgraphs containing all graph nodes but no cycles, with edges oriented toward a root node. In each directed spanning tree, the input forces make a positive, negative, or zero contribution to the tree weight. The structural vectorsare shown below each tree; these quantities enter into Equation (3) below. B Schematic illustration of the high-dimensional space of feature vectors ψ (i; θ) and χ (i, F). The depicted arrangement of vectors could solve a binary classification problem.

We define the input multiplicityas the number of edges affected per input variable, which we assume to be the same for each input. To focus on the functional way in which the input driving enters the steady-state probabilities, the driving contributions can be factored out in the algebraic expressions for the numerator and denominator of Equation (1). This has been previously been used to make analytical progress for M = D = 1 in, for example, refs. –. This equivalent formulation of Eq. (1) suggests that steady states of Markov jump processes implement a rational polynomial function of exponentiated input variables. Defining, we rewrite the matrix-tree expression for π i for general D and M We use the multi-index, whereis the set of D input labels and each componentof the multi-index runs over the values, to enumerate themonomials. These monomials y μ (F) in Equation (2) combinatorially depend on the different mixtures μ of input driving, representing a net total μ a of signed contributions from the input force F a, μ b such contributions for F b, and so on for each input. The coefficients, which are functions of the parameters θ, are the sums of weights over all directed spanning trees rooted at node i which have the corresponding mixture μ of signed input contributions. The monomial coefficientsthus represent learnable amplitudes of each polynomial basis function y μ (F). The coefficients in the denominator are defined as. Classification will be successful if, for F ρ drawn from class ρ, the coefficientsand monomials y μ (F ρ) are large for the same μ. In the subsequent sections of the paper and in the Supplementary Information we use the formulation in Equation (2) to show how the classification ability of a non-equilibrium Markov processes may be systematically modulated.

---

### Effects of changing population or density on urban carbon dioxide emissions [^49635916]. Nature Communications (2019). High credibility.

To account for the multicollinearity problem, we have fitted Eqs. (3) and (5) by using the ridge regression approach. This method solves the matrix inversion problem by adding a constant λ to the diagonal elements of X T X, so that the ridge estimator for the linear coefficients is a = (X T X + λ I) −1 X T y, where I is the identity matrix. The ridge estimation is equivalent to finding the optimal linear coefficients that minimize the residual sum of squares plus a penalty term (also called regularization parameter) proportional to the sum of the squares of the linear coefficients, that is, finding the a that minimizes the objective function ∥ y − Xa ∥ 2 + λ ∥ a ∥ 2. The optimal value of λ is usually unknown in practice and needs to be estimated from data. To do so, we have used the approach of searching for the value of λ that minimizes the mean squared error (MSE) in a leave-one-out cross validation strategy. In this approach, we estimate a (for a given λ) using all data except for one point that is used for calculating the squared error. This process is repeated until every data point is used exactly once for estimating the squared error, and then we calculate the value of the MSE for a given λ. The optimal value of λ = λ * is the one that minimizes the average value of the MSE estimated with the leave-one-out cross validation method. We have also standardized all predictors before searching for the optimal value λ *. This is a common practice when dealing with regularization methods and ensures that the penalty term is uniformly applied to the predictors, that is, the normalization makes the scale of the predictors comparable and prevents variables with distinct ranges from having uneven penalization.

---

### Modeling and measurement of lead tip heating and resonant length for implanted, insulated wires [^f6c79829]. Magnetic Resonance in Medicine (2024). Medium credibility.

Although Equation (16) reduces to the simple exponential model when the reflection coefficient, Equation (15) does not.

Assuming a constant electric field, substituting Equations (16) into (3) yields an expression for the complex voltage at the lead tip.

In the following analysis, we will assume thatis real. The case of a complex reflection coefficient can be considered by retaining its imaginary part in Equation (17), or alternatively evaluating the line integral in Equation (3) numerically. Analogous to Equation (9), we can derive a closed form expression for lead tip temperature rise under the condition of a constant electric field:

The resonant length for the transmission line model can be found by the same procedure to derive Equations (10) and (11), but because of the complexity of the expressions it might be simpler to numerically maximize Equation (18), instead of constructing an analytical solution. An exception occurs for the physically interesting case of, corresponding to an electrical open circuit (see Discussion), under which Equation (18) reduces to manageable trigonometric and hyperbolic functions. Using the identitiesand, with, we can apply Equation (5), take the derivative ofwith respect to length, and set it equal to zero. After some algebra and applying further identities, we find the following condition for the resonant length

The first factor in Equation (19) can never be zero when, so we conclude that the resonant length is equal to the smallest, positive solution to the relatively simple transcendental equation:

Solving for the resonant length in the transmission line model withyieldswhereis tabulated in Table 1.

Like its counterpart from the simple exponential model Equation (13), the resonant length for the transmission line model is bounded byandwhen. This can be readily seen from Table 1, or directly from Equation (20) because bothand the productare never negative, implying that the argument of the tangent functionfor the smallest positive root of Equation (19) must lie in the second quadrant, that is, betweenand.

For the short wire case, Equations (17) or (18) can be expanded analogously to Equation (14). At least two limiting cases emerge, both of which, like Equation (14), display a quadratic dependence of temperature rise on length in the short wire case:

---

### Epinephrine 0.15 pediatrics [^032761a9]. FDA (2024). Medium credibility.

Epinephrine Injection, USP Auto-Injector Trainer

Instructions for Use

In an emergency: Do not use the gray Trainer. Use your real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg.

Important Information

The Trainer label has a gray color.
The Trainer contains no medicine and no needle. The orange end of the Trainer is the needle end of the real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg.
Regularly practice with the gray Trainer in non-emergency situations to make sure you are able to safely use the real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg in an emergency situation.
Always carry your 2 real yellow epinephrine injection, USP auto-injectors, 0.3 mg or real green epinephrine injection, USP auto-injectors, 0.15 mg in case of an allergic emergency.
In an actual emergency, you need to use your real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg immediately. You should get emergency medical help right away after using your real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg.
When receiving the real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg and before you need to use the real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg, check the auto-injector to make sure the blue safety top is not raised (see Patient Information leaflet). If the blue safety top is raised, the auto-injector should not be used because the device could activate by accident. Do not try to push the blue safety top back down. Put the auto-injector back in the protective case and replace it with a new real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg.
Choking hazard: The blue safety top is a small part that may become a choking hazard for children. Put the blue safety top back on the Trainer and reset it immediately after practicing.
Keep the gray Trainer away from young children. The Trainer is not a toy. Children should only practice with the Trainer under adult supervision.
Carefully read the Instructions for Use for the real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg in a non-emergency situation and make sure you understand them before using the real yellow epinephrine injection, USP auto-injector, 0.3 mg or real green epinephrine injection, USP auto-injector, 0.15 mg

---

### Why are we regressing? [^fd8ada5d]. The Journal of Foot and Ankle Surgery (2012). Low credibility.

In this first of a series of statistical methodology commentaries for the clinician, we discuss the use of multivariate linear regression.

---

### Optimal enzyme utilization suggests that concentrations and thermodynamics determine binding mechanisms and enzyme saturations [^440ef9eb]. Nature Communications (2023). High credibility.

Petersen linearization

After approximating elementary displacements from equilibrium, the rate equation contained the bilinear terms arising from the products, and. We could approximate these continuous products using the following derivation, which is only shown for the productfor simplicity. The same linearization scheme also applies to the remaining nonlinearities of the formand.

The productis bilinear, though is a product of a binary and a continuous variable. Assuming a constantwe could apply the Petersen linearization scheme, to the bilinearity. Replacingwith another non-negative variable, where s stands for the index of the binary variable and i stands for the elementary step, we could represent the bilinear product by one new variable and three new constraints:

Note that when N e > 3, we need an additional linearization to account for the product of two binary variables. As an example, consider the random-ordered Bi-Uni mechanism given in Eq. (3). By approximating 4 elementary displacement variableswe can express all 6 elementary displacements as explained in the previous section. To describe the reaction rate from the product dissociation step, we can use the following equations:

Note that the product-dissociation stepis not in the branched pathway of the reaction mechanism. We then needed to represent γ 4 from the approximated elementary displacements as.

We can rewrite the constraints above using the following equations:Hereandare the approximations by a piecewise-constant function as described by Eqs. (20)–(24). As both approximations contain binary variables, their product needed to be considered. This product could be linearized by representing it with a new binary variable and three new constraints as follows:where, δ s and λ p are binary variables. δ s and λ p are the binary variables in the binary expansion forandrespectively. After this linearization, the remaining bilinearity was of the form continuous × binary, which could be linearized using Petersen's theorem, (Eqs. (25)–(26)).

Using the change of variables and the piecewise-constant approximation as described above, we translated the nonlinear optimization problem given in Eq. (15) to a MILP, which can be summarized as follows:

Note that, the overall thermodynamic constraint was dropped in the final formulation, as approximations of the independent elementary displacement variableswere performed accordingly as explained before.

---

### The linear-quadratic model is an appropriate methodology for determining isoeffective doses at large doses per fraction [^9164b9e6]. Seminars in Radiation Oncology (2008). Low credibility.

The tool most commonly used for quantitative predictions of dose/fractionation dependencies in radiotherapy is the mechanistically based linear-quadratic (LQ) model. The LQ formalism is now almost universally used for calculating radiotherapeutic isoeffect doses for different fractionation/protraction schemes. In summary, the LQ model has the following useful properties for predicting isoeffect doses: (1) it is a mechanistic, biologically based model; (2) it has sufficiently few parameters to be practical; (3) most other mechanistic models of cell killing predict the same fractionation dependencies as does the LQ model; (4) it has well-documented predictive properties for fractionation/dose-rate effects in the laboratory; and (5) it is reasonably well validated, experimentally and theoretically, up to about 10 Gy/fraction and would be reasonable for use up to about 18 Gy per fraction. To date, there is no evidence of problems when the LQ model has been applied in the clinic.

---

### Re-evaluation of quadratic and exponential models of litter accumulation incorporating climatic and species-specific dependence [^b5f949e5]. Nature Communications (2025). High credibility.

This is illustrated in Fig. 1, using the quadratic model for the functionas determined using the best-fit parameter values from ref.(Table 2). The figure shows that when, the modelled values ofare constrained to the grey shaded regions in the figures.

Fig. 1
Quadratic and Olson model comparison.

Prediction ranges (grey shading) given by Eq. (4) along with the All Eucalypt Forests and Representative Forests datasets of ref.: a All Eucalypt Forests (all data); b All Eucalypt Forests (data with); c Representative Forests (all data); d Representative Forests (data with). The red and blue curves are the quadratic model prediction(Eq. 5) and the Olson model prediction(Eq. 6), respectively, determined using least-squares regression. The black curves represent the quadratic component (Eq. 2) of the model values calculated using the corresponding parameter values in ref. Table 2.

---

### Quetiapine (Seroquel) [^8a8dd992]. FDA (2025). Medium credibility.

Warnings and precautions regarding the use of quetiapine fumarate PO (also known as Seroquel):
- **Anticholinergic syndrome**: use caution in patients with urinary retention, prostatic hypertrophy, constipation, or taking anticholinergic medications.
- **Antipsychotic withdrawal**: do not discontinue abruptly in any patient.
- **Aspiration pneumonia**: use caution in elderly patients, particularly with advanced Alzheimer's disease.
- **Cataract**: maintain a high level of suspicion, as long-term use of quetiapine has been associated with an increased risk of cataracts.
- **Falls**: maintain a high level of suspicion, as quetiapine may cause somnolence, orthostatic hypotension, motor and sensory instability, leading to falls and injuries.
- **Hematologic disorders**: use caution in patients with leukopenia/neutropenia include pre-existing low white cell count (WBC) and history of drug induced leukopenia/neutropenia.
- **Hyperprolactinemia**: maintain a high level of suspicion, as quetiapine has been associated with an increased risk of hyperprolactinemia.
- **Hypotension**: use caution in patients with cardiovascular or cerebrovascular disease, dehydration/hypovolemia, or taking antihypertensive agents.
- **Hypothyroidism**: maintain a high level of suspicion, as quetiapine has been associated with an increased risk of hypothyroidism. Monitor TSH and fT4 levels.
- **Mania**: use caution in patients with bipolar disorder. Screen patients for any personal or family history of bipolar disorder before initiating quetiapine.
- **Metabolic changes**: maintain a high level of suspicion, as quetiapine has been associated with an increased risk of metabolic changes, including hyperglycemia, diabetes mellitus, dyslipidemia, and weight gain.
- **Neuroleptic malignant syndrome**: maintain a high level of suspicion, as quetiapine has been associated with an increased risk of neuroleptic malignant syndrome.
- **Prolonged QT interval**: use caution in patients at increased risk of QT prolongation, such as the elderly, patients with CVD, family history of QT prolongation, congestive HF, or cardiac hypertrophy. Avoid using quetiapine with other QT-prolonging agents, including class IA or III antiarrhythmics, antipsychotics (such as ziprasidone, chlorpromazine, thioridazine), antibiotics (such as gatifloxacin, moxifloxacin), or other medications known to prolong the QT interval (such as pentamidine, levomethadyl acetate, methadone).
- **Seizure**: use caution in patients with seizure disorder or low seizure threshold.
- **Somnolence**: use extreme caution in patients performing activities requiring mental alertness, such as driving or operating machinery.
- **Stroke**: use caution in elderly subjects with dementia.
- **Tardive dyskinesia**: maintain a high level of suspicion, as quetiapine has been associated with an increased risk of tardive dyskinesia.
- **Torsades de pointes, SCD**: use caution, as quetiapine is associated with an increased risk of these adverse events. Avoid using quetiapine in patients with a history of cardiac arrhythmias, such as bradycardia, hypokalemia, hypomagnesemia, or congenital QT prolongation.

---

### Nonlinear magnitude and linear phase behaviors of T2✱ imaging: theoretical approximation and monte carlo simulation [^78d7f7fa]. Magnetic Resonance Imaging (2015). Low credibility.

The underlying source of brain imaging by T2✱-weighted magnetic resonance imaging (T2✱MRI) is the intracranial inhomogeneous tissue magnetic susceptibility (denoted by χ) that causes an inhomogeneous field map (via magnetization) in a main field. By decomposing T2✱MRI into two steps, we understand that the 1st step from a χ source to a field map is a linear but non-isomorphic spatial mapping, and the 2nd step from the field map to a T2✱ image is a nonlinear mapping due to the trigonometric behavior of spin precession signals. The magnitude and phase calculations from a complex T2✱ image introduce additional nonlinearities. In this report, we look into the magnitude and phase behaviors of a T2✱ image (signal) by theoretical approximation and Monte Carlo simulation. We perform the 1st-order Taylor expansion on intravoxel dephasing formula of a T2✱ signal and show that the T2✱ magnitude is a quadratic mapping of the field map and T2✱ phase is a linear isomorphic mapping. By Monte Carlo simulation of T2✱MRI for a span of echo times (with B0 = 3T and TE = [0,120] ms), we first confirm the quadratic magnitude and linear phase behaviors in small phase angle regime (via TE < 30ms), and then provide more general magnitude and phase nonlinear behaviors in large phase angle scenarios (via TE > 30ms). By solving the inverse problem of T2✱MRI, we demonstrate χ tomography and conclude that the χ source can be reliably reconstructed from a T2✱ phase image in a small phase angle regime.

---

### Nonlinearity of root trait relationships and the root economics spectrum [^4d494a06]. Nature Communications (2019). High credibility.

The root economics spectrum (RES), a common hypothesis postulating a tradeoff between resource acquisition and conservation traits, is being challenged by conflicting relationships between root diameter, tissue density (RTD) and root nitrogen concentration (RN). Here, we analyze a global trait dataset of absorptive roots for over 800 plant species. For woody species (but not for non-woody species), we find nonlinear relationships between root diameter and RTD and RN, which stem from the allometric relationship between stele and cortical tissues. These nonlinear relationships explain how sampling bias from different ends of the nonlinear curves can result in conflicting trait relationships. Further, the shape of the relationships varies depending on evolutionary context and mycorrhizal affiliation. Importantly, the observed nonlinear trait relationships do not support the RES predictions. Allometry-based nonlinearity of root trait relationships improves our understanding of the ecology, physiology and evolution of absorptive roots.

---

### Analog optical computer for AI inference and combinatorial optimization [^5ce378a5]. Nature (2025). Excellent credibility.

Medical image reconstruction case study

We implement compressed sensing on the AOC hardware, a technique enabling accurate signal reconstruction from fewer measurements than traditionally required. Compressed sensing accelerates image acquisition, reducing scan times and enhancing patient comfort. For magnetic resonance imaging (MRI), a sparse image representation is typically achieved using techniques such as wavelet regularization that penalize 'unnatural' reconstructions. The standard regularization choice is the ℓ 1 -norm, which promotes sparsity and enables optimization via convex solvers. However, the original compressed-sensing method employs the ' ℓ 0 -norm', which counts the number of non-zero elements in a vector. Minimizing the ℓ 0 -norm may yield better reconstruction in theory, although the optimization problem is deemed impractical in this case and, hence, remains largely unexplored in applied image reconstruction tasks. With the AOC hardware, we can address this original hard problem by formulating the compressed-sensing approach as the QUMO optimization problem:Here the first term ensures data fidelity between measurementsand the imagein the wavelet domain, and the matrixrepresents the MRI acquisition process consisting of Fourier and inverse wavelet transforms with an undersampling mask (Methods). To reduce the MRI scan time, the number of measurements M needs to be smaller than the number of pixels N; hence this data-fidelity term has infinitely many solutions on its own. The image pixels are normalized to x ∈ [0, 1] N in the wavelet domain and σ ∈ {0, 1} N is a binary vector that controls the sparsity of x. When σ i = 0, the λ 1 penalty disappears and the corresponding non-zero pixel value x i penalizes the objective owing to the λ 2 penalty. For σ i = 1, the λ 2 penalty disappears and the pixel x i can take any value to match the measurements, albeit at λ 1 penalty cost to the objective. Lastly, 1 and (⋅) T denote the vector of ones and the transpose operation in equation (3), respectively. The generalization of this reconstruction problem to the complex-valued variables is presented in Supplementary Information section G.3.

---

### The eighty five percent rule for optimal learning [^64cfc35e]. Nature Communications (2019). High credibility.

In terms of the decision variable, the optimal difficulty changes as a function of precision (Fig. 1c) meaning that the difficulty of training must be adjusted online according to the skill of the agent. Using the monotonic relationship between Δ and ER (Fig. 1b) it is possible to express the optimal difficulty in terms of the error rate, ER * (Fig. 1d). Expressed this way, the optimal difficulty is constant as a function of precision, meaning that optimal learning can be achieved by clamping the error rate during training at a fixed value, which, for Gaussian noise isThat is, the optimal error rate for learning is 15.87%, and the optimal accuracy is around 85%. We call this the Eighty Five Percent Rule for optimal learning.

Dynamics of learning

While the previous analysis allows us to calculate the error rate that maximizes the rate of learning, it does not tell us how much faster learning occurs at this optimal error rate. In this section we address this question by comparing learning at the optimal error rate with learning at a fixed error rate, ER f (which may be suboptimal), and, alternatively, a fixed difficulty, Δ f. If stimuli are presented one at a time (i.e. not batch learning), in both cases, gradient-descent based updating of the parameters, ϕ, (Eq. (4)) implies that the precision β evolves in a similar manner, i.e. For fixed error rate, ER f, as shown in the Methods, integrating Eq. (7) giveswhere t 0 is the initial time point, β 0 is the initial value of β and K f is the following function of the training error rateThus, for fixed training error rate the precision grows as the square root of time with the exact rate determined by K f which depends on both the training error rate and the noise distribution.

For fixed decision variable, Δ f, integrating Eq. (7) is more difficult and the solution depends more strongly on the distribution of the noise. In the case of Gaussian noise, there is no closed form solution for β. However, as shown in the Methods, an approximate form can be derived at long times where we find that β grows asi.e. exponentially slower than Eq. (38).

---

### A co-design framework of neural networks and quantum circuits towards quantum advantage [^aa9b9d37]. Nature Communications (2021). High credibility.

Neural computation P-LYR

An m -input neural computation component is illustrated in Fig. 4 c, where m -input data I 0, I 1, ⋯, I m −1 and m corresponding weights w 0, w 1, ⋯, w m −1 are given. Input data I i is a real number ranging from 0 to 1, while weight w i is a {−1, +1} binary number. Neural computation in P-LYR is composed of 4 operations: (i) R: this operation converts a real number p k of input I k to a two-point distributed random variable x k, where P { x k = −1} = p k and P { x k = +1} = 1 − p k, as shown in Fig. 4 b. For example, we treat the input I 0 's real value of p 0 as the probability of x 0 that outcomes −1 while q 0 = 1 − p 0 as the probability that outcomes +1. (ii) C: this operation calculates y as the average sum of weighted inputs, where the weighted input is the product of a converted input (say x k) and its corresponding weight (i.e. w k). Since x k is a two-point random variable, whose values are −1 and +1 and the weights are binary values of −1 and +1, if w k = − 1, w k ⋅ x k will lead to the swap of probabilities P { x k = −1} and P { x k = + 1} in x k. (iii) A: we consider the quadratic function as the nonlinear activation function in this work, and A operation outputs y 2 where y is a random variable. (iv) E: this operation converts the random variable y 2 to 0–1 real number by taking its expectation. It will be passed to batch normalization to be further used as the input to the next layer.

---

### Minimum-phase property of the hemodynamic response function, and implications for granger causality in fMRI [^71f855c3]. Human Brain Mapping (2025). Medium credibility.

3.3 Drysdale et al. Model

This spatiotemporal BOLD model is derived from first principles using a poroelastic model of cortical tissue (Drysdale et al.) and it uses the same BOLD change equation as the previous models Equation (5e). Its transfer function (Aquino et al.) depends on several parameters that are explained in Table 2:

TABLE 2
Parameter interpretation and default values in Drysdale et al. as summarized in Pang et al.).

The five poles of the transfer function (Pang et al.) are

The first three have negative real part. For the remaining two poles, the square root is a real number because its argument is positive in the desired parameter range (see Table 2). Hence, the real part of the remaining two poles iswhich is always negative sinceis positive. The zeros of the transfer function are

The first zero has negative real part sinceis positive (effective blood viscosity, see Table 2). The sign of the real part of the second zero depends on the BOLD change equation coefficients. With the choice of values in Table 2, we get, which is negative, so the modelled HRF is minimum‐phase.

However, for consistency with the previous models, we can replace the fixed values of the BOLD equation coefficients in Table 2 with the formulas in Table 1, which explicate their dependence on the physiological parameters (, TE) explained in Section 3.1.1. Now, the second zero of the transfer function only has a negative real part when. Therefore, this constraint is the minimum‐phase condition for this HRF model.

---

### Selecting fitted models under epistemic uncertainty using a stochastic process on quantile functions [^bb9b7f12]. Nature Communications (2025). High credibility.

After n refinement steps, we thus obtain a functiondefined at discrete points:which we extend to the entire interval [0, 1) by linear interpolation; see Fig. 5 d for an illustration. In practice we found that computations (specifically the risk computed by integrating) converge after about eight refinement steps.

This procedure has the important property that once a point is sampled, it does not change on further refinements:which follows from equation (67). Recall now that, as stated above, a process is self-consistent if "for small enough Δ Φ, the probability distribution at a point Φ [does] not depend on the level of refinement". Since equation (70) clearly satisfies that requirement, we see that the process obtained after infinitely many refinement steps is indeed self-consistent. We thus define the hierarchical beta (HB) process as

To complete the definition of, we need to specify how we choose the initial end pointsand. In our implementation, they are drawn from normal distributionswith Φ ∈ {0, 1}, where again c is determined via our proposed calibration procedure; this is simple and convenient, but otherwise arbitrary. We also need to explain how we choose the beta parameters α and β, which is the topic of the next subsection.

Choosing beta distribution parameters

All HB processes are monotone, continuous and self-consistent, but within this class there is still a lot of flexibility: since α and β are chosen independently for each subinterval, we can mouldinto a wide variety of statistical shapes. We use this flexibility to satisfy the two remaining desiderata: a) that realisationstrackover Φ ∈ [0, 1]; and b) that the variability ofbe proportional to. It is the goal of this subsection to give a precise mathematical meaning to those requirements.

Let x 1 ~ Beta(α, β) and x 2 = 1 − x 1. (The density function of a beta distribution is given in (24).) The mean and variance of x 1 areFor a given Φ, it may seem natural to select α and β by matchingtoandto. However both equations are tightly coupled, and we found that numerical solutions were unstable and unsatisfactory; in particular, it is not possible to make the variance large whenapproaches either 0 or 1 (otherwise the distribution of x 1 would exceed [0, 1]).

---

### Nonlinear deltaR*2 effects in perfusion quantification using bolus-tracking MRI [^14fb0c55]. Magnetic Resonance in Medicine (2009). Low credibility.

Dynamic susceptibility contrast MRI involves injection of a contrast agent, whose concentration is estimated from DeltaR*2 changes. However, measurement of contrast-agent concentration is prone to various sources of error; in particular, the commonly assumed linear relationship between contrast agent concentration and DeltaR*2 in arterial blood is known to be invalid. In this study, we characterized the associated perfusion errors. Large errors were found when the linear assumption is used; these errors were highly dependent on the choice of tissue relaxivity. The errors were greatly reduced when using the quadratic model, and were further reduced when quantifying perfusion as a relative measure. This study suggests the linear assumption should be abandoned in favor of the quadratic model. Thus, the errors are minimized leading to improved quantification that will enable perfusion MRI to continue to play an important role in quantifying perfusion in brain diseases (e.g., acute stroke).

---

### High-order species interactions shape ecosystem diversity [^083fa385]. Nature Communications (2016). Medium credibility.

We defined a community as feasible if all the species existed at the end of the simulation, with an abundance above a defined threshold (set as 10 −5 / N). The probability that a community would be feasible was then defined as the fraction of stable communities out of the R random communities simulated. To find the critical strength of interactions for a given number of species, we used a fixed collection of R sets of pairwise, three- and four-way interaction matricesand increased the interaction parameters until 5% of the communities exhibited extinctions. In Fig. 2 (as well as Supplementary Figs 2–5) this was done by increasing the strength of interactions of a given order, while the rest are kept at 0. In Fig. 3a this was done along radial lines in log (α), log (γ) space: α = 0.001·1.2 r ·cos θ, γ = 0.05·1.3 r ·sin θ, such that for each value of θ, we increased r until stability was lost.

Deriving stability criterion by considering effective pairwise interactions

The Jacobian of the system at a given point is:

Where, is the Kronecker delta. At a fixed point, the first term vanishes. We may also neglect the terms in the last line which are derivatives of the normalization, as we will justify below. Assuming stability of all species coexisting, the value of species abundances at this fixed point must scale as x i ≈1/ N (because the total abundance is fixed to 1). Equation 1 can therefore be approximated as pairwise dynamics:

with

the fixed point will be stable if the eigenvalues of the Jacobian all have negative real parts. Within our assumption x i ≈1/ N, we may focus on the eigenvalues of A eff, which differs from the Jacobian by a constant factor N that does not affect the signs of the eigenvalues (as previously reported, the actual Jacobian in a steady-state deviates somewhat from this simple analysis due to deviation of the fixed-point x i from 1/ N; Supplementary Fig. 9).

---

### Nonlinear delay differential equations and their application to modeling biological network motifs [^a6af3eb5]. Nature Communications (2021). High credibility.

Frequency response of feedforward motifs can be solved analytically and demonstrates low- and band-pass filtering capabilities

Biological regulatory networks often encode information as the change in frequency of an oscillating input, which has been suggested to be more robust to noise than encoding information in absolute concentration –. That feedforward loops filter short square pulses suggests more general frequency-filtering capabilities. We therefore analyze feedforward frequency response to sinusoidal input (Fig. 6 d–g). We show that the response follows the outline of a universal transfer function curve, independent of the logic or delay difference.

Instead of the step input analyzed above, here we consider a sinusoidal inputwhich oscillates between zero and 2 A (twice the amplitude) at a frequency f > 0. Taking the Fourier decomposition of each Hill-regulated term 1/[1 + X n (T)] and plugging into the governing Eq. (21) (Supplementary Note 6) provides the output Z (T) in terms of its magnitude I k and phase ϕ k as a function of frequency:whereare Fourier coefficients of Hill-regulated terms 1/[1 + X n (T)] at integer multiples k of the fundamental frequency f :for all f > 0. Note that the magnitudes are symmetric to interchange of the two regulation arms (η 1 ↔ η 2, n 1 ↔ n 2), while the phases are not.

---

### Lipid measurements in the management of cardiovascular diseases: practical recommendations a scientific statement from the National Lipid Association writing group [^7c8d5ed1]. Journal of Clinical Lipidology (2021). High credibility.

Sampson equation considerations describe potential utility and current evidence gaps: A bivariate quadratic equation published by Sampson and colleagues calculates LDL-C from TG and non–HDL-C and yields accurate estimates for samples with a TG level up to 800 mg/dL, although it may underestimate low LDL-C levels. In samples with normal triglyceride levels, it yields similar results to Martin/Hopkins at low LDL-C, but additional data in individuals with low LDL-C are needed before it can be more generally recommended for LDL-C calculation.

---

### Linear quadratic gaussian-based closed-loop control of type 1 diabetes [^84caab6b]. Journal of Diabetes Science and Technology (2007). Low credibility.

Background

We investigated the applicability of linear quadratic Gaussian (LQG) methodology to the subcutaneous blood glucose regulation problem. We designed an LQG-based feedback control algorithm using linearization of a previously published metabolic model of type 1 diabetes. A key feature of the controller is a Kalman filter used to estimate metabolic states of the patient based on continuous glucose monitoring. Insulin infusion is computed from linear quadratic regulator feedback gains applied to these estimates, generally seeking to minimize squared deviations from a target glucose concentration and basal insulin rate. We evaluated in silico subject-specific LQG control and compared it to preexisting proportional-integral-derivative control.

---

### Motion-corrected MRI with DISORDER: distributed and incoherent sample orders for reconstruction deblurring using encoding redundancy [^aeaa796c]. Magnetic Resonance in Medicine (2020). Medium credibility.

2 THEORY

2.1 Aligned reconstruction

Assuming whitened measurement noise, 21 the aligned reconstruction for parallel volumetric imaging can be formulated as:where x is the image to be reconstructed, θ are the motion parameters, r is the loss function, y is the measured k‐space data, T is a set of rigid motion transformations, S are the coil sensitivities, is the discrete Fourier transform (DFT), and A is a sampling mask. We are interested in reconstructing a 3D image of sizewiththe number of voxels along dimension d from C ‐element coil array samples of a discretized k‐space grid of size K.denotes the number of samples within segment m and M is the number of segments in the sequence, with each segment associated to a specific motion state. Detailed information about the terms in Equation 1 can be found in. 20 Here we provide a brief description of their structure:
y is a N × 1 vector.
A is a N × KMC block matrix comprising submatrices of sizewhose entries take the value 1 if the sample e of the segment m corresponds to the k‐space location indexed by k and 0 otherwise.
is a KMC × VMC block diagonal matrix comprising submatrices of size K × V representing 3D DFT's with applied k‐space sampling.
S is a VMC × VM block matrix comprising diagonal submatrices of size V × V whose diagonal elements correspond to the spatial sensitivity of the coil c.
T is a VM × V block matrix comprising unitary 22 submatrices of size V × V corresponding to the 3D rigid transformation modeling the motion state m by three translations and three Euler rotation angles codified in the parameter vector.
x is a V × 1 vector.

Equation 1 is a separable nonlinear least squares problem. 23, 24 We confront it by iteratively addressing the subproblems:The first subproblem, reconstructing the image x in the presence of rigid motion, 17 can be solved by conjugate gradient (CG). 21 As for the second, the solution must null the gradient of the objective function against the motion parameters, 20 which is tackled by a Levenberg‐Marquardt (LM) algorithm using a simplified Jacobian. 25 A natural initialization is a zero‐motion condition, so the first step corresponds to a standard sensitivity encoding (SENSE) reconstruction. Further in this paper, we describe how to temporally arrange the k‐space samples into segments to improve the aligned reconstruction convergence.

---

### Linear regression in medical research [^90ff7dca]. Anesthesia and Analgesia (2021). Medium credibility.

Variable selection is a much-debated topic, and the details are beyond the scope of this Statistical Minute. Basically, variable selection depends on whether the purpose of the model is to understand the relationship between variables or to make predictions. This is also predicated on whether there is informed a priori theory to guide variable selection and on whether the model needs to control for variables that are not of primary interest but are confounders that could distort the relationship between other variables.

Omitting important variables or interactions can lead to biased estimates and a model that poorly describes the true underlying relationships, whereas including too many variables leads to modeling the noise (sampling error) in the data and reduces the precision of the estimates. Various statistics and plots, including adjusted R 2, Mallows C p, and residual plots are available to assess the goodness of fit of the chosen linear regression model.

---

### Substantial hysteresis in emergent temperature sensitivity of global wetland CHemissions [^ca1657d2]. Nature Communications (2021). High credibility.

Emergent temperature dependence calculation and the hysteresis parameter

Emergent dependence of CH 4 emission on temperature (air or soil) is determined by fitting frost-free-season daily measurements ofand air and soil temperatures with a quadratic equation (Eq. 1), the Boltzmann–Arrhenius equation (Eq. 2), and first, second, third, and fifth order polynomials. Dailyestimates made by site- and time-specific emergenttemperature (air or soil) dependence models based on the above-mentioned functional forms show comparable root mean square errors (Supplemental Fig. 2). Results inferred from the quadratic equation (Eq. 1) are selected because (1) its functional form is mathematically consistent with the second-order polynomial equation of temperature for methanogenesis inferred from the MacroMolecular Rate Theory; and (2) it can prescribe seasonalhysteresis with a single site- and time- specific parameter (, defined below).

The fits based on the quadratic equation were forced to pass through the origin (assuming zeroat 0 °C, discussed below) andmeasured at maximum seasonal temperature in each site-year using the Matlab (MathWorks Inc. 2019, version 9.7.0) polyfix function (downloaded from). The resulting emergent dependence ofon temperature at any given time period can thus be represented as:

The symbols used in Eq. 1 denote CH 4 emission (, mg C m −2 d −1), hysteresis parameter (, mg C m −2 d −1 °C −2), daily mean temperature (, °C; air or soil), maximum seasonal temperature (, °C), and CH 4 emission measured at maximum seasonal temperature (, mg C m −2 d −1). Therefore, the functional relationship between and temperature, described by a quadratic equation (Eq. 1), is only determined by the value of hysteresis parameter and site-year variables.

---

### Ab-initio variational wave functions for the time-dependent many-electron schrödinger equation [^b4c20bc6]. Nature Communications (2024). High credibility.

Understanding the real-time evolution of many-electron quantum systems is essential for studying dynamical properties in condensed matter, quantum chemistry, and complex materials, yet it poses a significant theoretical and computational challenge. Our work introduces a variational approach for fermionic time-dependent wave functions, surpassing mean-field approximations by accurately capturing many-body correlations. We employ time-dependent Jastrow factors and backflow transformations, enhanced through neural networks parameterizations. To compute the optimal time-dependent parameters, we employ the time-dependent variational Monte Carlo technique and introduce a new method based on Taylor-root expansions of the propagator, enhancing the accuracy of our simulations. The approach is demonstrated in three distinct systems. In all cases, we show clear signatures of many-body correlations in the dynamics. The results showcase the ability of our variational approach to accurately describe the time evolution, providing insight into quantum dynamical effects in interacting electronic systems, beyond the capabilities of mean-field.

---

### NIPMAP: niche-phenotype mapping of multiplex histology data by community ecology [^68696763]. Nature Communications (2023). High credibility.

The negative term in the first bracket of the equation prevents niche weights from growing to infinity, by ensuring that there are two stable fixed points in the absence of diffusion (that is when D ≔ 0): α i = 0 — niche i is absent at (x, y) — and α i ≃ 2 K — niche i is present at (x, y).

The second bracket adds diffusion, to enforce smooth variation in niche weights with respect to space. We set the spatial domain in both x and y to [0, L] with L = 800 μm, the size of a MIBI image, using periodic boundary conditions.

We simulated this system numerically on a 50 × 50 lattice, that is d x = d y = L /50 = 16 μm until convergence using R's ode.2D solver from the deSolve library. At convergence, the α s were normalized to sum up to 1 at each position (x, y). We used n = 4 niches due to practical relevance to our re-analysis of the MIBI data of Keren et al. Setting D = 40 μm 2 /day produced niches whose spatial architecture resembles that of MIBI data (Supplementary Fig. 7a).

We define the prevalence of niche i as L −2 ∫ α i (x, y) d x d y. To simulate tissues in which one niche is more rare — less prevalent — than the others, we altered the initial condition α 0 (x, y). We randomly initialized α 0 (x, y) so that, at each (x, y), the weight of one niche was 1 and the weight of all other niches was 0. To simulate tissues in which niche 1 was less prevalent than other niches, we varied the probability f that α 1 (x, y) was 1. The probability that α i (x, y) = 1 for the other niches i ≠ 1 was set to be equal. This resulted in initial conditions α 0 (x, y) in which the prevalence of niche 1 was f and the prevalence of niche 2, 3 and 4 was (1 − f)/(n − 1).

---

### Geometrical uncertainties, radiotherapy planning margins, and the ICRU-62 report [^d4680469]. Radiotherapy and Oncology (2002). Low credibility.

In this paper, we elaborate on the proposals in the ICRU-62 report concerning planning target volume (PTV) margins for geometrical uncertainties during radiotherapy, such as variations in patient set-up and internal organ motion. According to the ICRU, these margins should be such that the planned dose in the PTV is representative of the real dose in the 'moving' clinical target volume (CTV). We demonstrate that the dosimetrical consequences of systematic and random geometrical uncertainties are fundamentally different, which should be reflected in margin calculations. The recommendation in the ICRU-62 report, to quadratically add standard deviations for systematic (Sigma(tot)) and random (sigma(tot)) errors to determine an overall standard deviation for margin calculations, is therefore generally not valid. Instead, a previously published recipe for PTV margin calculation, M = 2Sigma(tot) + 0.7sigma(tot), does indeed account for the different impact of systematic and random errors on the dose in the CTV. If, for both random and systematic uncertainties, the internal and external errors are uncorrelated and quantified by the standard deviations sigma(int), sigma(ext), Sigma(int), Sigma(ext), then Sigma(tot) = square root (Sigma(int)(2) + Sigma(ext)(2)) and sigma(tot) = square root (sigma(int)(2) + sigma(ext)(2)). If the PTV margin thus acquired is deliberately reduced to spare normal tissues, the planned PTV dose is not representative of the CTV anymore. Therefore, we recommend to also report the minimum dose in the volume originally defined by the recipe (designated RTV, i.e. representative target volume).

---

### EEG functional connectivity as a riemannian mediator: an application to malnutrition and cognition [^6db69c9d]. Human Brain Mapping (2024). Medium credibility.

2.4.2 of the response on the mediator

For the case where the response variable is a scalar, and the predictor is a matrix, we employ the methodologies and findings established in the study conducted by Zhou and Li. Letbe a scalar response, be a matrix covariate of size, andthe coefficient matrix of the same size

The inner product between two matrices is defined as, whereis the vectorization operator that stacks the columns of a matrix into a vector. Hereis a normal error with mean zero and variance. An illustration showing where this coefficient is located in the path diagram can be seen in Figure 4.

FIGURE 4
Illustration of theregression coefficient in the mediation model.

To solve (12), we need to find the solution of the minimization problem

According to Equation (13), the minimum value ofand the parametercan be found using the Nesterov algorithm (Nesterov,), as was the case for the NNMR of the mediator on the treatment described in the previous section. We used the methods in the MATLAB toolbox TensorReg (Zhou,) to perform the tensor operations and estimate theandcoefficients.

Although cross‐validation is usually chosen to obtain the penalization parameter, using AIC or BIC significantly improves computation time. Letdenote theobservation of, represent the estimated response under a given parameter, andis the variance of the error term from equation (12). Then for this model, andare defined by

andare defined similarly for the regression presented in (10) with the subtle difference of the matrix response variable. Here, denote degrees of freedom, and its calculation is detailed in Appendix B.

Investigating the instance of a complex inner product

If the mediator represents a complex cross‐spectral matrix and the resulting variable is a scalar, it is crucial to consider this while calculating the coefficient obtained from Equation (8), as the inner product will yield a complex value. To tackle this issue, we incorporated a penalization constant into the imaginary component of the inner product ofand, effectively nullifying it and subsequently satisfying the conditions imposed by Equation (8).

Assuming thatandare complex matrices, we have, were the superscriptsandaccount for the real and imaginary parts of the complex quantities, respectively. In matrix notation, we then can express:whereis the penalization parameter andsince the outcome must be scalar.

---

### From a microscopic inertial active matter model to the schrödinger equation [^5f56fd43]. Nature Communications (2023). High credibility.

Analogy to dark matter

In this section, we use the active-quantum mapping derived above to establish a relation between inertial active matter and dark matter. This illustrates the usefulness of this mapping, as it shows that active matter can be used as a model for dark matter (for example in analog experiments) and that our understanding of pattern formation can become useful for astrophysics.

An important field of application for the Madelung equations is the study of dark matter. Recently, there has been an increase of interest in so-called fuzzy dark matter (FDM), which consists of ultralight scalar particles. It was introduced to avoid the problem that the standard cold dark matter models predicted cuspy halos and excessive small-scale structures, in conflict with observations. Further motivations for research on FDM are the lack of evidence for other dark matter candidates and the fact that such ultralight particles are predicted by various models from particle physics (such as string theory).

On galactic scales, one can neglect self-interactions of the real scalar field representing dark matter and use a simple quadratic action functional. In the nonrelativistic limit, the real scalar field can be re-written using a complex field ψ that obeys a Schrödinger equation with modifications accounting for cosmic expansion. These modifications can be neglected on galactic scalesand are also neglected here. The FDM particles are mostly in the ground state and can thus be described by a single macroscopic wavefunction as in a Bose-Einstein condensate. It is very common in dark matter physics to transform from the Schrödinger equation to the Madelung equations since this allows to use hydrodynamic codes. FDM can then be described by the Madelung equations (24) and (25) coupled to the Poisson equationwith the gravitational constant G. Equation (35) determines U 1, which is here the gravitational potential, via the density ρ q.

---

### Identification of signal bias in the variable flip angle method by linear display of the algebraic ernst equation [^866dc6c7]. Magnetic Resonance in Medicine (2011). Low credibility.

Noise Propagation with Correlated Errors

The image noise is scaled individually along abscissa (σ S τ) and ordinate (σ S /τ). The errors are equal for τ = 1 or α = 53°. At smaller flip angle (τ → 0), the y -error is enhanced and the x -error is diminished, and vice versa for τ → ∞ (α → π).

In a function F of two variables, x and y, the statistical errors (given by the variances var x and var y) are propagated by the respective partial derivatives ∂ F /∂ x. If the errors in x and y are not independent (i.e. correlated), their covariance has to be taken into account by using the general law of Gaussian error propagation.

Here, F is the residual F (x, y) = y – (A – x /2ρ 1) with x = S × τ and y = S /τ. Thus, the covariance is identical to the image noise variance σ S 2 and independent of τ.

This is in stark contrast to the common linearization of Eq. 2, where the errors and their covariance increase strongly for small flip angles by 1/sin α or 1/tan α. Equation 16 yields

The expression in brackets denotes a τ-dependent scaling factor of the image noise. It can be cancelled by imposing suitable weights w (τ) onto the square residues

in the linear least squares objective function. These weights are maximal at τ E and decrease towards the intercepts with the x - and y - axes.

Short TR

If R 1 TR ≪ 1 then ρ 1 can be approximated and Eq. 9 arranged as

Under this condition, Sτ /2TR can be used as abscissa to incorporate varying values of TR into the regression. Estimates of T 1 are obtained directly as the (negative) slope

This is the generalization of the formula for the dual angle experiment.

---

### Deep learning for universal linear embeddings of nonlinear dynamics [^317523d7]. Nature Communications (2018). Medium credibility.

Methods

Creating the datasets

We create our datasets by solving the systems of differential equations in MATLAB using the ode45 solver.

For each dynamical system, we choose 5000 initial conditions for the test set, 5000 for the validation set, and 5000–20,000 for the training set (see Table 2). For each initial condition, we solve the differential equations for some time span. That time span is t = 0,.02,… ,1 for the discrete spectrum and pendulum datasets. Since the dynamics on the slow manifold for the fluid flow example are slower and more complicated, we increase the time span for that dataset to t = 0,.05,… ,6. However, when we include data off the slow manifold, we want to capture the fast dynamics as the trajectories are attracted to the slow manifold, so we change the time span to t = 0,.01,… ,1. Note that for the network to capture transient behavior as in the first and last example, it is important to include enough samples of transients in the training data.

Table 2
Dataset sizes

The discrete spectrum dataset is created from random initial conditions x where x 1, x 2 ∈[−0.5, 0.5], since this portion of phase space is sufficient to capture the dynamics.

The pendulum dataset is created from random initial conditions x, where x 1 ∈[−3.1,3.1] (just under), x 2 ∈[−2,2], and the potential function is under 0.99. The potential function for the pendulum is. These ranges are chosen to sample the pendulum in the full phase space where the pendulum approaches having an infinite period.

The fluid flow problem limited to the slow manifold is created from random initial conditions x on the bowl where r ∈[0, 1.1], θ ∈[0, 2 π], x 1 = r cos(θ), x 2 = r sin(θ),… This captures all of the dynamics on the slow manifold, which consists of trajectories that spiral toward the limit cycle at r = 1.

---

### The controversies and pitfalls in modeling normal tissue radiation injury / damage [^b35932c8]. Seminars in Radiation Oncology (2001). Low credibility.

Highly conformal fields have become achievable in routine clinical practice. The optimal shape of the resultant dose distributions depends on information that is not currently available. This missing information is the dose-volume response of the normal tissues at risk. These functions are now the subject of aggressive research. The research involves collecting the dose-response data, modeling the dose-response function, and fitting the models to the data. The controversies addressed here influence the selection of the biomathematical model that one might use to describe such a function. The form that the dose-volume response function takes depends on the nature of the volume effect. The nature of the volume effect for a given radiation response is the subject of considerable debate. Related to this debate, this report addresses the existence of the volume effect, the existence of a threshold volume, and the existence of functional subunits. The pitfalls relate to the problems in accurate determination and application of the dose-response functions.

---

### Best (but oft-forgotten) practices: checking assumptions concerning regression residuals [^f2ebb771]. The American Journal of Clinical Nutrition (2015). Low credibility.

The residuals of a least squares regression model are defined as the observations minus the modeled values. For least squares regression to produce valid CIs and P values, the residuals must be independent, be normally distributed, and have a constant variance. If these assumptions are not satisfied, estimates can be biased and power can be reduced. However, there are ways to assess these assumptions and steps one can take if the assumptions are violated. Here, we discuss both assessment and appropriate responses to violation of assumptions.

---

### A mechanism for reversible mesoscopic aggregation in liquid solutions [^f7cd174c]. Nature Communications (2019). High credibility.

Additional computational difficulties are caused by the presence of the non-linear termin Eq. (2). We have numerically solved the resulting non-linear differential equations for several realizations of parameters — to be discussed in due time — however the majority of the calculations were performed for a linearized version of Eq. (2) so that the interconversion between the two species is effectively a first order reaction:wherein each phase. Note that if one considers Eq. (7) as a linearized version of Eq. (2), a variable change 2 n 2 → n 2 is implied. Equations (7) can also be considered on their own merit: They can approximate a physical situation where species 1 converts into species 2 by binding a third species that is part of the buffer. If the transport of this third species is fast compared with the transport of species 1 and 2, then the above equations apply. This said, we will continue to call species 1 and 2 "the monomer" and "the dimer," respectively.

The linearity of the reaction terms in Eq. (7) renders the problem linear within an individual phase. The chemical potentials and concentrations can be presented as linear combinations of Yukawa-like terms r −1 e ± qr while the differential equation is thus reduced to an algebraic characteristic equation for the lengths q −1 that can be solved much more readily than the original non-linear differential Eq. (2). This circumstance allows one to readily explore broad ranges of parameters. Once a non-trivial solution of the 1st order case (7) is found, one may then attempt to confirm whether a similar solution exists in the more complicated, 2nd order case from Eq. (2). Throughout, we consider exclusively the spherically symmetric geometry; such solutions are expected to minimize the surface tension between the two phases during phase coexistence.

---

### Abstract representations of events arise from mental errors in learning and memory [^748e9b84]. Nature Communications (2020). High credibility.

Estimating parameters and making quantitative predictions

Given an observed sequence of nodes x 1,…, x t −1, and given an inverse temperature β, our model predicts the anticipation, or expectation, of the subsequent node x t to be. In order to quantitatively describe the reactions of an individual subject, we must relate the expectations a (t) to predictions about a person's reaction timesand then calculate the model parameters that best fit the reactions of an individual subject. The simplest possible prediction is given by the linear relation, where the intercept r 0 represents a person's reaction time with zero anticipation and the slope r 1 quantifies the strength with which a person's reaction times depend on their internal expectations.

In total, our predictionscontain three parameters (β, r 0, and r 1), which must be estimated from the reaction time data for each subject. Before estimating these parameters, however, we first regress out the dependencies of each subject's reaction times on the button combinations, trial number, and recency using a mixed effects model of the form 'RT~log(Trial)*Stage+Target+Recency+(1+log(Trial)*Stage+Recency|ID)', where all variables were defined in the previous section. Then, to estimate the model parameters that best describe an individual's reactions, we minimize the RMS prediction error with respect to each subject's observed reaction times, where T is the number of trials. We note that, given a choice for the inverse temperature β, the linear parameters r 0 and r 1 can be calculated analytically using standard linear regression techniques. Thus, the problem of estimating the model parameters can be restated as a one-dimensional minimization problem; that is, minimizing RMSE with respect to the inverse temperature β. To find the global minimum, we began by calculating RMSE along 100 logarithmically spaced values for β between 10 −4 and 10. Then, starting at the minimum value of this search, we performed gradient descent until the gradient fell below an absolute value of 10 −6. For a derivation of the gradient of the RMSE with respect to the inverse temperature β, we point the reader to the Supplementary Discussion. Finally, in addition to the gradient descent procedure described above, for each subject we also manually checked the RMSE associated with the two limits β → 0 and β → ∞. The resulting model parameters are shown in Fig. 4 a, b for random walk sequences and Fig. 4 g, h for Hamiltonian walk sequences.

---

### Light-induced switching between singlet and triplet superconducting States [^cdfb61d8]. Nature Communications (2024). High credibility.

Optical switching to a metastable state

Insight into whether strongly driving a triplet BS mode can allow for light-induced switching to a metastable odd-parity superconductor can be readily gleaned from an effective time-dependent Ginzburg-Landau (TDGL) description, which encodes the coupling of multiple order parameters to light and importantly accounts for relaxation. In this picture, a suitably tailored pulse liberates the superconducting order parameter from its global free energy minimum and brings it close enough to a proximal local minimum that it relaxes into a metastable opposite-parity phase. A minimal Lagrangian that describes this process readsand includes a kinetic contribution with damping coefficientsand inertial coefficients. The equilibrium free energyis taken to generalize the usual Ginzburg-Landau action to N order parameters that crucially include subdominant orders not stabilized in equilibrium, and formally readsHere, the bar denotes complex conjugation, and summation over repeated indices is implied. Coefficients, andare tensorial generalizations of the usual Ginzburg-Landau coefficients for quadratic, quartic, and gradient contributions. We use subscript Latin indices (i, j, m, n = 1,…, N) to index different order parameters, and superscript Greek indices (μ, ν) to index spatial directions. The theory accurately represents a multi-dimensional free energy landscape in the vicinity of the critical temperature T c for the equilibrium even-parity instability. Finally, we couple the superconductor to light by introducing minimal coupling to a gauge field in velocity gauge, where − e < 0 is the electron charge. We discard subsequent gradient terms by considering only spatially homogeneous irradiation and order parameters (∇ Δ i = 0). From this, one can derive Euler-Lagrange equations of motionthat describe light-induced dynamics of competing orders.

---

### A stochastic vs deterministic perspective on the timing of cellular events [^c3a6938f]. Nature Communications (2024). High credibility.

Case 1: the simple birth–death process

When r = 1, the model given in reaction scheme (8) coincides with a simple birth–death process. We are interested in the mean waiting time for the birth–death process to reach a fixed protein number N, given that the system is started from n initial proteins. Simulations of the simple birth–death process suggest the MFPT is smaller than the deterministic FPT (see Fig. 2 B, but note that only a small sample of trajectories are shown here for visualisation purposes). We now prove this analytically. To begin, we find an analytical solution for the MFPT of the stochastic description of the system, as given by the CME (see Equation (3) of the Supplementary Information).

Starting from Eq. (7), it can be shown (Supplementary Note 2), that the expected waiting time to reach N proteins given the system is started from n ≤ N, is given by, where for real number x and positive integer m, the notationabbreviates x (x − 1)… (x − (m − 1)), the falling factorial of x. In what follows for simplicity we shall set n = 0. The deterministic description of the system is given by the reaction rate equation d τ X = K − X, with X (0) = 0, and solving for X (τ) yields X (τ) = K (1 − e − τ). Solving for τ then gives, Consider some proportion 0 < ρ < 1, and consider the expected waiting time to reach ρ K, that is, some proportion ρ of the steady-state mean. Then Eq. (10) simplifies towhich we note is independent of K, and where the requirement of ρ < 1 enables this to be well defined. Now let us consider Eq. (9) for N = ⌊ ρ K ⌋. For notational simplicity only, we assume that ρ K is an integer, and again observe that the numeratoris bounded above by (ρ K) i +1. Replacing this in Eq. (9) givesRecognising the Taylor expansion ofaround 0 (for ρ < 1), we find that Eq. (12) is the truncated Taylor expansion of Eq. (11). Thus, as each term of the series is strictly positive, it follows that for any proportion ρ of the steady-state mean, the deterministic waiting time is a strict upper bound for the mean waiting times. An example is given in Fig. 2 C for ρ = 0.8. Here we show how the ratio of the stochastic mean waiting time to the deterministic waiting time, η, of the simple birth–death process scales with increasing K. Note that since δ = r = 1, K is equal to the steady-state mean number of molecules.

---

### Cooperative binding of T cell receptor and CD4 to peptide-MHC enhances antigen sensitivity [^00b448cd]. Nature Communications (2022). High credibility.

Two-step model for trimolecular interaction

We propose a two-step model for the formation of trimolecular bonds. Since the affinity and on-rate for the CD4–pMHC interaction are so much smaller than those of the TCR–pMHC interaction, it seems reasonable to assume that TCR interacts with pMHC at the same kinetic rates as bimolecular interaction in the first step as if CD4 does not interact with free pMHC. However, CD4 is able to interact with TCR-stabilized pMHC with a much higher affinity, thereby forming trimolecular bonds in the second step.

Let p m, n be the probability of having m TCR–pMHC bonds and n TCR–pMHC–CD4 bonds, which are governed by the following master equations:

We solved these master equations using a probability generating function, which converts Eq. 10 to a single first-order linear partial differential equation,

We found a general solution to Eq. 12 using the method of characteristics, which iswhere J is an arbitrary function of its two arguments. u 1 and u 2 are functions of x and y:

λ 1 and λ 2 are given by Eq. 2. They can be viewed as the fast (λ 1) and slow (λ 2) rates that control the two p44hases of the two-step interaction. To determine the function of integration J requires initial conditions. If there is no TCR–pMHC or TCR–pMHC–CD4 bonds at t = 0, the initial conditions on p m, n are:

The corresponding initial condition of g, obtained by substituting Eq. 15 into Eq. 11, is

Solving x and y in terms of u 1,2 from Eq. 14, substituting them into Eq. 16, and comparing the resulting equation to Eq. 13 evaluated at t = 0 allows us to solve for a particular solution for J:

---

### General statistical model shows that macroevolutionary patterns and processes are consistent with darwinian gradualism [^8492f49b]. Nature Communications (2022). High credibility.

Methods

Model

Write the value of some trait Y after an amount of time dt as the outcome of multiplicative diffusion from its starting position at time t and a change term incorporating possible directional and evolvability effects:where β is a directional change (per unit time), random changes ε are time-independent and homogeneous such that, and υ transforms the variance of ε to υσ 2. These parameters correspond to the directional and evolvability changes as described in Fig. 1. By definition, directional changes occur along phylogenetic branches, introducing a mean offset to all 'downstream' species, but with no change to the Brownian variance. Evolvability effects occur at phylogenetic nodes, altering the Brownian variance σ 2 of the descendant clade.

The model of Eq. (1) captures the commonly observed dependency in morphological data between a trait's value, Y, and its variance. Writing the model in logarithmic form yieldsand Eq. (2) defines a linear model with constant and normally distributed errors ε, independent of the value of Y. For traits with variance independent of Y on the natural (un-transformed) scale, the model of Eq. (2) is still applicable, but Y is not logarithmically transformed.

Positive values of β denote increases in the value of the trait, negative values denote reductions. When the trait's change along a branch is compatible with that which is likely under neutral drift, β = 0, its default value. The default value of υ is 1; values of υ > 1 signal an increase in the potential for evolutionary exploration, those < 1 indicate reduced exploration of the trait-space. The existence and magnitude of directional and evolvability parameters that differ from their default values will vary throughout the tree according to the macroevolutionary signals retained in the species.

The model of Eq. (2), when applied to the branches leading from the root of the phylogenetic tree to the tips, yields a description of each species as the sum of the common ancestral state at the root, α, any directional changes that have occurred along the branches leading to that species, and a normally distributed error. Writing the i th species' value as Y i, and treating Y i as having been logarithmically transformed where necessary, thenwhere the β ij are directional changes occurring in the branches of length t j (replacing the dt of Eq. (2)) leading to species i, and the error term has variance.

---

### Artificial web of disclination lines in nematic liquid crystals [^5b4d8905]. Nature Communications (2017). Medium credibility.

Theoretical analysis of forces on disclination lines

For a given boundary condition at the bounding surface, the equilibrium distribution of the director can be theoretically found as the one that minimizes the Frank elastic free energy, written as a sum of contributions from the three independent mode of deformations referred to as the splay, twist, and bend modes. These modes are associated with specific elastic constants, K 11, K 22, and K 33, respectively. Here, we give only the salient results of the analysis, leaving the detailed derivation to Supplementary Note 1. Under a fairly general condition of equal splay and bend Frank elastic constants, i.e. K 11 = K 33 ≡ K, it is shown that the equilibrium director profile is governed by a linear differential equation for the azimuthal angle of the director φ. The linearity allows superposition of solutions, making it possible to decompose the problem into simpler sub-problems. We then first consider a uniform π /2-twisted cell, and consider the effect of surface pattern later. The director profile around a straight 1/2-strength twist disclination line in a π /2-twisted cell of thickness L can be analytically solved as – where the x -axis is perpendicular to the cell surfaces located at x = L /2, − L /2, and the z -axis is taken along the disclination line running at x = d, y = 0. The plus–minus sign indicates the right and left handedness of the disclination line, which becomes nonequivalent when the entire system is chiral as in the present case. Along the x -axis right below and above the disclination, φ remains constant, but makes a π /2 jump across the disclination line. The induced distortions around the disclination line relax into the simple π /2-twist over the distance of.

---

### Emergent second law for non-equilibrium steady States [^ae4f60e6]. Nature Communications (2022). High credibility.

Many classes of systems satisfy the previous scaling assumptions besides the examples already mentioned. Additional examples include non-equilibrium many-body problems like the driven Potts model, reaction-diffusion models, and asymmetric exclusion processes.

From Eq. (12) we see that as Ω is increased, P t (x) is increasingly localised around the minimum of the rate function I t (x), which is the most probable value. Also, deviations from that typical state are exponentially suppressed in Ω. Thus, the limit Ω → ∞ is a macroscopic low-noise limit where a deterministic dynamic emerges. In fact, from Eq. (13) one can show that the evolution of the minima x t of I t (x) is ruled by the closed non-linear differential equationswhere i ρ (x) ≡ ω ρ (x) − ω − ρ (x) are the scaled deterministic currents. The vector field u (x) corresponds to the deterministic drift in state space. For chemical reaction networks the dynamical equations in Eq. (15) are the chemical rate equations, while for electronic circuits they are provided by regular circuit analysis.

In the following section we obtain bounds for the steady state rate function I ss (x), that according to Eq. (13) satisfies:

---

### Non-linear relationships in clinical research [^668fb19a]. Nephrology, Dialysis, Transplantation (2025). Medium credibility.

Polynomial functions

In Fig. 4, we provide an example of a simple power transformation using the square function, which raises a variable to the power of 2 (x 2), providing a U-shaped curve. Higher powers of x can be also used to determine the shape of the function, such as the cubic function (x 3) which has a distinctive S-shape. These power terms form the core elements of so-called polynomial functions, which along with the coefficients included in the function, offer a flexible way to model various curves. By adjusting the coefficients and power functions, polynomials offer a wide variety of shapes. "Fractional" polynomial functions allow the power terms to be fractions instead of just whole numbers (i.e. x 1/2) [21]. A (fractional) polynomial function often provides sufficient flexibility to follow relatively simple non-linear curves, providing a simpler solution than the more advanced techniques we describe below. However, higher degree polynomials can be sensitive to "noise" in the data, and are not suited for fitting some of the more complex curves (e.g. sudden shifts, discontinuities, or logarithmic curves). They may also suffer from Runge's phenomenon, becoming unstable and oscillating at the edges of the data, and extrapolate poorly beyond the original range of the independent variable.

Regression splines

A powerful approach to dealing with non-linearity is provided by the family of spline functions. Instead of a single function defining the whole curve, such as polynomials or other transformations, splines are constructed by using a series of functions, each defining a different segment of the curve. As splines are constructed segment by segment — or piece by piece — they are often referred to as "piecewise" functions. Segments are connected to each other using so-called "knots," and the spline is restricted to join at these knots so there are no gaps in the curve. The simplest spline function is the linear spline function. This function assumes linearity within each segment, but the overall curve formed by the connected segments can be non-linear. For a small number of segments, linear spline models can be as easy to interpret as linear regression, as each segment can be represented by a single slope. Figure 3 provides an example of a simple linear spline with two knots (in green). These two knots divide the range of the independent variable into three segments, each with its own slope.

---

### Nonlinear delay differential equations and their application to modeling biological network motifs [^b91959df]. Nature Communications (2021). High credibility.

A two-parameter summing function reproduces all 2-input monotonic logic gates

We first write out nondimensionalized equations corresponding to the logic gate motif as depicted in Fig. 5 a. We assume that the degradation constants (β) for Z and R are equal for simplicity, and that there is no leakage.

We describe the regulation of Z by X and Y using a sum of Hill terms. Logic gate behavior can be captured with other approaches such as a product of Hill terms, or summation within a single Hill term, each representing subtly different biology. We choose the separate Hill term approach as it describes many logic functions simply by tuning regulatory strengths, and can be extended to include multiplicative terms (Supplementary Note 5). Caveats include multiple states for Z, requiring additional binarization via R (Fig. 5 c), as well as poor response to ratiometric inputs, discussed in the next section on feedforward motifs.

Using Eq. (19), we can characterize the motif logic based on the idea of dynamic range matching. Every regulator in Eq. (19) is effectively compared against unity in the denominator of the Hill function for its corresponding output. For instance, Z provides an "on" or "off" signal to R if Z > 1 or Z < 1 respectively. Z can take on values below 1 as long asand, otherwise Z will always activate R, as indicated by the areas marked TRUE in Fig. 5.

Let us say that X and Y settle on steady-state values X * ≡ η X, Y * ≡ η Y, as inputs to our logic gate. A value of η X or η Y significantly greater than 1 is then "high" (true, 1), and "low" (false, 0) if much less than 1. We then want to determine whether Z * is greater than (true) or less than (false) 1. For example, if n 1,2 > 0 (two repressors), Table 1 gives the possible steady states of Z. If η Z 1 and η Z 2 are greater than 1, these steady states approximate a NAND gate. If they are less than 1, but sum to greater than 1, the steady states instead approximate a NOR gate.

---

### A mathematical study to select fractionation regimen based on physical dose distribution and the linear-quadratic model [^115715d1]. International Journal of Radiation Oncology, Biology, Physics (2012). Low credibility.

Purpose

Hypofractionated irradiation is often used in precise radiotherapy instead of conventional multifractionated irradiation. We propose a novel mathematical method for selecting a hypofractionated or multifractionated irradiation regimen based on physical dose distribution adding to biologic consideration.

Methods and Materials

The linear-quadratic model was used for the radiation effects on tumor and normal tissues, especially organs at risk (OARs). On the basis of the assumption that the OAR receives a fraction of the dose intended for the tumor, the minimization problem for the damage effect on the OAR was treated under the constraint that the radiation effect on the tumor is fixed.

Results

For an N-time fractionated irradiation regimen, the constraint of tumor lethality was described by an N-dimensional hypersphere. The total dose of the fractionated irradiations was considered for minimizing the damage effect on the OAR under the hypersphere condition. It was found that the advantage of hypofractionated or multifractionated irradiation therapies depends on the magnitude of the ratio of α/β parameters for the OAR and tumor in the linear-quadratic model and the ratio of the dose for the OAR and tumor.

Conclusions

Our mathematical method shows that multifractionated irradiation with a constant dose is better if the ratio of α/β for the OAR and tumor is less than the ratio of the dose for the OAR and tumor, whereas hypofractionated irradiation is better otherwise.

---

### Double-layer geodesic and gradient-index lenses [^f9d05ba5]. Nature Communications (2022). High credibility.

Fig. 2
Double-layer lenses with foci at infinity.

The Generalized Maxwell Fish Eye profile can be used as a double-layer lens, with one homogeneous layer and foci at infinity. We show four examples, with ray turning angle Δ ϕ of π plus a π /4; b π /2; c π; and d 3 π /2. When M is an odd integer, the lens provides the functionality of an ordinary Eaton lens; when M is an even integer, it acts as an invisible lens where the rays travel in loops in the lens. Note that in Fig. 2 and the following figures the mirror coupling into lower waveguide is indicated as a red solid line, and the color of the rays (blue/green) indicates in which waveguide the propagation occurs (upper inhomogeneous index/lower homogeneous index).

If one focus lies on the rim of the lens r s = 1, and the other at infinity r i = ∞ we have a double-layer lens with a function of an ordinary Luneburg lens or beam divider, depending on the value of Δ ϕ. In this case, the half turning angle (13) takes the form

Inserting this expression in (14) and carrying out the integral over L, the corresponding expression for the turning point as a function ofisSubstitutinginto (29) we obtain an implicit equation for the refractive index as a function of radiuswhere α = M /(M + 1/2) and β = (M − 1)/(M + 1/2). Examples of the numerical solution to this equation are shown in the density plots within Fig. (3). We can also find the shape of the equivalent geodesic lensAgain, this can be treated as a special case of the general solution in Eq. (23), thus obtained by letting r s = 1, r i = ∞ in Eqs. (21), (22). In general, we must numerically evaluate the refractive index (30) and the surface height. However, in the special case of M = 1, the implicit Eq. (30) reduces to a quadratic equation n −4/3 − n −2/3 /2 − r 2 /2 = 0 in n −2/3, which has the solution (taking the root where n = 1 at r = 1)

---

### Recommendations for noninvasive evaluation of native valvular regurgitation: a report from the American Society of Echocardiography developed in collaboration with the Society for Cardiovascular Magnetic Resonance [^eb9274e5]. Journal of the American Society of Echocardiography (2017). Medium credibility.

Table 17 — impact of multivalvular disease on assessment of valvular regurgitation with Doppler echocardiography and cardiovascular magnetic resonance (CMR) — details lesion-specific effects and provides CMR quantification formulas. In aortic stenosis (AS), assessment of aortic regurgitation (AR) has little impact, although hemodynamically significant AR will increase the AS gradient, and for CMR the phase-contrast plane is better in the left ventricular outflow tract (LVOT). AS influences mitral regurgitation (MR): for constant regurgitant orifice area (ROA), regurgitant volume (RVol) increases in proportion to the square root of excess pressure; jet area is exaggerated beyond this, and ROA may increase if the left ventricle dilates. With AR coexisting with MR, left ventricular dilation may increase ROA, mixed regurgitant lesions render volumetric methods challenging because net forward flow must be sought (e.g., right ventricular outflow tract), and for CMR the formulas are MV RVol = LVSV - aortic forward flow; MR Reg fraction = MR RVol/ (LVSV - AR RVol). Mitral stenosis (MS) has little direct impact on AR, although delayed left ventricular filling might theoretically lengthen AR pressure half-time, and if the mitral valve is heavily calcified, it may shadow and decrease jet area and the appearance of the jet. For MS, the lesion is most likely to increase pulmonary artery pressure (PAP) and thus worsen RVol and jet area. Mitral regurgitation coexisting with AR has little direct impact, but mixed regurgitant lesions render volumetric methods challenging, and rapid early filling may decrease AR pressure half-time. For pulmonic stenosis (PS), pulmonic regurgitation (PR) assessment has little impact although PR will exacerbate the PS gradient; for CMR the phase-contrast plane is better in the right ventricular outflow tract (RVOT). In PS, increased right ventricular systolic pressure (RVSP) will worsen RVol and jet area for tricuspid regurgitation (TR), and if right ventricular dysfunction occurs, ROA may increase. With PR affecting TR, increased right ventricular volume may increase ROA and worsen RVol and jet area; CMR formulas are TRVvol = RVSV - pulmonic forward flow. TR Reg fraction = TR RVol/ (RVSV - PR RVol). Tricuspid stenosis (TS) has little direct impact, although concomitant TR will exacerbate the TS gradient. TR can alter PR interpretation because rapid right ventricular filling from TR may further shorten PR pressure half-time and make the color PR jet more brief.

---

### What quantile regression does and doesn' T Do: a commentary on petscher and logan (2014) [^220ddc10]. Child Development (2019). Medium credibility.

Petscher and Logan's (2014) description of quantile regression (QR) might mislead readers to believe it would estimate the relation between an outcome, y, and one or more predictors, x, at different quantiles of the unconditional distribution of y. However, QR models the conditional quantile function of y given x just as linear regression models the conditional mean function. This article's contribution is twofold: First, it discusses potential consequences of methodological misconceptions and formulations of Petscher and Logan's (2014) presentation by contrasting features of QR and linear regression. Second, it reinforces the importance of correct understanding of QR in empirical research by illustrating similarities and differences in various QR estimators and linear regression using simulated data.

---

### Wave kinetics of random fibre lasers [^49606376]. Nature Communications (2015). Medium credibility.

To deal with active cyclic systems, we derive a pumping-driven wave kinetic equation governing the fast and strong wave spectrum evolution within round trip, in addition to the 'standard' wave kinetic equation governing the slow and incremental wave spectrum evolution from cycle to cycle.

Further, we briefly outline the derivation of the kinetic equation for the cyclic active wave system having numerous random-phase waves non-linearly interacting via cubic non-linearity, which is assumed to be weak. We consider the quadratic dispersion law specific for optics and spectrally narrow excitations. The system is under periodic energy pumping and dumping repeated in a cyclic way and is evolving within each period and from cycle to cycle Fig. 1b.

We start from the generic dynamical equation describing the evolution of the complex envelope field ψ over the evolution coordinate z (that, for instance, can be a propagation distance inside the fibre cavity) in dispersive non-linear medium:

Here t stands for time, while z is the evolution coordinate within the cycle. For the wave system, coefficients β and γ describe, respectively, the dispersion and non-linearity of the running wave with intensity proportional to, the linear operatordescribes energy pumping/dumping into/from the system. In the particular case of optics, equation (1) is the generalized non-linear Schrödinger equation, which describes light propagation in one-dimensional media, γ is associated with Kerr non-linearity andis the operator describing an optical spectrally dependent gain. The dynamical models based on the non-linear Schrödinger equation (1) are widely used for describing laser radiation in fibre lasers (see refs,), as well as other optical systems characterized by strong influence of noise and stochasticity.

---

### A space-time tradeoff for implementing a function with master equation dynamics [^57fa10b0]. Nature Communications (2019). High credibility.

Master equations are commonly used to model the dynamics of physical systems, including systems that implement single-valued functions like a computer's update step. However, many such functions cannot be implemented by any master equation, even approximately, which raises the question of how they can occur in the real world. Here we show how any function over some "visible" states can be implemented with master equation dynamics-if the dynamics exploits additional, "hidden" states at intermediate times. We also show that any master equation implementing a function can be decomposed into a sequence of "hidden" timesteps, demarcated by changes in what state-to-state transitions have nonzero probability. In many real-world situations there is a cost both for more hidden states and for more hidden timesteps. Accordingly, we derive a "space-time" tradeoff between the number of hidden states and the number of hidden timesteps needed to implement any given function.

---

### Non-linear predictor outcome associations [^1763f9aa]. BMJ Medicine (2023). High credibility.

Modelling with explicit polynomials

Polynomial regression models specify the non-linear association using a polynomial of the predictor. The purple solid line in figure 2 shows the association between mental wellbeing and BMI as a cubic curve. Polynomials with a degree greater than 3 are not generally used as they are too sensitive to outliers. Correlation between polynomial terms can also make the estimation less robust. Because only two additional terms (quadratic and cubic) are used, cubic polynomial regression is not that accurate for capturing complex non-linear associations. Fractional polynomials, that is, where the power can be a fraction (eg, x 1/2), can also used, where the power of each term in the regression formula, and the number of terms, are selected by a data-driven algorithm. Fractional polynomials can capture complex associations better than cubic polynomials. Nonetheless, all polynomial regression (like linear regression) estimates its coefficients using all the data, which means that one outlier at an extreme value can markedly affect the curve.

Figure 2
Association between body mass index and mental wellbeing using non-linear methods. Mental wellbeing is norm referenced with a population mean of 50 and standard deviation of 10. Adjusted for age, sex, ethnicity, education, and baseline physical and mental wellbeing. Age and wellbeing variables were adjusted as P-splines. Primary sampling units and strata were adjusted using random intercepts.

---

### Optimized amplitude modulated multiband RF pulse design [^682a31f2]. Magnetic Resonance in Medicine (2017). Low credibility.

Root‐Flipping

Root‐flipping, as proposed by Sharma et al 5, takes a direct approach to multiband pulse design using the Shinnar‐Le Roux (SLR) method 9. Briefly, this method involves designing a pair of polynomials of complex exponentialsand, whose frequency representations yield the desired slice profile. Typically, the polynomial coefficients ofare obtained using digital filter design; can then be inferred using the equations 9 wheredenotes the Hilbert transform. The time‐domain representationsandare then subjected to the inverse SLR transform to recover the required RF pulse.can be expressed in polynomial form (as a sum of products) or in factored form (as a product of sums) as follows:whereare the polynomial coefficients, are the roots of the polynomialandis the degree of the polynomial.

When the roots are plotted on the complex plane, they are scattered around the unit circle. Flipping the passband roots radially from inside to outside or outside to inside the unit circle, changes the through‐slice phase profile without affecting the magnitude profile. In the time domain, root‐flipping redistributes the contributions associated with those frequencies across the duration of the RF pulse. The redistribution depends on the flipping pattern across the passband. Placing all roots inside (or outside) the unit circle leads to a maximum (or minimum) phase arrangement, and aligns the associated main amplitude peak at the start (or end) of the pulse. A search strategy can be used to find a flipping pattern that results in the distribution which leads to the minimum peak amplitude.

Amplitude modulated root‐flipped pulses can be designed by ensuring roots are located inside or outside the unit circle symmetrically about the real axis. This ensures thatis conjugate symmetric, such that its time domain representationis real‐valued. Whenis designed using Equations (7), (8), (9), in whichis an even function, its magnitude functionwill be even. Moreover, the phase response will be odd because the Hilbert transform of an even function is odd 10. Hence, will be conjugate symmetric, and finally the inverse SLR transform 9 yields an AM RF pulse when bothandare real‐valued. An illustration for the conjugate symmetric condition for each of the three techniques is shown in Figure 1.

---

### Matrix factorization from non-linear projections: application in estimating T2 maps from few echoes [^91a2e8bd]. Magnetic Resonance Imaging (2015). Low credibility.

This work addresses the problem of estimating T2 maps from very few (two) echoes. Existing multi-parametric non-linear curve fitting techniques require a large number (16 or 32) of echoes to estimate T2 values. We show that our method yields very accurate and robust results from only two echoes, where as the curve-fitting techniques require about 16 echoes to achieve the same level of accuracy. We model T2 maps as a rank-deficient matrix. Since the relationship between T2 values and intensity values/K-space samples is not linear, estimating the T2 values requires recovering a low-rank matrix from non-linear projections. We solve this as a non-linear matrix factorization problem. Since the said problem has not been solved before, we propose a simple algorithm for the same.

---

### Listing criteria for heart transplantation: International Society for Heart and Lung Transplantation guidelines for the care of cardiac transplant candidates – 2006 [^b96ac520]. The Journal of Heart and Lung Transplantation (2006). Medium credibility.

Multi-organ function and renal monitoring — As part of an evaluation of multi-organ function, routine laboratory testing should be obtained at each follow-up appointment, and if a patient is taking an anti-coagulant, prothrombin time/international normalized ratio (PT/INR) should be checked more frequently per protocol. Renal function should be assessed at least every 6 months by estimation of GFR, and the National Kidney Foundation recommends estimation of GFR by using prediction equations over traditional creatinine clearance because of problems associated with 24-hour creatinine clearance. The quadratic GFR equation is provided, and if SCr < 0.8 mg/dL, use 0.8 for SCr.

---

### High tip angle approximation based on a modified bloch-riccati equation [^346f756b]. Magnetic Resonance in Medicine (2012). Low credibility.

When designing a radio-frequency pulse to produce a desired dependence of magnetization on frequency or position, the small flip angle approximation is often used as a first step, and a Fourier relation between pulse and transverse magnetization is then invoked. However, common intuition often leads to linear scaling of the resulting pulse so as to produce a larger flip angle than the approximation warrants — with surprisingly good results. Starting from a modified version of the Bloch-Riccati equation, a differential equation in the flip angle itself, rather than in magnetization, is derived. As this equation has a substantial linear component that is an instance of Fourier's equation, the intuitive approach is seen to be justified. Examples of the accuracy of this higher tip angle approximation are given for both constant- and variable-phase pulses.

---

### Advanced statistics: linear regression, part I: simple linear regression [^18239641]. Academic Emergency Medicine (2004). Low credibility.

Simple linear regression is a mathematical technique used to model the relationship between a single independent predictor variable and a single dependent outcome variable. In this, the first of a two-part series exploring concepts in linear regression analysis, the four fundamental assumptions and the mechanics of simple linear regression are reviewed. The most common technique used to derive the regression line, the method of least squares, is described. The reader will be acquainted with other important concepts in simple linear regression, including: variable transformations, dummy variables, relationship to inference testing, and leverage. Simplified clinical examples with small datasets and graphic models are used to illustrate the points. This will provide a foundation for the second article in this series: a discussion of multiple linear regression, in which there are multiple predictor variables.

---

### A model for optimizing normal tissue complication probability in the spinal cord using a generalized incomplete repair scheme [^8683b9ed]. Radiation Research (2001). Low credibility.

The purpose of this study was to determine the treatment protocol, in terms of dose fractions and interfraction intervals, which minimizes normal tissue complication probability in the spinal cord for a given total treatment dose and treatment time. We generalize the concept of incomplete repair in the linear-quadratic model, allowing for arbitrary dose fractions and interfraction intervals. This is incorporated into a previously presented model of normal tissue complication probability for the spinal cord. Equations are derived for both mono-exponential and bi-exponential repair schemes, regarding each dose fraction and interfraction interval as an independent parameter, subject to the constraints of fixed total treatment dose and treatment time. When the interfraction intervals are fixed and equal, an exact analytical solution is found. The general problem is nonlinear and is solved numerically using simulated annealing. For constant interfraction intervals and varying dose fractions, we find that optimal normal tissue complication probability is obtained by two large and equal doses at the start and conclusion of the treatment, with the rest of the doses equal to one another and smaller than the two dose spikes. A similar result is obtained for bi-exponential repair. For the general case where the interfraction intervals are discrete and also vary, the pattern of two large dose spikes is maintained, while the interfraction intervals oscillate between the smallest two values. As the minimum interfraction interval is reduced, the normal tissue complication probability decreases, indicating that the global minimum is achieved in the continuum limit, where the dose delivered by the "middle" fractions is given continuously at a low dose rate. Furthermore, for bi-exponential repair, it is seen that as the slow component of repair becomes increasingly dominant as the magnitude of the dose spikes decreases. Continuous low-dose-rate irradiation with dose spikes at the start and end of treatment yields the lowest normal tissue complication probability in the spinal cord, given a fixed total dose and total treatment time, for both mono-exponential and bi-exponential repair. The magnitudes of the dose spikes can be calculated analytically, and are in close agreement with the numerical results.

---

### Inferring time derivatives including cell growth rates using gaussian processes [^b5444dae]. Nature Communications (2016). Medium credibility.

Methods

Using a Gaussian process to fit time-series data

In the following, we will denote a Gaussian distribution with mean μ and covariance matrix Σ as(μ, Σ) and use the notation of Rasmussen and Williamsas much as possible.

Prior probability

For n data points y i at inputs x i (each x i is a time for a growth curve), we denote the underlying latent function as f (x). We define a covariance matrix k (x, x ′), which has an explicit dependence on hyperparameters θ, and obeys

where the expectations are taken over the distribution of latent functions (samples of f (x)).

We interpret equation (1) as giving the prior probability distribution of the latent functions f (X), where were we use X to denote the inputs x i, such that

where K (X, X) is the n × n matrix with components k (x i, x j). With f denoting [f (x 1). f (x n)], this prior probability can be written as

noting the dependence of k (x, x ′; θ) on the hyperparameters θ.

---

### Satralizumab (Enspryng) [^00543c3e]. FDA (2025). Medium credibility.

12.1	Mechanism of Action

The precise mechanism by which satralizumab-mwge exerts therapeutic effects in NMOSD is unknown but is presumed to involve inhibition of IL-6-mediated signaling through binding to soluble and membrane-bound IL-6 receptors.

12.2 Pharmacodynamics

The relationship between any of the pharmacodynamic effects of ENSPRYNG and clinical outcomes in NMOSD is unknown.

12.3 Pharmacokinetics

The pharmacokinetics of ENSPRYNG have been characterized both in Japanese and Caucasian healthy volunteers, and in NMOSD patients. The pharmacokinetics in NMOSD patients using the recommended dose were characterized using population pharmacokinetic analysis methods based on a database of 154 patients.

The concentration-time course of ENSPRYNG in patients with NMOSD was accurately described by a two-compartment population pharmacokinetic model with parallel linear and target-mediated (Michaelis-Menten) elimination and first-order subcutaneous absorption. ENSPRYNG clearance and volume parameters allometrically scaled by body weight (through power function with the fixed power coefficient of 0.75 and 1 for clearance and volume parameters, respectively). Body weight was shown to be a significant covariate, with clearance and Vcfor patients weighing 123 kg (97.5th percentile of the weight distribution) increased by 71.3% and 105%, respectively, compared to a patient weighing 60 kg.

Steady state pharmacokinetics were achieved after the loading period (8 weeks) as follows [mean (± SD)]: Cmin: 19.7 (12.2) mcg/mL, Cmax: 31.5 (14.9) mcg/mL, and AUC: 737 (386) mcg.mL/day.

Absorption

The bioavailability of satralizumab-mwge was 85%.

Distribution

Satralizumab-mwge undergoes biphasic distribution. The central volume of distribution was 3.46 L and the peripheral volume of distribution was 2.07 L. The inter-compartmental clearance was 0.336 L/day.

Elimination

The total clearance of satralizumab-mwge is concentration-dependent. Linear clearance (accounting for approximately half of the total clearance at steady state using the recommended dose in NMOSD patients) is estimated to be 0.0601 L/day. The associated terminal t1/2is approximately 30 days (range 22–37 days) based on data pooled from Study 1 and Study 2.

---

### Primer on binary logistic regression [^4e5ef025]. Family Medicine and Community Health (2021). Medium credibility.

The twovalues are below two and so are not problematic. For this model, the no perfect multicollinearity assumption is met.

The linearity assumption requires that continuous independent variables, or predictors, have a linear relationship with the log-odds of the predicted probabilities for the outcome. Linear relationships are relationships that seem to follow a relatively straight line. One way to check this relationship is to create a scatterplot with the continuous predictor on the x-axis and the log-odds of the predicted probabilities on the y-axis. Add a loess curve and a line representing a linear relationship between the two variables to the scatterplot. The loess curve shows the relationship between the predictor and the transformed outcome in a more nuanced way, while the fitted line shows what the relationship between the two would be if it were linear. If the loess curve and the fitted line are approximately the same, the linearity assumption is met. If the loess curve deviates from the line, the linearity assumption fails.

The loess curve is very close to the linear relationship so the linearity assumption appears to be met (figure 2). Assuming that these data were collected using an acceptable sampling frame without related observations (independence of observations assumption), the data meet the assumptions to report the model as unbiased.

Figure 2
Checking the linearity assumption graphically.

Step 3: estimate the binary logistic regression model

The dependent variable for binary logistic regression is a categorical variable with two categories (denoted as y in equation 1). In the statistical model it is transformed using the logit transformation into a probability ranging from 0 to 1 (equation 1).

Equation 1. A statistical form of the binary logistic regression model.

In equation 1, the p(y) stands for the probability of one category (often the presence of a behaviour or condition) of the dependent variable, theare coefficients of the independent variables or predictors, and theare the independent variables. Those who are familiar with linear regression might notice that the statistical form of the linear regression model is inside the parentheses of the exponent ofin the denominator of the right-hand side of the equation.

---

### Statistics review 7: correlation and regression [^4cb8dd2d]. Critical Care (2003). Low credibility.

The present review introduces methods of analyzing the relationship between two quantitative variables. The calculation and interpretation of the sample product moment correlation coefficient and the linear regression equation are discussed and illustrated. Common misuses of the techniques are considered. Tests and confidence intervals for the population parameters are described, and failures of the underlying assumptions are highlighted.

---

### Standards of care in diabetes – 2025 [^ef149bc3]. Diabetes Care (2025). High credibility.

Regarding specific circumstances for diabetic nephropathy, more specifically with respect to pediatric patients, ADA 2025 guidelines recommend to determine the eGFR at the time of diagnosis and annually thereafter.

---

### A unique analytical solution of the white matter standard model using linear and planar encodings [^f12d8453]. Magnetic Resonance in Medicine (2019). Medium credibility.

Purpose

It is known that white matter modeling based on commonly used linear diffusion encoding is an ill-posed problem. We analyze the additional information gained from a double pulsed diffusion encoding.

Methods

Zeroth (spherical means) and second-order (harmonic powers) rotation invariant signal features are used to factor micro- and mesoscopic contributions. The b-value dependency up to second-order of the features form 6 nonlinear equations, which are analyzed.

Results

The 6 derived equations can be uniquely solved for all relevant biophysical parameters. No assumptions about the form of the mesoscopic contribution (fiber dispersion) is necessary. Under certain conditions the solution still shows a certain degeneracy which is inherent to model. It is further shown that a combination of second-order information from single and spherical diffusion encoding is not enough to solve the problem.

Conclusions

A combination of single and double pulsed diffusion encodings is sufficient to solve the full 3 compartment white matter model uniquely.

---

### A single inverse-designed photonic structure that performs parallel computing [^cbb42b17]. Nature Communications (2021). High credibility.

In the search for improved computational capabilities, conventional microelectronic computers are facing various problems arising from the miniaturization and concentration of active electronics. Therefore, researchers have explored wave systems, such as photonic or quantum devices, for solving mathematical problems at higher speeds and larger capacities. However, previous devices have not fully exploited the linearity of the wave equation, which as we show here, allows for the simultaneous parallel solution of several independent mathematical problems within the same device. Here we demonstrate that a transmissive cavity filled with a judiciously tailored dielectric distribution and embedded in a multi-frequency feedback loop can calculate the solutions of a number of mathematical problems simultaneously. We design, build, and test a computing structure at microwave frequencies that solves two independent integral equations with any two arbitrary inputs and also provide numerical results for the calculation of the inverse of four 5x5 matrices.

---

### Solving the where problem and quantifying geometric variation in neuroanatomy using generative diffeomorphic mapping [^fd44f32f]. Nature Communications (2025). High credibility.

The statistical interpretation allows us to accommodate images with non reference signals, such as missing tissue, tracer injection sites, or other anomalies. At each pixel, the identity of the signal type is modeled as missing data, and maximum likelihood estimators are computed using an Expectation Maximization algorithm, which alternates between the E step: compute posterior probability π i (x) that each pixel corresponds to the reference image rather than one of the non-reference types, and the M step: update parameters by solving a posterior weighted version of the above:As an EM algorithm, this approach is guaranteed to be monotonically increasing in likelihood. An example of posterior weights are shown in the right hand column of Fig. 2 b.

Our approach uses mixtures of Gaussians to model variability in data, to allow large outliers to be accommodated by additional components, even though the Gaussian distribution itself does not have long tails. The Gaussian model allows for closed form expression (in terms of matrix inverse) for contrast transformation parameters. Other groups have used long tailed distributions to model variability and outliers in a robust manner, most notably the exponential distribution for l1 optimization. Techniques such as iteratively reweighted least squares can be applied as in Reuter et al. which lead lead to a weighted least squares problem which is similar to ours.

Nonconvex optimization with low to high dimensional subgroups and resolutions

This registration problem is highly nonconvex, and allows for many local minima. To provide robustness in our solution, we solve a sequence of lower dimensional subproblems, initializing the next with the solution to the previous. (i) 2D slice to slice rigid alignment maximizing similarity to neighbors(ii) 3D affine only alignment, registration using the full model at (iii) low (200 μm), (iv) medium (100 μm), and (v) high (50 μm) resolution. Time varying velocity fields are discretized into 5 timesteps and integrated using the Semi Lagrangian method. For most subproblems, spatial transformation parameters are estimated by gradient descent, and intensity transformation parameters are updated by solving a weighted least squares solution at each iteration. For subproblems that include linear registration only, parameters are estimated using Reimannian gradient descent (discussed in ref.and similar to a second order Gauss–Newton optimization scheme).

---

### Similarity and economy of scale in urban transportation networks and optimal transport-based infrastructures [^196ef8b8]. Nature Communications (2024). High credibility.

Having introduced the main problem and ideas, we now briefly describe the model. Consider a surface in 2D and a set of points on it. Specifically, we denote a set of origins and destinations as f + and f −, respectively. These contain the reference points where people enter and exit the transportation network. By defining f = f + − f −, mass conservation can be enforced with the constraint ∫ f d x = 0. The two main quantities of interest are denoted with μ (x, t), the transport density (or conductivity), and u (x, t) the transport potential. The former can be seen as a quantity proportional to the size of a network edge, while the latter determines the fluxes traveling along them. The dynamical equations in this continuous setting areEquation (1) determines the spatial balance of the flux, assumed to be governed by the Fick–Poiseuille flux as q = − μ ∇ u; Eq. (2) enforces optimal solutions, and represents the P. polycephalum dynamics in the continuous domain; Eq. (3) is the initial condition. The parameter β captures different optimization mechanisms: β < 1 enforces congested transportation, β = 1 is the shortest path-like and β > 1 is branched transportation. In Fig. 1 f–h we show examples of different optimal configurations, with β = 1, β = 1.5 and β = 2.0. Here, we consider the cases 1 < β ≤ 2, where the approximate support of the conductivity μ displays a network-like structure. Under the lenses of a network, the conductivities can be viewed as the traffic capacities on the edges, hence Eq. (3) defines how the initial traffic capacities are distributed along the network, while Eq. (2) describes how these capacities evolve in response to the fluxes. As time evolves (i.e.), the equilibrium solution pair (μ *, u *) is reached. In refs. the authors show that under certain assumptions, this equilibrium solution is a minimizer of the functionalThis can be interpreted as the network transportation cost, where the first term is a network operating cost (or power dissipation, it is the Dirichlet energy to the solution of the first partial differential equation), while the second is a non-linear cost to build the infrastructure. When β > 1, this second term corresponds to a principle of economy of scale, where it is more convenient to consolidate traffic into fewer (but larger) edges. This is the scenario we consider here. By changing β, one can tune their relative contribution to the total transportation cost, thus tuning the impact of the principle of economy of scale and how much concentrated path trajectories are. Besides being relevant for urban transportation, this strategy seems to be a fundamental mechanism in various natural systems, e.g. tree branches and roots, blood vessels or river networks.

---

### Modeling and measurement of lead tip heating and resonant length for implanted, insulated wires [^11bf46c2]. Magnetic Resonance in Medicine (2024). Medium credibility.

Another limitation of the study is that we did not independently optimizefor the simulated electric field case because of computational complexity. However, because the transmission line model with the simulated electric field in Figure 7 appears similar to the transmission line model with the constant electric field in Figure 6, we think adopting Γ from the constant electric field is a reasonable assumption.

We mentioned earlier that the signs of the real and imaginary part of the wavenumber are open to choice because of the square roots of Equations (1) and (2). Although the real partis never negative because of Equation (7), Liu et al.and King et al.adopted opposite sign conventions for. Here, we used the conventionin agreement with Liu et al.for all equations in this article, except foronly when evaluating Equation (2), because King adopted the sign convention(page 1695 in King et al.).

After these models have been further validated, they could provide useful guidance in clinical settings as well as for device companies. Clinically, they could guide lead placement, as well as how to avoid resonant lengths if a lead needs to be cut and abandoned. The MATLAB-based toolscould promote the wider use of the King wavelength and provide a better estimate of resonant length. For example, device manufacturers have some latitude in choosing the radii of the leads and insulating layers, as well as the dielectric constant of the insulating layer, which directly affect the wavenumber, which in turn affects resonant length.

---

### Denoising brain networks using a fixed mathematical phase change in independent component analysis of magnitude-only fMRI data [^d80af135]. Human Brain Mapping (2023). Medium credibility.

In addition, we define the percentage of large phase voxels (PoLPV) at ∆ φ = π /4 to further evaluate the mapping framework as follows:whereis the number of voxels with absolute phase values within [0, π /4], and the large phase denotes the phase values larger than π /4 for mSSP of a real‐valued ICA map or for absolute SSP of a complex‐valued ICA map. Given the mapping function, we can also compute PoLPV(π /4) using the cumulative distribution function (CDF) strategy as follows:wheredenotes the x value for, and we indeed use the right half of the mapping function, as shown in Figure 4.

As such, we can verify the effects of denoising (square, smooth, root) in terms of PoLPV (π /4) computed in two ways: (1) experimental computation using Equation (11); (2) theoretical strategy based on CDF using Equation (12) based on the mSSP values obtained from both simulated and experimental fMRI data. Figure 15 displays the results from the CDF strategy and the mSSP values. We see that the denoising (square, smooth, root) consistently enables the increase of PoLPV, and the PoLPV increase in the mSSP values is higher than that in the CDF values, demonstrating the good performance of mSSP denoising for real‐valued ICA maps.

FIGURE 15
A comparison of the percentage of large phase voxels (PoLPV) larger than π /4 computed by CDF strategy and mSSP values for normalized and denoised (square, smooth, root) ICA maps from (a) simulated and (b) experimental fMRI data. The results in (a) are averaged across C1–C7 maps extracted from simulated phase and magnitude data of all subjects under five CNRs, and the results in (b) are averaged across ACC maps extracted from the phase and magnitude of complex‐valued UNM data and the magnitude‐only HCP data of all subjects.

---

### X-linked hypophosphatemia management in adults: an international working group clinical practice guideline [^86938644]. The Journal of Clinical Endocrinology and Metabolism (2025). High credibility.

Regarding screening and diagnosis for X-linked hypophosphatemia, more specifically with respect to differential diagnosis, XLH-IWG 2025 guidelines recommend to obtain an evaluation of other possible causes of hypophosphatemia considering the differential.

---