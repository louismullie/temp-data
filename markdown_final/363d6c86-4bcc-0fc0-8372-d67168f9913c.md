# Medical Question & Answer

**Sample ID**: 363d6c86-4bcc-0fc0-8372-d67168f9913c
**Dataset Index**: 46177

---

## Question

Example 5 Let P be a point inside △ABC, and let D, E, F be the feet of the perpendiculars from P to BC, CA, AB respectively: Find all points P that minimize [BC/PD] + [CA/PE] + [AB/PF].
(22nd IMO)

---

## Answer

> Let's see… What do we have here? The user is asking which point P inside triangle ABC minimizes the expression BC/PD + CA/PE + AB/PF, where PD, PE, PF are the perpendicular distances from P to sides BC, CA, AB respectively. Let's break this down step-by-step. First, I need to think about how to set up the problem analytically and what constraints apply. Then, I should consider whether symmetry or special points like the incenter or centroid are candidates. Next, I will try to apply an inequality approach, likely Cauchy–Schwarz or a weighted variant, to bound the expression. After that, I should verify the equality conditions and check whether the minimum is attained at a unique point. Finally, I will synthesize the conclusion and ensure it aligns with geometric intuition and the inequality logic.

> Let me first confirm the setup and notation. P is an interior point of triangle ABC, and PD, PE, PF are the altitudes from P to sides BC, CA, AB respectively. The expression to minimize is S = BC/PD + CA/PE + AB/PF. I need to ensure that PD, PE, PF are positive, which they are for an interior point, and that the side lengths BC, CA, AB are fixed positive constants for the given triangle [^notfound].

> Wait, let me verify the natural candidates before jumping into inequalities. The incenter comes to mind because it is equidistant to all sides, but I should be cautious: equidistance does not automatically imply minimality for a weighted sum of reciprocals. The centroid minimizes the sum of squared distances, which is a different objective, so I should not assume it helps here. I will keep both in mind but not jump to conclusions until I see the inequality structure [^notfound].

> I will now examine the problem through a weighted Cauchy–Schwarz approach. Let me consider the expression S = BC/PD + CA/PE + AB/PF and think about pairing it with a sum that involves PD, PE, PF in the numerator. A classic trick is to multiply S by (BC·PD + CA·PE + AB·PF) and apply Cauchy–Schwarz, but hold on, I should verify what BC·PD + CA·PE + AB·PF actually represents geometrically before proceeding [^notfound].

> Let me think about the geometric meaning of BC·PD + CA·PE + AB·PF. This is twice the area of triangle ABC, because each term is twice the area of one of the subtriangles PBC, PCA, PAB. So BC·PD + CA·PE + AB·PF = 2Δ, where Δ is the area of triangle ABC, and this is constant regardless of P's position. That constancy is exactly what I need to anchor the inequality argument [^notfound].

> Now, applying Cauchy–Schwarz, I should confirm the form. Let me write S = BC/PD + CA/PE + AB/PF and consider the product S · (BC·PD + CA·PE + AB·PF). By Cauchy–Schwarz, this is at least (BC + CA + AB)^2, with equality when BC/PD: CA/PE: AB/PF = BC·PD: CA·PE: AB·PF. Simplifying the equality condition gives PD = PE = PF, which means P is equidistant from all three sides, i.e. P is the incenter of triangle ABC [^notfound].

> Hold on, I should verify the uniqueness and attainability. The inequality shows the minimum value is (BC + CA + AB)^2 / (2Δ), and equality holds if and only if PD = PE = PF, which uniquely characterizes the incenter. Since the incenter lies inside the triangle, the minimum is indeed attained at the incenter, and no other interior point satisfies the equality condition, so the solution is unique [^notfound].

> But wait, what if I tried a different inequality or approach? Let me reconsider whether Jensen's inequality or AM–GM could help. Initially, I thought AM–GM might directly apply, but I realize that would push me toward minimizing PD + PE + PF, which is not the objective here; the weights BC, CA, AB matter, and Cauchy–Schwarz is the right tool because it respects those weights and leverages the constant-area identity. So my first instinct to use AM–GM was off, and Cauchy–Schwarz is the correct path [^notfound].

> I should double-check the final statement. The point P that minimizes BC/PD + CA/PE + AB/PF is the incenter of triangle ABC, and the minimum value is (BC + CA + AB)^2 divided by twice the area of triangle ABC. This follows from the weighted Cauchy–Schwarz inequality and the fact that BC·PD + CA·PE + AB·PF = 2Δ for any interior point P [^notfound].

---

The point (P) that minimizes [BC/PD] + [CA/PE] + [AB/PF] is the **incenter** of triangle (ABC). This is because the incenter is equidistant from all sides, so (PD = PE = PF = r) (the inradius), and the expression becomes [(BC + CA + AB)/r], which is minimal since (r) is the largest possible inradius for any interior point. By the Cauchy-Schwarz inequality, any deviation from the incenter increases the sum, confirming the incenter as the unique minimizer.

---

## Geometric interpretation and setup

Let (P) be a point inside triangle (ABC), and let (D, E, F) be the feet of the perpendiculars from (P) to sides (BC, CA, AB) respectively. The distances (PD, PE, PF) are the perpendicular distances from (P) to the sides. The expression to minimize is:

[BC/PD] + [CA/PE] + [AB/PF]

---

## Application of the Cauchy-Schwarz inequality

The key insight is to apply the **Cauchy-Schwarz inequality** in the following form:

([BC/PD] + [CA/PE] + [AB/PF]) (BC × PD + CA × PE + AB × PF) ≥ (BC + CA + AB)²

The second factor, (BC × PD + CA × PE + AB × PF), equals twice the area of triangle (ABC) (denoted (2Δ)), because each term is twice the area of the sub-triangle formed by (P) and two vertices. Thus:

([BC/PD] + [CA/PE] + [AB/PF]) × 2Δ ≥ (BC + CA + AB)²

Rearranging gives:

[BC/PD] + [CA/PE] + [AB/PF] ≥ [(BC + CA + AB)²/2Δ]

---

## Condition for equality

Equality in Cauchy-Schwarz holds when the vectors are proportional, which here means:

[BC/PD]: [CA/PE]: [AB/PF] = BC × PD: CA × PE: AB × PF

This simplifies to (PD = PE = PF), i.e. (P) is equidistant from all three sides. The unique point inside a triangle equidistant from all sides is the **incenter**.

---

## Verification with the incenter

Let (P) be the incenter, and let (r) be the inradius. Then (PD = PE = PF = r), and the expression becomes:

[(BC + CA + AB)/r]

Since (r) is the largest possible inradius for any interior point, this value is minimal. Any other point (P) would have at least one distance smaller than (r), increasing the corresponding term and thus the total sum.

---

## Conclusion

The point (P) that minimizes [BC/PD] + [CA/PE] + [AB/PF] is the **incenter** of triangle (ABC). This result follows from the Cauchy-Schwarz inequality and the geometric property that the incenter is equidistant from all sides of the triangle.

---

## References

### Quantification of surgical route parameters for exposure of the jugular foramen via a trans-mastoidal approach exposing jugular foramen in three-dimensional visualization model [^7f42670d]. The Journal of Craniofacial Surgery (2018). Low credibility.

Objective

Surgical operation within the region of the jugular foramen presents a great challenge. The authors characterized the quantitative impact of surgical window parameters on the exposure of the jugular foramen via a trans-mastoidal approach.

Methods

Computed tomography and magnetic resonance imaging data were used to establish a 3-dimensional model of the jugular foramen region. The mastoidale, posterior edge of the mastoid, and the superior edge of the bony external acoustic meatus were selected as points a, b, and c. The anterior edge of the tuberculum jugulare was selected as point d. The midpoints of line segments ab, ac, and bc were selected as points e, f, and g. Triangle abc was divided into triangles aef, beg, cfg, and efg. Surgical corridors of the triangular pyramid were outlined by connecting the above triangles to point d. Anatomic exposure was evaluated by measuring the area and volume of various structures within each route. Statistical comparisons were performed via analysis of variance.

Results

The model allowed for adequate visualization of all structures. The areas of triangles beg and efg were greater than those of triangles aef and cfg (P < 0.05). The volumes of triangular pyramids d-beg and d-cfg were greater than those of triangular pyramids d-aef and d-efg (P = 0.000). Statistically significant differences were also observed for volumes of osseous, venous, and cranial nerve structures in all divided routes (P = 0.000).

Conclusion

Our results indicate that 3-dimensional modeling may aid in the quantification of surgical exposure and that division of the craniotomy window may allow for more precise operation.

---

### Reduction of artefacts caused by hip implants in CT-based attenuation-corrected PET images using 2-D interpolation of a virtual sinogram on an irregular grid [^afba8cf0]. European Journal of Nuclear Medicine and Molecular Imaging (2011). Low credibility.

Delaunay triangulation

Delaunay triangulation was proposed in 1934 and was used in many mathematical applications. We assume that there is a set, V, representing a set of N ≥ 3 points in the Euclidean plane, and that these points are not collinear and any four points are not co-circular. The Delaunay triangulation of this set, DT (V), divides the plane into triangles with vertices located on the points, which intersect in a common side. Delaunay triangulation has the property that the circumcircle of the triangles are empty, i.e. they contain no point of V in their interior (Fig. 2). To ensure that none of the points is inside the circumcircle of one triangle, an incircle test is applied to four distinct points. Consider the points A, B, C and D in Fig. 3. If A, B and C define a counterclockwise-oriented triangle, point D will be inside the circumcircle of the triangle ABC if the following condition is met:

Fig. 2
Example of Delaunay triangulation. Note that none of the points is inside the circumcircle of all triangles

Fig. 3
Incircle test applied to four distinct points: A, B, C and D

The proof can be found in.

After defining an irregular grid on the data points of the sinogram matrix which are not affected by metallic objects, we need to use an interpolation technique.

---

### MPicker: visualizing and picking membrane proteins for cryo-electron tomography [^35bdadb9]. Nature Communications (2025). High credibility.

Here, MPicker uses OptCuts software and provides a wrapper for convenience. OptCuts is a software that can automatically calculate parameterization with small distortions for triangle meshes. The user simply specifies a threshold for the degree of distortion, and OptCuts minimizes the lengths of the cuts made on the meshes while ensuring that the average distortion remains below the specified threshold. The advantage of this method is that the surface can exhibit a small overall distortion after flattening, without being cut into fragments. OptCuts measures the distortion using, whereandhave similar meanings as in Eq. 9.

---

### Performance characteristics of methods for quantifying spontaneous intracerebral haemorrhage: data from the efficacy of nitric oxide in stroke (ENOS) trial [^81f2b5b8]. Journal of Neurology, Neurosurgery, and Psychiatry (2015). Low credibility.

The sources of error that effect variation between ABC/2 and SAS merit consideration. First, the largest diameter of haemorrhage was measured in the axial plane but this may not be the largest ICH diameter, which may also have contributed to differences between 'A' and the visual size categorisation. Sucu et al suggested using the maximum length and width not necessarily on the same slice and found better correlation between ABC/2 and SAS. However, this adaptation applies only to chronic subdural haematomas which differ from spontaneous haemorrhages by extending to the cranial vault and being crescentic. Second, when using ABC/2, the scan plane is measured through AB/2, the formula for the area of a triangle. However, a triangle is not necessarily the most appropriate description of a haematoma. Last, standard ABC/2 approximates the haematoma volume as an ellipsoid with all three axes extending in three perpendicular directions; to compensate for the varying slice thickness, 'C' is derived by multiplying the number of slices of which the haematoma is seen by the slice thickness in centimetres. For the modified ABC/2, 'C' does not include slices if the area of the haemorrhage is less than 25% of the largest area, an approach that has no theoretical justification. Hence, this method does not estimate all three Cartesian coordinates of the ellipsoid. Since the modified ABC/2 method underestimated the ICH volume (by 2–4 cm³), and small differences in volume equate to the variation in outcome, the modified ABC/2 method cannot be recommended. Further, modern CT scanners provide thin slices and the ability to directly measure 'C', thereby eliminating the need for approximating slice areas.

---

### A general method for the creation of dilational surfaces [^6025b588]. Nature Communications (2019). High credibility.

Dilational structures can change in size without changing their shape. Current dilational designs are only suitable for specific shapes or curvatures and often require parts of the structure to move perpendicular to the dilational surface, thereby occupying part of the enclosed volume. Here, we present a general method for creating dilational structures from arbitrary surfaces (2-manifolds with or without boundary), where all motions are tangent to the described surface. The method consists of triangulating the target curved surface and replacing each of the triangular faces by pantograph mechanisms according to a tiling algorithm that avoids collisions between neighboring pantographs. Following this algorithm, any surface can be made to mechanically dilate and could, theoretically, scale from the fully expanded configuration down to a single point. We illustrate the method with three examples of increasing complexity and varying Gaussian curvature.

---

### Multiple tipping points and optimal repairing in interacting networks [^bf70cdce]. Nature Communications (2016). Medium credibility.

Geometry of the Manhattan distance minimization problem

The optimal strategies shown in different colours in Fig. 5 are derived from the geometrical reasoning shown in Fig. 9. Figure 9a shows a plot of a series of curves consisting of points at identical Manhattan distances from point S 1 (equidistant curves). They produce a 'diamond' shape, and the minimal Manhattan distance between point S 1 and the green region translates into the task of 'fitting' the diamond so that it just touches the green region and its centre is at S 1. The diamond in Fig. 9a touches the green region at two points — triple points, which are the solution to the minimization problem. Figure 9b shows the solution for point S 6 in the light blue region. Here the solution suggests a different strategy — decreasing only.

---

### Topologically optimized intrinsic brain networks [^295309dd]. Human Brain Mapping (2025). Medium credibility.

This loss function is then optimized using stochastic gradient descent. As the loss function itself tends to overfit to the topological term, resulting in subject maps that are quite similar to the reference maps, we needed a method for early stopping. Based on empirical evaluations, we found that 150 iterations were sufficient for our purposes. For our method to work properly, the subject spatial map, must begin with a sound initial state, to avoid non‐optimal local minima during training. This is why we first initialize every subject spatial map as the OLS best fit using the Moore‐Penrose pseudoinverse. Importantly, this OLS is computed using all network timecourses, but the topological correction algorithm is computed per network. A diagram of our methodology is in Figure 4.

FIGURE 4
A diagram of our methodology. We start by estimating the reference network, and its associated PD. Then, we initialize the subject network, such thatis the OLS estimation. For each iteration, we compute the subject PD, and estimate.is the final subject estimation. Blue are negative and Red are positive.

This method was originally developed in (Lewis et al.) for 2D slices. This work extends the original work by being adapted for 3D images. The original work only used 2D topological objects in 2D space. While this work includes 2D topological objects in both 3D space, meaning in the x, y, and z axes, as opposed to just the x and y axes.

2.6 Training and Gradients

The gradients for the training phase are computed the same way as laid out in the original paper (Gabrielsson et al.). Essentially, each birth‐death pair can be mapped to a single voxel. For the 2D case, as laid out in their paper, every homological object is mapped to a single simplex, or triangle, line, and point, which is then mapped to a single voxel in the subject maps, such that each voxel maps to one point, two lines, and two triangles; excluding edge voxels. However, in our case, every voxel now maps to points, lines, and triangles in 3 dimensions. This means that each voxel maps to one point, three lines, and two triangles. For the gradient computation, a gradient is computed for each homological object, and this gradient is then applied to a given voxel based on this mapping.

---

### Dyke intrusion between neighbouring arc volcanoes responsible for 2017 pre-eruptive seismic swarm at agung [^e9bfdf68]. Nature Communications (2019). High credibility.

Markov Chain Monte-Carlo (MCMC) inversions currently are too computationally expensive to be used with Finite Element Models as about 100,000 simulations are typically required to characterize the a-posteriori probability density function for each model parameter. For an analytical model (1 simulation per second), this requires about a day, but for a 3D FEM (1 simulation per minute), this would require about 70 days of computation. We therefore use hybrid optimization scheme combining (1) a random search (Monte-Carlo) for the initialization of the parameter values and (2) a downhill simplex method (Nelder−Mead) for convergence towards the optimal parameters. The downhill simplex (Nelder−Mead) method is applicable to non-linear optimization problems for which the derivatives are unknown. The method uses the concept of a simplex, which is a polytope of n + 1 vertices in n dimensions (e.g. a triangle on a plane or a tetrahedron in 3D) to find the minimum of the objective function. The optimization consists of a series of steps where the point of the simplex with the largest objective function moves towards a lower point. The limitation of the Nelder−Mead technique is that it may converge to a local minimum and the result can be strongly dependent on the set of parameters chosen for the first simplex. To avoid this, we run a series of Nelder−Mead optimizations with initializations defined by a Monte-Carlo exploration of the parameter space.

We initially perform 1000 random-search simulations and the models with the smallest objective function are selected and used for the initial simplex. After each Nelder−Mead optimization, we calculate the mean and the standard deviation between the final values obtained for each parameter (red circles in Fig. 9). A new Nelder−Mead optimization is performed as long as the standard deviation remains above 10% of the mean value, and only 20 Nelder−Mead simulations are required for most of the model parameters to meet the criterion (Supplementary Table 3). Our hybrid approach significantly reduces the computing time compared to an MCMC approach, as in total only 4000 forward models were required for the optimization. For the inversion of the temporal subdivisions, we reduce the time even further by using the best-fitting dyke intrusion model for the cumulative displacement to initialize the inversion and a downhill simplex approach to search for nearby minima.

---

### Four-component protein nanocages designed by programmed symmetry breaking [^4736d2d0]. Nature (2025). Excellent credibility.

Fig. 1
Overview of the design strategy.

a – c, General design route to T = 4 icosahedral cages using substructures extracted from a T = 1 cage. Twelve pentagonal substructures (pentons) from a T = 1 cage (a) are docked with 20 homotrimers to form a closed cage structure (b), which creates hexagonal local structures (shaded red) placed between pentons (shaded yellow; c). d – f, Schematic of the route to T = 4 tetrahedral (d), octahedral (e) and icosahedral (f) cages. Step 1: T = 1 cages are designed starting from C3 symmetric trimeric building blocks. Step 2: the trimers constituting each face of the T = 1 cages are displaced away from the origin along the symmetry axis orthogonal to the face (left) and replaced by ABC-type pseudosymmetric heterotrimers to produce crowns in which one of the three components (yellow) is free to be designed to dock to other building blocks (right). Step 3: the crowns are docked with a new set of homotrimers aligned along the threefold symmetry axis of each architecture, which produces T = 4 cages.

---

### Solving olympiad geometry without human demonstrations [^34ba4bce]. Nature (2024). Excellent credibility.

Fig. 5
AlphaGeometry discovers a more general theorem than the translated IMO 2004 P1.

Left, top to bottom, the IMO 2004 P1 stated in natural language, its translated statement and AlphaGeometry solution. Thanks to the traceback algorithm necessary to extract the minimal premises, AlphaGeometry identifies a premise unnecessary for the proof to work: O does not have to be the midpoint of BC for P, B, C to be collinear. Right, top, the original theorem diagram; bottom, the generalized theorem diagram, in which O is freed from its midpoint position and P still stays on line BC. Note that the original problem requires P to be between B and C, a condition where the generalized theorem and solution does not guarantee.

Human expert evaluation of AlphaGeometry outputs

Because AlphaGeometry outputs highly interpretable proofs, we used a simple template to automatically translate its solutions to natural language. To obtain an expert evaluation in 2000 and 2015, during which AlphaGeometry solves all geometry problems and potentially passes the medal threshold, we submit these solutions to the USA IMO team coach, who is experienced in grading mathematical olympiads and has authored books for olympiad geometry training. AlphaGeometry solutions are recommended to receive full scores, thus passing the medal threshold of 14/42 in the corresponding years. We note that IMO tests also evaluate humans under three other mathematical domains besides geometry and under human-centric constraints, such as no calculator use or 4.5-h time limits. We study time-constrained settings with 4.5-h and 1.5-h limits for AlphaGeometry in Methods and report the results in Extended Data Fig. 1.

Learning to predict the symbolic engine's output improves the language model's auxiliary construction

In principle, auxiliary construction strategies must depend on the details of the specific deduction engine they work with during proof search. We find that a language model without pretraining only solves 21 problems. This suggests that pretraining on pure deduction proofs generated by the symbolic engine DD + AR improves the success rate of auxiliary constructions. On the other hand, a language model without fine-tuning also degrades the performance but not as severely, with 23 problems solved compared with AlphaGeometry's full setting at 25.

---

### Universal non-hermitian skin effect in two and higher dimensions [^9618dcd5]. Nature Communications (2022). High credibility.

Fig. 3
The corner-skin effect and the geometry-dependent-skin effect.

The universal skin effect can be further classified into two types by the current functional, that is, non-reciprocal skin effect (∃ α, n, J α [n] ≠ 0) and generalized reciprocal skin effect (∀ α, n, J α [n] = 0). CSE (a)–(d) and GDSE (e)-(h) are representatives of these two types of skin effects, respectively. In (a, b, e, f), the light blue regions represent the spectrum under periodic boundary, where 200*200 k -grid is used, and the red points represent the eigenvalues under different open-boundary geometries. The system size under square geometry in (c, g) is L x × L y = 60 × 60, and each triangle geometry in (d, h) has the same right-angled side length L x = L y = 60. The spatial distributions of eigenstates W (x) are plotted in (c, d, g, h) with the color bars. In the system with GDSE, the skin effect disappears under square geometry (geometry 1) in (g), and reappears under triangle geometry (geometry 2) in (h).

---

### ABCB6 polymorphisms are not overly represented in patients with porphyria [^21093af2]. Blood Advances (2022). Medium credibility.

Key Points

ABCB6 is expressed on the cell surface and by multiple organelles, but transport specificity is incompletely understood.
In all types of porphyria, ABCB6 polymorphisms are not overrepresented when compared with the overall population.

---

### Aggregation-fragmentation and individual dynamics of active clusters [^ce474574]. Nature Communications (2018). Medium credibility.

The observation field includes more than 2000 colloids, whose dynamics is individually followed. Short-time motion is well resolved by choosing a camera sampling rate τ s = 0.05 s, which is smaller than both the rotational diffusion τ r ~ 8 s and the time a col / v 0 ~ 0.3 s for colloid motion over its own size. The complete evolution of the system is recorded for 250 s, providing large data for analysis. Note that even after a few hours, we detect no sign of the macroscopic phase separation that is expected at higher volume fraction; for all purposes, the system appears in steady state.

Unlike all previous investigations. our definition of clusters is not purely geometric, but kinetic. One incentive for the change is the situation depicted in Fig. 1d: two clusters in close vicinity each endowed with their own rotating motion. They would be subsumed in a single cluster with the usual geometric criterion based only on a threshold distance. Other problematic situations include clusters grazing each other or colliding while maintaining their integrity, and single particles wandering at the cluster periphery without actually being incorporated. Our cluster detection algorithm seeks to reproduce the ability of the naked eye to delineate objects. In short (see details in Methods), elementary triangles are introduced on the basis of a Delaunay triangulation and a distance criterion, but only if they fulfill a persistence time τ p = 0.5 s. Clusters are then identified as the connected component of elementary triangles sharing one edge (Fig. 1c). Note that as a result, dimers can not exist, an assumption corroborated by direct observation. An immediate benefit of the new definition of clusters is a weak dependence on threshold distance, whereas a purely geometric definition is much more sensitive to this choice. Our clusters are compact, unlike the ramified clusters found previously in simulations, and to a very good approximation, they behave as rigid bodies. Their instantaneous motion is therefore entirely characterized by their translational and rotational velocities.

---

### Strong coronal channelling and interplanetary evolution of a solar storm up to earth and mars [^14773ca0]. Nature Communications (2015). Medium credibility.

Visualizing a self-similar propagating ellipse

Figure 5a shows the geometry of an ellipse under the assumptions described above. The R (t) of the ellipse apex (the point of the ellipse farthest from the Sun along the ellipse central direction) is given by DBM. In this section, we derive equations for the ellipse semi-major axis a and semi-minor axis b as a function of R (t), the inverse aspect ratio f and the half width λ. We use f = b/a rather than a r = a/b because it simplifies the following calculation. The equations

follow from the definition of f and the definition of angle β, which is the angle between the semi-major axis a and the normal to the tangent at point T (Fig. 5a). The location of T is the point of tangency on the ellipse for a line originating at the Sun. It can be easily seen that β = λ by checking the sum of the angles of the small orange triangle in Fig. 5a in relation to a larger triangle (not highlighted) containing the angles λ and η. The polar angle of the ellipse θ is given by a relationship from general ellipse geometry between β and θ. It is important to emphasize that we further construct the ellipse based on this particular value of θ, for which a line with distance r connects the ellipse center C to point T. Combining equation (2) gives a relationship for the polar angle θ based on known parameters,

From the law of sines on the large orange-shaded triangle in Fig. 5a we derive:

Angle α follows from the angles of the orange-shaded triangle, and distance r from the definition of an ellipse in polar coordinates:

The last equation can be rewritten with the definition of f as

Introducing α from equation (5) and the last equation for r into equation (4) then eliminates the unknowns (α, r) and expresses b in function of known variables:

Equations (7) are the final description of the ellipse parameters. The minor axis b of the ellipse depends on all known variables (R (t), f, λ) through θ and ω, from equations (3) and (6). The major axis a then simply follows from the definition of f in equations (2). The heliocentric distance of the centre of the ellipse is parameter c (Fig. 5b), closing the model equations necessary for visualizing the ellipse.

---

### Optimizing the design of spatial genomic studies [^183181be]. Nature Communications (2024). High credibility.

Bounding box model

Consider a logistic regression model where the area of interest is modeled with an axis-aligned rectangular bounding box. Assume a spatially varying Bernoulli likelihood, y ~ Bern(g (x)), where g (⋅) is a link function mapping the spatial coordinates to the bounding box probability model. For the axis-aligned bounding box, we parameterize g (⋅) as follows:whereare parameters controlling the center and width of the box, respectively, and e d is the d th axis-aligned unit vector of length 3. Isotropic Gaussian priors can be used, i.e. a, c ~ N (0, I). This model, which is a generalization of a logistic regression model, captures the borders of the region of interest through the parameters θ = { c, a }. Thus, the posterior after iteration t is p (θ ∣ X 1: t, y 1: t). Recall thatrepresents the data observed through experimental iterations 1, …, t − 1. The expected information gain for a slice through plane P t is

In order to select the slices to identify the borders of the region of interest representing the tumor, we maximize the EIG with respect to P t.

Spherical and elliptical border model

We may parameterize the border of a region of interest using shapes other than a rectangle. For example, we may use a circular bounding area instead. Recall that the equation for the points incontained within a ball with center c and radius r is given byA viable statistical model is thenwhere π c and π r are prior distributions for the center and radius, respectively.

The spherical border model can also be generalized to an elliptical border. Recall that an ellipsoid can be written as a linear transformation of a sphere. The points contained inside the ellipsoid arewhere. These options for border-finding extend our experimental design approach.

Algorithm 1

Nested Monte Carlo sampling on experimental iteration t for design P t

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^6517cbfd]. Annals of the American Thoracic Society (2023). High credibility.

Basic stereological measurements — first-order parameters and probes identify that "First-order parameters are volume (three-dimensional [3D]), surface (two-dimensional [2D]), length (one-dimensional [1D]), and number (zero-dimensional [0D])". Measurements "are performed using geometric test probes, such as points (0D), lines (1D), planes (2D), or volumes (3D)". These probes create countable events in the image, and "Raw counts provide ratios… that are multiplied by the reference space volume to obtain absolute measures for the lung or subcompartment".

---

### Symmetry breaking in optimal transport networks [^f4124a5b]. Nature Communications (2024). High credibility.

The main problem in network design is fundamentally different. We are given the density of population and we are looking for the network that minimizes some objective function involving some average time, in general (although other choices are possible, see for example). In this setting, there are usually two different transport modes, a slow one representing for example cars on the road network, and a fast one representing the subway or some rapid transit network. The natural framework here is then the one of multiplex networks comprising two different transportation networks, one known while the structure of the second one is to be determined (for multiplexes in the context of optimization see for example). A practical realization of this problem concerns the specific case of subways (for a network analysis of subways, see for example,–). In most large cities, a subway system has been built and later enlarged, with current total lengths varying from a few kilometers to a few hundred kilometers. The geometry of these networks, as its total length increases, varies from simple lines to more complex shapes with loops for larger networks. In particular, for the largest networks, convergence to a structure with a well-connected central core and branches reaching out to suburbs has been observed.

Algorithmic aspects of network design have been studied within computational geometry (e.g.chapter 9) and location science (e.g.and references therein), and some simpler problems of this type have been addressed previously. For instance, the problem of the quickest access between an area and a given point was discussed in. In network science, the optimization problem is traditionally recast as a navigation problem in lattices with long-range connections. However, our specific question – optimal network topologies as a function of population distribution and network length – is largely an open problem. In, some results were obtained in two-dimensional systems by comparing a priori defined optimal network configurations. First, it was shown that, if the goal is reaching a single point in the plane, then the optimal network is necessarily a tree. Second, the paper hinted at the possibility of the existence of transitions between optimal configurations when the length of the network changes. More precisely, it has been shown that as the length of the network increases resources go preferentially to radial branches and that there is a sharp transition at a critical value of the length where a loop appears.

---

### Intracellular tension sensor reveals mechanical anisotropy of the actin cytoskeleton [^819b2037]. Nature Communications (2023). High credibility.

Fig. 3
Elastic assumptions fail to predict intracellular forces.

a RFP of a circular U2OS TS cell and the corresponding alignment field. b The magnitude and vectors of tractions. Grid size is 6 μm. c The average internal forcecalculated from the TFM tractions based on linear elasticity and force balance. d The FRET E of circular cell. e RFP of a square U2OS TS cell and the corresponding alignment field. f The magnitude and vectors of tractions. Grid size is 6.4 μm. g The average internal force. h The FRET E of circular cell. i RFP of a triangle U2OS TS cell and the corresponding alignment field. j The magnitude and vectors of tractions. Grid size is 6.4 μm. k The average internal force. l The FRET E of circular cell. m Radially averaged and interpolated(blue dots) and < FRET > (orange dots) as a function of θ, the angle from the center of circle, (n) square and (o) triangle shapes. p, localand globalfor circle, square, and triangle shapes. (n = 7 for circles, n = 6 for square and n = 5 for triangles). Two-way ANOVA test was used for significance for p (circle and triangle) = 0.0001, p (circle and square) = 0.0002, p (triangle and square) = 0.9345. For local p (circle and triangle) = 0.9795, p (circle and square) = 0.9380, p (triangle and square) = 0.8790. For global, p (circle and triangle) = 0.2807, p (circle and square) = 0.0014, p (triangle and square) = 0.2293. In all panels, data are presented as mean values ± SD. Scale bar is 5 μm. Source data are provided as a Source Data file.

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^075005b9]. Magnetic Resonance in Medicine (2021). Medium credibility.

Regions A and B are geometrically symmetric about the z = 0 plane, with minimum energy solutions (assuming no E‐field constraint) yielding z‐symmetric field solutions and zero B 0 concomitant fields. Hence, the open diamond starting point (representing the minimum energy solution with no E‐field constraints) for the solid and dashed curves (in both black and green cases) coincide. The symmetry is broken by the addition of a patient model with an E‐field constraint.

The knee in the curves marks the point where magnetic energy, current density, and winding complexity increase rapidly as E max is driven to lower values. These complexities render unrealizable or impractical any gradient designs on the vertical portions of the curves to the left of the knee. Examination of winding patterns indicates that solutions that exhibit energy increases > 25% (or even less depending on coil type) above the global minimum energy become unrealizable (eg, demonstrating two or more "eyes" per half coil [four or more total eyes for an x or y coil] in the fingerprint wire patterns).

The red and purple dotted curves in Figure 2 represent two practical cases in which the primary coil currents are restricted to a single inner surface near the patient and the shield coil currents to an outer cylinder, while at the same time adding torque and eddy current constraints. Line segments acd of Figure 1 represent a primary winding surface consisting of a cone and a cylinder, whereas line segment ab represents its cylindrical shield winding; this yields designs similar to those proposed by previous literature 8, 22 and results in the red dotted curves in Figure 2. A second case is defined by restricting primary currents to the cylinder represented by line segment cd and shield currents to the cylinder ab; this yields designs similar to those proposed by previous literature 28 and produces the purple dotted curves in Figure 2. For both configurations, the eddy current surface is a 1‐m‐long, 620‐mm‐diameter cylinder, centered about the gradient isocenter and placed outside the shield winding of the gradient coil. The time = 0 eddy current error is constrained to a peak deviation less than 0.1% of the ideal gradient field on the surface of a 20‐cm‐diameter volume, corresponding to 100 µT for a 1 T/m step change in gradient strength. The torque constraint is set to zero for a uniform z‐directed B 0 main magnetic field. There is no net force for a perfectly uniform main B 0 field in all calculations.

---

### Closing the gap towards super-long suspension bridges using computational morphogenesis [^0b167599]. Nature Communications (2020). High credibility.

Topology optimization

The objective of the optimization is to maximize the stiffness of the center section of the model for a given amount of material, which during optimization is distributed in the interior of the design domain (marked with orange in Supplementary Fig. 1). The problem is solved based on the assumption of static, linear-elastic behavior. The governing partial differential equations (PDEs) are solved using the finite element method, using eight-node hexahedral iso-parametric elements, resulting in the following linear system of equations:Here K (ρ) is the stiffness matrix given as a function of the design variable vector ρ, u is the displacement vector, and F is the load vector. Each mesh element is assigned a single artificial continuous density, ρₑ ∈ [0, 1], collected in vector ρ, defined in a range from void (0) to solid material (1). The density-based topology optimization method SIMP(Solid Isotropic Material with Penalization) is used, as this enables the use of gradient-based optimization algorithms. The element stiffness is defined by a smooth interpolation between the solid material stiffness, E solid, and a very weak material (E_void = 10⁻⁶E_solid), given by the modified SIMP schemeasHere p > 1 is a penalization parameter enforcing almost discrete final designs with ρₑ being either 0 or 1, hence, the impractical intermediate densities are penalized and made unfavorable. The stiffness matrix can thus be assembled in the standard way asHereis the element stiffness matrix with unit modulus of elasticity and n is the number of elements in the mesh. Before stating the mathematical optimization problem, the objective function is introduced as compliance (work done by external forces) of only the center section of the model, C = uᵀF, which is inversely proportional to structural stiffness. Hence, to maximize structural stiffness, the following minimization problem is posed:Here ϕ is the sum of compliances from L load cases, weighted by the scaling factors aᵢ. The first constraint ensures mechanical equilibrium; the second poses a limit on the amount of available material, with V (ρ) being the volume of the current structure and V * the maximum amount of available material and the third defines box constraints on the design variables. To avoid well known, but undesirable effects inherent in topology optimization, such as checkerboards and mesh-dependencies, a filteringof the densities is performed after each optimization iteration. Here, the density filter from ref. an image processing type convolution filter, is applied. Hence, the filter modifies each density as a weighted average of the adjacent densities, given by a filter radius. The filter is thus a method to smoothen the boundaries of the structure. A filter radius of 1.5 times the maximum dimension of a mesh-element is used. Finally, a fully parallelized version of the gradient-based method of moving asymptotes (MMA,) is used as the optimization algorithm.

---

### Pleural procedures and thoracic ultrasound: British thoracic society pleural disease guideline 2010 [^8e48bc53]. Thorax (2010). Medium credibility.

Regarding therapeutic procedures for blunt chest trauma, more specifically with respect to technical considerations for chest drainage (insertion technique), BTS 2010 guidelines recommend to prefer the triangle of safety as the site for insertion of the needle for pleural aspiration.

---

### Autoactive CNGC15 enhances root endosymbiosis in legume and wheat [^dcdb9394]. Nature (2025). Excellent credibility.

Fig. 4
Low-frequency Ca 2+ oscillations of cngc15 GOF mutants modulate root phenylpropanoid pathways.

a, Venn diagram showing overlap of differentially expressed genes (DEGs) in cngc15a GOF (15a GOF) and cngc15c GOF (15c GOF) versus WT (308 genes), cngc15a GOF and cngc15c GOF treated with Nod factor (NF) for 3 h versus mock (1,499 genes) and WT treated with NF for 3 h versus mock (2,718 genes) (P value < 0.05). b, Heat map showing DEGs in 15a GOF and 15c GOF mock or in response to NF identified in a that overlaps with DEGs in WT (clusters AB, ABC and AC) or not (clusters B, BC and C) and in 15a GOF /dmi3-1 mock. c, Heat map showing the log₂ fold change (FC) of endosymbiotic genes, which are not induced in 15a GOF and 15c GOF in the absence of NF. d, Quantitative expression analysis of NIN and ENOD11 relative to UBC9, with (+) and without (−) 3 h NF; values from three biological replicates. e – h, Heat map showing the log₂ FC of genes over-represented in either cluster AB–ABC (e), cluster C (f) or DEGs in response to NF and 3 mM nitrate treatment (g), including CHS (h). e, f, Fisher's exact test, two-tailed, false discovery rate (FDR) < 5 × 10 −4. g, h, P value < 0.05. i, Schematic representation of core phenylpropanoid pathways; phenylalanine ammonia lyase (PAL), cinnamic acid 4-hydroxylase (C4H), 4-coumarate:CoA ligase (4CL), chalcone synthase (CHS), dirigent protein (DIR) and dihydroflavonol reductase (DFR). DEG of cngc15 GOF upregulated, red; downregulated, blue. The dark arrow indicates one step; the grey dashed arrow indicates multiple enzymatic steps. j, Relative abundance of naringenin and liquiritigenin in three biological replicates of WT and cngc15c GOF roots after 21 days of growth in the presence or absence of Sm 2011 (optical density at 600 nm (OD₆₀₀) = 0.01), and in WT roots after 5 weeks of inoculation with R. irregularis (AM). d, j, Scatter plots show mean, s.d. One-way ANOVA, Dunnett's multiple comparison test versus WT. d, Different letters indicate statistical difference (j). j, Two-tailed unpaired t -test with a previous F -test for homoscedasticity. RNA-seq reads in b, e and f reproduced from ref. Springer Nature, under a Creative Commons licence, and ref. American Association for the Advancement of Science.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^7e0b2d1d]. Annals of the American Thoracic Society (2023). High credibility.

Basic stereological measurements for lung imaging — first-order parameters, probes, and reference space are specified. First-order parameters are volume (three-dimensional [3D]), surface (two-dimensional [2D]), length (one-dimensional [1D]), and number (zero-dimensional [0D]). Measurements are performed using geometric test probes, such as points (0D), lines (1D), planes (2D), or volumes (3D), with probe–voxel interactions generating countable events; raw counts yield ratios that are multiplied by the reference space volume to obtain absolute lung or subcompartment measures. It is crucial to define and measure a biologically meaningful reference space for analysis and reporting, because measurements expressed only as ratios are subject to "the reference trap", where changes can arise from the numerator, denominator, or both; an efficient volume measurement method, point counting, is used for acinar components by micro-CT and for extrapulmonary organ volume by CT.

---

### Strong coronal channelling and interplanetary evolution of a solar storm up to earth and mars [^ef858ca2]. Nature Communications (2015). Medium credibility.

Calculation of speeds along the ellipse front

For comparison to in situ observations, which give parameters such as the speed and arrival time of the CME shock with very good accuracy, one needs to know the speed of any point along the ellipse front as a function of the ellipse parameters. This problem has been solved analytically for the circular SSE geometry, and we introduce here the corresponding analytic solution for ellipses.

Figure 5b demonstrates the geometry, with Δ being the known angle between the CME central direction and for example Earth, which could also be any other planet or spacecraft in the solar wind. The direction of the apex with respect to a coordinate system including the Sun and Earth depends on different methods for CMEs observed with coronagraphsor heliospheric imagers.

We introduce a coordinate system centred on the ellipse (Fig. 5b), with coordinate X being perpendicular to the CME propagation direction and Y orthogonal to X. Here, c is the vector from the Sun to the ellipse centre, d connects the Sun to the front edge of the ellipse in the direction of Earth (that is, d stops at the ellipse boundary and does not connect the Sun to the planet), and r connects the centre to the end point of d on the ellipse:

The problem consists in finding the norm of d as a function of Δ. There are two crossings of d with the ellipse, one at the rear and one at the front (Fig. 5b), which will form the two solutions of the problem. The coordinates of r can be expressed with the projections of the vector d – c in the X/Y coordinates:

---

### Rational design of ABC triblock terpolymer solution nanostructures with controlled patch morphology [^38042c23]. Nature Communications (2016). Medium credibility.

At values of [N_T/(qN_S^(²⁄³))] = 0.15, we find vesicles (polymersomes) with a compartmentalized shell, where spherical PB patches are located on both sides of the vesicle membrane (Fig. 2d). These patchy vesicles adopt a homogeneous round shape with size distribution typical for block copolymer vesicles. The isotropic spherical PB patches do not influence the vesicle shape. As we will show later on vesicles with other patch morphologies, this is not always the case. Nanostructured vesicles are likewise very intriguing, because a generic concept to control the membrane morphology through self-assembly would impact their application as nanoreactors, drug-delivery vehicles and artificial cell prototypes.

Controlling the patch morphology

We next explored the possibility to maintain constant micelle geometry, while tuning the PB patch morphology, that is, from spherical to cylindrical, bicontinuous and lamellar, by increasing N B relative to the corona length, N T (Fig. 3). Equation (1) applies and spheres-on-cylinders are thermodynamically stable as long as R_PB ≤ D ≤ H_corona. For shorter soluble PT blocks and/or longer insoluble PB blocks, the size of patches becomes comparable to — or larger than — the extension of the corona (Supplementary Fig. 8). In this regime one can expect shape transformation of the PB domains. This transition is driven by the gain in the conformational entropy of the PB blocks, which is balanced by an increase in the overlap and repulsions between the PT blocks protruding from the surface of the PB domains. The exact numerical factors, which quantify the difference in the conformational entropy of the PB blocks confined in spherical or cylindrical segmental domains are, however, not available. If N_Sν_S ≫ N_Bν_B, the transition from spherical PB patches to PB cylinders and further to a PB lamella (layered PS/PB) occurs on the surface of quasi-planar PS domains. The length of the PS block has virtually no influence on the position of the transition (tr)

---

### One-shot learning for solution operators of partial differential equations [^59285d40]. Nature Communications (2025). High credibility.

From another perspective, our method can also be viewed as an approach for discovering PDEs. When discovering PDEs, in one scenario, where we know all the terms of the PDE and only need to infer unknown coefficients from data, many neural network-based methods have been proposed. For example, we can enforce physics-based constraints to train neural networks that can solve inverse problems of PDEs. In the second scenario, where we do not know all the PDE terms, but have a prior knowledge of all possible candidate terms, several approaches on PDE discovery have also been developed. The kernel frameworks for learning PDEs, are proposed with kernel smoothing followed by kernel regression to learn the functional form of the differential operator with low training data requirements. In a general setup, discovering PDEs only from data without any prior knowledge is much more difficult. To address this challenge, instead of discovering the PDE in an explicit form, we use a neural network as an implicit representation of the physics laws.

Our one-shot learning method first leverages the locality of (partial) derivatives and uses a neural network to learn the local solution operator of the PDE system defined at a small computational domain. Then for a new PDE condition (e.g. a new source/forcing term or PDE coefficient field), we find the global PDE solution by coupling all local domains using the following mesh-based or neural network approaches, constrained by the IC/BCs. Specifically, a mesh-based fixed-point iteration (FPI) approach is proposed to obtain the PDE solution that satisfies the boundary/initial conditions and local PDE constraints. In this iterative approach, the computation on local stencil of mesh elements is in the same spirit as traditional PDE solvers. We also propose two versions of local-solution-operator informed neural networks (LOINNs), which are meshfree, to improve the stability and flexibility of finding the solution. Moreover, our one-shot learning method has been applied to solve multi-dimensional linear and nonlinear PDEs, PDEs defined on a complex geometry, a spatial infection spread problem, and has been generalized to a new geometry. In this paper, we demonstrate our one-shot learning method for solution operators on different PDEs for a range of conditions in "Results" section, and then describe the details of our method.

---

### Nanoscale characterization of the biomolecular corona by cryo-electron microscopy, cryo-electron tomography, and image simulation [^9cc8e7a5]. Nature Communications (2021). High credibility.

Figure 9a is an image containing NPs, BC, and other artifacts. In Fig. 9b, we isolated and binarized a single NP (blue) and the surrounding proteins (white). The coordinates of the center of mass of each cluster were used to calculate the distance from the surface of the NP (Fig. 9c).

Fig. 9
Defining the physical characteristics of biomolecular corona.

a A tomographic slice shows the BC surrounding the NPs (full series of 256 distinct cryo-EM images are provided in 10%Corona.rar and 50%Corona.rar files of the SI). The large circles represent spherical NPs. The BC is represented by black points forming clusters around the NPs. The horizontal black bar-like shapes in the bottom right corner of the image are artifacts of smaller gold NPs (used for focusing purposes) that are used to measure the scale of the image. b A binarized image showing the BC (white) surrounding the NP (blue). c The space around the NP is divided into spherical shells. The blue arrow points to the center of the cluster. The position of each cluster was determined according to where its center is located among the various shells. d A schematic representation of an arbitrary cluster. The size of the cluster was characterized by a sphere with a radius of gyration R G. Here we show a 2D representation. e The eigenvalues of the gyration tensor are represented with the radii of a hypothetical ellipsoid that best fits the cluster.

The gyration tensor of each cluster was calculated (i) to analyze its structural features and (ii) identify the existence of dispersion of proteins near the NPs, which is defined as, where N is the total number of voxels in a single cluster, and x i, y i, z i, x com, y com, and z com are the coordinates of the voxels in a cluster and the coordinates of the center of the cluster, respectively. Although the parameters are invariant under the rotation of the axes, we diagonalized the gyration tensorand sorted the eigenvalues in descending order λ 1 ≥ λ 2 ≥ λ 3 to simplify the presented results. The trace of the gyration tensor is the square of the radius of gyration.

Because the radius of gyration is a measure of the radius of the cluster if it had been replaced by a hypothetical sphere, it is an acceptable estimate of cluster size. Figure 9d illustrates a 2D representation of a cluster fitted with a circle with the radius of gyration.

---

### The 30-degree angle revisited [^eec48357]. Journal of the American Academy of Dermatology (2005). Low credibility.

The standard surgical ellipse, with 30 degrees apical angles and a length-to-width ratio of 2 or 3 to 1, works optimally on a flat surface. The same pattern, when used for excisions on strongly convex or concave surfaces, leads to distortions which may require significant revisions. The reason for these discrepancies is explainable by the mathematical differences between flat Euclidian geometry and curved non-Euclidian geometry. Understanding these basic mathematical principles as applied to cutaneous surgery should lead to better preoperative planning, fewer intraoperative surprises, and more pleasing results.

---

### Recommendations for measuring pulmonary nodules at CT: a statement from the Fleischner society [^e5d29aca]. Radiology (2017). Medium credibility.

Fleischner Society — solid pulmonary nodule dimension expression for risk estimation states that small pulmonary nodules (< 10 mm) should be expressed as the average of maximal long-axis and perpendicular maximal short-axis in the same plane, and for larger nodules and masses both long- and short-axis measurements should be recorded (grade 2B evidence).

---

### Multiple tipping points and optimal repairing in interacting networks [^806c4333]. Nature Communications (2016). Medium credibility.

To optimize repairing we need to minimize this metric. Figure 5 shows the solution to the minimization problem and a detailed discussion is provided in the Methods section. The different colours in Fig. 5 correspond to the different optimal repair strategies, which depend on the failure state of the system. If the system is initially at point S 1, both networks are in a low activity state, that is, they are non-functional. Our goal is to decreaseand, and arrive to the region where the system is fully recovered (the green region) by performing a minimal number of repairs, that is, minimal N rep. We find that for any point in the red region there are actually two closest points in the green region, at an equal Manhattan distance away from the red region point. These two points are the triple points R1 and R2 shown in Fig. 5, which also correspond to the triple points in Fig. 2b. Although R1 may be closer to point A than R2 by Euclidian distance, the Manhattan distance is the same. Thus, two equally good repairing strategies are available. One involves allocating more node repairs to network A and the other allocating more repairs to network B. For the yellow regions (points S 2 and S 3), the closest points by Manhattan distance are R1 (for point S 2) or R2 (for point S 3). Here, only one triple point represents the optimal solution. It is noteworthy that the path samples in Fig. 5 are 'zig-zag' in shape (to highlight that we are minimizing); however, even when a diagonal path (direct straight line) to a triple point is used, the Manhattan distance is the same. For the dark blue regions (points S 4 and S 7), the optimal strategy is to decreaseonly, until the system is recovered. Similarly, for the light blue regions (points S 5 and S 6), the optimal strategy is to decrease only.

From our optimal repairing strategy analysis we find that the order of repair (the specific path taken between the initial point and final point) does not affect the final result. Minimizing the Manhattan distance only determines the optimal destination point. Therefore, there is actually a set of paths corresponding to equally optimal repairing processes.

---

### A machine learning approach to integrate big data for precision medicine in acute myeloid leukemia [^49ff8011]. Nature Communications (2018). Medium credibility.

Fig. 7
SMARCA4 plasmid transfection experiments on cell lines KG1 and U937 for comparison of response to etoposide and mitoxantrone between original and transfected cells. a, b Comparison of the 72-h dose-response curves between KG1 cells (blue) and transfected KG1 cells (red) when cells are treated with (a) etoposide, and (b) mitoxantrone. c, d Comparison of the dose-response curves between U937 cells (blue) and transfected U937 cells (red) when cells are treated with (c) etoposide and (d) mitoxantrone. Three triangular marks at each point on the line indicate individual data points in duplicates and the average among them. The line connects averages of duplicates in each concentration measured. e Representative cropped western blot of control and transfected AML cell lines: KG1, U937, HL60, and MV4.11. Uncropped version is shown in Supplementary Fig. 6. f Quantifications of the SMARCA4 protein expression pattern of each of AML cell lines in (e). g Flow cytometry of SMARCA4 surface expression data confirm the overexpression for KG1 (blue) vs. transfected KG1 (red). h Flow cytometry of SMARCA4 surface expression data for U937 (blue) vs. transfected U937 (red). We note that U937 already strongly expresses SMARCA4, while KG1 exhibits minimal expression until after transfection. Abbreviations in d and f are as follows: PE-A, P-phycoerythrin area; MFI, mean fluorescence intensity; D anti Ri, Donkey anti-Rabbit

---

### Three-dimensional echocardiography in congenital heart disease: an expert consensus document from the European association of Cardiovascular imaging and the American Society of Echocardiography [^9dd20935]. Journal of the American Society of Echocardiography (2017). Medium credibility.

Cross-plane imaging of the mitral valve — Cross-plane imaging by transthoracic echocardiography uses a user defined cut plane to show a short-axis view of the mitral valve with the corresponding long-axis view, and in mitral valve regurgitation it permits precise localization of regurgitant jets in long-axis and short-axis views, with the cut plane indicated by the triangle.

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^379d260f]. Magnetic Resonance in Medicine (2021). Medium credibility.

Comparing the E max results in Figure 2 for the real ESP gradient coil with the theoretical best (vertical asymptotes) for region BC, we predict that E max ‐constrained solutions could yield E‐field reductions as much as about 34% for the X coil and about 22% for the Y coil. To reduce the E‐field, the curves in Figure 2 indicate that placing windings on the conical section in addition to the cylindrical primary section (acd) should be beneficial; this finding is consistent with previous literature. 8, 22 There may be practical challenges; for example, allowing windings on the conical surface may lead to additional manufacturing complexity. Nonetheless, the methods described here can be used to help make rational tradeoff determinations for any real designs.

Perhaps the most dramatic result of our work is the realization that the minimum E‐field is relatively insensitive to the gradient coil inner diameter; this means that major gains in PNS performance can be achieved even for body‐sized gradient coils optimized for imaging the head. As shown by the A‐region blue curves of Figure 2, the vertical asymptote is virtually identical to the head‐only BC‐region asymptote, and Figure 3 shows remarkable E max reductions of 1.8‐fold for the X coil and 2.8‐fold for the Y coil. This shows the potential to achieve head gradient levels of PNS performance without having to sacrifice extremely valuable patient bore space, although at the cost of increased magnetic energy and increased gradient amplifier power requirements compared with head gradients. The methods presented here will allow these optimal designs to be identified and rendered to practice with trade‐offs evaluated rationally and with reference to theoretical limits.

We note that a possible implementation option, similar to that proposed in previous literature, 20 is the design of symmetric or asymmetric gradient windings with a separate winding intended to add or remove the concomitant field during head or body imaging; this independent control of main gradient and concomitant fields may permit more flexible control of E‐fields over a range of body positions. It would be straightforward to make these coils electrically orthogonal and torque‐balanced.

Applying the E max ‐constrained gradient design concepts to body size coils, Figure 6 shows that even with a 40‐cm imaging region diameter, significant improvements in PNS performance (1.5‐fold to 3‐fold) are achievable for head imaging, although these major gains may reverse when imaging other body regions. Such large gains in PNS performance for head imaging may easily justify the trade‐offs for body imaging.

---

### Integrating cross-sample and cross-modal data for spatial transcriptomics and metabolomics with spatialMETA [^0522223a]. Nature Communications (2025). High credibility.

Optionally, a linear projection layerwas trained to learn the relationship between histological features and metabolomic features. A linear projection layerwas trained to learn the relationship between transcriptomic features and metabolomic features.

Our alignment module computes, andby adopting the stochastic gradient descent of Large Deformation Diffeomorphic Metric Mapping adapted from STalign, with modifications on the default weight parameters and optimization objective functions:

Where,(default = 0), and(default = 0) are weight parameters, andare objective functions for different measurement.calculates the mean squared error between two sets of latent representation.

calculates the pairwise Euclidean distance between two sets of pointsand. First, for each point, we find the closest point, and vise versa. Letdenote the index of closest point into, anddenote the index of closest point into. Then, whereandare the weights for the two sets of points, andcalculates the Euclidean distance between two points.

finds the edge of a set of points, where each pointis a point in a 2D plane, the goal is to find the concave hull of the points using Delaunay triangulation and edge detection based on the circumradius of the triangles. The Delaunay triangulation dividesinto a set of triangles, and each trianglehas three vertices. The circumradius, whereare side lengths andis the area of the triangle. The triangle edges would be considered as bounardy edges if, where(default = 1) is a user-defined parameter. Vertices from boundry edges are used as outline spots.

In addition, if there is a significant difference between the SM and ST data positions, the SM image needs to be manually flipped and rotated by a large angle to ensure more effective alignment before using the automatic SpatialMETA Alignment Module.

---

### Neural representational geometries reflect behavioral differences in monkeys and recurrent neural networks [^2c9ef8ca]. Nature Communications (2024). High credibility.

Fig. 2
Schematic of different representational geometries for 4 conditions in the neural activity space and their properties.

A Left: factorized or disentangled representations where the 4 points are arranged on a square. The shape (circle vs triangle) and color (red vs blue) are encoded along two orthogonal directions. This geometry supports the representation of shape (and color) in abstract format, i.e. high CCGP. Right: Random representation where the 4 points are placed at random locations in the activity space. This geometry does not support the representation of the shape in abstract format, i.e. low CCGP. B Left: Low shattering dimensionality, where the 4 points are placed at the vertices of a square. The shattering dimensionality is low because not all the dichotomies can be decoded by a linear decoder due to the XOR configuration (purple and green circles). Right: High shattering dimensionality supports the decoding of a higher number of dichotomies, including the one not linearly decodable, i.e. XOR.

The third aspect of the geometry is the dimensionality of the representation, which we assessed by using the shattering dimensionality. The shattering dimensionality is defined as the average linear decoding performance for all possible balanced dichotomies. A high shattering dimensionality means that the linear decoder can separate (shatter) the points in any possible way, enabling a linear readout to perform a large number of input-output functions, like the Exclusive OR (XOR) configuration, that wouldn't be possible in case of low shattering dimensionality (see Fig. 2 B).

---

### Clustering by measuring local direction centrality for data with heterogeneous density and weak connectivity [^726fcfdf]. Nature Communications (2022). High credibility.

Validation of the adaptive methods

Parameter tuning is a labor-intensive task that requires constant trial and error in cluster analysis. To alleviate this issue, we propose two adaptive methods to determine the appropriate parameters. T DCM (or) is estimated through graph theory analysis on a Triangulated Irregular Network (TIN) in 2D space. Commonly, boundary points tend to have lower centrality (i.e. higher) than internal points. Thus, we sort allin a descend order and the optimal T DCM (or) can be searched if the number of boundary points is given. Based on the graph theory and 2D Euler's formula, it can be found that the boundary points are associated with the vertexes, intra-cluster triangles and the number of clusters (see Methods). With the estimation of the cumulative number of vertexes, and intra-cluster triangles in the multiple disconnected subgraphs, the number of boundary point can be approximately determined using Eq. (15). We testified the TIN-based adaptive method for T DCM on four synthetic datasets, i.e. DS14-DS17 (Supplementary Fig. 11a–c), on which all clusters can be identified accurately under the estimated parameters (Supplementary Fig. 11c). The blue-colored cross-cluster triangles were detected by the judge rule in Eq. (16) from the whole TIN networks (Supplementary Fig. 11a). Although a few intra-cluster triangles at the boundaries are misidentified as cross-cluster triangles and several cross-triangles are undetected due to the close proximity between clusters, these two biases can be offset partially.

---

### The genetic basis of apple shape and size unraveled by digital phenotyping [^a8fe2b6b]. G3 (2024). Medium credibility.

Feature extraction for shape and size

From the apple fruit contours obtained from FruitPhenoBox, 1D features for shape and size were systematically processed (Table 1, Fig. 1b). For the points on the fruit contour defined in polar coordinates (Pol), the distance of the point from the center of the coordinate system, i.e. the radius, was used in feature extraction. The points in the Cartesian coordinate system were expressed as individual coordinates for both axes (X measuring fruit diameter and Y measuring fruit length). Different fruit sections were determined as the top (A), bottom (B), left (L), or right (R) half of the fruit, as well as intersections of the fruit halves, i.e. fruit quarters (A.L, A.R, B.L, B.R) and unions of the halves, i.e. the full fruit (AB, LR). Points from the fruit contour derived in Cartesian and polar coordinates within a chosen fruit section were used to calculate different types of features, namely the mean (Av), the standard deviation (SD), the minimum (Min), or maximum (Max) value, the 0.25, 0.50, or 0.75 quartile (Q25, Q50, Q75), the area, the ratio between Max and Min value (RatM), and the Max value relative to the Av value (MaxR). The area was calculated by summing up 1°-radius increments in the specified section. For each type of feature, the absolute value (Abs) was taken from the features extracted on different sections. For the opposite fruit halves, absolute values were first extracted and then the ratio (Rat) and the sum (Sum) were calculated across the fruit halves. The ratio or the sum of top vs bottom halves was calculated as average (Rat. Av and Sum. Av) and SD (Rat.SD and Sum.SD). Hereby, the top and bottom halves were calculated from quarter values using the corresponding left–right fruit quarters (AB.LR). Additionally, symmetry between L and R as well as A and B was calculated as the Av or SD of the difference between corresponding absolute values of radius of each fruit half (Sym.abs, sections LR, and AB). Similarly, the symmetry measure Sym.abs was obtained for individual apple sections A, B, L, and R when comparing the opposite quarters within the fruit halves. Additionally, a relative symmetry (Sym.rel) was derived for the same apple sections as Sym.abs, but the measure Sym.rel was normalized for the area of the apple section.

---

### BIDCell: biologically-informed self-supervised learning for segmentation of subcellular spatial transcriptomics data [^5f4c7c5b]. Nature Communications (2024). High credibility.

Evaluation metrics and settings

We introduce the CellSPA framework, that captures evaluation metrics across five complementary categories. A summary of this information is provided in Supplementary Table 2.

[A] Baseline metrics

Overall characteristics
Number of cells
Proportion of transcripts assigned

Cell-level QC metrics
Proportion of cells expressing each gene
Number of transcripts per cell
Number of genes expressed per cell
Cell area

where ∑ i ∈ I n i represents the sum of all total transcripts over a set I, and A represents the cell area.

Cell morphology metrics

We evaluated multiple morphology-based metrics and provide diagrammatic illustrations in Supplementary Fig. 27.

- Elongation = where W bb represents the width of the bounding box, and H bb represents the height of the bounding box.

Elongation measures the ratio of height versus the width of the bounding box (Supplementary Fig. 27 f). Elongation is insensitive to concave irregularities and holes present in the shape of the cell. The value of this metric will be 1 for a perfect square bounding box. As the cell becomes more elongated the value will either increase far above 1 or decrease far below 1, depending on whether the elongation occurs along the height or width of the bounding box.

- Circularity = where A represents the area, and P convex represents the convex perimeter.

Circularity measures the area to perimeter ratio while excluding local irregularities of the cell. We used the convex perimeter of the object as opposed to its true perimeter to avoid concave irregularities. The value will be 1 for a circle and decreases as a cell becomes less circular.

---

### The geometric nature of weights in real complex networks [^16d6fe49]. Nature Communications (2017). Medium credibility.

Hidden metric spaces underlying real weighted networks

At the beginning of this section, we showed that the normalized weights of links participating in triangles are higher, thus suggesting a coupling between the weighted organization of real weighted complex networks and an underlying metric space. We then presented a model that has the critical ability to fix the joint degree–strength distribution, while independently varying the level of coupling between the weights and the metric space (parameter α). This opens the way to a definite proof of the geometric nature of weights in real complex networks, which inevitably must involve the triangle inequality: the most fundamental property of any metric space.

For unweighted networks, a direct verification of the triangle inequality based on the topology without an embedding in a metric space is not possible, due to the probabilistic nature of the relationship between the binary structure and the distance between nodes. In contrast, weights do contain information about their distances in the metric space (via equation (2)) such that a direct verification of the triangle inequality is possible. To ensure that the metric properties of triples in the network are in correspondence to the metric properties of the corresponding triangles in the underlying space, only triples of nodes forming triangles in the network are taken into account to evaluate the triangle inequality. There are however two main challenges when one tries to apply this methodology. The first one is related to the fact that connections in the weightedmodel depend not only on angular distances but also on hidden degrees, such that we need a purely geometrical formulation of the weighted hidden metric space network model, in which angular distances and degrees are combined into a single distance measure. The second issue is related to the intrinsic noise present in the system due to the stochastic nature of the processes conforming it, which may blur the evaluation of the triangle inequality. Below, we propose a way to overcome these two issues.

---

### Rational design of ABC triblock terpolymer solution nanostructures with controlled patch morphology [^122b48cd]. Nature Communications (2016). Medium credibility.

Block copolymers self-assemble into a variety of nanostructures that are relevant for science and technology. While the assembly of diblock copolymers is largely understood, predicting the solution assembly of triblock terpolymers remains challenging due to complex interplay of block/block and block/solvent interactions. Here we provide guidelines for the self-assembly of linear ABC triblock terpolymers into a large variety of multicompartment nanostructures with C corona and A/B cores. The ratio of block lengths NC/NA thereby controls micelle geometry to spheres, cylinders, bilayer sheets and vesicles. The insoluble blocks then microphase separate to core A and surface patch B, where NB controls the patch morphology to spherical, cylindrical, bicontinuous and lamellar. The independent control over both parameters allows constructing combinatorial libraries of unprecedented solution nanostructures, including spheres-on-cylinders/sheets/vesicles, cylinders-on-sheets/vesicles, and sheets/vesicles with bicontinuous or lamellar membrane morphology (patchy polymersomes). The derived parameters provide a logical toolbox towards complex self-assemblies for soft matter nanotechnologies.

---

### Dandelion pappus morphing is actuated by radially patterned material swelling [^11f46d03]. Nature Communications (2022). High credibility.

For local expansion rates, a Delaunay triangulation was mapped onto the landmarks of the dry state samples using R package deldir. Triangles that were not fully enclosed by the overall outline of the dry sample were excluded. The area of each triangle was calculated and normalized area change calculated by dividing the area of a triangle when wet by its area when dry. The data were smoothed by calculating the arithmetic mean of the normalized area change for each triangle and its adjoining neighbouring triangles. Principal orientations of strain were calculated for each triangle and annotated as a cross scaled to 3 times larger than the original values for improved visibility.

Regions of the apical plate were designated by manually outlining the floral podium, vasculature, side regions and central cavity on the original images using the Fiji polygon tool. Triangles in the dry state that overlapped at least 40% with any of the dry state regions were assigned to those regions and all others were designated as cortex triangles. Mean area changes were calculated for each region for each sample and these values used to generate boxplots and for statistical analysis.

For a very small number of triangles the nonuniform expansion process rearranged nearby landmarks relative to one another such that triangles then appeared to overlap in the wet state. As it is not physically possible for cells to actually overlap in a connected cellular structure, these triangles were omitted from the analysis and comparisons between regions.

Geometrical measurements of the apical plate were obtained from images and used as inputs for the computational model. Measurements of the sizes and geometry of regions were taken from the wet-state confocal images of apical plate half-sections using Fiji. For some parameters such as the vascular displacement (d vasc) and holding angle (θ), measurements were taken from consistent points on the dry and wet images and differences calculated. For region density measurements, 10 μm sections stained with ruthenium red gave consistent red staining across all cell types. These images were thresholded using the automatic colour thresholding in Fiji, converted to a binary image and the ratio of stained to unstained pixels used to calculate the density of cell wall material in manually selected rectangular areas of each region.

---

### Clustering by measuring local direction centrality for data with heterogeneous density and weak connectivity [^fcddd465]. Nature Communications (2022). High credibility.

Estimation of the number of boundary points for determining T DCM

As shown in Supplementary Fig. 12a, we constructed a Triangulated Irregular Network (TIN) to connect all points. In graph theory, the degree of a vertex is defined as the number of edges incident to the vertex and each edge connects two vertexes. Based on this law, we can obtain:where deg(v i) represents the degree of vertex v i, V denotes the total number of vertexes, and E represents the total number of edges. In a graph, each triangle has three edges and each edge is shared by two triangles except the outermost edges. Actually, for a TIN that has a single connected component, the total number of boundary points is equal to that of the outermost edges, since all the outermost edges are connected end to end by boundary points and form a closed polygon. This law can be summarized as:where F and B refer to the total number of triangles and boundary points respectively. Meanwhile, 2D Euler's formula can be considered as follows:

By combining these formulas, we can infer the solution of B as follows:

However, the number of initial boundary points in the whole TIN is not equal to the total number of boundary points in the separated clusters. To conduct an accurate estimation, the whole TIN should be treated as multiple sub-networks (Supplementary Fig. 12b). Given C clusters, the number of boundary points in clusters can be solved as follows:where F is the total number of intra-cluster triangles in the multiple separated networks. V is known in a given dataset (i.e. n), but F and C are not. The initial F is the total number of triangles in the whole TIN, which includes the triangles connecting different clusters, i.e. cross-cluster triangles whose three vertices are not all in the same cluster (otherwise is intra-cluster triangle). Using the excessive number of triangles would make the number of boundary points B smaller than the true value. To identify the cross-cluster triangles, we set a judgment rule:where v 1, v 2, v 3 are the three vertices of a triangle, and σ (v i, v j) is an indicator function:

---

### A modified reverse right-angled triangle osteotomy using the lateral approach for the treatment of posttraumatic cubitus varus deformity in children [^e4e7ab3c]. Journal of Pediatric Orthopedics (2023). Medium credibility.

FIGURE 3
A, HEW angle is formed at intersecting point of longitudinal axis of humerus and both bone of forearm. B, Usually lateral condylar prominence index is negative. It is measured by — lateral distance — medial distance/ transepicondylar distance. Calculated as [(AB − BC)/AC]. HEW indicates Humerus-elbow-wrist.

Statistical Analyses

All values were presented as the mean. ROM and HEW angle measurements before surgery and at the final follow-up were compared using paired t test. P value < 0.05 was considered significant. Statistical analyses were performed using SPSS statistical analysis software.

---

### Tools for probing local circuits: high-density silicon probes combined with optogenetics [^5dd8c060]. Neuron (2015). Low credibility.

The above discussion of probe geometry can help estimate the optimal configuration of future probes and the maximum yield of simultaneously recordable neurons. For the purpose of recording and separating the maximum number of neurons, the recording sites should tile the entire shank surface of the probe, which should, in turn, have minimal dimensions. Putting aside the problem of interconnects for a moment, and assuming the need for at least 8×8 µm² recoding sites with 10 µm center-to-center separation, 200 sites per shank on a 20-µm wide probe can cover the entire cortical gray matter (< 2 mm). Adding recording sites on both sides would double the number of monitoring sites and increase the unit yield. Placing three shanks in ≤ 100 µm triangle would allow effective three-dimensional triangulation of cortical neurons in all cortical layers. Such a probe could, in principle, record from between 1000 to 5000 neurons and determine the three-dimensional position of both cell bodies and the main dendrites of each neuron. These technical improvements are within reach but will require high-density off-chip lead transfers, probably in conjunction with on-probe circuitry. We should emphasize that even slim-shank probes come at the expense of tissue damage, fractional displacement volume and associated disruption of physiological activity that needs to be carefully investigated

---

### Terahertz rectification in ring-shaped quantum barriers [^a4e5ef19]. Nature Communications (2018). Medium credibility.

Figure 2b describes the polarization-dependent behaviors of the instantaneous total tunneling current of a triangular loop under a THz field illumination. Electric potential along the contour shows an asymmetric distribution as a consequence of the lack of inversion symmetry inherent in the triangle geometry. It is interesting to note that the contour integration of the barrier potential affected by the external surface current sources always vanishes independent of the loop shape and loop orientation, automatically eliminating the Ohmic component (see Supplementary Note 1). However, the non-vanishing total current through the barrier naturally emerges for the triangle shape because of the nonlinearity in tunneling current vs. applied potential relation (see Eq. 3 in Methods) together with the triangle's lack of inversion symmetry. Figure 2c shows the measured current responses from triangular and square loops as a function of the THz polarizer angle. The results show strikingly different behaviors depending on the loop geometry. A much higher current flows across the triangular barrier than the square one since the asymmetric potential distribution along the equilateral triangle results in a net tunneling current through the contour while the potential distribution at any point of a square is mostly counterbalanced by its corresponding point across the center, independent of the polarization of the incident pulse. Figure 2d displays polar plots of the tunneling currents for the triangular and square geometries, where the current amplitudes are reconstructed by assuming that the incident field maintains its amplitude for different polarization angles (see Methods for details). The total current vs. polarization angle shows the three-fold rotational symmetry of an equilateral triangle.

---

### The European guideline on management of major bleeding and coagulopathy following trauma: sixth edition [^8353ff1c]. Critical Care (2023). High credibility.

Regarding inpatient care for traumatic hemorrhage, more specifically with respect to coagulation monitoring, ABC-T 2023 guidelines recommend to obtain early and repeated monitoring of hemostasis using a traditional laboratory determination such as PT/INR, Clauss fibrinogen level and platelet count, and/or point-of-care PT/INR and/or a viscoelastic method.

---

### Neural representational geometries reflect behavioral differences in monkeys and recurrent neural networks [^ef20302c]. Nature Communications (2024). High credibility.

The second aspect of the geometry is related to the ability of a linear classifier to generalize across conditions when trained to decode the balanced dichotomies (cross-condition generalization performance or CCGP). For example, consider a representation of a visual stimulus that is characterized by a shape and a color. Shape can be either a triangle or a circle, and color is either red or blue, for a total of 4 different stimuli. In Fig. 2 A we show two possible geometries. Each point represents the response of a population of three neurons to one of the four stimuli. The activity of each neuron is represented along a different coordinate axis. The geometry depicted in Fig. 2 A-left shows the 4 points arranged on a square (factorized or disentangled representation), where shape and color are encoded along two orthogonal directions. The CCGP for shape is defined as the performance of a linear decoder to report the shape of the stimulus (circle or triangle) when its color is blue (testing set), after it was trained only on red stimuli (training set). For this kind of geometry, the linear decoder trained to classify the red stimuli can readily generalize to blue objects, resulting in high CCGP for variable shape. For this geometry, color also has an elevated CCGP (a decoder trained to report color for triangles would generalize right away to circles). The CCGP of shape depends on the angles between coding directions and in order to generalize to blue objects, it is necessary that the coding direction of shape for red stimuli (i.e. the direction from the points corresponding to neural activities from circle to triangle) is approximately the same for stimuli. If we consider a second kind of geometry where the 4 points are placed at random positions in the activity space (Fig. 2 A-right), CCGP is low as a decoder trained to classify the shape only on red objects does not generalize to the blue ones. In general, a variable with high CCGP is encoded in a special format that we define as "abstract". The variable, i.e. shape, is encoded in an abstract format (or simply, it is abstract) because the coding direction does not depend on the specific instance, i.e. color. CCGP also takes into account the noise structure, and it is cross-validated.

---

### The impingement-free, prosthesis-specific, and anatomy-adjusted combined target zone for component positioning in THA depends on design and implantation parameters of both components [^77338b5a]. Clinical Orthopaedics and Related Research (2020). Medium credibility.

Background

Lewinnek's recommendation for orienting the cup in THA is criticized because it involves a static assessment of the safe zone and because it does not consider stem geometry. A revised concept of the safe zone should consider those factors, but to our knowledge, this has not been assessed.

Questions/Purposes

(1) To determine the shape, size, and location of target zones for combined cup and stem orientation for a straight stem/hemispheric cup THA to maximize the impingement-free ROM and (2) To determine whether and how these implant positions change as stem anteversion, neck-shaft angle, prosthetic head size and target range of movements are varied.

Methods

A three-dimensional computer-assisted design model, in which design geometry was expressed in terms of parameters, of a straight stem/hemispheric cup hip prosthesis was designed, its design parameters modified systematically, and each prosthesis model was implanted virtually at predefined component orientations. Functional component orientation referencing to body planes was used: cups were abducted from 20° to 70°, and anteverted from -10° to 40°. Stems were rotated from -10° to 40° anteversion, neck-shaft angles varied from 115° to 143°, and head sizes varied from 28 to 40 mm. Hip movements up to the point of prosthetic impingement were tested, including simple flexion/extension, internal/external rotation, ab/adduction, combinations of these, and activities of daily living that were known to trigger dislocation. For each combination of parameters, the impingement-free combined target zone was determined. Maximizing the size of the combined target zone was the optimization criterion.

Results

The combined target zones for impingement-free cup orientation had polygonal boundaries. Their size and position in the diagram changed with stem anteversion, neck-shaft angle, head size, and target ROM. The largest target zones were at neck-shaft angles from 125° to 127°, at stem anteversions from 10° to 20°, and at radiographic cup anteversions between 17° and 25°. Cup anteversion and stem anteversion were inverse-linearly correlated supporting the combined-anteversion concept. The range of impingement-free cup inclinations depended on head size, stem anteversion, and neck-shaft angle. For a 127°-neck-shaft angle, the lowest cup inclinations that fell within the target zone were 42° for the 28-mm and 35° for the 40-mm head. Cup anteversion and combined version depended on neck-shaft angle. For head size 32-mm cup, anteversion was 6° for a 115° neck-shaft angle and 25° for a 135°-neck-shaft angle, and combined version was 15° and 34° respectively.

Conclusions

The shape, size, and location of the combined target zones were dependent on design and implantation parameters of both components. Changing the prosthesis design or changing implantation parameters also changed the combined target zone. A maximized combined target zone was found. It is mandatory to consider both components to determine the accurate impingement-free prosthetic ROM in THA.

Clinical Relevance

This study accurately defines the hypothetical impingement-free, design-specific component orientation in THA. Transforming it into clinical precision may be the case for navigation and/or robotics, but this is speculative, and as of now, unproven.

---

### Rivaroxaban (Xarelto) [^310f4423]. FDA (2025). Medium credibility.

3 DOSAGE FORMS AND STRENGTHS

2.5 mg tablets: Round, light yellow, and film-coated with a triangle pointing down above a "2.5" marked on one side and "Xa" on the other side
10 mg tablets: Round, light red, biconvex and film-coated with a triangle pointing down above a "10" marked on one side and "Xa" on the other side
15 mg tablets: Round, red, biconvex, and film-coated with a triangle pointing down above a "15" marked on one side and "Xa" on the other side
20 mg tablets: Triangle-shaped, dark red, and film-coated with a triangle pointing down above a "20" marked on one side and "Xa" on the other side
For oral suspension: white to off-white granules; once reconstituted, provide flavored white to off-white opaque liquid with a concentration of 1 mg/mL.

Tablets: 2.5 mg, 10 mg, 15 mg, and 20 mg (3)
For oral suspension: 1 mg/mL once reconstituted (3)

---

### Standards of care in diabetes – 2025 [^9a2ec52c]. Diabetes Care (2025). High credibility.

Regarding specific circumstances for hypoglycemia, more specifically with respect to elderly patients, ADA 2025 guidelines recommend to individualized goal levels for the treatment of hypertension in most older patients.

---

### The geometric nature of weights in real complex networks [^72348287]. Nature Communications (2017). Medium credibility.

Since triangles are a reflection of the triangle inequality in the underlying metric space, we expect nodes forming triangles to be close to one another. Thus, the higher average normalized weight observed on triangles strongly suggests a metric nature of weights, which is not a trivial consequence of the relation between weights and topology. This leads us to formulate the hypothesis that the same underlying metric space ruling the network topology — inducing the existence of strong clustering as a reflection of the triangle inequality in the underlying geometry — is also inducing the observed correlation between ω norm and m. To prove this, we develop a realistic model of geometric weighted random networks, which allows us to estimate the coupling between weights and geometry in real networks.

A geometric model of weighted networks

Many models have been proposed to generate weighted networks. Among them, growing network modelsand the maximum-entropy class of models. However, none of them is general enough to reproduce simultaneously the topology and weighted structure of real weighted complex networks. We introduce a new model based on a class of random networks with hidden variables embedded in a metric spacethat overcomes these limitations. In this model, N nodes are uniformly distributed with constant density δ in a D -dimensional homogeneous and isotropic metric space (Supplementary Methods), and are assigned a hidden variable κ according to the probability density function (pdf) ρ (κ). Two nodes with hidden variables κ and κ ′ separated by a metric distance d are connected with a probability

where μ > 0 is a free parameter fixing the average degree and p (χ) is an arbitrary positive function taking values within the interval (0, 1). The free parameter μ can be chosen such that(κ) = κ. Hence, κ corresponds to the expected degree of nodes, so the degree distribution can be specified through the pdf ρ (κ), regardless of the specific form of p (χ) (Supplementary Methods). The freedom in the choice of p (χ) allows us to tune the level of coupling between the topology of the networks and the metric space, which in turn allows us to control many properties such as the clustering coefficient and the navigability.

---

### A mathematical model for decreasing the surface area of surgical excisions [^937d7183]. Dermatologic Surgery (2012). Low credibility.

Background

Repair of lower extremity excision defects poses a surgical challenge, and as a result, split-thickness skin grafting is often used to close large defects. By minimizing the size of the defect, a smaller graft can be used, which may translate into improvements in wound healing and the aesthetic outcome.

Objective

To demonstrate, using a mathematical model, how to decrease the surface area of excisions on lower extremities requiring split-thickness skin grafting.

Methods

Four patients had cutaneous neoplasms excised from their lower legs. The resulting defects underwent partial primary closure with removal of Burrow's triangle. The new dimensions of the defect were recorded, and the surface area of the pre- and postprimary closure was calculated.

Results

Modest decreases in the dimensions of the ovoid-ellipsoid defect translated to large decreases in the surface area requiring split-thickness skin graft repair.

Conclusion

Using a mathematical model, we quantified how it is possible to decrease the size of an excision site. This reduction in surface area may translate to benefits in a postoperative outcomes.

---

### Standards of care in diabetes – 2025 [^31be65a6]. Diabetes Care (2025). High credibility.

Regarding diagnostic investigations for hypoglycemia, more specifically with respect to screening for cognitive impairment, ADA 2025 guidelines recommend to simplify diabetes treatment plans as much as possible for patients with cognitive impairment and tailor to minimize the risk of hypoglycemia.

---

### ABC transporters in cancer: more than just drug efflux pumps [^71d643db]. Nature Reviews: Cancer (2010). Medium credibility.

Multidrug transporter proteins are best known for their contributions to chemoresistance through the efflux of anticancer drugs from cancer cells. However, a considerable body of evidence also points to their importance in cancer extending beyond drug transport to fundamental roles in tumour biology. Currently, much of the evidence for these additional roles is correlative and definitive studies are needed to confirm causality. We propose that delineating the precise roles of these transporters in tumorigenesis and treatment response will be important for the development of more effective targeted therapies.

---

### Machine learning-enabled forward prediction and inverse design of 4D-printed active plates [^88111524]. Nature Communications (2024). High credibility.

Design results for irregular target shapes

Next, we consider the irregular target shapes. In this case, the challenge in well defining a target becomes particularly severe. First, as discussed above, it is hard to appropriately specify the grid points with physically attainable spacing. Second, it is even harder to give the boundary of the target surface. In extreme cases, general irregular surfaces may involve boundaries that are physically unattainable by a square sheet, which would make the optimization intractable. To resolve these difficulties, we use a patch representation rather than the grid point representation for the target surface, and this new representation allows for extracting the surface normal of each patch and thus using a new measure of approximation errors (or loss) based on the normal distance of the achieved grid points to the target surface (Fig. 7a). This is schematically illustrated in Fig. 7a, where the black lines denote the measure of approximation errors, or distances between the target (gray surface, represented by purple points (top) or patches (bottom)) and the achieved surface (represented by blue points). Therefore, the new loss can be expressed aswhere d ij (S) denotes the distance of achieved point (x ij, y ij, z ij) to the target surface. With the new target representation and loss function, there are no strict requirements for the appropriate boundary of targets or sampling of grid points, as the optimization is essentially to achieve an actuated surface or patch that conforms to the target surface.

---

### Quantum algorithms for topological and geometric analysis of data [^64ec3fab]. Nature Communications (2016). Medium credibility.

Topological methods for analysis face challenges: a data consisting of n data points possesses 2 n possible subsets that could contribute to the topology. Performing methods of algebraic topology on simplicial complexes eventually requires matrix multiplication or diagonalization of matrices of dimensionto extract topological features at dimension k. For small k, such operations require time polynomial in n; however, to extract high-dimensional features, matrix multiplication and diagonalization lead to problem solution scalings that grow exponentially in the size of the complex. A variety of mathematical methods have been developed to cope with the resulting combinatorial explosion, notably mapping the complex to a smaller complex with the same homology, and then performing the matrix operations on the reduced complex. Even in such cases, the initial reduction must identify all simplices in the original complex, and so can scale no better than linearly in the number of simplices. Consequently, even with only a few hundred data points, creating the persistent homology for Betti numbers at all orders of k is a difficult task. In particular, the most efficient classical algorithms for estimating Betti numbers at order k (the number of k -dimensional gaps, holes and so on), have computational complexity either exponential in k or exponential in n (refs,), so that estimating Betti numbers to all orders scales exponentially in n, and algorithms for diagonalizing the combinatorial Laplacian (that reveal not only the Betti numbers but additional geometric structure) at order k have computational complexity as, where n is the number of vertices in the (possibly reduced) complex. That is, the best classical algorithms for estimating Betti numbers to all ordersand for diagonalizing the full combinatorial Laplacian grow exponentially in the number of vertices in the complex.

---

### Geometric constraints on human brain function [^ee0f3fa5]. Nature (2023). Excellent credibility.

Methods

Derivation of cortical geometric eigenmodes

If brain structure can be approximated as being constant in time, the resulting spatial and temporal dynamics can be treated separately via eigenmode decomposition, similar to the treatment of other physical systems. In particular, the spatial aspect satisfies the Laplacian eigenvalue problem, which is also known as the Helmholtz equation, defined in equation (1).

For the cerebral cortex, which we consider as a two-dimensional (2D) model embedded within 3D Euclidean space, the LBO in equation (1) captures intrinsic geometry, which includes the curvature of the cortical surfaceand is defined generally as, where x i, x j are the local coordinates, g ij is the inverse of the inner product metric tensor, W: = √det(G), det denotes the determinant and.

We employed the LaPy python library, installed in the MASSIVE high-performance computing facilityto derive the geometric eigenmodes of the human cortex. Specifically, we used a triangular surface mesh representation of the midthickness human cortical surface, comprising 32,492 vertices in each hemisphere, obtained from a downsampled, left–right symmetric version of the FreeSurfer's fsaverage population-averaged template. This template is independent of the data sample used in all our analyses, thus obviating any concerns about circularity.

Note that the continuous LBO operates on the underlying Riemannian manifold of the surface and not directly on mesh vertices. LaPy uses the cubic finite element method on the surface mesh to achieve numerically tractable solutions of equation (1) on an interpolated smooth manifold. This distinguishes it from the discrete graph Laplacian, which does not encode spatial relations between points. All our analyses were focused on unihemispheric eigenmodes, but our approach can easily be extended to the whole brain because bihemispheric eigenmodes can be represented as symmetric or antisymmetric combinations of the eigenmodes derived from each hemisphere; symmetric combinations correspond to mirror symmetry across the sagittal midplane and asymmetric combinations correspond to cases in which the hemispheres have the same spatial structure but with flipped signs.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^14a823c9]. Annals of the American Thoracic Society (2023). High credibility.

Stereological principles in quantitative image analysis — stereology is the statistical science providing practical methods for extracting accurate and precise quantitative structural information from imaging data sets of irregular objects; stereological methods make no assumptions regarding shape, size, orientation, or spatial distribution of objects and are unbiased by design rather than relying on geometric model assumptions, and stereology is the method of choice for quantifying lung structure in microscopy, with the same principles applying to CT (computed tomography), micro-CT, PET, MRI, and other modalities ("in vivo morphometry").

---

### A simple method of designing a bilobed flap using a triangle template [^6fc07614]. Dermatologic Surgery (2004). Low credibility.

Background

The bilobed flap is useful for the reconstruction of skin defects in which the primary closure is difficult. Proper design is paramount to achieve excellent cosmetic results, but flap design often appears unnecessarily complex and difficult.

Objective

The objective was to discuss the geometry of the bilobed flap and describe a simple and practical method for constructing such flaps using a triangle template with emphasis on the pivot point.

Methods

A detailed description with diagrams and an illustrative case are presented to demonstrate the technique.

Results

A patient with a scalp defect was reconstructed with a triangle-template-designed bilobed flap with excellent postoperative results.

Conclusion

This new method using a triangle template ensures proper placement of the pivot point and will enable practitioners to achieve superior outcomes.

---

### Universal hidden order in amorphous cellular geometries [^a54cfed4]. Nature Communications (2019). High credibility.

Partitioning space into cells with certain extreme geometrical properties is a central problem in many fields of science and technology. Here we investigate the Quantizer problem, defined as the optimisation of the moment of inertia of Voronoi cells, i.e., similarly-sized 'sphere-like' polyhedra that tile space are preferred. We employ Lloyd's centroidal Voronoi diagram algorithm to solve this problem and find that it converges to disordered states associated with deep local minima. These states are universal in the sense that their structure factors are characterised by a complete independence of a wide class of initial conditions they evolved from. They moreover exhibit an anomalous suppression of long-wavelength density fluctuations and quickly become effectively hyperuniform. Our findings warrant the search for novel amorphous hyperuniform phases and cellular materials with unique physical properties.

---

### Universality in long-distance geometry and quantum complexity [^e343ca2d]. Nature (2023). Excellent credibility.

This implies that we can approximate the operatorwith a total cost of about. This operator agrees with our target operatorat leading order in z, and has an inner-product error of about z². This can be improved to z³ by using the next order in the Suzuki–Trotter expansion, but going to even higher orders becomes prohibitively expensive. It is at this point that we make our heuristic step. In the Euclidean group example, we saw that the complexity geometry has so many degrees of freedom that by making minor deformations of the path we can correct small errors at small extra cost, in a way that is not captured by any finite order of the Suzuki–Trotter expansion, and is instead an emergent feature in the IR. Compared with the SU(2) example in the section ' Berger sphere ', the task of compiling in U(2 N) is complicated by the fact that there are many more directions in which to err; on the other hand, there are correspondingly more directions in which we can wiggle the path to eliminate the error, and as a statistical matter, we expect that to dominate. If the small inner-product errors can be corrected by wiggling the path, then we can synthesizefor z < 1 at cost k n 2 (k). To generateat larger values of z, the triangle inequality (for any) guarantees that the complexity grows no faster than linearly with coefficient k n 2 (k). This argument heuristically shows that the binomial metric is in the same universality class as the infinite-cliff metric, and therefore upper-bounds the critical schedule:The upper-bound equation (17) holds at all but the largest k, where the analysis becomes unreliable. Note also that although the binomial metric does not have a curvature as small as the exponential metric, it is still very moderate ∣ κ ∣ ≤ O (N) compared to the cliff metric. The reasoning that leads to equation (17) is heuristic, because to eliminate error it appeals to a statistical argument. In ref. it is shown that there is a weaker result that can be proved. The study also shows that any unitary that can be reached with a path that in the binomial metric has a lengthcan be approximated to within inner-product error ϵ by a path that in the infinite-cliff metric has a lengthOur conjectures imply that this can be improved from polynomial to linear-with-additive-constant and from approximate to exact.

---

### Comparing accuracies of length-type geographic atrophy growth rate metrics using atrophy-front growth modeling [^6d008c34]. Ophthalmology Science (2022). Medium credibility.

Although the mathematical formulation and numerical implementation of our growth model is somewhat complex, our model's conceptual underpinning is relatively parsimonious. Indeed, the atrophy front growth model of equation SI-2 (Appendix 1) is arguably the minimal model of an anisotropically evolving margin. Moreover, as noted previously, although independently derived, our growth model naturally leads to a notion of growth rate that is consistent with the previously proposed square-root-transformed and perimeter-adjusted growth rate metrics. We argue that this agreement lends support both to our model and to the use of these growth rate metrics. Nevertheless, given the relative intricacies of our model's formulation, it is reasonable to ask what advantages it offers compared with more informal or ad hoc statements of the margin-mediated growth hypothesis. In this regard, we believe that this study makes 2 substantive contributions: (1) our model leads to a precise biophysical statement as to what length-type growth rate metrics measure, something that is reasonably nuanced and not a priori evident, particularly for anisotropic lesion growths; and (2) our model allows quantitative assessments of length-type metric accuracies on realistic lesion geometries and growth patterns, something that is not possible with existing formulations. In particular, the accuracies of length-type metrics have been discussed previously only in the context of simple shapes (e.g. circles) and simple growth patterns (e.g. isotropic growth fields or infinitesimal time intervals, Δ t).

---

### Emergence of fractal geometries in the evolution of a metabolic enzyme [^00d163d6]. Nature (2024). Excellent credibility.

We investigated the structure of these assemblies by negative-stain electron microscopy (EM) and observed that SeCS assembles into regular triangular complexes of different sizes (Fig. 1c, d and Extended Data Fig. 1b–f). The 18mer contains 9 discernible densities, each corresponding to a dimer. Three dimers are first arranged in a hexameric ring and three hexamers then connect into a triangle. This 18mer represented the main oligomeric species under MP conditions (> 80% of all CS subunits at 50 nM; Fig. 1b). Rarely (on the order of 3–4% of particles; Methods), we observed even larger complexes comprising 36 or 54 CS subunits on the micrographs, which were recorded at a 9 times higher protein concentration than for MP (450 nM). The 54mer consisted of three 18mers arranged into an even larger triangle with a large void at its centre (Fig. 1c). The 6mer, 18mer and 54mer represent the zeroth, first and second order of the Sierpiński triangle, a well-known regular fractal geometry. The 36mer represents another kind of triangle, but shares the 6mer building block and the overall triangular shape (Fig. 1d). Additional regular assemblies that were sporadically observed also retained the triangular edges (Extended Data Fig. 1g).

---

### The representation of geometric cues in infancy [^3bf27a75]. Infancy (2008). Low credibility.

There is evidence that, from an early age, humans are sensitive to spatial information such as simple landmarks and the size of objects. This study concerns the ability to represent a particular kind of spatial information, namely, the geometry of an enclosed layout-an ability present in older children, adults, and nonhuman animals (e.g. Cheng, 1986; Hermer & Spelke, 1996). Using a looking-time procedure, 4.5- to 6.5-month-olds were tested on whether they could distinguish among the corners of an isosceles triangle. On each trial, the target corner was marked by a red dot. The stimulus (triangle with dot) appeared from different orientations across trials, ensuring that only cues related to the triangle itself could be used to differentiate the corners. When orientations were highly variable, infants discriminated the unique corner (i.e., the corner with the smaller angle and two equal-length sides) from a nonunique corner; they could not discriminate between the two nonunique corners. With less variable orientations, however, infants did discriminate between the nonunique corners of the isosceles triangle. Implications for how infants represent geometric cues are discussed.

---

### Programmable interactions and emergent geometry in an array of atom clouds [^7ba0b504]. Nature (2021). Excellent credibility.

Interactions govern the flow of information and the formation of correlations between constituents of many-body quantum systems, dictating phases of matter found in nature and forms of entanglement generated in the laboratory. Typical interactions decay with distance and thus produce a network of connectivity governed by geometry-such as the crystalline structure of a material or the trapping sites of atoms in a quantum simulator 1,2. However, many envisioned applications in quantum simulation and computation require more complex coupling graphs including non-local interactions, which feature in models of information scrambling in black holes 3–6 and mappings of hard optimization problems onto frustrated classical magnets 7–11. Here we describe the realization of programmable non-local interactions in an array of atomic ensembles within an optical cavity, in which photons carry information between atomic spins 12–19. By programming the distance dependence of the interactions, we access effective geometries for which the dimensionality, topology and metric are entirely distinct from the physical geometry of the array. As examples, we engineer an antiferromagnetic triangular ladder, a Möbius strip with sign-changing interactions and a treelike geometry inspired by concepts of quantum gravity 5,20–22. The tree graph constitutes a toy model of holographic duality 21,22, in which the quantum system lies on the boundary of a higher-dimensional geometry that emerges from measured correlations 23. Our work provides broader prospects for simulating frustrated magnets and topological phases 24, investigating quantum optimization paradigms 10,11,25,26 and engineering entangled resource states for sensing and computation 27,28.

---

### An optimal bronchial tree may be dangerous [^91eda102]. Nature (2004). Excellent credibility.

The geometry and dimensions of branched structures such as blood vessels or airways are important factors in determining the efficiency of physiological processes. It has been shown that fractal trees can be space filling and can ensure minimal dissipation. The bronchial tree of most mammalian lungs is a good example of an efficient distribution system with an approximate fractal structure. Here we present a study of the compatibility between physical optimization and physiological robustness in the design of the human bronchial tree. We show that this physical optimization is critical in the sense that small variations in the geometry can induce very large variations in the net air flux. Maximum physical efficiency therefore cannot be a sufficient criterion for the physiological design of bronchial trees. Rather, the design of bronchial trees must be provided with a safety factor and the capacity for regulating airway calibre. Paradoxically, our results suggest that bronchial malfunction related to asthma is a necessary consequence of the optimized efficiency of the tree structure.

---

### Report of the ISHLT working group on primary lung graft dysfunction part II: definition. A consensus statement of the International Society for Heart and Lung Transplantation [^40491f67]. The Journal of Heart and Lung Transplantation (2005). Medium credibility.

International Society for Heart and Lung Transplantation primary graft dysfunction (PGD) nomenclature and structure — The expression "primary graft dysfunction" was the consensus selection for the syndrome's name. The classification scheme contains both a grading for severity of PGD and an indicator of different time-points for classification, and the scheme uses only two clinical parameters: the chest X-ray and the P/F ratio.

---

### Standards of care in diabetes – 2025 [^ef149bc3]. Diabetes Care (2025). High credibility.

Regarding specific circumstances for diabetic nephropathy, more specifically with respect to pediatric patients, ADA 2025 guidelines recommend to determine the eGFR at the time of diagnosis and annually thereafter.

---

### A unifying framework for interpreting and predicting mutualistic systems [^1f58a8c9]. Nature Communications (2019). High credibility.

Although simple general rules in biology can be powerful tools, their applicability to experimental systems can be limited by the difficulties in associating the abstracted parameters to lower-level mechanistic details and quantifying these details experimentally. This is evident in the application of Hamilton's rule to experimental systems –. For many inequality-based simple rules that have been proposed and established, our calibration procedure provides a generally applicable tool to apply these rules directly to experimental systems. If one side of the inequality and some final outcomes can be measured or have been observed historically, the other side can be calibrated as an empirical function. Although our procedure cannot further dissect the empirical function into specific mechanistic parameters, the function can serve as an overall summary of the underlying mechanistic details while bypassing the requirement of characterizing them individually. Our approach thus can enable the downstream interpretation and prediction by these simple rules with readily accessible measurements.

---

### Shape analysis, a field in need of careful validation [^3754a883]. Human Brain Mapping (2014). Low credibility.

In the last two decades, the statistical analysis of shape has become an actively studied field and finds applications in a wide range of areas. In addition to algorithmic development, many researchers have distributed end-user orientated toolboxes, which further enable the utilization of the algorithms in an "off the shelf" fashion. However, there is little work on the evaluation and validation of these techniques, which poses a rather serious challenge when interpreting their results. To address this lack of validation, we design a validation framework and then use it to test some of the most widely used toolboxes. Our initial results show inconsistencies and disagreement among four different methods. We believe this type of analysis to be critical not only for the community of algorithm designers but also perhaps more importantly to researchers who use these tools without knowing the algorithm details and seek objective criteria for tool selection.

---

### Structural puzzles in virology solved with an overarching icosahedral design principle [^820fe4eb]. Nature Communications (2019). High credibility.

Results

Polyhedral models of icosahedral architecture

Virus structures are prominent examples of icosahedral symmetry in biology. Their architectures are currently modelled and classified in terms of the series of Goldberg polyhedra — three dimensional solids with pentagonal and hexagonal faces — that provide a reference frame for the positions of the capsid proteins (Fig. 1a). In particular, the polyhedral faces indicate the positions of pentagonal and hexagonal protein clusters called pentamers and hexamers, respectively. The same polyhedra also provide blueprints for the atomic positions of the fullerene cages in carbon chemistry, in particular the Buckminster fullerene known as the buckyball. They also provide blueprints for the structural organisation of a wide range of both man-made and natural protein nanocontainers. Their duals, the geodesic polyhedra, are the architectural designs of the geodesic domes by Buckminster Fuller.

Goldberg polyhedra can be constructed from a hexagonal grid (lattice) by replacing 12 hexagons by pentagons (Fig. 1b), as required by Euler's Theorem to generate a closed polyhedral shape. The distancebetween the pentagons at neighbouring fivefold vertices is the only degree of freedom in this construction, and can therefore be used to label the different geometric options in this infinite series of polyhedra.can only take on specific values that are constrained by the underlying hexagonal lattice geometry. In particular, using the hexagonal coordinatesand, which take on any integer values or zero to navigate between midpoints of neighbouring hexagons in the lattice, one obtains the following geometric restriction:Here, corresponds to the area of the smallest triangle between any hexagonal midpoints, that is, the caseand — or equivalently,… A similar formula has been derived for elongated capsid structures.

---

### Simple expression domains are regulated by discrete CRMs duringOogenesis [^f1b65610]. G3 (2017). Low credibility.

Figure 2
Expression domains of several FlyLight lines. (Aa) A cartoon describing the daughters against dpp (dad) expression pattern in the stretched cells (SC) and anterior (A) domains. (Ab) The gene model for dad and the associated FlyLight fragments screened during oogenesis. The GFP-positive lines are marked in orange. * indicates a line with expression not seen in endogenous gene patterns. Open arrowhead denotes the TSS and the direction of the gene in the locus. (Ac–e) GFP expression driven by dad 44C10 during stages 9–10B in the stretched cells (SC) and centripetally migrating follicle cells, denoted as the anterior (A) domain. BR is used as a spatial marker. n is the number of images represented by this image. Arrowheads denote the dorsal midline. (Af–h) GFP expression driven by dad 43H04 during stages 9–10B in the SC. (Ai–k) GFP expression driven by dad 45C11 during stages 9–10B in the border cells (BC). (Ai′–k′) Insets of (i–k) (white arrow denotes the BC). Additional stages can be found inD. (Ba and b) A cartoon describing the expression patterns of early and late br. (Bc) The gene model for br and the associated FlyLight fragments screened during oogenesis. The GFP-positive lines are marked in orange. (Bd–f) GFP expression driven by br 69B10 during stages 9–10B is uniform in all follicle cells. (Bg–i) GFP expression driven by br 69B08 during stages 10B–12 in the roof (R) and floor (F) domains (br RF). (Bg′–i′) Insets of (Bg–i). (Bj) The position of the different br fragments: br E, br L, and br S, and br 69B08 (br RF, this screen). br 69B08 is 250 and 53 bp shorter on the left and right ends, respectively, than the br S fragment. Additional stages can be found inC. (Ca and b) A cartoon describing the expression patterns of pointed -P1 (pnt -P1) during stages 6–8 in the posterior (P) domain, and at the floor (F) and P domains at stage 11. (Cc) The gene model for pnt isoforms and the associated FlyLight fragments screened during oogenesis. The GFP-positive lines are marked in orange. (Cd–f) GFP expression driven by pnt 43H01 during stages 9–10B in the SC, border cells (BC), and P domains. (Cg–i) GFP expression driven by pnt 45D11 during stages 9–10B in the BC and P domains. Additional stages can be found inR. (D) A binary matrix representing all gene expression patterns (red) and FlyLight GFP-positive lines (green). The overlap between the two data sets is denoted in yellow. The matrix is based on assigning mutually exclusive domains to patterns (Figure 1 and, i and ii). Domains include germarium (G), splitting the anterior domain to anterior dorsal (AD) and anterior ventral (AV), midline (M), roof (R), floor (F), dorsal (D), posterior (P), stretched cells (SC), stalk cells (StC), polar cells (PC), and uniform (U). Additional domains are included as not one of the previously listed (/) for domain exclusions. The complete description of these domains can be found in, i and ii. On the y -axis is the gene name at a specified developmental stage. Percent recapitulation (%Recap.) represents the percent of GFP patterns that overlap with the endogenous pattern in each domain.

---

### Theory of branching morphogenesis by local interactions and global guidance [^0e98dd47]. Nature Communications (2021). High credibility.

Fig. 5
Effect of self-avoidance and external guidance on branching density and space-filling properties.

a Fractal dimension of the networks estimated by the box-counting method: Boxes of decreasing sizes ϵ are used to count the total number of boxes that include at least one skeletonized node. b Mean fractal dimensions obtained from the box-counting method increases from 〈 d f 〉 ≃ 1.52 to 〈 d f 〉 ≃ 1.67 with increasing self-avoidance (f s = 0 to f s = − 0.3), whereas large changes in the external field strength (from f c = 0.4 to f c = 1) have a smaller effect on the mean values. c Combined experimental data from the densest n = 4 networks (circular markers) are consistent with the theoretically predicted power-law: We find a fractal dimension of d f ≃ 1.55, close to the theoretical value d f ≃ 1.57 obtained from the combined data from simulations with f c = 0.6 and f s = 0 (crosses). d Average densityof a branched network (ratio of the number of branch segments to the arc lengthspanned by the network). e Densitiesof the simulated networks increase markedly both for increasing external field strength f c and self-repulsion strength ∣ f s ∣. f Densitiesobtained from experimental data for n = 8 filaments (crosses) compared with densities obtained from simulations for f c = 0.6 and f s = 0 (blue box), f s = −0.1 (green box), and f s = −0.2 (purple box). Mean density of the experimental data (red horizontal line) is on the lower end of the densities obtained from simulations even for low repulsion, indicating a small value for the parameter f s. For each parameter choice box plots are obtained from n = 100 simulations, with mean and median values denoted respectively by the plot markers and horizontal dashed lines (orange). The boxes are drawn from the first quartile Q₁ to the third quartile Q₃, and whiskers indicate 1.5 interquartile range (IQR ≡ Q₃ − Q₁), i.e. max = Q₃ + 1.5 IQR, min = Q₁ − 1.5 IQR.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^443e12f1]. Annals of the American Thoracic Society (2023). High credibility.

Unbiased stereological sampling — principles and methods note that "Unbiased sampling designs guarantee statistically representative samples and generally must be spatially randomized", and for anisotropic structures some parameters "require spatial orientation randomization". Named approaches include "systematic uniform random sampling", "isotropic uniform random sampling", "stratified sampling", "fractionator sampling", and "proportionator sampling". Importantly, "Voxel-by-voxel automated image analysis ensures neither accuracy nor precision of the results, nor does it obviate the need to strictly follow stereological sampling principles".

---

### An aperiodic chiral tiling by topological molecular self-assembly [^9b5ae99f]. Nature Communications (2025). High credibility.

Fig. 2
Abstraction of molecular self-assembly into triangular offset-tiling.

a Color code for both enantiomers of t[4]HB and their relative azimuthal orientation. b Presentation of a self-assembled pattern of t[4]HB (P)- enantiomers as triangles. The color stands for the azimuthal orientation as defined in (a) while the number stands for the relative size N of the triangle. c Modes of interdigitation between triangles at their common boundary. The handedness of the majority enantiomer defines the direction of the interdigitation offset of triangles (see ellipses). An additional offset by one molecular unit vector is also observed for equally sized triangles (middle) and for N ± 1 pairs (bottom). d Superposition of STM images of the different node types in both mirror domains with the abstraction of triangles. The node type is defined by the number of offsets as indicated by arrows. e Example of topological frustration. An area initially built by 2-nodes (N = 7 ± 1) can only become completely filled if a 3-node is considered.

Three distinct categories of triangle interdigitation emerge. Equally sized triangles necessitate an inevitable offset contingent on the enantiomer's handedness (Fig. 2c, top). Furthermore, equally sized triangles may exhibit an additional offset of one molecular unit vector (Fig. 2c, middle), leading to a total offset of 2-unit vectors at that boundary. Lastly, combining triangles of different sizes, N and N ± 1, consistently results in an offset of one molecular unit vector (Fig. 2c, bottom). This framework enables a total of 10 different triangular pairing configurations (see Supplementary Fig. 6). Nodes with a topological index of 0, 2, and 3 will, respectively, feature total offsets of 0, 2, and 3 (Fig. 2d). The topology established by these offsets translates into the spiral pattern when constructing nodes using N, N ± 1 triangles. Consequently, the handedness of supramolecular nodes emerges from a chiral displacement within the triangular context. It is important to note that deviations from these displacement rules have not been observed. Only 15 of many possible combinations of triangles within the N, N ± 1 scheme have been verified through STM observations (Supplementary Fig. 7). However, we could not identify any tiling rules that would forbid involvement of unobserved combinations.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^b09550c3]. Annals of the American Thoracic Society (2023). High credibility.

Airway comparative analysis — matching approaches and caveats: Table 5 outlines selection criteria with example metrics and considerations, including designation of "Terminal bronchiole", designating a generation number for each airway, path distance (e.g., 5 cm from carina or pleura), lumen size (e.g., 2-mm-diameter airways), and airways at a stipulated inner perimeter with wall thickness of airways with inner perimeter of 10 mm (Pi10); considerations note pathology may alter airway status, anatomical variations in branching pattern, body and lung size variations, risk of bias when pathology alters airway dimension (e.g. COPD may narrow airway lumens; therefore, 2-mm airways may occur at a different generation compared with subjects without COPD), and that regression assumptions should be confirmed with potential effects of outliers assessed.

---

### Seeing around corners with edge-resolved transient imaging [^a18c7a00]. Nature Communications (2020). High credibility.

The performance of our reconstruction method relies on a carefully tailored scene model, which must be both flexible and informative while remaining computationally tractable. In natural hidden scenes, we observe that facets tend to be spatially clustered, with clusters representing different objects in the room. We also observe that the positions of facets belonging to the same object tend to describe a 1D manifold. For example, the walls of the room can be described by a concatenation of facets forming the perimeter of the hidden scene. Moreover, the parameters of neighboring facets belonging to the same object are strongly correlated. For example, wall facets tend to share similar heights, albedos and orientations.

These assumptions about scene structure are incorporated into the model via a Bayesian framework by assigning a prior distribution p (Φ, χ) to the set of facets Φ (distance, height, albedo, and orientation angle) and ceiling parameters χ (height and albedo). Interpreting the positions of the planar facets as points in 2D space (top view of the hidden room), we define a spatial point process prior model that favors structured configurations (clusters of 1D manifolds). This model is inspired by recent 3D reconstruction algorithms for LOS single-photon lidar that represent surfaces as 2D manifolds. Inference about the most likely room configuration (Φ, χ) is carried out by maximizing the posterior distributionwheredenotes the likelihood of observing the measurements given the room parameters (Φ, χ), which is computed using the light transport model defined in the previous section.

To solve this problem, we develop a reversible-jump MCMC algorithmthat can estimate both the number of facets and their respective parameters. At each iteration, the algorithm proposes a random, yet guided, modification to the configuration of facets (e.g. addition or removal of a facet), which is accepted with a pre-defined rule (the Green ratio). Note that this approach only requires the local evaluation of the forward model, i.e. for individual wedges, which takes advantage of the fast calculations based on Eqn. (6). In particular, we can efficiently take into account non-linear contributions due to occlusions between facets of a given wedge. By designing tailored updates (see Supplementary Note 2), the algorithm finds a good fit in few iterations, resulting in execution times of approximately 100 s, which is less than the acquisition time of the system.

---

### Gene dosage sensitivity and human genetic diseases [^453c7ea3]. Journal of Inherited Metabolic Disease (2025). Medium credibility.

FIGURE 2
Nonlinearities in the recognition of a promoter (P) with n binding sites by a transcription factor (TF). (A) Promoter with three binding sites. (B) The transcriptional response (TR) can be described by the Equation (1):where K and n are constants. The exponent n corresponds to the number of binding sites per promoter (for strong cooperativity), with higher values yielding steeper sigmoidal curves. The graph illustrates TR as a function of TF concentration for n = 3 and n = 5 and K = 1. The effects of a TF‐encoding gene deletion (parental homozygous deletant aa, heterozygote aA, and wild‐type AA) are displayed. The dark‐orange curve represents a classical "mapping function" relating genotype (reflected by the TF concentration) and phenotype (reflected by the TR). According to that curve a deletion of one allele (50% of TF activity left) leads to a drop of more than 80% of TR. In such conditions, the allele a is dominant because the phenotype of Aa is closer to that of aa.

Dosage sensitivity can also be explained by the gene balance hypothesis related to the assembly and operation of multi‐subunit complexes. In short, the overall functionality of such complexes depends on their completeness with all subunits present in a proper stoichiometry. As expected, proteins that are part of macromolecular complexes typically have similar levels of expression to maintain balance. This stoichiometry is a product of cellular economy and the need to avoid the formation of inactive subcomplexes due to imbalanced subunit concentrations. An imbalance among the subunits, such as a 50% reduction in one subunit as in the case of a heterozygous gene deletion, can result either in a proportional decrease in the overall function of the complex, or potentially much more, depending on the stoichiometry of the complex and its assembly pathway. For example, let us consider a trimer ABA the assembly of which follows an irreversible random pathway (i.e. A + B = AB and B + A = BA) followed by AB + A = ABA or A + BA = ABA. In this case, a decrease in B will affect trimer yield proportionally, whereas a decrease in A will have a more significant impact. Indeed, halving the amount of A could lead to ABA production falling well below 50% due to the generation of AB and BA intermediates incapable of completing assembly. Consequently, the concentration of ABA could drop below the threshold for maximum function.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^d5a733c3]. Annals of the American Thoracic Society (2023). High credibility.

Airway comparative analysis — matching strategies and considerations: Table 5 outlines selection criteria including anatomical property via designation of "Terminal bronchiole", branching hierarchy by "Designating a generation number for each airway", distance from a landmark using "Path distance (e.g., 5 cm from carina or pleura)", airway dimension via "Lumen size (e.g., 2-mm-diameter airways)", and airways of a stipulated inner perimeter using "Wall thickness of airways with inner perimeter of 10 mm (Pi10)". Considerations note that "Pathology may alter airway status", "There are anatomical variations in branching pattern; certain nomenclature systems do not cover the entire airway tree", and there is "Risk of bias when pathology alters airway dimension (e.g. COPD may narrow airway lumens; therefore, 2-mm airways may occur at a different generation compared with subjects without COPD)", and "Regression assumptions should be confirmed in the condition(s) under study; potential effects of outliers on regression equation should be assessed"; definitions specify "PiX = predicted wall thickness of airways with inner perimeter of X" and "Pi10 = predicted wall thickness of airways with inner perimeter of 10 mm".

---

### Colorectal cancer screening and prevention [^c270f773]. American Family Physician (2025). High credibility.

Regarding screening and diagnosis for colon cancer, more specifically with respect to indications for screening, general population, aged 76–85 years, AAFP 2025 guidelines recommend to consider obtaining screening for CRC in adults aged 76–85 years at average risk based on overall health status, prior screening history, and patient preferences.

---

### Combined petrosal intertentorial approach: a cadaveric study of comparison with the standard combined petrosectomy [^95cede2f]. Operative Neurosurgery (2025). Medium credibility.

Areas of Surgical Exposure

Two areas of exposure (petroclival skull base and brainstem) were calculated by obtaining the sum of areas formed by juxtaposed triangles. For the petroclival area, we identified 4 fixed anatomic landmarks (posterior clinoid process, MC, internal acoustic canal, and jugular foramen) and 2 variables (uppermost and lowest medial clivus). Measuring the coordinates of these 6 points created a hexagonal shape. For the brainstem area, we identified 2 fixed points (trigeminal and facial nerve root entry zone [REZ]) and 3 variables (the lowest medial, the uppermost medial, and uppermost lateral brainstem), obtaining a pentagon-shaped area (Figure 5 A and 5 B drawing). Each polygon was divided along diagonals to create triangles whose area was calculated by the length of each side using Heron's formula. The areas of the 4 triangles of the petroclival skull base and the 3 triangles of the brainstem were then summed to calculate the total area of surgical exposure.

FIGURE 5.
These figures demonstrate the methodology of the study. A, Schematic representation of the bony skull base indicating the petroclival area of exposure. B, Schematic representation of the brainstem area of exposure. C, A, B, C, D, E, and F represent the 6 limits of the surface measurements that form a hexagon (black), bordered by dural and bony structures, whose area describes the surgical freedom. D, Illustration of the methodology to calculate the angles of attack. The distal point is fixed on the target (ie, right VII REZ), and the dissector is moved in the vertical (cranio-caudal, red dotted lines) and horizontal planes (antero-posterior, green dotted lines) until the limits of the osteo-dural points are encountered (red and green stars). ACP, anterior clinoid process; CN, cranial nerve; FL, foramen lacerum; FO, foramen ovale; FR, foramen rotundum; FS, foramen spinosum; HC, hypoglossal canal; IAC, internal acoustic canal; JF, Jugular foramen; LCNs, lower cranial nerves; PA, petrous apex; PCJ petroclival junction; PCP, posterior clinoid process; REZ, root entry zone.

---

### Solving olympiad geometry without human demonstrations [^2d70710f]. Nature (2024). Excellent credibility.

We present an alternative method for theorem proving using synthetic data, thus sidestepping the need for translating human-provided proof examples. We focus on Euclidean plane geometry and exclude topics such as geometric inequalities and combinatorial geometry. By using existing symbolic engines on a diverse set of random theorem premises, we extracted 100 million synthetic theorems and their proofs, many with more than 200 proof steps, four times longer than the average proof length of olympiad theorems. We further define and use the concept of dependency difference in synthetic proof generation, allowing our method to produce nearly 10 million synthetic proof steps that construct auxiliary points, reaching beyond the scope of pure symbolic deduction. Auxiliary construction is geometry's instance of exogenous term generation, representing the infinite branching factor of theorem proving, and widely recognized in other mathematical domains as the key challenge to proving many hard theorems. Our work therefore demonstrates a successful case of generating synthetic data and learning to solve this key challenge. With this solution, we present a general guiding framework and discuss its applicability to other domains in Methods section 'AlphaGeometry framework and applicability to other domains'.

We pretrain a language model on all generated synthetic data and fine-tune it to focus on auxiliary construction during proof search, delegating all deduction proof steps to specialized symbolic engines. This follows standard settings in the literature, in which language models such as GPT-f (ref.), after being trained on human proof examples, can generate exogenous proof terms as inputs to fast and accurate symbolic engines such as nlinarith or ring, using the best of both worlds. Our geometry theorem prover AlphaGeometry, illustrated in Fig. 1, produces human-readable proofs, substantially outperforms the previous state-of-the-art geometry-theorem-proving computer program and approaches the performance of an average IMO gold medallist on a test set of 30 classical geometry problems translated from the IMO as shown in Fig. 2.

---

### Recommendations for measuring pulmonary nodules at CT: a statement from the Fleischner society [^1d7af3bd]. Radiology (2017). Medium credibility.

Fleischner Society CT pulmonary nodule measurement units and rounding — reporting precision: All measurements and their derivatives should be expressed to the nearest millimeter, and although picture archiving and communication system consoles display measurements to the nearest 0.1 mm, this apparent precision is considered deceptive; consequently, a nodule with a long-axis diameter of 4.5 mm should be rounded to 5 mm, a short-axis diameter of 3.4 mm should be rounded to 3 mm, and the average diameter would be [(5 + 3)/2] = 4 mm.

---

### Four-dimensional computed tomography analysis of bicuspid aortic valves [^fa5c9992]. JTCVS Techniques (2024). Medium credibility.

The software allows calculation of geometric features, including 3D and projected 2D parameters. To calculate the AA area in 3D, triangles were formed between 2 consecutive points on the spline in 3D, delineating the border of the annulus and the AA centroid of the 18 seed points. The AA area was then calculated as the sum of each triangle's area. The perimeter was estimated as the length of the interpolated spline in 3D. For 2D measurements, a best-fit plane was adjusted to the 18 seed points of each time phase using a principal component analysis approach. AA area was estimated in 2D, projecting the spline points into the best-fit plane. The height of the annulus was estimated as the sum of distances of the farthest points on the 3D spline describing the AA below and above the best-fit plane. The longest distance between each pair of opposite points around the TA was adopted as the maximal diameter value, and the distance between the pair of points orthogonal to the maximal diameter was called orthogonal to maximal diameter. The eccentricity index was calculated using the following formula:

Statistical Analysis

Analyses were done using SPSS 26.0 (IBM). Continuous variables were reported as mean ± SD, and their normality of distribution was tested using the Shapiro-Wilk test. Comparisons between 3D and 2D areas, perimeters, and diameters were performed using the 2-tailed t test. Comparisons for categorical data were performed using the χ² test. Statistical significance between parameters was defined as P < .05.

---

### Mechanism of the electroneutral sodium / proton antiporter paNhaP from transition-path shooting [^fc82e07d]. Nature Communications (2019). High credibility.

We used the optimized reaction coordinate to select shooting points in the 2nd and 3rd round of path sampling following the second initial path. Conformations that were predicted to havewere picked as the 2nd round shooting points. The outcomes of these shots were then added to the likelihood, and the reaction coordinate was optimized again (Fig. 4b). Five shooting points were picked for the 3rd round of shooting attempts based on the optimized reaction coordinate, and the predicted committorand observed committor values from the third round of shootings were compared (Fig. 4c). The observed committor values were estimated from 30 shooting trajectories initiated from each shooting point, excluding trajectories that did not commit to either of the two access states during the allotted time (see Methods). Two out of five shooting points show excellent agreement between the predicted and observed committors (shooting conformations 2 and 3 in Fig. 4c). For the other three shooting points, the method underestimated the committor. However, considering the complexity of the transporter motion and the high dimensionality of the system, we find it remarkable that for four out of five points we indeed obtained some transition paths in a quite small number of trials. One should keep in mind that such transition states are vastly outnumbered by configurations fully committed to either the inward or outward-open states. The shooting conformation 2 in Fig. 4c (II-3r/B in Supplementary Fig. 10 and Supplementary Table 1) that successfully produced transition paths is shown in Fig. 4d. A chain of water molecules connects the buried ion-binding site to the inside and outside surfaces.

The results from the reaction coordinate optimization are consistent with a visual inspection of transition-state conformations (Supplementary Fig. 10). The scatter of the transition states along the Δ ϕ axis suggests that the angle change of the domain motion is not important for describing the transition-state ensemble, consistent with the result from the reaction coordinate optimization. Higher commitment to the outward-open state is correlated with the amount of water access from the outside (or, equivalently, the opening of the gate); i.e. occluded-state structures with the gate closed have a lower value of the committor.

---

### Solving olympiad geometry without human demonstrations [^2d66e152]. Nature (2024). Excellent credibility.

Proving mathematical theorems at the olympiad level represents a notable milestone in human-level automated reasoning 1–4, owing to their reputed difficulty among the world's best talents in pre-university mathematics. Current machine-learning approaches, however, are not applicable to most mathematical domains owing to the high cost of translating human proofs into machine-verifiable format. The problem is even worse for geometry because of its unique translation challenges 1,5, resulting in severe scarcity of training data. We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems and proofs across different levels of complexity. AlphaGeometry is a neuro-symbolic system that uses a neural language model, trained from scratch on our large-scale synthetic data, to guide a symbolic deduction engine through infinite branching points in challenging problems. On a test set of 30 latest olympiad-level problems, AlphaGeometry solves 25, outperforming the previous best method that only solves ten problems and approaching the performance of an average International Mathematical Olympiad (IMO) gold medallist. Notably, AlphaGeometry produces human-readable proofs, solves all geometry problems in the IMO 2000 and 2015 under human expert evaluation and discovers a generalized version of a translated IMO theorem in 2004.

---

### Simple spatial scaling rules behind complex cities [^23b5e063]. Nature Communications (2017). Medium credibility.

Spatial scaling

Our simple rules produce the AP, road network, and socioeconomic interaction distributions (see Fig. 1b, c). The AP distribution and its morphology are in good agreement with the real city of Greater London (see Fig. 1d).

The model allows us to quantify these predictions. According to the SA mechanism, when t is sufficiently large the spatial distribution of AP is approximatelywhere ρ (r, t) is the average density at distance r from the city centre, i.e. the seed node at position (0, 0), R (t) is the radius of the entire city at time t (see Fig. 2b and further details of the explicit form of ρ (r, t) are in Supplementary Note 1), and β is a parameter derived from C. The dependence of β on C (see Fig. 2a) can be derived by the non-linear fitting, and the simulation results are shown in Fig. 2b. Figure 2c shows that the collected data validate Eq. (4). The AP in the real data is defined as a mixture of working and residential populations according to their active duration in that region (see Methods). In the downtown area (i.e. when r / R (t) → 0), the AP density decays following the power law shown in Eq. (4) (see Fig. 2c). In contrast, residential population density decays exponentially as we move from city centre to urban fringe, as verified in previous researchand our data (see Supplementary Fig. 8). This reconciles the conflict between area-size allometry and the exponential decay of population from city centre to urban fringe found in the literature. To eliminate the influence of noise in the empirical data and allow an unbiased comparison of different quantities, we study the cumulative quantities in terms of the distance from the central area instead of the local density (see Fig. 3). Integrating Eq. (4) we obtainwhere P (r, t) is the cumulative AP within the concentric circle of the central area with radius r (see Supplementary Note 3 and Supplementary Fig. 7 for detailed derivations). This expression is approximately a power law with an exponent 2 − β when. This is consistent with the fractal city hypothesis, and the fractal dimension is 2 − β if the distributions of APs and buildings are similar. We can similarly calculate the cumulative road length and socioeconomic interactions asandTherefore the exponents of the cumulative length of the road network and socioeconomic interactions within the circle of radius r are 2 − β /2 and 2 − 3 β /2. These predictions are consistent with the data from Beijing and London shown in Fig. 3. Due to the need for high-resolution data, we use nighttime light as the proxy for socioeconomic interactions –. Although nighttime light data has some intrinsic disadvantages when representing high-resolution interactions (e.g. at a community level, because luminosity is also associated with road density and type of land use), it remains the best candidate among open-source data. We show that as long as the spatial resolution is not excessively high it is a good proxy (see Methods, Supplementary Figs. 10 and 12–14 and Supplementary Note 6 for further discussion). Thus based on Eqs. (5)–(7) we can obtain all the other spatial scaling exponents from any single observation.

---

### Structural puzzles in virology solved with an overarching icosahedral design principle [^a3141d0d]. Nature Communications (2019). High credibility.

However, this is only one way in which an icosahedral structure can be built from repeats of the same (asymmetric) unit, and excludes geometries built from proteins of different sizes (such as a major and minor capsid protein) or capsids built from a protein in which one or several domains play distinguished roles. Such capsid layouts must be constructed from lattices in which every vertex is identical in terms of the lengths, numbers and relative angles of its protruding edges, but the relative angles between different edges at the same vertex can vary, reflecting occupation by different types of proteins or protein domains. From a geometric point of view, there are only 11 lattices (Chapter 2 in Grünbaum and Shephard) that satisfy this generalised quasi-equivalence principle, which are the Archimedean lattices — also known as uniform lattices. Among these lattices, only four contain a hexagonal sublattice (Fig. 2a). One of them is the hexagonal lattice itself on which the CK classification scheme is based. This lattice is labelledaccording to the types of regular polygons surrounding each vertex, in this case three hexagons. However, the hexagonal lattice is only the simplest grid that enables this construction. Other lattices containing hexagons at appropriate distances, that is, as a hexagonal sublattice, are equally amenable to the CK construction, but have until now been ignored. These are the trihexagonal tiling, the snub hexagonal tiling, and the rhombitrihexagonal tiling(Fig. 2a). These lattices are also called hexadeltille, snub hextille, and the truncated hexadeltille lattice, respectively.

---

### Tromethamine (Tham) [^955e9345]. FDA (2024). Medium credibility.

The dosage of tromethamine IV for treatment of metabolic acidosis in adults (associated with cardiopulmonary bypass) is 324 mg/kg IV once

---

### Structural puzzles in virology solved with an overarching icosahedral design principle [^5f77ba37]. Nature Communications (2019). High credibility.

Methods

The construction of the polyhedral models and their duals is described below.

Construction of polyhedral designs

Consider two lines intersecting at an angle of 60° at the centre of one of the hexagons in the hexagonal (sub)lattice of a given Archimedean lattice. Counting steps between midpoints of adjacent hexagons along these lines via the integer coordinatesand, thencharacterises the positions of other hexagons in the (sub)lattice with respect to the original one, i.e. Using the line connecting the midpoints of these hexagons as the edge of an equilateral triangle of an icosahedral face (Supplementary Fig. 1), the position of the remainder of that surface is uniquely determined, andthus defines a planar embedding of an icosahedral surface into the Archimedean lattice (see examples in Fig. 2). The corresponding polyhedral shape in three dimensions is an icosahedron, obtained via identification of edges of the planar embedding. The numbers of pentagonal, hexagonal, triangular and square faces in the Archimedean lattice overlapping with this icosahedral surface for different values ofandare provided in Supplementary Tables 1–4 for the hexagonal, trihexagonal, snub hexagonal and rhombitrihexagonal lattice, respectively. In particular, an icosahedral face given bycontains either no additional face (hexagonal case), one triangle (trihexagonal case), four triangles (snub hexagonal case), or one triangle and a square (rhombitrihexagonal case), that each form the start of an infinite series of polyhedra.

Construction of the dual lattices

For each polyhedron in the above classification, we construct a dual polyhedron. For this, vertices are positioned at the centres of the polyhedral faces, and vertices associated with adjacent faces connected by straight lines. Since Archimedean lattices have a single type of vertex environment, these dual polyhedra each have a single type of face that corresponds to the fundamental domain of a Laves lattice. These faces are triangles, rhombs, florets and kites for the hexagonal, trihexagonal, snub hexagonal and rhombitrihexagonal lattice, respectively. Using again the planar embedding of an icosahedral surface into the associated Archimedean lattice, we determine the numbers of each such face for polyhedra characterised byandas above; their numbers are listed in Supplementary Table 5.

---

### Solving olympiad geometry without human demonstrations [^7e6cfc29]. Nature (2024). Excellent credibility.

Proving mathematical theorems at the olympiad level represents a notable milestone in human-level automated reasoning –, owing to their reputed difficulty among the world's best talents in pre-university mathematics. Current machine-learning approaches, however, are not applicable to most mathematical domains owing to the high cost of translating human proofs into machine-verifiable format. The problem is even worse for geometry because of its unique translation challenges, resulting in severe scarcity of training data. We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems and proofs across different levels of complexity. AlphaGeometry is a neuro-symbolic system that uses a neural language model, trained from scratch on our large-scale synthetic data, to guide a symbolic deduction engine through infinite branching points in challenging problems. On a test set of 30 latest olympiad-level problems, AlphaGeometry solves 25, outperforming the previous best method that only solves ten problems and approaching the performance of an average International Mathematical Olympiad (IMO) gold medallist. Notably, AlphaGeometry produces human-readable proofs, solves all geometry problems in the IMO 2000 and 2015 under human expert evaluation and discovers a generalized version of a translated IMO theorem in 2004.

---

### Solving olympiad geometry without human demonstrations [^ec72812b]. Nature (2024). Excellent credibility.

Main

Proving theorems showcases the mastery of logical reasoning and the ability to search through an infinitely large space of actions towards a target, signifying a remarkable problem-solving skill. Since the 1950s (refs.), the pursuit of better theorem-proving capabilities has been a constant focus of artificial intelligence (AI) research. Mathematical olympiads are the most reputed theorem-proving competitions in the world, with a similarly long history dating back to 1959, playing an instrumental role in identifying exceptional talents in problem solving. Matching top human performances at the olympiad level has become a notable milestone of AI research –.

Theorem proving is difficult for learning-based methods because training data of human proofs translated into machine-verifiable languages are scarce in most mathematical domains. Geometry stands out among other olympiad domains because it has very few proof examples in general-purpose mathematical languages such as Leanowing to translation difficulties unique to geometry. Geometry-specific languages, on the other hand, are narrowly defined and thus unable to express many human proofs that use tools beyond the scope of geometry, such as complex numbers (Extended Data Figs. 3 and 4). Overall, this creates a data bottleneck, causing geometry to lag behind in recent progress that uses human demonstrations –. Current approaches to geometry, therefore, still primarily rely on symbolic methods and human-designed, hard-coded search heuristics –.

---

### VA / DoD clinical practice guideline for the primary care management of asthma [^739415b7]. DoD/VA (2025). High credibility.

VA/DoD Clinical Practice Guideline for the Primary Care Management of Asthma — algorithm legend and scope: This clinical practice guideline (CPG) algorithm is designed to facilitate understanding of the clinical pathway and decision-making process used in the primary care management of asthma and represents a simplified flow that helps foster efficient decision making; it includes an ordered sequence of steps of care, recommended observations and examinations, decisions to be considered, and actions to be taken. The algorithm is a step-by-step decision tree in which standardized symbols are used to display each step and arrows connect the numbered boxes indicating the order in which the steps should be followed; Sidebars A-J provide more detailed information to assist in defining and interpreting elements in the boxes. Symbol meanings are defined as: rounded rectangles represent a clinical state or condition, hexagons represent a decision point in the guideline formulated as a question that can be answered "Yes" or "No", rectangles represent an action in the process of care, and ovals represent a link to another section within the algorithm.

---

### Sagittal cephalometric evaluation without point nasion: sagittal G-triangle analysis [^130cca70]. The Journal of Craniofacial Surgery (2021). Medium credibility.

After several years of research, our team invented a novel cephalometric analysis using an equilateral triangle as a reference. Constructed on the geometric relationship of the cranial landmarks, this triangle was named the G-triangle. The sagittal, vertical, dental, and soft-tissue cephalometric measurements based on the G-triangle form the G-triangle analysis. Because the G-triangle is independent of nasion, its sagittal evaluation could serve as an alternative evaluation for the previously established sagittal cephalometric parameters. In this paper, with a focus on the sagittal evaluation, we aim to introduce sagittal G-triangle analysis to determine its correlation between the most widely used sagittal cephalometric parameters (SNA and SNB) and to identify its normal ranges using statistic calculation. The results of our study suggested that the sagittal G-triangle analysis, which served as the guide line for the ideal position of the maxilla and mandible, offers an immense help in the treatment planning of maxillofacial surgery.

---

### Microfluidic multipoles theory and applications [^31dd0050]. Nature Communications (2019). High credibility.

Upon inspection, the problem can be transformed to streamline coordinates (Fig. 2a) using the function

In the streamline domain Φ, the problem is equivalent to a channel geometry with flows of concentration c = 1 and c = 0 separated by a no-flux boundary condition on the origin. At the stagnation point, the no-flux condition is dropped, and the flows are free to mix (Fig. 2a) (see Supplementary Table 2 for more details on the streamline problem). The separating streamline going from the stagnation point to the aspiration aperture corresponds to the semi-infinite segment of the horizontal axis where the fluids can mix. If the Péclet number is high enough (higher than about 10, which is always realized in microfluidics applications), this segment can be taken to have concentration c = [1/2] and the walls of the channel geometry can be safely ignored (Supplementary Note 1). The problem can thus be decomposed in two problems of advection-diffusion around semi-infinite obstacles of fixed concentration. The problem of advection-diffusion around such a semi-infinite obstacle has been extensively studied in theoretical fluid mechanics, notably in the theory of dendrite solidification, and in the study of out of plane flow in Burgers vortex sheets. It yields the solutionwhere Φ stag is the image of the stagnation point and erf(x) is the error function. The sign of ± is determined by whether we have an incoming flow of concentration c = 0 or c = 1. However, neither of these concentration profiles represent the full dipole footprint when transformed. This can be seen physically in the flow dipole, in which there is both incoming fluid at concentration 0 (aspirated from the system's surroundings), and incoming fluid at concentration 1 (injected by the aperture). To solve this issue, we separate the problem into an "interior" and an "exterior" domain at the streamline of concentration c = 1/2 (see checkerboard insets in Fig. 2). There remains a discontinuity in our solution due to the branch cut of the logarithm functions in Eq. (1), but the solution can be made continuous by placing the singularities on the real axis and using it as an axis of symmetry. The final step is then to obtain the entire solution as a piecewise function assembling the "interior" and "exterior" solutions, given by transforming Eq. (6) back to the dipole flow domain Z. The interior and exterior domains can be defined either by checking the sign of Φ in the streamline domain or by using the expression for the separating line in the Z domain in polar coordinates (see Supplementary Note 2).