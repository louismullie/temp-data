# Medical Question & Answer

**Sample ID**: 057494c5-eb99-c84a-d73a-c589d83ad2bc
**Dataset Index**: 347445

---

## Question

While designing a high-resolution transmission electron microscope operating at an accelerating voltage of 1000 kV, Mike connected vacuum pumps to create an ultra-high vacuum state (< 10^-9 Torr) in the sample compartment, aiming to minimize the presence of gas molecules for improved electron microscopy. However, as expected, some gas particles remained inside the compartment, as detected by the mass spectrometer. Mike accurately determined the mean free path of these gas molecules in the vacuum state (< 10^-9 Torr) to be Î»1, based on factors such as sample compartment volume, pressure, and temperature. However, upon initiating the electron beam, he made an intriguing observation concerning the mean free path based on electron scattering with the gas molecules. He found that the mean free path was no longer equal to Î»1; rather, it was Î»2, even though the sample compartment temperature remained the same.

What can we conclude about Î»2 based on the aforementioned scenario?

Answer Choices:
A. Î»2 < Î»1
B. Î»2 >= 1.22*Î»1
C. Î»1 < Î»2 < 1.22*Î»1
D. Î»2 = Î»1, indicating a discrepancy in Mike's observation

---

## Answer

> Let's seeâ€¦ What do we have here? The user is asking how the electronâ€“gas mean free path (Î»2) compares with the gasâ€“gas mean free path (Î»1) in an ultra-high vacuum TEM column at 1000 kV, and which option correctly characterizes their relationship. Let's break this down step-by-step. First, I need to think about what Î»1 actually represents and how it scales with pressure and temperature. Then, I should verify what Î»2 represents and why it differs from Î»1. Next, I will compare the cross-sections for electronâ€“atom scattering versus atomâ€“atom collisions. After that, I should estimate the magnitude of the ratio Î»2/Î»1 using physical arguments and known trends. Finally, I will match the result to the provided options and double-check for any pitfalls in the reasoning.

> Let me first confirm the definitions. Î»1 is the gasâ€“gas mean free path, which depends on the number density of gas molecules and the collision cross-section between neutral gas molecules; at a given temperature, Î»1 is inversely proportional to pressure, so at< 10^-9 Torr, Î»1 is very long, on the order of kilometers, which is why ultra-high vacuum is used to minimize gas scattering in TEM [^notfound]. Wait, let me verify that scale: yes, for air at room temperature, Î»1 is roughly 1 km at 10^-9 Torr, so the exact value is large but the key point is that Î»1 is determined by neutralâ€“neutral collisions and scales inversely with pressure.

> Now, Î»2 is the electronâ€“gas mean free path, which depends on the electron scattering cross-section with gas atoms or molecules and the gas number density. Importantly, Î»2 is not the same as Î»1 because the interaction cross-sections are fundamentally different: electrons interact via Coulomb and inelastic scattering processes that are not governed by the same hard-sphere or Lennard-Jones potentials that determine neutralâ€“neutral collisions [^notfound]. Hold on, I should verify that the question is indeed asking about electronâ€“gas scattering rather than gasâ€“gas scattering; yes, the prompt explicitly says "mean free path based on electron scattering with the gas molecules", so Î»2 reflects electronâ€“gas interactions, not gasâ€“gas collisions.

> Next, I should review the comparative cross-sections. Electron scattering cross-sections with atoms are generally much larger than neutralâ€“neutral collision cross-sections at typical TEM energies, especially for inelastic and elastic scattering that deflect electrons and degrade coherence. This is precisely why even trace gas in the column can cause measurable beam broadening and signal loss, despite the very long gasâ€“gas mean free path [^notfound]. I need to ensure I'm not overstating this; let me reconsider: while exact cross-sections vary by gas species and electron energy, the qualitative point that electronâ€“atom cross-sections exceed neutralâ€“neutral cross-sections holds and explains why Î»2 is shorter than Î»1 at the same pressure and temperature.

> I will now examine the magnitude of the effect. Because electronâ€“gas scattering cross-sections are larger, the electronâ€“gas mean free path Î»2 must be shorter than the gasâ€“gas mean free path Î»1 at the same pressure and temperature. I should double-check whether any of the options allow Î»2 to be equal to or greater than Î»1; options B and C posit Î»2â‰¥ 1.22 Î»1 or Î»2> Î»1, which would contradict the physical expectation that stronger scattering leads to a shorter mean free path. Therefore, the correct conclusion is Î»2< Î»1, which corresponds to option A [^notfound].

> But wait, what if the factor of 1.22 in option B is meant to reflect some relativistic correction or geometric factor? Hold on, let's not jump to conclusions: 1.22 is the familiar Rayleigh criterion factor for angular resolution, which is unrelated to mean free path physics, so using it to bound Î»2/Î»1 would be a category error. I should confirm that no credible physical argument supports Î»2 being greater than Î»1 in this context; none does, and the directionality of the effect is unambiguous: more effective scattering means a shorter mean free path for electrons in gas.

> Final answer: Î»2< Î»1, because electronâ€“gas scattering cross-sections are larger than gasâ€“gas collision cross-sections, so the electron mean free path is shorter than the neutral gas mean free path at the same pressure and temperature. Therefore, the correct choice is A [^notfound].

---

The correct answer is **A. Î»2< Î»1**. The electron mean free path (Î»2) is shorter than the gas molecule mean free path (Î»1) because electrons interact more strongly with gas molecules than molecules interact with each other, due to the electron's small size and high kinetic energy at 1000 kV. This stronger interaction increases the effective scattering cross-section, reducing the mean free path for electrons compared to neutral gas molecules at the same pressure and temperature.

---

## Mean free path: fundamental concepts

The mean free path (Î») is the **average distance a particle travels between collisions** with other particles. It depends on the number density of particles (n) and the collision cross-section (Ïƒ) according to the formula:

Î» = 1 / (nÏƒ)

In this scenario, Î»1 represents the mean free path of gas molecules in the vacuum chamber, while Î»2 represents the mean free path of electrons interacting with these gas molecules.

---

## Mean free path of gas molecules (Î»1)

For gas molecules, the mean free path Î»1 is determined by the **number density of gas molecules** and the collision cross-section between gas molecules. At ultra-high vacuum (< 10^-9 Torr), the number density of gas molecules is extremely low, resulting in a very long mean free path. For example, at 10^-9 Torr and room temperature, the mean free path of air molecules is approximately 1.3 km. This long mean free path is why ultra-high vacuum is essential in electron microscopy, as it minimizes unwanted collisions between gas molecules and the electron beam.

---

## Mean free path of electrons (Î»2)

When the electron beam is initiated, electrons travel through the vacuum chamber and interact with residual gas molecules. The mean free path of electrons (Î»2) is determined by the **number density of gas molecules** and the electronâ€“molecule collision cross-section. Electrons, being much smaller than gas molecules and having high kinetic energy at 1000 kV, interact differently with gas molecules compared to gas molecules interacting with each other.

---

## Comparison of Î»1 and Î»2

The key difference between Î»1 and Î»2 lies in the **collision cross-sections**. The electronâ€“molecule collision cross-section is significantly larger than the moleculeâ€“molecule collision cross-section. This is because electrons can penetrate the electron cloud of gas molecules, leading to strong electromagnetic interactions, including elastic scattering, inelastic scattering, and ionization. These interactions increase the effective collision cross-section for electrons, thereby reducing their mean free path compared to gas molecules.

---

## Quantitative analysis

Although exact calculations would require detailed knowledge of the specific gas composition and electronâ€“molecule collision cross-sections, general principles allow a qualitative comparison. At 1000 kV, electrons have very high kinetic energy, which increases their interaction probability with gas molecules. Consequently, the **electron mean free path (Î»2) is significantly shorter than the gas molecule mean free path (Î»1)** at the same pressure and temperature.

---

## Conclusion

Based on the above analysis, the correct answer is **A. Î»2< Î»1**. The mean free path of electrons (Î»2) is shorter than the mean free path of gas molecules (Î»1) because electrons interact more strongly with gas molecules due to their small size and high kinetic energy, resulting in a larger effective collision cross-section and a shorter mean free path.

---

## References

### Multiple proteins differing between laboratory stocks of mammalian orthoreoviruses affect both virus sensitivity to interferon and induction of interferon production during infection [^10eefb0b]. Virus Research (2018). Low credibility.

In the course of previous works, it was observed that the virus laboratory stock (T3D S ) differs in sequence from the virus encoded by the ten plasmids currently in use in many laboratories (T3D K ), and derived from a different original virus stock. Seven proteins are affected by these sequence differences. In the present study, replication of T3D K was shown to be more sensitive to the antiviral effect of interferon. Infection by the T3D K virus was also shown to induce the production of higher amount of Î² and Î±-interferons compared to T3D S . Two proteins, the Î¼2 and Î»2 proteins, were found to be responsible for increased sensitivity to interferon while both Î¼2 and Î»1 are responsible for increased interferon secretion. Altogether this supports the idea that multiple reovirus proteins are involved in the control of induction of interferon and virus sensitivity to the interferon-induced response. While interrelated, interferon induction and sensitivity can be separated by defined gene combinations. While both Î¼2 and Î»2 were previously suspected of a role in the control of the interferon response, other proteins are also likely involved, as first shown here for Î»1. This also further stresses that due caution should be exerted when comparing different virus isolates with different genetic background.

---

### Ageing and brain white matter structure in 3, 513 UK biobank participants [^f8688494]. Nature Communications (2016). Medium credibility.

Diffusion MRI processing and tractography

FA and MD are commonly derived variables, which describe the directional coherence and magnitude of water molecule diffusion, respectively. Water molecules tend to diffuse with greater directional coherence and lower magnitude when constrained by tightly packed fibres (such as well-myelinated axons) and by cell membranes, microtubules and other structures. Thus, individual differences in FA and MD in brain white matter reflect meaningful differences in underlying microstructure, borne out by comparison with brain white matter post-mortem work. Measures of tract-averaged Î»ax and Î»rad and MO were also available as IDPs from UK Biobank. The former two measures are also parameters of interest to brain ageing (for example, refs,) but are similar in their derivation from the three main tensor eigenvalues: MD is the mean of all three, whereas Î»ax=Î»1 and Î»rad is the mean of Î»2 and Î»3). MO (also known as the mode of anisotropy) describes the third moment of the tensor (a positive value denotes narrow tubular water diffusion, whereas a negative number denotes planar water diffusion), although little work has been done to examine MO in relation to ageing. Consequently, we also provide parallel analyses of Î»ax, Î»rad and MO in Supplementary Material.

---

### The role of macrophage IL-10 / innate IFN interplay during virus-induced asthma [^6dd591a8]. Reviews in Medical Virology (2015). Low credibility.

Type III IFNs (IFN-Î»1/2/3 also referred to as IL-29/IL-28A/IL-28B) are related to both type I IFNs and IL-10 and have antiviral activity and signal through a hetero-dimeric receptor composed of IFN-Î»R1/IL-28RÎ± and IL-10RÎ²/IL-10R2 chains. IL-29/IFN-Î»1 initially binds to signaling receptor IFN-Î»R1/IL-28RÎ± and causes a conformational change that subsequently allows the IL-10RÎ²/IL-10R2 receptor to bind to IL-29/IFN-Î»1. The receptor complex is activated and induces IFN-stimulated genes, which inhibits viral replication by interfering with viral RNA transcription and protein translation, but also has immunostimulatory and antiproliferative effects. The IFN-Î»1/IL-29 gene is regulated by virus-activated IRF-3 and NF-ÎºB, resembling that of the IFN-Î² gene, whereas IFN-Î»2 and/or IFN-Î»3 gene expression is mainly controlled by the IFN-stimulated gene IRF-7, resembling regulation of IFN-Î± genes and suggesting that IFN-Î»2/IFN-Î»3 could be expressed without IFN-Î»1.

The precise interactions between type I and type III IFNs have not been well defined. It has been reported that IFN-Î± amplifies the induction of IFN-Î» expression by influenza or Sendai virus partially by upregulating TLR and IRF-7 gene expression. However, recent studies have shown that the IFN-Î± and IFN-Î» ligandâ€“receptor systems can be activated independently in response to certain viruses and that type I IFN receptor IFNRA signaling is not essential for IFN-Î» production in epithelial cells.

It was suggested that IFN-Î» expression is more flexible than IFN-Î±/Î² expression, which could allow expression of type III IFNs in response to a wider range of stimuli compared with type I IFNs and will potentially make the expression of type III IFNs less sensitive to microbial evasion strategies targeting the IRF pathway. In the absence of IRF-3 activation and IFN-Î² production, alternative pathways allow IFN-Î» induction in the absence of IRF-3 activation.

---

### Molecular sociology of virus-induced cellular condensates supporting reovirus assembly and replication [^34179660]. Nature Communications (2024). High credibility.

Fig. 5 
Conformational change of the turret protein Î»2 during assembly.

a CryoEM map and the atomic model of MRV core from sub-particle reconstruction showing the turret is open with a central channel circled by dashed lines. The inner shell protein Î»1 is represented as shadow and Ïƒ2 is omitted from the model for clarity. b CryoEM map and the atomic model of MRV virion from sub-particle reconstruction showing the turret is closed. The spike protein Ïƒ1, not built in the model, is indicated as a red dot at the fivefold axis. c Domain organization of Î»2. Structure superposition of core and virion showing the conformational change of Î»2 during virus assembly. The inner shell protein Î»1 is omitted. Î»2 pentamers are shown in (d) and one of the five subunits in orthogonal view is shown in (e). Movements of the Ig-like domain of Î»2 from core to virion are indicated by arrows.

---

### Resection of cerebellar tumours causes widespread and functionally relevant white matter impairments [^c5464a44]. Human Brain Mapping (2021). Medium credibility.

FA and MD are summary metrics which provide a general and useful measure of maturation and integrity of whiteâ€matter, but they do not allow to discriminate between axonal or myelin pathology. Specifically, MD represents the average of parallel (Î»1, AD) and perpendicular (Î»2, Î»3, RD) diffusivity to the principal axis of the fibres. Animal studies show negative correlations between RD and myelination, whereas decreases in AD are often concomitant with axonal damage (Song et al. 2005, Song et al. 2003, 2002). In our study, the contrast between patients and controls revealed changes not only in FA/MD but also in RD, suggesting that cerebellar lesions relate to myelin disintegration across many of the extracerebellar tracts. Gradual loss of whiteâ€matter integrity, particularly demyelination, in supratentorial tracts may be related to the process of anterograde transsynaptic degeneration (Dinkin, 2017 ; Triarhou, Norton, & Ghetti, 1987). Here, following interruption of the anatomical pathway due to axonal damage of a cell, neuronal degeneration may spread to distant neurons that serve the same function as the injured neuron. Aberrant electrical and/or chemical activity arising from the site of injury can cause damage to distal brain areas functionally connected to the damaged brain region (a phenomenon known as diaschisis). This relates to the principle that, being integrated into a functional network, neurons need to receive trophic signals from other functionallyâ€related neurons in order to be sustained. If inflammation occurs as the result of this process, it may trigger abnormal activation of astrocytes, which further degenerate mature oligodendrocytesâ€”the type of glia cells responsible for supporting myelination (Nave & Werner, 2014 ; Sofroniew, 2005). Indeed, studies involving patients with hippocampal sclerosis, for example, have found that atrophy in distant areas of the primary injury site was increased in several regions of the Papez circuit after surgery, which likely indicated interrupted efferent axonal activity due to the surgical intervention (Kim, Tien, Felsberg, Osumi, & Lee, 1995 ; Kodama et al. 2003).

---

### Microstructure assessment of the thalamus in Wilson's disease using diffusion tensor imaging [^8d80a060]. Clinical Radiology (2014). Low credibility.

Aim

To assess diffusion changes of the thalamus in Wilson's disease using diffusion tensor imaging (DTI).

Materials and Methods

Fifteen patients with Wilson's disease and an abnormal signal in the thalamus (designated as group 1) and 18 patients with Wilson's disease with a normal-appearing thalamus (designated as group 2) at conventional magnetic resonance imaging (MRI) were recruited. Fifteen age-matched and sex-matched healthy volunteers were also enrolled as the control group (designated as group 3). The fractional anisotropy (FA), primary eigenvalue (Î»1), second eigenvalue (Î»2), and third eigenvalue (Î»3) of the thalamus were measured and the differences were compared.

Results

The FA values of the thalamus were different in the three groups (group 1: 0.36 Â± 0.02; group 2: 0.38 Â± 0.02; group 3: 0.43 Â± 0.02; F = 54.51, p < 0.001). A statistically significant difference was observed between group 1 and group 2 (p = 0.003), group 1 and group 3 (p = 0.001), and group 2 and group 3 (p < 0.001). The Î»1, Î»2, and Î»3 values of the thalamus were different in the three groups (1.11 Â± 0.06 mm(2)/s, 1.11 Â± 0.06 mm(2)/s, and 1.10 Â± 0.04 mm(2)/s of Î»1 in group 1, group 2, and group 3, respectively; 0.82 Â± 0.08 mm(2)/s, 0.78 Â± 0.05 mm(2)/s, and 0.72 Â± 0.02 mm(2)/s of Î»2 in group 1, group 2, and group 3, respectively; 0.52 Â± 0.05 mm(2)/s, 0.49 Â± 0.06 mm(2)/s, and 0.42 Â± 0.06 mm(2)/s of Î»3 in group 1, group 2, and group 3, respectively; F = 1.65, p = 0.203 of Î»1; F = 10.55, p < 0.001 of Î»2; F = 4.21, p = 0.021 of Î»3; respectively). A statistically significant difference in the Î»2 value was observed between group 1 and group 3 (p < 0.001) and group 2 and group 3 (p = 0.005). A statistically significant difference in the Î»3 value was also observed between group 1 and group 3 (p = 0.007). No significant difference in the Î»1 value was noted between each of the two groups.

Conclusions

Damage of the thalamus in Wilson's disease patients can be detected using DTI. DTI may provide information regarding thalamus damage in patients with Wilson's disease before abnormal signals on conventional MRI.

---

### Altered fornix integrity is associated with sleep apnea-related hypoxemia in mild cognitive impairment [^edcda7f8]. Alzheimer's & Dementia (2024). Medium credibility.

TABLE 3 
Hierarchical regression analyses with cognitive status and PCA_hypoxemia predicting left fornix microstructure.

FIGURE 2 
Associations between OSAâ€related hypoxemia and left fornix microstructure. (Aâ€“E) Scatter plots showing the associations between PCA_hypoxemia and FWâ€DTI measures of the left fornix. The yâ€axis shows the predicted values from the regression analyses adjusted for age (continuous), sex (men vs. women), body mass index (continuous), Epworth Sleepiness Scale (continuous), Vascular Burden Index (<2Â vs. â‰¥2 points), left fornix volume (divided by total intracranial volume; continuous), and cognitive status (CU vs. MCI). The solid line is the regression line and the gray area represents the 95% confidence interval. (F) Changes in the diffusion ellipsoid shape of the tissue compartment (gray ellipsoid) and the extracellular/FW compartment (blue sphere) associated with higher levels of hypoxemia in participants with MCI. Our results indicate that hypoxemia is associated with an increase in the three diffusivities (MD T, AxD T, and RD T), a constant FA T (which is consistent with a proportional increase in Î»1, Î»2, and Î»3), and a constant FW index (which is consistent with a proportional increase in the tissue compartment and the FW/extracellular comportment). Note that the changes in the shape of the diffusion ellipsoid are shown here for illustrative and conceptual purposes (i.e. these changes are conceptually consistent with our results, but the magnitudes of the changes are not scaled or calculated based on our data). * p <Â 0.01. AxD T, tissue axial diffusivity; CU, cognitively unimpaired; DTI, diffusion tensor imaging; FW, free water; MCI, mild cognitive impairment; MD T, tissue mean diffusivity; OSA, obstructive sleep apnea; PCA, principal component analysis; RD T, tissue radial diffusivity; Î», eigenvalue.

---

### A pathway linking reward circuitry, impulsive sensation-seeking and risky decision-making in young adults: identifying neural markers for new interventions [^02b8f79e]. Translational Psychiatry (2017). Low credibility.

Second level neuroimaging data analyses testing hypotheses

H1: uncertain RE-related neural activity and ISS

Due to the number of correlated predictors, we employed elastic net regression (â€˜lasso' function implemented in MATLAB; see Supplementary Information) to identify the relationship between ISS component trait measures and RE-related bilateral VS and left vlPFC activity in the ROIs described above. Elastic net is a modified form of least squares regression that penalizes complex models with regularization parameters (Î»1, Î»2), and is sensitive to correlated variables.The regularization (lasso/ridge regression) parameters shrink coefficients toward zero, and eliminate unimportant terms entirely. Cross validation identifies the optimal penalty terms that minimizes mean cross validated error, reduce the chances of overfitting and enforces recommended sparsity in the solution.Elastic net regression models thereby allow inclusion of a relatively large number of correlated independent variables in regression models. The main independent variables were all ISS component traits, including all impulsivity and sensation-seeking subcomponent measures (Table 1). This regression model also included the following covariates: state anxiety; depression severity (HAMD); anhedonia; group (distressed, healthy); demographic variables (age, gender and years of education); and motion (framewise displacement). Mania was not included as a covariate as only one participant scored >10 on the YMRS. Dependent variables were extracted BOLD signal from left vlPFC and bilateral VS during uncertain RE. Three separate elastic net models were run, one for each of these three ROI activity-dependent variables.

---

### Bile acids drive the newborn's gut microbiota maturation [^6efaa9c8]. Nature Communications (2020). High credibility.

The contribution of each metabolite to metabolomic variation was derived from age-constrained redundancy analysis (RDA) based on all metabolites stratified in group levels with additional scaling by normalization based on z-scores (Phyloseq package). Moreover, PCA was used to illustrate changes in the composition of the different metabolic groups during the postnatal period for both PC1 and PC2, and PC2 and PC3. For the bile acids the 2nd and 3rd component were chosen for plotting, since the first component was mainly driven by the strong separation observed between the first and subsequent time points (PND1 vs. PND7â€“56).

Multi-omics analyses

Regularized canonical correlation analyses (rCCA) were performed (Mixomics package 6.10.8)to unravel specific correlations between bile acids and OTUs with a minimal presence of 20% in all samples. Samples were excluded from the microbiota-data if they were not measured in the bile acid analyses (i.e. PND1 of litter 1 and 2). Prior to rCCA a hyperbolic sine transformation was used on OTU-counts and a log-transformation for the bile acids. For the estimation of regularization (penalization) parameters Î»1 and Î»2, the cross-validation procedure (CV) method was used. We used a Î»1â€‰=â€‰0.0001, Î»2â€‰=â€‰1 with a CV-scoreâ€‰=â€‰0.4779644 and 2 components. OTUs with a correlation between âˆ’0.3 and 0.3 on the first 2 components were filtered out to optimize the rCCA.

The Spearmanâ€™s rank correlation coefficient was calculated between bile acids (weight corrected) and bacterial genera (relative abundances) with a minimal presence of 20% in all samples. Benjamini and Hochberg FDR correction was performed to correct for multiple testing (p >â€‰0.05). For the heatmap only significant correlations with adjusted p -value of <0.05 are shown and sorted according to their PCA loading scores.

---

### Product lambda-doublet ratios as an imprint of chemical reaction mechanism [^ea627e5c]. Nature Communications (2016). Medium credibility.

In the last decade, the development of theoretical methods has allowed chemists to reproduce and explain almost all of the experimental data associated with elementary atom plus diatom collisions. However, there are still a few examples where theory cannot account yet for experimental results. This is the case for the preferential population of one of the Î›-doublet states produced by chemical reactions. In particular, recent measurements of the OD( 2 Î ) product of the O( 3 P)+D 2 reaction have shown a clear preference for the Î (A') Î›-doublet states, in apparent contradiction with ab initio calculations, which predict a larger reactivity on the A'' potential energy surface. Here we present a method to calculate the Î›-doublet ratio when concurrent potential energy surfaces participate in the reaction. It accounts for the experimental Î›-doublet populations via explicit consideration of the stereodynamics of the process. Furthermore, our results demonstrate that the propensity of the Î (A') state is a consequence of the different mechanisms of the reaction on the two concurrent potential energy surfaces.

---

### AMPK is a mechano-metabolic sensor linking cell adhesion and mitochondrial dynamics to myosin-dependent cell migration [^18e0a2a9]. Nature Communications (2023). High credibility.

Cell traction stress computation

In order to calculate stress from strains, the stiffness of the bovine collagen matrix was calculated using AFM microscopy. Stiffness of bovine collagen was ~19â€‰Pa, comparable to the stiffness observed in other studies,. We assume the material is purely elastic, continuous, homogeneous and isotropic. Stresses were calculated by integrating the strain data, depth information and stiffness of the matrix, using a direct Traction Force Microscopy (TFM) method, as opposed to more complicated and computationally extensive methods involving the solution of inverse equations and boundary conditions. The mathematical approach was based on that used by, following the assumption of a linearly isotropic material or substrate. According to this assumption, the Cauchy relation for traction stress, Ï„, is:where Î´ is the Cauchy stress tensor and n the direction of the normal vector.

The code was designed to process each of the aforementioned 512 variables, setting the X, Y and Z strain values as the principal strains (diagonal elements) of a 3D symmetric strain tensor Îµ, defined as:

Eq. (3) below was solved in order to obtain the shear modulus Î¼, which was then input into Eq. (4), to obtain the stress tensor Î´, for which isotropic linearly elastic properties are assumed. The constitutive mechanical properties required for these calculations included a Youngâ€™s modulus Î• of 28â€‰Pa, measured for our collagen matrix, and a Poisson ratio v of 0.25 based on that measured by Steinwachs et al. (2016).

The eigen Eq. (5) was then solved for the three eigenvalues (Î»1, Î»2, Î»3) and eigenvectors (V 1, V 2, V 3) of this stress tensor. The eigenvalues correspond to the traction stress solutions of the stress tensor Î´, whilst the eigenvectors correspond to the direction of the normal n, relative to the surface on which the traction stress is acting.where Î• represents the set of vectors which satisfy V =0.

---

### Comparative analysis of the antiviral effects mediated by type I and III interferons in hepatitis B virus-infected hepatocytes [^4692067b]. The Journal of Infectious Diseases (2019). Medium credibility.

Background

Type III interferons (IFNs) (Î»1-3) activate similar signaling cascades as type I IFNs (Î± and Î²) via different receptors. Since IFN-Î± and lymphotoxin-Î² activate cytosine deamination and subsequent purging of nuclear hepatitis B virus (HBV) DNA, we investigated whether IFN-Î² and -Î» may also induce these antiviral effects in differentiated HBV-infected hepatocytes.

Methods

After determining the biological activity of IFN-Î±2, -Î²1, -Î»1, and -Î»2 in differentiated hepatocytes, their antiviral effects were analyzed in HBV-infected primary human hepatocytes and HepaRG cells.

Results

Type I and III IFNs reduced nuclear open-circle DNA and covalently closed circular DNA (cccDNA) levels in HBV-infected cells. IFN-Î² and -Î» were at least as efficient as IFN-Î±. Differential DNA-denaturing polymerase chain reaction and sequencing analysis revealed G-to-A sequence alterations of HBV cccDNA in IFN-Î±, -Î², and -Î»-treated liver cells indicating deamination. All IFNs induced apolipoprotein B messenger RNA-editing enzyme-catalytic polypeptide-like (APOBEC) deaminases 3A and 3G within 24 hours of treatment, but IFN-Î² and -Î» induced longer-lasting expression of APOBEC deaminases in comparison to IFN-Î±.

Conclusions

IFN-Î², IFN-Î»1, and IFN-Î»2 induce cccDNA deamination and degradation at least as efficiently as IFN-Î±, indicating that these antiviral cytokines are interesting candidates for the design of new therapeutic strategies aiming at cccDNA reduction and HBV cure.

---

### Learning shapes cortical dynamics to enhance integration of relevant sensory input [^5f42e6ef]. Neuron (2023). Medium credibility.

Non-normal dynamics (Figure S1)

We derived expressions relating linear Fisher Information to the dynamics of an arbitrary normal or non-normal network (subject to the same approximations described above). These expressions had a simple and interpretable form in three special cases: two-dimensional networks, normal networks, and non-normal networks with strong functionally-feedforward dynamics. Related findings have been presented previously (;).

To illustrate our analytical findings for the two-dimensional case, we constructed networks with modes m 1 = [cos Î¸ 1 ; sin Î¸ 1], m 2 = [cos Î¸ 2 ; sin Î¸ 2]. Figure S1A was constructed using the same procedure as for Figure 2, but this time with Ï„ 1 = 10, Ï„ 2 = 5. For Figure S1B we chose input with isotropic covariance Î£ Î· = I 2 (where I N is the N x N identity matrix) and Î” g = g (s 2) - g (s 1) = [1; 0]. These inputs were chosen in order to demonstrate the influence of non-normality as clearly as possible. We set Ï„ 1 = 10, Ï„ 2 = 1,5,7.5,9 and varied Î¸ 1, Î¸ 2 from â€“ Ï€ /2 to Ï€ /2 for each value. For each network (defined by the parameters Î¸ 1, Î¸ 2, Ï„ 1, Ï„ 2 using the procedure described for Figure 2), the Fisher Information of the stationary state network responsewas computed by substituting the long-run solution for the mean Î” r = â€“ A â€“1 Î” g and the numerical solution to the Lyapunov equation for Î£ (described above). We normalized this linear Fisher Information by the maximum achievable SNR in any normal network with the same time constants by defining. For each network, we computed the information-limiting correlations as Ï ILC = Î” r T Î£Î” r /(Î” r T Î” r Trace(Î£)). For each choice of Ï„ 2, we computed the Pearson correlation between the Fisher information and the information-limiting correlations corr(ð“˜ F, Ï ILC), where the correlation was computed over a set of networks spanning the range of Î¸ 1, Î¸ 2 âˆˆ [- Ï€ /2, Ï€ /2). We computed this correlation for various settings of Î£ Î· = [v 1, v 2][Î» 1, 0; 0, Î» 2][v 1, v 2] T, by varying the angle of its principal eigenvector v 1 from Î” g and the ratio of its two eigenvalues Î» 2 / Î» 1 with Î» 1 = 1 and Î» 2 âˆˆ [0, 1].

---

### Genotype specific pathogenicity of hepatitis E virus at the human maternal-fetal interface [^b0cb938a]. Nature Communications (2018). Medium credibility.

HEV-1 replication impairs the type III interferon secretion

Innate sensing of invading pathogens has been clearly associated with the production of interferons (IFNs) that can impede the replication of a broad spectrum of viruses â€“. Nonetheless, at mid-gestation, the human placenta produces large amounts of type III IFNs even in the absence of threats. This constitutive release of IFNs correlated with expression of interferon-stimulated genes (ISGs) have been suggested as a persistent defense mechanism during the second trimester of pregnancy. In order to shed light on the mechanisms that underlie the discrepancies between HEV-1 and HEV-3 replication at the maternal-fetal interface, we assessed the secretion profiles of type I (IFN-Î±2 and -Î²), type II (IFN-Î³) and type III (IFN-Î»1, -Î»2/3) IFNs in tissue culture supernatants 2 days post infection (Fig. 5). Regardless of the infection, both the decidua and the placenta produced low levels of IFN-Î±2, IFN-Î² and IFN-Î³ (Fig. 5a, b). However, HEV-1 infection significantly impaired the production of IFN-Î»1 and IFN-Î»2/3 in the decidual, and IFN-Î»2/3 in the placental explants, while HEV-3 infection has no impact on type III IFN secretion (Fig. 5a, b). Correlation analyses demonstrated that the production of IFN-Î»1 and IFN-Î»2/3 is negatively correlated with HEV-1 load in the decidua (p â‰¤â€‰0.0087 by Spearmanâ€™s ranked correlation test, Fig. 5c), while correlation is observed only for IFN-Î»2/3 in the placental tissues (p =â€‰0.0096 by Spearmanâ€™s ranked correlation test, Fig. 5d).

---

### Diffusion tensor imaging combined with chemical shift-encoded sequence to quantify the adaptive changes of calf muscles in amateur marathoners [^878c4d1c]. European Journal of Radiology (2024). Medium credibility.

Purpose

Calf muscles play an important role in marathon race, and the incidence of injury is high in this process. This study prospectively quantified diffusion tensor metrics, muscle fat fraction (MFF) and cross-sectional area (CSA) of calf muscles induced by endurance exercise in amateur marathoners, and the potential mechanisms underlying the changes in these parameters were analyzed.

Method

In this prospective study, 35 marathoners (27 males, 8 females; mean age (standard deviation, SD), 38.92 (4.83) years) and 26 controls (18 males, 8 females; mean age (SD), 38.35 (6.75) years) underwent magnetic resonance imaging (MRI) from September 2022 to March 2023. The diffusion tensor eigenvalues (Î»1, Î»2, Î»3), radial diffusivity (RD), fractional anisotropy (FA), MFF and CSA of calf muscles were compared between marathoners and controls. A binary logistic regression model with gender correction was performed analyze the relationship between marathon exercise and DTI parameters, CSA and MFF of calf muscles.

Results

Interobserver agreement was good (ÎºÂ =Â 0.71). The results of binary logistic regression model with gender correction showed that the regression coefficients of FA values in anterior group of calf (AC), soleus (SOL), medial gastrocnemius (MG) and lateral gastrocnemius (LG) were negative, and the odds ratios (OR) were 0.33, 0.45, 0.35, 0.05, respectively (PÂ <Â 0.05). The OR of RD in SOL and Î»2 in external group of calf (EC) were relatively higher, 3.74 and 3.26, respectively (PÂ <Â 0.05). CSA was greater in SOL of marathoners, with an OR value of 1.00(PÂ <Â 0.05). The MFF in AC and LG was lower in marathoners and OR of two indexes were -0.69 and -0.59, respectively (PÂ <Â 0.05).

Conclusions

Diffusion tensor imaging (DTI) combined with chemical shift-encoded sequence can noninvasively detect and quantify the adaptive changes of calf muscle morphology, microstructure and tissue composition induced by long-term running training in amateur marathoners.

---

### Physical limits to sensing material properties [^c3e3f73f]. Nature Communications (2020). High credibility.

All materials respond heterogeneously at small scales, which limits what a sensor can learn. Although previous studies have characterized measurement noise arising from thermal fluctuations, the limits imposed by structural heterogeneity have remained unclear. In this paper, we find that the least fractional uncertainty with which a sensor can determine a material constant Î» 0 of an elastic medium is approximately [Formula: see text] for aÂ â‰«Â dÂ â‰«Â Î¾, [Formula: see text], and DÂ >Â 1, where a is the size of the sensor, d is its spatial resolution, Î¾ is the correlation length of fluctuations in Î» 0 , Î” Î» is the local variability of Î» 0 , and D is the dimension of the medium. Our results reveal how one can construct devices capable of sensing near these limits, e.g. for medical diagnostics. We use our theoretical framework to estimate the limits of mechanosensing in a biopolymer network, a sensory process involved in cellular behavior, medical diagnostics, and material fabrication.

---

### Enterovirus D68 vRNA induces type III IFN production via MDA5 [^13765ce6]. Virus Research (2024). Medium credibility.

3.3 EV-D68 vRNA stimulates IFN-Î» production

To investigate the mechanism of EV-D68-induced IFN-Î» production in respiratory epithelial cells, EV-D68 was used to infect Calu-3 cells at various M.O.Is. Observation of the expression of the 5â€²UTR confirmed EV-D68 infection, and the IFN-Î»1 and IFN-Î»2/3 transcript levels were increased in a dose-dependent manner (FigÂ 3 A). To investigate whether EV-D68 vRNA has the ability to stimulate the expression of IFN-Î», EV-D68 and UV-inactivated EV-D68 were used to infect Calu-3 cells, and our results indicated that the inactivated virions could not stimulate IFN-Î»1 and IFN-Î»2/3 expression (FigÂ 3 B). Furthermore, we extracted the EV-D68 genomic RNA and transfected it into Calu-3 cells. RD cell RNA was used as a transfection control. The RTâ€’qPCR results showed that both EV-D68 vRNA and RD cell RNA upregulated IFN-Î»1 and IFN-Î»2/3 expression. However, the induction of IFN-Î»1 and IFN-Î»2/3 by EV-D68 vRNA is significantly higher than RD cell RNA transfection (FigÂ 3 C). Our results demonstrated that the expression of IFN-Î» was stimulated by EV-D68 vRNA in Calu-3 cells.

---

### Effect of exogenous interferons on rhinovirus replication and airway inflammatory responses [^56134199]. Annals of Allergy, Asthma & Immunology (2013). Low credibility.

Background

Human rhinoviruses (HRVs) are the most common cause of asthma exacerbations. In airway epithelial cells, the primary site of HRV infection, decreased production of interferons (IFNs) may result in greater susceptibility to HRV and worsened symptoms. Thus, exogenous IFN could supplement the innate immune response and provide a treatment for virus-induced asthma exacerbations. Furthermore, the effects of exogenous IFN could be type specific in part because of the cellular distribution of type 1 and type 2 IFN receptors.

Objective

To investigate the effects of exogenous IFNs on HRV replication in bronchial epithelial cells.

Methods

Frozen stocks of primary human bronchial epithelial cells from healthy donors were cultured in monolayers; pretreated (24 hours) with 0.1-ng/mL, 1-ng/mL, or 10-ng/mL doses of IFN-Î±, -Î², -Î»1, or -Î»2; and infected with HRV-1A. Viral replication was quantified using real-time reverse transcription-polymerase chain reaction, and cytokine and chemokine secretion 24 hours after infection was measured by multiplex enzyme-linked immunosorbent assay.

Results

Compared with untreated samples, IFN-Î±, IFN-Î², IFN-Î»1, and IFN-Î»2 (0.1 ng/mL) significantly reduced HRV replication after high- (P < .02) and low-dose inoculation (P < .05). Similar effects were seen in 1-ng/mL and 10-ng/mL doses of IFN, where HRV replication was significantly decreased in both high- (P < .001) and low-dose inoculation (P < .001). Treatment with IFNs also enhanced HRV-induced IFN-Î³-induced protein 10 secretion (P < .001). Finally, treatment with either IFN-Î»1 or IFN-Î»2 significantly increased HRV-induced secretion of RANTES (regulated on activation, normal T-expressed, and presumably secreted) (P < .05) but not IL-1Î² or vascular endothelial growth factor.

Conclusion

These findings suggest that exogenous IFNs, IFN-Î»1 in particular, warrant further study as a potential therapy for virus-induced asthma exacerbations.

---

### Transient receptor potential V channels are essential for glucose sensing by aldolase and AMPK [^549d81c5]. Cell Metabolism (2019). Medium credibility.

This assay was also used for correcting background fluorescence of the Fura-2 indicator. Briefly, a series of solutions containing different concentrations of calcium ions were first prepared by diluting the CaEGTA stock solution at 37Â°C, pH 7.2, mimicking the inÂ vivo situation. The solution, along with 10Â Î¼M ionomycin, was then added to the Fura-2-loaded MEFs. Following the measurement of the F Î»1 and F Î»2 of Fura-2, cells were incubated for an additional 20Â min with 6Â mM MnCl 2 to quench the fluorescence of the indicator. The remaining fluorescence was considered as background fluorescence, which was subtracted from the total fluorescence, afterwards. The difference between the total fluorescence and the background fluorescence was considered as the actual cytosolic fluorescence. The corrected values of F Î»1 were increased proportionally to the increase of Ca 2+ concentrations in CaEGTA solutions, while the corrected values of F Î»2 were changed independent of Ca 2+ concentrations. The value of R min, was generated from the corrected F Î»1 /F Î»2 ratio at zero free Ca 2+, and R max from 27.96Â Î¼M (saturating) Ca 2+. Q value was determined by the ratio of F Î»2 at zero free Ca 2+, to F Î»2 at 27.96Â Î¼M free Ca 2+. A series values of log, generated from each solution, were then plotted with the log value of its free Ca 2+ concentration. After that, a straight line was yielded, and a linear regression equation: yÂ = 1.2956xÂ + 8.7237 (R 2 = 0.935), was generated. The log of K d was determined according to the x-intercept of this straight line. We determined that the K d for Fura-2 is 184.7872Â nM.

---

### Serum interferon levels associated with the disease activity in women with overt Graves' disease [^8493c885]. Cytokine (2021). Medium credibility.

Background

Inflammatory cytokines participate in immune reactions and the pathogenesis of autoimmunity. Herein, we quantified four groups of inflammatory cytokines, including interferons (IFNs), the tumor necrosis factor (TNF) superfamily (TNFSF), interleukin (IL)-related cytokines, and bone and extracellular matrix remodeling-related cytokines to determine their contributions in women with overt Graves' disease (GD).

Methods

Forty-three women with GD were enrolled in this cross-sectional study. Thirty-seven cytokines, thyroid-stimulating hormone (TSH), free thyroxine, and TSH receptor antibody (TSHRAb) were quantified. GD patients with a low TSH level at the time of sample collection were defined as having active GD.

Results

Patients with active GD had higher IFN-Î±2, IFN-Î³, IFN-Î»1, and IFN-Î»2 levels than those with inactive GD. In addition, certain TNFSF cytokines, including soluble cluster of differentiation 30 (sCD30), TNFSF member 14 (TNFSF14), pentraxin (PTX)-3, soluble TNF receptor 2 (sTNF-R2), and thymic stromal lymphopoietin (TSLP) were higher in active GD than in inactive GD. Moreover, active GD patients had higher IL-2, IL-12(p40), osteocalcin (OCN), and matrix metalloproteinase (MMP)-3 than inactive GD patients. All IFNs except IFN-Î»1 were correlated with TSHRAb titers. Moreover, TNFSF cytokines, consisting of B-cell-activating factor, sCD30, TNFSF14, PTX-3, sTNF-R2, and TSLP, were associated with TSHRAb levels.

Conclusions

Serum IFNs could be the most remarkable cytokines in modulating the disease severity and TSHRAb titers in women with full-blown GD. Further molecular-based research to clarify the actual role of IFNs in the disease progression of GD is needed.

---

### Stability of synchronization in simplicial complexes [^d605211c]. Nature Communications (2021). High credibility.

In analogy with the classification of systems made for synchronization of complex networks (Chapter 5 in ref.), one immediately realizes that, once specified the dynamical system taking place in each node (i.e. the function f), the various coupling functions g (1) and g (2), and the structure of the simplicial complex (i.e.and), all possible cases can be divided in three classes: (i) class I problems, where Î› max is positive in all the half plane (Ïƒ 1 â‰¥â€‰0, Ïƒ 2 â‰¥â€‰0), and therefore synchronization is never stable; (ii) class II problems, for which Î› max is negative within a unbounded area of the half plane (Ïƒ 1 â‰¥â€‰0, Ïƒ 2 â‰¥â€‰0); and (iii) class III problems, for which the area of the half plane (Ïƒ 1 â‰¥â€‰0, Ïƒ 2 â‰¥â€‰0) in which Î› max is negative is instead bounded, and therefore additional instabilities of the synchronous motion may occur at larger values of the coupling strengths. While class I problems are trivial (in that synchronization is never observed), examples of class II and class III problems are shown in Fig. 1 for simplicial complexes of RÃ¶ssler oscillators, and one easily sees that the predictions made by solving Eq. (3) are indeed fully confirmed by the simulations of the original system in Eq. (2).

---

### Expression of type III interferons (IFN Î» s) and their receptor in SjÃ¶gren's syndrome [^f7c6ec51]. Clinical and Experimental Immunology (2016). Low credibility.

Type III interferons (IFNs) or IFN-Î»s (IFN-Î»1/IL29, IFN-Î»2/interleukin (IL)-28A and IFN-Î»3/IL-28B) consist of a recently identified group of IFNs, implicated initially in several human diseases, including cancer and autoimmunity. In this study, we sought to investigate the expression of type III IFNs and their common receptor IFN-Î»R1/IL-28Ra in SjÃ¶gren's syndrome (SS). Type III IFN expression was examined in minor salivary gland tissues (MSG), peripheral blood mononuclear cells (PBMCs), sera and resting or Toll-like receptor (TLR)-stimulated salivary gland epithelial cells (SGEC) from SS patients and sicca-complaining controls. All type III IFN family members were detected in ductal and acinar epithelia of MSGs from both SS patients and sicca controls. IFN-Î»2/IL-28A and IFN-Î»3/IL-28B were also expressed in infiltrating mononuclear cells. In SS patients with intermediate MSG lesions, the epithelial expression of IFN-Î»2/IL-28A was more intense compared to sicca controls (P<0Â·05). The receptor IFN-Î»R1/IL-28Ra was detected in all types of cells except fibroblasts, and was exceptionally strong in plasmatocytoid dendritic cells, indicating that they are susceptible to type III IFN-mediated regulation. In the periphery, only IFN-Î»1/IL-29 was detected in the sera and was elevated significantly in SS patients with intermediate MSG inflammatory lesions compared to sicca controls (P=0Â·0053). None of the type III IFNs was expressed constitutively in resting SGECs; they were all induced readily by TLR-3 stimulation, suggesting that the in-situ epithelial expression can be attributed to local microenvironment. Type III IFNs are expressed in MSGs in a similar pattern to type I IFNs and their expression is probably subjected to micro-environmental regulation, suggesting that they are implicated in the inflammatory processes occurring in the affected exocrine glands.

---

### Changes in diffusion tensor imaging (DTI) eigenvalues of skeletal muscle due to hybrid exercise training [^6204d418]. Magnetic Resonance Imaging (2014). Low credibility.

Several studies have proposed the cell membrane as the main water diffusion restricting factor in the skeletal muscle cell. We sought to establish whether a particular form of exercise training (which is likely to affect only intracellular components) could affect water diffusion. The purpose of this study is to characterise prospectively the changes in diffusion tensor imaging (DTI) eigenvalues of thigh muscle resulting from hybrid training (HYBT) in patients with non-alcoholic fatty liver disease (NAFLD). Twenty-one NAFLD patients underwent HYBT for 30 minutes per day, twice a week for 6 months. Patients were scanned using DTI of the thigh pre- and post-HYBT. Fractional anisotropy (FA), apparent diffusion coefficient (ADC), the three eigenvalues lambda 1 (Î»1), Î»2, Î»3, and the maximal cross sectional area (CSA) were measured in bilateral thigh muscles: knee flexors (biceps femoris (BF), semitendinosus (ST), semimembranous (SM)) and knee extensors (medial vastus (MV), intermediate vastus (IV), lateral vastus (LV), and rectus femoris (RF)), and compared pre- and post-HYBT by paired t-test. Muscle strength of extensors (P<0.01), but not flexors, increased significantly post-HYBT. For FA, ADC and eigenvalues, the overall picture was of increase. Some (P<0.05 in Î»2 and P<0.01 in Î»1) eigenvalues of flexors and all (Î»1-Î»3) eigenvalues of extensors increased significantly (P<0.01) post-HYBT. HYBT increased all 3 eigenvalues. We suggest this might be caused by enlargement of muscle intracellular space.

---

### Anti-tumor immunity elicited by direct intratumoral administration of a recombinant adenovirus expressing either IL-28A / IFN-Î» 2 or IL-29 / IFN-Î» 1 [^38cfebc2]. Cancer Gene Therapy (2016). Low credibility.

Interleukin (IL)-28A/interferon (IFN)-Î»2 and IL-29/IFN-Î»1 have been demonstrated to elicit direct and indirect anti-tumor actions. In this study, we constructed an adenovirus vector expressing either IL-28A/IFN-Î»2 (AdIL-28A) or IL-29/IFN-Î»1 (AdIL-29) to evaluate the therapeutic properties of intratumoral injection of recombinant adenovirus to apply for the clinical implementation of cancer gene therapy. Despite the lack of an anti-proliferative effect on MCA205 and B16-F10 cells, a retarded growth of established subcutaneous tumors was observed following multiple injections of either AdIL-28A or AdIL-29 when compared with AdNull. In vivo cell depletion experiments displayed that both NK cells and CD8(+) T cells have a major role in AdIL-28A-mediated tumor growth suppression. A significant increase in the number of infiltrating CD8(+) T cells into the tumors treated with either AdIL-28A or AdIL-29 was observed. Moreover, specific anti-tumor cytotoxic T lymphocyte reactivity was detected in spleen cells from animals treated with either AdIL-28A or AdIL-29. In IFN-Î³-deficient mice, anti-tumor activities of AdIL-28A were completely impaired, indicating that IFN-Î³ is critically involved in the tumor growth inhibition triggered by AdIL-28A. IL-12 provided a synergistic anti-tumor effect when combined with AdIL-28A. These results indicate that AdIL-28A and AdIL-29 could be successfully utilized as an alternative cancer immunogene therapy.

---

### Importance of screening severe COVID-19 patients for IFN-Î» 1, IL-6 and anti-S1 IgG levels [^4fe05576]. Cytokine (2023). Medium credibility.

Cytokine storm is an important cause of death in COVID-19 patients. A recent clinical study showed that administration of recombinant interferon lambda 1 (IFN-Î»1 or IL-29) may prevent severe COVID-19. On the other hand, IL-6 has been associated as a prognostic marker of worsening for COVID-19 patients. The objective of this study is to screen IFN-Î»1, IL-6 and antibody levels in consecutive serum sample sets of COVID-19 patients. A total of 365 serum samples collected from 208 hospitalized COVID-19 patients were analyzed for IFN-Î»1 and IL-6 levels as well as SARS-CoV-2 neutralizing antibodies and anti-S1 IgG antibodies. Analyses of serum samples for cytokine levels showed that IFN-Î»1 (>8 pg/mL) and IL-6 (>2 pg/mL) were detected in approximately 64% and 21% patients, respectively. A decrement in IFN-Î»1 levels and IL-6 levels above 35Â pg/mL can be sign of clinical severity and upcoming dead. An increment in IL-6 levels wasn't detected in every COVID-19 patient but a decrement in IL-6 levels was related to clinical improvement. Importantly, the detection of IFN-Î»1 level together with an increase in anti-S1 IgG antibody response were observed in clinically improved patients. Screening severe COVID-19 patients for IFN-Î»1, IL-6, and anti-S1 IgG antibody levels during their hospital stay especially in intensive care units may be beneficial to monitor the clinical status and management of treatment strategies. Importantly, detection of IFN-Î»1 together with protective IgG antibody response can be an indication of clinical improvement in severe COVID-19 patients and these patients may be discharged from the hospital soon.

---

### Enterovirus D68 vRNA induces type III IFN production via MDA5 [^f73c5954]. Virus Research (2024). Medium credibility.

Fig. 3 
EV-D68 viral RNA transfection stimulates type III interferon expression. EV-D68 at 0.1, 2, and. 40Â M.O.I. was used to infect Calu-3 cells for 12Â h postinfection. The RNA expression levels of IFN-Î»1, IFN-Î»2/3, and EV-D68 5â€² UTR was detected by RTâ€’qPCR (A). Calu-3 cells were infected with EV-D68 or UV-inactivated EV-D68 at an M.O.I. of 2 for 12Â h postinfection. The EV-D68 5â€² UTR, IFN-Î»1, and IFN-Î»2/3 were detected by RTâ€’qPCR (B). Calu-3 cells were transfected with 1Â Î¼g of RD RNA or EV-D68 viral RNA. Total RNA was collected at 12Â h postinfection, and the expression of EV-D68 5â€² UTR, IFN-Î»1 and IFN-Î»2/3 was analyzed by RTâ€’qPCR (C). LF2K (Lipofectamine 2000) serves as a control for transfection. Data are expressed as the mean valueÂ Â±Â SD (*, p <Â 0.05, **, p <Â 0.01, ***, p <Â 0.001, Student's t-test).

---

### Proteomic profiling of neonatal herpes simplex virus infection on dried blood spots [^b8c7ae2f]. Communications Medicine (2024). Medium credibility.

Description of protein levels, cytokines, and interferon response

Many of the elevated proteins in neonates with disseminated disease compared to controls were involved in inflammatory response, such as interleukin-6 (IL-6), C-C motif chemokine ligand 8 (CCL8), CCL2, C-X-C motif chemokine ligand 10 (CXCL10), and antiviral defence, e.g. interferon-induced protein with tetratricopeptide repeats 1 (IFIT1), IFIT3, tumor necrosis factor superfamily member 10 (TNFSF10), and interferon lambda-1 (IFN-Î»1). Other elevated proteins were granulysin (GNLY), an antimicrobial protein present in cytotoxic T cells and NK cells, and sialic acid-binding immunoglobulin-like lectin 1 (SIGLEC1), which is involved in cell adhesion, binding of macrophages and pathogen recognition and clearance. Other proteins with reduced levels were chromosome 7 open reading frame 50 (C7orf50) and WD repeat-containing protein 46 (WDR46), representing mediators of cell metabolism and RNA processing (Supplementary Table 2). The three overlapping post-hoc significant proteins between SEM and disseminated disease were IFIT1, IFIT3 and CXCL10. For all phenotypes, the levels of IFN gamma (IFN-Î³), IFN lambda-2 (IFN-Î»2) and IFN omega (IFN-Ï‰), IFN membrane receptors, and other intracellular proteins related to the IFN response, e.g. TLR3, were not different from controls (Supplementary Fig. 3).

---

### Simplicial models of social contagion [^32a6a694]. Nature Communications (2019). High credibility.

Let us now focus on a more interesting but still analytically tractable case in which we extend the contagion dynamics up to dimension D =â€‰2, so that Eq. (1) reads:where âŒ© k Î” âŒªâ€‰â‰¡â€‰âŒ© k 2 âŒª. By defining as before Î» = Î² âŒ© k âŒª/ Î¼ and Î» Î” = Î² Î” âŒ© k Î” âŒª/ Î¼, and by rescaling the time by Î¼, we can rewrite eq. (2) as:whereandare the solutions of the second-order equation 1â€‰âˆ’ Î» (1â€‰âˆ’ Ï)â€‰âˆ’ Î» Î” Ï (1â€‰âˆ’ Ï)â€‰=â€‰0. We thus obtain:

The steady-state equation d t Ï (t)â€‰=â€‰0 has thus up to three solutions in the acceptable range Ï âˆˆâ€‰[0, 1]. The solutioncorresponds to the usual absorbing epidemic-free state, in which all the individuals recover and the spreading dies out. A careful analysis of the stability of this state and of the two other solutionsandis however needed to fully characterize the phase diagram of the system.

Let us first consider the case Î» Î” â‰¤â€‰1. It is possible to show that, when it is real-valued, is always negative, i.e. it is not an acceptable solution. Moreover,is positive for Î» >â€‰1 and negative for Î» <â€‰1. In the regime Î» Î” â‰¤â€‰1 therefore, if Î» <â€‰1, the only acceptable solution to d t Ï (t)â€‰=â€‰0 is; contrarily, for Î» >â€‰1, sinceand, Eq. (3) shows that d t Ï (t) is positive at small Ï (t): the absorbing stateis thus unstable and the solutionis stable. Asfor Î» =â€‰1, the transition at the epidemic threshold Î» =â€‰1 is continuous. In conclusion, when Î» Î” â‰¤â€‰1, the transition is similar to the one of the standard SIS model with Î» Î” =â€‰0.

---

### Effects of prolonged sitting with or without elastic garments on limb volume, arterial blood flow, and muscle oxygenation [^7dc87255]. Medicine and Science in Sports and Exercise (2022). Medium credibility.

Tissue oxygenation: NIR TRS

Tissue oxygenation was measured using a NIR TRS unit (TRS-20; Hamamatsu Photonics, Hamamatsu, Japan) with the distance between the emitter and detector set at 3.0 cm, providing approximately 4-cm 3 measurement volume. The NIR TRS signal noninvasively monitors absolute concentration changes in [oxy-Hb], [deoxy-Hb], and their sum as total hemoglobin [total-Hb], an index of the blood volume. The principle of this system has been previously described in detail. Briefly, the absolute concentrations of [deoxy-Hb], [oxy-Hb], and [total-Hb], as well as the tissue oxygen saturation (SO 2), can be determined using three wavelengths as follows:

where Îµ1 Î»1 (Îµ1 Î»2) and Îµ2 Î»1 (Îµ2 Î»2) are the extinction coefficient of oxy-Hb at wavelength Î»1 (Î»2) and the extinction coefficient of [deoxy-Hb] at wavelength Î»1 (Î»2), respectively. The parameters [deoxy-Hb], [oxy-Hb], [total-Hb], and SO 2 were calculated according to equations 1 to 4, respectively. At each time point, the NIR TRS system measured the [deoxy-Hb], [oxy-Hb], [total-Hb], and SO 2 every 10 s for 5 min in the lateral head of the gastrocnemius muscle. The probe was firmly attached to the belly of the lateral gastrocnemius head to reduce movement artifacts and was protected from ambient light. In the garment legs, the probe was attached through a small hole of 3 mm in diameter in the garment just over the belly of the lateral gastrocnemius head.

The coefficients of variation for repeated measurements of [oxy-Hb], [deoxy-Hb], and [total-Hb] were 4.7%, 7.5%, and 4.9%, respectively.

---

### Breast MRI during lactation: effects on tumor conspicuity using dynamic contrast-enhanced (DCE) in comparison with diffusion tensor imaging (DTI) parametric maps [^d9513428]. European Radiology (2020). Medium credibility.

Purpose

To investigate the effect of lactation on breast cancer conspicuity on dynamic contrast-enhanced (DCE) MRI in comparison with diffusion tensor imaging (DTI) parametric maps.

Materials and Methods

Eleven lactating patients with 16 biopsy-confirmed pregnancy-associated breast cancer (PABC) lesions were prospectively evaluated by DCE and DTI on a 1.5-T MRI for pre-treatment evaluation. Additionally, DCE datasets of 16 non-lactating age-matched breast cancer patients were retrospectively reviewed, as control. Contrast-to-noise ratio (CNR) comprising two regions of interests of the normal parenchyma was used to assess the differences in the tumor conspicuity on DCE subtraction images between lactating and non-lactating patients, as well as in comparison against DTI parametric maps of Î»1, Î»2, Î»3, mean diffusivity (MD), fractional anisotropy (FA), and maximal anisotropy index, Î»1-Î»3.

Results

CNR values of breast cancer on DCE MRI among lactating patients were reduced by 62% and 58% (p < 0.001) in comparison with those in non-lactating patients, when taking into account the normal contralateral parenchyma and an area of marked background parenchymal enhancement (BPE), respectively. Among the lactating patients, DTI parameters of Î»1, Î»2, Î»3, MD, and Î»1-Î»3 were significantly decreased, and FA was significantly increased in PABC, relative to the normal lactating parenchyma ROIs. When compared against DCE in the lactating cohort, the CNR on Î»1, Î»2, Î»3, and MD was significantly superior, providing up to 138% more tumor conspicuity, on average.

Conclusion

Breast cancer conspicuity on DCE MRI is markedly reduced during lactation owing to the marked BPE. However, the additional application of DTI can improve the visualization and quantitative characterization of PABC, therefore possibly suggesting an additive value in the diagnostic workup of PABC.

Key Points

â€¢ Breast cancer conspicuity on DCE MRI has decreased by approximately 60% among lactating patients compared with non-lactating controls. â€¢ DTI-derived diffusion coefficients and the anisotropy indices of PABC lesions were significantly different than those of the normal lactating fibroglandular tissue. â€¢ Among lactating patients, breast cancer conspicuity on DTI-derived parametric maps provided up to 138% increase in contrast-to-noise ratio compared with DCE imaging.

---

### Hsa-miR-2113-5p is not a key indicator for coronary artery disease: a case-controlled observational study [^7f81acc5]. Laboratory Medicine (2025). Medium credibility.

Introduction

Coronary artery disease (CAD) is a prevalent inflammatory disease. Interferon Î» 1 (IFN-Î»1) is a known factor that participates in the pathogenesis of proinflammatory diseases, but the roles of IFN-Î»1 in CAD and its regulators have yet to be clarified. Bioinformatic analysis revealed that hsa-miR-2113-5p can target IFN-Î»1 with a score of 84. Thus, this project was designed to explore the relative expression of hsa-miR-2113-5p in patients with CAD and its correlation with IFN-Î»1 expression.

Methods

In this project, 60 Iranian volunteers were enrolled, including 40 people with CAD and 20 people without CAD. Relative expression of hsa-miR-2113-5p and IFN-Î»1 was explored using the real-time polymerase chain reaction technique.

Results

The results showed that neither hsa-miR-2113-5p nor IFN-Î»1 expression levels were different between individuals with CAD and control individuals. There were no correlations among hsa-miR-2113-5p, IFN-Î»1, and age in control individuals or individuals with CAD.

Discussion

Because individuals with CAD have chronic inflammation and alteration of several genes, no alterations in the molecules demonstrated that chronic inflammation associated with CAD is independent of hsa-miR-2113-5p and IFN-Î»1.

---

### Entecavir-induced interferon-Î» 1 suppresses type 2 innate lymphoid cells in patients with hepatitis B virus-related liver cirrhosis [^6f529630]. Journal of Viral Hepatitis (2021). Medium credibility.

The immunomodulatory effects of entecavir (ETV) in anti-hepatitis B virus (HBV) therapy have long been recognized. This study aimed to determine the effects of ETV on non-natural killer innate lymphoid cells (non-NK ILCs) in HBV-related liver disease progression. We enrolled treatment-naÃ¯ve chronic hepatitis B (CHB) and HBV-related liver cirrhosis (LC) patients treated with ETV for 24Â months. Before and after therapy, the frequency and cytokine profiles of ILC2s and non-NK ILCs subset homeostasis and their clinical significance were determined, and serial serum interferon (IFN)-Î» levels were analysed. Peripheral blood mononuclear cells (PBMCs) of untreated LC patients were cultured with serum from untreated and ETV-treated LC patients in addition to being subject to IFN-Î»1 neutralization and stimulation, and the frequency and cytokine production of ILC2s as well as non-NK ILCs subset ratios were calculated. Furthermore, IFN-Î» receptor expression on non-NK ILCs and dendritic cells (DCs) was measured. After 24Â months of ETV treatment, the frequency and cytokine production of ILC2s (IL-4, IL-13, IFN-Î³, TNF-Î±) decreased with increased ILC1/ILC2 and decreased ILC2/ILC3 ratios, revealing a close association with disease status in LC patients. Long-term ETV administration-induced serum IFN-Î»1 levels were negatively correlated with ILC2s. ETV-treated LC serum culture and IFN-Î»1 stimulation yielded similar effects on suppression of ILC2s, and IFN-Î»1 neutralization in serum culture partly inhibited this effect. The IFN-Î» receptor was detected on DCs but not on non-NK ILCs. In conclusion, ETV suppresses the frequency and cytokine profiles of ILC2s by increasing IFN-Î»1 in LC patients.

---

### Improvement of immune dysregulation in individuals with long COVID at 24-months following SARS-CoV-2 infection [^0d114e85]. Nature Communications (2024). High credibility.

Blood markers associated with improvement of health-related quality of life

An established log-linear classification modelwas used to analyze 15 blood parameters (IL-6, PTX3, IFN-Î»1, IFN-Î³, IFN-Î»2/3, IFN-Î², CRP, D-dimer, platelets, troponin, cholesterol, blood sugar level, neutrophils, lymphocyte count and neutrophil: lymphocyte ratio) from LC participants at 24-months and associations with improvement of health-related quality of life were ascertained. The most prominent features that were associated with improvement of health-related quality of life were PTX3, CRP and platelet levels (Fig. 6A). The top 2 features being PTX3 and platelet count giving an accuracy of 71% and F1 score of 0.78. By adding CRP, accuracy increased to 73% with an F1 score of 0.80 (Fig. 6B). Levels of these 3 analytes were stratified between participants in LC group into recovered (improvement in health-related quality of life) and unrecovered (no improvement in health-related quality of life) and then compared to MC group. Beyond identifying the optimal set of blood markers that are most highly associated with recovery, log-linear classifiers define what is known as a decision boundary. A participantâ€™s concentration of the 3 aforementioned markers at 24-months will lie on either side of this boundary, and its positioning relative to the boundary will determine the association between recovered or unrecovered. The decision boundary for PTX3, Platelets and CRP are three-dimensional (Fig. 6C, left panel) and the domain boundary can be clearly visualized with two-dimensional projections (Fig. 6C, right panels).

Fig. 6 
Blood parameters associated with improvement in health-related quality of life at 24-months.

A Representative bar graph of log-linear model, showing frequency of features highly associated with recovery. B Table summarizing accuracy and F1 score for top 2 and top 3 most highly associated features. CIâ€‰=â€‰95% confidence interval. C Left-panel: 3-dimensional scatter plot of recovered vs unrecovered participant with concentration values of 3 markers (PTX3, CRP and platelets). Right-panel: 2D projections of PTX3 vs platelets (upper) and PTX3 vs. CRP (lower) with line representing the decision boundary. Recovered refers to improvement in health-related quality of life, unrecovered= no improvements, MC matched controls. Source data are provided as a Source Data file.

---

### An analytical theory of balanced cellular growth [^67e77770]. Nature Communications (2020). High credibility.

We now define a Lagrangian as the sum of the objective function Î¼ and the constraints g scaled by Lagrange multipliers Î» Ï, accounting for the density constraintÂ (14), and Î» Î³, accounting for the dependence of the dependent reactants Î³ âˆˆâ€‰{ Î³ }, Eq. (18):The first-order necessary conditions for a constrained local maximum are that all partial derivatives ofwith respect to the variables P, b Î², c Î³ and to the Lagrange multipliers Î» Ï, Î» Î³ are zero,

For the partial derivative with respect to an independent concentration x i (i âˆˆâ€‰{P, Î² }), we have

With Theorem 8, this results in

For the partial derivative with respect to a dependent reactant c Î³, we have

With Eq. (19), we obtain

Substituting Î» Î³ from the last equation into Eq. (27) gives (for i âˆˆâ€‰{P, Î² })

Rearranging results inwhere we used Î· Ï =â€‰âˆ’ Î» Ï / Î¼, which follows directly from the envelope theorem. With Î¼ >â€‰0, we can divide by Î¼ to obtain the balance equation. â–¡

The optimal state is perfectly balanced: the total marginal net benefit of each independent cellular concentration x i equals the marginal benefit of the cellular density, scaled by Îº i to account for its total utilization of cellular density. If i does not have any dependent reactants (âˆ€ Î³ : D Î³ i =â€‰0), then the balance equation simplifies to(Eq. (10)).

Theorem 10 states that if the dry weight density Ï would be allowed to increase by a small amount, such as 1â€‰mgâ€‰l âˆ’1, then the marginal fitness gain that could be achieved by increasing protein concentration (plus dependent concentrations) by this amount is identical to that achieved by increasing the concentration of any reactant Î² (plus its dependent concentrations) by the same amount.

---

### Family history of neurodegenerative and vascular diseases in ALS: a population-based study [^206b72cc]. Neurology (2011). Low credibility.

Objective

To determine whether the frequency of Parkinson disease (PD), dementia, and vascular diseases in relatives of patients with amyotrophic lateral sclerosis (ALS) differs from the frequency of those diseases in relatives of controls, providing further information about the association between these diseases.

Methods

We studied the occurrence of neurodegenerative and vascular diseases in families of patients with ALS in a prospective, population-based, case-control study in the Netherlands between 2006 and 2009, using the recurrence risk Î». Family history data were obtained by asking participants to fill in questionnaires.

Results

A total of 635 patients and 1,616 controls were included. The frequency of dementia was mildly increased only among parents and siblings of patients with sporadic ALS (Î»1.32; 95 confidence interval [CI] 1.10-1.59), not among grandparents, or aunts and uncles. The risk of PD was not elevated (any relative: Î» 0.91; 95% CI 0.70-1.17). Among relatives of patients with familial ALS, no significantly increased risk of neurodegenerative diseases was found. A reduced risk of vascular diseases was found in relatives of patients with sporadic ALS (stroke: Î» 0.90; 95% CI 0.80-1.01 and myocardial infarction: Î» 0.86; 95% CI 0.79-0.94), and in relatives of patients with familial ALS (stroke: Î» 0.88; 95% CI 0.61-1.27 and myocardial infarction: Î» 0.61; 95% CI 0.43-0.86).

Conclusions

This large, prospective, population-based study showed that familial aggregation of ALS, dementia, and PD is substantially lower than previously thought. The lowered risk of vascular diseases in relatives of patients with ALS supports the view that a beneficial vascular risk profile increases ALS susceptibility.

---

### Pathogenesis and transmission of SARS-CoV-2 D614G, alpha, gamma, delta, and omicron variants in golden hamsters [^fc8be26a]. Npj Viruses (2025). Medium credibility.

Since the emergence of SARS-CoV-2 in humans, novel variants have evolved to become dominant circulating lineages. These include D614G (B.1 lineage), Alpha (B.1.1.7), Gamma (P.1), Delta (B.1.617.2), and Omicron BA.1 (B.1.1.529) and BA.2 (B.1.1.529.2) viruses. Here, we compared the viral replication, pathogenesis, and transmissibility of these variants. Replication kinetics and innate immune response against the viruses were tested in ex vivo human nasal epithelial cells (HNEC) and induced pluripotent stem cell-derived lung organoids (IPSC-LOs), and the golden hamster model was employed to test pathogenicity and potential for transmission by the respiratory route. Delta, BA.1, and BA.2 viruses replicated more efficiently, and outcompeted D614G, Alpha, and Gamma viruses in an HNEC competition assay. BA.1 and BA.2 viruses, however, replicated poorly in IPSC-LOs compared to other variants. Moreover, BA.2 virus infection significantly increased secretion of IFN-Î»1, IFN-Î»2, IFN-Î»3, IL-6, and IL-1RA in HNECs relative to D614G infection, but not in IPSC-LOs. The BA.1 and BA.2 viruses replicated less effectively in hamster lungs compared to the other variants; and while the Gamma virus reached titers comparable to D614G and Delta viruses, it caused greater lung pathology. Lastly, the Gamma and Delta variants transmitted more efficiently by the respiratory route compared to the other viruses, while BA.1 and BA.2 viruses transmitted less efficiently. These findings demonstrate the ongoing utility of experimental risk assessment as SARS-CoV-2 variants continue to evolve.

---

### Dynamical regimes of diffusion models [^47bc7582]. Nature Communications (2024). High credibility.

Results

We focus on cases in which the data can be organized in distinct classes. For simplicity, we consider below two classes, identified in the spectrum of the covariance matrix of the data: this spectrum is assumed to display a single large eigenvalue along the principal component which we will denote Î›. This is a simplifying assumption; our analysis can be extended to more than two classes and subclasses within classes. The data consist of n data points. We assume that there exists an underlying distribution P 0 (a) from which data are drawn, and we denote by, the empirical distribution of the data. The components of a are normalized to be finite for large d, meaning we assume that the momentsremain of order one for d â†’ âˆž and finite p. This implies in particular that the expectation of âˆ£ x âˆ£ 2 grows linearly with d.

There exist many variants of DMs which are basically equivalent. We focus here on the diffusion process which consists in d independent Ornstein-Uhlenbeck Langevin equations,where d B (t) is square root of two times the standard Wiener process (a.k.a. Brownian motion) in. The exact empirical score is given bywhereis the noisy empirical distribution at time t due to the process in (1)This is the convolution of the empirical distribution of the data,, with a Gaussian law of variance Î” t =â€‰(1âˆ’ e âˆ’2 t). At long timesis a Gaussian distribution with zero mean and covariance equal to the identity. In DMs the generation of new data is obtained by time-reversing this process using the backward dynamicswhere the noise d Î¾ i (t) has the same distribution as in the forward process.

---

### Innate immune responses to rhinovirus are reduced by the high-affinity IgE receptor in allergic asthmatic children [^67e01a32]. The Journal of Allergy and Clinical Immunology (2012). Low credibility.

Background

Children with allergic asthma have more frequent and severe human rhinovirus (HRV)-induced wheezing and asthma exacerbations through unclear mechanisms.

Objective

We sought to determine whether increased high-affinity IgE receptor (FcÎµRI) expression and cross-linking impairs innate immune responses to HRV, particularly in allergic asthmatic children.

Methods

PBMCs were obtained from 44 children, and surface expression of FcÎµRI on plasmacytoid dendritic cells (pDCs), myeloid dendritic cells, monocytes, and basophils was assessed by using flow cytometry. Cells were also incubated with rabbit anti-human IgE to cross-link FcÎµRI, followed by stimulation with HRV-16, and IFN-Î± and IFN-Î»1 production was measured by Luminex. The relationships among FcÎµRI expression and cross-linking, HRV-induced IFN-Î± and IFN-Î»1 production, and childhood allergy and asthma were subsequently analyzed.

Results

FcÎµRIÎ± expression on pDCs was inversely associated with HRV-induced IFN-Î± and IFN-Î»1 production. Cross-linking FcÎµRI before HRV stimulation further reduced PBMC IFN-Î± (47% relative reduction; 95% CI, 32% to 62%; P< .0001) and IFN-Î»1 (81% relative reduction; 95% CI, 69% to 93%; P< .0001) secretion. Allergic asthmatic children had higher surface expression of FcÎµRIÎ± on pDCs and myeloid dendritic cells when compared with that seen in nonallergic nonasthmatic children. Furthermore, after FcÎµRI cross-linking, allergic asthmatic children had significantly lower HRV-induced IFN responses than allergic nonasthmatic children (IFN-Î±, P= .004; IFN-Î»1, P= .02) and nonallergic nonasthmatic children (IFN-Î±, P= .002; IFN-Î»1, P= .01).

Conclusions

Allergic asthmatic children have impaired innate immune responses to HRV that correlate with increased FcÎµRI expression on pDCs and are reduced by FcÎµRI cross-linking. These effects likely increase susceptibility to HRV-induced wheezing and asthma exacerbations.

---

### Modularity and stability in ecological communities [^ce023b34]. Nature Communications (2016). Medium credibility.

Combining the eigenvalues of A and B

Having derived the position of the eigenvalues of A, and, for particular cases, the support of the distribution of those of B, we want to combine the results to obtain an approximation for Re(Î» M,1), the real part of the rightmost eigenvalue of M = A + B.

This problem has been recently studied by O'Rourke & Renfrew, who considered the following case: B is a large, random matrix whose eigenvalues follow the elliptic law. It is defined by its size, S and the distribution of the coefficients, which are independently sampled in pairs from a bivariate distribution with mean zero, unitary variance and correlation Ï. A is a matrix with low rank (that is, few nonzero eigenvalues), and nonzero eigenvalues that are sufficiently larger than those of B. Then (Theorem 2.4), we can order the eigenvalues ofsuch that:

where the term o (1) goes to zero as S â†’âˆž. This means (ref.; Theorem 2.8) that a random matrix with a nonzero mean Î¼ will have a single outlier located approximately at Î¼S, exactly as found for the unstructured casestudied above.

Clearly, the correction above is well suited for the unstructured case, and for the perfectly modular one (which is the combination of two unstructured cases). We also corrected in the same way the eigenvalues for matrices with Î± =1/2, reasoning that the correction would have the same form, given that the spectra of these matrices converge to those of equivalent unstructured cases. We do not have a formula for correcting the eigenvalues of bipartite matrices, but, as for the other cases, the correction is negligible when | Î¼ | is large enough.

Supplementary Fig. 8 shows that our approximation is indeed excellent for all the cases considered here.

Simulating empirical network structures

We parameterized three empirical networks, and studied the effect of network structure by measuring the ratio, when varying a critical parameter Î¸. For simplicity, we always consider the case of matrices with zero on the diagonal.

---

### Human primary airway epithelial cells isolated from active smokers have epigenetically impaired antiviral responses [^f4460bf9]. Respiratory Research (2016). Low credibility.

Fig. 2 
Antiviral interferons and IP-10 induced by influenza virus infection were suppressed in HBEC isolated from smokers. After infection of cells with IAV PR8 at the MOI of 1 for 24Â h, total RNA was extracted and cell cytokine mRNA expression was assessed by qRT-PCR. Transcript levels of the cytokines (a) IFN-Î², (b) IFN-Î»1, (c) IFN-Î»2/3, and (d) IP-10 were normalized relative to the constitutively expressed Î²-actin gene. CSâ€‰=â€‰cigarette smoker; NSâ€‰=â€‰nonsmoker. Data were expressed as the meansâ€‰Â±â€‰SEM from three separate experiments from different donors. * denotes significant difference between the indicated groups, P <â€‰0.05

Fig. 3 
RIG-I and TLR3 upregulation by influenza virus infection was required for IFNÎ² induction and was suppressed in HBEC isolated from smokers. After infection of cells with IAV at an MOI of 1 for 24Â h, total RNA was extracted and cell PRR mRNA expression was assessed by qRT-PCR. Transcript levels of RIG-I (a) and TLR3 (b) were normalized relative to the constitutively expressed Î²-actin gene. ï»¿(c) HBEC from nonsmokers were first transfected with RIG-I or TLR3 siRNA for two days before IAV infection. Statistical significance was determined by ANOVA. Data were expressed as the meansâ€‰Â±â€‰SEM from three separate experiments from different donors. * denotes significant difference compared to data from the IAV infected cells from nonsmokers (NSâ€‰+â€‰IAV), P <â€‰0.05

To mimic the CS effect on HBEC ex vivo, we also treated HBEC isolated from nonsmokers with 2Â % CSE, using the same methods described earlier. Cultured cells were treated with 2Â % CSE or not for 24Â h prior to infection with 6â€‰Ã—â€‰10 6 PFU/ml of IAV. Virus-free diluents (mock) were the negative controls for the experiments. Consistent with our previous findings, pretreatment of the cells with 2Â % CSE decreased IAV stimulated IFN-Î², IFN-Î»1 and IFN-Î» 2/3 mRNA response by 48, 61 and 85Â % compared to cells without CSE treatmentÂ (Fig. 4a - c). The effect of CSE on the HBEC RIG-I and TLR3 response to IAV was also examinedÂ (Fig. 4d, e). CSE reduced RIG-I and TLR3 mRNA induction by 76 and 63Â %, respectively. Thus, the experiments demonstrated that CSE suppresses antiviral cytokine responses in IAV-infected HBEC through inhibition of RIG-I and TLR3 induction.

---

### An alternative to the breeder's and lande's equations [^2ccecec9]. G3 (2014). Low credibility.

The breeder's equation is a cornerstone of quantitative genetics, widely used in evolutionary modeling. Noting the mean phenotype in parental, selected parents, and the progeny by E(Z0), E(ZW), and E(Z1), this equation relates response to selection R = E(Z1) - E(Z0) to the selection differential S = E(ZW) - E(Z0) through a simple proportionality relation R = h(2)S, where the heritability coefficient h(2) is a simple function of genotype and environment factors variance. The validity of this relation relies strongly on the normal (Gaussian) distribution of the parent genotype, which is an unobservable quantity and cannot be ascertained. In contrast, we show here that if the fitness (or selection) function is Gaussian with mean Î¼, an alternative, exact linear equation of the form R' = j(2)S' can be derived, regardless of the parental genotype distribution. Here R' = E(Z1) - Î¼ and S' = E(ZW) - Î¼ stand for the mean phenotypic lag with respect to the mean of the fitness function in the offspring and selected populations. The proportionality coefficient j(2) is a simple function of selection function and environment factors variance, but does not contain the genotype variance. To demonstrate this, we derive the exact functional relation between the mean phenotype in the selected and the offspring population and deduce all cases that lead to a linear relation between them. These results generalize naturally to the concept of G matrix and the multivariate Lande's equation Î”(z) = GP(-1)S. The linearity coefficient of the alternative equation are not changed by Gaussian selection.

---

### Three questions to ask before using model outputs for decision support [^d09edd1a]. Nature Communications (2020). High credibility.

Question 1: what is the modelâ€™s purpose?

Models are developed for a specific purpose and by the need to address certain questions about real systems. Models therefore focus on aspects of the real system that are considered important in answering these questions. Consequently, different models exist for the same system. Without knowing its purpose, it is impossible to assess whether a modelâ€™s outputs can be used to support decisions affecting the real world.

Model purposes fall into three main categories: demonstration, understanding, and prediction. Given these different purposes, models also reflect different scopes. Models for demonstration are designed to explore ideas, demonstrate the consequences of certain assumptions, and thereby help communicate key concepts and mechanisms. For example, at the onset of the Covid-19 pandemic simple mathematical models were used to demonstrate how lowering the basic reproduction value, R 0, would lead to â€œflattening the curveâ€ of infections over time. This is an important logical prediction that helped to make key decisions, but it does not, and cannot, say anything about how effective interventions like social distancing are in reducing R 0.

Models for understanding are aimed at exploring how different components of a system interact to shape observed behavior of real systems. For example, a model can mechanistically represent movement and contact rates of individuals. The model can be run to let R 0 emerge and then explore how R 0 changes with interventions such as social distancing. Such models are not necessarily numerically precise, but they provide mechanistic understanding that helps to evaluate the consequences of alternative management measures.

Finally, models for prediction focus on numerical precision. They tend to be more detailed and complex and rely heavily on data for calibration. Their ability to make future projections therefore depends on the quality of data used for model calibration. Such models still do not predict the future with precision, as this is impossible, but they provide important estimates of alternative future scenarios.

Decision makers can benefit from all three types of models if they use them according to their given purpose. Modelers should therefore state a modelâ€™s purpose clearly and upfront. By asking this first screening question, one of the most common misuses of models can be prevented: using them for purposes for which they were not designed.

---

### Measuring the size of individual particles from three-dimensional imaging experiments [^f215a900]. Nature Communications (2012). Medium credibility.

Often experimentalists study particulate samples that are nominally monodisperse. In reality, many samples have a polydispersity of 4-10%. At the level of an individual particle, the consequences of this polydispersity are unknown as it is difficult to measure an individual particle size from images of a dense sample. Here we propose a method to estimate individual particle radii from three-dimensional data of the particle positions. We first validate our method with simulations. We then apply our method to experimental data of colloidal suspensions observed with confocal microscopy. We demonstrate that we can recover the full particle size distribution in situ. Finally, we use our method to study the relationship between homogeneous colloidal crystal nucleation and particle sizes. We show that nucleation occurs in regions that are more monodisperse than average.

---

### Reconciling time and prediction error theories of associative learning [^4b7d07a0]. Nature Communications (2025). High credibility.

We now specify the key features of timescale invariance required to recapitulate the behavioral phenomena of interest. Informally, we would like our model to capture the notion that the animal builds a histogram based on past stimulus-reward intervals. The histogramâ€™s bins are spaced uniformly on a logarithmic scale, and thus the width of a histogram bin is proportional to the binâ€™s location. Formally,
Each class Î¼ is associated with a timescale Ï„ Î¼. The timescales Ï„ Î¼ are spaced uniformly on a logarithmic scale; that is, Ï„ Î¼ +1 =Â (1Â + k) Ï„ Î¼, where k â‰ªÂ 1. The smallest and largest timescales are thus Ï„ 1 and Ï„ K =Â (1+ k) K âˆ’1 Ï„ 1, respectively. We assume that the support of the distribution spans many orders of magnitude, i.e. Ï„ K / Ï„ 1 â‰«Â 1, which implies K â‰«Â 1 if k â‰ªÂ 1.
The emission probabilities Ï• Î¼ (t) for all Î¼ have the form, where Ï• (x) is a density function that normalizes to one,. Thus, the functions Ï• Î¼ tile the interval axis from Ï„ 1 to Ï„ K, and the width of Ï• determines how much smoothing is applied when inferring the probability density from finite data. A reasonable choice is to require that Ï• Î¼ has width proportional to the difference in adjacent timescales, Î” Ï„ Î¼ = k Ï„ Î¼. Two possible choices for Ï• are: (a) a uniform distribution where Ï• Î¼ (t)Â =Â 1/(k Ï„ Î¼) when Ï„ Î¼ â‰¤ t â‰¤ Ï„ Î¼ +1 and zero otherwise; and (b) a Gamma distributionfor.

Inference

Exact inference in this model is challenging due to the â€œassignmentâ€ problem. For instance, consider a scenario where the causal stimulus c (cue) appears thrice at times t 1 < t 2 < t 3, and the target stimulus r (reward) appears thrice afterward at times s 1 < s 2 < s 3, with t 3 < s 1. Exact inference would involve iterating over the six possible assignments of the three causal cues with the three rewards. Unless the separation between successive rewards is significantly larger than the cue-reward interval, the number of possible assignments increases exponentially with the number of presentations of c and r in the worst case scenario. We outline a method for performing approximate inference in Supplementary Note 2, although our analysis of the standard conditioning protocol later allows for exact inference due to its trial structure.

---

### The decision path not taken [^5ea0a156]. Neuron (2015). Low credibility.

Real-life decisions often involve multiple intermediate choices among competing, interdependent options. Lorteije etÂ al. (2015) introduce a new paradigm for dissecting the neural strategies underlying such decisions.

---

### Mutualism supports biodiversity when the direct competition is weak [^1a78a1ee]. Nature Communications (2017). Medium credibility.

where we denote by x 1 the projection of vector x on the main eigenvector v 1,. The resulting vulnerability Î· i is a linear function of Î” that depends on the random variables q i and q 1. The variance of the denominator of equation (21) is given by. It is easy to see thatand. They both share the main qualitative property of, that is, they are all sums of d i +1 positive terms. Thus, to simplify formulas, in the following we estimate the variance of the denominator of equation (21) simply through.

The feasibility condition depends on the most vulnerable species, which is different in the unperturbed system Î”=0 (the species i that maximizes Î· i (p 0)) and for large Î” (the species v that maximizes Î· i (Î”)). If Î” is large enough, the most vulnerable species is the species that maximizes Î· i (q)âˆ’ Î· i (p 0) and it does not change for larger Î”, so that the maximum value of Î· i (Î”) increases linearly as Î· (Î”)â‰¡max i { Î· i (Î”)}â‰ˆ Î· v (p 0)+Î” Î· â€²(p 0). Î· â€² must be computed for the species with maximum Î· i, leading to

where we estimate q i with its root mean square value multiplied times a constant, v i 1 â‰ˆ1/and, and we take into account that p 0 depends on the effective growth rates.

The above formula is complex, and we prefer to compute Î· â€² numerically with equation (14), but it makes clear two important qualitative points: (1) Î· i decreases with the number of links (that is, the number of non-zero components G ik),, thus Î· â€² decreases with the connectance of the mutualistic network and (2) Î· â€² is larger for obligatory mutualism, in which the terms Î± and m have opposite sign.

---

### Key design considerations for adaptive clinical trials: a primer for clinicians [^6bfafe77]. BMJ (2018). Excellent credibility.

Clinical trial simulations

Simulations can be used for any type of study design but are customarily used in adaptive designs owing to the multitude of trajectories. They are used to establish statistical and practical properties of adaptive trial designs. The risks of false positives (type I error) and false negatives (type II error) in adaptive trials are difficult (if not impossible) to evaluate with conventional methods.Regulatory agencies commonly require control of these errors, so they should be decision-rules, using metrics such as expected reduction in required sample size, time to completion, number of treatment failures avoided, risk of biased interim effect estimates, and robustness of the planned statistical analysis at trial termination. These can be particularly helpful for planning a realistic budget and timeline.

Because simulation is an iterative process (fig 2), we recommend starting with fewâ€œbest caseâ€ and â€œworst caseâ€ scenarios based on current evidence or opinion, such as the two dose-response models in the case study (box 2). Exploring several scenarios can help quickly establish the likely efficiency gain from applying an adaptive design over a conventional design. Further, starting group discussions with only simple simulations can be important for engaging the clinical expertise of the investigators and help them to become more familiar with interpreting trial simulations. Then more comprehensive simulations extended to other scenarios can be shared for feedback. Statisticians should be engaged early in the planning phase. Trial simulations can be time consuming. Regulatory agencies should also be involved early in the planning phase.

---

### Striatal arbitration between choice strategies guides few-shot adaptation [^5fbb64f2]. Nature Communications (2025). High credibility.

Results

Unexpected event-driven few-shot adaptation hypothesis

In a context-switching environment with binary choices and probabilistic reward (Fig. 1 a left), a subject who infers the current task context as T 1 (p 1 > p 2 ; marked as a red square in the reward probability plot) is likely to choose the action A 1 since it leads to the outcome state S 1 with a higher reward probability (p 1). Suppose a reward is not offered, contrary to its expectation. Although this unexpected outcome can be regarded as a noisy event due to the probabilistic nature of the reward function, it could also indicate the context switching to T 2 (p 2 > p 1 ; marked as a blue square in the reward probability plot). This cognitive process might urge action A 2 at the trial right after, which can lead to highly rapid adaptation. Such contextual behavior patterns contradict the prediction of the conventional RL models that choices are made based on values of decision variables accumulated over several past trials.

Fig. 1 
Specialized action-selection strategy after experiencing the unexpected event.

a Alternative role of the unexpected event. Left for an example reversal learning task with two contexts and two actions. p 1 / p 2 is the probability of receiving a reward after arriving at the outcome state S 1 / S 2, respectively. Right for the reward probability plot depicting the context reversal. At the task context T 1, p 1 > p 2. On the other hand, in the task context T 2, p 1 < p 2. b, c Key terminology for behavioral measures. b The definition of action support/conflict events. c The two-step task; Left for the definition of positive/negative actions with the task diagram. Here, the current task context is T 1 (p 1 > p 2). Right for the summary table of 4 event types.

---

### KDIGO 2021 clinical practice guideline for the management of blood pressure in chronic kidney Disease [^7dcf99f6]. Kidney International (2021). High credibility.

KDIGO 2021 methodsâ€”GRADE system for grading quality of evidenceâ€”specifies that randomized controlled trials (RCTs) start at high quality and observational studies at low, with downgrades for â€œStudy limitations: âˆ’1, serious âˆ’2, very serious,â€ â€œInconsistency: âˆ’1, serious âˆ’2, very serious,â€ â€œIndirectness: âˆ’1, serious âˆ’2, very serious,â€ â€œImprecision: âˆ’1, serious âˆ’2, very serious,â€ and â€œPublication bias: âˆ’1, serious âˆ’2, very seriousâ€; for observational studies, quality can be raised for â€œStrength of association: +1, large effect size (e.g., <0.5 or >2) +2, very large effect size (e.g., <0.2 or >5),â€ as well as â€œEvidence of a dose-response gradientâ€ and when â€œAll plausible confounding would reduce the demonstrated effect.â€

---

### Disentangling signal from noise in visual contrast discrimination [^03b94848]. Nature Neuroscience (2001). Medium credibility.

Human ability to detect stimulus changes (Delta C) decreases with increasing reference level (C). Because detection performance reflects the signal-to-noise ratio within the relevant sensory brain module, this behavior can be accounted for in two extreme ways: first, the internal response change Delta R evoked by a constant Delta C decreases with C (that is, the transducer R = f(C) displays a compressive nonlinearity), whereas the internal noise is independent of R; second, Delta R is constant with C but the noise level increases with R. A newly discovered constraint on human decision-making helps solve this century-old problem: in a detection task where multiple changes occur with equal probabilities, observers use a unique response criterion to decide whether a change has occurred. For contrast discrimination, our results supported the first account above: human performance was limited by the contrast transducer nonlinearity and an almost constant noise.

---

### KDIGO clinical practice guideline on the evaluation and care of living kidney donors [^041cb4c4]. Transplantation (2017). Medium credibility.

GRADE system for grading certainty of evidence (Table 4) specifies starting levels and modifying factors: randomized controlled trials (RCTs) start High, while observational studies start Low; downgrading factors include â€œStudy limitations: âˆ’1, serious; âˆ’2, very serious,â€ â€œInconsistency: âˆ’1, serious; âˆ’2, very serious,â€ â€œIndirectness: âˆ’1, serious; âˆ’2, very serious,â€ â€œImprecision: âˆ’1, serious; âˆ’2, very serious,â€ and â€œPublication bias: âˆ’1, serious; âˆ’2, very serious.â€ For observational evidence, upgrading can occur for â€œStrength of association +1, large effect size (e.g., <0.5 or >2) +2, very large effect size (e.g., <0.2 or >5),â€ â€œEvidence of a doseâ€“response gradient,â€ and when â€œAll plausible confounding would reduce the demonstrated effect.â€

---

### Experimental designs for phase I and phase I / II dose-finding studies [^9715d3f5]. British Journal of Cancer (2006). Low credibility.

BACKGROUND

For cytotoxic anticancer drugs, it is assumed that there exists a doseâ€“toxicity effect whereby the higher the dose, the greater the risk of observing dose-limiting toxicity. The goal of dose-finding studies is to find the highest tolerable dosage: the maximum tolerated dose (MTD) that corresponds to some given acceptable toxicity rate. In studies of treatment efficacy, similar methodology is employed aiming to identify a dose capable of producing a given rate of success. A model that is widely assumed for cytotoxics, although (as for any model) open to debate, is a model that assumes monotonicity. This means that when a patient experienced a dose-limiting toxicity at a specific level, then, had this same patient been treated at any higher level he would also have suffered dose-limiting toxicity. Conversely, were the patient to tolerate the treatment at a specific dosage, then, for all lower levels, the patient would also have tolerated treatment. This is reasonable in most cases but might need to be questioned in certain situations, for example, for immunological therapies. Figure 1 illustrates three such dose toxicity curves for three hypothetical patients. Owing to patient variability, each patient responds at a different level. Some patients are able to tolerate higher levels of treatment than others. Most often we will not be able to know for any individual just what their particular dose toxicity (0, 1) step function might be; in other words, the lowest level at which the patient would encounter a dose-limiting toxicity. However, we can learn this for a group of subjects. In the light of patient variability, the lowest level for one patient may differ from that for another. Were we to take an average over the three patients, we would have a step function with steps of size 1/3 at the observed change points. Were we to target a level where 33% of subjects encounter a DLT, then we could estimate a point above dose d 3 and below dose d 4. This would of course be a rough estimate, since three patients may not be enough to capture the effects of a much larger group. However, as we include bigger samples, we can conceive of the simple step function for three patients becoming more refined and eventually looking something like Figure 2. In practice, we will not know such a curve and the problem is to find the dose d i such that some given percentage of patients will encounter a DLT at this dose and higher doses. Technically, our problem is to inverse the curve in Figure 2. This inversion would tell us which dose corresponds to some given rate of toxicity.

---

### Structure and function of a neocortical synapse [^73c0b204]. Nature (2021). Excellent credibility.

In 1986, electron microscopy was used to reconstruct by hand the entire nervous system of a roundworm, the nematode Caenorhabditis elegans 1 . Since this landmark study, high-throughput electron-microscopic techniques have enabled reconstructions of much larger mammalian brain circuits at synaptic resolution 2,3 . Nevertheless, it remains unknown how the structure of a synapse relates to its physiological transmission strength-a key limitation for inferring brain function from neuronal wiring diagrams. Here we combine slice electrophysiology of synaptically connected pyramidal neurons in the mouse somatosensory cortex with correlated light microscopy and high-resolution electron microscopy of all putative synaptic contacts between the recorded neurons. We find a linear relationship between synapse size and strength, providing the missing link in assigning physiological weights to synapses reconstructed from electron microscopy. Quantal analysis also reveals that synapses contain at least 2.7 neurotransmitter-release sites on average. This challenges existing release models and provides further evidence that neocortical synapses operate with multivesicular release 4-6 , suggesting that they are more complex computational devices than thought, and thereforeÂ expanding the computational power of the canonical cortical microcircuitry.

---

### Theoretically meaningful models can answer clinically relevant questions [^f4a24fb4]. Brain (2019). Medium credibility.

This scientific commentary refers to â€˜The ease and sureness of a decision: evidence accumulation of conflict and uncertaintyâ€™, by Mandali et al. (doi:).

One of the most dominant models of human decision-making over the past decades has been the diffusion model (;). However, the diffusion model may not be familiar to all readers of Brain, as the model has primarily been applied within the field of cognitive psychology. The diffusion model proposes that decision-making results from an internal process of sequential evidence accumulation, where each potential choice alternative accumulates evidence from the environment over time, until the evidence for one alternative reaches some threshold level of evidence that triggers a decision. Importantly, the diffusion model can decompose the accuracy and time taken for each decision into latent parameters from the underlying decision-making process, most notably drift rate, decision threshold, and non-decision time. The drift rate parameter is the rate of evidence accumulation, with faster accumulation indicating better ability. The decision threshold parameter is the amount of evidence required to trigger a decision, with higher decision thresholds indicating greater caution. The non-decision time parameter represents the time taken up by processes such as perceptual encoding and motor responding. These latent parameters allow researchers to directly assess changes in the components of the underlying cognitive process, rather than attempting to indirectly infer changes from the raw observed variables, such as accuracy and mean response time. A schematic overview of the diffusion model is provided in Fig. 1.

---

### Model-free decision-making underlies motor errors in rapid sequential movements under threat [^67954aa5]. Communications Psychology (2024). Medium credibility.

Two-step sequential movement task

Figure 1 illustrates the two-step sequential-movement task. The design of the task is based on past studies, and consists of two stages. In stage 1, participants encounter one of two states: â€˜Facesâ€™ or â€˜Objects'. The choices made at stage 1 deterministically decide the subsequent state at stage 2, which could be either â€˜Body Partsâ€™ or â€˜Scenes'. Notably, the available choices in the two states (Faces or Objects) in stage 1 are similar: selecting one of the tools (depicted in Fig. 1C on the right) or one of the faces (depicted in Fig. 1C on the left) always results in the same set of Scenes, while choosing the other tool or face leads to Body Parts. This equivalent structure helped us distinguish between model-based and model-free decision-making strategies, as only model-based learners can generalise their experiences across equivalent options at stage 1. Model-based learners utilise estimations of the expected outcomes for each option in stage 2 to determine their respective values in stage 1. Consequently, the impact of each second-stage outcome on stage 1 preference in subsequent trials remains the same, irrespective of whether the new trial begins with the same state as the previous one (e.g. faces followed by faces) or a different state (e.g. faces followed by objects). In contrast, a model-free learner evaluates options based solely on their past outcomes: the outcomes obtained from one starting state does not influence subsequent choices from the other starting state.

---

### Rapid, systematic updating of movement by accumulated decision evidence [^34a521b6]. Nature Communications (2024). High credibility.

A joint model of decision-making and motor trajectories

We formalized our observations about the impact of the prior and stimulus evidence onto response trajectories into a computational model that ties the dynamics of a latent decision variable mechanistically with the animalâ€™s orienting trajectory (Fig. 5). The model sets apart from traditional decision-making models by fully describing the dynamics of the orienting response, and not just its endpoint. It consists of a decision-making module and a motor module that reads the accumulated evidence at two discrete time points. The decision-making module extends the classical Drift-Diffusion Model,,â€“ whereby a decision variable, x (t), initialized at a value proportional to the prior evidence, integrates sensory evidence over time. When one of two decision bounds is reached, the associated side is selected. Crucially, the decision-making module includes an urgency process (Fig. 5a, top) that can initiate movement independently of the decision variable, thus accounting for the prevalence of express responses, (Fig. 1c). When the urgency process triggers the response movement onset, the targeted port of the initial trajectory is set by the sign of the decision variable at this moment (x 1). We refer to x 1 as the first read-out (Fig. 5a, empty circle). Importantly, the vigor of the initial trajectory depends on the value of x 1 : the more evidence towards the selected port, the faster the trajectory (Fig. 5b ; â€œMethodsâ€ Eq. 1). Accordingly, when the response movement onset is triggered by the decision variable hitting one of the decision bounds (x 1 =â€‰Â± Î¸), the initial response has maximum vigor. In either case, due to afferent and efferent delays, there is still sensory information in the processing pipeline at the movement onset. This information is incorporated into the movement in a second read-out x 2 (Fig. 5a, filled circles), that takes place once the whole stimulus evidence is fully integrated, allowing for the possibility to update the response trajectory. Specifically, the trajectory is sped up or slowed down if the evidence towards the initial choice increases with respect to the first read-out (i.e. | x 2 |â€‰>â€‰| x 1 |) or decreases (| x 2 |â€‰<â€‰| x 1 |), respectively (Fig. 5c ; â€œMethodsâ€ Eq. 2). When the decision variable accumulates enough evidence against the initial choice, hitting a specific bound (Î¸ CoM), the decision is reversed: a new ballistic trajectory is drawn toward the opposite port, implementing a change of mind (Fig. 5a, bottom, yellow trace). Note that, while in the model we can identify all CoMs, only a subset of those will be classified as trajectory reversals using the detection method based on trajectory deflections as in rats. Trajectories were generated using the principle of minimum jerk, to ensure smoothness, and had only two parameters: the targeted port and MT (â€œMethodsâ€). Therefore, their updating came down to drawing a new trajectory that smoothly continued the initial one, but in which either the remaining MT was shortened or extended (vigor update), or the final target was switched (CoM). Although relatively complex, most of the properties of the model are derived from the previous observations (see Table 1 for an explicit link between observations and model features).

---

### Measuring the effects of particle orientation to improve the efficiency of electron cryomicroscopy [^e9c1dcac]. Nature Communications (2017). Medium credibility.

To understand how efficiency relates to other factors that bear on the ultimate resolution of a reconstruction, we calculate how the mean resolution scales with number of particles, for different values of B (image quality), and E od (efficiency), by extending the theory of image contrast and resolution vs. particle number developed previously. The loss of contrast at high resolution is modelled by a Gaussian fall-off in the recorded Fourier amplitudes and the resolution limit is determined by the intersection of the average amplitude with the noise level, which scales inversely with the root of the number of particles. The result is shown in Fig. 1k. First, it is clear that the image quality, here taken as the B -factor, is the most important determinant of the resolution achieved for the currently practical number of particle images in a data set (10 4 â€“10 6 asymmetric views). The new generation of electron detectors improve image quality and, therefore, reduce the number of particles required to reach a particular resolution. Still, if there is insufficient Fourier space coverage, even a large data set will fail to reach high resolution, as indicated in Fig. 1k. Further, given a data set, one can use this theory to estimate the number of particles required to reach a particular resolution. Thus, one can rationally decide if it would be better to collect more data to reach a desired resolution or instead try to improve the efficiency through the use of specimen tilt or other specimen supports or preparation methods.

Optimal tilt angles for data collection

We also include an algorithm for predicting tilt angles for data collection, which will improve the efficiency and the resolution of a data set. This is based on finding the minimum tilt angle that rotates the direction of highest resolution in the PSF to the direction of lowest resolution, and includes a model of contrast loss at tilt where the contrast is proportional to the cosine of the tilt angle. We demonstrate this improvement experimentally (Supplementary Fig. 2); while tilting the specimen can help in some instances, it cannot overcome the problems of reduced image quality at tilt, which is ultimately the more important factor in determining the resolution of a reconstruction (Fig. 1k). Tilting also cannot ameliorate the potentially destructivemoleculeâ€“surface interactions indicated by an anisotropic orientation distribution. These can cause deformation or degradation of the specimen that cannot be compensated for in the imaging and reconstruction process.

---

### Fluctuation-learning relationship in recurrent neural networks [^9c37d8ae]. Nature Communications (2025). High credibility.

The random asymmetric network model has a random asymmetric Gaussian matrix J as the initial connectivity. This model is the same as the random symmetric network model except for the constraint of J i j = J j i. This network still satisfies the full-rank assumption.

The pre-embedded network model has the connectivity matrix J represented in Eq. (14), which is composed of the targets Î¾ Î¼ and the inputs Î· Î¼ (Î¼ =Â 1,. Î± N). We set the input and target patterns to be random as given by Â Â± binary vectors whose elements are generated according to the probability distributions P (Î¾ i =â€‰Â±1)â€‰= P (Î· i =â€‰Â±1)â€‰=â€‰0.5.

This network model has the target Î¾ Î½ as a fixed point in the presence of the associated input Î· Î½ (see previous papersfor details of the neural dynamics), as roughly shown below. It is shown that J Î¾ Î½ = Î¾ Î½ âˆ’ Î· Î½ and J Î· Î¼ = Î¾ Î¼ âˆ’ Î· Î¼ if all patterns of { Î¾ Î¼ } and { Î· Î¼ } are mutually orthogonalized. Otherwise J Î¾ Î½ = Î¾ Î½ âˆ’ Î· Î½ + O (Î± 1/2) and J Î· Î¼ = Î¾ Î¼ âˆ’ Î· Î¼ + O (Î± 1/2), where the last terms of the order of Î± 1/2 remains due to the interference between { Î¾ Î¼ } and { Î· Î¼ }. O (Î± 1/2) is evaluated byfor J Î¾ Î½ andfor J Î· Î¼, respectively. Therefore, when Î± is sufficiently small, the interference terms are negligible so that we obtain J Î¾ Î¼ + Î³ Î· Î¼ ~ Î¾ Î¼ +â€‰(Î³ âˆ’â€‰1) Î· Î¼ and, consequently, the target Î¾ Î¼ is a fixed point in the presence of Î· Î¼ with Î³ =â€‰1 for Î² â†’ âˆž, based on the properties of, which holds for all Î¼. With the increase in Î±, these interference terms increase, and the fixed points of the targets are unstable.

---

### Mutualism supports biodiversity when the direct competition is weak [^da37e8a2]. Nature Communications (2017). Medium credibility.

for Î” 0 = Î· c âˆ’0.05 and Î” 1 = Î· c +0.05.

For obligatory mutualism we have to consider that the plant abundance after the perturbation must remain large enough so that allare positive. Thus, it is not justified to neglect the change in equilibrium abundances because of the perturbation. We consider the worst case of an animal species i that only feeds on a single plant k. Positivity ofrequires that

whereis the saturation factor after the perturbation. To focus on the saturation factor, we neglect changes of the term, whose value before the perturbation is, and we obtain the inequality

whereis the minimum plant abundance after the perturbation that can maintain the animal species, that is, the minimum abundance such that the above inequality holds, which we want to estimate, and we neglected terms of orderand. Multiplying both sides times N k (P), usingand approximating the abundances with the average over the community,and, we can estimate the minimum plant abundance as

Equation (17) estimates the minimum abundance of plants in equation (13), while for animals we can consider=0 since we set the unperturbed abundances such that. Using the fact that Î· is a linear function of Î”, Î· = Î· v +Î” Î· â€², we find from equation (13)

whereis the fraction of plant species that are the only connection of at least one animal species in obligatory mutualism. The quantity/< N (P) > is indicated asin the main text. Finally,.

Predicting the propagation of perturbations

In equation (4), the propagation of perturbations Î· â€² is numerically computed through eqution (14). We can predict it analytically in the same approximation used above. We consider perturbations Î± i â†’ Î± i (1+Î” r i), where r i are independent random variables with normal distribution. The effective growth rate is= Î± i + m i and we neglect changes of m i =(1/ h i)(z i /(1+ z i)) 2 on perturbation. The productivity after perturbation is p i (Î”)=+Î” q i, where q i is a Gaussian variable with mean zero and variance

where G = Î³ LV(P) (Î² (A)) âˆ’1. To estimate Î· â€², we compute Î· i (p (Î”)) at first order in Î”:

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^e491e7e8]. Kidney International (2024). High credibility.

Relative and absolute risks associated with chronic kidney diseaseâ€”risk relationship of eGFRcr versus eGFRcr-cys: For the 8 outcomes that are not influenced by changes in creatinine (all except kidney failure and AKI), eGFRcr exhibited a âˆª-shaped association such that risk increased with eGFR values over 105 ml/min per 1.73 m2, whereas eGFRcr-cys demonstrated much more linear associations with each of these complications throughout its distribution.

---

### The computational neurology of movement under active inference [^dd0d84f5]. Brain (2021). Medium credibility.

Figure 3 
Discrete generative model for movement planning. This schematic illustrates the hierarchical discrete state-space generative model that sits above the continuous model shown in Fig. 1. This model generates the hidden causes (v) that are the (imaginary) attracting points and the target locations from the perspective of the continuous model, which effectively induce movement. The discrete (categorical) causes that generate these come in two forms: the alternative attracting points (red spheres) that act as equilibrium points, and which of the three possible target locations is currently specified. These causes are themselves generated by states at a higher level. At the highest level (upper left) we have a set of alternative combinations of trajectories. Each of these is defined in terms of which vertex of a triangle (i.e. target location) is at the start and end of that trajectory. There are three configurations not shown that represent a single vertex of the triangle being the start and end of a trajectory (i.e. a static â€˜trajectoryâ€™). In addition, the higher level includes a replica of the three possible target states (upper right). However, while these are considered static at the timescale of the lower level, the slower dynamics of the higher level allow this to change over time. The key distinction here is the absence of arrows between alternative target configurations at the first level. The C -vector represents the statistics of a prior belief that policies will lead to correct outcomes (i.e. hand and target location match). This ensures sequences of actions that lead to the realization of this goal are more plausible than those that do not. The arrows within a level indicate the allowed transitions (encoded by B) between these configurations. The arrows between levels show the generation of lower level variables by higher level variables. This rests upon generation of a discrete outcome via A (2), which is then used to generate policies [via E (1)] or initial states [via D (1)]. The role of D (2) is to provide a prior belief about the initial states at the higher level. Note that, if we were to extend this model to include further levels, this would also become an empirical prior, recapitulating the role of D (1). However, given that Level 2 is the highest level considered here, D (2) is simply a vector of prior probabilities. This says that the target states may be in any initial configuration with equal probability and that the initial state probability is equally distributed among any of the trajectories that start at the lower-right target.

---

### COVID-19 epidemiology during delta variant dominance period in 45 high-income countries, 2020-2021 [^50e43148]. Emerging Infectious Diseases (2023). Medium credibility.

The SARS-CoV-2 Delta variant, first identified in October 2020, quickly became the dominant variant worldwide. We used publicly available data to explore the relationship between illness and death (peak case rates, death rates, case-fatality rates) and selected predictors (percentage vaccinated, percentage of the population >65 years, population density, testing volume, index of mitigation policies) in 45 high-income countries during the Delta wave using rank-order correlation and ordinal regression. During the Delta-dominant period, most countries reported higher peak case rates (57%) and lower peak case-fatality rates (98%). Higher vaccination coverage was protective against peak case rates (odds ratio 0.95, 95% CI 0.91-0.99) and against peak death rates (odds ratio 0.96, 95% CI 0.91-0.99). Vaccination coverage was vital to preventing infection and death from COVID-19 during the Delta wave. As new variants emerge, public health authorities should encourage the uptake of COVID-19 vaccination and boosters.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^990cb6a1]. Annals of the American Thoracic Society (2023). High credibility.

Ventilationâ€“perfusion heterogeneity metricsâ€”modeling descriptionâ€”states that regional V_A/Q heterogeneity can be described with simple functional models corresponding to a few compartments and a narrow unimodal V_A/Q distribution; small-length scale heterogeneity develops in disease and under mechanical ventilation, resulting in heterogeneous V_A/Q distributions; and metrics include global heterogeneity and the second moments (log scale) of ventilation (LogSDV) and perfusion (LogSDQ) versus V_A/Q ratios distributions.

---

### KDIGO 2022 clinical practice guideline FOR the prevention, diagnosis, evaluation, and treatment of hepatitis C in chronic kidney disease [^f1b907bc]. Kidney International (2022). High credibility.

Albuminuria and proteinuriaâ€”category thresholds across measures are defined for normal to mildly increased (A1), moderately increased (A2), and severely increased (A3). Albumin excretion rate (AER, mg/d) uses <30, 30â€“300, and >300; protein excretion rate (PER, mg/d) uses <150, 150â€“500, and >500. Albumin-to-creatinine ratio (ACR) thresholds are <3, 3â€“30, and >30 mg/mmol and <30, 30â€“300, and >300 mg/g. Protein-to-creatinine ratio (PCR) thresholds are <15, 15â€“50, and >50 mg/mmol and <150, 150â€“500, and >500 mg/g. Protein reagent strip interpretations align as Negative to trace, Trace to positive, and Positive or greater. Relationships among measurement methods are stated as not exact and are based on an average creatinine excretion of ~1.0 g/d or 10 mmol/d, with an exact conversion from mg/g to mg/mmol by multiplying by 0.113, and the urine concentration affects the reagent strip relationship.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^6e468ce5]. Annals of the American Thoracic Society (2023). High credibility.

General principles of biophysical computational modelsâ€”biophysical computational models can be used for forward simulations of function or inverse identification of system structure and parameters. Forward models are described as useful for sensitivity analyses to evaluate the contribution of normal subject variability to imaging metrics to define a threshold for abnormal and can also predict emergent behavior after parameter changes at the cellular or tissue level. Inverse models are described as useful for deriving information that cannot be measured directly, including distributions of airway or vascular obstruction that produce specific VË™A/QË™ patterns. Both forward and inverse models can be used to analyze, interpret, and predict.

---

### Reconciling time and prediction error theories of associative learning [^fff47e27]. Nature Communications (2025). High credibility.

With appropriate constraints on c Î¼, the gating signal a Î¼ and the basis functions Ï• Î¼, we show that Eq. (6) is a generic online kernel density estimation algorithm for learning distributions of intervals between two events (Methods). The kernel is specified by the choice of a Î¼ and Ï• Î¼. The update rule is consistent with an interpretation of the weight w Î¼ as encoding the estimated probability that the reward appears within the interval (Ï„ Î¼, Ï„ Î¼ +1). The sum âˆ‘ Î¼ w Î¼ in turn encodes the probability that reward does indeed appear after the stimulus (âˆ‘ Î¼ w Î¼ <Â 1 in a partial reinforcement paradigm).

We now show how the general update rule (6) can be used to derive a timescale invariant density estimator implementable in biological networks. Specifically, the gating signals a Î¼ s are derived from a set of eligibility traces Ïˆ Î¼ s associated with each stimulus (Supplementary Fig. 2 a). The eligibility traces for each stimulus (say c) are updated aswhere f c (t) represents the stimulus train corresponding to stimulus c. A downstream network implements a soft winner-take-all operation,. In the Î² â†’ âˆž limit, we find that Î” Ï„ Î¼ = k Ï„ Î¼ and k â‰ªÂ 1 imply a Î¼ (t)Â â‰ˆÂ 1 in the interval (Ï„ Î¼, Ï„ Î¼ +1) after the stimulus and 0 otherwise. Thus, a Î¼ (t) represents the activity of â€œtime cellsâ€ that are active in the interval Ï„ Î¼ to Ï„ Î¼ +1 after the stimulus is presented (Supplementary Fig. 2 b). In simulations, we use normalized gamma functions with scale parameter Ï„ Î¼ and a fixed shape parameter as basis functions Ï• Î¼.

To derive an update rule for learning causal associations, we observe that the log likelihood L n after n trials can generally be written as. Based on this recursive equation, we propose an update rule for the relative log likelihood (â„“ c) that the stimulus c is causal:whereis a small constant that determines how many past events are averaged over when estimating â„“ c. The pre-factor f r (t) in equation (8) indicates that the causal association is updated whenever the reward appears.

---

### Ptychographic electron microscopy using high-angle dark-field scattering for sub-nanometre resolution imaging [^f40cbf1c]. Nature Communications (2012). Medium credibility.

Diffractive imaging, in which image-forming optics are replaced by an inverse computation using scattered intensity data, could, in principle, realize wavelength-scale resolution in a transmission electron microscope. However, to date all implementations of this approach have suffered from various experimental restrictions. Here we demonstrate a form of diffractive imaging that unshackles the image formation process from the constraints of electron optics, improving resolution over that of the lens used by a factor of five and showing for the first time that it is possible to recover the complex exit wave (in modulus and phase) at atomic resolution, over an unlimited field of view, using low-energy (30keV) electrons. Our method, called electron ptychography, has no fundamental experimental boundaries: further development of this proof-of-principle could revolutionize sub-atomic scale transmission imaging.

---

### A topological fluctuation theorem [^0a82bf95]. Nature Communications (2022). High credibility.

Let us now consider trajectories for which the initial and final points share the same radial and axial coordinates: Î” r =â€‰Î” z =â€‰0, while the total winding angle Î” Ï• remains arbitrary. In case I where the potential is isotropic (Î± =â€‰1) and its ground state coincides with the vortex core (x c =â€‰0), Î” U is independent of the winding angle Î” Ï• such that the probability ratio Ï‘ averaged over trajectory time and initial positions follows the predicted exponential scaling for all winding angles (see orange line in Fig. 2 f). In general, however, Î“ is affected by the symmetries of the trap such that Ï‘ does not decay exponentially with the winding angle Î” Ï•. Setting Î± â‰ â€‰1 (case II, Fig. 2 d), Î” U depends explicitly on Î” Ï• and vanishes only for Î” Ï• = n Ï€. Consequently, the averaged winding angle probability ratio departs from the exponential scaling for all Î” Ï• not multiple of Ï€ (see red line in Fig. 2 f). Moreover, in the third case of an isotropic harmonic potential, but whose minimum is shifted of x c â‰ â€‰0 (Fig. 2 e), the winding angle probability ratio shows similar oscillations as in case II, except that due to the lack of reflection symmetry of U those are 2 Ï€ -periodic (blue line in Fig. 2 f). In all cases, thanks to the topological protection offered by closed loops the data shown in Fig. 2 f systematically falls on the predicted exponential curve for Î” Ï• integer factor of 2 Ï€.

The multi-vortex case

To simplify the following analysis and allow for the study of fixed time trajectories, we now consider the case where the potential U (r) acts as a stiff wall confining the particles inside a cylinder of radius R and such that U =â€‰0 inside of the cylinder. For such confinement and a single vortex line located at r =â€‰0, we find that for t â‰ª R 2 / D the distribution p (Ï•, t) exhibits exponential tails, while for t â‰« R 2 / D the effect of confining boundaries leads to p (Ï•, t) being Gaussian (see Fig 2 c). As expected from Eq. (13), in this case one can set Î” U =â€‰0 and the fluctuation theorem is found to hold at winding angles for all observation times, independently of the particular shape of the distribution.

---

### Developing clinical prediction models: a step-by-step guide [^52143837]. BMJ (2024). Excellent credibility.

Step 9: Assess the performance of prediction models

General concepts in assessing model performance

We assess the predictive performance of the modelling strategies explored in step 8. Specifically, we contrast predictions with observed outcomes for people in a dataset to calculate performance measures. For continuous outcomes like blood pressure this is straightforward: observed outcomes can be directly compared with predictions because they are on the same scale. When dealing with binary or survival outcomes, the situation becomes more complex. In these cases, prediction models might give the probability of an event occurring for each individual while observed outcomes are binary (event or no event) or involve time-to-event data with censoring. Consequently, more advanced methods are required.

Dimensions of prediction performance

Prediction performance has two dimensions, and it is essential to assess them both, particularly for binary and survival outcomes (see glossary in table 1).

Discriminationâ€”for continuous outcomes, discrimination refers to the modelâ€™s ability to distinguish between patients with different outcomes: good discrimination means that patients with higher predicted values also had higher observed outcome values. For binary outcomes, good discrimination means that the model separates people at high risk from those at low risk. For time-to-event outcomes, discrimination refers to the ability of the model to rank patients according to their survival; that is, patients predicted to survive longer survived longer.
Calibration relates to the agreement between observed and predicted outcome values.For continuous outcomes, good calibration means that predicted values do not systematically overestimate or underestimate observed values. For binary and survival outcomes, good calibration means the model does not overestimate or underestimate risks.

Discrimination and calibration are essential when evaluating prediction models. A model can have good discrimination by accurately distinguishing between risk levels, but still have poor calibration owing to a mismatch between predicted and observed probabilities. Moreover, a well calibrated model might have poor discrimination. Thus, a robust prediction model should have good discrimination and calibration. Box 1 outlines measures for assessing model performance.

Box 1 
Measures of performance of prediction models for different types of outcomes

---

### Selecting fitted models under epistemic uncertainty using a stochastic process on quantile functions [^4d58a8e5]. Nature Communications (2025). High credibility.

Algorithm 2

Hierarchical beta process

Given, c and, â–¹ computed from data, â–¹ number of refinements, â–¹ 2-d distribution over end points

generate a discretized realisation.

Procedure:

â–¹ Initialise the procedure by drawing end point

1: repeat

2: draw

3: Until â–¹ PPFs must be increasing

â–¹ Successively refine the interval

4: for n âˆˆÂ 1,Â 2,Â â€¦, N do â–¹ refinement levels

5: for do â–¹ intermediate incrs.

6: compute r, v according to equations (73)

7: solve equations (75) to obtain Î± and Î²

8: draw x 1 ~Â Beta(Î±, Î²)

9:

10: end for

11: end for

12: return

The quantities r and v computed in Algorithm 2 conceptually represent the r atio between two sucessive increments and the v ariance of those increments.

Relevant concepts of Wiener processes

Before introducing the HB process, let us first review a few key properties which stochastic processes must satisfy and which are covered in most standard introductions â€“. We use for this the well-known Wiener process, and also introduce notation which will become useful when we define the HB process. Since our goal is to define a process for PPFs, we use Î¦ to denote the independent â€œdomainâ€ variable and restrict ourselves to 1-d processes for which Î¦ âˆˆÂ [0,Â 1].

For the Wiener process, each realisation is a continuous function. One way to approximate a realisation ofis to first partition the interval into subintervals [0, Î¦ 1),Â â€‰[Î¦ 1, Î¦ 2),Â â€‰â€¦,Â â€‰[Î¦ n,Â 1) with 0Â < Î¦ 1 < Î¦ 2 <Â â‹¯Â < Î¦ n <Â 1; for simplicity we will only consider equal-sized subintervals, so that Î¦ k = k Î” Î¦ for some. We then generate a sequence of independent random increments (one for each subinterval) {Î” W Î” Î¦ (0),Â â€‰Î” W Î” Î¦ (Î” Î¦),Â â€‰Î” W Î” Î¦ (2Î” Î¦),Â â€‰â€¦,Â â€‰Î” W Î” Î¦ (1Â âˆ’Â Î” Î¦)} and define the corresponding realisation as(Within each interval the function may be linearly interpolated, so that W is continuous.)

---

### Non-diffracting multi-electron vortex beams balancing their electron-electron interactions [^64c18fdb]. Nature Communications (2017). Medium credibility.

One of the most important applications of EBeams is electron microscopy, which has become an essential tool in many fields of science and technology, such as biology, materials science, electrical engineering and more. Scanning electron microscopy(SEM), transmission electron microscopy(TEM) and scanning transmission electron microscopy (STEM) produce images by scanning a sample with a focused EBeam or transmitting an EBeam through the sample. The EBeam interacts with the sample and produces an image containing information that is often at atomic resolution.

Importantly, the fundamental limit on the highest resolution possible in electron microscopy is the wavelength of the particle, which for electrons is on the order of picometers (10 âˆ’12 m). In practice, however, state-of-the-art electron microscopes are still 2â€“3 orders of magnitude away from this fundamental limit, in spite of the recent advances in correcting aberrations. There are several reasons limiting the resolution of electron microscopes,, among them the interaction between electrons,, which is called the space-charge effect. This effect is currently the dominant resolution barrier in time-resolved electron microscopy â€“. Moreover, with the recent technological improvements in electron microscopy, the space charge effect is likely to remain the last fundamental issue constraining the resolution limit. Of course, when the density of the electrons in the beam is low enough, this effect becomes negligible. However, working with one electron at a timeimplies longer integration times in the detection process to obtain a reasonable signal-to-noise ratio (SNR). This space charge effect is of even greater importance in low-voltage electron microscopes, which are now becoming more popular. There, electronâ€“electron interaction is already preventing an even lower acceleration voltages. Moreover, in the past few years, novel experiments employ ultrashort pulses of electrons in microscopy, triggered by ultrashort pulses of light. These ultrashort pulses of electrons correspond to high electron density, which fundamentally limits the resolution due to space charge field effects,,.

---

### Article 5. An introduction to estimation â€“ 2: from z to T [^fb82b806]. Emergency Medicine Journal (2001). Low credibility.

Provided the sample size is large enough (that is, n greater than 100), the z statistic can be used to determine the confidence interval estimation of the population mean even when the sigma is not known. In these cases the estimation of the standard error of the mean is used. The z statistic is also valid when determining the population's proportion based upon a large sample. However, when dealing with smaller samples, the z statistic is replaced by the t statistic. This makes it possible to estimate, in a population with an unknown standard deviation: The probability of getting a sample mean greater than or equal to a particular value The value of a sample mean with a particular probability of occurring The probability of getting a sample mean between two particular values The confidence interval for the estimation of the population mean can also be determined using the t statistic.

---

### Transmission electron microscope (TEM) [^8854e8a2]. CDC (2024). Medium credibility.

Transmission Electron Microscope On display is a powerful microscope: the electron microscope. This microscope, the TEM 410 Philips model, was made in the Netherlands and used in CDC labs from 1985-2005. This transmission electron microscope was purchased by CDC in 1985 to study the AIDS virus and over the next 20 years, scientists used it repeatedly in the rapid identification of emerging pathogens including hantavirus, Nipah virus, and SARS coronavirus. Take a closer look:
- Find high-resolution, public domain images of viruses/bacteria in CDCâ€™s Public Health Image Library, including transmission electron microscope images of coronaviruses and the hepatitis A virus.
- From where do up-close images of viruses and bacteria we see in the news come. Learn more from this National Institutes of Health article.
- View transmission electron microscope micrographs of rotavirus particles, the virus that causes rabies, variola virus particles, and poxvirus particles.

Then, take a look at what a transmission electron microscope looks like from the other side of the lens: in the 1960s and present day.
- Learn how to collect and prepare specimens for electron microscopy. From the source:
- Take a close look at how electron microscopy was used to confirm poxvirus infections during the smallpox eradication campaign.
- View a historic image of an electron microscope in use during 1988 laboratory studies of AIDS and a transmission electron microscopeimage of HIV from Global Health Chronicles, A CDC Museum/Emory University collaboration. Then and now:
- Learn how electron microscopy has aided CDC scientists in identifying the causative agents during critical infectious disease outbreaks.
- Read how transmission electron microscopy was used to understand molecular mechanisms of the severe acute respiratory syndrome, or SARS coronavirus outbreak in 2002.

---

### Improving local prevalence estimates of SARS-CoV-2 infections using a causal debiasing framework [^f0a11415]. Nature Microbiology (2022). High credibility.

Global and national surveillance of SARS-CoV-2 epidemiology is mostly based on targeted schemes focused on testing individuals with symptoms. These tested groups are often unrepresentative of the wider population and exhibit test positivity rates that are biased upwards compared with the true population prevalence. Such data are routinely used to infer infection prevalence and the effective reproduction number, R t , which affects public health policy. Here, we describe a causal framework that provides debiased fine-scale spatiotemporal estimates by combining targeted test counts with data from a randomized surveillance study in the United Kingdom called REACT. Our probabilistic model includes a bias parameter that captures the increased probability of an infected individual being tested, relative to a non-infected individual, and transforms observed test counts to debiased estimates of the true underlying local prevalence and R t . We validated our approach on held-out REACT data over a 7-month period. Furthermore, our local estimates of R t are indicative of 1-week- and 2-week-ahead changes in SARS-CoV-2-positive case numbers. We also observed increases in estimated local prevalence and R t that reflect the spread of the Alpha and Delta variants. Our results illustrate how randomized surveys can augment targeted testing to improve statistical accuracy in monitoring the spread of emerging and ongoing infectious disease.

---

### Reconciling time and prediction error theories of associative learning [^48b97bba]. Nature Communications (2025). High credibility.

A Bayesian framework for estimating interval distributions

We present our generative model and discuss algorithms for inference. In this model, there are C possible stimuli generated by a point process. Our goal is to predict when the rewarding stimulus, indexed by r, will appear next, based on the times at which stimuli have appeared in the agentâ€™s history. We assume that the rewarding stimulus r has a single cause, which we index as c. This causal stimulus c can be any one of the C stimuli, including r itself. The interval between r and its cause c is drawn probabilistically from a distribution described further below. We denote Îµ i as the logarithm of the ratio between the prior probability that stimulus i causes r and the prior probability that stimulus r causes itself. Clearly, Îµ r =Â 0.

We denote the posterior probability that stimulus i is the causal stimulus as Ï€ i. Following our terminology in the main text, we call Ï€ i the association of stimulus i to the reward r. After observing data, Ï€ i is given according to Bayesâ€™ rule aswhereis the log-likelihood of observing the data given that i is the cause, relative to the log-likelihood of observing the data given that r is the cause.

The reward r appears after cause c with probability p, where p is drawn from a Beta prior B (p ; a, b) with hyperparameters a and b. If r does appear after c, the interval t is drawn from a distribution Ï c. To sample the interval t ~ Ï c (t), we first sample an index Î¼ from a Dirichlet-multinomial distribution. Specifically, Î¼ (ranging from 1 to K) is drawn from a multinomial distribution with class probabilities q =Â (q 1, q 2,Â â€¦, q K). The probabilities q are in turn drawn from a Dirichlet prior D (Î±), where Î± =Â (Î± 1, Î± 2,Â â€¦, Î± K). Given the sampled index Î¼, we then draw t ~ Ï• Î¼ (t), where Ï• Î¼ (t) is a normalized probability density function defined below.

---

### A topological fluctuation theorem [^888dd8d2]. Nature Communications (2022). High credibility.

A detailed examination of this probability distribution reveals that it is strongly non-Gaussian. Indeed, for positive winding numbers p (n, t âˆ£ r 0) is asymptotically scale free: p (n, t âˆ£ r 0) n âˆ’3/2 (see Fig. 2 a), while, as a consequence of the fluctuation theorem (3), it decays exponentially as n â†’â€‰âˆ’ âˆž. This difference in scaling behaviors results in a strong asymmetry of the overall distribution between the positive and negative winding number sectors (see Fig. 2 b).

Fig. 2 
The topological fluctuation theorem for a single vortex.

a The exact winding number distribution for a free vortex exhibits a power law scaling for large positive n values. b At all times t and initial radial position r 0, the ratio of negative to positive winding number distributions maps onto the theoretical prediction (3) (inset) resulting in an exponential scaling of p (n, t âˆ£ r 0) for large negative windings (caption in panel a). c In the presence of boundaries restricting the particle motion with diffusivity D inside a disk of radius R and outside the vortex center, the winding angle distribution shows exponential tails at small times (red curve, D t / R 2 =â€‰0.1), while it becomes Gaussian for larger t (blue curve, D t / R 2 =â€‰10). The theorem holds irrespectively of the shape of the distribution (inset, the orange curve corresponds to D t / R 2 =â€‰1). d, e Representative trajectories corresponding to cases II and III discussed in the text. f The probability ratio (14) averaged over initial positions r 0 and trajectory times t as function of the total winding angle Î” Ï• for the three cases (case I corresponding to isotropic confinement) discussed in the text and Î” r =â€‰Î” z =â€‰0. In a, b Î³ =â€‰2 Ï€, while in c â€“ e Î³ =â€‰0.1â€‰Ã—â€‰2 Ï€. In d â€“ f we used k B T / k =â€‰10, while for case II (resp. III) Î± =â€‰0.5(1) and x c =â€‰0(4).

---

### KDIGO clinical practice guideline for the care of kidney transplant recipients [^2cd3ee78]. American Journal of Transplantation (2009). Medium credibility.

KDIGO GRADE system for grading quality of evidenceâ€”structure and upgrade/downgrade rulesâ€”starts by study design (Randomized trials = High; Observational study = Low; Any other evidence = Very Low), allows reductions for study quality, consistency, directness and other limitations with specified level changes, and allows raises for strength of association or other factors, with strong and very strong associations defined by risk ratio thresholds. Specifically, reductions include â€œâˆ’1 level if serious limitationsâ€ or â€œâˆ’2 levels if very serious limitations,â€ â€œâˆ’1 level if important inconsistency,â€ â€œâˆ’1 level if some uncertaintyâ€ or â€œâˆ’2 levels if major uncertainty,â€ and â€œâˆ’1 level if sparse or imprecise dataâ€ or â€œâˆ’1 level if high probability of reporting bias.â€ Raises include â€œ+1 level if strong,a no plausible confoundersâ€ or â€œ+2 levels if very strong,b no major threats to validity,â€ plus â€œ+1 level if evidence of a dose response gradientâ€ or â€œ+1 level if all residual plausible confounders would have reduced the observed effect.â€ Strong and very strong associations are defined as â€œsignificant RR of >2 (<0.5)â€ and â€œsignificant RR of >5 (<0.2),â€ respectively.

---

### Exploring the biological hallmarks of cancer of unknown primary: where do we stand today? [^8ac28076]. British Journal of Cancer (2020). Medium credibility.

The pathogenesis of CUP

According to current understanding, the process of tumorigenesis involves the consecutive sequence of clonal proliferation, invasion and intravasation of cancer cells from the primary tumour, dissemination through the circulation, extravasation in different organs and colonisation at metastatic sites (Fig. 1).

Fig. 1 
The successive steps in the carcinogenesis of CUP.

Clonal proliferation arises directly from normal stem cells or non-stem cells acquiring DNA alterations that result in the activation of stem-cell programmes according to a type 2 progression, which assumes the acquisition of a malignant phenotype directly without developing premalignant lesions.Some of these cells are stationary, leading to local tumour growth, whereas others are mobile, yielding distant metastasis.In the context of CUP, metastasis might occur before local tumour growth as a consequence of two scenarios (Fig. 1). In the first scenario, mobile cells spread at an early stage to metastatic sites and alter their microenvironment, leading to metastasis before the generation of a detectable primary tumour or even transformation into a malignant stage at the primary site. This theory is supported by the parallel progression model, with tumour cells showing independent genetic alterations at the primary tumour site and metastatic sites.In the second scenario, metastasis occurs without parallel progression, with the tumour microenvironment selectively favouring the outgrowth of tumour cells at the metastatic site, while it abrogates the growth of these genetically identical cells at the primary site. This hypothesis is supported by the existence of a clonal relationship between cells at the primary and metastatic sites.

---

### A behavioural science framework for tackling upstream challenges in health systems [^d920320e]. BMJ Global Health (2025). High credibility.

Phase 1: distill the system-level challenge into priority behaviours

Behavioural science offers insights into what drives behaviour; to apply it to health system challenges, it is necessary first to distill those challenges into one or more priority behaviours. This can be done systematically in four steps:

Identify an outcome of interest

The outcome should typically be defined broadlyâ€“to decrease maternal mortality or to reduce inequity in service access, for example. The answer to the question â€˜how will I define success from this effort?â€™ guides application of the framework to where a behavioural approach may be most impactful.

Describe changes within the system that create a pathway to achieve the outcome

In some instances where programme or policy goals are narrowly defined, this pathway may be apparent from the outset, for example, decreasing the frequency of stock-outs of a commodity, increasing resource allocation to a community health initiative or facilitating adoption of a high-impact practice. In other cases, a range of plausible pathways might be considered. When prioritising between pathways, it is important to consider both the significance of each pathway to the outcome of interest and to what extent it is (or might be) possible to intervene.

Identify the behaviours implicit in the pathway(s)

This means identifying who needs to act and what actions they must engage in to influence the outcome through the prioritised pathway(s). Often, several behaviours will contribute to each pathway, and one behaviour may be necessary or advantageous to encourage another. See figure 2 for an example.

Figure 2 
Phase 1 of Framework.

Defining which actors must engage in which actions is critical to seeing a complex challenge through a behavioural lens. No matter how complex the issue or how structural or systemic it may seem, it can be distilled to one or more people who are making decisions and engaging in actions that together contribute to that reality. Defining these behaviours does not reduce the complexity of the problem but offers a way forward to systematically address that complexity.

Prioritise among behaviours

Often, it will not be practical to address all of the relevant behaviours. Prioritisation among behaviours should consider the potential for impact by influencing each behaviour as well as political will, resources, timeline and connections to other priority behaviours. This prioritisation does not indicate a judgement about which behaviours or actors are most important, but instead an assessment of where a careful investigation is likely to generate the greatest value for policy, programme or service changes.

---

### Technology readiness levels for machine learning systems [^466752e9]. Nature Communications (2022). High credibility.

Level 2â€”Proof of Principle (PoP) development

Active R&D is initiated, mainly by developing and running in testbeds : simulated environments and/or simulated data that closely matches the conditions and data of real scenariosâ€”note these are driven by model-specific technical goals, not necessarily application or product goals (yet). An important deliverable at this stage is the formal research requirements document (with well-specified verification and validation (V&V) steps). A requirement is a singular documented physical or functional need that a particular design, product, or process aims to satisfy. Requirements aim to specify all stakeholdersâ€™ needs while not specifying a specific solution. Definitions are incomplete without corresponding measures for verification and validation (V&V). Verification: Are we building the product right? Validation: Are we building the right product? Here is one of several key decision points in the broader process: The R&D team considers several paths forward and sets the course: (A) prototype development towards Level 3, (B) continued R&D for longer-term research initiatives and/or publications, or some combination of A and B. We find the culmination of this stage is often a bifurcation: some work moves to applied ML, while some circles back for more research. This common MLTRL cycle is an instance of the non-monotonic discovery switchback mechanism (detailed in the â€œMethodsâ€ section and Fig. 3).

Fig. 3 
In the left diagram we show a discovery switchback (dashed) from 3 to 2, and an embedded switchback (solid) from 4 to 2.

The difference is the former is circumstantial while the latter is predefined in the process. The other embedded switchback we define in the main MLTRL process is from level 9 to 4, shown in Fig. 4. While it is true that the majority of ML projects start at a reasonable readiness out of the box, e.g. level 4, this can make it challenging and problematic to switchback to R& D levels that the team have not encountered and may not be equipped for. In the right diagram we show a common review switchback from Level 5 to 4 (staying in the prototyping phase (orange)), and a switchback (faded) that should not be implemented because the prior level was not explicitly done; level 2 is squarely in the research pipeline (red).

---

### Direct imaging of electron density with a scanning transmission electron microscope [^c9c6f699]. Nature Communications (2023). High credibility.

In light of these comments, it is worth explicitly pointing out that reabsorption of electrons can also occur. An SE emitted by an atom can be recaptured by the surrounding material resulting in zero net emission and this is therefore not detected in the SEEBIC signal. This phenomenon is typically captured theoretically by using a parameter called the â€˜escape depthâ€™, which decays exponentially with the emission depth in the material,. The physical justification for the use of such a parameter is obvious, however, the derivation of such a parameter from a bulk, homogeneous, and continuous material raises questions about the applicability to highly localized and atomically resolved images of 2D materials, where the information being observed is discontinuous and heterogeneous in nature. Nevertheless, the assumption that this reabsorption process has some influence over the observed image intensity is well grounded, the details of which should be explored in the future. Here, we merely point out that any atomic scale reabsorption variations arising from, for example, emission direction and the crystallographic orientation of the overlayers, is mitigated in large part by the averaging procedure due to the larger area represented by the sampling.

Theoretical approach to atomically resolved SEEBIC

This brings us to a more general concern with the understanding of SEEBIC image intensity. We have presented the SEEBIC intensity, thus far, from the view of individual ionization events. But, historically, this has not been the standard approach to treating this phenomenon. The theory of secondary electron (SE) emission from a variety of materials and primary beam energies has been studied from a macro-scale (that is, non-atomistic) perspective for understanding, among other things, the contrast observed in scanning electron microscopes (SEMs),. These treatments leverage material properties such as work function, Fermi energy, mean free path length, etc. that consider a material as a single uniform block and were developed, generally speaking, to describe thick materials where the primary electrons (or other high-energy particles) lose and transfer energy as they propagate through the material. Clearly, such descriptions begin to breakdown in the limit of 2D materials and with atomically resolved experiments where the emission from a single atom can be directly compared to the emission from its neighbor in the same material. This is the same issue that arises when considering escape depth at an atomic length scale.

---

### Core GRADE 1: overview of the core GRADE approach [^77e05af5]. BMJ (2025). Excellent credibility.

This first article in a seven part series presents an overview of the essential elements of the GRADE (Grading of Recommendations Assessment, Development and Evaluation) approach that has proved extremely useful in systematic reviews, health technology assessment reports, and clinical practice guidelines. GRADE guidance has appeared in many articles dealing with both core issues and more specialised and complex guidance, and it has evolved over time. This series of articles presents GRADE essentials, Core GRADE, focusing on the core judgments necessary to summarise the comparative evidence about alternative care options and to make recommendations that apply to the care of individual patients. This article presents detailed guidance on formulating questions using the PICO (population, intervention, comparison, outcome) structure, and refining the question considering possible differences in relative and absolute effects across patient groups. The article then provides an overview of the remainder of the Core GRADE approach, including decisions about the certainty of the evidence and considerations in moving from evidence to guidance and recommendations.

---

### Validating whole slide imaging for diagnostic purposes in pathology: guideline from the college of American pathologists pathology and laboratory quality center [^ddcb0ec9]. Archives of Pathology & Laboratory Medicine (2013). Medium credibility.

Supplemental Table 12â€”Evidence to Decision Summary of Recommendation 3 reports response distributions as follows: For â€œIs the problem a priority?â€, Yes was 70% (7/10) with 20% (2/10) Probably No, 10% (1/10) Probably Yes, and 0 for No, Varies, and Donâ€™t Know. For â€œHow accurate is the test?â€, Very Inaccurate 0, Inaccurate 10% (1/10), Accurate 30% (3/10), Very Accurate 30% (3/10), Varies 20% (2/10), and Donâ€™t Know 10% (1/10). For â€œHow substantial are the desirable anticipated effects?â€, Trivial 0, Small 0, Moderate 20% (2/10), Large 40% (4/10), Varies 20% (2/10), and Donâ€™t Know 20% (2/10). For â€œWhat is the overall certainty of the evidence of test accuracy?â€, Very Low 10% (1/10), Low 10% (1/10), Moderate 20% (2/10), High 40% (4/10), Very High 20% (2/10), and No Included Studies 0. For â€œWhat is the overall certainty of the evidence of effects of the management that is guided by the test results?â€, Very Low 10% (1/10), Low 20% (2/10), Moderate 30% (3/10), High 30% (3/10), Very High 10% (1/10), and No Included Studies 0. For â€œHow certain is the link between test results and management decisions?â€, Very Low 10% (1/10), Low 20% (2/10), Moderate 10% (1/10), High 40% (4/10), Very High 10% (1/10), and No Included Studies 10% (1/10). For â€œWhat is the overall certainty of the evidence of effects of the test?â€, Very Low 10% (1/10), Low 0, Moderate 40% (4/10), High 40% (4/10), Very High 10% (1/10), and No Included Studies 0. For â€œWhat is the overall certainty of the evidence for any critical or important direct benefits, adverse effects or burden of the test?â€, Very Low 10% (1/10), Low 20% (2/10), Moderate 30% (3/10), High 40% (4/10), Very High 0, and No Included Studies 0.

---

### Neighborhood characteristics and mental health from childhood to adolescence [^026220d2]. JAMA Network Open (2025). High credibility.

Y it ~â€‰Normal (Î¼ it,Ïƒ 2)

Î¼ it =â€‰Î± i +â€‰âˆ‘ p Î² p x it,p +â€‰âˆ‘ k Î³ t,k z it,k +â€‰interaction

Î± i ~â€‰N(Î¼ Î±,Ïƒ 2 Î±)

Î³ t,k ~â€‰N(Î¼ Î³,k,Ïƒ 2 Î³,k).

Here, Î± i is the individual-specific intercept, modeled by a normal distribution with mean Î¼ Î± and variance Ïƒ 2 Î±.The term âˆ‘ p Î² p x it,p captures the effects of individual- and household-level variables x it,p, each associated with a corresponding coefficient Î² p, where the set of coefficients is given by Î² 1, Î² 2, â€¦, â€¦ Î² p. The term âˆ‘ k Î³ t,k z it,k includes k time-varying neighborhood-level covariates z it,k, each linked to a coefficient Î³â€‰=â€‰Î³ t,1, Î³ t,2, Î³ t,3, Î³ t,k. For the fixed-effects Î², and hyperparameters Î¼ Î± and Î¼ Î³ we specified a Normal (0,1000) prior. For the variance parameters Ïƒ 2, Ïƒ 2 Î±, and Ïƒ 2 y,k we assumed an inverse-gamma (1,0.01) prior. This is equivalent to specifying a prior on precision (Ï„â€‰=â€‰1/Ïƒ 2) under the common bayesian framework, where Ï„ represents the reciprocal of the variance. We explored effect modification with sociodemographic factors by including various interaction terms between sex, ethnicity, and poverty and neighborhood-level exposures. We considered a prior Normal (0,1000) for the coefficient of the interaction terms.

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^87712576]. Kidney International (2024). High credibility.

CKD mineralâ€“bone parameters by albuminuria categoryâ€”figure context: The y axis represents the meta-analyzed absolute difference from the mean adjusted value at an eGFR of 80 ml/ min per 1.73 m^2 and albumin excretion <30 mg/g (<3 mg/mmol), with albuminuria categories defined as A1, albuminuria <30 mg/g (<3 mg/mmol); A2, albuminuria 30â€“300 mg/g (3â€“30 mg/mmol); and A3, >300 mg/g (>30 mg/mmol).

---

### Probing the symmetry of the potential of localized surface plasmon resonances with phase-shaped electron beams [^9117352a]. Nature Communications (2017). Medium credibility.

Plasmonics, the science and technology of the interaction of light with metallic objects, is fundamentally changing the way we can detect, generate and manipulate light. Although the field is progressing swiftly, thanks to the availability of nanoscale manufacturing and analysis methods, fundamental properties such as the plasmonic excitations' symmetries cannot be accessed directly, leading to a partial, sometimes incorrect, understanding of their properties. Here we overcome this limitation by deliberately shaping the wave function of an electron beam to match a plasmonic excitations' symmetry in a modified transmission electron microscope. We show experimentally and theoretically that this offers selective detection of specific plasmon modes within metallic nanoparticles, while excluding modes with other symmetries. This method resembles the widespread use of polarized light for the selective excitation of plasmon modes with the advantage of locally probing the response of individual plasmonic objects and a far wider range of symmetry selection criteria.

---

### New paradigm in dose-finding trials: patient-specific dosing and beyond phase I [^813baedb]. Clinical Cancer Research (2005). Low credibility.

We propose a new paradigm for the clinical evaluation of new cancer therapies. It entails adjusting the search for the optimal dose on the basis of measurable patient characteristics that may be predictive of adverse responses to treatment, and extending this search beyond phase I and into phases II and III. We provide examples of (a) how the fine-tuning of dose may involve utilization of patient-specific attributes to obtain a personalized treatment regimen, and (b) how novel methods for phase I design can be used to update the working dose for the conduct of phase II and III cancer clinical trials. These examples should be interpreted as an enticement for the development of new methods to implement the proposed new paradigm.

---

### Dynamically primed synaptic vesicle States: key to understand synaptic short-term plasticity [^b2b1ae6f]. Neuron (2018). Low credibility.

Based on evidence that the docked and primed synaptic vesicle state is very dynamic, we propose a three-step process for the buildup of the molecular machinery that mediates synaptic vesicle fusion: (1) loose tethering and docking of vesicles to release sites, forming the nucleus of SNARE-complex assembly, (2) tightening of the complex by association of additional proteins, and partial SNARE-complex zippering, and (3) Ca 2+ -triggered fusion. We argue that the distinction between "phasic synapses" and "tonic synapses" reflects differences in resting occupancy and stability of the loosely and tightly docked states, and we assign corresponding timescales: with high-frequency synaptic activity and concomitantly increased Ca 2+ -concentrations, step (1) can proceed within 10-50Â ms, step (2) within 1-5Â ms, and step (3) within 0.2-1Â ms.

---

### Controlling the pandemic during the SARS-CoV-2 vaccination rollout [^a6857413]. Nature Communications (2021). High credibility.

In addition, we explored Scenario 4 (Fig. 7) where measures are relaxed in a step-wise manner so that contact rates first rise to the level of Juneâ€“August 2020 (Step 1, Scenario 3), then to the level of Septemberâ€“October 2020 (Step 2, Scenario 2) and, finally, to the pre-pandemic level (Step 3, Scenario 1) (Fig. 7 b). The mid-points of transitions were 1 April, 1 June and 1 October 2021 (blue vertical lines in Fig. 7) and the relaxation speed of 10 days was used for all transitions. In this scenario, additional waves can be prevented altogether and hospitalizations stay at the level comparable to that in summer 2020 when the epidemic activity was low (Fig. 7 a). The number of hospitalizations in Scenario 4 is 2.2 times larger than in Scenario 3 (3194 vs 1450 from 1 April 2021 till 1 January 2022) and 2.8 times smaller than in Scenario 2 (3194 vs 8975 in the same time period) but the situation would still seem manageable for the healthcare system because the model does not predict sharp increases in hospital admissions. Most importantly, unlike in Scenarios 2 and 3 where contact rates stay reduced after 1 April 2021, the return to pre-pandemic contact patterns in Scenario 4 is gradual and the complete lifting of measures occurs on 1 October 2021 which would have important socio-economic consequences. Interestingly, Step 2 (1 June) and Step 3 (1 October) increase R e above 1 (Fig. 7 c) leading to waves of infections (Supplementary Fig. 5) but a large increase in hospitalizations is not observed because a substantial proportion of the vulnerable population has been vaccinated (Fig. 5). The full control of the pandemic (R e (t)â€‰<â€‰1 and pre-pandemic contact rates) is reached on 8 February 2022 (Fig. 7 c) when 36% of the population are protected after natural infection, 48% after vaccination, and 17% stay unprotected (Fig. 7 d). This is drastically different from Scenario 1, where the control was reached mainly due to protection through natural infection (60%), and the minority was protected by vaccination (10%).

---

### Clinical practice guidelines for hemodialysis adequacy, update 2006 [^5c74e315]. American Journal of Kidney Diseases (2006). Medium credibility.

Hemodialysis adequacyâ€”minimum singleâ€‘pool Kt/V (spKt/V) targets per treatment to achieve a weekly standard Kt/V (stdKt/V) of approximately 2.0 are stratified by residual urea clearance (K_r): for 2x/wk dialysis with K_r <2 mL/min/1.73 m2 it is Not recommended, whereas with K_r â‰¥ 2 mL/min/1.73 m2 it is 2.0*; for 3x/wk the minima are 1.2 (K_r <2) and 0.9 (K_r â‰¥ 2); for 4x/wk 0.8 and 0.6; and for 6x/wk (short daily) 0.5 and 0.4. Table 13 states these sessional targets correspond to â€œa weekly stdKt/V value of 2.0â€ in patients â€œundergoing 2 to 6 treatments per weekâ€ with adjustment for â€œa weekly K_r of 2 mL/minâ€; a â€œurea clearance of 2 mL/min is approximately 20 L/wkâ€ and with â€œV = 30 L, it represents about a 0.67 weekly Kt/V unit.â€ It is noted that â€œthe minimum values for spKt/Vâ€ do not account for outcome improvements when frequency â€œis increase to more than 3/wk.â€ The Work Group â€œrecommended targeting an spKt/V value that is about 15% higher than the recommended minimum targets,â€ developed a scheme that â€œlimited the downward adjustment in spKt/V for K_r to 2 mL/min,â€ and stated that â€œMaintaining a minimum â€˜total Kt/Vâ€™ value of 1.2 â€¦ would allow reduction of the dialysis dose down to near zero.â€

---

### Noxivent 102 [^511e12e1]. FDA (2025). Medium credibility.

3. DOSAGE FORMS AND STRENGTHS

Noxiventâ„¢ (nitric oxide) gas is available in 100 ppm and 800 ppm concentrations.

---

### Iterative quality improvement can occur faster than one element at a time [^2219d181]. The American Psychologist (2013). Low credibility.

Responds to the comments by S. Hamby and J. Grych (see record 2013-31242-011) on the current authors' original article, "Disruptive innovations for designing and diffusing evidence-based interventions" (see record 2012-10813-001). Hamby and Grych implied that the careful and systematic testing of one element at a time is a prerequisite to its application in service contexts. This is certainly one valid approach to generating such evidence and follows the dominant paradigm of current scientific norms. In fact, it would partially contribute to a more molecular and theory-based understanding of intervention efficacy than we currently have; however, we believe that the choice to apply elements of an intervention or to study them first is a false dichotomy given the real-world complexities of behavioral interventions, ongoing need for interventions to impact families currently in need, and funding environments.

---

### Ptychographic electron microscopy using high-angle dark-field scattering for sub-nanometre resolution imaging [^f865581a]. Nature Communications (2012). Medium credibility.

By the standards of conventional TEM, we use a very low accelerating voltage (30 keV). For many years, the main strategy for improving TEM resolution was to work at high voltage, thus decreasing the electron wavelength. A typical medium performance TEM (no aberration correction) working at 200 keV can routinely achieve just under a 0.2-nm resolution. However, at these energies, the electrons have sufficient momentum to displace atoms into interstitial sites or completely out of the specimen, creating 'knock-on' damage. For the lightest elements, such as carbon, atoms can be displaced with an electron energy of only 50 keV (ref.). An advantage of low electron energy, which we exploit here, is that the cross-section of interaction with the atomic potential increases, so that the diffraction pattern has good signal-to-noise ratio at high-scattering angles (high-resolution data is more strongly expressed). However, for weakly bound soft matter, such as biological samples where the dominant damage mechanism is radiolysis or heating, it is advantageous to work at high voltage. Ptychography can work at any accelerating voltage, and so in practice one would choose to operate at a point where competing damage mechanisms add up to an overall minimum.

---

### Imaging and microscopy-NCI-CCR-OSTR-national cancer institute (...) [^b65c5425]. ostr.ccr.cancer.gov (2023). Medium credibility.

Bethesda, MD Collaborative The Spatial Imaging Technology Resource provides expertise and service in state-of-the-art protein analysis technologies to advance CCR research in basic discovery and translation/clinical studies. Applications include: Quantitative profiling of cell signaling and post-translational modification, Measurement of cytokine, metabolite, and serum/plasma markers, Identification and validation of biomarkers & therapeutic targets, Assessment of onâ€ and offâ€target druâ€¦. CCR Volume Electron Microscopy Frederick, MD Collaborative CCR VOLUME Electron Microscopy aims to develop new techniques in volume electron microscopy and, in collaboration with CCR Investigators, apply these techniques to research cell biological questions well-suited for study by high-resolution 3D electron microscopy.

CVEM, headed by Kedar Narayan, uses focused ion beam scanning electron microscopy, array tomography, electron tomography and other complementary methods to visualize ultrastructural features of cells and tissues, including cell membranes, cellular organelles, and virus particles. CVEM is a CCR-dedicateâ€¦. Bethesda, MD Collaborative As a multi-user facility, the different instruments provide a wide range of imaging modes for EIB scientists, from standard immunohistochemistry, through brightfield and wide-field epifluorescence imaging, to highly complex live cell confocal microscopy and super-resolution STED imaging. LSM 880 microscope is capable of advanced imaging techniques, such as FRAP, FRET, photoactivation/photo switching, laser microirradiation, and spectral imaging. We continually develop or refine microscopy-based assays, aimed primarily at addressing questions related to cellular immunology, but we are not engâ€¦.

The core provides access to several different state-of-the-art 3D microscopes as well as computers to visualize and process image data. The facility houses equipment for 2D or 3D imaging of fixed and living specimens. High resolution images can be obtained by confocal microscopy or deconvolution, and super-resolution techniques SIM, STORM, MINFLUX. Single Molecule tracking is supported on MINFLUX, and custom HILO-illumination microscopes. Established Technologies Facility personnel are available for consultation about the design of imaging experiments and/or the analysis of image data. Speciâ€¦.

---

### Practical guide to the idea, development and exploration stages of the IDEAL framework and recommendations [^1ecdcea6]. The British Journal of Surgery (2016). Low credibility.

Background

Evaluation of new surgical procedures is a complex process challenged by evolution of technique, operator learning curves, the possibility of variable procedural quality, and strong treatment preferences among patients and clinicians. Preliminary studies that address these issues are needed to prepare for a successful randomized trial. The IDEAL (Idea, Development, Exploration, Assessment and Long-term follow-up) Framework and Recommendations provide an integrated step-by-step evaluation pathway that can help investigators achieve this.

Methods

A practical guide was developed for investigators evaluating new surgical interventions in the earlier phases before a randomized trial (corresponding to stages 1, 2a and 2b of the IDEAL Framework). The examples and practical tips included were chosen and agreed upon by consensus among authors with experience either in designing and conducting IDEAL format studies, or in helping others to design such studies. They address the most common challenges encountered by authors attempting to follow the IDEAL Recommendations.

Results

A decision aid has been created to help identify the IDEAL stage of an innovation from literature reports, with advice on how to design and report the IDEAL study formats discussed, along with the ethical and scientific rationale for specific recommendations.

Conclusion

The guide helps readers and researchers to understand and implement the IDEAL Framework and Recommendations to improve the quality of evidence supporting surgical innovation.

---

### What is a clinical pathway? Development of a definition to inform the debate [^991ebf84]. BMC Medicine (2010). Low credibility.

Background

Clinical pathways are tools used to guide evidence-based healthcare that have been implemented internationally since the 1980s. However, there is widespread lack of agreement on the impact of clinical pathways on hospital resources and patient outcomes. This can be partially attributed to the confusion for both researchers and healthcare workers regarding what constitutes a clinical pathway. This paper describes efforts made by a team of Cochrane Review authors to develop criteria to assist in the objective identification of clinical pathway studies from the literature.

Methods

We undertook a four-stage process aiming to develop criteria to define a clinical pathway: (1) identify publications exploring the definition of a clinical pathway; (2) derive draft criteria; (3) pilot test the criteria; and (4) modify criteria to maximise agreement between review authors.

Results

Previous literature and liaison with the European Pathways Association resulted in five criteria being used to define a clinical pathway: (1) the intervention was a structured multidisciplinary plan of care; (2) the intervention was used to translate guidelines or evidence into local structures; (3) the intervention detailed the steps in a course of treatment or care in a plan, pathway, algorithm, guideline, protocol or other 'inventory of actions'; (4) the intervention had timeframes or criteria-based progression; and (5) the intervention aimed to standardise care for a specific clinical problem, procedure or episode of healthcare in a specific population. After pilot testing it was decided that if an intervention met the first criteria (a structured multidisciplinary plan of care) plus three out of the other four criteria then it was included as a clinical pathway for the purposes of this review. In all, 27 studies were included in the final review. The authors of the included studies referred to these interventions as 'clinical pathways', 'protocols', 'care model', 'care map', 'multidisciplinary care', evidence-based care' and 'guideline'.

Conclusions

The criteria used for the identification of relevant studies for this Cochrane Review can be used as a foundation for the development of a standardised, internationally accepted definition of a clinical pathway.

---

### Full-field structured-illumination super-resolution X-ray transmission microscopy [^9a11645b]. Nature Communications (2019). High credibility.

Signal extraction

First, both, the reference frames and the sample frames are corrected subtracting the dark frame. Hot pixels and dead pixels are corrected in a second step. Therefore, as an intermediate step, the median of the frame with a size of 3â€‰Ã—â€‰3 pixels is calculated and subtracted from the original one. If the absolute value of the difference was >120â€‰counts, the value of this pixel was replaced by its median. As a next step, the 2â€‰Ã—â€‰2 software binning of the images mentioned above was performed. The actual signal extraction works as follows: First, we identified the minima of the structured illumination within each row of the detector. For a region between two minima, the centre of mass was calculated and the maximum intensity was extracted. This is done for each frame individually. Image formation from the 10 frames, which were acquired stepping the illumination over the sample in steps of 500â€‰nm, is done like in a normal scanning transmission microscope. In the latter case, the measured intensity is assigned to the respective position of the raster scan resulting in a two-dimensional map of the intensity transmitted through the sample. In our case, the intensity of each of the multiple foci recorded in the large two-dimensional image is extracted as described above. Each extracted intensity is then assigned to the position of the respective focus just like in the pencil-beam case. Accordingly, in the final reconstructed image every tenth pixel column in the horizontal direction is obtained from one image, while the other nine pixel columns in between originate from the images of the nine other grating positions of the stepping. Owing to a step size of 500â€‰nm for scanning, the horizontal pixel size in the reconstructed image is 500â€‰nm, while the vertical pixel size remains 1.36â€‰Âµm, i.e. the resulting pixels have a rectangular shape. Therefore, the final image spans the original image size in the vertical direction and 1.36â€‰Î¼m/(5â€‰Î¼m/10â€‰steps)â€‰=â€‰2.72 times the original image size in pixels in the horizontal dimension. The whole procedure described so far is done for the reference scan and the sample scan independently. The last step is the reference correction of the reconstructed sample image dividing it by the reference image. For the analysis, the image was rectified and rotated so that the lines of the resolution test chart are oriented horizontally or vertically, respectively, as the resolution test chart was slightly tilted by 0.9Â° with respect to the detector. Nearest-neighbour interpolation was performed in this step.

---