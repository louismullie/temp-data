# Medical Question & Answer

**Sample ID**: dc880c6e-4977-dc9a-77ed-6f8ac20ce028
**Dataset Index**: 355644

---

## Question

A ___________ is a method in which a computer security mechanism is bypassed untraceable for accessing the computer or its information.

Answer Choices:
A. front-door
B. backdoor
C. clickjacking
D. key-logging

---

## Answer

> Let's see… What do we have here? The user is asking which method allows bypassing a computer security mechanism in a way that is untraceable for accessing a computer or its information, with options including front-door, backdoor, clickjacking, and key-logging. Let's break this down step-by-step. First, I need to think about the precise definition of each option. Then, I should verify which option inherently implies stealthy, untraceable bypass of normal authentication or controls. Next, I will check whether any of the alternatives could plausibly be described as "untraceable" in common usage. Finally, I will confirm the best-fit answer and briefly justify why the others do not match the definition.

> Let me first confirm the core concept. A backdoor is a deliberate, hidden mechanism that bypasses normal security controls to provide unauthorized access, often designed to be difficult to detect or trace, which aligns with the phrase "bypassed untraceable" in the question stem [^ba390f82].

> Wait, let me verify the alternatives so I don't jump to conclusions. Clickjacking is a UI-redressing attack that tricks users into clicking on something different from what they perceive; it is not inherently untraceable and typically leaves user-interaction logs, so it does not fit the "untraceable bypass" description. Key-logging records keystrokes and can be stealthy, but it is a surveillance method rather than a built-in bypass mechanism, and its traces can be detected with endpoint monitoring, so it is not the best fit for "untraceable bypass". Front-door refers to legitimate, authorized access paths and is the opposite of a bypass, so it cannot be correct here [^notfound].

> Hold on, I should verify whether any of the provided sources explicitly tie "backdoor" to untraceable or hidden access. The AI ethics discussion notes that code can intentionally or unintentionally leave backdoor access to systems, reinforcing that backdoors are concealed entry points that circumvent security, which matches the stealthy, untraceable bypass implied by the question [^ba390f82].

> I will now examine whether any other option could be argued as "untraceable". Initially, I wondered if key-logging might qualify because it can operate silently; but wait, key-logging is fundamentally about capturing credentials rather than providing a built-in bypass, and its presence can be revealed by security tools and audit logs, so calling it an untraceable bypass would be misleading. Similarly, clickjacking leaves user-action artifacts and is detectable via UI forensics, so it fails the "untraceable" criterion in this context [^notfound].

> Putting this together, the only option that consistently denotes a hidden, built-in bypass of security mechanisms — often designed to be difficult to trace — is a backdoor. Therefore, the correct answer is B. backdoor [^ba390f82].

---

The correct answer is **B. backdoor**. A backdoor is a hidden or undocumented method of bypassing normal authentication or security controls, allowing unauthorized access to a computer system or its data, often without leaving detectable traces [^ba390f82]. Unlike front-door access (legitimate, authorized entry), clickjacking (user-interface deception), or key-logging (keystroke capture), a backdoor is specifically designed to be stealthy and untraceable, enabling persistent, covert access [^ba390f82].

---

## Definition and characteristics of a backdoor

A **backdoor** is a covert access mechanism that circumvents standard authentication or security controls, allowing unauthorized users to enter a system without detection. Key characteristics include:

- **Stealth**: Designed to avoid detection by users and security tools, often operating at a low level or using obfuscation techniques [^ba390f82].
- **Persistence**: Provides ongoing access, enabling repeated entry without re-exploitation.
- **Untraceability**: Leaves minimal or no audit trail, making it difficult to detect or attribute access [^notfound].

---

## Comparison with other options

| **Option** | **Description** | **Traceability** | **Bypass mechanism** |
|-|-|-|-|
| A. Front-door | Legitimate, authorized access through standard authentication | Highly traceable | No bypass |
| B. Backdoor | Hidden bypass of security controls | Untraceable | Yes |
| C. Clickjacking | UI deception tricking users into unintended actions | Traceable via user interaction logs | No direct bypass |
| D. Key-logging | Recording keystrokes to capture credentials | Traceable via malware detection | No direct bypass |

---

## Real-world examples of backdoors

- **Hardware backdoors**: Malicious circuits embedded in chips or devices, providing covert access at the hardware level [^notfound].
- **Software backdoors**: Hidden code in applications or operating systems, allowing unauthorized access or control [^notfound].
- **Firmware backdoors**: Persistent malware in device firmware, surviving reboots and reinstalls [^notfound].

---

## Detection and prevention

Detecting backdoors is challenging due to their stealthy nature; prevention focuses on **secure coding**, **regular audits**, and **intrusion detection systems**. Advanced techniques like **formal verification** and **runtime monitoring** can help identify hidden backdoors [^notfound].

---

## Conclusion

A backdoor is a method of bypassing computer security mechanisms in a way that is designed to be **untraceable**, enabling unauthorized access to systems or data. This distinguishes it from front-door access, clickjacking, and key-logging, which are either legitimate or detectable.

---

## References

### Toward security-aware portable sequencing [^5a572807]. Nature Communications (2025). High credibility.

A common but flawed assumption is that security can be ensured simply by disconnecting the device from the Internet during the sequencing procedure. Unfortunately, this approach does not recognize that a host machine, which can be connected to the Internet at any time, remains vulnerable to security breaches and malware. Thus, merely halting the Internet connection before or during sequencing does not eliminate the risk of data exfiltration and manipulation due to a compromise in the host machine.

Collectively, these observations underscore that the portability of sequencing devices, while enhancing accessibility and operational flexibility, fundamentally redefines the security landscape, necessitating a reevaluation of trust assumptions, host-machine dependencies, and protection mechanisms traditionally accepted in controlled laboratory environments. A clear example is when company policies like Bring Your Own Device allow users to connect their personal computers, not managed by organizations' IT security groups, to the sequencers to perform job duties locally or remotely. An employee in a laboratory might unknowingly fall victim to phishing attacks by clicking on a malicious link in a seemingly legitimate email, thus compromising their device. This compromised personal computer, once connected to the sequencer, can be used to manipulate sequencing data during elaborations or allow unauthorized access to sensitive sequencing data while the user is unaware of the compromise. To the best of our knowledge, these vulnerabilities have not been exposed in the wild, meaning they have not been observed being actively exploited in current real-world systems or environments. Further research and empirical validation are necessary to assess the extent of the threat. A summary of these potential exploitations and their impact is summarized in Table 1.

Table 1
Overview of vulnerabilities in portable sequencing devices with examples and potential impacts

---

### Toward security-aware portable sequencing [^0d5ded95]. Nature Communications (2025). High credibility.

Potential solutions

A prevalent misconception is the expectation that the end users of sequencers, such as lab technicians, clinical personnel, and biologists, are also responsible for the overall security of their workflows when outside of their laboratory, during analysis in the field, or remotely. Although in general, security awareness is necessary, this assumption overlooks the complexity of modern connected computer systems and the specialized knowledge required to manage security effectively. Decades of cybersecurity best practices (see Microsoft Security Development Lifecycle:Accessed: 2025-09-28), and seminal research works, such as Why Johnny Can't Encrypt and Users are not the enemy have long demonstrated the risks of relying on users to configure and maintain security, underscoring the need for transparent, user-focused mechanisms that are enforced automatically, without requiring users to manage complex technical processes. This paradigm acknowledges that insecure user behavior often stems from a lack of technical background in security and poor communication about cybersecurity risks. For example, users might choose to engage in insecure behavior not because they don't care about security, but because of convenience, such as when security protocols slow down their workflow (e.g. using dual-factor authentication vs. "Remember Me" functionalities to not retype login info). At the same time, a scenario giving the impression that its security mechanisms are perfectly secure at all times is likely to induce careless behavior, since the level of perceived threat is low. Organizations must actively inform users about existing and potential threats to their systems and the sensitivity of the information they contain. Maintaining users' security awareness over time and through technology shifts and changing scenarios requires balance. Users need clear guidance to avoid leading them to rely on incomplete personal judgment. Security levels should also change as complexity and scenarios evolve, and be transparently linked to the processes and information they protect. This approach has been proven to reduce the risk of human error and make security more effective in preventing data breaches.

---

### Message in a molecule [^eaa541c2]. Nature Communications (2016). Medium credibility.

Since ancient times, steganography, the art of concealing information, has largely relied on secret inks as a tool for hiding messages. However, as the methods for detecting these inks improved, the use of simple and accessible chemicals as a means to secure communication was practically abolished. Here, we describe a method that enables one to conceal multiple different messages within the emission spectra of a unimolecular fluorescent sensor. Similar to secret inks, this molecular-scale messaging sensor (m-SMS) can be hidden on regular paper and the messages can be encoded or decoded within seconds using common chemicals, including commercial ingredients that can be obtained in grocery stores or pharmacies. Unlike with invisible inks, however, uncovering these messages by an unauthorized user is almost impossible because they are protected by three different defence mechanisms: steganography, cryptography and by entering a password, which are used to hide, encrypt or prevent access to the information, respectively.

---

### Think like a hacker [^26308d44]. Journal of Diabetes Science and Technology (2017). Low credibility.

Ready or not, the Internet of things (IoT) is here. No longer just a buzz term, it'll continue to grow at an unprecedented pace over the next few years expecting to reach over 25 billion connected devices by 2020. History shows us that most fast growth technology solutions focus on solving business problems first and security is an afterthought. Unfortunately, IoT is following the same trend. Most IoT devices, apps, and infrastructure were developed without security in mind and are likely going to become targets of hackers. According to some security experts, major cyberattacks against the IoT devices are looming. According to the FBI, criminals can gain access to unprotected devices used in home health care, such as those used to collect and transmit personal monitoring data or time-dispensed medicines. Once criminals have breached such devices, they gain access to any personal or medical information stored on the devices, as well as the power to change the coding that controls the dispense mechanism of medicines or health data collection. This can result in major health issues and potential loss of lives. Are organizations ready to protect themselves? What are the key vulnerable points? There are various steps that companies can take to raise the barrier. In this article, we'll talk about the background, issues, potential attack vectors liable to be hacked, protection strategies, and more.

---

### Do smartphone applications in healthcare require a governance and legal framework? It depends on the application! [^892e9763]. BMC Medicine (2014). Low credibility.

The need for relevant information governance

The lack of seamless access to patient information across the care pathway remains one of the most pressing issues in healthcare. The absence of an integrated system poses a threat to care quality and patient safety as important clinical decisions have to be made after referring to multiple electronic systems, raising further issues in terms of governance and handling of confidential data. It is possible that the enthusiasm among healthcare professionals to use smartphones to help make clinical decisions stems in part from a frustration with existing information technology systems provided by healthcare organizations. In this context, apps may have provided a 'quick fix' for circumventing the underlying problems related to healthcare information technology architecture, rather than being horizontally integrated into the wider health informatics landscape. This in turn is contributing to the observed fragmentation of apps.

Apps may provide a robust mechanism for improving out-of-hours care where one reason for poorer patient outcomes may be lack of remote access to data to help inform decision-making by non-resident practitioners. Utilizing apps to overcome this, however, is mired with difficulties, chief among them being access to patient data and patient confidentiality. Existing electronic systems and servers in healthcare operate behind secure firewalls. Providing access to patient data through mobile devices would require careful consideration of the ethical, security and governance aspects of data handling. But this need not be a deterrent. If enacted correctly and systematically, access to patient information through mobile devices can be much more secure than access through paper records, which can be transported and/or photocopied and misplaced much more easily. Data encryption methods specifically designed for mHealth apps are now coming to fruition. However, electronic and digital systems pose their own threats and resilience to malware and cyber attacks must be developed.

---

### Blockchain, information security, control, and integrity: who is in charge? [^37ff82e4]. Plastic and Reconstructive Surgery (2023). Medium credibility.

Summary

Blockchain technology has attracted substantial interest in recent years, most notably for its effect on global economics through the advent of cryptocurrency. Within the health care domain, blockchain technology has been actively explored as a tool for improving personal health data management, medical device security, and clinical trial management. Despite a strong demand for innovation and cutting-edge technology in plastic surgery, integration of blockchain technologies within plastic surgery is in its infancy. Recent advances and mainstream adoption of blockchain are gaining momentum and have shown significant promise for improving patient care and information management. In this article, the authors explain what defines a blockchain and discuss its history and potential applications in plastic surgery. Existing evidence suggests that blockchain can enable patient-centered data management, improve privacy, and provide additional safeguards against human error. Integration of blockchain technology into clinical practice requires further research and development to demonstrate its safety and efficacy for patients and providers.

---

### The internet [^b842b89d]. Journal of Neurology, Neurosurgery, and Psychiatry (2002). Low credibility.

The growing use of email and the world wide web (WWW), by the public, academics, and clinicians-as well as the increasing availability of high quality information on the WWW-make a working knowledge of the internet important. Although this article aims to enhance readers' existing use of the internet and medical resources on the WWW, it is also intelligible to someone unfamiliar with the internet. A web browser is one of the central pieces of software in modern computing: it is a window on the WWW, file transfer protocol sites, networked newsgroups, and your own computer's files. Effective use of the internet for professional purposes requires an understanding of the best strategies to search the WWW and the mechanisms for ensuring secure data transfer, as well as a compendium of online resources including journals, textbooks, medical portals, and sites providing high quality patient information. This article summarises these resources, available to incorporate into your web browser as downloadable "Favorites" or "Bookmarks" from www.jnnp.com, where there are also freely accessible hypertext links to the recommended sites.

---

### Toward security-aware portable sequencing [^0c3bd264]. Nature Communications (2025). High credibility.

The first step in implementing zero-trust solutions consists of adopting strong authentication mechanisms to control access to the sequencer and the sequencing data on the host machine, both locally and remotely. In addition to passwords, multi-factor authentication or passkey can significantly increase the difficulty for attackers to impersonate legitimate users while preserving confidentiality and availability. For example, common two-factor authentication mechanisms that require users to approve login attempts have been shown to virtually eliminate an entire class of password-stealing/cracking attacks.

Second, data should be secure even if the host is compromised, as it is transmitted from the sequencer to secure online servers or databases using lightweight encryption suitable for low-resource embedded systems. Achieving this goal may also require rethinking the role of the host machine in the sequencing workflow. For example, one can construct a private sequencing pipeline using public-key cryptography. The sequencer can encrypt the raw data before it transmits to the host device, preventing untrusted intermediaries from gaining access to the underlying genetic information. The host machine, considered untrusted, does not have access to the cryptographic keys necessary to decrypt the collected data, preserving confidentiality. Its sole responsibility is to transmit the data over the network, adhering to the zero-trust principle of least privilege, where each component in the workflow has only the access it needs to perform its function.

When data must be used on the host machine, integrity can be ensured by using techniques such as Message Authentication Codes (MACs), which can detect tampering during data sharing and transmission. These codes, often used on resource-constrained devices, work by having both the sender and receiver compute a mathematical transformation (e.g. a hash) on the data. MACs have two key properties: they are non-reversible, meaning an adversary cannot determine the original sequence from the code, and they rarely collide, meaning different data sequences do not produce the same code. These properties allow the receiver to verify whether the received data has been altered by calculating the code itself. The approach does not assume trusted input from workflow components, allowing each system to independently verify data integrity. For example, these techniques have been explored in wireless body area networks, which collect and transmit patient physiological data.

---

### Blockchain, consent and prosent for medical research [^7844897f]. Journal of Medical Ethics (2021). Medium credibility.

Blockchain technologies

Blockchain is a distributed technology enabling interactions of systems which, by design, does not rely on third parties to guarantee the integrity of a transaction. Instead, several features of blockchain technologies act in concert to guarantee data integrity. These are distribution of the blockchain to each member in its network, combined with a consensus mechanism designed to disincentivise fraud, and a hashing mechanism used to prove data integrity. More precisely and for convenience, we can imagine blockchain as a single shared database of which all users get a public copy, called the ledger. Table 1 lists some key principles and corresponding features and affordances of blockchain.

Table 1
Key features and affordances of blockchain technology

Technically, blockchains are organised in a decentralised fashion and the ledger is stored partially or in full on each of the computers (nodes) that participate in the recording and sharing of the data. Blockchains are distributed to each node in their network, are frequently updated, may be transparent and typically have low bandwidth. For these reasons, it is important to note that in most practical implementations of blockchain technologies in the healthcare context, the actual medical data of interest would not be recorded on the blockchain. Rather, the blockchain would store transactional and metadata such as hashes indicating whether or not a patient had consented; cryptographic keys denoting which healthcare professionals have access to which records; and evidence of database transactions, such as whether and when a healthcare professional has accessed a specific record, and what, if anything, that professional did with the resulting data.

For a new block to be accepted into the chain, a majority of these nodes need to agree on its veracity. This consensus mechanism is backed up by economic mechanisms designed to prevent malicious activity by disincentivising fraud.

A malignant attacker trying to corrupt data would require access to a majority (or a set, depending on the consensus mechanism) of the networked computers. This becomes almost impossible as the network grows.

---

### DNA origami cryptography for secure communication [^f0ea425a]. Nature Communications (2019). High credibility.

Introduction

Information security — confidentiality, integrity. and availability (the "CIA triad") of information — plays a pivotal role in modern society. In order to meet this demand, sophisticated cryptography schemesrelying on hard computational problems have been established for secure communication –. However, current cryptography protocols are facing severe challenges: the tremendous and ongoing progress of electronic computerswill soon allow to crack currently used cryptography protocols within acceptable time by brute-force attacks, while the emergence of novel quantum computerswill allow to crack keys based on prime factorization via Shor's algorithm. Next-generation cryptography circumventing these threats, therefore, has received extensive attention. In particular, quantum cryptography methods exploiting the quantum mechanical uncertainty principle hold great promise for assuring message confidentiality. However, whether CIA of information can be comprehensively achieved via quantum communication remains unclear.

Biomolecular cryptography that utilizes highly specific, thermodynamically controlled biomolecular interactions instead of computational schemes for encryption has been previously proposed as an alternative –. For instance, a biomolecular keypad lock that can authorize password entries was developed based on the sequential recognition of input substrates of specific biocatalysts. Similarly, proteins, aptamers, bacteria, and DNA-based biocomputinghave been exploited to protect messages for secure communication. However, in previous studies, information security relied on fixed biomolecular reaction schemes, whose security would have been compromised as soon as the adversary uncovered the "trick". In 1999, Clelland et al. developed a DNA-based steganography scheme to hide secret messages, opening a new era of DNA cryptography that involved information-rich biomolecules for the creation of data encryption keys to ensure message confidentiality –. Nevertheless, these DNA-based strategies generally exploit sequence information only, whereas they largely ignore the structural potential of DNA.

---

### Guidelines for the practice of telepsychology [^2aedc222]. The American Psychologist (2013). Medium credibility.

Telepsychology glossary — privacy, security, and technology terms define key constructs for practice: Protected health information (PHI) is information, including demographic information, which relates to an individual's health, the provision of health care, or payment for health care, and it includes many common identifiers when they can be associated with the health information; personally identifiable information (PII) is information that can be used to distinguish or trace the identity of an individual alone or when combined with other identifying information. Multi-factor authentication is authentication using two or more different factors to provide increased security during log-ins and factors may include something you know, something you have, or something you are. Telecommunications is the preparation, transmission, communication, or related processing of information by electrical, electromagnetic, electromechanical, electro-optical, or electronic means. Telepresence describes how participants experience the technology system, including how it makes them feel present and how it enables them to interact with and respond to others, and considerations often include virtual eye contact and other mechanisms through which patients interact with and respond to technology. Telesupervision is supervision of psychological services either through asynchronous methods or synchronous audio and video where the supervisor is not in the same physical facility as the trainee. Third-party monitoring/third-party observer refers to the influence of an observer's presence on human behaviors, specifically the potential negative effects a present third party may have on the process, results, and outcome of a neuropsychological assessment. mHealth is the use of mobile and wireless technologies to support the achievement of health objectives, and malware is a computer program covertly placed onto a computer or electronic device with the intent to compromise the confidentiality, integrity, or availability of data, applications, or operating systems. GDPR is a data privacy law governing the processing, storing, and managing of the personal data of individuals in the European Union that extends to organizations anywhere if they collect data related to people in the EU, and HIPAA requires the Secretary of HHS to promulgate standards for the electronic exchange, privacy, and security of health information.

---

### Clinical bioinformatician body of knowledge-molecular diagnostics core: a report of the Association for Molecular Pathology [^bf70cd25]. The Journal of Molecular Diagnostics (2025). High credibility.

AMP BoK Molecular Diagnostics Core — database maintenance, validation, and security: "Another challenge with genomic databases is the need for regular updates in response to ongoing scientific and technological advances". Once selected for clinical use, a database "cannot simply be replaced with an updated version, even for minor revisions, without carefully evaluating the potential impact on the accuracy and reproducibility of clinical results", and "pipeline revalidation may be required to ensure that the updated database does not affect the workflow or results". Technically, "the bioinformatician must be able to verify the integrity of the data after download, using methods like hash sums or similar techniques to confirm data fidelity", and "controlling access to data within the laboratory's computing environment is essential to maintain security and prevent unauthorized changes". "Caution should be exercised when accessing data remotely", and "Ensuring that the database remains consistent throughout the validation process is critical to avoid potential issues".

---

### Privacy-friendly evaluation of patient data with secure multiparty computation in a European pilot study [^1cd941fa]. NPJ Digital Medicine (2024). Medium credibility.

Discussion

Regarding the study protocol, the ethics vote, and the patient information material, in future iterations it would be beneficial to explicitly describe methods of secure computing. This would limit the fashion in which data may be processed, and it would make the (commendable) use of secure computing transparent to ethics counsellors and patients. For the purpose of this experiment, at the time of writing of the study protocol the exact mechanism for data sharing was not known, and hence the study protocol and subsequent documents allowed for more lenient alternatives of data processing.

Regarding the cooperation agreement, it has been argued by a law firm involved in the project that secure multiparty computation would constitute a joint responsibility as provided by GDPR: "Where two or more controllers jointly determine the purpose and means of processing, they shall be joint controllers". (Art. 26 GDPR) Insofar it would be advisable to explicitly frame the parties as "joint controllers" in future iterations of cooperation agreements that foresee secure multiparty computation. The further provisions of Art. 26 GDPR were adhered to in this project, anyway.

As far as written informed consent is concerned, the novel method does have advantages in terms of privacy and data security, but it was discussed with legal experts that this is not something that the patient should have to rely upon or that should be advertised to the patient. In particular, the new method must not be abused to circumvent any stipulations. In particular, there must not be "less" consent for the novel method to be employed than for conventional open data sharing between the joint controllers. Also, it was recommended by a specialist law firm that the method should be legally considered pseudonymization, rather than anonymization, of the data. For this reason, patients were informed in the consent form that their "personal data and clinical findings will be processed in encrypted (pseudonymized) form and will be shared with cooperation partners of the study for scientific evaluation". The cooperation partners abroad were also explicitly named. We are not aware of any challenges obtaining informed consent.

---

### A quantum access network [^53c18616]. Nature (2013). Excellent credibility.

The theoretically proven security of quantum key distribution (QKD) could revolutionize the way in which information exchange is protected in the future. Several field tests of QKD have proven it to be a reliable technology for cryptographic key exchange and have demonstrated nodal networks of point-to-point links. However, until now no convincing answer has been given to the question of how to extend the scope of QKD beyond niche applications in dedicated high security networks. Here we introduce and experimentally demonstrate the concept of a 'quantum access network': based on simple and cost-effective telecommunication technologies, the scheme can greatly expand the number of users in quantum networks and therefore vastly broaden their appeal. We show that a high-speed single-photon detector positioned at a network node can be shared between up to 64 users for exchanging secret keys with the node, thereby significantly reducing the hardware requirements for each user added to the network. This point-to-multipoint architecture removes one of the main obstacles restricting the widespread application of QKD. It presents a viable method for realizing multi-user QKD networks with efficient use of resources, and brings QKD closer to becoming a widespread technology.

---

### Addressing contemporary threats in anonymised healthcare data using privacy engineering [^30859d86]. NPJ Digital Medicine (2025). Medium credibility.

Privacy engineering via accountability mechanisms

Data privacy breaches can be addressed by several mechanisms. Access controls aim to ensure that granular information is only available to approved individuals with a legitimate need for their task. Privacy-preserving programming frameworks can be used to restrict the types of computations run or enforce that they are run in a privacy-preserving manner (e.g. using differential privacy). Controlled environments, such as data clean rooms, trusted execution environments, and secure research facilities can also be used to limit the misuse of data. For example, Dutch researchers developed a controlled environment to analyze vertically partitioned health data across multiple parties in a privacy-preserving manner. Finally, audit logging can be used to monitor which individuals access information, and what types of computations they run. While access controls and audit logging were originally developed for security purposes, their use has extended into modern data privacy practices to restrict the flow of information to appropriate individuals for appropriate use cases. Taken together, these mechanisms provide practical barriers to restrict improper information disclosure, by documenting when and how information was used and by whom.

---

### Technical challenges of enterprise imaging: HIMSS-SIIM collaborative white paper [^b32533aa]. Journal of Digital Imaging (2016). Low credibility.

However, for each of these there is a near equivalent DICOM or XDS service that could be used instead. It is recommended that when considering the use or creation of a proprietary ingestion method, that strong consideration be given to standards-based transfers and a high bar be placed for approval and implementation of a proprietary method. The content management system vendor should be contacted to ascertain when standards-based methods for ingestion will be provided.

At a minimum, the new system must also provide standards-based methods for storage, retrieval, and viewing in order to avoid a technological "lock-in" to a vendor specific proprietary strategy with no easy escape mechanism. What is particularly problematic is the situation where the images are saved in an opaque proprietary format (database blobs or data files) rather than either standard photographic image formats (e.g. JPEG, JPEG 2000, TIFF) or better yet, DICOM.

Consideration must be given to image exchange and interchange with other institutions as well as eventual migration to a new content management system, VNA or XDS infrastructure.

DICOM and XDS Security-Related Considerations

For all traditional DICOM operations, though it is possible to communicate user level authentication information when establishing the connection, this is not often done. DICOM supports various types of user authentication, including username and password, Kerberos tokens, and SAML assertions.

Recipients can be configured to be "promiscuous" (accept objects or requests from any source) or restricted to accept connections or requests objects from a named set of sources. DICOM uses the ISO OSI terms "Application Entity" (AE) and "Application Entity Title" (AET) to identify endpoints for communication.

When using DICOM over TLS, client and server certificates can be used for more sophisticated control over individual connections and the information used for selective access control and to record in audit trails, as defined in the IHE Audit Trail and Node Authentication (ATNA) integration profile.

The DICOMweb transactions can make use of normal HTTP security mechanisms, including those for confidentiality (e.g. TLS) and for user authentication.

IHE defines various profiles related to user authentication and authorization for SOAP and non-SOAP transactions for enterprise, cross-enterprise, and Internet applications.

Other Considerations

---

### Developing policies and procedures for a picture archiving and communication system [^0171950c]. Journal of Digital Imaging (2001). Low credibility.

Policies and procedures (P&P) constitute the mechanism for planning, standardizing, and documenting the provision of clinical services. Upon approval by hospital management, the P&P is an official statement of hospital rules and regulations. Each P&P establishes organizational responsibility for providing services. P&P are a mechanism for communicating standard operating procedures to hospital and medical staff. P&P serve as a reference document for unusual events, as well as routine procedures. P&P are often reviewed by inspection teams from the Joint Commission on Accreditation of Hospital Organizations (JCAHO) to determine whether the hospital has documented systematic practices. A picture archival and communications system (PACS) provides a new vehicle for providing radiology services. P&P that were designed for conventional film-based imaging are often not appropriate for electronic imaging. Because PACS is new and not yet widespread, good examples of PACS P&P are not yet available. JCAHO has no official requirements for PACS: PACS is viewed only as a means for the hospital to accomplish its work. Successful P&P development is a team effort, drafted by personnel responsible for executing the procedure, assisted by staff proficient in PACS technology, and tested in the field. The P&P should be reviewed and approved by management personnel knowledgeable about hospital and imaging operations. P&P should be written in clear and concise language. Successful P&P development is an ongoing effort. P&P must be periodically reviewed and updated to reflect changes in PACS technology and changes in clinical operations. New P&P must be developed when a deficit is noted. PACS security is a good example of a topic worthy of P&P development, especially in the face of the Health Insurance Portability and Accountability Act (HIPAA) legislation of 1996. What are the provisions for access control? Does the system include a feature for automatic shut-off of the software? Are there "generic" passwords and log-ins shared by a community of users? How are passwords assigned and how frequently are they changed? What security measures are in place to assure passwords are given to the appropriate user? Who grants and denies access? Service calls are another topic for P&P. Who initiates a service call? What is the process for escalating a service call from the operator level to the vendor? What immediate actions are expected by the operator in order to restore PACS services? How are service events documented? Who is responsible for determining when "downtime" procedures should be initiated or suspended? When our hospital's total electrical system had to be shut down for an extended period, we found that a P&P was lacking for a task as mundane as shutting down and restarting our PACS components. What is the sequence for the shutdown? Who is responsible for shutting down and restarting? How long can the devices operate on uninteruptible power supplies (UPS)? What components are on emergency power? Should we expect the components to survive the switchover to generator power? Developing this P&P was worth the effort: it made the PACS more fault-tolerant and served as a reference document 3 years later when expansion of our physical plant required two more power outages.

---

### Prompt injection attacks on vision language models in oncology [^318e25ed]. Nature Communications (2025). High credibility.

Discussion

In summary, our study demonstrates that subtle prompt injection attacks on state-of-the-art VLMs can cause harmful outputs. These attacks can be performed without access to the model architecture, i.e. as black-box attacks. Potential attackers encompass cybercriminals, blackmailers, insiders with malicious intent, or, as observed with increasing and concerning frequency, political actors engaging in cyber warfare. These would only need to gain access to the user's prompt, e.g. before the data reaches the secure hospital infrastructure. Inference, for which data is sent to the (most-likely external) VLM-provider, serves as another gateway (Fig. 1b). Here, a simple, malicious browser extension would suffice to alter a prompt that is sent via web-browser –. These methods are of significant concern, especially in an environment such as healthcare, where individuals are stressed, overworked and are operating within a chronically underfunded cybersecurity infrastructure. This makes prompt injection a highly relevant security threat in future healthcare infrastructure, as injections can be hidden in virtually any data that is processed by medical AI systems. Given that prompt injection exploits the fundamental input mechanism of LLMs, prompt injection is likely to be a fundamental problem of LLMs/VLMs, not exclusive to the tested models, and not easily fixable, as the model is simply following the (altered) instructions. Recent technical improvements to LLMs, e.g. Short circuiting, important to mitigate intrinsically harmful outputs such as weapon-building-instructions, are insufficient to mitigate such attacks. Agent-systems composed of multiple models have similarly been shown to be targetable. Further, other types of guardrails can be bypassedor compromise usability, as shown for Gemini 1.5. A possible solution to this could be hybrid alignment training, enforcing prioritization on ethical outputs alongside human preferences over blind adherence to inappropriate requests. As we show that Claude-3.5, after years of alignment research from Anthropic, is the only tested model where mitigation worked to some extent (Fig. 4), this approach appears promising. Other approaches could include rigorous enforcement or wrapping of the prompt structure. Moreover, public release of model-specific approaches to alignment training, currently not available, could assist in the development of solutions, especially as this would allow causal investigations for the varying levels of susceptibility to prompt injection attacks for different models. Overall, our data highlight the need for techniques specifically targeting this form of adversarial attacks.

---

### Clinical bioinformatician body of knowledge-clinical laboratory regulation and data security core: a report of the Association for Molecular Pathology [^ef135cbc]. The Journal of Molecular Diagnostics (2025). High credibility.

Clinical laboratory risk assessments — scope and methods are described as follows: Risk assessment is an essential component of computer system validation, laboratory informatics operations, and general clinical laboratory practice, involving identifying vulnerabilities, hazards, and risks to the system or data, measuring their associated impacts, and taking measures to reduce risks to an acceptable level. Information gathering for identification of potential risks and vulnerabilities can be accomplished via document reviews, expert opinions, checklists, diagramming, structured surveys, medical device security questions (National Electrical Manufacturers Association Manufacturer Disclosure Statement for Medical Device Security), and feedback from stakeholders of the system. The evaluation should be directed toward the intended functionality of the system and should consider the specific setting within which the system is deployed, and ideally, the assessment should comprehensively encompass all aspects of the system's processes before its implementation and should be conducted with the participation of members of the workforce and stakeholders. The identified risks are analyzed using qualitative or quantitative techniques to determine their probability of occurrence, severity, and impact; qualitative risk analysis is a subjective approach based on expert judgement rather than numerical values and may use a risk assessment matrix for prioritization, whereas in contrast, quantitative risk analysis uses verifiable data, quantitative tools, and techniques to objectively report risks in numerical terms.

---

### Necessary security mechanisms in a PACS DICOM access system with web technology [^018ab141]. Journal of Digital Imaging (2002). Low credibility.

The evolution in information and telecommunication technologies has allowed the development of systems that use the Internet infrastructure and Web technology to remotely access a hospital's picture archiving and communication system (PACS). However, one of the main problems in the construction of this type of system is the development of mechanisms that guarantee the security of the medical data that are being consulted. Most countries have specific norms for the protection of such medical data. This work describes security mechanisms that are developed in an access system to PACS DICOM with Web technology and comply with the Spanish legislation concerning the protection of medical data. The proposed security mechanisms are flexible, they leave room for the definition of security policies adjusted to the needs of each particular organization and they can be adapted to comply with new or foreign norms.

---

### Confidentiality of medical information in the workplace [^9f553771]. ACOEM (2012). Medium credibility.

ACOEM position — handling sensitive information, scope of release, and record policies specifies that although all personal health information should be presumed to be confidential, physicians should recognize that certain types of health information are particularly sensitive such as sexual orientation, HIV/AIDS status, drug and alcohol treatment, past history of physical or sexual abuse, treatment for sexually transmitted diseases, and genetic information; physicians should be aware that a general consent for disclosure of medical records cannot be presumed to be sufficient in these situations and that specific written consent for release of such information must be obtained, and this information should only be disclosed in compliance with U.S. federal and state law; because it is often possible to infer sensitive information from other parts of the medical record, such as the medication history, the physician should treat such information in the same manner as explicitly sensitive information. Physicians should release only the portion of a record covered by a release and not disclose the entire medical record unless indicated and permitted by the patient, and forwarding records that have been obtained from other medical providers is appropriate when that information is relevant to the specific problem in question and permitted. Physicians should develop a written policy for the treatment of medical records in their offices, clinics, or workplaces; the policy should address such issues as where, and for how long the records are stored; the security of medical records including computer databases; what happens in the event of employee resignation, layoff, termination, job transfer, or closure and/or merger of employer; and the mechanisms of employee access and consent for disclosure, and physicians should make reasonable efforts to ensure that those under their supervision act with due care regarding the confidentiality of medical records, and act to educate fellow health care providers and office support staff regarding the confidentiality of medical information.

---

### Toward security-aware portable sequencing [^28b81682]. Nature Communications (2025). High credibility.

Redefining security for portable sequencers

The emergence of portable genome sequencing technology has the potential to transform the way biological samples are collected and analyzed. We define portable sequencing as a compact instrument that acquires raw signals on-device but relies on an external host (e.g. a laptop or desktop) for basecalling and further elaborations, whereas standalone sequencing refers to self-contained benchtop platforms that integrate signal conversion and computation within the device. These "sequence anywhere" devices are "palm-sized platforms designed for use in the lab or field" (, Accessed September 22, 2025). For example, in a seminal field deployment between 2014 and 2016 West African Ebola epidemic, a portable nanopore system was transported to Guinea and used to perform real-time genomic surveillance, producing results within 24 h of sample receipt, and sequencing runs as short as 15 min on 142 clinical samples. These findings demonstrated that genomic surveillance can be established rapidly in resource-limited settings and can inform outbreak tracking and response logistics without relying on centralized laboratories. However, these new capabilities have the potential to open new attack vectors and vulnerabilities for adversaries who wish to undermine the security and privacy of the sequenced data. Unlike traditional standalone laboratory equipment, these devices often lack the computational capacity to convert raw signal traces into sequence data. Instead, they use a host machine to perform the necessary signal processing and basecalling tasks. The decoupling of sequencing hardware from computing systems has the potential to open up a range of security vulnerabilities by broadening the attack surface to threats that were not considered before when used outside secure laboratory environments, as illustrated in Fig. 1. In other words, there are more avenues for attackers to attempt to gain access and alter data, such as compromising host machines to manipulate the elaboration, and exploiting insecure communication channels between sequencers and hosts for eavesdropping.

---

### Security of electronic medical information and patient privacy: what you need to know [^e3aa915f]. Journal of the American College of Radiology (2014). Low credibility.

The responsibility that physicians have to protect their patients from harm extends to protecting the privacy and confidentiality of patient health information including that contained within radiological images. The intent of HIPAA and subsequent HIPAA Privacy and Security Rules is to keep patients' private information confidential while allowing providers access to and maintaining the integrity of relevant information needed to provide care. Failure to comply with electronic protected health information (ePHI) regulations could result in financial or criminal penalties or both. Protected health information refers to anything that can reasonably be used to identify a patient (eg, name, age, date of birth, social security number, radiology examination accession number). The basic tools and techniques used to maintain medical information security and patient privacy described in this article include physical safeguards such as computer device isolation and data backup, technical safeguards such as firewalls and secure transmission modes, and administrative safeguards including documentation of security policies, training of staff, and audit tracking through system logs. Other important concepts related to privacy and security are explained, including user authentication, authorization, availability, confidentiality, data integrity, and nonrepudiation. Patient privacy and security of medical information are critical elements in today's electronic health care environment. Radiology has led the way in adopting digital systems to make possible the availability of medical information anywhere anytime, and in identifying and working to eliminate any risks to patients.

---

### Cybersecurity in PACS and medical imaging: an overview [^a668ce9d]. Journal of Digital Imaging (2020). Medium credibility.

Physical Mitigation Measures

The first and arguably most obvious level of cybersecurity is physical: technical mitigation measures such as passwords, virus scanners or fine-grained user privileges are of little value if an attacker can simply walk into a server room and steal computers or storage media. An ENISA study reports that physical and environmental security is the second top security requirement in eHealth, after incident reporting. "A basic principle for the physical protection of data is to ensure that file servers are located in secure areas safeguarded from unauthorized access and environmental threats such as fire, flood, loss of power etc". Liu et al. report that most data breaches of protected health information in the USA "occurred via electronic media, frequently involving laptop computers or portable electronic devices. Most breaches also occurred via theft". This highlights that mobile devices, which cannot be kept behind locked doors in server rooms, are a topic that also needs to be taken into account; we will discuss this further in the next section.

A guideline by the US Department of Health and Human Services explains that, "should a data storage device disappear, no matter how well an office has taken care of its passwords, access control, and file permissions, it is still possible that a determined individual could access the information on it. Therefore, it is important to limit the possibility of devices disappearing or being tampered with". The guideline recommends that "securing devices and information physically should include policies limiting physical access, for example, securing machines in locked rooms, managing physical keys, and restricting the ability to remove devices from a secure area". Finally, Wikina mentions the installation of security cameras as a possible security measure.

---

### Clinical bioinformatician body of knowledge-clinical laboratory regulation and data security core: a report of the Association for Molecular Pathology [^be6c3893]. The Journal of Molecular Diagnostics (2025). High credibility.

Workflow orchestration, containers, and environment separation — It is important to have a test environment that mimics but is distinct from the production environment; however, it should have the same computational resources and integrations as the production environment, and ideally there should also be a development environment that is distinct from the test and production environments. Workflow management and orchestration software enables modularity within the code, detailed descriptions of inputs, outputs, and connections, error handling and error logging, restarting code from where an error occurs, and easier launching of pipelines. The use of containers enables the packaging of software components or whole pipelines complete with the environments needed to run them, and when building containers it is helpful to restrict the privileges of the container on the host machine to the minimum necessary and minimize the range of software installed in the container to reduce its vulnerability footprint. Containers should be scanned periodically for vulnerabilities, it is also critically important to keep software up to date with appropriate patches to prevent exposing the organization to the potentially catastrophic effects of malware through known vulnerabilities, and preventing unauthorized outside access to the software and limiting the access of laboratory software to necessary networks and applications can further protect the organization from adverse cybersecurity events.

---

### Without a trace: why did corona apps fail? [^ef151a30]. Journal of Medical Ethics (2021). Medium credibility.

The kinds of breaches we should be concerned about in decentralised systems are attacks that could expose the identities of infected users. When a user of a decentralised system reports that he is infected with COVID-19, all of his ephemeral identifiers are uploaded to the central server, where they are accessible to everyone. This makes it possible to record the ephemeral identifiers broadcasted by particular users, and then to check them later against the identifiers stored on the server. This would enable the identification of those that have become infected. Such attacks, Vaudenay contends, could be conducted by any tech-savvy user, and 'are undetectable, can be done at a wide scale, and… proposed countermeasures are, at best, able to mitigate attacks in a limited number of scenarios'. Attacks on centralised systems, on the other hand, can be better identified and mitigated 'by accounting and auditing'. Vaudenay even suggests that privacy-conscious users would in fact be less likely to report that they are infected in a decentralised system than a centralised one. Vaudenay also notes that information stored in a decentralised manner could be utilised by law enforcement — for example, 'after a burglary during which a Bluetooth sensor captured an ephemeral identifier, suspects could have their phones inspected for 2 weeks to find evidence'. Because one's own ephemeral identifiers are stored on one's phone in a decentralised system, access to someone's phone would yield more information than under a centralised system.

---

### High throughput tools to access images from clinical archives for research [^c339f32f]. Journal of Digital Imaging (2015). Low credibility.

IRB and Auditing Support

Central to the vision of the mi2b2 software is a robust way for administrators and healthcare entities to control and audit user activity that accesses both images and related protected health information on clinical archives. We do not attempt to de-identify or anonymize data sets but instead leave this responsibility to the IRB-approved project members. The mi2b2 software ensures the privacy of all patients by limiting access to the data to only trusted users who are named on the associated IRB proposal. Per institutional policy, it is required that all named users will have up-to-date Collaborative Institutional Training Initiative certification or equivalent and commit to following all behavioral and technological guidelines of the institution for protecting the data (e.g. password protected, encrypted computers, hard disks within institutional firewalls, etc.). Both the i2b2 and mi2b2 software tools are developed with these security measures as well as ex post review methods, including audit trail mechanisms for all image files accessed.

The mi2b2 software accomplishes this in two ways. First, mi2b2 limits user queries and requests for images to a predefined list of medical record numbers. This list is tied to an IRB protocol approval and may contain an expiration date to automatically stop PACS access when the approval has ended. Second, every query a user performs for patient information and study information is recorded in the database. The date and time of image retrievals from the mi2b2 cache is also tracked. At any time, administrators may audit mi2b2 activity by querying the appropriate tables in the database.

---

### Secure and federated genome-wide association studies for biobank-scale datasets [^836596fd]. Nature Genetics (2025). High credibility.

Methods

Ethics and inclusion statement

The use of all controlled-access datasets in this study were approved by the respective data access committees through the NIH Database of Genotypes and Phenotypes (dbGaP) and the UKB Access Management System (project ID: 46341 and 41910).

Review of secure MPC

MPC techniques enable multiple entities to securely and interactively perform computation on private inputs (Supplementary Note). Standard MPC frameworksleverage (additive) secret sharing, where each private value is split into random (encrypted) shares, which are in turn distributed to different computing parties. Although the shares collectively encode the private value, any subset of shares provably does not leak any private information. Computing parties then collaborate and use the secret shares to evaluate a function on the private input without revealing information about the private input to any entity involved. For example, the secure addition of two secretly shared numbers x and y can be executed by having each party add their individual shares for x and y. The new shares constitute a sharing of x + y, which is the desired computation result. More sophisticated functions (for example, multiplication, division, square root and sign) can be similarly defined over the secret shares but require the two parties to interact by exchanging a sequence of numbers, which also do not reveal private information. These secure routines can be composed to perform arbitrary operations on private input data held by multiple entities. However, the communication cost of MPC can introduce a bottleneck in applications involving complex tasks. In addition, secret sharing requires that the entire input data be shared with all computing parties.

---

### ACR practice parameter for communication of diagnostic imaging findings [^7ad45468]. ACR (2025). High credibility.

ACR practice parameter — communication policies and patient access notes that if an imaging department has written a policy on communication, it can be an effective tool to promote patient care, providing guidance on critical communications, responsible individuals, and appropriate methods, and to be effective, any written policy must be followed and shared within the institution. As technology changes and new methods of communication evolve, interpreting physicians may wish to modify their actions to accommodate these changes, but they must also remain in compliance with federal, state, and local statutes and developing legal requirements; HIPAA states that patients have a right to access their personal health information, and in recognition of this legal obligation and in the interest of added value and personalized medicine, the ACR recommends that all imaging reports be made readily available to the patient, including via posting through a Web-based portal. Any method used should consider the best interests of the patient and the professional relationship between the patient and the referring physician/health care provider, any Web-based portal must comply with federal, state, and, as appropriate, with hospital directives ensuring patient information integrity and security, and any known or suspected breach in the portal should be immediately reported to the appropriate agencies and patients involved.

---

### 'CTRL': an online, dynamic consent and participant engagement platform working towards solving the complexities of consent in genomic research [^6d186c23]. European Journal of Human Genetics (2021). Medium credibility.

Fig. 3
Incorporating Dynamic Consent into the existing Australian Genomics study participant pathway.

Pathway A reflects the current implementation strategy. Pathway B is also HREC-approved, but barriers experienced include lack of access to tablets or computers in the clinic and inability to pre-assign participant Study ID numbers, which is not compatible with ethics requirements and standard study practice.

The premise of a Dynamic Consent platform is that participants can make changes to their choices that will be reflected in real time. While an administrator interface for the portal is still under consideration as part of further development, three overlapping pathways have been established to allow the study team to access information in the CTRL website database and process changes in consent choices: (1) daily email reports generated by the platform that detail any new or changed registrations and changes to consent choices, (2) a securely hosted instance of Metabase, an open-source data analytic tool to view, extract and upload relevant data to the REDCap study database and (3) directly integrating crucial, time-sensitive information from the CTRL database into corresponding fields in the participant's REDCap study database profile. This means REDCap can be queried at any time to determine participants' consent preferences, and likewise access the complete history of changes made to consent choices. These methods reliably inform us of any actions that need to be taken by the study team, for example follow-up phone calls to participants.

---

### Blockchain vehicles for efficient medical record management [^aab6636a]. NPJ Digital Medicine (2020). Medium credibility.

Conclusion

A Blockchain allows data across multiple independent systems to be accessed simultaneously and immediately by those with sufficient permissions. This interfacing of different systems saves medical and financial sacrifices and reduces administrative delays. The use of smart contracts allows patients' consent preferences to be executed immediately, further reducing administrative costs. An off Blockchain data lake is scalable and can store a variety of data types, making it versatile and suitable enough for the developing forms of data brought about by the Internet of Things in the healthcare field. Furthermore, it supports high-throughput data analysis as well as machine learning strategies to be applied, while being encrypted and digitally signed to ensure data privacy and authenticity of access. Interoperability achieved in this manner will allow greater collaboration between patients, doctors and researchers, leading to specific and personalised care pathways.

Its weaknesses must however be taken into account during development: Blockchain involves concepts unfamiliar to the vast majority of the population, including cryptographic signatures and key management. Costs are involved in concealing these and assimilating data from various legacy systems while maintaining adherence to various regulatory restrictions.

Nevertheless, Blockchain represents an innovative vehicle to manage medical records, ensuring interoperability but without compromising security. It also protects patient privacy, allowing patients to choose who can view their data. Investments into this technology would be outweighed by returns as the interfacing of systems leads to increased collaboration between patients and healthcare providers, and improved healthcare outcomes.

Exclusive license

The authors grant to the Publishers and its licensees in perpetuity, in all forms, formats and media (whether known now or created in the future), to (i) publish, reproduce, distribute, display and store the Contribution, (ii) translate the Contribution into other languages, create adaptations, reprints, including within collections and create summaries, extracts and/or abstracts of the Contribution and convert or allow conversion into any format, including without limitation audio, (iii) create any other derivative work(s) based in whole or part on the on the Contribution, (iv) to exploit all subsidiary rights to exploit all subsidiary rights that currently exist or as may exist in the future in the Contribution, (v) the inclusion of electronic links from the Contribution to third-party material wherever it may be located and (vi) licence any third party to do any or all of the above.

---

### A mechanism for controlled access to GWAS data: experience of the GAIN data access committee [^b2e6c0c5]. American Journal of Human Genetics (2013). Low credibility.

The Genetic Association Information Network (GAIN) Data Access Committee was established in June 2007 to provide prompt and fair access to data from six genome-wide association studies through the database of Genotypes and Phenotypes (dbGaP). Of 945 project requests received through 2011, 749 (79%) have been approved; median receipt-to-approval time decreased from 14 days in 2007 to 8 days in 2011. Over half (54%) of the proposed research uses were for GAIN-specific phenotypes; other uses were for method development (26%) and adding controls to other studies (17%). Eight data-management incidents, defined as compromises of any of the data-use conditions, occurred among nine approved users; most were procedural violations, and none violated participant confidentiality. Over 5 years of experience with GAIN data access has demonstrated substantial use of GAIN data by investigators from academic, nonprofit, and for-profit institutions with relatively few and contained policy violations. The availability of GAIN data has allowed for advances in both the understanding of the genetic underpinnings of mental-health disorders, diabetes, and psoriasis and the development and refinement of statistical methods for identifying genetic and environmental factors related to complex common diseases.

---

### ESR white paper: blockchain and medical imaging [^173441f4]. Insights Into Imaging (2021). Medium credibility.

Clinical trials framework for biomarker derivation

Clinical trials are key in informing changes in clinical practice. Rigorous trial conduct and an audit trail with absolute transparency are mandatory elements for a successful and reliable trial. As imaging is frequently a cornerstone of identifying disease progression or regression, blockchain technology has the potential to introduce a tamper-proof mechanism for recording imaging data within clinical trials. This encompasses all stages of image manipulation, analysis and quantitative assessment. Imaging data in trials is often derived from pre-specified imaging protocols, and variations in these, or their inaccurate recording, have potential to alter the images and therefore the measured outputs. The temptation to manipulate images prior to measurement is removed by the implementation of blockchain, ensuring the integrity of the images and their measurements. This kind of audit is of particular value when images are being uploaded or downloaded between participating sites to perform multiple measurements. Any change to image settings prior to making measurements, which potentially will influence outcomes, would be date- and time-stamped by the blockchain system, so acknowledging when and by whom the changes were made. This would avoid inappropriate data manipulation and ensure traceability of any significant changes. Any data corruption would be identified without the need for human interrogation of the data. In an era where commercial outputs often hang on the validity of imaging measurements, a robust method of documenting measurement history is vital.

Specific areas that could exploit blockchain technology within an imaging trials portfolio include lesion segmentation and implementation of analysis algorithms. Segmentation is traditionally manual, but increasingly is becoming semi- or even fully-automated. Often the manual segmentation data sets annotated by experts are used to train an algorithm to autonomously achieve a similar result. Documentation of the training sets, and their adjustments in the context of experts and software would provide insights into the basis for the machine-learnt outputs and explain unexpected variations. Data groups for each block could be assigned by patient visit, or by groups of examinations at specific time-points within the trial.

Overwhelming evidence of bias exists when commercial or academic investigators analyze and report their own findings. Blockchain technology applied to imaging within clinical trials would deliver provenance-assured data sets to third parties for analysis. This would separate the hypothesis driving the trial from the expected results. A particular bonus would be in secondary research exploiting data sets from imaging biobanks, where the integrity of the raw data, especially when pooling data from multiple trials, could be assured.

---

### Concealable physical unclonable functions using vertical NAND flash memory [^e37c2927]. Nature Communications (2025). High credibility.

Introduction

The explosive growth of the Internet of Things (IoT) is connecting numerous network devices in everyday life, collecting sensitive information such as basic secret data like passwords, as well as health information and authentication tokens for financial transactions –. While the development of IoT has brought significant convenience, concerns about personal information leakage have grown, increasing the need for hardware security to protect data from hacking, cyberattacks, and counterfeiting. Traditional hardware security primarily relies on storing secret keys in Non-Volatile Memory (NVM), with the key serving as the most critical and fundamental piece of information for constructing hardware security protocols. While the processes and methods for constructing security protocols are public, the key must remain secret, as it becomes the sole means to compromise security, underscoring the paramount importance of concealing the key. However, the non-volatile nature of NVM, which retains information even when powered off, makes key security vulnerable and hinders preventing key duplication. Moreover, side-channel attacks that exploit radiation emitted or power consumption from NVM storing the key can also provide access to the key. These security weaknesses of storing keys in NVM highlight the need for more robust hardware security mechanisms.

One emerging alternative to enhance hardware security is the Physical Unclonable Function (PUF). PUF is considered analogous to human fingerprints as it generates unique and unpredictable keys, earning it the name "device fingerprint, ". The entropy required to produce random PUF keys primarily originates from the random physical properties, process variations, and minor variations introduced during the fabrication process. Since random sources are naturally introduced during the fabrication process, PUFs incur minimal additional cost while offering a critical advantage that even the manufacturer cannot easily predict or replicate –. Another distinguishing feature of PUFs compared to fixed security keys like passwords is their interactive nature, where different outputs are generated based on the input. The input is referred to as a "challenge", and the corresponding output is called a "response", together forming a Challenge-Response Pair (CRP). The security approach using CRP generation strengthens security because the output is different from the input, and different inputs yield different outputs.

---

### Clinical bioinformatician body of knowledge-clinical laboratory regulation and data security core: a report of the Association for Molecular Pathology [^19b17113]. The Journal of Molecular Diagnostics (2025). High credibility.

Encryption — A key security consideration is to ensure that data are safely secured, contained, and isolated; this includes appropriate levels of encryption of the stored data at rest (including permanent and ephemeral storage during computation) and during transfer, and appropriate controls and protocols should be in place for authentication and encryption of key access and storage.

---

### Synthetic DNA applications in information technology [^6c2dc7c0]. Nature Communications (2022). High credibility.

The idea of designing a cryptosystem made of DNA molecules was first introduced by Gehani et al. in 1999, who proposed techniques that were in principle unbreakable. In the same year, Clelland et al. created the first DNA-based steganography scheme to conceal messages within a large pool of random DNA. Their idea was to encode a plain-text message into the four nucleotides of DNA, subsequently mixing the message-DNA with human genome DNA for the message-DNA to be hidden. With knowledge of the primer to amplify the message-DNA as well as the encryption key, the recipient could then use PCR to decipher the DNA message.

Mainly inspired by the high information density of DNA, various data encryption schemes, exploiting the benefits of Watson–Crick complementary base pairing was developed thereafter. Some of the methods for decryption relied on PCR or gel-electrophoresis so that there was no need for sequencing, which seemed advantageous at the time when sequencing readout was slow and more costly than it is today. The paradigm shift of DNA cryptographic thinking began when researchers not only made use of the sequence information in DNA strands but started taking advantage of the high structural versatility DNA has to offer. This enabled methods for secure communication like DNA origami cryptography (DOC), generating scaffold DNA nanostructures that allow for complex patterning of molecules. This scaffolding technique opens up an enormous design space, allowing for a theoretical key size of 700 bits (in contrast to the advanced encryption standard, which uses 256 bits). The DOC architecture also allows for differential access to only parts of the encrypted message and overall guarantees confidentiality, integrity, and availability (CIA) of information opening the door for biomolecular next-generation information security. Despite these vast opportunities, intrinsic limitations of characterization methods restrict usage of the hypothetically huge keyspace (as resolution or 3D characterization methods limit the level of detection), and in addition, long read-out times of a few hours cannot yet compare to electronic computation standards. More in-depth reviews of DNA as a tool for cryptography are available in literature by Lustgarten et al.and by Zhang et al.

---

### Use of mobile devices for medical imaging [^1233a206]. Journal of the American College of Radiology (2014). Low credibility.

Mobile devices have fundamentally changed personal computing, with many people forgoing the desktop and even laptop computer altogether in favor of a smaller, lighter, and cheaper device with a touch screen. Doctors and patients are beginning to expect medical images to be available on these devices for consultative viewing, if not actual diagnosis. However, this raises serious concerns with regard to the ability of existing mobile devices and networks to quickly and securely move these images. Medical images often come in large sets, which can bog down a network if not conveyed in an intelligent manner, and downloaded data on a mobile device are highly vulnerable to a breach of patient confidentiality should that device become lost or stolen. Some degree of regulation is needed to ensure that the software used to view these images allows all relevant medical information to be visible and manipulated in a clinically acceptable manner. There also needs to be a quality control mechanism to ensure that a device's display accurately conveys the image content without loss of contrast detail. Furthermore, not all mobile displays are appropriate for all types of images. The smaller displays of smart phones, for example, are not well suited for viewing entire chest radiographs, no matter how small and numerous the pixels of the display may be. All of these factors should be taken into account when deciding where, when, and how to use mobile devices for the display of medical images.

---

### Clinical bioinformatician body of knowledge-clinical laboratory regulation and data security core: a report of the Association for Molecular Pathology [^0b592785]. The Journal of Molecular Diagnostics (2025). High credibility.

Genetic information protections, interoperability and breach notification requirements, and research oversight include the following: The Genetic Information Nondiscrimination Act of 2008 prohibits discrimination on the basis of genetic information with respect to health insurance and employment and required the Department of Health and Human Services to classify genetic information as health information under the HIPAA Privacy Rule; the Health Information Technology for Economic and Clinical Health Act implemented Promoting Interoperability (formerly Meaningful Use) requirements for certified EHR systems, added to and strengthened enforcement of HIPAA, added Security Breach Notification Rule and requirements for secure health information exchange, and is part of the American Recovery and Reinvestment Act of 2009; the HIPAA Omnibus Rule strengthened the security and privacy of health information under HIPAA, modified the Security Breach Notification Rule, and modified the HIPAA Privacy Rule to strengthen privacy protections for genetic information by implementing Title I Section 105 of GINA; FDA Guidance on Validation of Blood Establishment Computer Systems sets validation requirements for systems performing genetic testing that may inform assignment of blood products to patients; the 21st Century Cures Act implements interoperability requirements and security practices for health information exchange and access, supports patients' access to their EHR data (including laboratory results), and increases transparency of health care cost data to patients; and the Federal Policy for the Protection of Human Subjects (the Common Rule) revised the rule governing research on human subjects funded by the federal government and provides a new definition for identifiable biospecimen.

---

### Guidelines for the practice of telepsychology [^6a22bf2c]. The American Psychologist (2013). Medium credibility.

Guideline 3 — data security, management, and transmission — psychologists who provide telepsychology services seek to take reasonable steps to ensure security measures are in place to protect patient/client/service recipient data from unintended access, disclosure, loss, or corruption, and psychologists are encouraged to be mindful of potential threats such as computer malware, hackers, device loss or theft, damaged drives, flawed software, unsecured files, outdated technology, third-party policies on data use, and data breaches of partner technology companies. Psychologists are encouraged to be mindful of these potential threats and aim to take reasonable steps to ensure that security measures are in place for protecting and controlling access to patient/client/service recipient data within an information system; this applies to data created, stored and/or transmitted by the psychologist, including data stored on third-party platforms, and psychologists are encouraged to be cognizant of relevant laws and regulations (e.g. HIPAA, Health Information Technology for Economic and Clinical Health Act [HITECH], GDPR) and to develop appropriate policies and procedures to comply with such directives. In application, psychologists are encouraged to conduct a routine analysis of the potential security risks to their practice setting, telecommunication technologies (including devices), and staff access to ensure that data is accessible only to appropriate and authorized individuals, strive to obtain appropriate training or consultation from relevant experts when additional knowledge is needed, strive to maintain these guidelines when practicing in institutions with their own technology infrastructure, and also strive to comply with recordkeeping requirements for documenting authorized access requests and any unauthorized access or data breaches; when developing policies and procedures, psychologists may consider concerns posed by public and private devices and wireless networks, safeguards for different environments and staff roles, and various telecommunication technologies.

---

### Extended outlook: description, utilization, and daily applications of cloud technology in radiology [^6fc6ced3]. AJR: American Journal of Roentgenology (2013). Low credibility.

Objective

The purpose of this article is to discuss the concept of cloud technology, its role in medical applications and radiology, the role of the radiologist in using and accessing these vast resources of information, and privacy concerns and HIPAA compliance strategies.

Conclusion

Cloud computing is the delivery of shared resources, software, and information to computers and other devices as a metered service. This technology has a promising role in the sharing of patient medical information and appears to be particularly suited for application in radiology, given the field's inherent need for storage and access to large amounts of data. The radiology cloud has significant strengths, such as providing centralized storage and access, reducing unnecessary repeat radiologic studies, and potentially allowing radiologic second opinions more easily. There are significant cost advantages to cloud computing because of a decreased need for infrastructure and equipment by the institution. Private clouds may be used to ensure secure storage of data and compliance with HIPAA. In choosing a cloud service, there are important aspects, such as disaster recovery plans, uptime, and security audits, that must be considered. Given that the field of radiology has become almost exclusively digital in recent years, the future of secure storage and easy access to imaging studies lies within cloud computing technology.

---

### A blockchain consensus mechanism for real-time regulation of renewable energy power systems [^e6c19a3e]. Nature Communications (2024). High credibility.

Discussion

Security at the information layer becomes increasingly important for the control, dispatch, and trading of power energy systems. With the access to a large number of renewable energy resources, the increasing level of power electronification and informatization in power energy systems, traditional control methods in a passive way would be sluggish in the face of network imperfections. Developed PoT is a blockchain consensus mechanism tailored for real-time control tasks, providing reliable and desired regulation effects for REPSs in the presence of cyber threats. The performance in the test validates that PoT not only effectively improves the security and computing capability of power energy systems, but also facilitates the accomplishment of complex control tasks under various physical constraints. Furthermore, three different applications suggest that the proposed consensus protocol is both effective and generalizable for various configurations of REPSs.

PoT has been successfully applied to the distributed secondary control of renewable energy resources-based DC microgrids and load frequency control for multi-area interconnected power systems. In addition, the PFC, a kind of degraded PoT consensus mechanism, provides a feasible and simplified solution for applying PoT in the centralized control of DC microgrids. The superiority of PoT lies in its real-time performance, multi-pattern data protection, and computational resource extraction, combined with the intelligence to perceptually adjust consensus participants. These characteristics allow PoT to provide a trusted and fast computing paradigm. Besides being able to provide abundant computational resources, PoT also possesses the innate property of trustworthiness, which is not available in other computing modes. This technology is promising to broaden the application scope of blockchain, and facilitate the development of smart energy.

---

### Quantum-secure covert communication on bosonic channels [^d6d6601a]. Nature Communications (2015). Medium credibility.

Encryption prevents unauthorized access to transmitted information — a security need critical to modern-day electronic communication. Conventional computationally secure encryption, information-theoretic secrecyand quantum cryptographyoffer progressively higher levels of security. Quantum key distribution (QKD) allows two distant parties to generate shared secret keys over a lossy–noisy channel that are secure from the most powerful adversary allowed by physics. This shared secret, when subsequently used to encrypt data using the one-time-pad cipher, yields the most powerful form of encryption. However, encryption does not mitigate the threat to the users' privacy from the discovery of the very existence of the message itself, nor does it provide the means to communicate when the adversary forbids it. Thus, low probability of detection/intercept, or covert communication systems are desirable, which not only protect the message content but also prevent the detection of the transmission attempt.

---

### Digitizing clinical trials [^2b0d9709]. NPJ Digital Medicine (2020). Medium credibility.

Clinical trials are a fundamental tool used to evaluate the efficacy and safety of new drugs and medical devices and other health system interventions. The traditional clinical trials system acts as a quality funnel for the development and implementation of new drugs, devices and health system interventions. The concept of a "digital clinical trial" involves leveraging digital technology to improve participant access, engagement, trial-related measurements, and/or interventions, enable concealed randomized intervention allocation, and has the potential to transform clinical trials and to lower their cost. In April 2019, the US National Institutes of Health (NIH) and the National Science Foundation (NSF) held a workshop bringing together experts in clinical trials, digital technology, and digital analytics to discuss strategies to implement the use of digital technologies in clinical trials while considering potential challenges. This position paper builds on this workshop to describe the current state of the art for digital clinical trials including (1) defining and outlining the composition and elements of digital trials; (2) describing recruitment and retention using digital technology; (3) outlining data collection elements including mobile health, wearable technologies, application programming interfaces (APIs), digital transmission of data, and consideration of regulatory oversight and guidance for data security, privacy, and remotely provided informed consent; (4) elucidating digital analytics and data science approaches leveraging artificial intelligence and machine learning algorithms; and (5) setting future priorities and strategies that should be addressed to successfully harness digital methods and the myriad benefits of such technologies for clinical research.

---

### A blockchain consensus mechanism for real-time regulation of renewable energy power systems [^94fd120e]. Nature Communications (2024). High credibility.

With the ongoing development of renewable energy sources, information technologies and physical energy systems are further integrated, which leads to challenges in ensuring the secure and stable operation of renewable energy power systems in the face of potential cyber threats. The strengths of blockchain in cybersecurity make it a promising solution to these challenges. However, existing blockchains are not well-suited for control tasks due to their low real-time performance. Here, we present a consensus mechanism that enables real-time security control of systems, called Proof of Task. Instead of solving meaningless hash puzzles in Proof of Work, Proof of Task addresses problems closely related to the stable operation and control performance of these systems. With the proposed verification mechanism, Proof of Task significantly enhances the real-time performance of blockchain while mines its computational resources for tasks of interest. To demonstrate the effectiveness and necessity of Proof of Task, it is deployed across three renewable energy power systems. The results show that Proof of Task markedly fortifies the security and computing capability of these systems, ensuring their reliable and stable operation. This work highlights the promise of blockchain to facilitate security control and trusted computing of large-scale, complex-dynamic systems.

---

### Wireless communications sensing and security above 100 GHz [^8763a749]. Nature Communications (2023). High credibility.

Today's wireless networks provide multi-user capabilities, in which an access point or base station transmits to (or receives from) multiple users simultaneously in order to increase aggregate data rate and decrease latency. Realizing this capability with THz frequencies will require two new advances. First, waveforms and modulation formats must be designed to support simultaneous transmission, incorporating that users will not be co-located and will be using directional transmissions. In some downlink cases, spatial separation of receivers combined with narrow beams may provide a simple starting point. Yet, for the uplink, and even for the downlink when users are close together, interference and co-stream management must be carefully controlled. Second, even if a network has the physical capability to realize a multi-user transmission, control plane mechanisms are needed to coordinate the transmission. Namely, the control plane must identify and localize the users, determine the appropriate spectrum and modulations to use, trigger the transmission at the correct time, and so on. In some cases, these functions are sufficiently similar to those of existing networks that comparable methods can be used; in other cases, entirely new protocols will need to be developed. For example, while traditionally medium access control protocols are driven by the transmitter, an alternative procedure based on receiver-initiated link synchronization, in which a receiver periodically polls potential transmitters as its antenna sweeps / scans the space, can increase the reliability and throughput and reduce latency.

---

### Recommendations for achieving interoperable and shareable medical data in the USA [^19fa6a00]. Communications Medicine (2022). Medium credibility.

Easy access to large quantities of accurate health data is required to understand medical and scientific information in real-time; evaluate public health measures before, during, and after times of crisis; and prevent medical errors. Introducing a system in the USA that allows for efficient access to such health data and ensures auditability of data facts, while avoiding data silos, will require fundamental changes in current practices. Here, we recommend the implementation of standardized data collection and transmission systems, universal identifiers for individual patients and end users, a reference standard infrastructure to support calibration and integration of laboratory results from equivalent tests, and modernized working practices. Requiring comprehensive and binding standards, rather than incentivizing voluntary and often piecemeal efforts for data exchange, will allow us to achieve the analytical information environment that patients need.

---

### Creating an IHE ATNA-based audit repository [^483841c1]. Journal of Digital Imaging (2006). Low credibility.

Compliance with the Health Insurance Portability and Accountability Act (HIPAA) requires gathering audit information from picture archiving and communications systems (PACS) regarding evidence trails of human interactions. Until recently, most PACS users have had limited access to auditing information. Access required resources to handle manual inspection of audit logs, and access to proprietary databases was not always available. Some vendors now produce eXtensible Markup Language (XML) audit logs based on certain events occurring in PACS. However, it is up to the user to convert this information into an easily mined data repository supporting compliance and quality control. This process can be handled in multiple ways, which could mean different audit mechanisms depending on the PACS (or other hospital system) used. It is apparent that an organized method of dealing with audit information is needed. This help may be provided within the Integrating the Healthcare Environment (IHE) framework. The IHE initiative defines a set of profiles, actors, and transactions that create common scenarios for particular workflow processes. The Integration Profiles depict security as a fundamental requirement of the framework. Specifically, the Audit Trail and Node Authentication (ATNA) profile defines standards based mechanisms for securely transmitting and storing audit records in a central repository. The data structure defined by the profile provides a number of record types that capture different audit events. A general feasibility study for storing currently available PACS audit information following the profile is defined, and steps to an automated solution are discussed.

---

### Blockchain vehicles for efficient medical record management [^c65caf7b]. NPJ Digital Medicine (2020). Medium credibility.

Fig. 1
Progress of a Blockchain transaction.

Public-key cryptography creates a public and a private key for each user, using a one-way hash function to create the public from the private key. The public keys are used by the sender and receiver of a transaction to identify each other. Private keys remain undisclosed, and are used by the sender and receiver to sign and verify transactions, respectively. Here, User 1 sends a transaction to User 2, using User 2's Public key. User 2 receives the transaction, identified as having been sent by User 1's public key.

The system can also allow components of arbitrary logic to be added in order to process, validate, and sanction access to the data secured within, simplifying consent processes for patients and doctors. This is known as a smart contract, and functions as a string of computer code that executes whenever these certain predetermined conditions are met, ensuring both the security of the system and authorised access. It is this ability to create smart contracts that makes Blockchain suitable for healthcare, a field in which strict regulations govern how sensitive data may be used, an increasingly important factor following the recent introduction of the General Data Protection Regulation.

Another major concern relating to healthcare records is the cost associated with transferring records between locations, and in particular between Trusts. Sending data via email is considered a security risk, while there is clear inefficiency inherent in transcribing a digital asset onto optical media, which is commonly only read once at the receiving site. Furthermore, repeated imaging studies carried out because of unavailability of prior results can be dangerous in the context of delayed treatment as well as financially costly. As a decentralised database, Blockchain is fundamentally interoperable, and authorised sharing of data comes at no extra cost.

---

### Unaddressed privacy risks in accredited health and wellness apps: a cross-sectional systematic assessment [^fda95de3]. BMC Medicine (2015). Low credibility.

Data transmission assessment

To capture data transmitted by included apps, we reconfigured local network infrastructure so that a copy could be obtained without interrupting the flow of communication, a form of eavesdropping known as a 'man-in-the-middle' attack (Fig. 1). The advantage of this approach was that it required no modification to either apps or online services that might have affected the process of data exchange and bias interpretation. We combined an existing open source software tool with custom scripting and back-end database to capture and store all traffic generated during the test period. By making a simple configuration change to the operating systems on each test device, we were able to intercept encrypted communications in addition to unsecured traffic (principles explained in Additional file 1: Figure AF2).

Fig. 1
A 'man-in-the-middle' attack. A man-in-the-middle attack is able to intercept network traffic sent by a mobile app in a way that is invisible to users and services

Prior to the start of the evaluation, we conducted pilot testing using a range of system and user apps not included in the study to ensure that all data would be captured. We anticipated that some test apps might implement certificate pinning, a technical security measure designed to prevent man-in-the-middle attacks on encrypted communications. However, in practice, this was only observed for certain communications generated by the mobile operating system and did not affect interception of traffic generated by test apps.

Personal information sent by apps was categorized in a two-part process, using the same coding schema used to analyze data collection (Additional file 1: Table AF1). In the first step, an automated process was used to classify data according to destination and the mechanisms used to secure the content, if at all. Known instances of particular data types were also identified automatically by searching for user details generated during testing such as app-specific simulated email addresses. No data were discarded during automatic coding. In the second step, the content of captured traffic was displayed in a custom software tool for manual review (see Additional file 1: Figure AF3). Although all traffic was inspected, multiple transmissions with identical content (excluding timestamps) were automatically combined for review. The review process allowed study reviewers to check automatic tagging and manually code any personal information not already identified. Coding was performed by two researchers, working independently, and reconciled through discussion.

---

### ERegistries: governance for electronic maternal and child health registries [^9aa9a5d9]. BMC Pregnancy and Childbirth (2016). Low credibility.

Security

Security is defined as strategies such as safeguards, policies, or protocols through which access or sharing of patient health information by stakeholders is controlled and protected from intentional or unintentional disclosure to unauthorized persons, and from loss, destruction or alternation. Security controls applied to electronic data can take many forms including anonymity techniques, encryption, authentication systems, access control models, access policies, user roles, audit logs, and education and training of employees.

As reported by public health officials, the physical, administrative, and technical data security safeguards currently in use do not appear to adequately safeguard women's and children's highly sensitive health information. A common assumption is that since electronic information systems are in a nascent stage in many LMICs, the skills to access systems unlawfully are similarly underdeveloped. Yet, this discounts potential threats from outside a country. Such general skepticism of potential threats may reflect an overall lack of concern and subsequent inaction by many e- and mHealth projects in LMICs. Moreover, data and information security is maintained differently in resource-constrained countries given the limited ICT capacity, training, and resources. As a result, privacy and security issues have not received the same attention in countries with emerging electronic health systems. In addition, a workforce inexperienced or untrained in safe data practices may not fully appreciate the far-reaching implications of security breaches.

Another rationale for not prioritizing security issues is the notion that health needs outweigh privacy concerns in LMIC countries. Moreover, there may be a presumption that it is too premature to address these issues prior to security legislation or regulation being adopted. The potential for harm and unintended consequences of ignoring legal and ethical issues, however, is considerable on both an individual and societal level. Compromising the privacy of an individual's sensitive health information can have devastating consequences for the individual and his/her family and on a larger scale, could undermine trust in electronic health information systems in general thereby undercutting efforts to improve health.

---

### Acquisition, analysis, and sharing of data in 2015 and beyond: a survey of the landscape: a conference report from the American Heart Association data summit 2015 [^a99ec9a2]. Journal of the American Heart Association (2015). Low credibility.

Models of Responsible Data Sharing

A useful set of principles to govern the pursuit of responsible data sharing was laid out in an article in The New England Journal of Medicine. 88 First, the model should provide sufficiently broad access to data to achieve the sought‐after benefits. It should apply to trials of all drugs, devices, and biologics approved in at least 1 country. Second, it should be designed to maximize protection of participants' privacy interest. Third, it should treat all qualified data requesters and trial sponsors evenhandedly. Fourth, it should ensure accountability by requiring data requesters to commit to protecting participants' privacy and conducting analyses that adhere to accepted scientific standards. If those who generate the data are allowed to influence when the data are released, they must commit to transparent, principled decision making. Finally, the system should be practicable. It must be able to render timely decisions and avoid undue burdens on data generators. To advance these principles, a data‐sharing system should have the following specific features:
A binding mechanism to ensure universal participation and compliance by data generators — a regulatory requirement is the most obvious mechanism, although trial sponsors would prefer a private alternative
Minimum standards for what must be shared and how
Equal application of any requirements to all trial sponsors
Explicit decision criteria for data releases
Public disclosure of the reasons for decisions
Public disclosure of requesters' identities and analysis plans
A mechanism to enforce conditions of data use, such as a data use agreement
Provision of technical support to ensure that data requesters understand the data

In public discussions of data sharing, 4 models have emerged. In the first, an "open access model", data sets and accompanying materials would be posted online for downloading. This model would serve the principles of broad access and transparency superbly but would not provide sufficient protection of the interests of participants and data generators.

In the second model, a "database query" model, the data generator would continue to hold the data and would run analyses on the data at the request of outside parties and send out the results. The data generator would be obliged to run any analysis that met the following 3 decision criteria:
Is there a reasonable scientific hypothesis, sound analytical plan, and adequate plan to disseminate findings?
Do the potential public health benefits of answering the proposed question outweigh the probable adverse effects on the data generator and risks to participants?
Does the requester have expertise sufficient to carry out the analyses?

---

### Quantum cryptography and data protection for medical devices before and after they meet Q-day [^7c9fb539]. NPJ Digital Medicine (2025). Medium credibility.

Quantum cryptography and computing for clinicians

But why is encryption flawed, and how do quantum-safe methods differ from current approaches? Modern encryption can be categorised into symmetric and asymmetric methods. Symmetric encryption, such as the Advanced Encryption Standard (AES), uses a shared secret key for both encryption and decryption. Conversely, asymmetric methods, such as RSA, rely on mathematically related public and private keys. The public key is created from two very large secret prime numbers, and the private key depends on knowing these primes. Since factoring such large numbers is only possible by testing every combination, it is practically impossible for classical computers. Thus, the private key cannot be feasibly derived from the public one. These techniques underpin protocols like Transport Layer Security (TLS) in a hybrid manner, which secures online communications. At a high level, when a client initiates a secure connection with a website, the client and server exchange cryptographic keys and verify authenticity through certificates and digital signatures using asymmetric methods. More efficient symmetric algorithms then protect the actual data transfer, ensuring confidentiality, authenticity, and integrity. The previously exchanged key is used for encryption and decryption (Fig. 1).

Fig. 1
Symmetric, asymmetric, and hybrid encryption methods.

The hybrid encryption method uses a two-stage approach. First, a secret key is shared using an asymmetric encryption method. Second, the main message is sent using a symmetric encryption method.

QC alters this landscape. Shor's algorithm, introduced in 1994, demonstrated that large prime numbers can be efficiently factorised on a quantum computer, thereby breaking RSA and ECC. These widely used asymmetric systems would no longer be secure once functional quantum computers exists. In contrast, symmetric algorithms are less affected. Here, Grover's algorithm can speed up brute-force key searches, but its advantage is limited. Increasing key sizes, such as moving from AES-128 to AES-256, is sufficient to maintain security against such attacks for the time being. However, because protocols like TLS rely on asymmetric encryption to exchange symmetric keys, the compromise of the asymmetric component would expose those keys, allowing attackers to decrypt the entire communication.

---

### Clinical bioinformatician body of knowledge-clinical laboratory regulation and data security core: a report of the Association for Molecular Pathology [^438bf27d]. The Journal of Molecular Diagnostics (2025). High credibility.

Cybersecurity review criteria for software and pipelines — the criteria to be considered include: ability to demonstrate that developers understand the technology underlying the software, flow of data, and existing infrastructure to ensure secure integration; ability to provide compliance with appropriate governance, regulation, and privacy regulations; ability to demonstrate familiarity with software security basics (confidentiality, integrity, availability, authentication, authorization, auditing, and management of configuration, sessions, and exceptions); ability to provide documentation of protections for sensitive information with appropriate data classification; availability of design documentation for application security design, vulnerabilities, and security threats; ability to demonstrate appropriate implementation of security controls with documentation of code reviews for security vulnerabilities and penetration testing; specifications of a test environment appropriately matched to the production environment; ability to follow the change management process, including managing software releases and bug fixes; and ability to describe the process used for vulnerability and penetration testing before deploying new software versions.

---

### Secure and scalable gene expression quantification with pQuant [^62543822]. Nature Communications (2025). High credibility.

Computations on encrypted data can be achieved through homomorphic encryption, a cryptographic method that allows computation on ciphertexts, producing an encrypted result that, when decrypted, matches the result of operations performed on the plaintext. Homomorphic encryption has several advantages over other cryptographic techniques used in genomics such as Secure Multiparty Computation (MPC)and Trusted Executive Environments (TEE). Computations with homomorphic encryption do not depend on communication between servers (such as MPC) and the security in homomorphic encryption is grounded in the hardness of specific mathematical problems while TEEs requires security at the hardware level. Consequently, homomorphic encryption is less vulnerable to privacy attacks and easily accessible for use in cloud settings.

The most direct approach to utilizing homomorphic encryption for gene expression quantification would be adopting widely used RNA-seq analysis algorithms to operate under homomorphic encryption protocols. We show that such direct adaption is not possible due to the limitations of homomorphic encryption (please see Suplementary Methods 3.1 for a detailed explanation). Thus, to leverage the privacy-preserving properties of homomorphic encryption in RNA-seq analysis, it is necessary to develop a quantification algorithm that is compatible with homomorphic encryption. There are two key considerations to develop such an algorithm. First, it should only employ simple mathematical operations, such as additions or multiplications. Second, it should be data-independent, meaning that any operations performed on encrypted data should be computed without any information of private data.

---

### Occupational electronic health records: recommendations for the design and implementation of information systems in occupational and environmental medicine practice-ACOEM guidance statement [^4a904a0e]. Journal of Occupational and Environmental Medicine (2024). High credibility.

Informatics considerations for occupational electronic health records (OEHRs) — regulatory and privacy/communication elements note that the 21st Century Cures Act Final Rule (2020) emphasizes secure and streamlined patient access to personal health data at no cost and prohibits information blocking; the Cures Act promoted a standardized API enabling any computer system, including third-party vendors, to request and gain access to personal electronic health records; most healthcare systems comply via patient-facing online health portals that enable direct access to personal health records and secure communication; to remain compliant, portals should include a messaging platform over secure and encrypted communication channels, and employees should be discouraged from communicating PHI through personal or work email accounts due to less restrictive security protocols and higher liability for privacy breaches under HIPAA; while portals may permit online forms and uploads from wearables and other medical devices, employee health portals should also be careful to discourage downloading PHI on publicly accessible work computers; employer-facing portals allow supervisors and human resources personnel access to limited data on work status and restrictions, and such access controls must be tightly coordinated with human resources to ensure sharing only with current and appropriate supervisors on a need-to-know basis; employer-facing portals may pull limited data from an OEHR through API calls.

---

### Secure and federated genome-wide association studies for biobank-scale datasets [^50d590bf]. Nature Genetics (2025). High credibility.

Our algorithmic design strategies for enabling secure population structure correction

Our federated framework for secure computation allows us to develop efficient and provably secure algorithms for collaborative GWAS. Our work introduces practical methods for two standard approaches to account for population structure, namely PCA and LMMs. We adopt the following algorithmic design strategies to obtain accurate and efficient performance. First, we closely adhere to the computational pipeline of the desired centralized algorithm to obtain accurate results while securely operating over private datasets held by multiple parties. This is in contrast to other collaborative approaches that simplify or approximate the analysis to address the lack of access to a pooled dataset (for example, meta-analysis). Next, we restructure the computation while maintaining its equivalence to the original algorithm to both maximize the use of low-cost operations and minimize communication by leveraging local plaintext data. We switch between MPC and MHE routines throughout the protocol to improve the efficiency and numerical robustness of our routines. We also optimize the vectorized encoding of data in encrypted representations for efficient composition of linear algebra operations. We detail our algorithmic strategies and optimization techniques in Supplementary Note.

In addition to enabling a substantial performance improvement for PCA compared to prior work, our techniques facilitate the design of a practical protocol for secure and federated LMMs (Supplementary Note). LMMs typically involve operations on the genetic relatedness matrix, which scale with the number of individuals in the dataset and impose a notable computational burden for large cohorts, even in centralized analysis settings. Our approach builds upon REGENIE, a recently developed algorithm for LMM association tests based on a stacked ridge regression approach, which directly models the ancestry-related confounding effect as the output of a genome-wide regression model, thus circumventing the use of a genetic relatedness matrix. This approach brings scalability improvements while providing accuracy comparable to other LMM methods such as BOLT-LMM, fastGWAand SAIGE. Unfortunately, REGENIE cannot be directly applied in a secure federated setting. Although ridge regression can be efficiently performed in plaintext on a pooled dataset, implementing standard algorithms (for example, those based on the closed-form solution) with secure computation techniques results in impractical runtime requirements due to the complex matrix operations, such as inversion, that need to performed on large encrypted matrices.

---

### Guidelines for the practice of telepsychology [^4fa5b56a]. The American Psychologist (2013). Medium credibility.

Guideline 4 — data disposal — psychologists who provide telepsychology services are encouraged to make reasonable efforts to dispose of personally identifiable information (PII), including protected health information (PHI) data, and related technologies used to create, store, and transmit these data in an appropriate manner. Properly disposing of records in a manner that preserves patient/client/service recipient confidentiality and privacy requires awareness of appropriate methods for clearing, purging, or destroying PII and the technologies that interact with it, and psychologists are therefore encouraged to conduct an analysis of the potential risks for their specific practice requirements and formulate a plan for proper disposal of PII and the technologies that create, store, and transmit it. Psychologists are responsible for the maintenance and, when appropriate, disposal of all paper-based and electronic PII, including PHI, and, for example, the NIST Guidelines (NIST SP 800–88, 2014) offer guidance for effectively clearing, purging, and destroying data stored on electronic media devices; psychologists are encouraged to seek consultation from technology experts when needed. To foster proper digital disposal techniques, psychologists recognize the limitations of deleting information from a system, which can allow for recovery of such information later, and psychologists strive to securely dispose of software and hardware used in the provision of telepsychology services as well as the generation, storage, and transmission of PII in a manner that ensures the confidentiality and security of patient/client/service recipient information. Toward this end, psychologists seek to ensure that all PII data is removed from hardware (e.g., computer, mobile device, tablets, remote monitoring devices, fax machines, printers, peripheral storage devices such as external memory drives) before disposal of the hardware, and psychologists endeavor to remove all PII data and images stored in software.

---

### Web services and cloud computing in pediatric care [^ecb7a4be]. Pediatrics (2021). High credibility.

Needs for authentication and auditing — health care applications such as electronic health records (EHRs) are held to a higher standard than consumer applications, and EHRs ensure that the chain of data from entry to storage and retrieval is secure, auditable, and restricted to individuals with appropriate authorization. Access to and editing of patient information are often restricted by role; inappropriate chart access may be a terminable offense, records are to be accessed only by individuals who are authorized by policy, and access to patient charts should be audited. Web services and applications need to preserve these safeguards, including user authentication and authorization, and are not allowed to take shortcuts, such as permitting Web services or applications to use a higher level of privileges than the user. Audits of who accessed data to determine if access was proper and legal are important, and when Web services that access and/or store data are implemented, this access must be recognizably recorded for auditing purposes so that practices can determine if data compromise is a result of data stored by Web services or a breach of security at the practice.

---

### Security guidance for select agent or toxin facilities: 7 CFR part 331, 9 CFR part 121, 42 CFR part 73 [^ba2e016e]. CDC (2013). Medium credibility.

Animals exposed to a Tier 1 BSAT — security controls: An animal that is experimentally infected or exposed to a Tier 1 BSAT must be secured as a Tier 1 BSAT itself until such time as it is demonstrated to be free of that select agent. Individuals who exposed the animal must be SRA approved and have gone through the entity's pre-access suitability and subject to on-going assessment, and personnel who handle or care for the animal must be SRA approved and have gone through the entity's pre-access suitability and subject to on-going assessment. The area where the animal is handled and housed meets all the physical security requirements for Tier 1 agents. Final barrier usually the door to the suite. Verification Check Access logs.

---

### Secure wireless communication of brain-computer interface and mind control of smart devices enabled by space-time-coding metasurface [^40d8e7d1]. Nature Communications (2025). High credibility.

Introduction

Brain–computer interface (BCI) has emerged as a cutting-edge technology in human–machine interaction and demonstrates promising applications such as brain-controlled spelling input, medical rehabilitation, and equipment control. Electroencephalography (EEG) signals remain the predominant input signal modality in BCI systems, with notable implementations including motor imagery, P300, and steady-state visually evoked potential (SSVEP). The SSVEP-based BCI systems utilize the brain's SSVEP response to the fixed-frequency visual stimuli for mind recognition and interaction, offering a significant advantage of a high information transfer rate. Recently, some high-performance BCI systems have been proposed –, and the advancement of 6G wireless communication technology has significantly expanded the potential applications of BCIs. Hence, ensuring high information security and privacy preservationfor the BCI users and devices becomes imperative when facilitating intelligent interactions within the constructed communication environment.

However, most existing BCI systems lack in-depth research in terms of security. Wireless transmission of brain signals in the BCI systems is vulnerable to theft and attacks, potentially leading to inaccurate control commands and unauthorized privacy breaches. Although some methodologies have been proposed to enhance the security and privacy in BCIs –, the encryption mechanisms specifically tailored to these systems remain largely unexplored. Moreover, visual stimulation is often isolated from back-end information processing, lacking deep integration and interaction. With the increasing demand for secure BCI systems, it is essential to develop intelligent interactions in a secure and reliable communication environment. The frequency-dependent SSVEP responses and programmable harmonic characteristics of space-time-coding (STC) metasurfaces have notable similarities. Therefore, the STC metasurfaces can be used as a promising method that not only provides visual stimulation but also enhances the security of the BCI systems at the physical layer, owing to their powerful ability to flexibly manipulate electromagnetic (EM) waves in both time and space domains.

---

### Technical guidelines for United States – Mexico coordination on public health events of mutual interest [^b4c1b5b0]. CDC (2012). Medium credibility.

United States–Mexico confidentiality, protection of privacy, and dissemination — Epidemiological information may be sensitive in nature, and inappropriately handled information may expose individuals, communities and countries to stigma or discredit, affecting their stability, security and wellbeing; therefore both countries should protect the information shared by the neighboring country and establish secure mechanisms and tools for transmitting and storing all information shared by the other country. This information should not be disseminated outside the purview of relevant public health authorities unless by mutual agreement or if it has been made public by the provider country, and if the receiving country's public health agencies or institutions are obligated to share data beyond its original purpose because of legal requirements or they become aware of an unintentional leak of information, they should warn as soon as possible the relevant public health agencies of the provider country.

---

### Navigating the tradeoff between personal privacy and data utility in speech anonymization for clinical research [^3c7b6543]. NPJ Digital Medicine (2025). Medium credibility.

Once personally identifying information is removed, post-processing should also ensure secure usage of the data via encrypted or privacy preserving mechanisms such as multi-party computation (multiple parties can jointly compute a function over their inputs while keeping the inputs private from each other) or homomorphic encryption (computations can be performed directly on encrypted data, without decrypting it. The output is also encrypted and can be decrypted only by the data owner). However, these techniques are generally impractical for individual-level speech data due to the complexity of speech recordings and the computational demands of these methods. Both approaches introduce significant processing and bandwidth demands, making tasks like feature extraction, automatic speech recognition, or model training prohibitively slow and resource-intensive when applied to raw or lengthy recordings. Additionally, they only protect data during computation, not after decryption, meaning speaker identifiable traits remain unless further anonymization is applied. While secure platforms and legal frameworks are essential components of a comprehensive data protection strategy, they really can only mitigate risk through compliance and enforcement; they cannot eliminate the potential for data exposure.

---

### Web services and cloud computing in pediatric care [^fbe0577d]. Pediatrics (2021). High credibility.

Protected environment — authentication scope and sandboxing for EHR Web services are outlined: Currently, many EHR systems authenticate users using a username, password, and location-based authentication, and EHR vendors are to determine when a Web service is accessing user data, how the Web service will be authenticated, and what access and permissions are allowed. Ideally, when Web services are authenticated, they would not authenticate through an existing user profile with potentially broad permissions, but instead, in a way that the service would have limited or no access to protected health information. Because Web services may represent a security risk if an application is redirected to a different service with ill intent or if the service is not robust and/or mishandles data, the calling application must be able to manage situations in which the service attempts unauthorized actions, corrupts data, or returns invalid results, and EHR applications should provide a limited and protected environment (a sandbox) so the service cannot cause harm resulting in data breaches, impermissible access, or data corruption.

---

### The future of digital health with federated learning [^c8725d09]. NPJ Digital Medicine (2020). Medium credibility.

System architecture

Unlike running large-scale FL amongst consumer devices such as McMahan et al. healthcare institutional participants are equipped with relatively powerful computational resources and reliable, higher-throughput networks enabling training of larger models with many more local training steps, and sharing more model information between nodes. These unique characteristics of FL in healthcare also bring challenges such as ensuring data integrity when communicating by use of redundant nodes, designing secure encryption methods to prevent data leakage, or designing appropriate node schedulers to make best-use of the distributed computational devices and reduce idle time.

The administration of such a federation can be realised in different ways. In situations requiring the most stringent data privacy between parties, training may operate via some sort of "honest broker" system, in which a trusted third party acts as the intermediary and facilitates access to data. This setup requires an independent entity controlling the overall system, which may not always be desirable, since it could involve additional cost and procedural viscosity. However, it has the advantage that the precise internal mechanisms can be abstracted away from the clients, making the system more agile and simpler to update. In a peer-to-peer system each site interacts directly with some or all of the other participants. In other words, there is no gatekeeper function, all protocols must be agreed up-front, which requires significant agreement efforts, and changes must be made in a synchronised fashion by all parties to avoid problems. Additionally, in a trustless-based architecture the platform operator may be cryptographically locked into being honest by means of a secure protocol, but this may introduce significant computational overheads.

---

### Chaotic information metasurface for direct physical-layer secure communication [^a053dcb2]. Nature Communications (2025). High credibility.

Wireless information security has garnered significant attention with the ever-increasingly widespread adoption of broadcast wireless communication systems. The utilization of chaotic systems for secure communication methods has become a prominent area of research, given their inherent advantages of high randomness and sensitivity to initial conditions. However, existing chaos-based approaches usually require legitimate receivers to have access to the chaotic system's parameters as decryption keys, often involving complex operations at the digital level. In this study, we present a novel physical-layer secure communication scheme that relies on an information metasurface whose local reflection properties are dynamically modulated by chaotic patterns. Our approach introduces a "one-time" mixed-pattern generation method that concurrently ensures communication security and transmission efficiency. More importantly, our proposed scheme removes the stringent requirement for decryption operations, enabling the legitimate receiver to directly access the original data while illegitimate receivers receive chaotically encrypted signals. This approach demonstrates significant merits, encompassing high security, a streamlined architecture, and intrinsic backward compatibility. Our innovative strategy provides a renewed perspective for advancing next-generation secure wireless communication systems.

---

### Guidelines for the practice of telepsychology [^4a82b461]. The American Psychologist (2013). Medium credibility.

Telepsychology — data security policies, vendor controls, and breach reporting — psychologists are encouraged to clearly address which telecommunication technologies are used and the purpose of the communication, and are cognizant that preserving the actual communication may be preferable to summarizing it, depending on the type of technology used. As part of their data security policies and procedures, psychologists seek to use encryption technology and robust security or multi-factor authentication controls for devices and for access to software or relevant websites, and psychologists strive to ensure that they have signed business associate agreements (BAA) in place with any third-party vendors as appropriate, including technology vendors, documenting their compliance with and adherence to the regulations regarding data security; this is especially relevant for tools with automated and/or artificial intelligence (AI) facilitated features. Psychologists are encouraged to be aware of what data is stored on Internet-based tools (e.g., practice management, electronic health records), and to ensure that those tools are HIPAA compliant, and psychologists are encouraged to review the data management and retention policies of any third-party technology vendors or other business associates regarding patient data before beginning to use a product or service and also on a periodic basis, because over time vendors may change terms of service. If there is a breach of unsecured electronically communicated or maintained data, psychologists seek to notify their patients/clients/service recipients and other appropriate individuals/organizations consistent with federal, state, provincial, territorial, and other organizational reporting requirements, are encouraged to understand what types of reporting are made on behalf of the psychologist to individuals affected by a data breach as outlined in the BAA executed with the third-party organization, and are encouraged to undertake due diligence to ensure comprehensive reporting in line with ethical and legal guidelines, regardless of the terms and conditions of the BAA. In addition, they are encouraged to make their best efforts to keep secure back-up versions of electronic data, such as through encrypted cloud-based storage, network drives, external devices, etc., and an organization may appoint a data security officer to facilitate and control access, oversee required data security-related training of employees, and mitigate potential risks.

---

### Utilization review in workers' compensation: review of current status and recommendations for future improvement [^e0e79350]. Journal of Occupational and Environmental Medicine (2020). High credibility.

Information management, security, and confidentiality — professionals shall conduct UR consistent with the jurisdictional regulatory, licensing, credentialing, and insurance laws and rules as well as national standards, and credentialing by independent organizations like URAC or NCQA is desirable to promote compliance with high level QA standards. UR professionals should ensure that workplaces are secure and private, including policies and procedures with effective training, restricted access to worksite, secure computers and information technology system, strong computer passwords, locked access to sensitive information, confidential conversations, liability coverage, and rapid response to data breaches. Backup systems are necessary and should involve a set of policies, tools, and procedures to enable the recovery or continuity of vital technology infrastructure and systems following a disaster. Disaster recovery planning is an integral part of any UR service, a good plan will cover all potential scenarios, and disaster recovery requires the determination of the recovery time objective in order to designate the maximum amount of time the business can be without IT systems post-disaster.

---

### 'Fit-for-purpose?'-challenges and opportunities for applications of blockchain technology in the future of healthcare [^104ddaa0]. BMC Medicine (2019). Medium credibility.

More robust data access can also enable better patient recruitment into clinical trials. With recruitment costs ranging between US$ 2 billion and US$ 3 billion (also depending on the phase of the clinical trial), this represents a major barrier that continues to increase. Blockchains can aggregate patient and trial data that is anonymized or else subject to patient-driven permissions. In this way, patients and sponsors/sites could connect better with eligible patient populations where there is mutual interest for trial participation. With this challenge, permissioned-based blockchains with the patient at the center of data governance might be the best approach.

Data integrity and data provenance are key in clinical trials. Sponsors and investigational sites have to prove data provenance and respond to queries from regulatory authorities to help ensure that clinical results maintain their integrity from data capture through to interim and final analyses. This process is burdensome and time consuming and increases the costs of a clinical trial's data sharing and management procedures. Blockchain has an architecture that can transparently show the provenance of the data from the origin to the final clinical summary report. The underlying trust in the data is enhanced, accelerating the regulatory approval process, and regulatory authorities will be better equipped to evaluate clinical trial results and determine if a treatment is safe and beneficial to patients. With regards to clinical trial data management, the design of a blockchain will likely be on a private network, with only trusted nodes associated with the study protocol. In the event of a regulatory inquiry, private key management could also enable a regulator to inspect the data for integrity.

Another challenge arises when sponsors are planning a clinical study, as the protocol often goes through several revisions and is revised even after patient enrollment to provide the best outcome for the patients. Sites managing the trial have to ensure appropriate patient consent (often via paper format) with the latest version of the protocol, which is a challenge as consent collection is a dynamic process. Sponsors are accountable for this process, and it is a key area of focus for regulatory authorities in their inspections. In response, sponsors can build a consent workflow using blockchain to implement a process allowing for collection of patient informed consent (including, potentially, e-consent through smart contracts), which is bound to protocol revisions. This process would allow for a built-in layer of transparency and traceability by time-stamping each step of a patient's consent and potentially automating it via set rules in smart contracts.

---

### Blockchain technology: principles and applications in medical imaging [^9bd5a777]. Journal of Digital Imaging (2020). Medium credibility.

Blockchain is an immutable, encrypted, distributed ledger technology. While initially devised for and most commonly referenced with cryptocurrencies, there are an increasing number of applications outside finance, many of which are relevant to medical imaging. In this paper, the concepts and principles underlying the technology and applications relevant to medical imaging are discussed, in addition to potential challenges with implementations such as public versus private key access, distributed ledger size constraints, speed, complexity, and security pitfalls. Potential use cases for blockchain specifically relevant to medical imaging include image sharing including direct patient ownership of images, tracking of implanted medical devices, research, teleradiology, and artificial intelligence. While blockchain offers exciting ways to facilitate the storage and distribution of medical images, similar to the advent of picture archiving and communication systems decades ago, it does have several key limitations of which healthcare providers of medical imaging and imaging informatics professionals should be aware.

---

### Secure and federated genome-wide association studies for biobank-scale datasets [^18cf5dd2]. Nature Genetics (2025). High credibility.

Main

Secure computation frameworks from modern cryptography offer promising strategies to address privacy concerns in collaborative genomic studies. These techniques allow a group of parties to jointly analyze their data by exchanging encrypted information while ensuring that each party's data remain private from others. Although recent work has illustrated the potential of this strategy for genome-wide association studies (GWAS) –, existing methods remain limited in practical utility. Prior work based on the framework of secure multiparty computation (MPC)is prohibitively slow for large biobank-scale cohorts (as demonstrated in this work) and requires the external sharing of entire input datasets in encrypted form, which may not be feasible in practice due to security risks. More recent methods based on homomorphic encryption (HE) schemes, improve efficiency but fail to support the standard analysis pipelines commonly used by researchers due to their computational complexity. These pipelines include those based on principal-component analysis (PCA) and linear mixed models (LMMs), which provide strategies to account for population structure within a study cohort to accurately estimate association signals.

We developed secure federated genome-wide association studies (SF-GWAS), a secure and federated algorithm for multisite GWAS, to enable collaborative genomic studies at scale with cryptographic privacy guarantees (Fig. 1). SF-GWAS builds upon the following two key conceptual advances. First is our 'federated' approach to secure computation, whereby each input genomic dataset is kept at the respective source site. This approach minimizes computational costs by both avoiding large data transfers between sites and allowing the use of efficient cryptographic operations that leverage the unencrypted input data locally available at each site. To enable this strategy, we combine MPC and HE — two cryptographic schemes for analyzing encrypted (masked) private data, which previous work on secure GWAS has separately leveraged — into a hybrid framework (Methods). Our framework employs HE for local computations over large matrices and vectors (for example, multiplication between a genotype matrix and a vector of individual phenotypes) and MPC for nonlinear operations such as division and sign functions (for example, used in statistical calculations) to improve numerical precision and efficiency. Previous work on a multiparty extension of HEdid not utilize computational MPC routines, which we found crucial for our large-scale analysis pipelines due to the wide range of values encountered during the analysis.

---

### The LISTEN principles for genetic sequence data governance and database engineering [^ca8472d5]. Nature Genetics (2025). High credibility.

Several international legal agreements include an 'access and benefit-sharing' (ABS) mechanism that attaches obligations to the use of genetic sequence data. These agreements are frequently subject to critique on the grounds that ABS is either fundamentally incompatible with the principles of open science, or technically challenging to implement in open scientific databases. Here, we argue that these critiques arise from a misinterpretation of the principles of open science and that both considerations can be addressed by a set of simple principles that link database engineering and governance. We introduce a checklist of six database design considerations, LISTEN: licensed, identified, supervised, transparent, enforced and non-exclusive, which can be readily adopted by both new and existing platforms participating in ABS systems. We also highlight how these principles can act in concert with familiar principles of open science, such as findable, accessible, interoperable and reusable (FAIR) data sharing.

---

### Decentralized clinical trials: the future of medical product development? ∗ [^1e0fd7f3]. JACC: Basic to Translational Science (2021). Medium credibility.

Challenges for DCTs

Compared with DCTs, a major advantage to centralized studies is comparatively simple drug distribution and management. In centralized studies, drugs are shipped to trial centers that centrally manage and maintain them. DCTs require shipping to multiple coordinating sites, including potentially directly to patient homes. For this to occur, there must be assurance of drug stability and appropriate storage facilities in the patient's home, as well as measures to prevent unauthorized access, methods to detect tampering, temperature tracking to assure appropriate drug storage, dosing diaries to record administration of the drug, and communication between the storage system and the drug source to provide timely refills and prevent study interruptions. In addition, local laws may need to be addressed that affect state-specific allowable parameters of drug dispensing. The complexity of decentralized drug shipping and management introduces potentially greater complexity and risk in clinical trials, both to the subjects themselves and to the integrity of the trial.

Technological advances are core elements that allow DCTs, but they are also a main challenge to adoption of DCT study design. Wearable biometric devices, for example, are still in early phases of development, and before these devices will be widely accepted in regulatory decisions, they require clinical validation. Operation of the devices themselves depend also on the availability of technical support and troubleshooting, batteries, transmission methods, and internet infrastructure, such as cellular towers in remote locations or hard-wired internet connectivity in homes currently without it.

Protecting patient privacy stored on connected devices, and the information transmitted through connection services is another problem. Reliable cybersecurity systems are a must, if private patient data is to be stored and transmitted in a DCT. Most traditional trials use local data systems that are firewalled and centrally managed. But in many studies, patients/subjects will interact with multiple health care providers using multiple electronic health record systems (EHRs), creating challenges for central data amalgamation from multiple EHRs that often do not communicate with each other efficiently, if at all.

---

### 'Fit-for-purpose?'-challenges and opportunities for applications of blockchain technology in the future of healthcare [^bd500bd3]. BMC Medicine (2019). Medium credibility.

Fig. 2
Depiction of blockchain data architecture components. This includes the core functions of blockchain data by generation of a first (genesis) block that is timestamped and may include certain transaction data/metadata (transation data) or state-of-data information. These blocks of data are chained together via a cryptographic hash of the data. The data layer represents where data can reside on the blockchain, primarily either storing data on the blockchain itself (on-chain storage) or storing the data in a different source but including a pointer or using a distributed application as an intermediary (off-chain storage). The core functions of the blockchain should also assess certain design considerations (in far right yellow box), including whether the blockchain is public, private or consortium, the consensus mechanism to be used, the type of permissions structure, where data should reside and how it should be managed, and the governance of the blockchain (who are the users, peers, validators, nodes, etc.). Finally, a feature layer including blockchain-enabled technology options, such as the use of cryptocurrencies/tokens, digital wallets, smart contracts, and distributed applications, can also be added if needed for a particular healthcare use case

---

### 2021 ISHNE / HRS / EHRA / APHRS collaborative statement on mHealth in arrhythmia management: digital medical tools for heart rhythm professionals: from the international society for holter and noninvasive electrocardiology / Heart Rhythm Society / European Heart Rhythm Association / Asia Pacific Heart Rhythm Society [^5af64d7b]. Journal of Arrhythmia (2021). High credibility.

Cybersecurity guidance for mHealth devices — key risks, motives, and the need for protective practices are outlined. Interconnection of medical devices and clinical data creates opportunities for intrusions to disable systems and/or access protected health information (PHI). The motivation is largely financial, with healthcare facilities and medical device companies attractive targets because attack strategies can yield large rewards, including ransomware that locks hospital systems until paid, theft and sale of PHI, and company attacks that exploit flaws then publicize them; attackers may also sell their methods or credentials. Although lethal scenarios have been imagined and demonstrated by researchers, to date no such attack is known in the real world, making it essential to establish best practice methods to maintain patient safety and privacy in an ecosystem of remotely managed devices and mass data collection.

---

### Clinical bioinformatician body of knowledge-clinical laboratory regulation and data security core: a report of the Association for Molecular Pathology [^c37d83e8]. The Journal of Molecular Diagnostics (2025). High credibility.

HIPAA Security Rule risk assessment — requirements and methods specify that security risk assessment is an administrative safeguard requirement under HIPAA regulations. All electronic PHI (e-PHI) generated, received, maintained, or transmitted by an organization is subject to the Security Rule, which requires organizations to assess risks and vulnerabilities in their environments and to implement security measures to protect against reasonably anticipated threats or hazards to the security or integrity of e-PHI. Common threats include malware, data encryption (ie, ransomware), data theft, corruption, and loss, and the Security Rule does not prescribe a specific method for performing the analysis; techniques may include root cause analysis, failure modes and effects analysis, fault tree analysis, preliminary hazard analysis, functional hazard analysis, and human error analysis.

---

### Web services and cloud computing in pediatric care [^8b695fb3]. Pediatrics (2021). High credibility.

Web services and cloud computing — definitions and mechanisms relevant to health information systems describe software services accessed over Internet protocols, using Simple Object Access Protocol (SOAP) over Hypertext Transport Protocol (HTTP versus HTTPS) or representational state transfer (REST) with uniform resource identifiers (URIs) and standard methods such as GET, PUT, POST, and DELETE, with vendor platforms handling storage, authentication, networking, messaging/e-mail, cross-platform functionality, updating, and "big" clinical data, thereby reducing the customer's need to supply computing power.

---

### SHEA position statement on pandemic preparedness for policymakers: pandemic data collection, maintenance, and release [^a163c3ec]. Infection Control and Hospital Epidemiology (2024). High credibility.

Data availability and sharing — The statement notes that, in line with the Open Science Framework, the modernized data resource should include mechanisms for broad access to shared national resources to democratize data availability, and that to the extent feasible, data sets should be made publicly available. When person or facility/healthcare system-level identifiers are required, a simple data use agreement process with protections could be used, similar to the CDC restricted access COVID-19 database, to balance access and data safety for transferring and sharing large data sets. Once a sufficient number of cases have accrued to protect patient and/or facility/healthcare system privacy, anonymized data should be made widely available with minimal access restrictions.

---

### Concept-match medical data scrubbing. how pathology text can be used in research [^af67b085]. Archives of Pathology & Laboratory Medicine (2003). Low credibility.

Context

In the normal course of activity, pathologists create and archive immense data sets of scientifically valuable information. Researchers need pathology-based data sets, annotated with clinical information and linked to archived tissues, to discover and validate new diagnostic tests and therapies. Pathology records can be used for research purposes (without obtaining informed patient consent for each use of each record), provided the data are rendered harmless. Large data sets can be made harmless through 3 computational steps: (1) deidentification, the removal or modification of data fields that can be used to identify a patient (name, social security number, etc); (2) rendering the data ambiguous, ensuring that every data record in a public data set has a nonunique set of characterizing data; and (3) data scrubbing, the removal or transformation of words in free text that can be used to identify persons or that contain information that is incriminating or otherwise private. This article addresses the problem of data scrubbing.

Objective

To design and implement a general algorithm that scrubs pathology free text, removing all identifying or private information.

Methods

The Concept-Match algorithm steps through confidential text. When a medical term matching a standard nomenclature term is encountered, the term is replaced by a nomenclature code and a synonym for the original term. When a high-frequency "stop" word, such as a, an, the, or for, is encountered, it is left in place. When any other word is encountered, it is blocked and replaced by asterisks. This produces a scrubbed text. An open-source implementation of the algorithm is freely available.

Results

The Concept-Match scrub method transformed pathology free text into scrubbed output that preserved the sense of the original sentences, while it blocked terms that did not match terms found in the Unified Medical Language System (UMLS). The scrubbed product is safe, in the restricted sense that the output retains only standard medical terms. The software implementation scrubbed more than half a million surgical pathology report phrases in less than an hour.

Conclusions

Computerized scrubbing can render the textual portion of a pathology report harmless for research purposes. Scrubbing and deidentification methods allow pathologists to create and use large pathology databases to conduct medical research.

---

### Remote inspection of adversary-controlled environments [^cbce369a]. Nature Communications (2023). High credibility.

Discussion

We have experimentally demonstrated key aspects of a radio-wave-based inspection system designed to remotely confirm that valuable items located in an adversary-controlled environment are kept in storage. Our proof of principle does neither require secure communication channels nor tamper-resistant sensor hardware at the inspected site. Our inspection system yields reproducible results in an extensive measurement campaign for a notional storage facility, can detect physical changes on the order of a few millimeters, and is robust against major physical and computational attacks. In addition, important security parameters such as the number of input mirrors, the wavelength of the probing signal, and the complexity of the room can be scaled to the disadvantage of potential attackers. The baseline scenario for which we intend this concept addresses long-established concerns with the verification of non-deployed nuclear weapons, where parties are mutually distrustful, have privacy and security constraints, and want to keep the interval of on-site visits at sensitive facilities to a bare minimum. Beyond nuclear arms control verification, our inspection system could find application in the financial, information technology, energy, and art sectors. The ability to remotely and securely monitor activities and assets is likely to become more important in a world that is increasingly networked and where physical travel and on-site access may be unnecessary or even discouraged.

---

### Without a trace: why did corona apps fail? [^e02742b1]. Journal of Medical Ethics (2021). Medium credibility.

At the beginning of the COVID-19 pandemic, high hopes were put on digital contact tracing, using mobile phone apps to record and immediately notify contacts when a user reports as infected. Such apps can now be downloaded in many countries, but as second waves of COVID-19 are raging, these apps are playing a less important role than anticipated. We argue that this is because most countries have opted for app configurations that cannot provide a means of rapidly informing users of likely infections while avoiding too many false positive reports. Mathematical modelling suggests that differently configured apps have the potential to do this. These require, however, that some pseudonymised data be stored on a central server, which privacy advocates have cautioned against. We contend that their influential arguments are subject to two fallacies. First, they have tended to one-sidedly focus on the risks that centralised data storage entails for privacy, while paying insufficient attention to the fact that inefficient contact tracing involves ethical risks too. Second, while the envisioned system does entail risks of breaches, such risks are also present in decentralised systems, which have been falsely presented as 'privacy preserving by design'. When these points are understood, it becomes clear that we must rethink our approach to digital contact tracing in our fight against COVID-19.

---

### Registered access: authorizing data access [^eef22de5]. European Journal of Human Genetics (2018). Low credibility.

The GA4GH is working to define a set of custom claims for registered access that all OpenID Providers and relying parties can adopt (Library Cards) providing interoperability across the ecosystem of registered access adopters. Strong identity-proofing will be required within a unified identity framework, especially in the future, for registration that is independent of institutional listing or peer vouching. We plan to use existing guidelines for how to establish and maintain trust in digital identities. These frameworks rank a spectrum of assurance levels, and relying parties can report (in claims) which of these levels was used to perform identity proofing.

Researcher attributes and registered access status count as personal, identifiable information, which is protected by privacy laws, including the new GDPR in the EU. To protect the privacy of researchers and respect data protection laws, it is proposed that OpenID Providers limit the amount of personal data shared with relying parties. This would mean communicating only a pseudonymous identifier of the researcher (i.e. an alphanumeric code, which is needed for thwarting re-identification and other attacks on multiple relying parties simultaneously) and their registered access status (which is needed for verifying the requestor's status), including its route and provenance, i.e. which registry delivered the status. Consent is one of the six lawful bases to process personal information in the GDPR. Article 4(11) defines consent as: "any freely given, specific, informed and unambiguous indication of the data subject's wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her". For the registration process, this would entail providing users with a way to consent to the sharing of their personal data for the purposes of gaining registered status, which ELIXIR has integrated into its pilot system.

---

### Long-term active surveillance of implantable medical devices: an analysis of factors determining whether current registries are adequate to expose safety and efficacy problems [^71f7e78b]. BMJ Surgery, Interventions, & Health Technologies (2019). High credibility.

The future

Advancing technology will enable increasing amounts of useful data to be collected by device registries. Electronic health records, smartphone apps and wearable devices will enable a range of information, including patient-reported outcome measures, to be captured. Increasing capacity for data linkage offers huge potential, but this will need careful attention to its governance. International linkages will increase the power of information gathering, but will require attention to differing national data legislative requirements. Manufacturer's registries straddle national boundaries, but these need assurances of transparency and unbiased oversight to provide confidence in their data. Clear plans for the use of registries when new devices are presented for regulatory approval will help shift the balance that is required between premarket and postmarket evidence. It will allow earlier access to new products while providing assurance of a mechanism to monitor performance. The data from registries will help manufacturers to develop ever safer and more effective devices for future use.

---

### AI and the falling sky: interrogating X-risk [^ba390f82]. Journal of Medical Ethics (2024). Medium credibility.

A fifth risk concerns threats to privacy. Privacy, understood as 'the right to be left alone' and 'the right of individuals to determine the extent to which others have access to them, is valued as instrumental to other goods, such as intimacy, property rights, security or autonomy. Technology can function both as a source and solution to privacy threats. Consider, for example, the 'internet of things', which intelligently connects various devices to the internet — personal devices (eg, smart phones, laptops); home devices (eg, alarm systems, security cameras) and travel and transportation devices (eg, webcams, radio frequency identification (RFD) chips on passports, navigation systems). These devices generate personal data that can be used both to protect people, and to surveil them with or without their knowledge and consent. For example, AI counters privacy threats by enhancing tools for encryption, data anonymisation and biometrics; it increases privacy threats by helping hackers breach security protocols (eg, captcha, passwords) meant to safeguard personal data, or by writing code that intentionally or unintentionally leaves 'backdoor' access to systems. When privacy protection is left to individuals, it has too often 'devolved into terms-of-service and terms-of-use agreements that most people comply with by simply clicking 'I agree', without reading the terms they agree to'. Jecker et al, p.10–11)

---

### A web-based interface for communication of data between the clinical and research environments without revealing identifying information [^7795e7cf]. Academic Radiology (2007). Low credibility.

Rationale and Objectives

Recent health care policies and regulations have affected the manner in which patient data — especially protected health information (PHI) — are handled in both the clinical and research settings. Specifically, it is now more challenging to obtain de-identified PHI from the clinic for use in research while adhering to the requirements of this new environment.

Materials and Methods

To meet this challenge, we have devised a novel web-based interface that facilitates the communication of data (eg, biopsy results) between the clinic and research environments without revealing PHI to the research team or associated research identifiers to the clinical collaborators. At the heart of the scheme is a web application that coordinates message passing between the researchers (in general, the requesters of de-identified PHI) and clinical collaborators (who have access to PHI) by use of a protocol that protects confidentiality.

Results

We describe the design requirements of this communication scheme and present implementation details of the web application and its associated database.

Conclusions

We conclude that this scheme provides a useful communication mechanism that facilitates clinical research while maintaining confidentiality of patient data.

---

### Confidentiality in the care of adolescents: technical report [^fd3bd726]. Pediatrics (2024). High credibility.

Adolescent confidentiality in electronic health record (EHR) portals — ideally, there would be automated segmentation of information and differential entry points for patients and proxies, and health care professionals have to consider how to verify portal ownership because parents may create accounts or use a parent e-mail, requiring identity confirmation and mechanisms to ensure accounts are used as designed. Because the practicality of such mechanisms is unclear, the page emphasizes the need for detailed education of both adolescent and parent before establishing portal access and notes that improved data segmentation and increased parental access to nonsensitive information may decrease parental misuse. The report adds that health care professionals have limited training in managing confidentiality with EHRs and patient portals and cites a common suggestion to generate secure notes or otherwise denote confidential content, while acknowledging the burden this places on clinicians. Professional guidance is referenced, including a statement by the North American Society for Pediatric and Adolescent Gynecology and the Society for Adolescent Health and Medicine endorsed by the AAP, and additional AAP guidance describing key exceptions that would allow blocking information release to proxies and release only to adolescents when state laws allow; understanding valid exceptions to information blocking prohibitions can mitigate challenges and barriers to confidentiality for youth.

---

### Assessment of firearm storage practices in the US, 2022 [^3efb8c59]. JAMA Network Open (2023). High credibility.

To assess current firearm storage practices, participants were presented with a series of items depending on which types of firearms they reported owning for specific reasons. For each selected reason for firearm ownership, participants were presented with the following wording: "What storage/staging device(s) do you currently use for that/those firearm(s) used for [specific purpose]?" If the participant did not report owning any firearms for any of the reasons listed in the previous question, they were instead presented with the following text: "You indicated that you do not have any firearms in/near your home for any of the purposes listed in the previous question, but you did indicate that you have firearms in/near your home. What storage/staging device(s) do you use for that/those firearm(s)?" Participants were then presented a matrix listing a variety of storage devices, broken down by locking mechanism (key, PIN, dial vs biometric), with text descriptions of each method paired with an image representing that method (eFigure in Supplement 1). Participants were also presented with the option of selecting "unlocked, hidden" and "unlocked, not hidden".

To assess reasons for current storage practices, participants who reported any of the secure firearm storage options from the previous item were asked "What are the reasons you currently use storage/staging locking devices?" Answer choices included "prevent theft", "prevent unauthorized access by an adult household member", "prevent access by an adolescent/teenager", "prevent access by a child (younger than adolescent/teenager)", "keep firearm in good condition", and "other". Individuals who reported storing any firearms unlocked were asked, "Are there any circumstances where you would consider using a locking device for the firearm(s) you indicated are currently unlocked?" Answer choices for this item mirrored those for the previous item.

---

### Are novel, nonrandomized analytic methods fit for decision making? The need for prospective, controlled, and transparent validation [^45d50216]. Clinical Pharmacology and Therapeutics (2020). Medium credibility.

A number of obstacles will have to be overcome before the full potential of these data sources can be brought to bear on pharmaceutical research and care. The obstacles have been broadly grouped in two domains 1: (i) technical/operational readiness, which relates to factors like extent of EHR coverage, use of structured data, interoperability of databases, and data quality; and (ii) data governance readiness, which addresses legal issues impeding secondary data analysis, including data privacy concerns, level of consent required, and clarity on who has legal access to health data for research purposes. A recent Organisation for Economic Co‐operation and Development (OECD) report highlighted that all OECD countries still face challenges in both domains. 1 Applicability of RWD across healthcare systems remains an additional issue.

Yet, we are optimistic. As the ecosystem for e‐health develops, so will data quantity. Issues of data quality, including missing data, and differences in terminologies and data formats will be more challenging to resolve. 2 However, the need for quality assurance and control procedures has been recognized and a range of initiatives are aiming to bring RWD quality to a level of regulatory acceptability. Collaborations among stakeholders and opportunities for data processing and quality improvement are constantly growing. 3, 4 Progress will likely happen in fits and starts but we foresee a future where healthcare data from different sources and of sufficient quantity and, eventually, quality will be available for rapid secondary analysis by researchers. Some secondary use of RWD is well established 5 (e.g. drug utilization, disease epidemiology, or safety evaluation). 6 However, if fully exploited, RWD could also contribute to, for example, demonstrating efficacy and treatment stratification to inform regulatory, reimbursement, and personalized treatment 7 decisions. The broad range of research questions that might be addressed with the help of new data sources have been described elsewhere. 4, 8

---

### Break down the decentralization-security-privacy trilemma in management of distributed energy systems [^fab9bb23]. Nature Communications (2024). High credibility.

Discussion

In the management of multiple DESs, decentralized schemes have garnered significant attention due to their alignment with the decentralized structure of the user side. However, decentralization based solely on the blockchain can raise privacy concerns, while decentralization based on parallelizable mathematical algorithms may compromise security and decision robustness if DES agents deviate from predefined rules. This paper introduces a management mechanism for DESs that is privacy-preserving, secure, and fully decentralized by combining blockchain and parallelizable mathematical optimization methods. We leverage the strengths of these methods to address their respective weaknesses.

The concept of decentralization in this work encompasses two aspects. The first is specialization, whereby the overall management task is divided into distinct sections, each handled by dedicated professionals. The DES owners, miners, and computation parties work on specific sections. The second is distributed computation, where the calculation related to each section is decomposed and carried out by multiple participants. More importantly, all of the exchanged data within or across sections are encrypted fragments, safeguarding against the massive leaks of sensitive information and malicious analysis and manipulation.

We use an example to support the following findings. First, the proposed scheme can obtain a feasible and bid-cost-optimal operation plan through efficient iterations. Second, the proposed scheme protects the sensitive information of DESs. This may help prevent risks from other adversaries. Third, the DESs stand to benefit in the settlement stage, which encourages more participation so that the integrated system can turn more competitive.

We base the security of our framework on the integrity of edge devices to perform simple calculation and communication tasks for DESs. Although there are some widely used solutions to ensure this feature, in actual production environments the edge equipment may also turn offline due to network failure or fluctuations. In engineering applications, backup plans need to be set up by regulators or the owner of the distribution grid. Besides, we rely on modern asymmetric cryptography-based network infrastructures and TEE hardware producers. Their vulnerability should also be carefully considered, but is out of the scope of our research.

---

### Unaddressed privacy risks in accredited health and wellness apps: a cross-sectional systematic assessment [^9aef84ff]. BMC Medicine (2015). Low credibility.

Results of data entry and mobile-device storage assessment

Most apps (89%, n = 70/79) included some form of data entry mechanism. The majority of these (83%, n = 58/70) collected generic user-generated content such as annotations (20%, n = 14/70), appointments (14%, n = 10/70), bookmarks (16%, n = 11/70), feedback ratings (17%, n = 12/70), messages (7%, n = 5/70), reminders (19%, n = 13/70) and diaries (6%, n = 4/70). However, two-thirds (64%, n = 45/70) allowed users to enter strong identifiers, most commonly email addresses (31%, n = 22/70), username/password information (30%, n = 21/70) or a full name (23%, n = 16/70). A fifth (20%, n = 14/70) of apps included a registration process involving the creation of a user account. Registration was mandatory in most (71%, n = 10/ 14) of these apps. Eight apps (11%, n = 8/70) allowed photographs of people to be stored, for example as a user avatar or to track progress in weight loss. Half (49%, n = 34/70) captured weaker identifiers, for example gender (26%, n = 18/70), 'blurred' location data, for example partial postcode (20%, n = 14/70), or age (16%, n = 11/70). Almost three-fifths (57%, n = 40/70) of apps captured potentially sensitive information. Most (56%, n = 39/70) recorded health-related details consisting of measurements made by users (n = 6), other medical history details (n = 14), or both (n = 13). Reflecting the number of apps (27%, n = 21/79) addressing health promotion topics, almost a fifth of apps (19%, n = 13/70) captured information relating to alcohol, smoking and substance use. A small proportion of apps (7%, n = 5/70) captured other sensitive information, including ethnicity (n = 3), employment status (n = 2) and sexuality (n = 1). The majority of apps (84%, n = 59/70) also collected other types of user-generated content. This information was commonly related to aspects of health self-management, for example annotations in personal health records (20%, n = 14/70), reminders (19%, n = 13/70) or appointments (14%, n = 10/70). Some apps collected information explicitly intended to be shared with others. Both service directories and some health promotion apps included features for users to share opinions and feedback on services and content (16%, n = 11/70). A small number of apps (6%, n = 4/70) allowed users to post messages to a forum or to other users.

---

### Protocol and establishment of a queensland renal biopsy registry in Australia [^bc2ad77b]. BMC Nephrology (2020). Medium credibility.

Sample size

We estimate that 300 biopsy proven renal disorder patients are seen annually in public hospitals. For example, there will be about 600 patients in 2 years. This sample size will be generally sufficient for association tests in regression analyses with more than 20 independent variables and for estimating the population mean or proportion with a small margin of error.

Data security and retention

Data are stored in secure locked locations on Queensland Health government property at each participating hospital. The primary central data repository is located within the secured electronic filing system of the Metro North Kidney Health Service.

Physical Security: All computers which store electronic health information data are contained in locked rooms with limited, staff ID-based, restricted access.

Technological Security: All study related documentation and participant data/data bases is stored on a secure limited-shared file. Access to shared files within Queensland Health is restricted and password protected. The computers of all persons who can access health information data are protected with automatic screen locking after 5 min of inactivity. In accordance with the high-quality security provisions of Queensland Health, computers and the electronic information that is stored upon them will be protected using firewalls, secure encrypted pathways or other methods as recommended by the Information Technology department. All security protection measures are regularly updated.

Paper records: no paper records of any personal health information data are created, at any time.

Data reporting and dissemination

At a minimum of annual intervals during the study, results are converted into a report of de-identified data for user groups, participating Renal units, and collaborators, which will include, but is not limited to, Queensland Health, The University of Queensland, the Australasian and New Zealand Society of Nephrology, the Renal Society of Australasia, and Kidney Health Australia. In addition, outcomes will be published in academic journals and on the QRBR website: www.QRBR.org, for professional and patient information and dissemination. Reports of the units will be publicly displayed if there is a minimal collection of the data of at least 80% of the patients.

---

### Privacy in consumer wearable technologies: a living systematic analysis of data policies across leading manufacturers [^f4db8213]. NPJ Digital Medicine (2025). Medium credibility.

12. Data Retention — The company limits data retention, discloses retention periods, and deletes or anonymizes data when no longer necessary.

13. Data Control — Users can control data collection via settings, such as turning off collection or limiting permissions.

14. Control Over Targeted Advertising — Users can control and disable the use of their data for targeted advertising.

15. Data Access — Users can access their data easily, in a structured format, and at no cost.

16. Data Deletion — Users can delete their data, and the company provides clear deletion and retention policies.

17. Data Sharing — The company is transparent about data sharing, limiting it to necessary parties and disclosing what is shared and with whom.

18. Authentication — The company implements secure authentication mechanisms, such as multi-factor authentication, to protect user accounts.

19. Encryption — User data is encrypted during transmission and storage, with end-to-end encryption enabled by default.

20. Known Exploit Resistance — The product is secure against known vulnerabilities and exploits.

21. Security Oversight — The company monitors internal access to user data and commissions third-party security audits.

22. Security Over Time — The company ensures product security through regular updates and communicates the product lifecycle.

23. Vulnerability Disclosure Program — The company has a bug bounty or vulnerability disclosure program with clear timelines for addressing vulnerabilities.

24. Breach Notification — The company promptly notifies affected users and authorities in the event of a breach, with a clear process for addressing it.

The full evaluation results for each company across all 24 criteria are publicly available via the Open Science Framework (OSF) at:

---

### Cybersecurity in PACS and medical imaging: an overview [^4a45c52a]. Journal of Digital Imaging (2020). Medium credibility.

Technical Mitigation Measures

The second level on which cybersecurity must be implemented is the level of technical mitigation measures. The majority of recommendations in literature concern this level. In this section, we present a summary of the technical mitigation measures that apply to PACS and medical imaging devices. Many of these will seem obvious, but will still require effort for an effective implementation.
Regular backups: ENISA recommends the performance of regular backups. "This very important action can solve many attacks that could cause great impacts to smart hospitals such as ransomware or physical attacks. Running regular full or incremental backups can be done combined with setting a hot or warm site, making the hospital systems resilient even in the case of natural disaster". The US Department of Justice adds that operators should "ensure backups are not connected permanently to the computers and networks they are backing up. Examples are securing backups in the cloud or physically storing backups offline". NTT Security points out that a comprehensive backup strategy includes "storage of offline backups, as well as confirming the organization's ability to rebuild systems and restore data". Sittig et al. recommend that backups "should be made frequently (i.e. at least daily, and a continuous or real-time backup is ideal)". They also recommend hospitals to "periodically conduct mock system recovery exercises (i.e. identify backups and test restore capabilities)".
Firewalls and network segmentation: Kruse et al. performed an analysis of literature on security techniques for electronic health records and conclude that "the security technique most commonly discussed was the implementation of firewalls to protect the healthcare organizations' information technology system". They also point out that firewalls "have proven to be very successful in securing an organization's network and the protected health information that resides on the network". ENISA points out that "it is important to separate critical parts of the network from non-critical parts. For instance, it is recommended to separate medical devices to the largest possible extent from office components that are typically — due to the use of standard components — susceptible to a wide range of attacks. Moreover, devices with known vulnerabilities that cannot be removed easily may only be used in a separate part of the network or not connected to the network at all". NTT explains that network segmentation is important because "if attackers can breach back-end servers, they may be able to move laterally to access other portions of your network, doing further damage, and possibly gaining a foothold across multiple systems". They recommend the use of "firewalls, routers, and other network security devices to implement and enforce network segregation", i.e. "restricting the flow of network traffic between network segments with different security profiles". They also recommend the use of "web and application gateway firewalls to help protect key internal and external applications". Recent trends in this field are micro-segmentation and the zero trust paradigm. OTech explains that "micro-segmentation allows for networks to be configured using software such that certain devices only talk with each other. If a device or application moves, the security policies and attributes move with it. Zero trust means that it is not sufficient to only protect the perimeter; nothing can be trusted anymore as devices might become infected as well, so it shifts the focus to internal protection". An introduction to micro-segmentation is provided by De Vincentis, and an implementation of zero trust networks is described by Vanickis et al. Finally, the use of "data diodes" has been proposed for healthcare networks. These are hardware devices that enforce a strictly unidirectional communication from one network with a high security level to another network with a lower security level. El Hajal et al. describe their use in the context of a PACS network, but point out that data diodes cannot be used with the existing DICOM network protocol, which relies on bidirectional communication.
Disabling unused physical ports: One important route for the delivery of malware and for data theft is via portable storage media such as universal serial bus (USB) memory sticks. Sittig et al. recommend, therefore, "that at the local device level, organizations should consider disabling USB ports to prevent malicious software delivery". ENISA recommends operators to "ensure that devices only feature the essential physical external ports (such as USB) necessary for them to function and that the test/debug modes are secure, so they cannot be used to maliciously access the devices". In general, operators should "lock down physical ports to only trusted connections".
Whitelisting of permitted applications: Many operating systems support the concept of "whitelisting" applications. When enabled, only applications that are included in the "whitelist" managed by the operating system can be executed, while all others are blocked. NEMA reports that "whitelisting mechanisms can effectively preclude execution of malware code and can be integrated into a device prior to commissioning". NTT recommends that organizations should, "if feasible, use application whitelisting on servers, desktops, and laptops so ransomware and other unauthorized executables can't be run". This requires organizations to develop "a 'whitelist' of specified programs that are allowed to run"., which should be relatively simple in the PACS context where only a limited number of applications will be used, e.g. on a diagnostic workstation, but might be a rather complex task on general-purpose office PCs. As an alternative where whitelisting is not possible, the US guidance document on ransomware protection recommends users to "implement Software Restriction Policies (SRP) or other controls to prevent programs from executing from common ransomware locations, such as temporary folders supporting popular Internet browsers or compression/decompression programs, including the AppData/LocalAppData folder". Whitelisting is one of the technologies described by ENISA as a good practice that is often not implemented today.
User authentication and access rights: A study by KPMG showed that among the most important data security vulnerabilities in healthcare are breaches or data theft by employees. This indicates that managing access rights is an essential requirement. The first part of this is the user authentication. ENISA defines strong authentication as a baseline security element for ICT products in healthcare, which "shall provide and support strong authentication mechanisms for all accounts. If authentication is unsuccessful the product shall not allow any user specific activities to be performed". They furthermore state that "it is essential that authentication is a strong and non-reputable, and that privileges are fine-grained". NTT security recommends organizations to "follow the principle of least privilege for file access on servers and other systems available through file shares. This reduces the impact of ransomware encrypting files on these systems". They also recommend to "limit administrator-level privileges as much as possible. Require people to use administrator accounts only when necessary and to use regular user accounts for all other tasks. This reduces the chances attackers will be able to gain immediate access to administrator privileges through a single attack". The recommendation to assign access rights based on the principle of least privilege can be found in many guidelines. Historically, this is certainly not a strong point of the PACS community where until 2004 the DICOM standard did not even permit a diagnostic workstation to notify the PACS server about the user identity when queries were performed or images were accessed. The importance of this topic has increased, however, with the advent of "enterprise PACS". Disciplines such as pediatrics, surgery and dermatology store sensitive images, e.g. of children or plastic surgery, unlimited access to which across the complete enterprise may not be acceptable. Furthermore, hospitals nowadays often deploy so-called vendor neutral archives (VNA) where multiple systems store their data on common storage servers (storage area network or network attached storage, SAN/NAS). The potential of a single system that gets infected with malware and has unlimited write access to damage not only the PACS archive, but disrupt the operation of multiple IT systems makes the management of access rights an important requirement.
Regular updates and patches: ENISA explains that "regular patching and updating of software is essential to avoid the exploitation of known vulnerabilities as well as to ensure the detection of attacks using known paths. Accordingly, in smart hospitals, patches and updates are not only important for networked medical devices and clinical networked information systems, for example, but also for firewalls, antivirus software and other software-based security measures". Sittig et al. recommend that "personnel in the organization responsible for maintaining all of the computers' operating systems, application software, browsers and plug-ins, firmware, and anti-virus software should ensure that they are up-to-date with the latest patches. Before applying any patches, health IT professionals should thoroughly test them". NTT Security recommends organizations to "prioritize patching efforts based on exposure, most critical systems, and highest risk vulnerabilities". The US Department of Justice recommends to "consider using a centralized patch management system".
Virus and malware protection: ENISA recommends that "computers should run antimalware and anti-spam software (also known as antivirus) to detect and remove or quarantine malicious software. This includes but not limited: medical devices, IT equipment, health information systems, SCADA [Supervisory Control and Data Acquisition] and Cloud-based data and application services, etc". NEMA adds that "virus protection mechanisms are good practice to combat (known) threats, and suppliers should ensure that virus definition and updated virus protection patterns do not affect clinical/operational functionality by conducting basic assurance testing of the imaging device". The US Department of Justice recommends to "set anti-virus and anti-malware programs to conduct regular scans automatically". Finally, Sittig et al. suggest that "organizations should consider blocking email messages with potentially weaponized attachments" (i.e. file types that may contain executable code).
Encryption: In cybersecurity, usually three states of data are distinguished: "in use", "at rest", and "in transit". Data is in use when currently read or written by some application. Data is at rest when it is stored but not currently used. Data is in transit when it is being transmitted, either using a network connection or a storage medium such as a compact disk (CD) or a flash memory stick. While it is obvious that data cannot be fully encrypted while being used (it must be in clear-text form at least in the system's memory), data can be encrypted while being "at rest" or "in transit". ENISA states that "encryption is one of the most common solutions used in hospitals, mainly because of the criticality and sensitivity of the data at rest, in transit and in use. Health information data stored in third party providers, as well as the ones stored in the hospitals should be encrypted". Furthermore, they recommend that organizations "ensure a proper and effective use of cryptography to protect the confidentiality, authenticity and/or integrity of data and information (including control messages), in transit and in rest. Ensure the proper selection of standard and strong encryption algorithms and strong keys, and disable insecure protocols. Verify the robustness of the implementation". Furthermore they recommend to "ensure that communication security is provided using state-of-the-art, standardized security protocols, such as TLS (Transport Layer Security) for encryption". NEMA confirms that encryption of data "in transit" not only affects wide area transmission of data: "Secure communication is essential when transmitting Protected Health Information (PHI) and associated information between devices and recipients, whether internal to the organization or with external parties".
Audit trail/logging: The purpose of an audit trail (or audit log) is to keep a permanent record of all events related to the creation, modification, use and transmission of protected health information. NEMA suggests the introduction of "audit logs for imaging equipment and imaging informatics systems". ENISA proposes to "implement a logging system that records events relating to user authentication, management of accounts and access rights, modifications to security rules, and the functioning of the system. Logs must be preserved on durable storage and retrievable via authenticated connections". A standardized message format and communication protocol for audits related to PACS and medical imaging is described in the Integrating the Healthcare Enterprise (IHE) "Audit Trail and Node Authentication" (ATNA) integration profile, which is part of the IHE IT-Infrastructure Technical Framework, and in the related DICOM Audit Trail Message Format Profile. It should be noted, however, that an audit trail server is a very attractive cybersecurity target in itself and must, therefore, be appropriately protected.
Network monitoring and intrusion detection: Sittig et al. recommend that "all organizations should develop a network and user activity monitoring system that conducts surveillance for suspicious activities such as receipt of email messages from known fraudulent sources, executable email attachments, unexpected changes in key files on network-attached drives, unknown processes encrypting files, or significant increases in network traffic on unexpected ports". The purpose of this monitoring is "to detect suspicious activities and identify and address security problems before they cause harm". ENISA also recommends the implementation of monitoring and intrusion detection systems, which are "are solutions that monitor a network or systems for malicious activity or policy violations. Violations that are detected are typically reported directly to a member of the IT staff or collected in a central database for further analysis". It should be noted that intrusion detection is a field of active research, since such systems need to react on certain "patterns" of system behavior. For example, Maimó et al. describe a machine-learning (i.e. "artificial intelligence") approach that can identify ransomware attacks with high accuracy, thus improving response times and limiting damage.
Protection of mobile devices: The rise of mobile devices such as smartphones and tablet computer has given rise to the concept of "Bring Your Own Device" (BYOD), where employees use personally owned mobile devices at work, e.g. to read e-mail, receive notifications, or access medical images from remote. This creates a new attack vector since these devices might get compromised by malware, or get stolen. Liu et al. report that most breaches of health data "occurred via electronic media, frequently involving laptop computers or portable electronic devices". ENISA states that the "lack of a clear and strict BYOD policy can be great vulnerability", and that "hospitals should typically prevent patients/employees from connecting their own personal devices to hospital systems (including via Wi-Fi, Ethernet, or VPN (virtual private network)), and where this is not appropriate apply effective technical controls to protect the hospital and the network infrastructure from rogue or compromised devices". They recommend hospitals to "create a BYOD and mobile device policy for users; as this is a component of a smart hospital ecosystem this needs to become a priority". In detail, they recommend the introduction of mobile device management (MDM) solutions, "a particular type of asset and configuration management systems that allow changing configurations and working with logs. They allow better protecting the sensitive data that may be stored on mobile devices. Logs of system events sometimes allow detecting malicious actions or system failures". Furthermore, they note that the installation of antivirus software could "also be a prerequisite for remote care equipment and users mobile devices (in BYOD) to connect to the hospital systems". The lack of a BYOD policy or control of that policy is noted by ENISA as one of the good practices that is often not implemented today. As described above, the ENISA study identified a number of gaps, i.e.g.ood practices that are often not implemented in hospitals. The following gaps are related to technical mitigation measures, in addition to the two practices already discussed in this section:
Automated asset inventory discovery tools: These are tools for maintaining an inventory of hardware and deployed software. The tools provide a "discovery" feature to either scan the network for active devices, or to identify devices by passively analyzing their network traffic. ENISA writes: "Hospitals adopting IoT components need to monitor how these sensors interact with medical devices and systems, and if information collection process is always correct. To achieve this, an automated asset inventory discovery tool is needed. This tool enables systems managers to track of all assets and being able to use different discovery methods in case of a disruption. Lack of this makes smart healthcare systems more vulnerable to availability and integrity attacks".
Ensuring secure configurations: ENISA states that "hospital information security managers should include cyber security in the requirements when purchasing new equipment when building their smart hospital. Security should be built-in but also (due to the great number of legacy systems) integratable; patching and updating should be a regular task of information security officers". One aspect of ensuring secure configurations is that security mechanisms and algorithms that are considered secure today may be discovered to be faulty in the future, or may become insecure simply because of the general increase in computer speed and memory available to attackers. For systems with a long lifetime, such as medical imaging devices, this means that the security features may need to change over time. ENISA therefore demands that "the provider shall guarantee support throughout the agreed lifetime of the product such that the system can work as agreed and is secure".
Client certificates: According to ENISA, these certificates are needed "to validate and authenticate systems: Authentication and authorization is significant in the context of smart hospitals; however due to the disperse nature of its components this is not a priority".
Remote administration over secure channels: ENISA states that "Remote services are a benefit of smart hospitals. Introducing this new function in a traditional hospital requires more than a regular monitoring system. The remote devices need to be monitored and sometimes even controlled through a central system over secure channel". The fact that remote services are a viable vector for cyberattacks is illustrated by a news report by ProRepublica published in September 2019 that details such an incident and concludes that the attack "illustrates a new and worrisome frontier in ransomware — the targeting of managed service providers, or MSPs, to which local governments, medical clinics, and other small- and medium-sized businesses outsource their IT needs".

---

### Automating insulin delivery through pump and continuous glucose monitoring connectivity: maximizing opportunities to improve outcomes [^b6f8646d]. Diabetes, Obesity & Metabolism (2024). Medium credibility.

FIGURE 2
Methods used by Bluetooth technology to maintain connectivity; packets refer to small portions of larger data. Clockwise: adaptive frequency hopping is the process of dynamically switching between communication channels to reduce the likelihood of interference; despite interventions to prevent interference, data loss can still occur; acknowledgements confirm receipt of packages. Automatic re‐transmission is the process of sending multiple copies of data packets to reduce the likelihood of signal contamination by interference. Smaller, faster packets reduce the likelihood of data being intercepted by interfering signals.

3.4 Cybersecurity

Despite the benefits of wireless connectivity between CGM devices and insulin pumps, the increased utilization of wireless connectivity brings with it added cybersecurity concerns. Devices operating via RF and Bluetooth offer authentication and encryption that act together to create secure connectivity between communicating devices. However, both are optional features, so mandating their use may assist in preventing unauthorized data access. Devices operating via Bluetooth announce when they are available for pairing. This can be detected by other devices within the proximity. Although device authentication can prevent an individual's personal device pairing with unknown devices, the user could be identified during announcement, and unauthorized access to data whilst authenticated devices are announcing themselves available for pairing is not impossible. Switching devices to 'not discoverable' modes may protect against such risks without affecting connectivity between authenticated paired devices. In those HCL systems housing algorithms within smartphone applications (apps), the possibility of security breaches from corrupt mobile downloads or installed apps is also possible. The use of multifactor authentication to access app data may mitigate this risk.

The ability of OS systems to incorporation newer insulin pumps utilizing Bluetooth connectivity (Table 1) proves that even advancing methods of wireless connectivity are not infallible. Identifying means to mitigate cybersecurity breaches may facilitate user safety and trust within commercial systems.

---

### Improving authenticity and provenance in digital biomarkers: the case for digital watermarking [^92de67dc]. NPJ Digital Medicine (2025). Medium credibility.

Harmonization with existing principles, standards, and ecosystem

Digital watermarking must not only align with foundational security, privacy and research standards like the Health Insurance Portability and Accountability Act, Digital Object Identifier, and FAIR Principles but should also actively support health systems in maintaining compliance with these frameworks by creating an embedded auditable trail of patient data access and modifications.

Watermarking can ensure traceability and authenticity but this depends on the context of use. In closed systems, it may primarily safeguard against tampering and unauthorized distribution rather than providing transparency to patients or stakeholders. For publicly shared datasets, watermarking verifies provenance and detects manipulation, proving particularly useful in secondary applications like AI model training or research. To achieve greater transparency in situations where data usage occurs behind closed doors, watermarking should be paired with complementary tools like audit logs, regulatory oversight, and lineage reporting mechanisms. Together, these measures provide a comprehensive framework for safeguarding data integrity, ensuring compliance with standards, and fostering trust by making data lineage more transparent to both patients and stakeholders.

---

### Federated learning enables big data for rare cancer boundary detection [^80e6471f]. Nature Communications (2022). High credibility.

The coordination began with engaging the security teams of collaborating sites and providing them access to the source code of the platform developed to facilitate this study. These security discussions highlighted the benefit of the platform being open-source, making security code reviews easier. Resource gathering was then carried out by identifying technical leads and assessing computational resources at each site. With the technical leads, we then proceeded to test the complete workflow to further identify gaps in the requirements, such as network configurations and hardware requirements. We then proceeded with data curation and preprocessing, and finally connected individual sites to the aggregation server to initiate their participation.

Following the precise definition of our problem statement –, ensuring strict compliance with the preprocessing and annotation protocol for the generation of reference standards was vital for the model to learn correct information during training. To this end, we instituted an extensively and comprehensively documented annotation protocol with visual example representations and common expected errors (as observed in the literature,) to all collaborators. We have further circulated an end-to-end platformdeveloped to facilitate this federation, providing to each collaborating site all the necessary functionalities to (i) uniformly curate their data and account for inter-site acquisition variability, (ii) generate the reference standard labels, and (iii) participate in the federated training process. Finally, we held interactive sessions to complement the theoretical definition of the reference standards, and further guide collaborating sites. Particular pain points regarding these administrative tasks included managing the large volume of communication (i.e. emails and conference calls) needed to address questions and issues that arose, as well as the downtime incurred in FL training due to issues that had not yet been identified and were adversely affecting the global model. Though we developed many ad-hoc tools for this workflow ourselves (particularly for the data processing and orchestration steps), many issues we encountered were common enough in retrospect (for example common Transport Layer Security (TLS) errors) that mature automated solutions will address them. Many of these automations will be use-case dependent, such as the MRI data corruption checks we used from the FeTS tool. For these use-case-dependent automation, more associated tools are expected to become available as various domain experts enter into the FL community, while some will be more general purpose. As our inspection of both local and global model validation scores was manual during our deployment, we in retrospect see great value in automated notifications (performed at the collaborator infrastructure to help minimize data information leakage) to alert a collaborator (or the governor) when their local or global model validation is significantly low. Such an alert can indicate the potential need to visually inspect example failure cases in their data for potential issues. With continued efforts towards developing automated administration tools around FL deployments, we expect the coordination for large FL deployments to become easier.

---