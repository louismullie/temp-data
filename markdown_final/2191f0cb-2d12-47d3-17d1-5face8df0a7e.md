# Medical Question & Answer

**Sample ID**: 2191f0cb-2d12-47d3-17d1-5face8df0a7e
**Dataset Index**: 220408

---

## Question

## Problem Statement

Find the point of intersection of the line and the plane.
[(x − 3)/1] = [(y + 2)/(−1)] = [(z − 8)/0]

5x + 9y + 4z − 25 = 0

---

## Answer

> Let's see… What do we have here? The user is asking to find the point of intersection of a line and a plane. Let's break this down step-by-step. First, I need to think about the parametric form of the line and whether the direction vector is valid. Then, I should substitute the parametric equations into the plane equation and solve for the parameter. Next, I will check for consistency, especially the z-component constraint, and finally compute the intersection coordinates and verify the result against the plane equation.

> Let me first confirm the line's parametric representation. The symmetric form ([(x − 3)/1] = [(y + 2)/(−1)] = [(z − 8)/0]) implies a direction vector of ((1, -1, 0)) and a point on the line of ((3, -2, 8)), so the parametric equations are (x = 3 + t), (y = -2 - t), and (z = 8 + 0 · t = 8). Wait, let me verify the z-component: division by zero in the symmetric form means the z-coordinate is constant, so yes, (z = 8) for all points on the line [^notfound].

> Next, I should substitute these parametric expressions into the plane equation (5x + 9y + 4z - 25 = 0). Substituting gives (5(3 + t) + 9(-2 - t) + 4(8) - 25 = 0). Hold on, I should double-check the arithmetic: (15 + 5t - 18–9t + 32–25 = 0) simplifies to ((-4t) + (15–18 + 32–25) = 0), which is (-4t + 4 = 0), so (t = 1). That looks correct [^notfound].

> Now, I will plug (t = 1) back into the parametric line equations to find the intersection point. This yields (x = 3 + 1 = 4), (y = -2–1 = -3), and (z = 8). So the candidate intersection is ((4, -3, 8)). Wait, let me verify this against the plane equation to ensure consistency: (5(4) + 9(-3) + 4(8) - 25 = 20–27 + 32–25 = 0), which checks out [^notfound].

> But wait, what if the line were parallel to the plane or lay in it? I should confirm that the direction vector is not orthogonal to the plane's normal. The plane's normal is ((5, 9, 4)), and the dot product with the line's direction ((1, -1, 0)) is (5(1) + 9(-1) + 4(0) = -4), which is not zero, so the line is not parallel to the plane and a unique intersection exists, which aligns with our solution [^notfound].

> Final answer: The line intersects the plane at the point ((4, -3, 8)) [^notfound].

---

The line and plane intersect at the point **(4, −3, 8)**. This is found by writing the line in parametric form as (x = 3 + t), (y = −2 − t), and (z = 8), then substituting into the plane equation (5x + 9y + 4z − 25 = 0) to solve for (t = 1), which gives the intersection coordinates.

---

## Parametric equations of the line

The symmetric equations of the line are:

[(x − 3)/1] = [(y + 2)/(−1)] = [(z − 8)/0]

From this, we derive the parametric equations:

x = 3 + t, y = −2 − t, z = 8

where (t) is a parameter.

---

## Substitution into the plane equation

Substitute the parametric equations into the plane equation (5x + 9y + 4z − 25 = 0):

5(3 + t) + 9(−2 − t) + 4(8) − 25 = 0

Simplify:

15 + 5t − 18 − 9t + 32 − 25 = 0

(15 − 18 + 32 − 25) + (5t − 9t) = 0

4 − 4t = 0

Solve for (t):

−4t = −4 ⇒ t = 1

---

## Coordinates of the intersection point

Substitute (t = 1) back into the parametric equations:

x = 3 + 1 = 4, y = −2 − 1 = −3, z = 8

Thus, the intersection point is **(4, −3, 8)**.

---

## Verification

Verify by substituting (4, -3, 8) into the plane equation:

5(4) + 9(−3) + 4(8) − 25 = 20 − 27 + 32 − 25 = 0

The equation holds, confirming the intersection.

---

The line and plane intersect at the point **(4, −3, 8)**.

---

## References

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^6517cbfd]. Annals of the American Thoracic Society (2023). High credibility.

Basic stereological measurements — first-order parameters and probes identify that "First-order parameters are volume (three-dimensional [3D]), surface (two-dimensional [2D]), length (one-dimensional [1D]), and number (zero-dimensional [0D])". Measurements "are performed using geometric test probes, such as points (0D), lines (1D), planes (2D), or volumes (3D)". These probes create countable events in the image, and "Raw counts provide ratios… that are multiplied by the reference space volume to obtain absolute measures for the lung or subcompartment".

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^075005b9]. Magnetic Resonance in Medicine (2021). Medium credibility.

Regions A and B are geometrically symmetric about the z = 0 plane, with minimum energy solutions (assuming no E‐field constraint) yielding z‐symmetric field solutions and zero B 0 concomitant fields. Hence, the open diamond starting point (representing the minimum energy solution with no E‐field constraints) for the solid and dashed curves (in both black and green cases) coincide. The symmetry is broken by the addition of a patient model with an E‐field constraint.

The knee in the curves marks the point where magnetic energy, current density, and winding complexity increase rapidly as E max is driven to lower values. These complexities render unrealizable or impractical any gradient designs on the vertical portions of the curves to the left of the knee. Examination of winding patterns indicates that solutions that exhibit energy increases > 25% (or even less depending on coil type) above the global minimum energy become unrealizable (eg, demonstrating two or more "eyes" per half coil [four or more total eyes for an x or y coil] in the fingerprint wire patterns).

The red and purple dotted curves in Figure 2 represent two practical cases in which the primary coil currents are restricted to a single inner surface near the patient and the shield coil currents to an outer cylinder, while at the same time adding torque and eddy current constraints. Line segments acd of Figure 1 represent a primary winding surface consisting of a cone and a cylinder, whereas line segment ab represents its cylindrical shield winding; this yields designs similar to those proposed by previous literature 8, 22 and results in the red dotted curves in Figure 2. A second case is defined by restricting primary currents to the cylinder represented by line segment cd and shield currents to the cylinder ab; this yields designs similar to those proposed by previous literature 28 and produces the purple dotted curves in Figure 2. For both configurations, the eddy current surface is a 1‐m‐long, 620‐mm‐diameter cylinder, centered about the gradient isocenter and placed outside the shield winding of the gradient coil. The time = 0 eddy current error is constrained to a peak deviation less than 0.1% of the ideal gradient field on the surface of a 20‐cm‐diameter volume, corresponding to 100 µT for a 1 T/m step change in gradient strength. The torque constraint is set to zero for a uniform z‐directed B 0 main magnetic field. There is no net force for a perfectly uniform main B 0 field in all calculations.

---

### To infinity and some glimpses of beyond [^d42883f3]. Nature Communications (2017). Medium credibility.

Methods

Complexification of ordinary differential equations

The complexified version(z = x + iy) leads to the two-dimensional dynamical system:

The real axis is an invariant subspace, retrieving our real results; yet complexification endows the dynamics with an intriguing capability: as Fig. 4a, b illustrates through the (x, y) phase plane, collapse is avoided in the presence of a minuscule imaginary part. Large elliptical-looking trajectories are traced on the phase plane, eventually returning to the neighborhood of the sole fixed point of (0, 0) — which in the real case one would characterize as semi-stable. The system of Eq. (19) can be tackled in closed form since the ODEyields [1/z] = − t + [1/z](0). For z = x + iy (z (0) = x₀ + i y₀) we obtain the explicit orbit formulaEliminating time by dividing the two ODEs within Eq. (19) directly yields an ODE for y = y (x) (rather than the parametric forms of Eqs. (20), (21)). From this ODE, one can obtain that the quantityis an invariant of the phase plane dynamics, and thus the latter can be written as x² + (y − R)² = R², where. That is, the trajectory evolves along circles of radius R in the upper (resp. lower) half plane if y₀ > 0 (resp. y₀ < 0.) Approaching the axis with y₀ → 0, the curvature of these circles tends to 0 and their radius to ∞ (retrieving the real dynamics as a special case). Figure 4 through its planar projections illustrates not only the radial projection of the dynamics in the x − y plane, but the x − t and y − t dependencies.

---

### Standardization of spirometry 2019 update. An official American Thoracic Society and European Respiratory Society technical statement [^df365e99]. American Journal of Respiratory and Critical Care Medicine (2019). High credibility.

Back-extrapolated volume (BEV) on the volume–time curve — Time 0 is found by drawing a line with a slope equal to peak flow through the point of peak flow on the volume–time curve and setting Time 0 to the point where this line intersects the time axis. The BEV is equal to the volume of gas exhaled before Time 0, which, in these two examples from the same patient, is 0.136 L for the left panel (acceptable) and 0.248 L for the right panel (unacceptable). For this patient, the BEV limit is 5% FVC = 0.225 L.

---

### Standardization of spirometry 2019 update. An official American Thoracic Society and European Respiratory Society technical statement [^abfb5c44]. American Journal of Respiratory and Critical Care Medicine (2019). High credibility.

Within-maneuver evaluation and back-extrapolated volume (BEV) — at the point of PEF on the volume–time graph, a tangent is drawn and its intersection on the abscissa defines time 0, which becomes the start for all timed measurements; the BEV is the volume of gas that has already been expired from maximal lung volume to time 0 and is included in the FEV1 (forced expiratory volume in 1 second) and FVC (forced vital capacity) measurements; to ensure that the FEV1 comes from a maximal effort, the BEV must be ≤ 5% of the FVC or 0.100 L, whichever is greater; the 0.100-L tolerance is a reduction from the 0.150-L tolerance in the 2005 standards; the hesitation time, defined as the time from the point of maximal inspiration to time 0, should be 2 seconds or less; FEV1 and FVC measurements from a maneuver with BEV exceeding the limit are neither acceptable nor usable, and a large BEV will usually result in an erroneously high FEV1; patients with upper airway obstruction or neuromuscular disease are often unable to initiate a rapid increase in flow, and the BEV limit may be exceeded.

---

### Engineering phase and polarization singularity sheets [^d73719c8]. Nature Communications (2021). High credibility.

Fig. 2
Comparison between phase gradient maximization and field minimization to obtain phase singularities.

Both methods can be used to obtain phase singularities, but they produce different field behavior in terms of its real (blue) and imaginary (red) zero-isosurfaces. Yellow dots label the positions at which the field and phase gradients are optimized. Inset surface plots are the logarithmically scaled field intensities at z = 0 μm over the same XY domain. The z = 0 μm plane is indicated with the gray plane in each isosurface plot. a When the phase gradient in a specified direction is maximized, the two zero-isosurfaces align approximately tangentially and in the direction normal to that specified gradient. This produces a flat low field intensity structure along these aligned zero-isosurfaces. b Minimizing the field amplitude at a point to produce a singularity merely enforces a crossing of the zero-isosurfaces without any alignment, producing a 1D line singularity. c Simultaneously optimizing two nearby points with directed phase gradients can extend the range of the singularity sheet. d Minimizing the field amplitude at two points simultaneously does not guarantee alignment of the zero-isosurfaces and can instead produce multiple crossing lines, each producing a 1D line singularity.

---

### Fractional response analysis reveals logarithmic cytokine responses in cellular populations [^47f7d39e]. Nature Communications (2021). High credibility.

Methods

Software implementation

The methodology to perform and visualize FRA is provided as a user-friendly R-package available for download at. The package contains an installation guide and a brief user manual.

Formal definition of the FRC

Consider a series of doses x₁, …, xᵢ, …, xₘ and denote a single-cell response as y. Depending on the context, y, may be a number or a vector, e.g. the level of one or more measured signaling effectors. Suppose that responses to a given dose, xᵢ, are represented as the probability distribution, The FRC is then formally defined aswhere integration takes place over, the set of all possible responses, y. The integral quantifies the area under the curve (or under surface for multivariate data), with respect to y, defined asFor the calculations shown in Fig. 2 the integration corresponds to the calculation of the area of the gray regions in c–e. As explained in Supplementary Note 1, the FRC defined as above is closely related Rényi min-information capacity.

Formal definition of typical fractions

Having the responses represented in terms of the probability distribution, Eq. 3, we can define which responses, y, are typical to any of the doses. Precisely, we define the response, y, to be typical for dose x j if it is most likely to arise for this dose, which writes asThe above condition allows assigning any response, y, to a dose for which it is typical. Therefore, for a given dose, x i, we can identify what fraction of cells stimulated with this dose exhibits responses typical to any dose, x j, for j from 1 to m. These fractions, denoted as v ij, can be practically computed as explained below.

---

### Carrier-envelope phase on-chip scanner and control of laser beams [^84e8da44]. Nature Communications (2023). High credibility.

Fig. 3
Spatial CEP distribution measured with the on-chip probe.

a, c, d Cross-sections through the measured spatial change of CEP in degrees in the xz (horizontal), xy (transversal), yz (vertical) planes, where x and y are the axes along (horizontal) and perpendicular (vertical) to the laser polarization, respectively, and z is the laser beam propagation axis. The beam waist and the Rayleigh length of the measured beam are w₀ = 1.7 μm and zᵣ = 11.3 μm, respectively, with a central wavelength of 800 nm. c The phase map is overlapped with green contours of the measured current J₀. Cuts go through the point of the highest J₀. Dashed lines show the intersects of the plotted cuts: cyan for transversal, pink for horizontal and green for vertical. Phase and J₀ along the optical axis (black dashed line) are shown in (b). Triangles and circles are the measured datapoints of the current amplitude J₀ and the CEP, respectively. The maximum of J₀ (green) signifies the position of the focus, where the measured phase was offset to zero. Solid black line shows the best fit of the model from Eq. (12) in ref.with parameters g = 0.2, γ = 0.3, and Cᵣ = −0.8. Dotted line is the –atanfunction, i.e. Gouy phase. Dotted horizontal lines define the range of CEP used for the calculation of volume of flat phase being 9.6 μm³. e, f Show the model in xy (transversal), yz (vertical) plane.

---

### Advanced statistics: linear regression, part I: simple linear regression [^18239641]. Academic Emergency Medicine (2004). Low credibility.

Simple linear regression is a mathematical technique used to model the relationship between a single independent predictor variable and a single dependent outcome variable. In this, the first of a two-part series exploring concepts in linear regression analysis, the four fundamental assumptions and the mechanics of simple linear regression are reviewed. The most common technique used to derive the regression line, the method of least squares, is described. The reader will be acquainted with other important concepts in simple linear regression, including: variable transformations, dummy variables, relationship to inference testing, and leverage. Simplified clinical examples with small datasets and graphic models are used to illustrate the points. This will provide a foundation for the second article in this series: a discussion of multiple linear regression, in which there are multiple predictor variables.

---

### Three-dimensional wave breaking [^58966bb2]. Nature (2024). Excellent credibility.

Fig. 1
Surface elevations of maximally steep 3D wave groups differ in space and time.

a – c, g – i, Top and bottom rows show the measured surface elevation of maximally steep non-breaking waves at the time of maximum amplitude with corresponding images above and below. a – c, Directionally spread wave groups (Δ θ = 0°) with σ θ = 0° (a), 20° (b) or 40° (c). g – i, Crossing wave groups (σ θ = 0°) with Δ θ = 90° (g), 135° (h) or 180° (i). d, e, Time series (d) and corresponding frequency spectra (e) measured at the intended point of the linear focus (x = 0 and y = 0) for maximally steep wave groups with fixed Δ θ = 0° (top) and fixed σ θ = 20° (bottom). The line colours go from dark to light as σ θ and Δ θ are increased. f, Visualization of the directional parameter space of our experiments (Δ θ = 0°; σ θ = 0°,10° or20°; Extended Data Table 1). Markers with black outlines correspond to the experiments shown in a – c and g – i. In a – c and g – i, the waves travel from left to right.

---

### Accuracy of reverse shoulder arthroplasty angle according to the size of the baseplate [^757fecc7]. Journal of Shoulder and Elbow Surgery (2023). Medium credibility.

Background

Glenoid inclination must be assessed precisely during preoperative planning for reverse shoulder arthroplasty (RSA) to position the glenoid baseplate correctly. We hypothesized that a more dynamic measurement method would better match the diversity of glenoid heights in the population and the variety of commercialized glenoid baseplates. Our purpose was to describe a new method to measure the RSA angle accounting for the baseplate size.

Methods

Computed tomography scans of 50 shoulders that underwent RSA for primary osteoarthritis or cuff tear arthropathy between June 2019 and February 2020 were included (mean age, 76 years). Three variants of the RSA angle were measured: the RSA angle as originally described by Boileau et al, the relative RSA 25 angle (which simulates the implantation of a 25-mm baseplate), and the relative RSA 29 angle (which simulates the implantation of a 29-mm baseplate). Measurements in the 2-dimensional true reformatted scapular plane were made by 3 independent operators.

Results

The mean R-S distance (ie, distance between point R [intersection of supraspinatus fossa line with glenoid surface] and point S [inferior border of glenoid]) was 24.2 ± 4.0 mm. The mean RSA angle was 20.3° ± 8.4°, whereas the mean relative RSA 25 angle was 19.3° ± 7.8° and the mean relative RSA 29 angle was 15.6° ± 7.6°. The mean difference between the RSA angle and the relative RSA 25 angle was 1.0° ± 4.1° (P = 0.16). The mean difference between the RSA angle and the relative RSA 29 angle was 4.7° ± 3.8° (P < .0001). In half of the shoulders in our series, the difference between the RSA angle and the RSA 29 angle exceeded 5°.

Conclusion

The RSA angle is a reproducible measure of the inclination of the inferior part of the glenoid that is reliable in most cases for glenoid baseplates of 24–25 mm in height. However, surgeons should be aware that the RSA angle may overestimate the superior orientation of the inferior glenoid for baseplates of different sizes or for small- or large-stature patients. In these cases, the relative RSA angle adapted to the size of the baseplate more accurately evaluates the inclination of the inferior glenoid.

---

### Cortices of fibula and tibia can provide landmarks for accurate syndesmosis fixation angle: computed tomography validation of angle bisector method [^3c850a92]. The Journal of Foot and Ankle Surgery (2023). Medium credibility.

Anatomic syndesmosis reduction is necessary to restore ankle biomechanics and prevent poor clinical outcomes, but malreduction can be encountered frequently since the ideal fixation angle varies between patients and fixation levels. This study aimed to validate the angle bisector method to reveal whether it provides an accurate syndesmotic fixation angle that is patient- and level-specific. Lower extremity CT angiography of 50 consecutive patients (25 male, 25 female) without evident ankle pathology were evaluated. The average age was 52.8 (± 18, range: 18–75). Lines tangent to anterior and posterior cortices of tibia and fibula were drawn in the axial plane at both 2 cm and 3.5 cm above the ankle joint line. Bisection of the angle formed between these lines was drawn and its relationship with the centroidal axis, which is proposed to be the ideal syndesmotic axis, was evaluated. The angle between the bisector line & the centroidal axis and the distance between their most lateral intersections with the fibula were calculated. The measurements were made by 3 blinded observers. Intra- and interobserver reliability analyses were conducted. The average centroidal axis-bisector angle was 2.1° ± 2.1° at 2 cm and 0.6° ± 1.3° at 3.5 cm level. The average distance to the actual syndesmosis entry point was 1.0 ± 0.9 mm at 2 cm and 0.4 ± 0.4 mm at 3.5 cm level. The values didn't show any significant difference according to gender. Intra- and interobserver reliability analysis showed excellent correlation in all parameters (interclass correlation coefficient > 0.90). Angle bisector method was found strongly reliable providing accurate direction for syndesmotic axis. It can provide a patient- and level-specific angle for the application of syndesmotic implants without increasing the fluoroscopy exposure. Its use can have a broad impact on functional outcomes of ankle injuries by decreasing the malreduction rates. Further cadaveric validation and safety studies should be conducted for possible clinical usage.

---

### Symmetry-enforced topological nodal planes at the fermi surface of a chiral magnet [^97fd5fe6]. Nature (2021). Excellent credibility.

Calculated electronic structure

Figure 1e shows the density functional theory (DFT) band structure of MnSi, taking into account spin–orbit coupling, for the experimental moment of 0.41 Bohr magnetons (μ B) per Mn atom along the [010] direction (Methods, Extended Data Fig. 5). Ten bands are found to cross the Fermi level (Fig. 1e). In agreement with our symmetry analysis and the tight-binding model (Fig. 1d), we find the same generic band crossings, namely: (1) NPs on the BZ boundaries k x = ± π and k z = ± π; (2) an odd number of Weyl points along Y 1 –Γ–Y; and (3) an odd number of four-fold points along R 1 –U–R.

The calculated FSs as matched to experiment are shown in Fig. 1f, highlighting the NPs at the BZ boundaries at k x = ± π and k z = ± π (see Extended Data Table 1 for key parameters and Extended Data Fig. 5). Eight FS sheets centred at Γ comprise two small isolated hole pockets (sheets 1 and 2), two intersecting hole pockets with avoided crossings and magnetic breakdown due to spin–orbit coupling (sheets 3 and 4) and two pairs of jungle-gym-type sheets (sheets 5 and 6, and sheets 7 and 8). Sheets 9 and 10 are centred at R, comprising eight three-fingered electron pockets around the [111] axes and a tiny electron pocket, respectively. The sheet pairs (5, 6), (7, 8) and (9, 10) extend beyond the BZ boundaries with pairwise sticking at the NPs. They represent TPs (marked in red) with extremal Berry curvatures protected by the magnetic screw rotationsand. In contrast, sheets 5 to 10 do not form TPs at the BZ boundary k y = ± π, because the moment pointing along [010] breaks.

---

### Foot deformity correction planning in the sagittal plane based on the vitruvian foot first metatarsal mechanical axis and calcaneus anatomic axis [^7bd5abb5]. The Journal of Foot and Ankle Surgery (2021). Medium credibility.

The aim of the study was to test a novel planning method for simultaneous midfoot and hindfoot deformity correction, based on reference lines and angles (RLA) of the talus, calcaneus and first metatarsal in 64 normal radiographs from 55 patients. Talus Joint Line (TJL), from the border of the articular surface of the talus and the posterior process of talus, and mechanical axis of the first metatarsal form the mechanical Lateral Talometatarsal Angle (mLTMA) = 23.6º (± 3.2). The length of the first metatarsal line was measured from its intersections with the TJL and first metatarsal head and it was 4.3 (± 0.94) times longer that TJL (k). For hindfoot correction planning, we used an axis of the calcaneus formed by a line starting at the middle of the back of the calcaneal tuberosity and going perpendicular to a line from the top point to the bottom point of the calcaneal tuberosity. The intersection of the calcaneal line and the anterior continuation of TJL form the lateral heel angle (LHA) = 15.2º (± 3.4). The following parameters were identified: the length from the intersection point of the lines and anterior point of TJL was 2.56 ± 1.1 longer than TJL (k1). The length from the intersection point and posterior border of the calcaneus was 4.59 ± 1.0 times longer than TJL (k2). Planning using the new method was demonstrated and confirmed on 3 case examples. A novel method for analysis and planning of midfoot and hindfoot sagittal plane deformity correction may be used separately or simultaneously for complex deformity correction.

---

### Iobenguane I-123 (Adreview) [^0479e97e]. FDA (2024). Medium credibility.

Step 1.	Visual Guidelines for AdreView Cardiac Uptake on Anterior Planar Chest Images

a. Normal:

Distinct visualization of the left ventricular myocardium in the left lower chest, with greater uptake in the heart than in the adjacent lungs and mediastinum (Figure 1).
Figure 1.	Normal anterior planar AdreView image of the chest
b.	Abnormal:

Homogeneously or heterogeneously decreased cardiac uptake, with indistinct or absent visualization of the left ventricular myocardium. Cardiac activity is usually less than or equal to that of the adjacent left lung (Figure 2a). In extreme cases, little or no AdreView uptake is seen in the left lower chest (Figure 2b).
Figure 2.	Abnormal anterior planar AdreView images of the chest: a) Heterogeneously reduced cardiac uptake; b) Absent cardiac uptake

Step 2.	Quantitate AdreView Cardiac Uptake

The AdreView H/M ratio is determined from the activity in heart (H) and mediastinum (M) regions of interest (ROIs) drawn on the anterior planar chest image (Figure 3) using the following procedure:

Draw an irregular ROI defining the epicardial border of the heart. If the epicardial border cannot be defined because all or the majority of the myocardium is not visualized, draw the ROI based upon the presumed location of the heart, using the medial aspects of the left and right lower lung for anatomical guidance.
Draw a horizontal line to mark the estimated location of the lung apices. If the most superior aspect of the image does not include the lung apices (because of limited field of view for a small gamma camera), draw this line at the top of the image display.
Draw a vertical line approximately equidistant from the medial aspects of the right and left lung.
Examine the counts for the 12 pixels along the vertical line starting 4 pixels below the intersection point with the horizontal line determined in step 2, and identify the pixel with the lowest counts. If more than one pixel has this same number of counts, choose the most superiorly located pixel.
Using the pixel defined in step 4 as the center, draw a square ROI of 7×7 dimensions.
Calculate the H/M ratio by dividing the counts/pixel in the total myocardium ROI determined in step 1 by the counts/pixel in the 7×7 pixel mediastinal ROI determined in step 5.

Figure 3. Illustration of creation of regions of interest for determination of the H/M ratio

---

### Three-dimensional analysis of bone morphology of the rheumatoid arthritis elbow [^c7f13557]. Journal of the American Academy of Orthopaedic Surgeons: Global Research & Reviews (2025). Medium credibility.

Points of Interest

The Cartesian coordinate systems of the humerus (X H, Y H, and Z H -axes), ulna (X U, Y U, and Z U -axes), and radius (X R, Y R, and Z R -axes) were determined for the reference bones (Figure 2, see Supplemental Digital Content 1).

Fig. 2
Illustration showing axis settings. (A) Distal humerus, (B) proximal ulna, and (C) radial head.

In the distal humerus, the sagittal planes were defined as the planes passing through the anatomical points of the (1) capitellum center, (2) lateral trochlear ridge, (3) trochlear groove, and (4) center of the medial trochlea. Seven planes (0°, 30°, 60°, 90°, 120°, 150°, and 180°), including the Y H -axis, were determined with the X H Y H plane at 0°/180° and the Y H Z H plane at 90°. Subsequently, the points of interest were determined at the intersection of the six planes, with the sagittal planes on the surface of the 3D model, and were categorized into anterior (0° and 30° planes), inferior (60°, 90°, and 120° planes), and posterior (150° and 180° planes) regions (Figure 3, A).

Fig. 3
Illustration showing planes to be evaluated for joint surfaces. A, Distal humerus, (B) proximal ulna, and (C) radial head.

In the proximal ulna, the sagittal plane was defined as the plane passing the anatomical points of the (1) lateral verge of the trochlear notch, (2) ridge of the trochlear notch, and (3) center of the medial trochlear notch. Seven planes are established at 0°, 30°, 60°, 90°, 120°, 150°, and 180°, including the Y U -axis. The Y U Z U plane corresponds to 0°/180°, whereas the X U Y U plane is positioned at 90°. Subsequently, the points of interest were determined at the intersection of the six planes, with the sagittal planes on the surface of the 3D model, and were categorized into anterior (0° and 30° planes), inferior (60°, 90°, and 120° planes), and posterior (150° and 180° planes) regions (Figure 3, B).

---

### On-chip cherenkov radiation tuning in 3.2–14 THz [^1df4335a]. Nature Communications (2025). High credibility.

Fig. 2
Measurement results of the THz radiation frequency and spectrum of the chip.

a Measured spectral peaks spanning 3.2–14 THz for different grating periods under different electron energies. The central frequency and the sample numbers are shown at the top and bottom of the figure, respectively. The corresponding values of E and p for different samples are listed in Supplementary Information Section S5. b Wavevector matching for the CR in the HMM and radiation coupled into free space. The deep red, red, and light red solid lines represent the projections of the k x - k z hyperbolic curve (the red hyperbolic curve indicated in Fig. 1b) onto the ω-k z plane at different frequencies. The black lines are the dispersion lines of the evanescent fields surrounding free electrons (namely, ω = u 0 ·| k z |) with different u 0 (E). The black lines and colored lines intersect at the deep red, red, and light red points, which indicate the end points of the k z of the excited CR in the HMM and correspond to the same k z. To extract the CR into free space, k z needs to be matched by the wavevector introduced by the grating (2π n / p) to change it to the free space radiation region (| k z | < ω / c). According to this figure, a higher electron velocity (energy) results in a higher radiation frequency of the chip. c The black line (ω = u 0 ·| k z |) intersects with the red, violet, and yellow solid lines (projections of the k x - k z hyperbolic curve onto the ω-k z plane) at the red, violet, and yellow points, which indicate the end points of the k z of the excited CR and correspond to different k z values. To extract the CR into free space, k z needs to be matched by the wavevector introduced by the gratings (2π n / p) of different grating periods p, and a smaller p corresponds to a higher radiation frequency. d Measured radiation spectra at E = 1.4 keV (deep red line), 2.0 keV (red line), and 2.6 keV (light red line). The grating period of the chip is fixed at 5 μm. e Measured radiation spectra at p = 5 μm (red line), 4 μm (violet line), and 3 μm (yellow line). The electron energy is fixed at 2 keV. Each spectrum in this figure is normalized by its own maximum peak.

---

### Nodal band-off-diagonal superconductivity in twisted graphene superlattices [^b50d4752]. Nature Communications (2023). High credibility.

Spectral properties

We here have the rather unique situation that there are pairing channels, associated with the IRs A 1,2 and E 2, where the pairing is constrained by C 2 z to be entirely band-off-diagonal. One immediate very unusual consequence is that the superconducting order-parameter transforming under the trivial representation (A 1) has a symmetry-imposed line of zeros along the Γ-M line, and hence a nodal point in the spectrum. This is related to the topology-induced non-trivial representation of C 2 x in band space. We refer to ref.for the discussion of other topological nodal points for pairing in obstructed TBG bands. As we will show next, band-off-diagonal pairing leads to additional unusual spectral properties with far-reaching consequences for graphene moiré systems. To this end, consider the following effective Hamiltonian, where the scalar function Δ k describes the form of pairing. We will here study two cases that are conventionally considered to be fully gapped, (i) a momentum-independent " s -wave state" (A 2 or A pairing in Table 1) where Δ k = Δ 0 and (ii) a "chiral p -wave" state, or more precisely an E 2 (1, i) state, where Δ k = Δ 0 (X k + i Y k) with (X k, Y k) being smooth, MBZ-periodic functions transforming as (x, y) under C 3 z. Furthermore, we parameterize the dispersion, ξ η ⋅ k, α, of the two flat bands (α = ±) in valley η = ± as ξ k, α = ϵ k − μ + α δ k, where ϵ k and δ k are C 3 z (and, for D 0 = 0, C 2 x) symmetric functions.

---

### Primer on binary logistic regression [^8adbb90e]. Family Medicine and Community Health (2021). Medium credibility.

Visualising the logistic function can help to clarify why this statistical form is useful for examining a binary outcome. Figure 3 shows the logistic function as the curve connecting the data points. Each data point is plotted with a value of the outcome along the y-axis. Because the outcome is binary with the two values of 0 and 1, the points are plotted at y = 0 and y = 1. The predictor variable is shown along the x-axis and appears to be continuous. Each data point takes a value of x which seems to range from about 10 to about 35. It is clear that the data points in the y = 0 category of the outcome generally have lower values of x than the data points in the y = 1 category. This pattern suggests that, as x increases, the probability of a person having the outcome value of y = 1 also increases.

Figure 3
The logistic function with example data.

The grey logistic function line is the logistic regression model for these data. The line identifies the predicted probability of y = 1 for each value of x. For example, if x = 17, the predicted probability of y would be.18. This might be translated into into a percentage with a statement like, there is an 18% probability that someone with an x value of 17 would have a y value of 1. A more concrete example might be to think of the x value as years a person has smoked cigarettes daily and y as their probability for being diagnosed with lung cancer. So, a person who has smoked daily for 17 years has an 18% probability of being diagnosed with lung cancer. Please note that these data are not actual lung cancer data; this is just an example to assist in developing intuition around the logistic function meaning. If these data were years of smoking predicting lung cancer diagnosis, equation 1 might be rewritten as equation 2:

Equation 2. Applying the statistical form of the binary logistic regression model.

---

### Atlas (C1) lateral mass screw placement using the intersection between lateral mass and inferomedial edge of the posterior arch: a cadaveric study [^f3e7920d]. European Spine Journal (2022). Medium credibility.

Purpose

To compare the Atlas (C1) lateral mass screw placement between screw trajectories of 0° and 15° medial angulation while using the intersection between lateral mass and inferomedial edge of the posterior arch.

Methods

Forty-eight Atlas lateral masses were prepared and divided into 2 groups: Group 1; screws inserted at 3 mm lateral to the reference point with screw trajectory of 0° angulation(N = 24) and Group 2; those inserted with screw trajectory of 15° medial angulation(N = 24). We evaluated the atlas anatomy, screw purchase and the presence of any breaches using CT scan.

Results

The radiographic parameters for Groups 1 and 2 were found statistically different (p-value < 0.05): bilateral intraosseous screw lengths (17.92 ± 1.47 mm. vs. 20.71 ± 2.4 mm.), bilateral screw length (29.92 ± 1.72 mm. vs. 33.13 ± 1.78 mm.), left screw medial angulation (x°) (0.67° ± 0.78° vs.14.17° ± 3.51°), right screw medial angulation (y°) (0.83° ± 1.03° vs.14.25° ± 2.53°) and bilateral screw medial angulation (0.75° ± 0.9° vs. 14.21° ± 2.99°). Twenty-two screws (91.67%) using the 0° medial angulation and nineteen screws (79.17%) using the 15° medial angulation had no cortical violations (Grade 0). However, two screws (8.33%) with 0° medial angulation and five screws (20.83%) with 15° medial angulation had breach less than 2 mm (Grade 1). There were no screws with breach between 2 and 4 mm (Grade 2) or greater than 4 mm. (Grade 3).

Conclusion

A starting point of 3-mm lateral to the intersection between lateral mass and inferomedial edge of the Atlas posterior arch can be safely and effectively used to insert C1 lateral mass using both 0° and 15° medial angulation.

---

### Photonic crystals possessing multiple weyl points and the experimental observation of robust surface States [^bc8084ec]. Nature Communications (2016). Medium credibility.

Robust surface states on Weyl photonic crystals

Owing to the topological charges of Weyl points, the existence of surface states connecting the Weyl points with opposite topological charges is guaranteed by the bulk-surface correspondence. To study the properties of the boundary modes, we consider a Weyl photonic crystal truncated in the y direction, bounded by a PEC slab, as illustrated in Fig. 5a. Periodic boundary conditions are applied in both the x and z directions in our simulation. Calculated surface dispersions near 12.25 GHz are shown in Fig. 5b. Surface states are plotted in colour, while the projected bulk states are plotted in grey. Only half of the Brillouin zone (k z ∈[−0.5 π / d, 0.5 π / d]) is shown for clarity. The Weyl points at K and K ′ with frequency of 12.25 GHz are projected onto (k x, k z) = (2 π /3 a, 0) and (4 π /3 a, 0), respectively. Each of these two Weyl points carries a topological charge of −1. Two linearly dispersive cones of projected bulk bands are formed near these points. Two sheets of surface states, which are connected to one of the two Weyl points, are found in the positive k z region and the negative k z region, where the colours indicate the frequency of surface states. The surface states with positive k z always have positive group velocity (that is, in the + x direction), which is consistent with the k z -Chern number in Fig. 1j; the surface states with negative k z have negative group velocity. When we treat k z as an additional parameter of the 2D subsystem, Weyl points can be viewed as phase transition points where the bands in a k z plane change their Chern numbers along with k z. This can be seen by cutting three k z slices (k z = −0.05 π / d, 0, 0.05 π / d) in the surface dispersion, as shown in Fig. 5c–e. When k z = −0.05 π / d, the gap Chern number between the fifth and sixth bands is −1. The subsystem has an anticlockwise (in the xy plane) surface state, as shown by the blue line in Fig. 5c. As k z increases to 0 (Fig. 5d), the fifth and sixth bands touch at K and K ′ and the surface states are symmetric about k x as required by time-reversal symmetry. As k z increases further to 0.05 π / d (Fig. 5e), the 2D band gap reopens with a gap Chern number of 1 and the group velocity of surface states changes direction (now clockwise). Furthermore, the surface dispersion in vicinity of the projection of Weyl point (Supplementary Fig. 6) forms a helicoidwith its winding direction determined by the sign of the topological charge. In addition, two other Weyl points at H and H ′ lie at (2 π /3 a, π / d) and (4 π /3 a, π / d) of the surface Brillouin zone, which are not shown in Fig. 5b. These Weyl points carry a topological charge of +1. Due to the band dispersion along the y direction, these two Weyl points are immersed in the projected band of the bulk state in the surface Brillouin zone. The sheets of surface states with positive and negative k z will eventually merge into the bulk state.

---

### Revealing topology with transformation optics [^ffb7f764]. Nature Communications (2021). High credibility.

Fig. 1
The multiplicity of a conformal mapping.

Metasurface geometries in a, b the virtual space (u-v frame) and in c, d the real space (x – y frame). The relation between these two spaces is governed by the transformation in Eq. (1), and its contour plot containing the isolines of real and imaginary parts of z is shown by the light-gray solid lines in a, b. The filled orange circles and triangle markers in a, b, and e denote theandsingularities of the mapping, respectively. The solid orange lines in a and b denote the branch cut of the mapping, terminating at theandsingularities. All the magenta and black solid lines in a, b correspond to the boundary of the metasurface with the same colors shown in c, d, showing the multiplicity of the mapping. To further demonstrate such multiplicity, four points along the black line of the slab in a, b with coordinates (u, v) = (1, − π), (1, − π /2), (1, 0), and (1, π /2) are highlighted by the open stars, circles, triangles, and squares, and their equivalent points are shown by the same markers in c, d and in the eccentric cylinder of the virtual space in b. The values of a 0 are 0 in a and c, and 0.1 in b and d. Other geometric parameters are Λ = 30 π nm, w 0 = 1.5, u 0 = 1, and d = 0.5. e The left panel illustrates the geometries of the plasmonic metasurfaces in the virtual space for a complex a 0 = δ exp(i θ). The two solid lines show the trajectories of the ln(0) singularities as θ varies from − π to π, for two values of δ = 0.1 (green) and δ = 0.03 (purple). Along the solid green line, we depict the eccentric cylinders with different values of θ, and their corresponding metasurfaces in the real space are shown in the right panel. The orange dashed lines highlight the metasurfaces when δ = 0.

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^13a4a404]. Magnetic Resonance in Medicine (2021). Medium credibility.

FIGURE 4
A, A region contours of constant Bz for Y gradient coil, with (red) and without (black) E max optimization, showing that gradient distortion is virtually identical despite the peak E‐field being reduced by a factor of 2.8 for the Y coil. B, Difference in the B y components of the gradient field with versus without E‐field optimization. Values are normalized to the gradient strength yielding units of length (mm) and show a highly uniform concomitant y‐directed field added to the optimized (asymmetric) solution. C, Wire pattern representing the difference between optimized (asymmetric) and nonoptimized (symmetric) solutions with same current scaling as Figure 3. Similar results are obtained for the X gradient coil

The key difference between the E‐field minimized and nonminimized solutions is the addition of a uniform concomitant B 0 field component in the x or y direction. Figure 4B shows a difference plot of the concomitant B y field, normalized to gradient strength (units of millimeters), which is responsible for the reduction in E‐field. Figure 4C shows the winding that would need to be added to the Y symmetric coil (Figure 3B) to obtain the winding pattern of the Y asymmetric coil (Figure 3D), and shows the fundamental difference between the two solutions. The winding in Figure 4C produces a uniform field transverse to the main B 0 field, resulting in a concomitant component with additional magnetic stored energy. Conceptually, this can be thought of as a second coil, which if activated, converts the symmetric coil into an asymmetric coil with reduced E‐field but otherwise identical distortion. The added concomitant field in Figure 4B is highly uniform with a 0.85% variation over the 26‐cm imaging region, resulting in minimal distortion of the desired gradient field; this concomitant field can be compensated with a phase/frequency offset correction by the scanner. Figure 4B shows that the average concomitant field of 88.5 mm within the imaging region can be directly compared with the z₀ₓ defined by Meier et al, 29 in which a value of 127 mm was reported for an asymmetric head gradient. The z₀ₓ for both the ESP and HG2 gradients are approximately 120 mm 30; these are both fully asymmetric designs (single eye per half coil with all return currents flowing above the head), similar to the original concept defined by Roemer. 12 The X coil of Figure 3 requires a smaller concomitant field (z₀y = 57.8 mm) than the Y coil, reflecting a decreased need to pull E‐field off the torso region due to the smaller extent of the body in the anterior–posterior direction.

---

### Charge density wave induced nodal lines in LaTe [^cc2515f4]. Nature Communications (2023). High credibility.

Fig. 3
Band crossings and the Kramers nodal line (KNL).

a E (k z) bands at k x = 0.59 Å −1 without (w/o) spin-orbit coupling (SOC) for the 7f structure. The irreducible representations are shown. The vertical dashed line represents the k z point on Γ 2 X 2 i.e. the Σ line in the 2 nd BZ (see Fig. 1 d). Zoomed colored rectangles of a show the bands around b L, c R, d T, and e B. Comparison of ARPES and DFT for f R at k z = 0.229 Å −1 and g L at k z = 0.196 Å −1. The positions of these crossings obtained from DFT (orange and blue filled circles for R and L, respectively) are superimposed. The dashed orange and blue curves serve as guide to the eye. h A schematic representation of the gapless L and R crossings in the E - k z - k x space (red dashed lines) and their projection on the k x - k z plane showing the spinless nodal lines (thick red lines on both sides of the Σ line). i – m Same as a – e except that the calculations are performed with SOC. n E (k x) ARPES intensity plot at k z = 0.204 Å −1 (dashed red and black curves serve as guide to the eye) compared with the positions of the crossings from DFT for T (red, light red circles) and B (black, gray circles). o A schematic representation of the four crossings (green dashed lines) related to the upper and lower branches of T and B. The KNL appears along the Σ line and is denoted by a green thick line on the k x - k z plane.

---

### Causal evidence of a line attractor encoding an affective state [^243fec37]. Nature (2024). Excellent credibility.

Fig. 3
Neural implementation of a line attractor by functional connectivity.

a, Left, the paradigm for examining activity in non-targeted x 1 and x 2 neurons after activation of unitary x 1 neurons. Right, the average z -scored activity of the perturbed (targeted) x 1 neurons (25 single neurons from n = 8 mice). Data are the average trace (dark green) ± s.e.m. (shaded green area). b, The average z -scored activity of non-targeted x 1 neurons after targeting unitary x 1 neurons. n = 8 mice. Data are average trace (dark green) ± s.e.m. (shaded green area). c, The average z -scored activity of non-targeted x 2 neurons after targeting of unitary x 1 neurons. n = 8 mice. Data are average (trace in dark red) ± s.e.m. (shaded red area). d, Quantification of activity in non-targeted x 1 neurons after targeting of single x 1 neurons. NS, P = 0.16; ✱✱ p = 0.0037 (bottom), ✱✱ p = 0.0005, P = 0.0016 (top). n = 8 mice. Data are mean ± s.e.m. e, Quantification of the activity in non-targeted x 2 neurons after targeting of single x 1 neurons (NS; n = 8 mice). Data are mean ± s.e.m. f, The paradigm for examining the activity in non-targeted x 1 and x 2 neurons after activation of single x 2 neurons (left). Right, the average z -scored activity of targeted x 2 neurons (18 single neurons from n = 7 mice). Data are the average trace (dark red) ± s.e.m. (shaded red area). g, The average z -scored activity of non-targeted x 2 neurons after targeting of single x 2 neurons. n = 7 mice. Data are the average trace (dark red) ± s.e.m. (shaded red area). h, The average z -scored activity of non-targeted x 1 neurons after targeting of single x 2 neurons. n = 7 mice. Data are the average trace (dark green) ± s.e.m. (shaded green area). i, Quantification of activity in non-targeted x 1 neurons after targeting of single x 2 neurons. NS, from bottom to top, P = 0.999, P = 0.31, P = 0.09; ✱ p = 0.0316. n = 7 mice. Data are mean ± s.e.m. j, Quantification of activity in non-targeted x 2 neurons after targeting of single x 2 neurons (NS). n = 7 mice. Data are mean ± s.e.m.

---

### Non-additivity of molecule-surface van der waals potentials from force measurements [^8e13a69c]. Nature Communications (2014). Medium credibility.

C 3 coefficients

We now turn to the determination of precise C 3 coefficients within the theoretical model given by equation (2). For a correct recovery of the (by definition asymptotic) C 3 values, it is crucial to exclude the z tip -interval where the height z mol of the lower end of the molecule above the surface (Fig. 1) is small and deviations from equation (3) are expected, due to Pauli repulsion, higher-order terms of the vdW multipole expansion, and the invalid point dipole approximation. To identify the minimal allowed z mol, we fit the experiments in intervals that start between z mol = 3.5 and 7.0 Å (yellow regions in Fig. 3a) and end at the largest z tip values reached. We find that all fit parameters (Fig. 3b) and the fit quality s (inset of Fig. 3a) converge to a plateau for z mol ≥ 4.8 Å. Below this threshold, the fitted parameters depend strongly on the starting value of the fit region, with z₀ becoming unphysically small. The value of the threshold is consistent with calculations in the random phase approximation (RPA)(see Supplementary Methods). Fits for a starting value of z mol = 5.3 Å are displayed in Fig. 3a, while Fig. 3c shows how the fit quality depends on the individual C 3, X values. For all three molecules, we find a clear minimum in s, for NTCDA at C₃,N = 24.9 kcal mol⁻¹ Å³, for PTCDA C₃,P = 25.9 kcal mol⁻¹ Å³ and for TTCDA C₃,T = 28.0 kcal mol⁻¹ Å³. The respective data points are plotted in Fig. 4a.

---

### Critical exponents and scaling invariance in the absence of a critical point [^760713e6]. Nature Communications (2016). Medium credibility.

Scaling and characteristic lengths

As suggested by one of the reviewers, in a conventional ferromagnet scaling plots can also be written in such a way that the dependence on the correlation lengthis made explicit (ν being the corresponding critical exponent). Let us consider the following equations of state of a ferromagnet:

and

with F 1 (x) and F 2 (x) some scaling functions. In Fig. 5b, c the same data points shown in Fig. 4c are plotted in the representations defined above. Points falling in the grey zone are rendered in grey. Indeed, collapsing is observed for the coloured points while the grey ones spread out in the plot planes. Figure 5c appears very similar to Fig. 4c and basically the same considerations apply. Equation (7) leads instead to the plot in Fig. 5b that has a different shape.

If the spreading of grey points observed in all the scaling plots was due to the size of magnetic domains L acting as a cutoff for the correlation length, from equation (7) one would expect the following relation to be fulfilled in the patterned phase

with F 3 (x) andappropriate scaling functions. This scaling relation is not compatible with the one found in within the grey zone, which can be rewritten as

Equations (9) and (10) can be simultaneously fulfilled only for

This last relation is not obeyed by the 2D-Ising critical exponents β = 1/8, δ = 15 and ν = 1.

A more proper framework to discuss whether L acts as a cutoff for the correlation length is provided by the finite-size scaling (FSS) ansatz, according to which the magnetization M L (T) of a finite system of linear size L x should be related to the magnetization of the corresponding infinite systems M ∞ (T) by the law

---

### Interstitial oxygen as a source of p-type conductivity in hexagonal manganites [^d3b1534d]. Nature Communications (2016). Medium credibility.

Position of interstitial oxygen and structural effects

The low temperature at which YMnO 3 exchanges oxygen with the atmosphere makes cation vacancies and diffusion unrealistic, and the positive Seebeck coefficient from mobile holes points to interstitial oxygen anions, O i, as the dominating point defect. High-temperature X-ray diffraction measurements of nanocrystalline YMnO 3 show that interstitial oxygen is incorporated into the lattice, causing anisotropic chemical expansion (Supplementary Fig. 2). We now turn our attention to the position of interstitial oxygen in YMnO 3. Potential energy surfaces (PES) were determined by mapping the energy landscape of the O i position in several lattice planes by static Density Functional Theory (DFT) calculations (See details in Supplementary Fig. 3 and Supplementary Note 1). For illustration, the PES of O i in the (002) (a) and (3 / 2 00) (b) planes are included in Fig. 2 along wth a unit cell with the corresponding lattice planes (d). The relative energy of O i along the grey line in Fig. 2b is shown in Fig. 2c. The most stable positions of O i was found to be between three Mn in the Mn–O planes at z = 0 and 1 / 2, resulting in six equivalent possible sites for O i in the P 6 3 cm unit cell, (1 / 3, 1 / 3, 0), (2 / 3, 0, 0), (0, 2 / 3, 0), (2 / 3, 2 / 3, 1 / 2), (1 / 3, 0, 1 / 2) and (0, 1 / 3, 1 / 2), as illustrated by green circles in panels a and b.

---

### Operative guidelines for the reconstruction of the native glenoid plane: an anatomic three-dimensional computed tomography-scan reconstruction study [^d959b6d8]. Journal of Shoulder and Elbow Surgery (2012). Low credibility.

Background

Reconstruction of the native plane in biconcave eroded glenoids is difficult. Nevertheless, accurate reconstruction of this plane is imperative for successful total shoulder arthroplasty. This study aims to determine guidelines that can increase the accuracy of glenoid component positioning.

Methods

Three different circular planes were determined on 3-dimensional computed tomography (CT) scans of 152 healthy shoulders. First, the circular max (CM) plane is formed with the superior tubercle and 2 points, 1 anterior and 1 posterior, at the rim of the inferior third of the glenoid. Second, the circular inferior (CI) plane is formed by 3 points at the inferior 2 quadrants of the glenoid rim. Third, the circular minima (Cm) plane is formed with 3 points situated at the noneroded sector of the anterior glenoid. The angulation of the spinal scapular axis (SSA), the line between the most medial point of the scapular spine and the center of the three different glenoid planes, and the correlation coefficient between the radius of the circle and the length of SSA are calculated.

Results

Angle SSA in the x-axis were 94°, 93°, 93° and in the y-axis were 95°, 111°, and 111° for CM, CI, and Cm, respectively. Correlation coefficient between the radius of the circle and the length of SSA: r = 0.69 for CM, r = 0.75 for CI, and r = 0.75 for Cm.

Conclusion

Three points situated at the native anterior glenoid can reconstruct, within 2° accuracy (95% confidence interval, 1.8°-2.3°), the CI plane. A relationship exists between the radii of the 3 glenoid circles and the width of the scapula (SSA length).

---

### Metamaterials with index ellipsoids at arbitrary k-points [^01be2dad]. Nature Communications (2018). Medium credibility.

Forming closed equifrequency surfaces

The twisting of a single bundle in real space in the z -direction shifts the zero-frequency solution along k z and generates modes with linear dispersion along k z. However, we do not have a closed equifrequency surface, which requires a three-dimensional (3D) periodic structure. As such, we construct a 3D wire metamaterial by arranging helical wire – bundles in a two-dimensional (2D) hexagonal lattice with a lattice constant of a in the x – y plane as shown in Fig. 3a. The calculated band structure is shown in Fig. 3e. As expected, this bundle array supports quasistatic modes locating atfor m = ± 1, ± 2, ± 3. In the vicinity of, linear bands emerges along the Γ - A direction as shown in Fig. 3e. Their group velocities are plotted in Fig. 3g by black dotted lines, which are almost the same as that of a single bundle in Fig. 2c (colored lines in Fig. 3g). There is weak coupling between neighboring bundles since the eigenfields of the quasistatic modes localize strongly between the wires of the same bundle. The group velocities of m = ± 1 mode deviates from the single bundle case more than that of m = ± 2, ± 3, because the quasistatic mode with smaller m decays more slowly according to Eq. (3). Due to the weak coupling, the dispersion is nearly flat in the k x – k y plane for any value of k z. In other words, the band dispersions along the k z direction are almost independent of k x and k y (see Supplementary Note 4 and Supplementary Fig. 3). Similar flat equifrequency surfaces have been found in 2D wire arrays, which can be used for subwavelength imaging. Apart from the linear bands emerging at(m = ± 1, ± 2, ± 3), two linear bands emerge from the Γ point (the lowest two bands from k z = 0 to k z = 0.1 π / d), whose eigenfields resemble the plane-wave solutions with circular polarization (see Supplementary Fig. 4). As a chiral hyperbolic medium, its equifrequency surface consists of an ellipse and two flat sheets centered at the Γ point (see Fig. 3i for equifrequency surfaces at frequency 0.02 c / d). The other 10 flat sheets in Fig. 3i stem from the quasistatic modes at(m = ± 1, ± 2, ± 3).

---

### A multi-step model of Parkinson's disease pathogenesis [^e2cef97a]. Movement Disorders (2021). Medium credibility.

Box 1
Armitage and Doll Multistep Model – Heuristic Argument*

If disease development depends on one step, incidence in a given year will be proportional to the chance of undergoing that step:If two‐steps are required, then incidence is the product of the chance of undergoing the first step by age t and the rate of undergoing the second step:And for n‐steps:Taking log of both sides returns the equation for a straight line:The slope is one less than the number of steps required to develop the disease, and the intercept represents the combined probability of undergoing these steps.

*see Webster 2019 for full derivation.

A multistep model of pathogenesis could account for many of the epidemiological observations made in PD. These include the variability in the expression of disease and age of onset in carriers of disease‐causing mutations, and the multiple environmental and genetic associations that confer a risk of developing PD. A multistep model could also explain the phenotypic variability seen in PD, if it is assumed that at least some steps apply to specific neuronal populations rather than the nervous system as a whole. Furthermore, the predictions arising from such a model can be used to test specific hypotheses about basic observations in PD, such as whether the higher incidence and prevalence of PD in males observed in most parts of the world relates to differential environmental exposures by sex.

---

### The virtual cone: a novel technique to generate spherical dose distributions using a multileaf collimator and standardized control-point sequence for small target radiation surgery [^12a7bbaa]. Advances in Radiation Oncology (2018). Low credibility.

Results

Volumes and the equivalent sphere diameters calculated by the treatment planning system for 50%, 25%, and 10% of the maximum dose are shown in Table 1. The mean ratio of the film-to-calculated dose (defined as the ratio of the mean dose inside the 50% area of the calculation) obtained from the 3 coronal plan films was 0.99 (range, 0.96–1.01), 1.03 (range, 1.02–1.04), and 1.05 (range, 1.03–1.07) for the 1.6, 2.1, and 2.6 mm leaf gaps, respectively. The mean offset between the measured and calculated dose distributions in the film plane was 0.3 mm.

Table 1
Volumes and equivalent diameters calculated by the treatment planning system for 50%, 25%, and 10% of the maximum dose

Profiles normalized by the film-to-calculated dose ratio and shifted by the offset are shown in Figure 2 for the 2.1 mm leaf gap and the 4 mm and 5 mm cones. The equivalent diameters of the 50% and 25% isodose areas in the 3 planes for measured and calculated dose distributions are provided in Table 2. The treatment planning system underestimated the diameter of the 50% isodose line by 0.3, 0.2, and 0.1 mm and of the 25% isodose line by 0.8, 0.5, and 0.3 mm for the 1.6, 2.1, and 2.6 mm leaf gaps, respectively. Profiles for the 2.1 mm leaf gap are shown with the treatment planning system calculation in Figure 3.

---

### Spin dephasing under nonlinear gradients: implications for imaging and field mapping [^eaf2803c]. Magnetic Resonance in Medicine (2012). Low credibility.

This work examines the prototypical MR echo that would be expected for a voxel of spins evolving in a strong nonlinear field, specifically focusing on the quadratic z² − ½(x² + y²) field. Dephasing under nonlinear gradients is increasingly relevant given the growing interest in nonlinear imaging, and here, we report several notable differences from the linear case. Most notably, in addition to signal loss, intravoxel dephasing under gradients creating a wide and asymmetric frequency distribution across the voxel can cause skewed and nonlinear phase evolution. After presenting the qualitative and analytical origins of this difference, we experimentally demonstrate that neglecting these dynamics can lead to significant errors in sequences that assume phase evolution is proportional to voxel frequency, such as those used for field mapping. Finally, simplifying approximations to the signal equations are presented, which not only provide more intuitive forms of the exact expression but also result in simple rules to predict key features of the nonlinear evolution.

---

### J-shapedness: an often missed, often miscalculated relation: the example of weight and mortality [^9e991138]. Journal of Epidemiology and Community Health (2014). Low credibility.

We present three considerations in analysing the association between weight and mortality, as well as other relations that might be non-linear in nature. First, authors must graphically plot their independent and dependent variables in a continuous manner. Second, authors should assess the shape of that relation, and note its shape. If it is non-linear, and specifically, J-shaped or U-shaped, careful consideration should be given to using the 'best' statistical model, of which multivariate fractional polynomial regression is a reasonable choice. Authors should also refrain from truncating their data to avoid dealing with non-linear relations.

---

### The making of the standard model [^0fc9a4ce]. Nature (2007). Excellent credibility.

A seemingly temporary solution to almost a century of questions has become one of physics' greatest successes.

---

### Nuclear fission modes and fragment mass asymmetries in a five-dimensional deformation space [^6c6f5020]. Nature (2001). Excellent credibility.

Nuclei undergoing fission can be described by a multi-dimensional potential-energy surface that guides the nuclear shape evolution — from the ground state, through intermediate saddle points and finally to the configurations of separated fission fragments. Until now, calculations have lacked adequate exploration of the shape parameterization of sufficient dimensionality to yield features in the potential-energy surface (such as multiple minima, valleys, saddle points and ridges) that correspond to characteristic observables of the fission process. Here we calculate and analyse five-dimensional potential-energy landscapes based on a grid of 2,610,885 deformation points. We find that observed fission features — such as the distributions of fission fragment mass and kinetic energy, and the different energy thresholds for symmetric and asymmetric fission — are very closely related to topological features in the calculated five-dimensional energy landscapes.

---

### Optimal placement for needle electromyography of the supinator muscle: cadaveric studies [^0aab884b]. Muscle & Nerve (2022). Medium credibility.

Introduction/Aims

The existing methods for needle electromyography are confusing as to which is the safest and most effective. Our aim was to identify the optimal and safest needle electromyographic insertion site in the supinator muscle.

Methods

We performed a two-step cadaveric dissection of the supinator muscle and related neurovascular structures. The study was performed using 18 upper limbs of 9 fresh adult cadavers (step 1) and 14 upper limbs of 7 fresh adult cadavers (step 2). In step 1, an imaginary line connecting the radial head (RH) and midpoint of the dorsal wrist (RW line) was drawn, and the distance from the RH to the point where the RW line and posterior interosseous nerve (PIN) intersect (L_CROSS) was measured on the RW line. In step 2, the needle was inserted 30mm distal to the RH according to the results of step 1. After injection with India ink, dissection was performed to measure the distance between the needle insertion site and PIN (L_CROSS_Inj) on the RW line.

Results

The median L_CROSS was 51.4 (35.5–65.6) mm. Needle insertion spared the PIN in all cases during step 2, and the needle was inserted into the supinator muscle in all cases. The median L_CROSS_Inj was 27.4 (13.2–39.8) mm.

Discussion

A safe and accurate needle insertion site for the supinator muscle is approximately 30 to 40mm distal to the RH along the RW line.

---

### Suppressing high-dimensional crystallographic defects for ultra-scaled DNA arrays [^78b0d03c]. Nature Communications (2022). High credibility.

Correlation between crystallographic defects and line pitch

By programming the widths of the repeating unit cells, we demonstrated DNA lines with larger line pitches along x direction (Fig. 2). Within each pattern, we kept identical DNA line module on top (i.e. 3 helices × 4 helices × 94 basepairs along the x-y-z directions, Fig. 2a, d). In the bottom DNA substrates modules, 6 helices × 4 helices × 94 basepairs, and 8 helices × 4 helices × 94 basepairs were used for the designed line pitches of 12.6 nm and 16.8 nm (namely 12-3w4h and 16-3w4h, respectively, calculated from 2.1 nm diameter per dehydrated DNA helix), respectively.

Using identical assembly approach to that of 8-3w4h, we assembled the designer DNA lines with larger pitches. Both the leaf-like morphologies and the pattern dimension distributions were similar to those of 8-3w4h (Supplementary Figs. 2 and 3). For the correctly assembled patterns (Fig. 2b, e), the line pitches were measured as 11.5 nm ± 0.4 nm in 12-3w4h and 15.3 nm ± 0.7 nm in 16-3w4h (100–200 DNA lines were counted, Supplementary Fig. 11 and Table 1) along x direction. While the line widths were similar (6.6 nm ± 0.2 nm in 12-3w4h and 6.9 nm ± 0.3 nm in 16-3w4h), the spacing values between neighboring lines were increased from 4.9 nm in 12-3w4h to 8.4 nm in 16-3w4h.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^8992bf26]. Annals of the American Thoracic Society (2023). High credibility.

Quantitative imaging metrics — common sources of systematic errors in imaging and analysis include six categories with representative examples: technical issues during acquisition (differences in hardware and software, acquisition protocol, signal-to-noise ratio, and resolution), biased sampling of structure for analysis (comparison of mismatched airways), failure to define an appropriate reference space, issues with segmentation or registration, inaccurate assumptions or simplifications (assuming alveolar airspaces are spheres), and failure to consider spatiotemporal and biological heterogeneity (anatomical or gravitational gradients in tissue density, ventilation, and perfusion).

---

### FAT1-weighted MRI-guided focused ultrasound thalamotomy for essential tremor [^34ccf176]. BMJ Neurology Open (2025). High credibility.

Lesion characteristics

Lesions were visualised on both intraoperative T2-FR-FSE and at 6 months follow-up on T2-SPACE and FAT1 scans (figure 1). All lesions converged on the Vim as visualised on cohort average FAT1 template (figure 3), in line with the surgical targeting strategy. Cohort average volumes at baseline and follow-up were 134.0 ± 40.6 mm 3 and 67.0 ± 24.4 mm, 3 respectively. Mean coordinates of the lesion centres based on the mid-commissure point were as follows: lateral 14.5 ± 1.0, posterior 5.9 ± 0.8 and superior 1.9 ± 0.4 mm (online supplemental table 1). Poorer outcomes in patients 1, 3 and 8 are not explained by lesion volume and location alone. The lesion volumes (61.0, 63.0 and 61.0 mm 3 at 6 months) did not differ significantly from the cohort mean lesion volume (z < −0.25). Similarly, lesion centroid coordinates from all of these patients, apart from Z coordinates for patient 8, did not differ significantly from cohort mean values (X: z < ± 0.6, Y: z < ± 1.0, Z: z = −0.5 for patients 1 and 3, z > 2.25 for patient 8; online supplemental table 1).

Figure 3
Cohort lesion frequency map. Cohort patient frequency map, or N-map, showing the overlap of MRgFUS lesion locations across the cohort, with greatest frequency, that is, overlap of every patient in the cohort (n = 14), in bright orange, and minimum frequency (n = 1) in dark orange, overlayed onto cohort average FAT1 template. MRgFUS, Magnetic resonance-guided focused ultrasound.

---

### Image distortion correction in EPI: comparison of field mapping with point spread function mapping [^e1f5d953]. Magnetic Resonance in Medicine (2002). Low credibility.

Echo-planar imaging (EPI) can provide rapid imaging by acquiring a complete k-space data set in a single acquisition. However, this approach suffers from distortion effects in geometry and intensity, resulting in poor image quality. The distortions, caused primarily by field inhomogeneities, lead to intensity loss and voxel shifts, the latter of which are particularly severe in the phase-encode direction. Two promising approaches to correct the distortion in EPI are field mapping and point spread function (PSF) mapping. The field mapping method measures the field distortions and translates these into voxel shifts, which can be used to assign image intensities to the correct voxel locations. The PSF approach uses acquisitions with additional phase-encoding gradients applied in the x, y, and/or z directions to map the 1D, 2D, or 3D PSF of each voxel. These PSFs encode the spatial information about the distortion and the overall distribution of intensities from a single voxel. The measured image is the convolution of the undistorted density and the PSF. Measuring the PSF allows the distortion in geometry and intensity to be corrected. This work compares the efficacy of these methods with equal time allowed for field mapping and PSF mapping.

---

### 3D atomic structure from a single X-ray free electron laser pulse [^d0199ca7]. Nature Communications (2024). High credibility.

Experimental setup

We have developed the experimental procedure for x-ray holography for many years at synchrotron sources and could reach measuring times in the range of 1 s for a statistically meaningful pattern. Kossel line pattern measurements require a very similar setup as inside source holography. except the spatial resolution of the 2D detector used for parallel detection of the fluorescent intensity forming the Kossel lines or the hologram. The short measuring time of holograms and Kossel lines at synchrotronsprompted us to try the measurement of Kossel lines at XFEL sources. We realized the possibility of collecting a pattern during a single pulse. Starting from intensity considerations only, this conclusion seems trivial, since in the probe beam at a synchrotron we have about the same number of photons during 1 s as we have in a single XFEL pulse. However, the collection of all these photons in the very short time of an XFEL pulse with the precision necessary for distinguishing the lines from the background is not straightforward. The reason is that the detectors used at synchrotrons are counting detectors, while their XFEL counterparts are charge-integrating detectors. We have already experienced at synchrotrons that the detector is the weak point in the measurement. Since at XFEL-s, the detector problem is even more pronounced, we tried to optimize all other experimental conditions for this demonstration experiment. First, we used samples (GaAs, GaP) from which we already collected good Kossel patterns or expected good-quality patterns. This allows us to check and strengthen the validity of XFEL measurements. Second, we choose the incident energy (10.5 keV) to excite only one element of the sample (Ga), increasing this way the signal to background ratio. Third, the sample was placed in He atmosphere in order to decrease air scattering. Unfortunately, we could not optimize two more parameters, the sample thickness and the experimental geometry. In the experiment, we used 100 micron thick samples in transmission geometry (Fig. 2 top left). None of the reflection geometries (Fig. 2 top right) were available due to technical limitations and the sample was thicker than the optimal 20–30 microns. Higher intensities obtained from thinner samples or in reflection geometry would cause saturation and malfunction of the detector. The implemented forward transmission arrangement (Fig. 2 bottom photo) yielded about 20/120 and 200/800 fluorescent photons/pixel/pulse at the edges/center of the 4 M Jungfrau detectorplaced at 120 mm from the sample for GaAs and GaP, respectively. Due to the mismatch between the detector speed and the intra-train pulse repetition rate only a single pulse was used from each train, namely data was acquired at 10 Hz. The spot size on the sample was set by compound refractive lenses to ~25 μm diameter. In one shot we had about 1 mJ total energy. Since pulses have different total energies because of the stochastic nature of the spontaneous emission, we took several shots, every shot at a new place of the sample to avoid the effect of radiation damage. With these beam parameters, we do not expect distortion of the Kossel lines caused by radiation damage. The radiation damage and possible nonlinear effects are discussed in more detail in the Supplementary Information file Supplementary Note 2. The sample motion was controlled by a fast x-y scanner, while the sample surface was checked by an optical microscope. Good shots were selected by visual inspection and statistical analysis of the recorded detector images later in the evaluation process.

---

### Point singularity array with metasurfaces [^7b75dc33]. Nature Communications (2023). High credibility.

Fig. 2
Comparison between two methods of producing 0D singularities: intensity minimization and phase gradient maximization.

Only field behavior along the optic axis (z axis) is shown for simplicity. a Real (E r) and imaginary (E i) parts of scalar field E in the vicinity of a low intensity position with minimum intensity ϵ. Intensity minimization at z = 0 does not take the spatial distribution of fields around the low intensity point into account, producing fields with slowly varying E r and E i through the minimum, thereby producing a broad intensity minimum. b On the contrary, since phase gradient maximization at z = 0 simultaneously minimizes the intensity there and maximizes the field slopespassing through that point, the resultant intensity minimum is narrow. c The phase gradient peak through z = 0 for the field in (a) produced by intensity minimization there is typically much lower than that of phase gradient maximization, as depicted in (d), which plots the phase gradient for the field in (b).

---

### Deep brain stimulation for arm tremor: a randomized trial comparing two targets [^105aa4d9]. Annals of Neurology (2022). Medium credibility.

FIGURE 4
Active contact location of individual patients in each randomized period and at one‐year follow‐up. Left hemisphere is shown anatomically, but all contacts are shown, with those in the right hemisphere projected onto the left hemisphere. Upper panels: coronal plane, lower panels: sagittal plane. Panels A and C show the location of each patient's active contact used in the VIM treatment period (red dots) and PSA period (light blue dots); panels B and D show the active contact used at the one‐year follow‐up (pink dots). The mean (standard deviation) AC‐PC‐based coordinates for the active contacts were in the left/right hemispheres for the VIM period: X (mm lateral to the ICL‐line) = 13.29(1.45)/−13.10 (1.32), Y (mm anterior–posterior relative to MCP) = −4.74(1.83)/−4.85 (1.51), Z (mm superior/inferior to the ICL‐plane) = −0.25(1.67)/−0.24(1.44); for the PSA period: X = 12.25(1.37)/−11.90(1.13), Y = −6.58(1.52)/−6.88(1.20), Z = −3.02 (1.40)/−3.04(1.32). Coordinates in the MNI‐space were in the left/right hemispheres for the VIM‐period: X = 12.47 (1.21)/12.65 (1.11), Y = −15.28 (2.28)/−16.43(1.84), Z = −3.22 (1.71)/−3.15 (1.84); for the PSA‐period: X = −12.05 (1.20)/11.95 (0.93), Y = −17.64 (1.74)/−18.54 (1.35), Z = −5.61 (1.61)/−5.94 (1.53). AC, anterior commissure; MCP, mid‐commissural point; MNI, Montreal Neurological Institute; PC, posterior commissure; PSA, posterior subthalamic area; VIM, ventral intermediate nucleus.

---

### Recommendations for a standardized pulmonary function report. An official American Thoracic Society technical statement [^d6d8fcbc]. American Journal of Respiratory and Critical Care Medicine (2017). Medium credibility.

Spirometry reporting specifies that numerical values are given for the FEV1, the FVC, and the FEV1/FVC ratio; the latter should be reported as a decimal fraction and the space for percent predicted value left blank, and if bronchodilators are given the LLN column need not be repeated with absolute and percent change given only for FEV1 and FVC. Other numerical values such as the forced inspiratory flow at 75% of FVC (FEF75%) and FEF25–75% are not recommended for routine use. Graph requirements include that for the volume–time curve the volume scale should be at least 10 mm/L, the time scale at least 20 mm/s, and 1 second prior to the start of expiration should be displayed; on the flow–volume plot the flow display should be at least 5 l/min/L/s, and the ratio of flow to volume should be 2 L/s to 1 L, and linear and log scales where values are plotted as z-scores relative to the predicted value (z = 0) give an intuitive sense of severity.

---

### The XZZX surface code [^8f6ac9c8]. Nature Communications (2021). High credibility.

This structured noise model thus leads to two distinct regimes, depending on which failure process is dominant. In the first regime where, we expect that the logical failure rate will decay like. We find this behaviour with systems of a finite size and at high bias where error rates are near to threshold. We evaluate logical failure rates using numerical simulations to demonstrate the behavior that characterises this regime; see Fig. 6 (a). Our data show good agreement with the scaling ansatz. In contrast, our data are not well described by a scaling.

Fig. 6
Sub-threshold scaling of the logical failure rate with the XZZX code.

a Logical failure rateat high bias near to threshold plotted as a function of code distance d. We use a lattice with coprime dimensions d × (d + 1) for d ∈ {7, 9, 11, 13, 15} at bias η = 300, assuming ideal measurements. The data were collected usingiterations of Monte-Carlo (MC) samples for each physical rate sampled and for each lattice dimension used. The physical error rates used are, from the bottom to the top curves in the main plot, p = 0.19, 0.20, 0.21, 0.22 and 0.23. Error bars represent one standard deviation for the Monte-Carlo simulations. The solid lines are a fit of the data to, consistent with Eq. (2), and the dashed lines a fit to, consistent with Eq. (3) where we would expect, see Methods. The data fit the former very well; for the latter, the gradients of the best fit dashed lines, as shown on the inset plot as a function of, give a linear slope of 0.61(3). Because this slope exceeds the value of 0.5, we conclude that the sub-threshold scaling is not consistent with. b Logical failure ratesat modest bias far below threshold plotted as a function of the physical error rate p. The data (markers) were collected at bias η = 3 and coprime d × (d + 1) code dimensions of d ∈ {5, 7, 9, 11, 13, 15} assuming ideal measurements. Data is collected using the Metropolis algorithm and splitting method presented in refs. The solid lines represent the prediction of Eq. (3). The data show very good agreement with the single parameter fitting for all system sizes as p tends to zero.

---

### Gravitationally redshifted absorption lines in the X-ray burst spectra of a neutron star [^b4654ece]. Nature (2002). Excellent credibility.

The fundamental properties of neutron stars provide a direct test of the equation of state of cold nuclear matter, a relationship between pressure and density that is determined by the physics of the strong interactions between the particles that constitute the star. The most straightforward method of determining these properties is by measuring the gravitational redshift of spectral lines produced in the neutron star photosphere. The equation of state implies a mass-radius relation, while a measurement of the gravitational redshift at the surface of a neutron star provides a direct constraint on the mass-to-radius ratio. Here we report the discovery of significant absorption lines in the spectra of 28 bursts of the low-mass X-ray binary EXO0748-676. We identify the most significant features with the Fe XXVI and XXV n = 2–3 and O VIII n = 1–2 transitions, all with a redshift of z = 0.35, identical within small uncertainties for the respective transitions. For an astrophysically plausible range of masses (M approximately 1.3–2.0 solar masses; refs 2–5), this value is completely consistent with models of neutron stars composed of normal nuclear matter, while it excludes some models in which the neutron stars are made of more exotic matter.

---

### Theory of optical responses in clean multi-band superconductors [^5e35553c]. Nature Communications (2021). High credibility.

Table 2
Properties of time-reversal-symmetric constant pairing functions in a 2D model of FeSe at Γ.

Here,… The second column shows the result of transformationby g = m x, m y, m z or c 4 z. The signs + and − mean +Δ and −Δ, respectively.

Fig. 3
Optical conductivity in a model of superconducting FeSe near Γ at zero temperature.

Model parameters in the normal state are adapted from ref.(see section 6 in the Methods). The x x and y y components of the conductivity tensor is shown in red and blue, respectively, in (a – d, f, g). a – d Nonzero intrinsic optical conductivity tensors for each constant pairing function. See Methods and Table 2 for the matrix form and symmetries of the six constant pairing functions Δ 1 –Δ 4 a, Δ 4 b, and Δ 5. The case of the Δ 1 pairing is not shown as the conductivity is identically zero. e Superconducting gap similar to the experimentally observed gap. FS and the ellipse enclosing it represent the Fermi surface. Red and blue curves correspond to the choice of pairing functions (i) Δ 1 = 4.09 meV, Δ 2 = 4.82 meV, and Δ 3 = 1.93 meV or (ii) Δ 1 = 8.98 meV, Δ 2 = 9.39 meV, and Δ 3 = 0 meV, respectively. They are least-square fits with and without Δ 3 to(shown as a black curve) that was obtained in ref.from experimental data. f, g Conductivity with pairing functions used in (e). σ int is the internal optical conductivity in the superconducting state (solid lines), and σ n is the Drude conductivity in the normal state (dashed lines). The disorder-mediated conductivity in the superconducting state is expected to be comparable to σ n. h Ratio of σ int and σ n. Red and blue curves are for parameters in (f), and magenta and cyan are for parameters in (g). x x and y y indicate the component of the conductivity tensor. σ x y and σ y x are not shown in all plots because they vanish due to M x symmetry.

---

### Fundamental limits to learning closed-form mathematical models from data [^5954e9c9]. Nature Communications (2023). High credibility.

Fig. 1
Probabilistic model selection makes quasi-optimal predictions about unobserved data.

We select two models m *, whose expressions are shown at the top of each column. a, b From each model, we generate synthetic datasets D with N points (shown, N = 100) and different levels of noise s ϵ (shown, s ϵ = 1). Here and throughout the article, the values of the independent variables x 1 and x 2 are generated uniformly at random in [− 2, 2]. Vertical lines show the observation error ϵ i for each point in D. For a model not drawn from the prior and data generated differently, see Supplementary Fig. S1. c, d For each dataset D (with dataset sizes N ∈ {25, 50, 100, 200, 400}), we sample models from p (m ∣ D) using the Bayesian machine scientist, select the MDL model (maximum p (m ∣ D)) among those sampled, and use this model to make predictions on a test dataset, generated exactly as D. We show the prediction root mean squared error (RMSE) of the MDL model onas a function of N and s ϵ. For comparison, we also show the predictions from an artificial neural network (ANN, dotted lines; Methods). Since s ϵ is the irreducible error, predictions on the diagonal RMSE = s ϵ are optimal. e, f We plot the prediction RMSE scaled by the irreducible error s ϵ; optimal predictions satisfy RMSE/ s ϵ = 1 (dashed line).

---

### A magnetic reconnection X-line extending more than 390 earth radii in the solar wind [^5527412a]. Nature (2006). Excellent credibility.

Magnetic reconnection in a current sheet converts magnetic energy into particle energy, a process that is important in many laboratory, space and astrophysical contexts. It is not known at present whether reconnection is fundamentally a process that can occur over an extended region in space or whether it is patchy and unpredictable in nature. Frequent reports of small-scale flux ropes and flow channels associated with reconnection in the Earth's magnetosphere raise the possibility that reconnection is intrinsically patchy, with each reconnection X-line (the line along which oppositely directed magnetic field lines reconnect) extending at most a few Earth radii (R(E)), even though the associated current sheets span many tens or hundreds of R(E). Here we report three-spacecraft observations of accelerated flow associated with reconnection in a current sheet embedded in the solar wind flow, where the reconnection X-line extended at least 390R(E) (or 2.5 x 10(6) km). Observations of this and 27 similar events imply that reconnection is fundamentally a large-scale process. Patchy reconnection observed in the Earth's magnetosphere is therefore likely to be a geophysical effect associated with fluctuating boundary conditions, rather than a fundamental property of reconnection. Our observations also reveal, surprisingly, that reconnection can operate in a quasi-steady-state manner even when undriven by the external flow.

---

### Raising the joint line in TKA is associated with mid-flexion laxity: a study in cadaver knees [^1f8b292b]. Clinical Orthopaedics and Related Research (2018). Low credibility.

Background

In a typical osteoarthritic knee with varus deformity, distal femoral resection based off the worn medial femoral condyle may result in an elevated joint line. In a setting of fixed flexion contracture, the surgeon may choose to resect additional distal femur to obtain extension, thus purposefully raising the joint line. However, the biomechanical effect of raising the joint line is not well recognized.

Questions/Purposes

(1) What is the effect of the level of the medial joint line (restored versus raised) on coronal plane stability of a TKA? (2) Does coronal alignment technique (mechanical axis versus kinematic technique) affect coronal plane stability of the knee? (3) Can the effect of medial joint-line elevation on coronal plane laxity be predicted by an analytical model?

Methods

A TKA prosthesis was implanted in 10 fresh frozen nonarthritic cadaveric knees with restoration of the medial joint line at its original level (TKA0). Coronal plane stability was measured at 0°, 30°, 60°, 90°, and 120° flexion using a navigation system while applying an instrumented 9.8-Nm varus and valgus force moment. The joint line then was raised in two steps by recutting the distal and posterior femur by an extra 2 mm (TKA2) and 4 mm (TKA4), downsizing the femoral component and, respectively, adding a 2- and a 4-mm thicker insert. This was done with meticulous protection of the ligaments to avoid damage. Second, a simplified two-dimensional analytical model of the superficial medial collateral ligament (MCL) length based on a single flexion-extension axis was developed. The effect of raising the joint line on the length of the superficial MCL was simulated.

Results

Despite that at 0° (2.2° ± 1.5° versus 2.3° ± 1.1° versus 2.5° ± 1.1°; p = 0.85) and 90° (7.5° ± 1.9° versus 9.0° ± 3.1° versus 9.0° ± 3.5°; p = 0.66), there was no difference in coronal plane laxity between the TKA0, TKA2, and TKA4 positions, increased laxity at 30° (4.8° ± 1.9° versus 7.9° ± 2.3° versus 10.2° ± 2.0°; p < 0.001) and 60° (5.7° ± 2.7° versus 8.8° ± 2.9° versus 11.3° ± 2.9°; p < 0.001) was observed when the medial joint line was raised 2 and 4 mm. At 30°, this corresponds to an average increase of 64% (3.1°; p < 0.01) in mid-flexion laxity with a 2-mm raised joint line and a 111% (5.4°; p < 0.01) increase with a 4-mm raised joint line compared with the 9-mm baseline resection. No differences in coronal alignment were found between the knees implanted with kinematic alignment versus mechanical alignment at any flexion angle. The analytical model was consistent with the cadaveric findings and showed lengthening of the superficial MCL in mid-flexion.

Conclusions

Despite a well-balanced knee in full extension and at 90° flexion, increased mid-flexion laxity in the coronal plane was evident in the specimens where the joint line was raised.

Clinical Relevance

When recutting the distal and posterior femur and downsizing the femoral component, surgeons should be aware that this action might increase the laxity in mid-flexion, even if the knee is stable at 0° and 90°.

---

### Harnessing many-body spin environment for long coherence storage and high-fidelity single-shot qubit readout [^3a3f7e8b]. Nature Communications (2022). High credibility.

Fig. 3
Single-shot NMR detection of the electron spin state.

a Spin echo of 75 As nuclei in a t B = 37 nm sample at B z ≈ 7.8 T measured with a single-shot optical detection of the resulting hyperfine shift variation Δ E hf. Measurement rf pulse sequence is (π /2) x − (τ evol /2) − (π) x − (τ evol /2) − (π /2) x with several values of the total free evolution time τ evol = 0.4 − 1300 μs shown. Results are plotted as histograms of the detected single-shot spin echo amplitudes Δ E hf. Lines show double Gaussian fits. Schematic shows electron spin in an s_z = +1/2 or −1/2 states (balls with up or down arrows). After the initial (π /2) x pulse all nuclear spins point along the same axis orthogonal to z (dashed small arrow) and then precess around the z axis to point along generally different directions (solid small arrows) prior to the final (π /2) x pulse: An electron spin-flip during the nuclear spin precession dephases the spins, resulting in Δ E hf ≈ 0, whereas in the absence of electron flips, nuclear spin echo is formed, resulting in Δ E hf ≈ 1.9 μeV. b Single-shot measurement of the free induction decay in an empty QD (0 e), using sequence (π /2) x − (τ evol) − (π /2) y, where subscripts x, y denote the equatorial axes in the rotating frame towards which the spins are flipped by the rf pulses. Line shows Gaussian fit. c Same sequence as in (b) applied to a charged QD (1 e). For a sufficiently short evolution timethe spin s_z = −1/2 (s_z = +1/2) of a single-electron pointing down (up) gives rise to a negative (positive) quadruature nuclear spin polarization Δ E hf, observed as a bimodal distribution of the single-shot-detected Δ E hf. Lines show double Gaussian fits.

---

### Glycemic deviation index: a novel method of integrating glycemic numerical value and variability [^cedf5e7c]. BMC Endocrine Disorders (2021). Medium credibility.

The functional form of y₁ should meet the exponential increase of the x value at a certain symmetrical point. To ensure that y 1 satisfies the following two criteria: 1) the value range of x is symmetrical around a certain point, 2) the target range of x is also symmetrical around this point; the following equation was constructed:

The solution calculated using MATLAB was: a = − 0.801, b = 0.672. Inserting a and b into eq. 1–1 provided:

Furthermore, to adjust the value range to occupy the range of [0,10], and to meet the normal range at [0,1] synchronously, the following formula was introduced (Fig. 1 a):

Fig. 1
Functional images of MGI (a) and SDGI (b). The definitional domain of MGI is [2.8, 33.3], while the definitional domain of SDGI is [0, 7.4]. The value domain of both functions is [0, 10]

Next, to reduce the "neutralization" of hyperglycemia on hypoglycemia, MGI was calculated in two steps. MG 1 and MG 2 represent the average of blood glucose in the hypoglycemic and non-hypoglycemic periods separately, respectively substituted into formula 1–3 for the calculation to be performed. The weighting coefficient "c" was used to indicate duration in the hypoglycemic range (percentage of readings below 3.9 mmol/L per 72 h). The final formula of MGI was as follows:

The target range of SDG in this study was 0–1.4 mmol/L, based on previous studies, and the value range was defined as 0–7.4 mmol/L. The degree of deviation of glycemic variability was represented as the standard deviation of glucose index (SDGI). The SDGI value was exponentially augmented after SDG crossed over the normal threshold (Fig. 1 b). SDGI was listed as follows, where "z" represented the SDG, while "e" and "f" were constant parameters:

---

### Recommendations for noninvasive evaluation of native valvular regurgitation: a report from the American Society of Echocardiography developed in collaboration with the Society for Cardiovascular Magnetic Resonance [^1d043137]. Journal of the American Society of Echocardiography (2017). Medium credibility.

Cardiac magnetic resonance (CMR) phase-contrast flow measurement — technical considerations include setting velocity encoding to the lowest feasible without aliasing; centering the imaging plane in the vessel of interest, aligning it orthogonally to the expected main blood flow direction in two spatial directions, and positioning it at the magnet isocenter; and considering phantom or background correction because eddy current–related phase offset errors can still occur.

---

### Topological transitions among skyrmion-and hedgehog-lattice States in cubic chiral magnets [^a0a694a6]. Nature Communications (2019). High credibility.

SANS and LTEM studies under magnetic fields

Having confirmed the variation of magnetic properties in MnSi 1− x Ge x, we investigated the magnetic structures under magnetic fields by SANS in x = 0.2, 0.6, and 0.8 (as representative compositions of the three magnetic phases), and by LTEM in the thin plate of x = 0.2. Magnetic field (H) is applied perpendicular to the incident neutron beam for SANS experiment (Fig. 3a), while H is applied parallel to the electron beam for LTEM measurement (Fig. 3b). As for x = 0.2, LTEM directly reveals the formation of a hexagonal SkL in the plane perpendicular to H, which is also confirmed by the six-fold Fourier transform image (Fig. 3c).

Fig. 3
Magnetic structures of MnSi 1− x Ge x revealed by small-angle neutron scattering (SANS) and Lorentz transmission electron microscopy (LTEM) under magnetic field. a The SANS setup with magnetic field H perpendicular to the incident neutron beam. b Schematic illustration of LTEM observation with H parallel to the incident electron beam (orange lines), where the blue arrows represent the in-plane magnetic moment configuration of a skyrmion. c The over-focused LTEM image (T = 6 K, μ 0 H = 0.3 T) in (001) crystal plane and its Fourier transform pattern. d – f The SANS measurement points (gray dots) and sequences (blue arrows) are shown in the magnetic phase diagrams of x = 0.2 (d), x = 0.6 (e), and x = 0.8 (f), where the blue stars represent the data points shown in g – i. The SANS intensity patterns of x = 0.2 (T = 25 K, μ 0 H = 0.5 T) (g), x = 0.6 (T = 50 K, μ 0 H = 1 T) (h), and x = 0.8 (T = 2 K, μ 0 H = 3 T) (i). The small white circles emphasize the characteristic peak intensities for each composition. The candidate multiple-q structures explaining the observed SANS intensity patterns are shown in h – l, where the yellow rings represent the rotation degrees of freedom of q -vectors due to randomly oriented crystal domains in the polycrystalline samples and the yellow dots represent the scattering intensities on the detector plane

---

### Smooth 2D manifold extraction from 3D image stack [^f9c6b5cf]. Nature Communications (2017). Medium credibility.

where FFT denotes the fast Fourier transform. A three classes k-means is then performed on those spectral density profiles to roughly identify the three classes: the foreground z-profiles (class with the highest amount of lowest frequency components), the background z-profiles (class with the lowest amount of lowest frequency components) and the uncertain z-profiles (class with intermediate frequency components). This segmentation does not need to be precise as it is not definitive as such but helps driving the final index map towards the foreground. To offer a class-specific control on the relative weight between the regularization term and the data attachment term, a weight C (x, y) is assigned to each z-profile the following way:

The weight 0 is affected to the background class such that the z level for all positions of that class will be determined only by the local curvature and by extension by the local foreground. In the Supplementary Methods and in Supplementary Fig. 4, we show how the weights c F and c U can be set automatically. Intuitively, if the local curvature of the foreground is large in average and the noise level is low, then c F should remain high to preserve the foreground curvature. On the other hand, if the foreground lies on a flattish manifold and the noise level is high, this term should be lower to ensure convergence to a smooth z index map. Hence, an optimal value c F exists and depends both on the curvature of the foreground and the noise level. In the cost function (equation 1), decreasing the first term by a given Δ z for any location (x, y) translates to an increase of Δ σ and conversely. To scale those two terms on the whole image, we seek for a c = Δ σ /Δ z that would smooth the foreground yet preserving its highest local curvature (the distribution of such c on all the voxels of the foreground of an example image is showed in Supplementary Fig. 4b). Taking the maximum value of c would prevent any smoothing of the foreground and would be equivalent to consider that there is no noise. On the other hand, taking its average would ensure that the average curvature is maintained, however some regions of high curvature would be overly smoothed, causing partial loss of details. To choose the best compromise, we make the assumption that the noise follows a Bernoulli process, where a pixel of Z_max(x, y) is either the right z -level value on the foreground, or a wrong random value uniformly distributed over [0, D] due to the fact a random voxel can be selected as the maximum intensity instead of the correct foreground level (with a higher probability when the signal-to-noise ratio is weak). Fortunately, the probability for the latter to happen can be obtained directly from the misclassification of the maximum intensity values in the foreground class as shown in Supplementary Fig. 4a. Following this idea, c F is chosen to be the value of the c distribution that match the probability of false positive of the maximum intensity distribution on the foreground profile. This is described in Supplementary Fig. 4c. Once c F has been computed, the rational is to choose c U between 0 and c F. Intuitively, if the signal to noise is rather low, then it means that a larger fraction of uncertain profiles in fact belong to the background and should be ignored, c U should then be closer to 0. On the opposite, if the signal to noise is rather high, c U should be close to c F. Thus, the correct ratio to apply can be obtained from the relative position of the means of the Z max distributions of foreground, background and uncertain classes as showed in Supplementary Fig. 4c.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^6efded20]. Annals of the American Thoracic Society (2023). High credibility.

Pulmonary vascular metrics — density, tortuosity, and fractal dimension: "Extraction of pulmonary vascular data from imaging data sets can be automated or semiautomated", and "Loss of pulmonary vascular density or distal PA blood volume is associated with right heart failure indices in smokers, emphysema progression, and asthma severity". "Vessel tortuosity can be determined by comparing the linear distance between two points on a vessel with the actual 3D path length", with this "distance metric" increased in pulmonary arterial hypertension and "correlated with mean PA pressure, pulmonary vascular resistance, and arterial and venous oxygen content and saturation". For fractal analysis, "the number of vessel-containing cubes is related to cube size on a double logarithmic plot; fractal dimension is the slope of the linear portion of the plot", or it "can be estimated from CT or MRI perfusion scans by calculating the relative dispersion (standard deviation/ mean)… and evaluating the slope of the relationship between log relative dispersion versus log number of voxels averaged".

---

### Limits on fundamental limits to computation [^98c96d2d]. Nature (2014). Excellent credibility.

An indispensable part of our personal and working lives, computing has also become essential to industries and governments. Steady improvements in computer hardware have been supported by periodic doubling of transistor densities in integrated circuits over the past fifty years. Such Moore scaling now requires ever-increasing efforts, stimulating research in alternative hardware and stirring controversy. To help evaluate emerging technologies and increase our understanding of integrated-circuit scaling, here I review fundamental limits to computation in the areas of manufacturing, energy, physical space, design and verification effort, and algorithms. To outline what is achievable in principle and in practice, I recapitulate how some limits were circumvented, and compare loose and tight limits. Engineering difficulties encountered by emerging technologies may indicate yet unknown limits.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^d6563994]. Annals of the American Thoracic Society (2023). High credibility.

Quantitative imaging (QI) — challenges and sources of error emphasize that advances in QI are crucially dependent on technology and computational power, with massive data sets run through "black box" algorithms and distilled into selected "biomarkers" to evaluate their ability to detect, stratify, and monitor lung disease. Numerous imaging modalities, manufacturers, platforms, and algorithms may not integrate smoothly, and emergent QI metrics vary among centers in the methods of acquisition, quantification, interpretation, and extrapolation; technological advances contribute to difficulty in standardization. Systematic errors may arise at each step of image acquisition, processing, and analysis, including 1) technical issues (e.g., depth of inspiration, acquisition protocol, signal-to-noise ratio, resolution), 2) nonrepresentative sampling of parts of interest (e.g., comparing regions, lobes, or airways), and 3) lack of a well-defined reference space, as well as 4) inaccurate landmark coregistration for evaluating paired images obtained at different lung volumes and 5) failure to consider basic physiology and/or biological or spatiotemporal heterogeneity.

---

### Rigorous location of phase transitions in hard optimization problems [^d98ebea5]. Nature (2005). Excellent credibility.

It is widely believed that for many optimization problems, no algorithm is substantially more efficient than exhaustive search. This means that finding optimal solutions for many practical problems is completely beyond any current or projected computational capacity. To understand the origin of this extreme 'hardness', computer scientists, mathematicians and physicists have been investigating for two decades a connection between computational complexity and phase transitions in random instances of constraint satisfaction problems. Here we present a mathematically rigorous method for locating such phase transitions. Our method works by analysing the distribution of distances between pairs of solutions as constraints are added. By identifying critical behaviour in the evolution of this distribution, we can pinpoint the threshold location for a number of problems, including the two most-studied ones: random k-SAT and random graph colouring. Our results prove that the heuristic predictions of statistical physics in this context are essentially correct. Moreover, we establish that random instances of constraint satisfaction problems have solutions well beyond the reach of any analysed algorithm.

---

### A high-throughput and low-waste viability assay for microbes [^82feecc8]. Nature Microbiology (2023). High credibility.

Image processing

The goal of the image processing was to extract individual pipette tips from the collected images and identify individual colonies. These were broken into two steps performed sequentially. MATLAB (Mathworks, R2022a) was used for all image processing analyses. The app can be used without a MATLAB license using a compiled version (Windows only) or on all OS using the source code.
Pipette tip segmentation. All images from a given field of view were converted to a 16-bit greyscale image. The overall orientation of the image was calculated to ensure that each tip was oriented perpendicular to the x axis. Due to small variations in the tip loading onto the lightbox, this was necessary to accurately calculate the colony distance from the pipette tip. The Hessian (fibermetric.m) of the image was calculated and convoluted with a horizontal line to locate the angle of the tips. The image was then rotated (imrotate.m) by this angle to orient the pipettes vertically in the image. To identify the x pixels corresponding to the pipette tip, the Hessian was again calculated from the rotated image. From the middle of the image, a convolution of a single line at different angles was used to calculate the left and right boundaries of the pipette tip. These lines were then extended to the bottom of the pipette tip to locate the left and right boundaries of the tip.
Semi-automated colony segmentation. Colonies were segmented using a semi-automated custom script in MATLAB. From the extracted image of the pipette tip, the user selected 1 of 5 different segmentation routines corresponding to the varying sizes of colonies in the pipette tip. The first routine segmented the entire pipette tip, while the last segmentation algorithm zoomed into 1/20th of the full tip and segmented the first 30 colonies. Segmentation was done using MATLAB's Image Processing Toolbox. Subsequently, the user could curate the automated segmentation by adding missed colonies or removing erroneous colonies.
The colony count and position of the first and last colonies were used in equations (1) and (2) to calculate the GVA estimate of the CFU.s mL −1. For the error analysis, the factor by which the GVA estimate differed from the correct value was calculated according to: Factor off by = . This approach to error calculation takes into account the large dynamic range of possible CFUs mL −1.

---

### Adaptive resetting for informed search strategies and the design of non-equilibrium steady-states [^cfcebb66]. Nature Communications (2025). High credibility.

Fig. 3
Search with environmental information.

a The mean first-passage time to the origin as a function of r 0 and b for one-dimensional diffusion with diffusion coefficient D = 1. Motion starts at L = 1 and is conducted under position-dependent resetting of the form given in Equation (8). The dashed and dotted lines indicate the optimal rate for diffusion with a constant resetting rate, r 0 = 2.5, and the optimal rate for a parabolic resetting, r 0 = 5.6 b 2, respectively. b First-passage time distributionsfor the three marked points in the phase space of (a), estimated from simulations without resetting (solid lines), and brute-force simulations with resetting (markers). For simulations with resetting, we plot the meanstandard deviation of ten independent repetitions with 10 4 trajectories each (errors are smaller than the marker size in almost all cases).

We emphasize that all the results of Fig. 3 a were obtained using a single set of trajectories with no resetting and simply re-evaluating Equations (4–7) for every value of r 0 and b, leading to a different MFPT through Equation (3). Previously, obtaining the above results would have required performing an ensemble of brute-force simulations at every value of the parameters r 0 and b, to map out the MFPT phase space. This approach would be computationally prohibitive in many cases. Moreover, the strength of our approach becomes even clearer when considering other forms of r (x) apart from Equation (8). Tackling these using brute-force simulations, analytical methods, or experiments, would require a complete reanalysis of the problem. On the other hand, using our method, we can use the same initial ensemble of trajectories to generate the MFPT phase space for any resetting protocol, with minimal added cost. In section 4 of the Supplementary Information, we demonstrate this for several other sigmoidal-shaped resetting protocols (Supplementary Fig. S2).

---

### Modelling the temporal trajectories of human milk components [^a7f977f9]. BMC Pregnancy and Childbirth (2024). Medium credibility.

Fig. 9
Examples for our generic, two-phase saturation model. Broken line: initial phase (colostrum). Continuous line: second (saturation) phase. The alternative of the λ = 0 case (when the parameter a becomes per se insignificant) is λ = 6, with either a < 0, a = 0, or a > 0.000000000000000e+00 Similarly, significance test may show that r can be taken as zero, implying y 0 + aλ = y End

F-test decided whether the full two-phase model with four parameters (y 0, a, r, y End) were needed to describe a dataset, or any of the parameters could be a fixed value, to decrease the dimension of the model. Note that value set of λ was considered binary: it is either 6 (default) or 0. In the latter case, the first phase is embedded in the saturation model, and the result is a single-phase, pure saturation model, with three-parameters. Again, F-test decided if the single-phase pure saturation model was sufficient to fit a particular dataset or the λ = 6 case was significant with a slope a.

Similarly, F-test was used to decide whether one or two of the parameters can be considered identical, for a pair of datasets (e.g. a pair of trajectories, showing the effects of delivery mode; – see Fig. 4).

The secondary model could be used to quantify the effect of various factors, mother history and other characteristics on the fitted parameters (e.g. y End) of the primary model. The non-linear regression algorithm was built in a bespoke Microsoft Excel Add-In, written in Visual Basic, implementing the standard Levenberg–Marquardt method. The Data Analysis Add-In of Excel was used to carry out linear regression and ANOVA procedures, with 5% significance level.

---

### Expanding applications of pulmonary MRI in the clinical evaluation of lung disorders: Fleischner society position paper [^d1036308]. Radiology (2020). High credibility.

Pulmonary MRI pulse sequences — shortening echo time (TE) and zero-TE characteristics: The figure describes a progression toward shorter TE values and defines echo time as the interval between excitation of magnetization and sampling of the central k-space region, noting that hardware switching time can limit minimal TE and that a Δ of 5 μsec might be considered typical. For zero echo time approaches, a central region in k-space cannot be sampled, and comments include properties of zero-TE readouts described as merged RF and read, nearly silent, and missing k-space center.

---

### Regression plane concept for analysing continuous cellular processes with machine learning [^fcaafbe2]. Nature Communications (2021). High credibility.

Active regression

Usually, the most time-consuming part of statistical learning for biomedical applications (including shallow and deep learning) is the procedure of annotation, and – as transfer learning is rarely used – it is often repeated for new experiments. Active learningaims at reducing the number of training samples needed to achieve the most representative training set by automatically proposing cells for annotation. It has previously been shown by Smith and Horvaththat active learning reduces the time cost of annotation in HCS compared to classical labelling. Most of the active classification methods are based solely on the predicted class labels, enabling the underlying model to be freely modified. However, these methods are not directly applicable for regression, as they assume that the predicted label is discrete. Active regression methods were developed by Cohn et al. based on variance reduction for Neural Networks, Mixture of Gaussians and Locally Weighted Regression. Here we present active regression methods inspired by the general active classification approaches, and a specific method for Gaussian Processes utilizing its properties (Supplementary Fig. 1).

Committee members

The Committee Members approach is inspired by the QueryByCommittee active classification method. Similarly to cross-validation, a set of models (committee) is built up from the available training samples, and a measure of disagreement is defined for the committee. In case of regression, the classical measures cannot be applied directly for two reasons: (1) they rely on the fact that the output is discrete, and (2) they require a probabilistic model. Thus, we propose using the quadratic mean of the Euclidean distance between the committee consensus and the single committee predictions. Hence, the next cell to be labelled by the expert is defined by the following formula:where C is the size of the committee, is the predicted position for x (a sample not taken from the TS) by the i th committee member, is the mean of, and d is the Euclidean distance.

Empty regions

The Empty regions method targets the cells which were predicted to the least dense region of the regression plane in terms of training samples. This heuristic is supposed to explore those cell types that are not presented in the TS.

Out of bounds

By design, the regression plane is represented by a unit-square, and has limits in each direction. However, this limitation was not incorporated into the regression models, consequently it is possible that cells are predicted outside of the regression plane's boundaries. Therefore, we propose a strategy that selects these cells for annotation, ranked by their distance from the edges of the regression plane.

---

### Assessing and improving reliability of neighbor embedding methods: a map-continuity perspective [^ab4f01c9]. Nature Communications (2025). High credibility.

LOO-map reveals intrinsic map discontinuities

By analyzing the LOO loss, we identify the two observed discontinuity patterns as a result of the map discontinuities of f (x). We use t-SNE as an example to illustrate the main results.

We generate mixture data by sampling 500 points from two overlapping 2D Gaussian distributions and run t-SNE with two representative choices of perplexity, 5 and 50. The resulting visualizations confirm the two discontinuity patterns (Fig. 3 a). OI discontinuity pushes mixed points to cluster boundaries, creating overly tight structures, while FI discontinuity fragments embeddings into small pieces, leading to many sub-clusters. Similar discontinuity patterns are also common among other neighbor embedding methods (Supplementary Fig. 1).

Fig. 3
LOO loss landscape reveals the origins of two distortion patterns.

a We illustrate two discontinuity patterns on simulated Gaussian mixture data. OI discontinuity: t-SNE embeds points into well-separated clusters and creates visual overconfidence. FI discontinuity: t-SNE with an inappropriate perplexity creates many artificial fractures. b Origin of OI discontinuity: LOO loss contour plot shows distantly separated minima. We add a new input point x at one of the 4 interpolated locations x = t c 1 + (1 − t) c 2 where t ∈ {0, 0.47, 0.48, 1} and then visualize the landscape of the LOO loss L (y; x) using contour plots in the space of y. The middle two plots exhibit two well-separated minima (orange triangle), which cause a huge jump of the embedding point (as the minimizer of the LOO loss) under a small perturbation of x. c Origin of FI discontinuity: We show LOO loss contour plots with interpolation coefficient t ∈ {0.2, 0.4, 0.6, 0.8}. The plots show many local minima and irregular jumps. Under an inappropriate perplexity, the loss landscape is consistently fractured. Numerous local minima cause an uneven trajectory of embedding points (dashed line) when adding x at evenly interpolated locations. Source data are provided as a Source Data file.

---

### Coherent movement of error-prone individuals through mechanical coupling [^5d974ae9]. Nature Communications (2023). High credibility.

Two snapshots showing the start and end of a typical experimental run are superimposed. The dotted lines indicate the start and finish lines, which are placed at a distance of 120 cm from each other. At the beginning of each trial, the Kilobot Soft Robot is positioned such that its Centre of Mass (CoM), computed as the average position of all modules composing the robot and indicated with a yellow star, is in the vertical centre of the start line. The Kilobot Soft Robot is oriented in parallel to the x-axis to directly face the finish line (on the right). It is tasked to move forward. It is not provided with any external feedback and does not perceive any cues related to the trajectory. In this sense, the robot is assessed in open-loop control. However, the modules estimate the relative positions among each other, and act accordingly.

We conduct experiments with robots of seven sizes, S ∈ {1 × 1, 2 × 2, …, 7 × 7}. For each size, 10 trials are performed, that is, 70 trials in total. Each trial is run for a fixed duration T = 800 s, which we chose by doubling the expected time for successful completion (in the absence of any faults) which was established through preliminary tests. If the robot (its CoM) reaches the finish line, the trial is considered successful and stopped. Otherwise, the trial is considered unsuccessful.

Only 40% and 30% of trials were successful for the 1 × 1 and 2 × 2 Kilobot Soft Robots, respectively, whereas 80% of trials were successful for the 3 × 3 Kilobot Robots. For Kilobot Soft Robots of larger size (4 × 4 to 7 × 7), 90% of trials were successful. Hence, a clear trend can be observed (see Table S1 in Supplementary Information).

---

### Progression of coronary artery calcification seems to be inevitable, but predictable-results of the Heinz nixdorf recall (HNR) study [^b9e09a1c]. European Heart Journal (2014). Low credibility.

Statistical analysis

Continuous data were depicted as means ± SD, and in the case of substantially skewed distribution also as median (Q1, Q3); count data as frequency and percentage. Demographics and risk factors at baseline (b) and after 5 years (5y) were given in quartiles/upper deciles of CAC b and CAC 5y, respectively. To evaluate the relationship between CAC groups and continuous data, we used a Spearman correlation test for trend with CAC groups, and for count data a Cochran–Armitage test for trend.

In a first step, age- and sex-related percentiles of CAC distribution for baseline and 5-year follow-up data were analysed. Previously, we had shown that the graphical presentation of percentiles such as the 50th, 75th, and 90th percentiles calculated from linear quantile regression of log(CAC + 1) on age showed an exponential curvature during ageing. This reflects the natural history of CAC with a progression of CAC proportional to the given CAC b value.

To prove that also the CAC progression for individual participants follow such an exponential curvature of CAC distribution, we developed a new mathematical tool (Figure 1). Therefore, we performed a linear quantile regression analysis from the baseline data set of the form log(CAC b + 1) = I + β ·age in 0.05 quantile steps, starting at 0.025 up to 0.975 getting a total of 20 quantiles. Each step yields an intercept (I) and a slope parameter (β), which is demonstrated in Figure 1 for the 50th, 75th, and 90th percentiles. To interpolate between these straight lines, both I and β were fitted as functions of quantile (Q) using quadratic equations (see). In short, to determine a subject's percentile at baseline in two steps, we first identified the percentile (resolution 5%) pertaining to the straight line fit I + β ·age, which is closest to the subject's coordinates (determined by age, gender, and CAC b). Second we refined, by selecting the solution of the respective quadratic equation which is closest to the first, the coarse-grained prediction.

---

### National Lipid Association recommendations for patient-centered management of dyslipidemia: part 1 – full report [^1f3166b0]. Journal of Clinical Lipidology (2015). Medium credibility.

Usefulness of treatment goals — evidence base notes that most RCTs of lipid-lowering drug therapies have tested drug treatment against a placebo control or compared more intensive with less-intensive regimens, and the strategy of treating patients to a specific level of LDL-C or non–HDL-C has not been tested in any of the large trials assessing ASCVD morbidity and mortality; however, the lack of RCTs explicitly designed to test goals does not invalidate the considerable evidence supporting use of goals; taken together, RCTs using various methods for lowering atherogenic cholesterol have indicated that lower on-treatment levels have been consistently associated with lower absolute risk for an ASCVD event, aligning with observational studies that suggest a log-linear relationship between atherogenic cholesterol levels and absolute ASCVD event risk.

---

### Nigral stimulation for resistant axial motor impairment in Parkinson's disease? A randomized controlled trial [^868e9cbd]. Brain (2013). Low credibility.

Electrode localization

Localization of the active STN and SNr contacts were determined by coregistration analyses of preoperative 3D T 1 -weighted MPRAGE and postoperative 3D T 1 -weighted FLASH sequences. Coregistration analyses were performed with Matlab 7.0 and the open-source toolbox SPM5 and indicated electrode localization of active contacts in the dorsolateral portions of STN and SNr, respectively (Fig. 2).

Figure 2
Localization of active electrode contacts of (A) dorsolateral STN and (B) dorsolateral SNr. Coordinates relative to the midcommisural point (MCP) were: left STN −11.4 ± 0.8, −0.9 ± 2.0, −3.0 ± 1.7; right STN 13.5 ± 1.1, −0.5 ± 1.7, −2.2 ± 1.5; left SNr −10.0 ± 0.9, −3.4 ± 2.1, −6.4 ± 1.8; right SNr 12.1 ± 1.3, −3.3 ± 1.7, −5.8 ± 1.5 (x, y, z; x = medio-lateral, y = anterio-posterior, z = rostro-caudal). Electrode coordinates (mean ± standard deviation in x - and y -direction) are visualized in coronal view on the Atlas of the Human Brain with permission (Mai et al. 2007). (C) An additional illustrative image of electrode localization including a simulation on volume of tissue activated was kindly provided by Medtronic based on work by Yelnik et al. (2007) (atlas) and D'Haese et al. (2012) (atlas and algorithms).

---

### Recommendations for cardiac chamber quantification by echocardiography in adults: an update from the American Society of Echocardiography and the European association of cardiovascular imaging [^36a9c0c5]. Journal of the American Society of Echocardiography (2015). Medium credibility.

Table 5 — Echocardiographic assessment of LV mass (linear method, 2D) notes that 2D imaging facilitates orientation perpendicular to the LV long axis, but it shares the same geometrical assumptions as M‑mode and the same limitations in patients with abnormal LV geometry; the impact of harmonic imaging on mass calculations and normal values remains to be defined, and normal values are less well established than for M‑mode measurements.

---

### Guidelines for performing a comprehensive transthoracic echocardiographic examination in adults: recommendations from the American Society of Echocardiography [^f664ce66]. Journal of the American Society of Echocardiography (2019). High credibility.

Color M‑mode flow propagation — apical window A4C Color M mode has been used to measure the early diastolic flow propagation velocity from the slope of the linear isovelocity contour to assess the rapid filling phase of diastole, and this measure may be helpful in the evaluation of diastolic dysfunction; a normal propagation velocity is > 50 to 55 cm/sec, whereas < 45 cm/sec has been associated with impaired relaxation; to acquire and measure, align the M‑mode cursor with the mitral inflow jet in the apical view, set the color M‑mode box to include the area from mitral annulus to the LV apex, move the color baseline toward the direction of flow to create aliasing so that the central highest velocity jet is blue, measure the slope along the red first aliasing line of the signal in early diastole with the same timing as the E wave, measure from the mitral annulus to ≥ 4 cm into the left ventricle, and divide the distance by time in seconds to obtain the slope in centimeters per second.

---

### Hourly step recommendations to achieve daily goals for working and older adults [^a81a03f5]. Communications Medicine (2024). Medium credibility.

Fig. 3
Estimated mean step counts in the next hour.

a Weekday for 6 p.m. 8 p.m. and 10 p.m. b Weekend for 6 p.m. 8 p.m. and 10 p.m. c Weekday for 7 p.m. 9 p.m. and 11 p.m. d Weekend for 7 p.m. 9 p.m. and 11 p.m. The figure shows the predicted mean step counts (y -axis) and the 95% credible intervals (CI) on the mean step counts for the rest of the day, adjusting for age group, BMI group and sex. The posterior sample size is 20,000. Further details are provided in the Supplementary Method. The bars denote the 95% CIs, and the dots denote the mean. The means and the 95% CIs were plotted assuming the participant had accumulated total step counts in intervals of 500 steps at the start of the hour from 0 to 12,500 steps (x -axis). The daily step goals (diagonal lines) were 5000, 7500, and 10,000 steps.

For the first half of the day (12 a.m. to 12 p.m.), the logistic and gamma regression covariates were dummy variables for age group, BMI group and sex, as these covariates were associated with physical activity.

Accounting for the financial incentive structure of NSC3, the daily step goals were 5000, 7500, and 10,000 steps, which earned participants 10, 25, and 40 HealthPoints, respectively (Supplementary Table S1). For the second half of the day (12 p.m. to 12 a.m.), we defined four disjoint intervals: (i) 0–4999 steps, (ii) 5000–7499 steps, (iii) 7500–9999 steps, and (iv)10,000 steps. The model was stratified into the above four disjoint intervals based on the sum of the step counts up to the previous hour. The logistic and gamma regression covariates were age, BMI, sex, and the sum of step counts up to the previous hour divided by 10,000. This scaling ensured that the variable was equal to one when participants had just completed all their daily step goals. A value that exceeded one meant that the participant exceeded the daily 10,000-step goal. Furthermore, the scaling ensured that the prior was uninformative.

---

### Lipid measurements in the management of cardiovascular diseases: practical recommendations a scientific statement from the National Lipid Association writing group [^7c8d5ed1]. Journal of Clinical Lipidology (2021). High credibility.

Sampson equation considerations describe potential utility and current evidence gaps: A bivariate quadratic equation published by Sampson and colleagues calculates LDL-C from TG and non–HDL-C and yields accurate estimates for samples with a TG level up to 800 mg/dL, although it may underestimate low LDL-C levels. In samples with normal triglyceride levels, it yields similar results to Martin/Hopkins at low LDL-C, but additional data in individuals with low LDL-C are needed before it can be more generally recommended for LDL-C calculation.

---

### Local planar gradients with order-of-magnitude strength and speed advantage [^9495dcca]. Magnetic Resonance in Medicine (2007). Low credibility.

A three-axis uniplanar gradient coil was designed and built to provide order-of-magnitude increases in gradient strength of up to 500 mT/m on the x- and y-axes, and 1000 mT/m for the z-axis at 640 A input over a limited FOV (approximately 16 cm) for superficial regions, compared to conventional gradient coils, with significant gradient strengths extending deeper into the body. The gradient set is practically accommodated in the bore of a conventional whole-body, cylindrical-geometry MRI scanner, and operated using standard gradient supplies. The design was optimized for gradient linearity over a restricted volume while accounting for the practical problems of torque and heating. Tests at 320 A demonstrated up to 420-mT/m gradients near the surface at efficiencies of up to 1.4 mT/m/A. A new true 2D gradient-nonlinearity correction algorithm was developed to rectify gradient nonlinearities and considerably expand the imageable volumes. The gradient system and correction algorithm were implemented in a standard 1.5 T scanner and demonstrated by high-resolution imaging of phantoms and humans.

---

### Deferiprone [^b76312b7]. FDA (2025). Medium credibility.

3 DOSAGE FORMS AND STRENGTHS

Tablets (three times a day): 1,000 mg are white, film-coated, oval shaped tablets; imprinted with "T" score "1 K" on one side and plain on the other side.
Tablets: 500 mg are white to pinkish-white, capsule-shaped tablets; scored on one side, engraved "T" on the left of the score line and "5" on the right and plain on the other side.

Tablets (three times a day): 1,000 mg with functional scoring (3)
Tablets (three times a day): 500 mg with functional scoring (3)

---

### Inter-element miscibility driven stabilization of ordered pseudo-binary alloy [^e979605b]. Nature Communications (2022). High credibility.

To determine why the Z 3-Fe(Pd, In d) 3 structure was preferentially formed, we undertook a theoretical approach using first-principles calculations. First, we calculated the formation energies (E form) of various FePd 3 phases in L 1 2 and Z 3 structures before and after adding In by using the equation below; where E [Fe x Pd y In z] represents the total energies of Z 3- or L 1 2 -Fe x Pd y In z ((x, y, z) = (2, 6, 0), (2, 5, 1), or (1, 6, 1)) and μ[Fe], μ[Pd] and μ[In] are the chemical potentials of Fe, Pd and In, respectively, which are equivalent to their total energies of the ground states. As shown in Fig. 3a, the calculation results showed that the L 1 2 -(Fe 1, In 1)Pd 6 and Z 3-Fe 2 (Pd 5, In 1 d) structures were most stable in each structural type, which was in good agreement with the In sites in L 1 2 -type and Z 3-type structures estimated from XAFS analysis. Furthermore, the differences in E form values between L 1 2 -(Fe 2- x, In x)Pd 6 and Z 3-Fe 2 (Pd 6- x, In x d) (0 < x < 1) (see Methods) showed that the Z 3-type structure became more stable than the L 1 2 -type structure from x > 0.48, or In/(In+Pd) > 8 at.% (Fig. 3b). The calculation results also agreed with the experimental tendency in terms of the phase transition and the critical In/Pd at.% from the L 1 2 -type to Z 3-type phases when increasing the In composition. Therefore, although the L 1 2 -FePd 3 structure is thermodynamically stable for FePd 3 systems, introducing a small amount of In atoms into FePd 3 systems makes the Z 3-type structure more stable than the L 1 2 -type structure.

---

### 3D alignment of distant patterns with deep-subwavelength precision using metasurfaces [^2c53c4ed]. Nature Communications (2024). High credibility.

Fig. 4
Simulation and experimental results.

a Simplified illustration of the measurement setup. b Simulated and their corresponding experimentally measured interference patterns for different lateral and axial misalignments. Scale bar: 5 mrad. c Simulated interference patterns for the aligned and 10 nm laterally misaligned marks. Expanded views and the intensity plots along the θ y = 0 lines (dashed lines) are also shown, indicating that 10 nm misalignment can be visually detected. Scale bar: 5 mrad. d Simulated and measured interference patterns of the aligned and 50 nm laterally misaligned marks. Scale bar: 5 mrad. θ x and θ y are far-field angles, and Δ x and Δ z represent the lateral and axial misalignment values, respectively.

Figure 4 b shows simulated and experimentally measured far-field patterns for different lateral and axial misalignments of the two workpieces (see "Methods" for simulation details and Supplementary Fig. 2 for more results). When the samples are aligned, the two holograms interfere destructively on the optical axis, and the interference pattern is composed of multiple concentric rings. A lateral misalignment of the samples laterally moves the two holograms by a different amount, thus changing their interference pattern. For a small lateral misalignment, the relative hologram movement makes the intensity distribution asymmetric along the movement direction (x- direction in Fig. 4 b), and for large misalignments, the two holographic spots are spatially separated. A misalignment along the axial direction defocuses both holograms and their interference patterns, resulting in the reduction of the peak intensity and the relative intensity of different rings. Figure 4 c presents the simulated intensity results for the aligned sample and for the lateral misalignment of Δ x = 10 nm. As the intensity cut along the θ y = 0 shows, a 10 nm lateral misalignment can be readily visually detected. The accuracy and precision of the proposed alignment technique are dictated by systematic errors and the signal-to-noise ratio of the recorded images (see the Discussion section). The mechanical vibrations, most probably caused by the camera fan, were the dominant source of random errors in our measurements, and the sample movement accuracy was limited by the actuators to ~ 60 nm, thus we could reliably detect ~ 50 nm lateral misalignment from a single captured image as shown in Fig. 4 d. We attribute slight differences between the measured and simulated results shown in Fig. 4 b, d to mechanical vibration noise in our setup and to interference with the undesired light scattered from an aperture in the setup that was used to reduce the incident laser beam diameter.

---

### Centering the projection reconstruction trajectory: reducing gradient delay errors [^4b3d64dc]. Magnetic Resonance in Medicine (2003). Low credibility.

The projection reconstruction (PR) trajectory was investigated for the effect of gradient timing delays between the actual and requested start time of each physical gradient. Radial trajectories constructed with delayed gradients miss the center of k-space in an angularly dependent manner, causing effective echo times to vary with projection angle. The gradient timing delays were measured in phantoms, revealing delays on the x, y, and z gradients which differed by as much as 5 micro sec. Using this one-time calibration measurement, the trajectories were corrected for gradient delays by addition of compensatory gradient areas to the prephasers of the logical x and y readout gradients. Effective projection-to-projection echo time variability was reduced to less than 1 micro sec for all imaging orientations. Using corrected trajectories, artifacts were reduced in phantom images and in volunteer studies. This correction should potentiate greater clinical use of the PR trajectory.

---

### Microscopic response to inhomogeneous deformations in curvilinear coordinates [^3649c2b2]. Nature Communications (2013). Medium credibility.

A mechanical deformation of a continuum can be expressed as a generalized coordinate transformation of space. Consequently, the equations of electrostatics in deformable media must satisfy covariance requirements with respect to such transformations, a problem that has long been addressed in the context of general relativity. Here we show how these ideas can be incorporated into the framework of density-functional perturbation theory, providing access to the microscopic charge density and electrostatic potential response to an arbitrary deformation field. We demonstrate the power of our approach by deriving, in full generality, the surface contributions to the flexoelectric response of a finite object, a topic that has recently been a matter of controversy. The breakdown of translational periodicity produces consequences that might seem highly paradoxical at first sight: for example, the macroscopic bulk polarization does not always correspond to the physical surface charge.

---

### Methodologies for the development of CHEST guidelines and expert panel reports [^e7ef9102]. Chest (2014). Medium credibility.

CHEST grading framework — dimensions and evidence adjustment are defined explicitly. The CHEST grading system defines the grades based on two key dimensions: (1) the balance of benefits of the proposed action as compared with the possible harms or risks and (2) the methodologic quality of the supporting evidence. Both factors are represented in the overall grade, with the former represented by 1 or 2 and the latter A, B, or C. The methodologic quality is initially based on the hierarchy of study design, but studies can be upgraded or downgraded based on specific criteria (eg, existence of methodologic flaws, directness, precision, consistency of results).

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^59d10d7c]. Annals of the American Thoracic Society (2023). High credibility.

Ventilation–perfusion (V A /Q) distribution modeling is binned into 50 equally spaced (log scale) compartments, with V A /Q ratios < 0.005 (shunt) and > 100 (dead space) separately calculated, and relative dispersion and gravitational gradients may also be assessed.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^89cdccc2]. Annals of the American Thoracic Society (2023). High credibility.

V_A/Q distribution modeling — derived from cumulative plots of ventilation or perfusion versus V_A/Q — is binned into 50 equally spaced log-scale compartments, with shunt and dead space handled separately. Specifically, V_A/Q ratios < 0.005 (shunt) and > 100 (dead space) are calculated as separate components, and relative dispersion and gravitational gradients may also be assessed.

---

### Nonlinear mechanics of human mitotic chromosomes [^2b2b1030]. Nature (2022). Excellent credibility.

Collapse of stiffness-force curves

To achieve a collapse of the stiffness-force curves they were normalized on a log-log-scale. Therefore, curves were interpolated to a logarithmic force scale to get evenly spaced data after taking the logarithm. In addition, negative values for force and stiffness were discarded. Then the logarithms of force ln(F) and stiffness ln(K) were calculated and fitted with a piecewise function y = ln(K₀) for x ≤ ln(F_c) and y = c − ln(F_c) + ln(K₀) for x > ln(F_c) to determine the initial stiffness K 0 and the critical force F c. If the determined parameters for K 0 and F c were in the range of the stiffness-force curve, the curves normalized by K 0 and F c were plotted in a double-logarithmic plot to achieve the collapse. The criteria that K 0 and F c had to be positive and within the range of the stiffness-force curve were met by 29 out of 44 curves.

---

### AASLD practice guidance on the clinical assessment and management of nonalcoholic fatty liver disease [^8476c565]. Hepatology (2023). High credibility.

Regarding follow-up and surveillance for metabolic dysfunction-associated steatotic liver disease, more specifically with respect to laboratory and imaging follow-up, AASLD 2023 guidelines recommend to consider using improvement in ALT or reduction in liver fat content by imaging in response to an intervention as a surrogate for histological improvement in disease activity.

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^070d751c]. Magnetic Resonance in Medicine (2021). Medium credibility.

Force and torque constraints can be added using the known main B 0 field distribution, integrating over the current distribution for each basis function and entering the results into matrix H or C. One row is added for each direction of force or torque, to obtain an overall magnitude constraint. Eddy currents are computed in a similar manner; the step response for time‐dependent eddy currents on the surface of a conducting cylinder — typically the thermal shield in the magnet — is computed at multiple points in space and time. Each point in space and time is entered as a separate inequality constraint equation. It is usually sufficient to constrain eddy currents at time = 0 following a step change in gradient current, reducing the size of the problem.

Finally, and of primary significance to the present work, E‐field constraints can be handled in a similar manner to those for force and torque. At gradient frequencies of interest, the time evolution of E‐fields in human tissues is short, and therefore proportional to instantaneous slew rate and not the detailed waveform shape in time. Thus, given a body model, the E‐field is computed from each gradient coil basis function for unit slew rate at a series of points over the body surface, such as using the methods we have described recently. 17 Calculation at points on the interior of the model is not required, as the maximum magnitude always occurs on the surface of a uniform body model (see Supporting Information). A magnitude constraint is created on the surface by placing a series of rotated inequality constraints on the vector E‐field tangent to the surface. For example, we choose 32 directions at each point spaced over 360º, which constrains the magnitude to within 0.5% of the desired value.

---

### American association of clinical endocrinology clinical practice guideline on pharmacologic management of adults with dyslipidemia [^1e8e8282]. Endocrine Practice (2025). High credibility.

Regarding classification and risk stratification for dyslipidemia, more specifically with respect to risk assessment, AACE 2025 guidelines recommend to use a validated tool or calculator to predict future risk of ASCVD events in adult patients with dyslipidemia as part of shared decision-making around treatment.

---

### Resolving discrepancies between chimeric and multiplicative measures of higher-order epistasis [^7747af71]. Nature Communications (2025). High credibility.

Equation (21) demonstrates that X = (X 1, X 2) follows an exponential family distribution, a wide class of distributions that includes many common distributions including normal distributions or Poisson distributions. In particular, using the terminology of exponential families, equation (21) shows that the sufficient statistics of X are X 1, X 2, and X 1 X 2, with corresponding canonical parameters β 1, β 2, and β 12. As a result, the distribution P (X) is uniquely defined by the expected values E [X 1], E [X 2], E [X 1 X 2] of the sufficient statistics, sometimes called the moments or the mean parameters of the distribution. Thus, we obtain a third parametrization of the distribution P (X) using the moments μ 0 = 1, μ 1 = E [X 1], μ 2 = E [X 2], μ 12 = E [X 1 X 2]. The elements of the vector μ = (1, μ 1, μ 2, μ 12) of moments are sometimes called the mean parameters of the distribution.

---

### A non-canonical visual cortical-entorhinal pathway contributes to spatial navigation [^c9e75e21]. Nature Communications (2024). High credibility.

Viral constructs and injection strategy

The injection pipette was at a 18° angle towards the caudal end of the brain in all surgeries. We set the position of bregma as X = 0 mm, the transverse sinus position as Y = 0 mm, the surface of the brain as Z = 0 in all surgeries. For targeting vCE L5a of MEC, a craniotomy was made at X = 3.5–3.75 mm, Y = 0.7–0.8 mm, and virus was slowly released at Z = 2.6–2.8 mm. For targeting other regions, the coordinates were as follows: ME L5a (X = 3.5–3.75 mm, Y = 0.7–0.8 mm, Z = 3.2–3.4 mm), MEC L2 (X = 3.5–3.75 mm, Y = 0.4–0.5 mm, Z = 1.8–3.0 mm), V2L (X = 3.5–3.6 mm, Y = 2.0–2.2 mm, Z = 0.7–1.0 mm), V2M (X = 1.3–1.5 mm, Y = 1.9–2.0 mm, Z = 0.7–0.9 mm), V1 (X = 2.3–2.5 mm, Y = 1.7–1.9 mm, Z = 0.6–0.8 mm), iCA1 (X = 3.4–3.6 mm, Y = 2.0–2.2 mm, Z = 2.1–2.2 mm) and vCA1 (X = 3.4–3.6 mm, Y = 2.0–2.2 mm, Z = 3.4–3.5 mm). After delivering the virus, the injection pipette was left in place for an additional 10 min before it was fully withdrawn.

---

### Standards of care in diabetes – 2025 [^bc33815b]. Diabetes Care (2025). High credibility.

Regarding screening and diagnosis for diabetes mellitus type 1, more specifically with respect to indications for screening (T1DM), ADA 2025 guidelines recommend to recognize that having multiple confirmed islet autoantibodies is a risk factor for clinical diabetes. Consider testing for dysglycemia to further forecast near-term risk. Consider referring patients with identified multiple islet autoantibodies to a specialized center for further evaluation and/or consideration of a clinical trial or approved therapy to potentially delay development of clinical diabetes.

---

### Identifying domains of applicability of machine learning models for materials science [^72c4ba76]. Nature Communications (2020). High credibility.

An illustrative example

Before describing the details of DA identification and its integration into the ML process, let us illustrate the concept and its utility via a synthetic example (see Fig. 1). We consider a simple two-dimensional representation consisting of independent features x 1 and x 2 that are each distributed according to a normal distribution with mean 0 and variance 2 (N (0, 2)) and a target property y that is a third-degree polynomial in x 1 with an additive noise component that scales exponentially in x 2 :That is, the y values are almost determined by the third-degree polynomial for low x 2 values but are almost completely random for high x 2 values. Discovering applicable domains reveals how different models cope differently with this setting even if they have a comparable average error. To show this, let us examine the error distributions obtained from three different kernelized regression models of the formwith parameter vector ν that are fitted around a training, or fitting (F), setwith three different choices for the kernel function k. We observe:
When using the linear (lin) kernel, the resulting linear model is globally incapable to trace the variation of the third-order polynomial except for a small stripe on the x 1 -axis where it can be approximated well by a linear function. Consequently, there is a very high error globally that is substantially reduced in the DA described by σ lin (x₁, x₂) ≡ −0.3 ≤ x₁ ≤ 0.3.
When using the Gaussian kernel), the resulting radial basis function (rbf) model is able to represent the target property well locally unless (a) the noise component is too large and (b) the variation of the target property is too high relative to the number of training points. The second restriction is because the rbfs have non-negligible values only within a small region around the training examples. Consequently, the discovered DA is not only restricted in x 2 -direction but also excludes high absolute x 1 -values: σ rbf ≡ −3.3 ≤ x 11 ≤ 3.1 ∧ x 2 ≤ 0.1.
In contrast, when using the non-local third-degree polynomial (poly) kernel, data sparsity does not prevent an accurate modeling of the target property along the x 1 -axis. However, this non-locality is counterproductive along the x 2 -axis where overfitting of the noise component has a global influence that results in higher prediction errors for the almost deterministic data points with low x 2 -values. This is reflected in the identified DA σ poly (x₁, x₂) ≡ −3.5 ≤ x₂ ≤ 0.1, which contains no restriction in x 1 -direction, but excludes both high and low x 2 -values. This highlights an important structural difference between the rbf and the polynomial model that is not reflected in their similar average errors.

---

### Comparison of parameter optimization methods for quantitative susceptibility mapping [^26a0417b]. Magnetic Resonance in Medicine (2021). Medium credibility.

Purpose

Quantitative Susceptibility Mapping (QSM) is usually performed by minimizing a functional with data fidelity and regularization terms. A weighting parameter controls the balance between these terms. There is a need for techniques to find the proper balance that avoids artifact propagation and loss of details. Finding the point of maximum curvature in the L-curve is a popular choice, although it is slow, often unreliable when using variational penalties, and has a tendency to yield overregularized results.

Methods

We propose 2 alternative approaches to control the balance between the data fidelity and regularization terms: 1) searching for an inflection point in the log-log domain of the L-curve, and 2) comparing frequency components of QSM reconstructions. We compare these methods against the conventional L-curve and U-curve approaches.

Results

Our methods achieve predicted parameters that are better correlated with RMS error, high-frequency error norm, and structural similarity metric-based parameter optimizations than those obtained with traditional methods. The inflection point yields less overregularization and lower errors than traditional alternatives. The frequency analysis yields more visually appealing results, although with larger RMS error.

Conclusion

Our methods provide a robust parameter optimization framework for variational penalties in QSM reconstruction. The L-curve-based zero-curvature search produced almost optimal results for typical QSM acquisition settings. The frequency analysis method may use a 1.5 to 2.0 correction factor to apply it as a stand-alone method for a wider range of signal-to-noise-ratio settings. This approach may also benefit from fast search algorithms such as the binary search to speed up the process.

---

### Identifying domains of applicability of machine learning models for materials science [^196a563d]. Nature Communications (2020). High credibility.

Fig. 1
Domains of applicability of three 2d-models of a noisy third-degree polynomial.

Three different models, linear (top), radial basis function (rbf, center), and polynomial (poly, bottom), are shown approximating the same distribution of two independent features x 1 ~ N (0, 2) and x 2 ~ N (0, 2), and the target property, where N (μ, ϵ 2) denotes a normal distribution with mean μ and standard deviation ϵ. Test points are plotted in 3d plots against the prediction surface of the models (color corresponds to absolute error) where the DA is highlighted in gray. The distributions of individual errors for the DA (gray) and globally (black) are shown in the 2d plots of each panel with the mean error (solid) and the 95th percentile (95 perc./dashed) marked by vertical lines. Note that the global error distribution of the linear model has a considerably long tail, which is capped in the image.

---

### Wilderness Medical Society clinical practice guidelines for prevention and management of avalanche and nonavalanche snow burial accidents: 2024 update [^1caa4be0]. Wilderness & Environmental Medicine (2024). High credibility.

Probe line search for buried victims without transceivers — For buried victims without transceivers, a probe line should be established. The initial probe depth should be 1.5 m to maximize efficiency, which would reach 88% of victims recovered alive in the United States and 95% of victims recovered alive in Switzerland. The probe technique should follow the 3-holes-per-step method, which is 30% faster than standard coarse probing; the rescuer inserts the probe into the snow 3 times while standing: 20 cm to the rescuer's left, center, and 20 cm to the rescuer's right, then steps forward to repeat. In slalom probing, organized rescuers probe 3 areas in a left-to-right pattern 50 cm apart while walking in zig-zags; slalom probing covers the same surface area faster than the 3-holes-per-step method but may be less effective. Probe line grid spacing influences detection, and a 50 x 50 cm grid offers the best probability of detection without prolonging search time. We recommend the initial probe pass should be limited to a depth of 1.5 m using 3-holes-per-step or slalom probing to cover a 50 x 50 cm grid. Strong recommendation, low quality evidence.

---

### Optimal use of left ventriculography at the time of cardiac catheterization: a consensus statement from the Society for Cardiovascular Angiography and Interventions [^95a53fd4]. Catheterization and Cardiovascular Interventions (2015). Medium credibility.

Radionuclide ventriculography — measurement characteristics and accuracy: Left ventricular counts are gated to the R-R interval and summated over a period (typically 5–10 min) or in a single pass to derive measurements, and because measurements are independent of geometrical assumptions the method is highly accurate and very reproducible with inter-observer variability of < 5%; it can be used to examine both atria and ventricles and the principal disadvantage is radiation exposure.