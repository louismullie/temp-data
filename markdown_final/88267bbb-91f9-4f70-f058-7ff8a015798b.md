# Medical Question & Answer

**Sample ID**: 88267bbb-91f9-4f70-f058-7ff8a015798b
**Dataset Index**: 371061

---

## Question

22(1264). Represent the expression $2 x^{2}+2 y^{2}$ as a sum of two squares.

---

## Answer

> Let's see… What do we have here? The user is asking how to represent the expression (2x^2 + 2y^2) as a sum of two squares. Let's break this down step-by-step. First, I need to think about factoring out the common coefficient. Then, I should verify how to rewrite the remaining expression as a sum of squares. Next, I will distribute the coefficient back into each squared term to maintain equality. Finally, I should double-check that the resulting expression is indeed a sum of two squares and consider whether any alternative forms are valid or preferable.

> Let me first confirm the structure of the original expression. (2x^2 + 2y^2) is a binomial with a common factor of 2, so factoring yields (2(x^2 + y^2)), which is a valid first step toward simplifying the representation.

> Wait, let me verify the core identity I'm using. The expression inside the parentheses, (x^2 + y^2), is already a sum of two squares, so the original expression is literally 2 times a sum of two squares. However, the question asks to represent the entire expression as a sum of two squares, not merely to factor it, so I need to distribute the 2 into each squared term in a way that preserves the sum-of-squares form.

> I will now examine how to distribute the 2. One way is to write (2x^2 + 2y^2 = (\\sqrt{2}x)^2 + (\\sqrt{2}y)^2), because ((\\sqrt{2}x)^2 = 2x^2) and ((\\sqrt{2}y)^2 = 2y^2), so the sum remains equivalent to the original expression. Hold on, I should verify the arithmetic: (\\sqrt{2} \\times \\sqrt{2} = 2), so yes, this distribution is correct.

> Let me consider whether there are alternative representations. Another valid approach is to factor out 2 and keep the sum of squares explicit: (2(x^2 + y^2)), which is mathematically equivalent but not itself a sum of two squares. If the intent is strictly to write the expression as a sum of two squares, then the form ((\\sqrt{2}x)^2 + (\\sqrt{2}y)^2) is the direct answer, whereas (2(x^2 + y^2)) is a factored form rather than a sum of two squares.

> Hmm, wait a minute, I initially thought I might need to invoke a sum-of-squares identity like ((a + b)^2 + (a - b)^2 = 2a^2 + 2b^2), but hold on, let's not jump to conclusions. That identity would give (2a^2 + 2b^2), which matches the structure of (2x^2 + 2y^2) if I set (a = x) and (b = y), so I could also write (2x^2 + 2y^2 = (x + y)^2 + (x - y)^2). Let me verify: expanding ((x + y)^2 + (x - y)^2) gives (x^2 + 2xy + y^2 + x^2–2xy + y^2 = 2x^2 + 2y^2), which confirms the identity works here.

> I should double-check which form best answers the question. Both ((\\sqrt{2}x)^2 + (\\sqrt{2}y)^2) and ((x + y)^2 + (x - y)^2) are valid representations of (2x^2 + 2y^2) as a sum of two squares. The first keeps the variables separated and scales them by (\\sqrt{2}), while the second mixes (x) and (y) in each square but avoids irrational coefficients. Either is acceptable unless the problem specifies a preference, so I can present either or both.

> Final answer: (2x^2 + 2y^2 = (\\sqrt{2}x)^2 + (\\sqrt{2}y)^2), or equivalently, (2x^2 + 2y^2 = (x + y)^2 + (x - y)^2).

---

The expression (2x^2 + 2y^2) can be written as a sum of two squares in two equivalent ways:

- **((\\sqrt{2}x)^2 + (\\sqrt{2}y)^2)**: factor out 2 and express each term as a square of a scaled variable.
- **((x + y)^2 + (x - y)^2)**: use the identity (2x^2 + 2y^2 = (x + y)^2 + (x - y)^2).

Both forms are valid; the first is a direct scaling, and the second is a symmetric decomposition that avoids irrational coefficients.

---

## Method 1: Direct factorization

Factor out the common coefficient 2:

[
2x^2 + 2y^2 = 2(x^2 + y^2)
]

Then express each term as a square of a scaled variable:

[
2(x^2 + y^2) = (\\sqrt{2}x)^2 + (\\sqrt{2}y)^2
]

Thus, (2x^2 + 2y^2 = (\\sqrt{2}x)^2 + (\\sqrt{2}y)^2).

---

## Method 2: Using algebraic identities

Use the identity (2x^2 + 2y^2 = (x + y)^2 + (x - y)^2):

[
2x^2 + 2y^2 = (x + y)^2 + (x - y)^2
]

This form avoids irrational coefficients and is often preferred for algebraic manipulation.

---

## Verification

Both forms are algebraically equivalent to the original expression:

- **Form 1**: ((\\sqrt{2}x)^2 + (\\sqrt{2}y)^2 = 2x^2 + 2y^2)
- **Form 2**: ((x + y)^2 + (x - y)^2 = x^2 + 2xy + y^2 + x^2–2xy + y^2 = 2x^2 + 2y^2)

---

## Conclusion

The expression (2x^2 + 2y^2) can be represented as a sum of two squares in two equivalent ways:

- **((\\sqrt{2}x)^2 + (\\sqrt{2}y)^2)**
- **((x + y)^2 + (x - y)^2)**

Both representations are correct; choose the one that best fits the context of your problem.

---

## References

### The challenge of population aging for mitigating deaths from PMair pollution in China [^67bde257]. Nature Communications (2023). High credibility.

Disease mortality is determined by ϵ in Eq. (8), ϵ represents the residual between the estimated value and the actual value, obeying the mean of 0, and the variance ofis normally distributed. Therefore, the 95% confidence interval for ln (m) can be expressed as:where ln(m) CI represents the uncertainty interval for the natural logarithm of mortality from a specific type and age group of diseases; the sum of y^ and ϵ^ represents the predicted value of ln(m), andrefers to the variance of the residual term in the regression model (Eq. 10). T 95% (n-2) represents the t-statistic with n-2 degrees of freedom under the 95% confidence interval, where n is the sample size for constructing the regression model.can be further obtained by the following formula.whereis the residual sum of squares of the regression model, andrepresent the mean of each independent variable and independent variable in the regression model, respectively, andrepresents the input value of the independent variable when predicting the future based on the regression model. We reported the 5-year intervals to smooth out the influence of abrupt changes due to data artifacts (Fig. 1 and Fig. 2).

---

### On the psychometric properties and genomic etiology of the general factor of psychopathology [^9748d483]. Molecular Psychiatry (2025). Medium credibility.

Fig. 1
Graphical representation of reliability estimation.

Squares 1, 2 and 3 represent observed items, and the square labeled "sum score" represents an observed (weighted) sum score of these three items. F represents a latent factor, and R1, R2, and R3 represent residuals that are not explained by F. Using structural equation modeling tracing rules (assuming unit factor and residual variances), one can estimate the variance explained in the sum score by F (Γ) as a product of the factor loadings (a, b, c) and factor weights (g, h, i): One can also estimate the variance in the sum score not explained by F (Θ) as the product of the factor weights (g, h, i) and the residuals (d, e, f): Reliability can then be estimated as the variance explained in the sum score by F divided by the total variance: Reliability is typically labeled alpha when the factor loadings (denoted a, b, and c) and factor weights (denoted g, h, and i) are constrained to equality, omega when the factor loadings are free to vary but the factor weights are constrained to equality, and determinacy when both the factor loadings and the factor weights are free to vary.

Regardless of whether a high reliability should be considered a vice or virtue, three additional and more technical notes are worth mentioned regarding Fried and colleagues' critique. First, reliability is usually expressed in terms of variance explained, rather than as a correlation, because variance is used when estimating measurement error about an individual's score, and how much regression betas might be underestimated by. Squaring the observed correlations renders reliability estimates of 99% and 75% at waves 1 and 2, respectively, of which at least the latter seems less supportive of the original authors' argument.

Second, Fried and colleagues estimated a latent hierarchical factor model, and, in an unorthodox fashion, correlated the latent factors with the total sum score in the same model. This approach is seldom, if ever, used because sum scores are a perfect linear combination of its indicators such that matrix inversion (a necessary feature of factor analysis) becomes impossible. Although the authors circumvented this issue by estimating the factor model based on the tetrachoric (rather than the Pearson) correlations, I would instead advocate in favor of using standard psychometric techniques when estimating the association between latent factors and their constituent sum scores.

---

### Deep representation learning of chemical-induced transcriptional profile for phenotype-based drug discovery [^09814cae]. Nature Communications (2024). High credibility.

Performance evaluation metrics

As shown in Table 2, the model's prediction performance was mainly evaluated using following metrics: Root mean squared error (RMSE), Pearson's correlation coefficient, and Precision@K. RMSE and Pearson coefficient were used to measure the prediction performance on the overall landmark genes. Precision@k, on the other hand, focused on the most significantly up- and down-regulated expressed genes. In this study, Positive Precision@100 was evaluated for the top 100 up-regulated genes, while Negative Precision@100 was evaluated for the top 100 down-regulated genes. We also evaluated additional regression metrics, including sum of squares due to error (SSE), mean square error (MSE), mean absolute error (MAE) and multiple r 2.

Table. 2
Description of the evaluation metrics

a represents the number of landmark genes in expression profiles, represents the sets of top 100 positive/negative genes, represents the sets of top 100 predicted genes.

---

### Negative global phosphorus budgets challenge sustainable intensification of grasslands [^76cda9fb]. Nature Communications (2016). Medium credibility.

The sampled values for the first model parameter are randomly paired to the samples of the second parameter, and these pairs are subsequently randomly combined with the samples of the third source and so on. This results in an LHS consisting of N combinations of k parameters. The parameter space is thus representatively sampled with a limited number of samples.

LHS can be used in combination with linear regression to quantify the uncertainty contributions of the input parameters to the model outputs. The output Y considered (see columns in Supplementary Tables 7 and 8) is approximated by a linear function of the parameters X i expressed by

where β i is the so-called ordinary regression coefficient and e is the error of the approximation. The quality of the regression model is expressed by the coefficient of determination (R 2), representing the amount of variation Y explained by Y − e. Since β i depends on the scale and dimension of X i, we used the standardized regression coefficient (SRC), which is a relative sensitivity measure obtained by rescaling the regression equation on the basis of the s.d.'s σ Y and:

SRC i can take values in the interval [−1, 1]. SRC is the relative change Δ Y / σ Y of Y due to the relative change Δ X i /of the parameter X i considered (both with respect to their s.d. σ). Hence, SRC i is independent of the units, scale and size of the parameters. A positive SRC i value indicates that increasing a parameter value will cause an increase in the calculated model output, while a negative value indicates a decrease in the output considered caused by a parameter increase.

The sum of squares of SRC i values of all parameters equals the coefficient of determination (R 2), which for a perfect fit equals 1. Hence, SRC i 2 / R 2 yields the contribution of parameter X i to Y. For example, a parameter X i with SRC i = 0.1 adds 0.01 or 1% to Y in case R 2 equals 1.

---

### Value computations underpin flexible emotion expression [^912c8d5b]. Communications Psychology (2025). Medium credibility.

Fig. 2
Expressive communication.

Each colored shape represents the proportion of trials where a participant chose that emotion response (Red: Anger, Blue: Sadness, Yellow: Happiness, Grey: Neutral) in the Self-Report (circles; N = 84), Expression (triangles; N = 87), and Reputation condition (squares; N = 83). The boxplots represent the maximum a posteriori estimate and 95% HDI of the model-estimated posterior distribution of the population mean *95% HDI of the difference between conditions does not include zero. †90% HDI does not include zero.

Table 1
Proportion of emotion responses across conditions

Note: Cells indicate the maximum a posteriori estimate of the average proportion of responses of the emotion category and the 95% high-density interval (HDI) around it in brackets. The values in each column may not sum to one due to aggregation over posterior predictions.

a 95% HDI does not include zero.

b 90% HDI does not include zero.

---

### A systems-level framework for drug discovery identifies csf1R as an anti-epileptic drug target [^64e418d6]. Nature Communications (2018). Medium credibility.

Co-expression network analysis

Co-expression networks were constructed using hierarchical clustering of normalized gene expression profiles from 100 epileptic mice hippocampi. First, for all genes expressed in the hippocampus, we calculated 1-Spearman's correlation coefficients (called Spearman's distance) as a distance metric between the expression of any two genes –. Second, the distances between any gene pair were partitioned (clustered) using the Ward's clustering methodand organized into a dendrogram. Briefly, starting from the matrix of Spearman distances, Ward's method uses a recursive clustering procedure to form partitions (clusters) of genes. At each step of the procedure, the Ward clustering minimizes the loss of information (measured as the error of sum of squares in the Spearman distances) associated with each grouping of genes. To identify discrete clusters, we recursively cut the dendrogram to generate 299 clustering configurations that included from K = 2 to K = 300 clusters. In order to identify the optimal and stable number of clusters (K x), we calculated the percentage of the variance explained (R 2) by each clustering configuration (i.e. R 2 for each considered K) as follows:where BSS (between sum of squares) is the between-groups variance in Spearman distances and WSS (within sum of squares) is the within-groups variance in Spearman distances. We used two criteria to choose the value K x for which the variance explained reaches a plateau, that is, there is no additional gain in information (R 2) when using the next clustering K x + 1 (Figure S1). The criteria used to choose K x were (1) the "Elbow" (or "knee") methodand (2) the pseudo F-index. Both criteria indicated an optimal and stable number of clusters, K x = 29 (Figure S1).

---

### Refining the definition of HER2-low class in invasive breast cancer [^4b183dbc]. Histopathology (2022). Medium credibility.

Step 1: K‐means clustering

The K‐means technique aims to partition the data into K‐groups such that the sum of squares from points to the assigned cluster centres is minimised. HER2 mRNA values were classified, using K‐means, into two clusters based on their similarity of expression across multiple HER2 scoring parameters. Those cases which had a score of 1+ or 0 were clustered into two groups based on HER2 mRNA level and the detailed IHC scoring performed. Cluster 1 was defined as HER2‐negative (0) while cluster 2 represented HER2‐positive (1+). HER2 2+ were excluded from the clustering to avoid data bias.

---

### Gene-expression measurement: variance-modeling considerations for robust data analysis [^4e2bc0ca]. Nature Immunology (2012). Medium credibility.

System-wide measurements of gene expression by DNA microarray and, more recently, RNA-sequencing strategies have become de facto tools of modern biology and have led to deep understanding of biological mechanisms and pathways. However, analyses of the measurements have often ignored statistically robust methods that account for variance, resulting in misleading biological interpretations.

---

### Nonadditive gene expression is correlated with nonadditive phenotypic expression in interspecific triploid hybrids of willow (salix spp.) [^5fa6cb0d]. G3 (2022). Medium credibility.

Deviations in expected dosage but global conformity of gene expression is apparent

To test whether there was a dosage effect on parent alleles in triploid progeny, ASE ratios were compared within and among families. Only extreme deviations from expected dosage ratios (Pr = 1 × 10 −5) were included in the analysis and considered to be dysregulated. Because it is expected that the triploid hybrid has inherited a single copy of the diploid parent allele and 2 copies of the tetraploid parent allele, if there was no deviation in expression of the parent alleles in the hybrid, all loci would be represented by a single point at the intersection of expected P 2X /P 4X difference of logs, log 2 (P 2X /P 4X) (Fig. 2).

Fig. 2.
Superimposed dosage differential scatterplots of 10 individuals from each of the families 415, 423, and 430 (left to right, respectively). Each point depicts the log 2 ratio of the diploid parent allele in the hybrid and the diploid parent allele in the parent against the log 2 ratio of the tetraploid parent allele in the hybrid and the tetraploid parent allele in the parent. Points are colored according to their regulatory assignment. Ellipses mask most of the distribution of log 2 dosage ratios (Pr = 1 × 10 −5), such that points sitting outside ellipses are extreme outliers from expected dosage. Dotted lines at log 2 (1/3) = −1.585 and log 2 (2/3) = −0.585 represent distribution averages for diploid and tetraploid ratios, which is where the average distribution of dosage ratios is expected to occur.

---

### Estimating heritability of gene expression using parent-offspring regression with 2-channel microarrays [^170af714]. The Journal of Heredity (2008). Low credibility.

With the advent of microarrays, it is possible to look at the entire transcriptome of an organism as a suite of quantitative traits. An obvious question to now ask is: To what extent is gene expression heritable? In quantitative genetics, single parent-offspring regression is the most straightforward method in situations where the progenies are produced by cross-pollination to many male parents of unknown location. However, estimation of the heritability of gene expression with single parent-offspring regression has not yet been examined with 2-channel microarrays. Here we introduce 3 experimental designs: chain design, independent quartets design, and completely independent design. We then compare them with common reference design in respect to statistical power and bias of the estimates. In our simulations, we also incorporated a model of simple inheritance with one gene. The results of our simulations indicate the efficiency of the chain design over the alternative design considered.

---

### Use of 1H-nuclear magnetic resonance to screen a set of biomarkers for monitoring metabolic disturbances in severe burn patients [^a96e4e1c]. Critical Care (2014). Low credibility.

Pattern recognition

All multivariate statistics and pattern recognition were performed using the Eigen victor toolbox (ver6.2.1) with two techniques: PCA and PLS on the Matlab. Before analyzing, scaling was applied to minimize the variation of the 1 H-NMR peak to ensure that the large peak did not overshadow the contribution of the small one. PCA score plots were constructed to visualize the inherent clustering of the samples based on burning. The toolbox can export the Q 2 value, which indicates how well the model predicts new data. A large Q 2 (> 0.5) indicates good predictive capability.

For further analysis, PLS-discriminant analysis (PLS-DA) was used in the data processing. PLS is used to find the fundamental relationship between two matrices (X and Y), that is, a latent variable approach to modeling the covariance structures in these two spaces. Here the X is a 200 × 24 matrix, in which each row represents the integral value of the NMR spectrum of each patient, and Y represents the patient's condition where 1 indicates burn and 0 indicates health. A PLS model will try to find the multidimensional direction in the X space that explains the maximum multidimensional variance direction in the Y space; that is, it will try to find the spectrum variables in X that can explain the result of burn or health in Y. PLS is particularly suited when the matrix of predictors has more variables than observations.

In order to avoid excessive classification, we further adopted cross-validation (CV) to evaluate the stability of the model. We addressed the validation by cutting a single observation from the original sample as the validation data and the remaining observations as the training data. Each observation in the sample is used once as the validation data in turn. The Q 2 value represents the percentage of the variation in the dataset predicted by the model according to CV, that is, the Q 2 value represents the discriminating ability of the PPM of a particular segment. The formula for Q 2 is as follows:

Here PRESS is the predictive residual sum of squares, and SSY is the sum of squares of the Y matrix. These measures can be equivalently expressed as standard error of prediction (SDEP or SEP), or standard error of CV (SECV).

---

### The simplicity of protein sequence-function relationships [^84b22d02]. Nature Communications (2024). High credibility.

Fig. 1
Reference-free analysis (RFA) of genetic architecture.

a Illustration of RFA on a 2-site, 2-state genetic architecture. The four possible genotypes are arranged on a plane with their phenotype indicated by elevation. (First panel) The zero-order effect (e 0) is the mean phenotype of all genotypes, marked by the clear plane with cyan edges. The first-order effect of state A or B at site 1 [e 1 (A) or e 1 (B), green arrows] measures how the mean phenotype of all genotypes containing the state (dashed line) differs from the global mean. The green plane predicts the phenotype based on the state at site 1. (Second panel) First-order effects at site 2 are defined similarly and shown in pink. (Third panel) The first-order model predicts phenotypes by summing the first-order effects of all genetic states plus the global mean, shown as the gray plane tilted in both dimensions; the fraction of phenotypic variance explained is shown. (Fourth panel) The pairwise interaction between states A and B at sites 1 and 2 [e 1, 2 (A, B)] measures how the mean phenotype of all genotypes containing the two states [here just one genotype (A, B)] differs from the first-order prediction. b We implement RFA with a nonlinear link function to incorporate nonspecific epistasis. Each variant's genetic score (s) is the sum of the effects of its genetic states. The link function transforms s of each variant into its phenotype, y. Although the link function can take any form, here we use a simple sigmoid defined by two parameters representing the upper and lower bounds of the measurable phenotype. c (Left) A 5-site, 3-state genetic architecture was simulated by drawing reference-based effects from the standard normal distribution (but setting all fifth-order effects to zero); a small amount of simulated noise was added to the phenotypes. (Middle) Absolute error of RFA terms computed from the simulated measurements. Dashed lines, mean absolute error of individual phenotypes. Supplementary Fig. 1 shows the individual inferred terms. (Right) The fraction of phenotypic variance explained by the true, directly computed, and regression-estimated RFA terms. Supplementary Section 1.1 analyzes additional simulated genetic architectures.

---

### Transient power-law behaviour following induction distinguishes between competing models of stochastic gene expression [^6513fe13]. Nature Communications (2025). High credibility.

What features of transcription can be learnt by fitting mathematical models of gene expression to mRNA count data? Given a suite of models, fitting to data selects an optimal one, thus identifying a probable transcriptional mechanism. Whilst attractive, the utility of this methodology remains unclear. Here, we sample steady-state, single-cell mRNA count distributions from parameters in the physiological range, and show they cannot be used to confidently estimate the number of inactive gene states, i.e. the number of rate-limiting steps in transcriptional initiation. Distributions from over 99% of the parameter space generated using models with 2, 3, or 4 inactive states can be well fit by one with a single inactive state. However, we show that for many minutes following induction, eukaryotic cells show an increase in the mean mRNA count that obeys a power law whose exponent equals the sum of the number of states visited from the initial inactive to the active state and the number of rate-limiting post-transcriptional processing steps. Our study shows that estimation of the exponent from eukaryotic data can be sufficient to determine a lower bound on the total number of regulatory steps in transcription initiation, splicing, and nuclear export.

---

### Combinatorial code governing cellular responses to complex stimuli [^f2481e0e]. Nature Communications (2015). Medium credibility.

Methods

Identification of the interaction profiles

The number of ways to rank the numbers e 0, e X, e Y and e X+Y was computed using the recurrence relation A n k = A n− 1 k +k A n− 1 k− 1 which, for n = 4 and summing up for k = 1, 2, 3 and 4 gives 75 possible rankings. Each ranking can be seen as a set of outcomes of the following qualitative pairwise comparisons:
e X versus e 0
e Y versus e 0
e X+Y versus e 0
e Y versus e X
e X+Y versus e X
e X+Y versus e Y

In our framework, the outcome of a qualitative comparison can take on the following three values: 0 (equal numbers), 1 (first larger than the second) and −1 (first smaller than the second). Each of 75 rankings was coded uniquely as a vector of six components describing the qualitative outcome of the comparisons 1–6 as listed above. For example, the vector (0,0,1,0,1,1) corresponds to:

e X = e 0, e Y = e, e X+Y > e 0, e Y = e X, e X+Y > e X, e X+Y > e Y

To identify which rankings were compatible with positive or negative interactions, we considered the equations 1–6 together with the inequalities that define positive and negative interactions:
Δ e X+Y > Δ e X + Δ e Y (positive interaction)
Δ e X+Y < Δ e X + Δ e Y (negative interaction)

which can be written as

(7a) e X+Y − e X − e Y + e 0 > 0

(8a) e X+Y − e X − e Y + e 0 < 0

If a ranking is consistent with a positive (or negative) interaction, the inequality constraints encoded in the corresponding vector can be solved simultaneously with 7a (or 8a). To verify this, we developed a constraint satisfaction that attempts to solve the six constraints of each ranking together with the inequality 7a (or 7b). The solution is searched numerically with a MATLAB linear solver. The variables e 0, e X, e Y and e X+Y were constrained to the interval 2–16, taken as an approximate of the range of expression values from Affymetrix chips in log2 scale. The method is implemented in the MATLAB code and is available upon request.

---

### DC3 is a method for deconvolution and coupled clustering from bulk and single-cell genomics data [^3fa3b0ab]. Nature Communications (2019). High credibility.

Fig. 3
Analysis of subpopulation-specific regulatory networks. a – c Scatter plots of TF expression level and motif enrichment scores in the three subpopulations in RA-day 4. Node color represents expression specificity. Horizontal and vertical black lines indicate threshold values of motif enrichment scores and TF expression level. Key TFs are represented by squares (see text for key TF definition). d Top 30 key TFs in each subpopulation. Ranking is based on the product of log2(FPKM), motif enrichment score and expression specificity. e – g Dense subnetworks of key TFs plus expressed RA receptors in subpopulations 1 to 3 (left to right). Cadet blue color nodes represent the core subnetwork, violet nodes represent the upstream subnetwork and pink nodes represent the downstream subnetwork. Only the top 30 key TFs are shown. Source data are provided as a Source Data file

(Step 2) Construction of gene regulatory networks: On each subpopulation, we identified enhancer-target gene pairs with loop counts greater than or equal to 2. Given an enhancer-target gene pair, we connect it to key TFs which have both significant motif match on the enhancer region and significant correlation with target gene in the single cell gene expression data. This gives 14,979, 4,909 and 15,459 TF-Enhancer-Gene triplets in subpopulations 1, 2, and 3 respectively. Finally, for any pair of TF and target gene, say T i and G j, we compute a TF-Target score W ij as the sum, over TF-RE-Gene triples with TF = T i and Gene = G j, of the product of the motif score of T i on the RE and the loop count between RE and G j. In this way, we obtained a regulatory networks for each subpopulation, defined as the directed graph with key TFs are nodes and TF-Target scoresas edge weights. The networks for the three subpopulations contain (58 nodes, 1043 edges), (42 nodes, 685 edges) and (71 nodes, 1037 edges) respectively.

---

### Enhancers regulate 3' end processing activity to control expression of alternative 3' UTR isoforms [^b40d7d40]. Nature Communications (2022). High credibility.

Stratified random sampling

The range of gene expression log2 fold-changes was subdivided into 13 strata of equal width, with 1 as an upper bound and the minimum of the "SU up" genes as the lower bound (approximately −4). For each stratum, we randomly subsampled the two groups ("gene not up" and "SU up") to have matching numbers of genes. The number of genes per stratum was determined by the group with the least genes in that stratum.

Statistics

For all pairwise comparisons of PAS usage or transcriptional activity a 2-sided, 2-sample unequal variance t-test for independent samples was applied. When comparing several samples, a One-way ANOVA was performed. Mann–Whitney tests were used to determine if gene expression influences SU usage. Chi-square (X 2) tests were used to test for significant enrichment of genes associated with Ery-specific enhancers. The Pearson value was reported. Statistical tests were performed using Excel, R, and SPSS.

Reporting summary

Further information on research design is available in the Nature Research Reporting Summary linked to this article.

---

### Estimating the statistical significance of gene expression changes observed with oligonucleotide arrays [^ba8afa58]. Human Molecular Genetics (2002). Low credibility.

We present a simple method to assign approximate P-values to gene expression changes detected with Affymetrix oligonucleotide arrays and software. The method pools data for groups of genes and a small number of like-to-like comparisons in order to estimate the significance of changes observed for single genes in comparisons of experimental interest. Statistical significance levels are based on the observed variability in the fractional majority of probe pairs that indicate increasing or decreasing differential expression in comparisons of technical replicates. From this reference distribution or error model, we compute the expected frequency for fractional majorities in comparisons for N ≥ 2. These computed distributions are the source of P-value estimates for changes seen in the experimental comparisons. The method is intended to complement the Affymetrix software and to rationalize gene selection for experimental designs involving limited replication.

---

### SUMMIT: an integrative approach for better transcriptomic data imputation improves causal gene identification [^f5554381]. Nature Communications (2022). High credibility.

Methods

Penalized regression model for expression prediction

Consider the following linear regression model for estimating the genetically regulated components of gene expression:where Y is the N -dimensional vector of gene expression levels of a gene of interest (corrected for important covariates such as age, sex, and principal components of genotypes), is the N × p standardized genotype matrix of p cis -SNPs around the gene (within 1 MB of the gene transcription start site and end site), the p -dimensional vectoris the cis -eQTL effect size, and ϵ is random noise with a mean of zero.

We estimate w using a penalized regression framework. Specifically, the objective function iswhere J λ (⋅) is a penalty term. Since the performance of different penalties may vary under different genetic architectures, we consider several penalties, including LASSO, elastic net, the minimax concave penalty (MCP), the smoothly clipped absolute deviation (SCAD), and MNet. Note that the objective function (Equation (2)) is a function of the marginal statisticsand the linkage disequilibrium (LD) matrix, and does not require the individual-level data to be observed and stored. This allows us to build expression prediction models using eQTL summary-level data, which are computed using a much larger sample size. That is, we rewrite the objective function aswhereis a p -dimensional vector of standardized marginal effect size for cis -SNPs (i.e. correlation between cis -SNPs and gene expression levels), andis the LD matrix of the cis -SNPs. We use the z -scores provided in the summary-level eQTL dataset to estimate r (denoted by) and use a shrinkage estimator (illustrated below) with an LD reference panel (such as that of the 1000 Genomes Project) to estimate R (denoted by). We add an L 2 penalty term(where θ ≥ 0) to the objective function, which ensures a unique solution upon optimization. Note thatdoes not depend on w and can be ignored when optimizing f. Thus, the final objective function that we optimize can be written as, The estimatescan be obtained by the coordinate descent algorithm, which solves the univariate penalized regression problem sequentially and iteratively. Briefly, suppose thatare the coefficients in the t -th iteration of the coordinate descent algorithm. DefineWhen J λ (w) is the LASSO penalty, we can update w j asfor j = 1,…, p and t = 0, 1,…

---

### Fundamentals of experimental design for cDNA microarrays [^7e65d35e]. Nature Genetics (2002). Medium credibility.

Microarray technology is now widely available and is being applied to address increasingly complex scientific questions. Consequently, there is a greater demand for statistical assessment of the conclusions drawn from microarray experiments. This review discusses fundamental issues of how to design an experiment to ensure that the resulting data are amenable to statistical analysis. The discussion focuses on two-color spotted cDNA microarrays, but many of the same issues apply to single-color gene-expression assays as well.

---

### Integrative analysis of lung molecular signatures reveals key drivers of idiopathic pulmonary fibrosis [^393e61dd]. BMC Pulmonary Medicine (2021). Medium credibility.

Gene expression-driven subgrouping and pathobiological characterization

To identify gene expression-driven subgroups in an unbiased manner, we performed an agglomerative hierarchical clustering using DEG profiles from lung tissue samples of 585 IPF patients. We found that two clusters most optimally represented the data by computing the silhouette score and sum of squared error for two to six clusters (Fig. 2 A). Two clustered subgroups were designated C1 (n = 252) and C2 (n = 333) in order. Segregation of IPF subgroups were reproduced by t -stochastic neighbor embedding analysis and principal component analysis (Fig. 2 C).

Fig. 2
Unsupervised clustering using an agglomerative hierarchical clustering method. A Dendrogram of the hierarchical clustering based on differentially expressed genes (DEGs). B Silhouette scores and the sum of squared error were used to identify the optimal number of clusters. The maximum peak of the silhouette score plots and the point at which the sum of squared error begins to diminish (the "elbow" method) determined the optimal number of clusters. C t -distributed stochastic neighbor embedding (t -SNE) and principal component analysis of the DEG profiles. C1 (n = 252) and C2 (n = 333) are colored red and yellow, respectively

---

### A regression-based method to identify differentially expressed genes in microarray time course studies and its application in an inducible Huntington's disease transgenic model [^b57fc5cd]. Human Molecular Genetics (2002). Low credibility.

Time-course studies with microarray technologies provide enormous potential for exploring underlying mechanisms of biological phenomena in many areas of biomedical research, but the large amount of gene expression data generated by such studies also presents great challenges to data analysis. Here we introduce a regression-based statistical modeling approach that identifies differentially expressed genes in microarray time-course studies. To illustrate this method, we applied it to data generated from an inducible Huntington's disease transgenic model. The regression method accounts for the induction process, incorporates relevant experimental information, and includes parameters that specifically address the research interest: the temporal differences in gene expression profiles between the mutant and control mice over the time course, in addition to heterogeneities that commonly exist in microarray data. Least-squares and estimating equation techniques were used to estimate parameters and variances, and inferences were made based on efficient and robust Z-statistics under a set of well-defined assumptions. A permutation test was also used to estimate the number of false-positives, providing an alternative measurement of statistical significance useful for investigators to make decisions on follow-up studies.

---

### The contributions of sex, genotype and age to transcriptional variance in drosophila melanogaster [^aa87e974]. Nature Genetics (2001). Medium credibility.

Here we present a statistically rigorous approach to quantifying microarray expression data that allows the relative effects of multiple classes of treatment to be compared and incorporates analytical methods that are common to quantitative genetics. From the magnitude of gene effects and contributions of variance components, we find that gene expression in adult flies is affected most strongly by sex, less so by genotype and only weakly by age (for 1- and 6-wk flies); in addition, sex x genotype interactions may be present for as much as 10% of the Drosophila transcriptome. This interpretation is compromised to some extent by statistical issues relating to power and experimental design. Nevertheless, we show that changes in expression as small as 1.2-fold can be highly significant. Genotypic contributions to transcriptional variance may be of a similar magnitude to those relating to some quantitative phenotypes and should be considered when assessing the significance of experimental treatments.

---

### The snm procedure guideline for general imaging 6.0 [^638aaec4]. SNMMI (2010). Medium credibility.

SNM Procedure Guideline for General Imaging — matrix size and pixel depth in nuclear medicine acquisitions notes that matrix size is almost always a power of 2 with typical values 64 x 64, 128 x 128, 256 x 256 and 512 x 512, and that non-square matrix sizes also exist for whole-body studies. Each pixel can be represented with a single byte (pixel values ranging from 0 to 255 counts) or with 16 bit words (pixel values ranging up to a maximum of 32k or 64k). Overflow occurs when the number of counts recorded at some given position exceeds the maximum number of counts, and overflow is more likely to occur when using a byte matrix.

---

### Global quantification of mammalian gene expression control [^6eab7aec]. Nature (2011). Excellent credibility.

Gene expression is a multistep process that involves the transcription, translation and turnover of messenger RNAs and proteins. Although it is one of the most fundamental processes of life, the entire cascade has never been quantified on a genome-wide scale. Here we simultaneously measured absolute mRNA and protein abundance and turnover by parallel metabolic pulse labelling for more than 5,000 genes in mammalian cells. Whereas mRNA and protein levels correlated better than previously thought, corresponding half-lives showed no correlation. Using a quantitative model we have obtained the first genome-scale prediction of synthesis rates of mRNAs and proteins. We find that the cellular abundance of proteins is predominantly controlled at the level of translation. Genes with similar combinations of mRNA and protein stability shared functional properties, indicating that half-lives evolved under energetic and dynamic constraints. Quantitative information about all stages of gene expression provides a rich resource and helps to provide a greater understanding of the underlying design principles.

---

### Propagation of error from parameter constraints in quantitative MRI: example application of multiple spin echo tmapping [^508b70e9]. Magnetic Resonance in Medicine (2018). Low credibility.

Purpose

Quantitative MRI may require correcting for nuisance parameters which can or must be constrained to independently measured or assumed values. The noise and/or bias in these constraints propagate to fitted parameters. For example, the case of refocusing pulse flip angle constraint in multiple spin echo T 2 mapping is explored.

Methods

An analytical expression for the mean-squared error of a parameter of interest was derived as a function of the accuracy and precision of an independent estimate of a nuisance parameter. The expression was validated by simulations and then used to evaluate the effects of flip angle (θ) constraint on the accuracy and precision of T⁁2 for a variety of multi-echo T 2 mapping protocols.

Results

Constraining θ improved T⁁2 precision when the θ-map signal-to-noise ratio was greater than approximately one-half that of the first spin echo image. For many practical scenarios, constrained fitting was calculated to reduce not just the variance but the full mean-squared error of T⁁2, for bias in θ⁁≲6%.

Conclusion

The analytical expression derived in this work can be applied to inform experimental design in quantitative MRI. The example application to T 2 mapping provided specific cases, depending on θ⁁ accuracy and precision, in which θ⁁ measurement and constraint would be beneficial to T⁁2 variance or mean-squared error. Magn Reson Med 79:673–682, 2018. © 2017 International Society for Magnetic Resonance in Medicine.

---

### Advances in mixed cell deconvolution enable quantification of cell types in spatial transcriptomic data [^7aea0682]. Nature Communications (2022). High credibility.

Box 2 The SpatialDecon algorithm

1. Run the log-normal deconvolution algorithm.

2. Choose δ as the expression level below which technical noise predominates. For GeoMx data normalized to have expected background = 1, we use δ = 0.5.

3. Define the residuals of the algorithm fit as R = log 2 (pmax(Y, δ)) – log 2 (pmax(B + X, δ)), where pmax(x, δ) is the function replacing all elements of x below δ with δ.

4. For all { i, j } with | R i, j | > 3, set Y i, j to NA. In simulated data, this threshold of 3 performed well, and deconvolution results were not sensitive to the choice of threshold (Supplementary Fig. 9).

5. Re-run the log-normal deconvolution algorithm using the updated Y matrix, obtaining estimatesand covariance matrices.

6. Calculate the standard error for eachwith sqrt.

7. Calculate the p-value for each β i, j with p = 2 (1−ɸ(t = , df = p – K – 1)), where ɸ is the cumulative distribution function of the standard normal distribution. (/is the square root of the Wald statistic, which is asymptotically normal.)

8. Calculate the 95% confidence interval for each β i, j with ± 1.96 1/2

Returnalong with the standard errors and p-values of its elements.

Estimating background

For GeoMx studies, each region's background level can be estimated by taking the mean of the negative control probes. These probes target sequences identified by the External RNA Controls Consortium (ERCC) as alien to the human genome.

---

### Independent control of mean and noise by convolution of gene expression distributions [^062c50b9]. Nature Communications (2021). High credibility.

Gene expression noise can reduce cellular fitness or facilitate processes such as alternative metabolism, antibiotic resistance, and differentiation. Unfortunately, efforts to study the impacts of noise have been hampered by a scaling relationship between noise and expression level from individual promoters. Here, we use theory to demonstrate that mean and noise can be controlled independently by expressing two copies of a gene from separate inducible promoters in the same cell. We engineer low and high noise inducible promoters to validate this result in Escherichia coli, and develop a model that predicts the experimental distributions. Finally, we use our method to reveal that the response of a promoter to a repressor is less sensitive with higher repressor noise and explain this result using a law from probability theory. Our approach can be applied to investigate the effects of noise on diverse biological pathways or program cellular heterogeneity for synthetic biology applications.

---

### STAT3 targets suggest mechanisms of aggressive tumorigenesis in diffuse large B-cell lymphoma [^692e988a]. G3 (2013). Low credibility.

Figure 5
Hierarchical clustering analysis of gene expression. Clustering was performed on the 1545 genes that are differentially expressed at FDR < 0.05 in ABC cell lines vs. GCB cell lines. Green and red blocks, respectively, represent high and low signals in the BR relative to the average, whereas black blocks indicate no difference in expression. Read counts were log transformed to approximate a normal distribution, standardized by cell line, and each gene was normalized with sum of squares set to unity. GCB cell lines are represented by orange bars and ABC cell lines by blue bars. Generated using the heatmap.2 function in the R package gplots.

Figure 6
Differential gene expression. (A) RefSeq genes with differential expression (FDR < 0.05) divided by expression pattern. (B) Examples of differentially expressed genes. CCR7 shows greater expression in the ABC cell lines: SU-DHL2, OCI-Ly3, OCI-Ly10, and U-2932. PRKCA shows greater expression in the GCB cell lines: SU-DHL4, SU-DHL6, SU-DHL10, and OCI-Ly7.

---

### The impact of exercise on gene regulation in association with complex trait genetics [^99731bf3]. Nature Communications (2024). High credibility.

Fig. 2
Tissue-specific differential gene expression from exercise can exceed natural variation.

In this figure we visualize the procedure used to obtain Standardized Effect Sizes. In the numerator of (a) lies a truncated kernel density estimate of the distribution of log 2 FCs induced by exercise at the 8w timepoint. A stacked histogram of estimates forfor expression scores from GTEx (p < 0.10 after IHW correction) is on the left in the denominator. On the right are the inverse-gamma distributions serving to regularize log 2 -normalized expression scores. Together, this results in a value equal to the estimated genetic variance of expression. Taking its square root yields a standard deviation, which we use to divide exercise-induced log 2 FC. In (b), we plot the empirical quantile function for distributions of ratios of each tissue's exercise-induced log 2 (gene expression) / SD(log 2 (gene expression)). As most of the interesting behavior is contained in the tails of each distribution, we applied two separate transforms to the axes of each plot. The horizontal axis, corresponding to a given quantile in (0,1), was logit-transformed. The vertical axis, corresponding to the ratio of DE / SD(log 2 expression), received an inverse hyperbolic sine transformation. The upper panels are in units of standardized phenotypic effect, and the lower in units of standardized genetic effect for those genes and tissues with significant non-zero(IHW α = 0.10, one-sided). Source data for this figure are provided as a Source Data file.

---

### Alternative splicing during theCell cycle [^d500f0fb]. G3 (2020). Medium credibility.

Table 1
Alternatively spliced Cluster 5 genes

Figure 2
Cluster analysis along the diurnal cycle. (A) Sum of squares calculated within each cluster as a measure of variation is (Intra-cluster variation) plotted to estimate the number of clusters for k-mean clustering (B) Heatmap of the PSI values of filtered alternative SS The white to black transition on the heatmap represents PSI value that ranges from 0 to 0.6. The numbers on the right of the heatmap are cluster numbers referred to in the text and x-axis are timepoints color-coded by three phases. (C) Mean PSI value of Cluster 5 alternative SS events are plotted for each timepoint (bar represents color code by phase: light G1: yellow, S-M: orange, dark G1: blue) where dot represents the mean PSI value across genes and error bars represent standard error. (D) Fold change in the RPKM value of Cluster 5 genes. compared to their mean expression value across all timepoints (bar represents color code by phase: light G1: yellow, S-M: orange, dark G1: blue). The dot represents the mean fold change across genes and error bar represents standard error.

These splicing events follow a coordinated splicing pattern with the diurnal cell cycle (Figure 2C), and thus, we followed up on these events. Since changes in the gene expression could affect the detection of a particular SS at a given timepoint, we asked if this coordinated splicing pattern is related to differential gene expression across these genes. The RPKM values of these 26 genes (Supplementary Dataset 1 and 2) across all timepoints were normalized by their mean expression value to give a fold-change in gene expression compared to the mean expression value. The average value of the fold-change of these genes and their standard deviation is plotted for all timepoints (Figure 2D). Although there is trend of increased gene expression among these genes at the Dark G1 timepoint compared to the Light G1, the mean fold change across these genes from their mean expression value is less than twofold at all timepoints (Figure 2D). This suggests that most of these genes do not show large and changes in gene expression and that AS is regulated independently of gene expression.

---

### Segmentation aware probabilistic phenotyping of single-cell spatial protein expression data [^b37572a0]. Nature Communications (2025). High credibility.

Fig. 2
A plausibility score quantifies how well clusters align with known protein co-expression patterns.

A The plausibility score is derived by collating pairs of proteins known to not be co-expressed or show conditional expression. The score is then defined by computing the proportion of centroids that lie in the expected regions under some threshold of expression. For pairs not co-expressed, this is the proportion of centroids with values that do not both exceed the threshold (green); for conditional expression, this is the proportion of centroids that do not have expression of one protein above the threshold without the other (yellow). B To validate the plausibility score on real data, we took three IMC datasets and separated cells into those that have neighbors (N) or no neighbors (NN). We clustered each with three clustering algorithms and computed the plausibility score on the centroids. Cells with no neighbors and therefore likely fewer segmentation errors show significantly higher plausiblity scores than those with neighbors. This was repeated for 50 random subsamples of 10,000 cells each with a two-sided Wilcoxon rank-sum test with no multiple hypothesis testing correction used. Boxplots represent the first and third quantiles of the data, with upper and lower whiskers extending to at most 1.5x the interquartile range. C The plausibility score quantified across three datasets, three normalization scenarios, and three hyperparameter settings. The black triangles represent the score at initialization using three popular clustering algorithms (FS: FlowSOM, KM: K-means; PG: PhenoGraph) and colored lines after training. The black squares represent the two step approach of first removing likely doublets. Source data are provided as a Source Data file.

---

### Addressing sex as a biological variable in preclinical models of lung disease: an official American Thoracic Society research statement [^044a47b9]. American Journal of Respiratory and Critical Care Medicine (2025). High credibility.

Figure 1 logic tree — delineating mechanisms behind sex differences in experimental lung disease phenotypes outlines a pathway from the question 'Does the phenotype show a sex difference?' to 'Discriminate effects of gonadal hormones vs. sex chromosomes', including 'Do changes in levels of gonadal hormones (gonadectomy/ hormone replacement) explain the sex difference?' with mechanistic questions ('Which hormones cause sex difference? Which receptors mediate hormone effect? When does hormone act? Where is hormone produced? Which cell type is the target of hormone effect?'). The algorithm incorporates the four core genotypes (FCG) model — 'Use FCG model to test for both sex chromosome and gonadal hormone effects' — and downstream steps ('Identify downstream molecular effects of hormones in specific cell types mediating sex differences' and 'Measure interactions of hormones and sex chromosome genes'). For sex chromosome mechanisms, it directs 'Use XY* model to discover X effect or Y effect', 'Manipulate expression of specific X or Y genes to discover which genes account for sex chromosome effect', and 'Identify downstream molecular effects of sex chromosome genes in specific cell types mediating sex differences'; if no difference is observed, 'Consider sex-specific effects that counterbalance each other'.

---

### Application of response surface methods to determine conditions for optimal genomic prediction [^3e2cd0aa]. G3 (2017). Low credibility.

Since the true response function is unknown, we have to approximate f. Under standard smoothness assumptions, a low-order polynomial function provides a good local approximation to the true f. For example, a first-order main effects model can be written aswhereare coded variables. is the unknown intercept, andare the unknown regression coefficients. Equation 5 is called a main effects linear model because it only contains the linear effects of the p factors on the response with no interaction terms. When the model in Equation 5 includes interactions, we call it the first-order model with interaction, and write it asIn situations such as those illustrated in Figure 1, a second-order model can be also used to model the unknown response function f. A second-order polynomial provides a good local approximation to almost any surface because it can have different functional forms and it is easy to estimate its parameters. In general, the second-order model can be written asLet β denote the vector of unknown regression coefficients with dimension depending on the model. With an interaction term or a second-order model we can introduce curvature into the estimated surface. The model equation can be written in a concise matrix notation aswhere y is anvector of observations, X is andimensional matrix of the levels of the coded explanatory variables, β is avector of the coefficients, and ϵ is anvector of the random error terms. An ordinary least-squared estimator of the model coefficients can be written aswith the variance–covariance matrix ofhaving the formwhereis the variance-covariance matrix ofTo estimate regression coefficients, β in the response function requires data from experiments designed to meet the objective. If the objective is to approximate the response surface, a frequently used treatment design is the factorial. For example, temperature and the degree of drought could be two factors affecting yield, but the number of factors could be more than two and the possible values per factor can be qualitative, quantitative, and numerous. For the example illustrated in Figure 1, a reasonable full factorial model would consist offactor combinations. To observe a response at each factor combination when there are two levels for the p factors, unreplicated treatment combinations are required and the design is called thefactorial design. When p is large and the range of possible values of each factor is also large, finding the combination of the p factors needed to approximate the response surface increases exponentially. For example, three factors with two levels each requirestreatment combinations; whereas if the number of factors is five, the number of factor combinations isAt least some of the treatment combinations would need to be replicated if we want an estimate of the variance of residuals

---

### All-optical spatiotemporal mapping of ROS dynamics across mitochondrial microdomains in situ [^d826061a]. Nature Communications (2023). High credibility.

Optical control of ROS generation in single mitochondria in situ

ROS diffusion between mitochondria and the cytosol governs cellular responses to changes in metabolism, but the dynamics of ROS movement between these regions remain unknown. To monitor ROS dynamics in mitochondria, we first co-expressed the superoxide-generating protein tandem-KillerRed (KR) and H 2 O 2 biosensor HyPer7, both targeted into the matrix of mitochondria in HEK293T cells and later in mouse embryonic fibroblasts (MEFs). The photosensitizer KR has a known superoxide quantum yield. HyPer7 has been previously shown to be highly selective for H 2 O 2 and sensitive enough to detect gradients of mitochondrial ROS in living organisms. We reasoned that the coupling expression of these two proteins could record single mitochondrial ROS responses (Fig. 1a).

Fig. 1
Spatiotemporal manipulation and monitoring of ROS in single mitochondria.

a Schematic representation of all optical ROS generation and detection in mitochondria. b Imaging and analysis workflow to track spatiotemporal mitochondrial responses relative to single mitochondrial ROS photogeneration in HEK293T cells. c Representative images, where dotted line indicates a single cell expressing matrix-targeted HyPer7 and KR. Denoted circle indicates static spot stimulation used to pulse ROS photogeneration. d Inset from c highlighting transient elongation and contact of photostimulated mitochondria. e Single mitochondrial responses of HyPer7 and KR intensities normalized to area and baseline. f Comparison of HyPer7 and KR responses at first frame immediately following pulse 1, 10 min following first stimulation, immediately following pulse 2, and 10 min following second stimulation. Two-way ANOVA with Tukey post-hoc multiple comparisons. g Decay of HyPer7 following stimulation 1 and 2 fitted with a nonlinear variable plateau followed by single phase decay, mean ± SEM. Decay compared with one-sided extra sum-of-squares F test. h Mitochondrial regional proportion of proximal and distal subpopulations relative to total in the cell over time. i Area of individual mitochondria in subpopulations over time through ROS photostimulation. Two-way ANOVA with Holm-Šídák's post-hoc multiple comparisons, mean ± SEM. j Form factor of individual mitochondria in subpopulations over time through ROS photostimulation. Two-way ANOVA with Tukey post-hoc multiple comparisons, mean ± SEM. Green bars indicate single frames of KR photostimulation. Mean ± SEM, N = 39 distal, 54 proximal, and 95 non-stimulated mitochondria per frame per group, on average. ✱ p < 0.05, ✱✱ p < 0.01, ✱✱ p < 0.001. Scalebars denote 5 µm.

---

### Advances in mixed cell deconvolution enable quantification of cell types in spatial transcriptomic data [^bedbedac]. Nature Communications (2022). High credibility.

Mapping cell types across a tissue is a central concern of spatial biology, but cell type abundance is difficult to extract from spatial gene expression data. We introduce SpatialDecon, an algorithm for quantifying cell populations defined by single cell sequencing within the regions of spatial gene expression studies. SpatialDecon incorporates several advancements in gene expression deconvolution. We propose an algorithm harnessing log-normal regression and modelling background, outperforming classical least-squares methods. We compile cell profile matrices for 75 tissue types. We identify genes whose minimal expression by cancer cells makes them suitable for immune deconvolution in tumors. Using lung tumors, we create a dataset for benchmarking deconvolution methods against marker proteins. SpatialDecon is a simple and flexible tool for mapping cell types in spatial gene expression studies. It obtains cell abundance estimates that are spatially resolved, granular, and paired with highly multiplexed gene expression data.

---

### Transient power-law behaviour following induction distinguishes between competing models of stochastic gene expression [^0a60715c]. Nature Communications (2025). High credibility.

Inferring the number of inactive gene states is difficult from steady-state data

In Fig. 2 the steady-state mRNA count distributions of thousands of rate parameter sets for the N = 3, 4, 5 state models are compared with those of their effective telegraph models (computed using the previously detailed three-step procedure). Note that to ensure biological relevance, the rate parameter ranges for each model were chosen to comfortably cover the bounds of the telegraph model rate parameters estimated using a range of eukaryotic data in various published studies (see Table 1 of ref.for these estimates and see Supplementary Note 2 for further details on generating the rate parameter sets).

Fig. 2
The steady-state mRNA count distribution of the N -state model can often be well fit by an effective telegraph model.

Thousands of rate parameter sets of the N -state model (N = 3, 4, 5) were sampled in the range relevant for eukaryotic gene expression. For each parameter set the mapping in Eq. (2) was used to obtain the rate parameters of an effective telegraph model. A – C P-P plots comparing the cumulative distribution function (CDF) of the N -state and effective telegraph models. These are constructed from the 500 rate parameter sets with the largest Wasserstein distance (WD) values between the distributions of the two models. Deviations from the line y = x (red) indicate differences between the distributions. D – G Typical steady-state mRNA count distributions of the 5-state (solid blue lines) and effective telegraph models (histograms) for four classes of distributions (Shape I: Unimodal with Fano factor < 2; Shape II: Unimodal with Fano factor ≥ 2; Shape III: Bimodal with one peak at zero and another at a non-zero value; Shape IV: Bimodal with peaks at non-zero values. H Boxplots displaying summary statistics of the WD between the steady-state distribution of mRNA counts of the N -state and effective telegraph model. The horizontal line and the box show the median and the interquartile range, respectively; whiskers extend to the 10th and 90th percentiles; sample sizes given in Supplementary Table 2. I – K Bar charts displaying the percentage of each distribution shape sampled across the parameter space. The agreement between the N -state and its effective telegraph model becomes worse as N increases and is worst for Shape IV because this shape is qualitatively impossible to capture by the telegraph model. See Supplementary Note 2 for implementation details.

---

### Approaches to working in high-dimensional data spaces: gene expression microarrays [^8ae2f7fd]. British Journal of Cancer (2008). Low credibility.

This review provides a focused summary of the implications of high-dimensional data spaces produced by gene expression microarrays for building better models of cancer diagnosis, prognosis, and therapeutics. We identify the unique challenges posed by high dimensionality to highlight methodological problems and discuss recent methods in predictive classification, unsupervised subclass discovery, and marker identification.

---

### National Lipid Association recommendations for patient-centered management of dyslipidemia: part 2 [^118cd013]. Journal of Clinical Lipidology (2015). Medium credibility.

Sex-specific coronary heart disease (CHD) and stroke outcomes are synthesized in a meta-analysis and displayed as forest plots for CHD event and for stroke in women and men. Solid squares represent the odds ratios in individual trials and have a size proportional to the inverse of variance, with horizontal lines, diamonds, and squares denoting the 95% confidence intervals for individual trials and summary statistics. Pooled estimates were computed from a random effects model.

---

### Cubic regression-based degree of correction predicts the performance of whole bisulfitome amplified DNA methylation analysis [^3ce2ab8c]. Epigenetics (2012). Low credibility.

Figure 1. Schematic representation of the experimental design.

Table 1. Raw and corrected b values, sums of squared errors of the differences between estimated and real methylation levels, and coefficients of variation between replicates are shown for each gene and methodology, expressed as average values of the 9 points of the curve and standard deviations

Figure 2. Degree of bias and correction in each experiment. In all graphs, the x axis represents the real methylation levels, while the experimental (black diamonds and squares) and estimated (gray triangles) values are on the y axis. The derived cubic polynomial curve is shown for one of the sets of experimental results (diamonds), presenting in most cases a preferential amplification of unmethylated alleles (b < 1, except for MAP3K7 with conventional pyrosequencing). Gray triangles plot the real values vs. the levels estimated after the cubic equation-based correction and are fitted to a y = x linear regression (discontinuous line). Linear correlation coefficients are shown for each experiment.

Assays with a correlation coefficient higher than 0.99 in the estimated vs. real value linear regression (Table 1) were able to discriminate clearly between all adjacent points of the 9-point methylation curves. This was the case in 7 out of 8 target genes analyzed with the conventional pyrosequencing method but only in 2 of the genes assayed with qMAMBA. In the plots with lower correlation values, several adjacent points of the dilution curve (differing in 12.5% methylated DNA) were scored with similar estimated values and could not be discriminated, as highlighted in Figure 2.

Sum of squared errors were calculated in order to quantify the accumulated difference between real and estimated methylation values with different target genes and techniques. In general, sum of squared error values were notably higher in the qMAMBA results. On the other hand, variation coefficients and their standard deviations across the different curve points were also calculated and showed more variation between replicates in the case of qMAMBA results (Table 1).

---

### Mantel statistics to correlate gene expression levels from microarrays with clinical covariates [^710bc74d]. Genetic Epidemiology (2002). Low credibility.

Mantel statistics provide an additional step to standard approaches in the analysis of gene expression and covariate data, allow the calculation of standard statistics such as correlation, partial correlation, and regression coefficients, and, with permutation tests, provide P values for these statistics to relate the sample covariates to the expression levels. In this article we describe the Mantel statistics and illustrate their use and interpretation with data from a study of seven human oligodendrogliomas (brain tumors) where expression levels of 1013 genes and five covariates were previously analyzed using standard approaches. In the previous analysis of these data, qualitative relationships were found between gene expressions and two of the clinical covariates. We show in this article how the Mantel statistics are able to formally quantify and provide P values to determine statistical significance of these relationships. We also show how the Mantel statistics can be used to rank subsets of genes, found using standard clustering methods, in terms of differential expression across samples.

---

### GrandR: a comprehensive package for nucleotide conversion RNA-seq data analysis [^ac05e5a0]. Nature Communications (2023). High credibility.

Fig. 5
Estimating changes in synthesis or degradation from snapshot experiments.

a – d Scatterplots comparing simulated log2 fold changes against maximum-a-posteriori (MAP) estimates of RNA synthesis log2 fold changes (a), MAP estimates of RNA half-life log2 fold changes (b), observed new RNA log2 fold changes (c) or old RNA log2 fold changes (d). Three replicates at 2 h of labeling were simulated after perturbing synthesis (a, c) or half-lives (b, d) for 2 h and compared against unperturbed controls. The root mean square deviations (RMSD) over all n = 10,835 simulated genes are indicated for each comparison. e Boxplots showing the log2 fold changes of new RNA or of estimated synthesis rates either for the simulated samples with perturbed RNA half-lives (perturbed HL) or the unperturbed samples vs the controls. Separate distributions for genes from different simulated half-live classes are shown as indicated (0–2 h, n = 1621 genes; 2–4 h, n = 2996 genes; 4–6 h, n = 1940 genes; 6–8 h, n = 1182 genes; > 8 h, n = 3096 genes; center line, median; box limits, upper and lower quartiles; whiskers, 1.5x interquartile range; points, outliers). f Empirical cumulative distributions showing log2 fold changes of either estimated synthesis rates (yellow) or RNA half-lives (blue). For each distribution, either unperturbed samples (solid lines), samples with perturbed synthesis rates (dashed lines) or samples with perturbed half-lives (dotted lines) were compared against controls. Distributions are shown for all genes, only for genes with short RNA half-lives t 1/2 < 2 h, and for simulated labeling of 2 h or 4 h, as indicated. g, h Scatterplots comparing simulated log2 fold changes against MAP estimates of RNA synthesis log2 fold changes (g) or RNA half-life fold changes (h). Three replicates at 2 h of labeling were simulated with synthesis rates (g) or degradation rates (h) slowly approaching a perturbed state during 2 h of labeling. RMSDs over all n = 10,835 simulated genes are indicated for each comparison. i Scatterplot comparing log2 fold changes of RNA half-lives estimated from the full progressive labeling time courses using the NLLS method (x -axis) or the MAP estimator from our Bayesian model using the 2 h time point only. The Pearson correlation and the associated P -value (two-sided t -test) are indicated.

---

### Perturbations of transcription and gene expression-associated processes alter distribution of cell size values in… [^cab628e3]. G3 (2019). Medium credibility.

Results

Rationale

The approach we followed in this study is shown schematically in Figure 1. How different values of a single parameter are distributed can be instructive for the underlying processes leading to its distribution pattern. Accurately fitting the measured variable to a univariate distribution is also necessary for its proper statistical analysis, when determining how removed a given observation (e.g. a mutant) is from the most typical one (wild type) in a population. With regards to the size of individual organisms, the usual pattern is that deviations from the common type are not symmetrical. Instead, small individuals tend to be more frequent than large ones, leading to distributions which are positively skewed, with a right-side tail. The sizes of bacterial and animal cells have been modeled on lognormal distributions. To our knowledge, although S. cerevisiae is a prime model system in studies of size control, how size is distributed in this organism has not been examined. Consequently, our objectives for this study were: First, determine how cell size is distributed in S. cerevisiae (Figure 2). Second, use the distribution model that fits the best to empirical data as a metric to identify mutants that deviate the most from that distribution (Figures 3, 4). Third, validate the outliers experimentally (Figure 5), and test the role of the corresponding biological processes in determining size distributions (Figure 6).

---

### Dosage-sensitive miRNAs trigger modulation of gene expression during genomic imbalance in maize [^c26f5f18]. Nature Communications (2022). High credibility.

Fig. 7
Scatter plots of MIRNA expression in each ploidy series and B chromosome series.

a Scatter plots in each ploidy series compared with diploids. Analysis was conducted as described in Fig. 2. A FC of 1.0 (logFC of 0) represents no change. FCs of 0.5 (1X/2X), 1.33 (4X/3X), 1.5 (3X/2X), and 2.0 (4X/2X) represent a gene-dosage effect, whereas FCs of 2.0 (1X/2X), 0.75 (4X/3X), 0.67 (3X/2X), and 0.5 (4X/2X) represent the inverse ratio of MIRNA expression. These FC values are demarcated with labeled vertical lines in red (0.5), pink (0.67), orange (0.75), black (1.0), blue (1.33), green (1.5), and purple (2.0). b Scatter plots of diploids with one B chromosome compared with the corresponding control with no B (1B/0B). Source data are provided in Supplementary Data 4.

---

### A single-cell comparison of adult and fetal human epicardium defines the age-associated changes in epicardial activity [^c1aaca77]. Nature Cardiovascular Research (2022). High credibility.

Gene–gene co-occurrence and epicardial gene module construction

Cells annotated as epicardium after clustering were isolated in a new matrix, and a set of epicardial features for clustering was selected using differential expression analysis between adult and fetal epicardial cells (Wilcoxon rank-sum test; P < 1× 10–10, log 2 fold change > 0.5) (Supplementary Table 10). After removing the previously identified control genes, the epicardial matrix of 1,912 cells across 1,594 genes was binarized, counting positive expression as a value of at least 1. For gene module construction, this matrix was further subset to omit nuclei barcodes, as gene clustering was shown to be affected largely by their expression in nuclei or cells, giving a binary matrix of 1,315 cells and 1,594 genes. However, nuclei were added back into the matrix after module construction, and we observed that nuclei largely retained gene module patterns, independently validating our results. We implemented the approach by Qiu (ref.) in R to cluster gene-dropout patterns. In brief, we calculated the co-occurrence of each gene pair across all cells with a modified chi-square statistic. Then, for each gene pair, all chi-square statistics below a given threshold were discarded to retain only the high-scoring gene–gene pairs. This threshold was calculated using random permutations of the data. An undirected graph of highly concerted genes was then formed from the remaining gene pairs, weighted by the chi-square statistics and adjusted by a Jaccard index. Finally, this gene–gene graph was clustered using a conservative Louvain method for community detection, removing all clusters with fewer than 20 genes. Genes in resulting gene modules were ordered by their mean chi-square value with other genes in the module, ranking the genes by pattern specificity. New gene module commitment features for all epicardial cells, including nuclei, were calculated by the mean of binarized expression of each gene module, and a PCA was carried out. We represented components 2 and 4, as component 1 was technical noise, correlating with library size and source (Kendall rank correlation, P < 0.05) (Fig. 3b and Extended Data Fig. 3), whereas components 2 and 4 correlated with cell type and age and were orthogonally represented in the PCA. The Louvain method for community detection was used to generate epicardial states, and states were ordered by age using their mean of PCA component 2, which highly correlated with the sample-ranked age of each cell (Kendall's tau = –0.67, P < 0.01, n = 1,912). Gene set overrepresentation analysis of Gene Ontology terms across gene modules was carried out using the R package gprofiler2 (ref.) against a background of all expressed genes in epicardial cells.

---

### Controlling gene expression with deep generative design of regulatory DNA [^5e38a70f]. Nature Communications (2022). High credibility.

We tested different functional aspects of ExpressionGAN and compared it with existing solutions experimentally or computationally: (i) experimentally validating ExpressionGAN-generated sequences (Fig. 6), (ii) comparing the use of the whole gene regulatory structure to single regulatory regions and shorter promoter parts, commonly used with mutagenesis, (Fig. 4), (iii) comparing the properties of generated sequences to natural ones (Fig. 2) and testing whether they contain known DNA regulatory grammar and properties that drive gene expression (Fig. 5), and (iv) contrasting the generative approach with a standard mutational one that does not inherently model the allowed sequence-function landscape (Fig. 6). The experimental analysis was designed specifically to test the most divergent possible sequence variants, with an average sequence identity well below 70% both to natural sequences and amongst themselves (Fig. 6a, b, Supplementary Fig. 15). This validated the approach in vivo across 3 orders of magnitude of expression levels with a wide range of unique sequence variants (Fig. 6d), not merely identifying mutational varieties of a common conserved and active regulatory scaffold. Furthermore, we found that sequences spanning the whole gene regulatory structure improve the achievable dynamic range of gene expression compared to the common single regulatory regionsand shorter proximal, and core promoter parts(Fig. 4a, b). Despite that in specific cases even single nucleotide variations can have a strong effect on expression, generally due to the natural evolutionary prerequisites of regulatory adaptability and robustness, short regulators simply cannot precisely control the full amount of expression in comparison to longer sequences spanning multiple regulatory regions, where regulatory adaptation is orchestrated across a range of meticulous and interacting sequence optimizations. Consequently, the limitation and inability of current methods to design anything but short sequences spanning single regulators gives strong support for the use of generative approaches, capable of designing whole gene regulatory structures by learning from natural genomic and transcriptomic data directly, without requiring any screening experiments. A notable positive consequence of using transcriptomic data is also the ease of relating sequence to function, namely, expression levels and their dynamic ranges, whereas most alternative approaches focus primarily on protein expression via relative fluorescence intensity, or cell growth, making it harder to relate their measurements to a comprehensible gene expression scale (e.g. TPM) and thus potentially concealing more limited dynamic ranges than are initially understood. Moreover, despite using here the most relevant region sizes based on previously published results, we note that the functionality of the gene regulatory structure requires further extensive research in order to decipher key regulatory effects and interactions, while also validating the observations and applicability with different reporter genes, organisms, and tissues. Nevertheless, since recent optimized short sequence designs, are not capable of driving gene expression fully, with a large range of expression control remaining potentially untapped (Fig. 4d, f), the use of the whole gene regulatory structure offers a promising development focus for unlocking the full potential of gene expression control.

---

### Module networks: identifying regulatory modules and their condition-specific regulators from gene expression data [^7ce726eb]. Nature Genetics (2003). Medium credibility.

Much of a cell's activity is organized as a network of interacting modules: sets of genes coregulated to respond to different conditions. We present a probabilistic method for identifying regulatory modules from gene expression data. Our procedure identifies modules of coregulated genes, their regulators and the conditions under which regulation occurs, generating testable hypotheses in the form 'regulator X regulates module Y under conditions W'. We applied the method to a Saccharomyces cerevisiae expression data set, showing its ability to identify functionally coherent modules and their correct regulators. We present microarray experiments supporting three novel predictions, suggesting regulatory roles for previously uncharacterized proteins.

---

### Water proton MR properties of human blood at 1.5 tesla: magnetic susceptibility, T (1), T (2), T* (2), and non-lorentzian signal behavior [^dc746839]. Magnetic Resonance in Medicine (2001). Low credibility.

Accurate knowledge of the magnetic properties of human blood is required for the precise modeling of functional and vascular flow-related MRI. Herein are reported determinations of the relaxation parameters of blood, employing in vitro samples that are well representative of human blood in situ. The envelope of the blood (1)H(2)O free-induction decay signal magnitude during the first 100 msec following a spin echo at time TE is well- described empirically by an expression of the form, S(t) = S(o). exp[-R(*)(2). (t - TE) - AR*. (t - TE)(2)]. The relaxation parameters AR* and R(*)(2) increase as a function of the square of the susceptibility difference between red blood cell and plasma and depend on the spin-echo time. The Gaussian component, AR*, should be recognized in accurate modeling of MRI phenomena that depend upon the magnetic state of blood. The magnetic susceptibility difference between fully deoxygenated and fully oxygenated red blood cells at 37 degrees C is 0.27 ppm, as determined independently by MR and superconducting quantum interference device (SQUID) measurements. This value agrees well with the 1936 report of Pauling and Coryell (Proc Natl Acad Sci USA 1936;22:210–216), but is substantially larger than that frequently used in MRI literature. Magn Reson Med 45:533–542, 2001.

---

### 2018 ACC / HRS / NASCI / SCAI / SCCT expert consensus document on optimal use of ionizing radiation in Cardiovascular imaging: best Practices for safety and effectiveness: a report of the American college of cardiology task force on expert consensus decision pathways [^ca95c403]. Journal of the American College of Cardiology (2018). Medium credibility.

Kerma-area product (KAP) in cardiovascular x-ray fluoroscopy — definition, units, and determinants — is commonly used as a metric to estimate a subject's total absorbed dose and incorporates both dose and exposed tissue volume into a single measurement; KAP is expressed in units of Gy · cm2 and is calculated by multiplying the beam air kerma by its cross-sectional area, with some x-ray system manufacturers reporting μGy· m2, where 1 Gy · cm2 = 100 μGy· m2; air kerma is a measure of dose intensity (measured in J/kg), and air kerma and KAP represent cumulative doses from an exposure, not exposure rates; in a diverging x-ray beam, KAP is independent of the distance from the source because the beam intensity decreases proportionally to the square of the distance while the beam area increases with square of the distance; KAP is affected by air kerma output and by collimation or field size such that, if exposure intensity is constant, reduction in exposure field size decreases KAP, and at a constant exposure field size, increasing radiation output increases KAP, which underscores the importance of minimizing the exposed field size in x-ray fluoroscopic examinations.

---

### Independent control of mean and noise by convolution of gene expression distributions [^68fa797c]. Nature Communications (2021). High credibility.

One important limitation to all of these previous approaches is that they rely upon genetic parts, circuits, or pathways that are native to or have been optimized to function in a particular organism. As a result, substantial re-engineering may be required to achieve the same results in each new organism of interest. Additionally, there may be fundamental limitations on the levels of gene expression and noise that can be achieved using these approaches. For example, a two-step cascade primarily allows control of extrinsic noise as it relies on transmission of noise from the upstream regulator to the output. Likewise, modulation of promoter kinetics is expected to primarily modulate intrinsic noiseand is unlikely to be effective at high copy numbers.

Here, we show that combining the protein expression distributions from multiple promoters in a single cell is a generalizable and straightforward strategy to achieve robust and independent control of mean and noise over a wide area. To this end, we first use a simple theoretical model to reveal that the mean and noise of a population distribution can be independently controlled using two co-expressed and orthogonally regulated inducible promoters (IPs). We then implement this approach experimentally by constructing low and high noise generating IPs activated by the addition of two separate inducer molecules in E. coli. Next, we show that mean and noise of total gene expression can be manipulated using inducer combinations to control the activity of each IP. We characterize the steady-state behavior of cells harboring the IP pair and present a simple mathematical model to predict mean and noise from inducer concentrations. Next, we show that our experimental gene expression profiles can be predicted with high accuracy by simulating convolutions between the distributions contributed by each IP. Finally, we use our approach to independently tune mean and noise in the expression of a bacterial transcriptional repressor and analyze how each affects the activity of a target promoter independently.

---

### Regional brain iron and gene expression provide insights into neurodegeneration in Parkinson's disease [^f6702640]. Brain (2021). Medium credibility.

Partial least squares regression

We used PLS regression to examine the association between the healthy brain transcriptome and cortical QSM in Parkinson's disease, as this technique is well suited to the high collinearity of gene expression data.PLS regression is a multivariate analysis technique, similar to principal component analysis, which combines dimension reduction and linear regression, producing components from X (the 180 × 15 475 predictor matrix of 180 regional mRNA measurements for 15 475 genes) that have maximum covariance with Y (the 180 × 1 regional QSM score vector). The second PLS component (PLS2) was used to weigh and rank gene predictor variables. In total, 10 000 permutations based on sphere-projection-rotationsof the QSM-score cortical map were examined to test the null hypothesis that PLS2 explained no more variance in Y than chance. Bootstrapping was used to estimate the variability of each gene's positive or negative weight on PLS2 and the ratio of the weight of each gene to its bootstrapped standard error was used to rank its contribution to the PLS2. All PLS and bootstrapping analyses were conducted in MATLAB. We tested the null hypothesis of zero weight for each gene using a false discovery rate inverse quantile transformation correction to account for winner's curse bias using R version 3.6.1. Only genes that survived this correction at Q < 0.05 were included in the enrichment analyses, and upweighted and downweighted genes were assessed separately.

Gene ontological analysis

We used the g:Profilertoolset, implemented in R, to perform a gene ontological (GO) enrichment analysis of the significant positively and negatively weighted genes defined by PLS2. We filtered the resulting list of GO terms by retaining only those that were significantly enriched at P < 0.05 (corrected for multiple comparisons using the g:SCS algorithm) and discarded the terms associated with > 2500 genes as being too general. To reduce and visualize the GO terms, we used the REViGO web page tool, which is based on semantic similarity.

We performed additional GO enrichment analyses using R to mitigate against the possibility of false-positive bias for GO terms in the enrichment analyses of brain-wide transcriptomic data due to null models not accounting for gene-gene co-expression and spatial autocorrelation present within such data. Specifically, we ran GO enrichment analyses for both a random and spatial-spin permutation of our QSM score data (generated in MATLAB) and compared the associated GO terms to those arising from our main analysis.

---

### Dissecting gene expression changes accompanying a ploidy-based phenotypic switch [^878f2324]. G3 (2017). Low credibility.

Characterization of genes commonly differentially expressed in the chromosome XV and XVI disomes

In our model of the mechanisms by which aneuploidy can affect gene expression (Figure 1B), we specified two mechanisms that could produce effects on gene expression unique to each aneuploid and two mechanisms that could produce similar effects on transcription across multiple aneuploids. To assess the relative contribution of shared vs. disome-specific factors in the gene expression patterns of our disomes, we examined the degree of similarity between the expression patterns of the two disomes. After accounting for direct copy number effects, by twofold downward adjustment of expression from the disomic chromosomes, the differential expression profiles of the two disomes, relative to F45, were similar (Figure 5), with an R of 0.70 (Pearson test, two-tailed, t = 74.5175, df = 5776, p-value < 1e−15). The same relationship (R = 0.71) was seen when only genes on chromosomes I–XIV were considered. More genes were repressed in each disome (ChrXV: 2171, ChrXVI: 1852) than induced (ChrXV: 1307, ChrXVI: 1149), at the multiple hypothesis corrected p < 0.01 level. Given their similarity, it appears that the differential gene expression patterns of the two disomes are dominated by shared, rather than disome-specific, factors.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^cbffc27e]. CDC (2011). Medium credibility.

Appendix G. Mathematical formula for sample size — sample size required to detect the difference of GM between two subpopulation groups defines a z test with null hypothesis GM1 = GM2 or GMmax/GMmin = 1 and alternative GM1 ≠ GM2 or GMmax / GMmin > 1, where GMmax = max(GM1, GM2) and GMmin = min(GM1, GM2). It considers power W (say 80% chance) to detect that one group's GM is at least k fold higher and gives the p-value as p = Prob(Z ≥ z) = 1 − φ−1(z) with Z ~ Normal (0,1). Given α (e.g., 0.05) and target ratio k, power is W = Prob (Z > φ−1(1 − α) − log10(k)/(S√(1/n1 + 1/n2))), where S is the expected standard deviation of log10(VL) in the population of interest; when n1 = n2 = n, W = Prob (Z > φ−1(1 − α) − log10(k)/(S√(2/n))). The required sample size is n = 2[(φ−1(1 − α) − φ−1(1 − W))S/log10(k)]^2, and tables are provided for W = 0.8 and W = 0.9 with α = 0.05.

---

### American Thyroid Association guide to investigating thyroid hormone economy and action in rodent and cell models [^4ebd4708]. Thyroid (2014). Medium credibility.

Gene expression as a marker of thyroid hormone status — T3 target genes can be either positively or negatively regulated, and exploratory screens indicate that on average, approximately 50% of the T3-responsive genes display increased mRNA levels and 50% display decreased levels in response to T3. Even with limitations, the mRNA level of selected genes provides a useful indicator of the response status of the tissue.

---

### 2018 ACC / HRS / NASCI / SCAI / SCCT expert consensus document on optimal use of ionizing radiation in cardiovascular imaging: best practices for safety and effectiveness [^0defde76]. Catheterization and Cardiovascular Interventions (2018). Medium credibility.

Kerma-area product (KAP) in x-ray fluoroscopy — KAP is commonly used to estimate a subject's total absorbed dose and reflects both dose and exposed tissue volume; air kerma is a measure of dose intensity (measured in J/kg). KAP is expressed in units of Gy
- cm2 and is calculated by multiplying the beam air kerma by its cross-sectional area; some manufacturers report KAP in μGy·m2 with the conversion 1 Gy·cm2 = 100 μGy·m2, and air kerma and KAP represent cumulative doses from an exposure, not exposure rates. In a diverging x-ray beam, KAP is independent of distance from the source because beam intensity decreases with the square of distance while beam area increases with the square of distance. KAP is affected by air kerma output and by collimation or field size, so if exposure intensity is constant, reducing field size decreases KAP, whereas at constant field size increasing radiation output increases KAP, underscoring the importance of minimizing exposed field size in x-ray fluoroscopic examinations.

---

### Transcriptional programming using engineered systems of transcription factors and genetic architectures [^a1b0a314]. Nature Communications (2019). High credibility.

The control of gene expression is an important tool for metabolic engineering, the design of synthetic gene networks, and protein manufacturing. The most successful approaches to date are based on modulating mRNA synthesis via an inducible coupling to transcriptional effectors. Here we present a biological programming structure that leverages a system of engineered transcription factors and complementary genetic architectures. We use a modular design strategy to create 27 non-natural and non-synonymous transcription factors using the lactose repressor topology as a guide. To direct systems of engineered transcription factors we employ parallel and series genetic (DNA) architectures and confer fundamental and combinatorial logical control over gene expression. Here we achieve AND, OR, NOT, and NOR logical controls in addition to two non-canonical half-AND operations. The basic logical operations and corresponding parallel and series genetic architectures represent the building blocks for subsequent combinatorial programs, which display both digital and analog performance.

---

### A bottom-up approach to gene regulation [^bfd00a10]. Nature (2006). Excellent credibility.

The ability to construct synthetic gene networks enables experimental investigations of deliberately simplified systems that can be compared to qualitative and quantitative models. If simple, well-characterized modules can be coupled together into more complex networks with behaviour that can be predicted from that of the individual components, we may begin to build an understanding of cellular regulatory processes from the 'bottom up'. Here we have engineered a promoter to allow simultaneous repression and activation of gene expression in Escherichia coli. We studied its behaviour in synthetic gene networks under increasingly complex conditions: unregulated, repressed, activated, and simultaneously repressed and activated. We develop a stochastic model that quantitatively captures the means and distributions of the expression from the engineered promoter of this modular system, and show that the model can be extended and used to accurately predict the in vivo behaviour of the network when it is expanded to include positive feedback. The model also reveals the counterintuitive prediction that noise in protein expression levels can increase upon arrest of cell growth and division, which we confirm experimentally. This work shows that the properties of regulatory subsystems can be used to predict the behaviour of larger, more complex regulatory networks, and that this bottom-up approach can provide insights into gene regulation.

---

### Guidelines for validation of next-generation sequencing-based oncology panels: a joint consensus recommendation of the Association for Molecular Pathology and college of American pathologists [^01148c3a]. The Journal of Molecular Diagnostics (2017). Medium credibility.

Nonparametric tolerance intervals for non-normal distributions: The above estimate of the tolerance interval would only be applicable to a population that is normally distributed, but when the underlying population is often not normal (eg, when there is a natural boundary that the data cannot exceed (ie, 0% or 100%)) it is helpful to define tolerance intervals using nonparametric methods; the one-sided nonparametric tolerance interval can be determined by finding the value for k that satisfies the cumulative binomial equation, where CL is the confidence level (eg, 0.95), and by setting k = 0 (ie, 0 failures) the formula can be simplified.

---

### Digital profiling of gene expression from histology images with linearized attention [^48519a59]. Nature Communications (2024). High credibility.

Identification of significantly well-predicted genes

To assess the performance within the TCGA cohort, we concatenated the predictions of all test sets i (i = 1.5). For each gene, the predicted gene expression values were compared to the ground truth using both Pearson's correlation analysis and RMSE. The resulting correlation coefficient and RMSE values were then compared to those obtained with a random, untrained model of the same architecture.

To identify genes with significantly well-predicted expression levels, we combined three criteria: (1) The correlation coefficient (r 1) between ground truth and the predicted gene expression values must be positive and the associated P value (p 1) should be less than 0.05 (r 1 > 0 and p 1 < 0.05); (2) r 1 must be significantly higher than r 2 (r 1 > r 2) as determined by the Steiger's Z test, where r 2 represents the correlation coefficient between ground truth and predicted gene expression values obtained from the random model. We required the raw Steiger P value to be less than 0.05 (p 2 < 0.05) and the adjusted P value by Benjamini-Hochberg correction to be less than 0.2 (p 3 < 0.2); (3) The RMSE values obtained from the trained model must be smaller than those from the random model (r m s e 1 < r m s e 2).

For better presentation and interpretation, we calculated a "normalized RMSE value" using a two-step method. First, since the absolute gene expression values varied across different genes, we performed quantile normalization of the RMSE values. For each gene, the RMSE value between the prediction and ground truth was divided by the interquartile range of its absolute expression values across the samples. This normalization ensured that the RMSE values were comparable between different genes. Second, we performed min-max normalization for the quantile-normalized RMSE values across all genes calculated in each specific cancer type. This step scaled the quantile-normalized RMSE values to a range between 0 and 1. Therefore, the final normalized RMSE value is bounded between 0 and 1, with smaller values indicating more accurate predictions.

---

### Methylphenidate hydrochloride (Jornay pm) [^f67ab85f]. FDA (2023). Medium credibility.

After 3 weeks of treatment, the ADHD-RS-IV total scores were statistically significantly better (lower) for JORNAY PM than placebo (Table 2). The secondary efficacy endpoint, the BSFQ, was also statistically significantly better (lower) for JORNAY PM versus placebo.

Table 2 summarizes the primary endpoint results for Study 1 and Study 2.

Figure 2: Study 1 — LS Mean SKAMP Combined Score on Day after Final Treatment, as Measured in an Analogue Classroom in Pediatric Patients (6 to 12 years old) with ADHD, N = 117

LS = Least Squares; CS = Combined Score (sum of items 1–13); N = Sample Size; SE = Standard Error

---

### Experimental design and analysis of antibody microarrays: applying methods from cDNA arrays [^aab535b5]. Cancer Research (2005). Low credibility.

Protein expression microarrays, also called antibody arrays, represent a new technology that allows the expression level of proteins to be assessed directly. As is also the case with gene expression microarrays, it is hoped that protein expression microarrays will aid in biomarker discovery, predicting disease outcomes and response to treatments, and detecting molecular mechanisms and/or pathways associated with a particular disease state. However, accurately achieving these aims is dependent upon suitable experimental designs, normalization procedures that eliminate systematic bias, and appropriate statistical analyses to assess differential expression or expose expression patterns. In the last five years, a large amount of research has been devoted to two-color cDNA arrays to improve experimental design, normalization and statistical analyses to assess differential expression and classification. These methods are directly applicable to two-color antibody arrays. The objective of this article is to discuss statistical methods that have been developed for cDNA arrays and describe how the methods can be directly applied to antibody arrays.

---

### Constraints on eQTL fine mapping in the presence of multisite local regulation of gene expression [^e2e9a2de]. G3 (2017). Low credibility.

Figure 5
Biases in effect size estimation from conditional and joint analysis. All panels refer to 500,000 simulated data points where effect sizes were sampled from a uniform distribution to explain from 2% to 10% of the expression at a locus for each of 4 SNPs picked at random from 400kb intervals of the CAGE genotype data. Panel (A) compares estimates from joint and conditional modeling, as a heatmap of the average difference in panels C and D, where yellow indicates that joint modeling produces a larger estimated effect size, and blue a lower estimate with three bands of negative values indicating greater bias in the conditional estimates. Panel B shows the density distribution on the log2 scale of the number of simulations with alleles for each pixel with the indicated β (in standard deviation units, sdu) on the x-axis, and average LD with the other 3 sites at the locus on the y-axis. Panels C and D show the average absolute value of the deviation between the observed and known effect size for sites under the multi-site model where all discovered sites are fit jointly (C) or from single site estimates after each step of sequential conditional analysis (D), for the 4:0 scenario where all minor alleles have effects in the same direction. See Figure S4 for the equivalent panels for the 3:1 and 2:2 scenarios.

---

### Variation in gene expression within and among natural populations [^9a11baac]. Nature Genetics (2002). Medium credibility.

Evolution may depend more strongly on variation in gene expression than on differences between variant forms of proteins. Regions of DNA that affect gene expression are highly variable, containing 0.6% polymorphic sites. These naturally occurring polymorphic nucleotides can alter in vivo transcription rates. Thus, one might expect substantial variation in gene expression between individuals. But the natural variation in mRNA expression for a large number of genes has not been measured. Here we report microarray studies addressing the variation in gene expression within and between natural populations of teleost fish of the genus Fundulus. We observed statistically significant differences in expression between individuals within the same population for approximately 18% of 907 genes. Expression typically differed by a factor of 1.5, and often more than 2.0. Differences between populations increased the variation. Much of the variation between populations was a positive function of the variation within populations and thus is most parsimoniously described as random. Some genes showed unexpected patterns of expression — changes unrelated to evolutionary distance. These data suggest that substantial natural variation exists in gene expression and that this quantitative variation is important in evolution.

---

### The impact of species-wide gene expression variation on caenorhabditis elegans complex traits [^f0a760c2]. Nature Communications (2022). High credibility.

Complex regulatory genetic architectures in wild C. elegans strains

To estimate the association between gene expression differences and genetic variation, we calculated the broad-sense heritability (H 2, here calculated as strain-wise variance) and the narrow-sense heritability (h 2, here calculated using the SNV matrix in the below GWA mappings) for each of the 25,849 transcript expression traits. We observed a median H 2 of 0.31 and a median h 2 of 0.06 (Fig. 2a and Supplementary Data 1), indicating strong influences from environmental factors, epistasis, or other stochastic factors on transcript expression variation. However, h 2 of thousands of transcript expression traits indicated a substantial heritable genetic component of the population-wide expression differences.

Fig. 2
Expression QTL map of 207 wild C. elegans strains.

a Heritability for 25,849 transcript expression traits with (orange) or without (black) detected eQTL. The narrow-sense heritability (h 2, y-axis) for each trait is plotted against the broad-sense heritability (H 2, x-axis). b The genomic locations of 6,545 eQTL peaks (x-axis) that pass the genome-wide EIGEN 5% FDR threshold are plotted against the genomic locations of the 5,291 transcripts with expression differences (y-axis). Golden points on the diagonal of the map represent local eQTL that colocalize with the transcripts that they influence. Purple points correspond to distant eQTL that are located farther away from the transcripts that they influence. c The variance explained (VE) by each detected eQTL (y -axis) that passed Bonferroni (BF) 5% FDR or EIGEN 5% FDR threshold for each trait is plotted against the narrow-sense heritability h 2 (x -axis). The dashed lines on the diagonal are shown as visual guides to represent h 2 = H 2 (a) and VE = h 2 (c). d Comparison of VE between 3185 local and 3,360 distant eQTL shown as Violin plots. The mean and median VE by local or distant eQTL are indicated as red points and horizontal lines in each box, respectively. Box edges denote the 25th and 75th quantiles of the data, and whiskers represent 1.5× the interquartile range. Statistical significance was calculated using a two-sided Wilcoxon test. e A histogram showing the number of distant eQTL detected per transcript expression trait. One to six distant eQTL were detected for 2,553 transcript expression traits, of which 447 traits also have one local eQTL. Numbers before slashes (indicated as the golden proportion of each bar) represent the number of traits with a local eQTL in addition to their distant eQTL. Numbers after each slash represent the total number of traits in each category.

---

### The SNMMI and EANM practice guideline for renal scintigraphy in adults [^39160d12]. European Journal of Nuclear Medicine and Molecular Imaging (2018). Medium credibility.

Renal scintigraphy reporting — dynamic and static image outputs — should include a short series of summed images representative of the different phases of the renography with gray or color scale, labelled ROIs on a summed image, right and left background-corrected renograms identified by color or line structure on the same diagram with curves expressed in counts/sec and scaled on the y-axis on the higher peak count, radiopharmaceutical and diuresis or captopril renography when appropriate, relative renal function as expressed in percentages and normal range, and transit parameters (one or two at the most) with their normal ranges; for static studies include all the projections in black white scale, set at the maximum counts into the kidney picture of each image, and relative kidney function as percentage of the total.

---

### Transient power-law behaviour following induction distinguishes between competing models of stochastic gene expression [^12696d87]. Nature Communications (2025). High credibility.

Fig. 3
Simulations confirm the predicted power-law behaviour of the time-dependent statistics of the mRNA count following induction.

A – C Mean of mRNA counts, variance of mRNA counts and Fano factor of mRNA counts for the N = 5-state model. D Mean of mRNA counts for the 5-state model with one extra step modelling the translation of mRNA (M) to protein (P). E Mean of mRNA counts for the 5-state model with cell-to-cell variation of rate parameters (static extrinsic noise); each rate parameter is drawn from a gamma distribution. F Mean mRNA count from extensions of the 5-state model that incorporate reversible reactions between gene states and state change upon mRNA synthesis; these are special cases of the system (5). The theory is shown by the dashed lines and simulations by solid lines (obtained by direct numerical integration of the moment equations of the chemical master equation (CME)). In (E) the simulations are done in two ways: solid lines are obtained by direct numerical integration of the moment equations of the CME with rate parameters fixed to the average of the gamma distributions and dots are from stochastic simulations (10 5 trajectories) with rate parameters randomly drawn from these distributions. In all cases, there is excellent agreement between theory and simulations for short times. All panels use a log-log scale hence a power-law relationship is represented by a straight line with gradient corresponding to the exponent of the power law. The colours: blue, pink, orange, and yellow, represent the initial inactive gene state after induction: j = 1, 2, 3, 4 respectively and are illustrated by the model diagram in each panel. The outward-pointing green arrow represents mRNA synthesis and the other shows the state after synthesis. The parameters were chosen to be within the range relevant for eukaryotic gene expression (the range used for Fig. 2). See Supplementary Note 2 for reaction network schemes.

---

### Digital profiling of gene expression from histology images with linearized attention [^2fa24501]. Nature Communications (2024). High credibility.

Since histological phenotypes and gene expression profiles vary across cancer types, the model was independently developed and validated in each cancer type. To evaluate the model, we carried out five-fold cross-validation. In each iteration, slides from 80% of the patients were allocated for training (of which 10% were used as validation set), while the remaining 20% were reserved for testing (Supplementary Fig. 1). For each gene, we concatenated the predicted expression values of tissues from the test sets and compared them to the ground truth using Pearson's correlation analysis and root mean squared error (RMSE).

The resulting correlation coefficient and RMSE values were further compared to those obtained with a random, untrained model of the same architecture (see "Methods" for details). To identify genes with significantly well-predicted expression levels, we combined three criteria: (1) the predicted gene expression values must be significantly correlated with the ground truth, with a positive correlation coefficient and the associated P value smaller than 0.05 (r 1 > 0 and p 1 < 0.05); (2) r 1 must be statistically higher than r 2 (r 1 > r 2), as determined by Steiger's Z test, where r 2 represents the correlation coefficient obtained from the random model. For this comparison, we required the raw Steiger P value to be smaller than 0.05 (p 2 < 0.05) and the adjusted P value by Benjamini–Hochberg correction smaller than 0.2 (p 3 < 0.2); (3) the RMSE values obtained from the trained model must be smaller than those from the random model.

---

### Addressing sex as a biological variable in preclinical models of lung disease: an official American Thoracic Society research statement [^b298ece6]. American Journal of Respiratory and Critical Care Medicine (2025). High credibility.

Sex as a biological variable (SABV) in preclinical lung disease models — study design and reporting guidance emphasizes a 2 × 2 factorial design and explicit sex-based reporting. In a 2 × 2 factorial design, each sex is represented within the two treatment or intervention groups, and factorial designs incorporate at least two factors, with at least two levels each, enabling answers to whether outcomes differ between treated and control groups, between males and females, and whether there is an interaction between biological sex and treatment or intervention. When reporting study findings, it is essential to provide specific information to ensure reproducibility and minimize bias, and in the methods section it is crucial to state the sex of biological replicates and how that was assessed, the respective sample size, and a justification of power or otherwise the ability to detect sex-based effects; if available, researchers should include sex-specific biological variables such as estrous cycle status, developmental stage, and hormone levels. For in vitro studies, the sex of the cells used and the culturing conditions (e.g., phenol red–free and/or charcoal-stripped media) should be documented, and the figures and tables in the manuscript should display all data disaggregated by sex using distinct visual markers and including both significant and nonsignificant findings and effect sizes for sex differences. Table 3 summarizes the major recommendations for incorporating SABV in preclinical models of lung disease, and a checklist (Table 4) for the inclusion and analysis of SABV in the model, which researchers and reviewers can use, has been included in the online supplement.

---

### Roflumilast (Zoryve) [^e2de6cd7]. FDA (2024). Medium credibility.

The dosage of roflumilast TOP for treatment of plaque psoriasis in adults is 1 application(s) TOP daily (0.3% cream or foam)

---

### Harnessing the central dogma for stringent multi-level control of gene expression [^46049af5]. Nature Communications (2021). High credibility.

Strictly controlled inducible gene expression is crucial when engineering biological systems where even tiny amounts of a protein have a large impact on function or host cell viability. In these cases, leaky protein production must be avoided, but without affecting the achievable range of expression. Here, we demonstrate how the central dogma offers a simple solution to this challenge. By simultaneously regulating transcription and translation, we show how basal expression of an inducible system can be reduced, with little impact on the maximum expression rate. Using this approach, we create several stringent expression systems displaying > 1000-fold change in their output after induction and show how multi-level regulation can suppress transcriptional noise and create digital-like switches between 'on' and 'off' states. These tools will aid those working with toxic genes or requiring precise regulation and propagation of cellular signals, plus illustrate the value of more diverse regulatory designs for synthetic biology.

---

### Guidelines for validation of next-generation sequencing-based oncology panels: a joint consensus recommendation of the Association for Molecular Pathology and college of American pathologists [^59838d2f]. The Journal of Molecular Diagnostics (2017). Medium credibility.

Sample size metrics — tolerance intervals versus confidence intervals: Although performance is often stated in terms of confidence intervals (CI), the CI of the mean only gives an estimate of the population mean with a stated level of confidence and does not give an indication of the performance of any given sample; to estimate the distribution of the underlying population and the performance of individual samples, the tolerance intervals should be used, with the lower tolerance interval for a normally distributed population determined as x̄ ± k × s, where s is the sample standard deviation (SD) and k is a correction factor, and for two-sided 95% confidence with n = 20 the k value is 2.75, approaching the z-score as the number of samples increases.

---

### Addressing sex as a biological variable in preclinical models of lung disease: an official American Thoracic Society research statement [^5f3a67c5]. American Journal of Respiratory and Critical Care Medicine (2025). High credibility.

Statistical design, analysis, and reporting for SABV in preclinical in vitro studies emphasize power analysis and transparent sex-based planning: researchers "should determine minimum group sizes and sex allocations based on primary outcomes and effect sizes from preliminary studies". "Ideally, an equal number of male and female biological replicates should be used; at a minimum, the sex of biological replicates should be recorded a priori". "Preliminary findings can guide the two-way ANOVA to assess sex as an independent variable and its interaction with other factors", and "incorporating existing sample sizes and power analyses will aid in designing future studies focused on sex differences". Reporting expectations include that "reporting effect size, statistical power, and predicted sample sizes for each sex is essential for accurately calculating the necessary sample size to examine SABV (190)". For powering sex effects, "sample sizes must be calculated separately for each sex and then combined, accounting for sex differences in disease incidence and effect size", and "the ideal study design for evaluating sex differences should be powered to detect statistically significant sex-by-treatment interactions", noting "such a study requires a larger sample size than one designed solely to detect the main effect or sex alone (191)". When sex differences are not the primary focus and sizing is uncertain, investigators can follow "The Four C's of Studying Sex to Strengthen Science": "1) Consider — design studies that account for sex or justify its exclusion; 2) Collect — gather sex-based data; 3) Characterize — analyze sex-specific data; and 4) Communicate — report and publish".

---

### Clinical practice guidelines for hemodialysis adequacy, update 2006 [^5c74e315]. American Journal of Kidney Diseases (2006). Medium credibility.

Hemodialysis adequacy — minimum single‑pool Kt/V (spKt/V) targets per treatment to achieve a weekly standard Kt/V (stdKt/V) of approximately 2.0 are stratified by residual urea clearance (K_r): for 2x/wk dialysis with K_r < 2 mL/min/1.73 m2 it is Not recommended, whereas with K_r ≥ 2 mL/min/1.73 m2 it is 2.0*; for 3x/wk the minima are 1.2 (K_r < 2) and 0.9 (K_r ≥ 2); for 4x/wk 0.8 and 0.6; and for 6x/wk (short daily) 0.5 and 0.4. Table 13 states these sessional targets correspond to "a weekly stdKt/V value of 2.0" in patients "undergoing 2 to 6 treatments per week" with adjustment for "a weekly K_r of 2 mL/min"; a "urea clearance of 2 mL/min is approximately 20 L/wk" and with "V = 30 L, it represents about a 0.67 weekly Kt/V unit". It is noted that "the minimum values for spKt/V" do not account for outcome improvements when frequency "is increase to more than 3/wk". The Work Group "recommended targeting an spKt/V value that is about 15% higher than the recommended minimum targets", developed a scheme that "limited the downward adjustment in spKt/V for K_r to 2 mL/min", and stated that "Maintaining a minimum 'total Kt/V' value of 1.2… would allow reduction of the dialysis dose down to near zero".

---

### Replicated effects of sex and genotype on gene expression in human lymphoblastoid cell lines [^e953d3c6]. Human Molecular Genetics (2007). Low credibility.

The expression level for 15,887 transcripts in lymphoblastoid cell lines from 19 monozygotic twin pairs (10 male, 9 female) were analysed for the effects of genotype and sex. On an average, the effect of twin pairs explained 31% of the variance in normalized gene expression levels, consistent with previous broad sense heritability estimates. The effect of sex on gene expression levels was most noticeable on the X chromosome, which contained 15 of the 20 significantly differentially expressed genes. A high concordance was observed between the sex difference test statistics and surveys of genes escaping X chromosome inactivation. Notably, several autosomal genes showed significant differences in gene expression between the sexes despite much of the cellular environment differences being effectively removed in the cell lines. A publicly available gene expression data set from the CEPH families was used to validate the results. The heritability of gene expression levels as estimated from the two data sets showed a highly significant positive correlation, particularly when both estimates were close to one and thus had the smallest standard error. There was a large concordance between the genes significantly differentially expressed between the sexes in the two data sets. Analysis of the variability of probe binding intensities within a probe set indicated that results are robust to the possible presence of polymorphisms in the target sequences.

---

### Experimental noise cutoff boosts inferability of transcriptional networks in large-scale gene-deletion studies [^b2076e8b]. Nature Communications (2018). Medium credibility.

Fraction of inferable links

Inferability of a directed link between source and target node requires that the remaining network may not contain the same information that is transmitted between them. A sufficient condition is that all information that the remaining network receives from the source node is destroyed by sufficiently strong perturbations. If the target node is not perturbed, information from the source node may reach the remaining network through the target node. In this case also the targets of the target node must be perturbed (Fig. 2a). Counting network motifs that satisfy these conditions gives the number of inferable links. If the network size, N, is significantly larger than the number of outgoing links for both the source and target nodes, we can approximate the fraction of inferable links, F (q), by the expression (Supplementary Note 1)Here, P (k, l, m | k → l) is the conditional probability of finding two connected nodes in the directed network, where the source node has k ≥ 1 outgoing links, the target node has l ≥ 0 outgoing links, and both share m nodes as common targets of their outgoing links. The first term in the brackets corresponds to the case that independent perturbation data for node B exists (Fig. 2a, left panel) and the second term to the case where independent perturbation data for node B are absent (Fig. 2a, right panel). In the calculation of F (q) we assumed that the links in the network are represented by noiseless, linear functions with non-zero slope and that ensure that information of source nodes is neither destroyed nor absorbed in the process of transmission.

Data preparation

Kemmeren et al.provided a transcriptome data set of a Saccharomyces cerevisiae genome-wide knockout library (with mutant strains isogenic to S288c). This data set comprises transcript levels of 6170 genes for 1484 deletion mutants. The data are presented as the logarithm of the fluorescence intensity ratios (M-values) of transcripts relative to their average abundance across a large number of wild-type replicates, resulting in logarithmic fold changes of mutant/wild-type gene expression levels compared with a wild-type reference level. Kemmeren et al. also used a dye swap setup for several experiments to average out the effect of a possible dye bias. Their chip design measures most of the genes twice per biological sample, thus allowing to estimate the technical variance. The preprocessing of the data is described in Kemmeren et al. Supplementary Information.

---

### Dynamics of lineage commitment revealed by single-cell transcriptomics of differentiating embryonic stem cells [^fe5b4c15]. Nature Communications (2017). Medium credibility.

Quantification of the flow cytometry experiments

The distribution of cells in the space of CD24 and PDGFRA expression was modeled by the sum of 4 bivariate normal distributions. This model has in principle 19 free parameters (8 for the means, 8 for the standard deviations and 3 for the size of the relative contributions). To ensure robust fitting to the date we reduced the number of parameters to 9 by keeping the standard deviations constant and only allowing 4 different values for the means.

N(x, y, µ x, µ y, σ x, σ y) is a bivariate normal distribution in x and y (PDGFRA and CD24 expression, respectively) with mean (µ x, µ y) and standard deviation (σ x, σ y). This model was fit to a reference data set (typically untreated control cells after 96 h of RA exposure) by maximizing the log-likelihood −log(p). To subsequently calculate the size of the fractions f i for a particular sample we first calculated the probabilities that the expression values (x, y) found in a particular cell were drawn from one the 4 normal distributions N(x, y, µ x, µ y, σ x, σ y). The cell was then ascribed to the distribution from which it was most likely drawn.

---

### Synthetic analog computation in living cells [^c53dfa6f]. Nature (2013). Excellent credibility.

A central goal of synthetic biology is to achieve multi-signal integration and processing in living cells for diagnostic, therapeutic and biotechnology applications. Digital logic has been used to build small-scale circuits, but other frameworks may be needed for efficient computation in the resource-limited environments of cells. Here we demonstrate that synthetic analog gene circuits can be engineered to execute sophisticated computational functions in living cells using just three transcription factors. Such synthetic analog gene circuits exploit feedback to implement logarithmically linear sensing, addition, ratiometric and power-law computations. The circuits exhibit Weber's law behaviour as in natural biological systems, operate over a wide dynamic range of up to four orders of magnitude and can be designed to have tunable transfer functions. Our circuits can be composed to implement higher-order functions that are well described by both intricate biochemical models and simple mathematical functions. By exploiting analog building-block functions that are already naturally present in cells, this approach efficiently implements arithmetic operations and complex functions in the logarithmic domain. Such circuits may lead to new applications for synthetic biology and biotechnology that require complex computations with limited parts, need wide-dynamic-range biosensing or would benefit from the fine control of gene expression.

---

### Genetic analysis of genome-wide variation in human gene expression [^894b2fcc]. Nature (2004). Excellent credibility.

Natural variation in gene expression is extensive in humans and other organisms, and variation in the baseline expression level of many genes has a heritable component. To localize the genetic determinants of these quantitative traits (expression phenotypes) in humans, we used microarrays to measure gene expression levels and performed genome-wide linkage analysis for expression levels of 3,554 genes in 14 large families. For approximately 1,000 expression phenotypes, there was significant evidence of linkage to specific chromosomal regions. Both cis- and trans-acting loci regulate variation in the expression levels of genes, although most act in trans. Many gene expression phenotypes are influenced by several genetic determinants. Furthermore, we found hotspots of transcriptional regulation where significant evidence of linkage for several expression phenotypes (up to 31) coincides, and expression levels of many genes that share the same regulatory region are significantly correlated. The combination of microarray techniques for phenotyping and linkage analysis for quantitative traits allows the genetic mapping of determinants that contribute to variation in human gene expression.

---

### Experimental noise cutoff boosts inferability of transcriptional networks in large-scale gene-deletion studies [^061df17c]. Nature Communications (2018). Medium credibility.

To further improve the predictive power of our method we included the prior knowledge that transcriptional networks are highly sparse. Sparsity constraints are typically realised by penalising either the existence of links or the link strengths by adding appropriate cost functions, such as L 1 -norm regularised regression (Lasso). Adding a cost function to the main objective comes with the problem to trade-off the log-likelihood against the number of links in the network whose strength is allowed to be non-zero. In the absence of experimentally verified interactions there is no obvious way how to determine a suitable regularisation parameter that weights the likelihood against the cost function, which is one of the great weaknesses of such methods.

In our approach we reduce network complexity by assuming that functionally relevant information in molecular networks can only pass through nodes whose response to perturbations is significantly above the base line that is given by the variability among biological replicates. The individual noise levels can be estimated from natural variations among wild-type experimental replicates (Fig. 3a). The significance level that removes nodes from the network with low signal-to-noise ratio can be set to a desired false discovery rate. It can be shown that removal of noisy nodes imposes a sparsity constraint on the inference problem (Online Methods). The different steps required to arrive at a list of significant links are illustrated in Fig. 4a. In the first step, genes are grouped in clusters that are co-expressed under all perturbations. These clusters are treated as single network nodes in the subsequent steps. In the second step, only those samples are extracted from the data set that correspond to a perturbation of a chosen gene — the source node — with no other genes perturbed (node 5 in Fig. 4a). From this reduced data set, we identify all nodes in the network that change expression above a given significance level upon perturbing the source node. These significantly responding nodes define a subnetwork for each source node, which is typically much smaller in size than the complete network. In the third step, we collect all perturbation data from the complete data set for all nodes that are part of the subnetwork. Before inferring a direct interaction that points from the source node to a given target node in the subnetwork (green arrows in Fig. 4a), we remove all experiments from the data set where the target node is perturbed. The second and third steps essentially realise the counting procedure of inferable links as illustrated in Fig. 2a, with the difference that significant links are identified by PRCs in combination with residual bootstrapping over replicates (Online Methods, Supplementary Note 3). In the fourth step, we collect all clusters of co-expressed genes that contain exactly two nodes, with one of the nodes perturbed and check statistical significance of the directed link between them. In the fifth step, all significant links are collected in an edge list. We refer to these five steps as the clustering method. If we remove all links from the edge list that have more than one node in a source cluster or more than one node in a target cluster, we obtain an edge list that corresponds to links between single genes. This reduced edge list would also arise by skipping the clustering step and we refer to the remaining inference steps that compute links between single genes as subnetwork method.

---

### Clotrimazole [^b5a7188a]. FDA. Low credibility.

The dosage of clotrimazole OTIC for treatment of otomycosis in adults is 1 vial OTIC BID for 14 days (1%/0.17 mL)

---

### New designs for phase 2 clinical trials [^a90544dc]. Blood (2003). Low credibility.

Conventional phase 2 clinical trials are typically single-arm experiments, with outcome characterized by one binary "response" variable. Clinical investigators are poorly served by such conventional methodology. We contend that phase 2 trials are inherently comparative, with the results of the comparison determining whether to conduct a subsequent phase 3 trial. When different treatments are studied in separate single-arm trials, actual differences between response rates associated with the treatments, "treatment effects", are confounded with differences between the trials, "trial effects". Thus, it is impossible to estimate either effect separately. Consequently, when the results of separate single-arm trials of different treatments are compared, an apparent treatment difference may be due to a trial effect. Conversely, the apparent absence of a treatment effect may be due to an actual treatment effect being cancelled out by a trial effect. Because selection involves comparison, single-arm phase 2 trials thus fail to provide a reliable means for selecting which therapies to investigate in phase 3. Moreover, reducing complex clinical phenomena, including both adverse and desirable events, to a single outcome wastes important information. Consequently, conventional phase 2 designs are inefficient and unreliable. Given the limited number of patients available for phase 2 trials and the increasing number of new therapies that must be evaluated, it is critically important to conduct these trials efficiently. These concerns motivated the development of a general paradigm for randomized selection trials evaluating several therapies based on multiple outcomes. Three illustrative applications of trials using this approach are presented.

---

### Linear mapping approximation of gene regulatory networks with stochastic dynamics [^36b6fa32]. Nature Communications (2018). Medium credibility.

Further applications of the LMA

Having verified the high accuracy of the LMA, we shall next use it to shed light on how the stochastic properties of a feedback loop are affected by cooperativity and protein bursting. In particular we are interested in how these two features affect: the first-passage time distribution of switching from one promoter state to the other, the sensitivity of the coefficient of variation squared to a change in the parameter values and the stochastic bifurcation diagram.

Practically, all GRNs involve multiple promoter states with different post-translational pathways enabled by each state. Hence the switching from one state to another is important to understand from the perspective of cellular decision-making, e.g. a cell's response to a stimulus may require the quick switching on of certain biochemical machinery. This can be mathematically characterized using the first-passage time (FPT) distribution which is the probability distribution of the time it takes to switch between two promoter states given initially one of the states. The switch from G * to G occurs via G * → G + P, which is a linear reaction with rate σ u and hence it can be easily shown that the FPT for the promoter switching from state G * to G is simply exponential distribution with mean. Hence, cooperativity and bursting have no effect on this switch. The switch from G to G * occurs via G + P → G *, which is a nonlinear reaction with rate σ b; in this case it is much more difficult to obtain the FPT because the process is nonlinear (most FPT theory is for linear reactions though there are exceptions) and since there is a dependence on the instantaneous protein number that is affected by many different processes (transcription, degradation, bursting, cooperativity, etc). However, the LMA maps the above nonlinear reaction to a linear one, and thus enables us to obtain an approximate non-exponential expression for the FPT of switching from state G to G * (given no protein initially in state G) for nonlinear GRNs (see "Methods" section). In Fig. 7a, we show the LMA's estimate of the FPT distribution for the feedback loop (Fig. 1a upper); the feedback loop with cooperativity, specifically two protein molecules binding the promoter in state G (Fig. 2b) and the feedback loop with protein bursting and a mean burst size of two protein molecules (Fig. 2a) (the four parameters which are common to all three GRNs are fixed for comparison purposes; see Fig. 7 caption for details). The estimates are close to the FPT calculated using the SSA thus verifying the LMA's accuracy. The mean time to switch from G to G * in a feedback loop is decreased considerably by cooperativity and slightly by bursting; this was observed for all parameter sets, which we studied. We also found out using the LMA that over a large region of parameter space, the mean first-passage time τ is approximately described by a simple power law in two parameters (Fig. 7b):

---

### Combining spatial transcriptomics with tissue morphology [^eff0f1eb]. Nature Communications (2025). High credibility.

Clustering evaluation metrics

Since spatial domain identification is not a classification problem in which there is a one-to-one connection between regions, we need metrics that take this into account. The Rand index (RI) and its adjusted version (ARI) –, measure the similarity of two clusters, accommodating for scenarios with unlabeled and different amounts of categories. To evaluate the similarity between two clustering results, we use metrics that account for such complexities.

The ARI is a measure of the similarity between two data clusterings, correcting for the chance grouping of elements. The ARI ranges from −1 to 1, where 1 indicates perfect agreement between the two clusterings, 0 indicates random clustering and negative values indicate less agreement than expected by chance.where RI is the measure of the similarity between two data clusterings, and Expected RI is the expected value of the RI for random clustering.

Autocorrelation metrics

Gene expressions at different locations may exhibit spatial autocorrelation, where nearby locations have similar expression levels. To assess this, authors use Moran's I, and Geary's C, statistics.

Moran's I quantifies the overall spatial autocorrelation of gene expression. It ranges from −1 to 1, where 1 indicates a clear spatial pattern, 0 indicates random spatial expression, and −1 indicates a chessboard-like pattern.where x i and x j are the gene expressions at spots i and j, is the mean expression, N is the total number of spots, w i j is the spatial weight between spots i and j, and W is the sum of w i j. A common choice it to set w i j = 1 for the 4 nearest neighbors of spot i and w i j = 0 otherwise.

Geary's C also measures spatial autocorrelation but focuses on local differences. Its value ranges from 0 to 2.

To align it with Moran's I, we scale it to [−1, 1]:

Here, 1 indicates perfect positive autocorrelation, 0 indicates no autocorrelation, and −1 indicates perfect negative autocorrelation. Both metrics provide insight into the spatial patterns of gene expression.

---

### National Lipid Association recommendations for patient-centered management of dyslipidemia: part 2 [^364f9843]. Journal of Clinical Lipidology (2015). Medium credibility.

Figure 4 — statin primary prevention in women: A meta-analysis presents a forest plot of odds ratios for women across primary prevention risk levels, where solid squares represent individual-trial odds ratios sized by inverse variance, horizontal lines, diamonds, and squares denote 95% confidence intervals, and pooled estimates were computed using a random effects model.

---

### Elacestrant (Orserdu) [^25e5bc7d]. FDA (2024). Medium credibility.

The dosage of elacestrant PO for treatment of breast cancer in postmenopausal female adults with ESR1 mutation (advanced or metastatic, ER-positive, HER2-negative, progression after ≥ 1 line of endocrine therapy) is 345 mg PO daily until disease progression or unacceptable toxicity

---

### The genetic architecture of gene expression in peripheral blood [^c2d3854e]. American Journal of Human Genetics (2017). Low credibility.

We analyzed the mRNA levels for 36,778 transcript expression traits (probes) from 2,765 individuals to comprehensively investigate the genetic architecture and degree of missing heritability for gene expression in peripheral blood. We identified 11,204 cis and 3,791 trans independent expression quantitative trait loci (eQTL) by using linear mixed models to perform genome-wide association analyses. Furthermore, using information on both closely and distantly related individuals, heritability was estimated for all expression traits. Of the set of expressed probes (15,966), 10,580 (66%) had an estimated narrow-sense heritability (h 2) greater than zero with a mean (median) value of 0.192 (0.142). Across these probes, on average the proportion of genetic variance explained by all eQTL (h COJO 2) was 31% (0.060/0.192), meaning that 69% is missing, with the sentinel SNP of the largest eQTL explaining 87% (0.052/0.060) of the variance attributed to all identified cis- and trans-eQTL. For the same set of probes, the genetic variance attributed to genome-wide common (MAF > 0.01) HapMap 3 SNPs (h g 2) accounted for on average 48% (0.093/0.192) of h 2. Taken together, the evidence suggests that approximately half the genetic variance for gene expression is not tagged by common SNPs, and of the variance that is tagged by common SNPs, a large proportion can be attributed to identifiable eQTL of large effect, typically in cis. Finally, we present evidence that, compared with a meta-analysis, using individual-level data results in an increase of approximately 50% in power to detect eQTL.

---

### Allelic heterogeneity and more detailed analyses of known loci explain additional phenotypic variation and reveal complex patterns of association [^b3b7ed37]. Human Molecular Genetics (2011). Low credibility.

The identification of multiple signals at individual loci could explain additional phenotypic variance ('missing heritability') of common traits, and help identify causal genes. We examined gene expression levels as a model trait because of the large number of strong genetic effects acting in cis. Using expression profiles from 613 individuals, we performed genome-wide single nucleotide polymorphism (SNP) analyses to identify cis-expression quantitative trait loci (eQTLs), and conditional analysis to identify second signals. We examined patterns of association when accounting for multiple SNPs at a locus and when including additional SNPs from the 1000 Genomes Project. We identified 1298 cis-eQTLs at an approximate false discovery rate 0.01, of which 118 (9%) showed evidence of a second independent signal. For this subset of 118 traits, accounting for two signals resulted in an average 31% increase in phenotypic variance explained (Wilcoxon P < 0.0001). The association of SNPs with cis gene expression could increase, stay similar or decrease in significance when accounting for linkage disequilibrium with second signals at the same locus. Pairs of SNPs increasing in significance tended to have gene expression increasing alleles on opposite haplotypes, whereas pairs of SNPs decreasing in significance tended to have gene expression increasing alleles on the same haplotypes. Adding data from the 1000 Genomes Project showed that apparently independent signals could be potentially explained by a single association signal. Our results show that accounting for multiple variants at a locus will increase the variance explained in a substantial fraction of loci, but that allelic heterogeneity will be difficult to define without resequencing loci and functional work.

---

### Evaluation of the evenness score in next-generation sequencing [^1f5f1936]. Journal of Human Genetics (2016). Low credibility.

The evenness score (E) in next-generation sequencing (NGS) quantifies the homogeneity in coverage of the NGS targets. Here I clarify the mathematical description of E, which is 1 minus the integral from 0 to 1 over the cumulative distribution function F(x) of the normalized coverage x, where normalization means division by the mean, and derive a computationally more efficient formula; that is, 1 minus the integral from 0 to 1 over the probability density distribution f(x) times 1-x. An analogous formula for empirical coverage data is provided as well as fast R command line scripts. This new formula allows for a general comparison of E with the coefficient of variation (= standard deviation σ of normalized data) which is the conventional measure of the relative width of a distribution. For symmetrical distributions, including the Gaussian, E can be predicted closely as 1-σ(2)/2⩾E⩾1-σ/2 with σ ≤ 1 owing to normalization and symmetry. In case of the log-normal distribution as a typical representative of positively skewed biological data, the analysis yields E≈exp(-σ*/2) with σ*(2) = ln(σ(2)+1) up to large σ (≤ 3), and E≈1-F(exp(-1)) for very large σ (⩾2.5). In the latter kind of rather uneven coverage, E can provide direct information on the fraction of well-covered targets that is not immediately delivered by the normalized σ. Otherwise, E does not appear to have major advantages over σ or over a simple score exp(-σ) based on it. Actually, exp(-σ) exploits a much larger part of its range for the evaluation of realistic NGS outputs.

---

### Permutation-based adjustments for the significance of partial regression coefficients in microarray data analysis [^37b82a90]. Genetic Epidemiology (2008). Low credibility.

The aim of this paper is to generalize permutation methods for multiple testing adjustment of significant partial regression coefficients in a linear regression model used for microarray data. Using a permutation method outlined by Anderson and Legendre [1999] and the permutation P-value adjustment from Simon et al. [2004], the significance of disease related gene expression will be determined and adjusted after accounting for the effects of covariates, which are not restricted to be categorical. We apply these methods to a microarray dataset containing confounders and illustrate the comparisons between the permutation-based adjustments and the normal theory adjustments. The application of a linear model is emphasized for data containing confounders and the permutation-based approaches are shown to be better suited for microarray data.

---

### Controlling gene expression with deep generative design of regulatory DNA [^65ceef8e]. Nature Communications (2022). High credibility.

Fig. 3
Predictor-guided generator optimization enables gene-specific navigation of the regulatory sequence-expression landscape.

a Schematic depiction of the procedure to optimize the generator using a trained predictor, which introduces codon frequency information into the generative approach and explores the input latent space of the generator to produce sequence variants across the whole range of gene expression, providing precise navigation of the gene regulatory sequence-expression landscape. b Predicted expression levels of generated sequence variants across optimization iterations set to either maximize (red) or minimize (blue) expression levels (n = 64,000). Black lines denote average expression levels and TPM transcripts per million. c T -distributed stochastic neighbor embedding (t-SNE)mapping of the input latent subspaces that produce unique sequence variants spanning ~6 orders of magnitude of gene expression (black and colored dots: progression of low to high expression levels is marked with progression from blue to red, respectively), uncovered using the predictor-guided generator optimization. Black dots represent selections of 10 sequence variants per each of the 4 expression groups covering a 4 order-of-magnitude range of predicted expression levels from TPM ~10 to ~10,000. Source data are provided as a Source Data file.

Merging the results of both maximization and minimization of gene expression and using t-distributed stochastic neighbor embedding (t-SNE) dimensionality reductionover the latent vectors confirmed that with this approach, desired expression levels are mapped to the identified latent subspace, resembling a continuous manifold, and covering regulatory sequence evolution in a range of almost 6 orders of magnitude of expression levels (Figs. 3 c and 4a, b, Supplementary Fig. 5). Thus, with optimization, the dynamic range of expression levels of the generated sequences increased over 3-fold compared to those obtained by randomly sampling the unoptimized generator (in equally sized samples), surpassing the whole natural range of expression levels (Fig. 1b: 4 orders of magnitude of median TPM across conditions), entirely for a specific gene of interest, by ~40% (Fig. 3c: GFP coding sequence shown). As before, analysis of sequence identity verified that the sequences produced by the generator optimization were not similar to any natural ones and retained the natural median sequence diversity of 67% (Supplementary Fig. 6). This suggested that points in the generator's latent space with desired expression levels can be sampled, which generalize beyond the naturally available gene expression levels, to generate unique sequences with feasible natural-like regulatory DNA properties.

---

### Spatially resolved gene expression profiling of tumor microenvironment reveals key steps of lung adenocarcinoma development [^a11cf2fb]. Nature Communications (2024). High credibility.

Fig. 2
Spatial transcriptome analysis of LUAD No. 2.

a H&E (left) and results of clustering analysis (middle and right) of LUAD No. 2 FFPE section C. The H&E image shows two regions of interest (ROIs). The capture area that is surrounded by the fiducial frame in the H&E image is 6.5 mm × 6.5 mm. b Violin plots of marker genes in each cluster. The plots for some other markers are also depicted in Supplementary Fig. S4c. c Spatial distribution of the expression levels of NKX2-1 (left) and HNF4A (right). The ROI-1 is represented as a dashed square. d Gene expression levels in the boundary region (ROI-1). e Gene set enrichment analysis on genes that were highly expressed in cluster 6 using Metascape (version 3.5). The p -values were calculated based on the hypergeometric test by Metascape. f Expression of IDO1 and representative cell markers in PhenoCycler immunostaining. Left: ROI-1. Right: an enlarged view of the white square in the left panel. g The spatial distribution of the expression levels of MUC5AC and SPINK1. The ROI-2 is represented as a dashed square. h PhenoCycler immunostaining in the mucin-negative, invasive area. Top: ROI-2. Bottom: an enlarged view of the white square in the top panel. i Expression of CAF markers and representative DEGs in the mucin-negative area (ROI-2). Source data are provided as a Source Data file for (e).

---

### Application of transcriptional gene modules to analysis of' gene expression data [^62a65936]. G3 (2020). Medium credibility.

To enable functional evaluation of the modules, it is useful to summarize them as discrete gene sets. To this end, we partitioned each column of the S matrix into three sets of genes: one set consisting of genes excluded from the module, and two other sets consisting of genes implied to be regulated in opposite directions. We refer to these latter two sets as "hemi-modules" "a" and "b", one set consisting of genes with highly positive weights and the other consisting of genes with highly negative weights (signs assigned based on skewness) in the independent component. Thus, module genes regulated in one direction (up or down) are part of one hemi-module and genes regulated in the opposite direction (down or up) are part of the other hemi-module. The "a" hemi-module is derived from the more highly skewed side of the independent component, and is usually larger (i.e. contains more genes). While others have used a fixed-threshold approach to component partitioning; for example, defining genes with weights exceeding +/− 3 standard deviations from the component mean to be "in" each hemi-module, we found that different individual modules showed maximum annotation enrichments at different thresholds, suggesting that a 'one-size-fits-all' approach to partitioning was sub-optimal. An alternative approach to partitioning that we attempted (described in) failed to converge in many cases (data not shown). Therefore, to increase partitioning accuracy, we trained a function to predict partitioning thresholds from the shape of component distributions. Because plots of training data revealed a complex solution surface, we decided to use an artificial neural network (ANN) to predict partitioning thresholds for each component from the skewness and kurtosis of its distribution. The output of the ANN, i.e. predicted partitioning thresholds, is shown in Figure S2a. Although using a fixed-threshold approach to module partitioning produced similar results qualitatively (Figures S2b-d), it resulted in fewer significant annotations across the range of parameters tested than did ANN-based partitioning (P < 2.2E-16, Figure S2e). Because the mean optimum number of extracted components (dashed vertical lines in Figure 2a-c and Figures S2b-d) was similar for both threshold and ANN partitioning (209, and 209.33, respectively), we chose 209 as the final number of components to extract from the compendium.

---

### Induction and inhibition of drosophila X chromosome gene expression are both impeded by the dosage compensation complex [^3c58f057]. G3 (2022). Medium credibility.

DE genes are further from DCC HAS

A complementary way to assess the effect of the DCC on differential gene expression is to measure the distance to the nearest DCC HAS for each gene. We cannot test for differences in distance to HAS between DE genes and non-DE genes because there are too few X-linked DE genes for statistical testing. Instead, we calculated the correlation between distance to the nearest HAS and log 2 FC for all genes, regardless of whether they are significantly DE.

First, we considered |log 2 FC| as a measure of the extent of differential expression, regardless of up- or downregulation. In nearly all combinations of treatments, HAS datasets, and sexes, there was a positive correlation between |log 2 FC| and distance from an HAS (Fig. 6a). Therefore, X-linked genes further from an HAS were more DE following bacterial infection, viral infection, or abiotic treatment. This is consistent with the hypothesis that the DCC inhibits differential expression (i.e. both up- and downregulation).

Fig. 6.
Correlations between distance from a dosage compensation complex HAS and the log 2 fold-change in expression between treatment and control (log 2 FC). Each dot is the rank order correlation (ρ) between distance to the nearest HAS and log 2 FC. Error bars show the 95% confidence interval determined by bootstrap resampling the data 1,000 times. The X -axis shows the specific treatment. Dots and error bars are colored based on the sex of the flies used in the experiment (see legend). HAS were obtained from 2 different datasets, with results from the 2 different datasets shown separately in the 2 columns. Correlations are plotted with |log 2 FC| values for all genes (a), only genes with log 2 FC > 0 (b), and only genes with log 2 FC < 0 (c).

---

### NCCN guidelines® insights: melanoma: cutaneous, version 2.2024 [^a6d6fda7]. Journal of the National Comprehensive Cancer Network (2024). High credibility.

Gene expression profiling limitations — although gene expression profiling for melanoma could be an enormously valuable contribution to understanding the biology of the disease, results across studies aimed at defining the most predictive gene sets show inconsistency with minimal overlap in specific genes thought to be predictive of outcome, and identification and validation of a prognostic gene expression profile is a complicated multi-step and often multi-study process in which specifics of study design and methodology can impact the end result.

---

### Clinical genetic counseling and translation considerations for polygenic scores in personalized risk assessments: a practice resource from the National Society of Genetic Counselors [^44d1cb0a]. Journal of Genetic Counseling (2023). High credibility.

Polygenic score (PGS) development and validation — A PGS is a single value representing a relative risk of a condition compared with an individual in the population at average risk, derived from associated SNPs identified by genome-wide association studies (GWAS). Calculation relies on two components: (1) effect estimates per risk allele from a GWAS for the phenotype of interest and (2) genotype data for the individual to which the GWAS estimates are applied; for each individual, the PGS is calculated by summing the number of risk alleles (0, 1, or 2 copies) weighted by the GWAS effect size. Integrated risk model fitting combines a polygenic risk score (PRS) with demographics (age, sex, ancestry), genetic data, and non-genetic variables to predict the outcome of interest, expressed as "Predicted outcome of interest = Final PRS + Demographics + Non-genetic variables". Validation uses a PRS validation sample with the same inputs and includes application to a validation cohort external from training. Evaluation components shown include PRS distribution, risk model calibration using Hosmer–Lemeshow (χ2), risk model discrimination with AUROC (AUC) and reclassification, and risk model predictive ability via PRS effect size R2.

---

### Roflumilast (Zoryve) [^11a5acd0]. FDA (2024). Medium credibility.

The dosage of roflumilast TOP for treatment of plaque psoriasis in both children (in patients 6–12 years) is 1 application(s) TOP daily (0.3% cream)

---