# Medical Question & Answer

**Sample ID**: 92fc0ab4-55dc-d7b8-a471-4b265a310939
**Dataset Index**: 102479

---

## Question

9.2. Given one hundred numbers: $1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \ldots, \frac{1}{100}$. We will compute 98 differences: $a_{1}=1-\frac{1}{3}, a_{2}=\frac{1}{2}-\frac{1}{4}, \ldots$, $a_{98}=\frac{1}{98}-\frac{1}{100}$. What is the sum of all these differences?

---

## Answer

> Let's see… What do we have here? The user is asking for the sum of 98 differences of the form a_k = 1/k − 1/(k+2) for k = 1, 2,…, 98. Let's break this down step-by-step. First, I need to think about the exact pattern of terms and confirm the general form. Then, I should verify whether this is a telescoping series and identify which terms cancel. Next, I will write out the partial sums explicitly to see what remains. Finally, I will compute the exact sum and double-check the arithmetic.

> Let me first confirm the pattern. The differences are a_1 = 1 − 1/3, a_2 = 1/2 − 1/4, a_3 = 1/3 − 1/5, and so on, up to a_98 = 1/98 − 1/100, so the general term is indeed a_k = 1/k − 1/(k+2) for k = 1 to 98 [^notfound].

> Wait, let me verify whether this telescopes. A telescoping series has terms that cancel in pairs when summed; here, the negative part of a_k is −1/(k+2), and the positive part of a_{k+2} is +1/(k+2), so those should cancel across the sum, leaving only a few terms at the beginning and end. I should confirm that the indices align correctly for cancellation.

> I will now examine the partial sums to make the cancellation explicit. The sum S = Σ_{k = 1}^{98} (1/k − 1/(k+2)) can be written as (1 − 1/3) + (1/2 − 1/4) + (1/3 − 1/5) + (1/4 − 1/6) +… + (1/97 − 1/99) + (1/98 − 1/100). Let me think about which terms survive: the −1/3 cancels with +1/3, the −1/4 cancels with +1/4, and this pattern continues so that most intermediate terms vanish, leaving 1 + 1/2 − 1/99 − 1/100.

> Hold on, I should verify the surviving terms. The positive terms that do not get canceled are the first two: 1 and 1/2, and the negative terms that do not get canceled are the last two: −1/99 and −1/100, so the sum simplifies to 1 + 1/2 − 1/99 − 1/100. Let me double-check that I haven't missed any uncanceled terms; no, the pattern holds consistently across the 98 terms.

> Next, I should review the arithmetic. 1 + 1/2 equals 3/2, and 1/99 + 1/100 equals (100 + 99)/(99 × 100) = 199/9900, so the sum is 3/2 − 199/9900. Converting to a common denominator, 3/2 = 14850/9900, so 14850/9900 − 199/9900 = 14651/9900. I should confirm that this fraction is in lowest terms; 14651 and 9900 share no obvious common factors, so the simplified form is 14651/9900.

> But wait, what if I misstated the last term earlier? I initially thought the final negative term was −1/98, but that would be incorrect; the last difference is a_98 = 1/98 − 1/100, so the uncanceled negative terms are indeed −1/99 and −1/100, not −1/98. I should correct that mistake explicitly to avoid confusion.

> Final answer: The sum of all 98 differences is 14651/9900. Let me reconsider the steps to ensure no arithmetic error: the telescoping logic is sound, the surviving terms are correct, and the subtraction 14850/9900 − 199/9900 does equal 14651/9900, so I am confident in this result.

---

The sum of the 98 differences is a **telescoping series** that simplifies to (1 + \\frac{1}{2} - \\frac{1}{99} - \\frac{1}{100}). Calculating this gives (\\frac{14651}{9900}), which is approximately 1.4799.

---

## Step-by-step solution

### Step 1: identify the pattern

The differences are of the form:

[
a_k = \\frac{1}{k} - \\frac{1}{k+2}
]

for (k = 1, 2, \\ldots, 98).

---

### Step 2: write out the series

The sum is:

[
\\sum_{k = 1}^{98} \\left(\\frac{1}{k} - \\frac{1}{k+2} \\right)
]

Expanding this, we get:

[
\\left(1 - \\frac{1}{3}\\right) + \\left(\\frac{1}{2} - \\frac{1}{4}\\right) + \\left(\\frac{1}{3} - \\frac{1}{5}\\right) + \\cdots + \\left(\\frac{1}{98} - \\frac{1}{100}\\right)
]

---

### Step 3: observe telescoping cancellation

Most terms cancel out: the (-\\frac{1}{3}) from the first term cancels with the (+\\frac{1}{3}) from the third term, the (-\\frac{1}{4}) from the second term cancels with the (+\\frac{1}{4}) from the fourth term, and so on. The remaining terms are:

[
1 + \\frac{1}{2} - \\frac{1}{99} - \\frac{1}{100}
]

---

### Step 4: compute the exact sum

Combine the remaining terms:

[
1 + \\frac{1}{2} - \\frac{1}{99} - \\frac{1}{100} = \\frac{3}{2} - \\left(\\frac{1}{99} + \\frac{1}{100}\\right)
]

Calculate the sum of fractions:

[
\\frac{1}{99} + \\frac{1}{100} = \\frac{100 + 99}{9900} = \\frac{199}{9900}
]

Subtract from (\\frac{3}{2}):

[
\\frac{3}{2} - \\frac{199}{9900} = \\frac{14850}{9900} - \\frac{199}{9900} = \\frac{14651}{9900}
]

---

### Step 5: approximate the decimal value

[
\\frac{14651}{9900} \\approx 1.4799
]

---

The sum of the 98 differences is (\\boxed{\\frac{14651}{9900}}), or approximately 1.4799.

---

## References

### Quantification of network structural dissimilarities [^3cf663e0]. Nature Communications (2017). Medium credibility.

Identifying and quantifying dissimilarities among graphs is a fundamental and challenging problem of practical importance in many fields of science. Current methods of network comparison are limited to extract only partial information or are computationally very demanding. Here we propose an efficient and precise measure for network comparison, which is based on quantifying differences among distance probability distributions extracted from the networks. Extensive experiments on synthetic and real-world networks show that this measure returns non-zero values only when the graphs are non-isomorphic. Most importantly, the measure proposed here can identify and quantify structural topological differences that have a practical impact on the information flow through the network, such as the presence or absence of critical links that connect or disconnect connected components.

---

### Estimating disease prevalence in large datasets using genetic risk scores [^b1d0401c]. Nature Communications (2021). High credibility.

The Means method

This compares the mean GRS of the mixture cohort to the means of the two reference cohorts and estimates the mixture proportion according to the normalised difference between the two (Fig. 1c).

The Earth Mover’s Distance (EMD) method

This uses the weighted cost of transforming the mixture distribution into each reference distribution (more formally, the integral of the difference between the cumulative density functions, i.e. the area between the curves). This method allowsandto be computed independently (Fig. 1d) and so provides a way to validate the assumption that the mixture is composed solely of the samples from the two reference cohorts,; if the sum is significantly different from 1, then the assumption is not satisfied. In this study, we use the mean of the two estimates forandas the estimate of the.

The Kernel Density Estimation (KDE) method

This method fits a smoothed template to each reference distribution (by convolving each sample with a Gaussian kernel) and builds a model of the mixture as a weighted sum of these two templates. The method then adjusts the proportion of these templates with the Levenberg–Marquardt (damped least squares) algorithm until the sum optimally fits the mixture distribution (Fig. 1e), noting that the algorithm could find one of the potentially several local minima. In other words, the method finds (one of) the linear (convex) combination(s) of the reference distributions that best fits the mixture distribution.

---

### Power of data in quantum machine learning [^03099894]. Nature Communications (2021). High credibility.

Given some set of data, if s K (N) is found to be small relative to N after training for a classical ML model, this quantum model f (x) can be predicted accurately even if f (x) is hard to compute classically for any given x. In order to formally evaluate the potential for quantum prediction advantage generally, one must take s K (N) to be the minimal over efficient classical models. However, we will be more focused on minimally attainable values over a reasonable set of classical methods with tuned hyperparameters. This prescribes an effective method for evaluating potential quantum advantage in practice, and already rules out a considerable number of examples from the literature.

From the bound, we can see that the potential advantage for one ML algorithm defined by K 1 to predict better than another ML algorithm defined by K 2 depends on the largest possible separation betweenandfor a dataset. The separation can be characterized by defining an asymmetric geometric difference that depends on the dataset, but is independent of the function values or labels. Hence evaluating this quantity is a good first step in understanding if there is a potential for quantum advantage, as shown in Fig. 1. This quantity is defined bywhere ∣∣. ∣∣ ∞ is the spectral norm of the resulting matrix and we assume Tr(K 1) = Tr(K 2) = N. One can show that, which implies the prediction error bound. A detailed derivation is given in Supplementary Section C and an illustration of g 12 can be found in Fig. 2. The geometric difference g (K 1 ∣∣ K 2) can be computed on a classical computer by performing a singular value decomposition of the N × N matrices K 1 and K 2. Standard numerical analysis packagesprovide highly efficient computation of a singular value decomposition in time at most order N 3. Intuitively, if K 1 (x i, x j) is small/large when K 2 (x i, x j) is small/large, then the geometric difference g 12 is a small value ~1, where g 12 grows as the kernels deviate.

---

### Inconsistency between overall and subgroup analyses [^eed221ea]. General Psychiatry (2022). Medium credibility.

In table 3, we use numerical examples to show that if p 1 ≠ p 2 and d 1 d 2 ≠0, all combinations of 1–9 and 13 in table 2 may occur.

Table 3 
Numerical examples of Δ 0, Δ 1 and Δ when p 1 ≠ p 2 and d 1 d 2 ≠0

The following theorem gives a more general sufficient condition of consistency than the first three cases discussed above.

Theorem : given Δ 0 and Δ 1, for any p 1 and p 2 between 0 and 1, there always exists a p between 0 and 1 such that Δ=Δ 0 p +Δ 1 (1− p) if and only if p 1 = p 2 or d 1 d 2 ≤0.

The proof of this theorem is available on request. Note that d 1 d 2 =0 implies d 1 d 2 ≤0.

Unfortunately, if we are only given the information that p 1 ≠ p 2 and d 1 d 2 >0, we cannot determine whether the inconsistency will happen. For example, combinations 1 and 3 satisfy the condition of p 1 ≠ p 2 and d 1 d 2 >0. In combination 1, the overall difference is consistent with the subgroup differences, while it is not in combination 3.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^dee6cacc]. CDC (2011). Medium credibility.

Community viral load sample size calculations—sample size to detect differences in geometric mean (GM) viral load depends on power and standard deviation (S). The table specifies “α = 0.05 and W = 0.8,” with S columns 1 to 1.5; for k = 3 the minimum sample sizes by S are 54, 66, 78, 92, 106, and 122, and “1.2 is the standard deviation of national VL data,” so at S = 1.2 the needed sample size is 78.

---

### The minimum clinically important difference: which direction to take [^056cd2ac]. European Journal of Neurology (2019). Medium credibility.

Over the past decades in modern medicine, there has been a shift from statistical significance to clinical relevance when it comes to interpreting results from clinical trials. A concept that is increasingly being used as a surrogate for clinical relevance and effect size calculation is the minimum clinically important difference (MCID). In this paper, an overview is presented of the most important aspects of the MCID concept used in research trials and a discussion of what this means for the neurological patient in clinical trials and daily practice is given. Is the MCID the best outcome measure cut-off to be implemented?

---

### Agreement between methods [^ce77f1f2]. Kidney International (2008). Low credibility.

Before new tests are implemented, it is important to compare their results with those of other measurement methods that are already in use. In the determination of this so-called agreement between methods, one may choose between several statistical approaches. The correlation coefficient is a popular approach to determine the agreement between measurement methods. It is easy to calculate, but has important limitations: it does not provide any information on the type of association and it is extremely sensitive to the range of values within the study. Finally, a correlation coefficient does not reveal whether any difference between two measurements is systematic or random. Therefore, it is highly preferable to use Bland-Altman plots instead, as these reveal both systematic and random errors. Bland-Altman plots are also preferable in case of repeated measurements and calibrations.

---

### Lung ultrasound in COVID-19 and post-COVID-19 patients, an evidence-based approach [^40286608]. Journal of Ultrasound in Medicine (2022). Medium credibility.

Figure 5 shows how the distributions of scores vary with different systems, for both COVID‐19 (Figure 5 ‐a) and post‐COVID‐19 (Figure 5b) patients. As introduced in the Materials and Methods section, five systems have been investigated, that is, system 1 (scanned areas, 7, 9, 12, and 14), system 2 (scanned areas, 7–14), system 3 (scanned areas, 1, 3, 4, 6, and 7–14), system 4 (scanned areas, 1–14), and a system based on 10 scanning areas (scanned areas 7–14 plus 2 posterior areas). Figure 5 shows how the trend of score distributions and percentage of agreement is similar when evaluating COVID‐19 patients (Figure 5a) and post‐COVID‐19 patients (Figure 5b). In fact, even though the score distributions of these two groups are significantly different, the levels of agreement with system 4 for systems 1, 2, and 3 are 65, 76, and 98% for COVID‐19 patients (Figure 5a, top right), and 68, 82, and 97% for post‐COVID‐19 patients (Figure 5b, top right). Consistently with a previous study,for this type of analysis the level of agreement was computed by summing the number of patients sharing the same worst score from the reference protocol and dividing it by the total number of patients.

---

### How to evaluate agreement between quantitative measurements [^7316afc8]. Radiotherapy and Oncology (2019). Medium credibility.

When a method comparison study is performed, the aim is to evaluate the agreement of measurements of different methods. We present the Bland-Altman plot with limits of agreement as the correct analysis methodology. We also discuss other scaled and unscaled indices of agreement and commonly used inappropriate approaches.

---

### The null need not be nil: clarifying the parallel arbitrariness of difference testing and equivalence testing [^8675289c]. The American Journal of Clinical Nutrition (2025). Medium credibility.

In every statistical analysis, a critical step is to determine the smallest effect size of interest, namely, the arbitrary dividing line between meaningful and negligible results. Different tests address this in different ways, and the contrasting approaches can sometimes lead to confusion. We discuss a key example of such confusion, whereby equivalence testing is perceived to be more arbitrary than difference testing. Our comments are intended to clarify that the latter methods share parallel arbitrariness, and to show how the contrary perception is fueled by the habituated use of "nil null hypotheses" in difference testing. The main premise is that nil null hypotheses give an appearance of objectivity by making the smallest effect size of interest an implicit factor in the interpretation stage of difference testing. When contrasted with the requirements of equivalence testing (where the smallest effect size of interest must be explicitly declared and justified a priori, in the form of the equivalence zone), it is therefore understandable how the misperception of greater arbitrariness could emerge. By combating the latter misperception, our comments serve to promote good practice in both difference testing and equivalence testing.

---

### The timescale and direction of influence of a third inferior alternative in human value-learning [^4834d9cf]. Communications Psychology (2025). Medium credibility.

In particular, in the range normalization model, each alternative value is divided by the range of all values (i.e. maximum minus minimum) in the current context –. Therefore, when the context features a higher distractor value, it leads to a narrower range or smaller normalization term. This gives rise to a higher distorted value (i.e. subjective value) for both of the two high-value alternatives (Fig. 1A, right), and a greater difference between them (Fig. 1A, right, embedded plot), effectively leading to a positive distractor effect (Fig. 1B, right). By contrast, in the divisive normalization model, each value is normalized by the sum of all values in the context. Thus, a higher distractor value results in a larger normalization term, dwarfing both the values of the two high-value alternatives (Fig. 1A, middle) and their value difference (Fig. 1A, middle, embedded plot). Consequently, this type of distortion gives rise to a negative distractor effect (Fig. 1B, middle).

---

### Foundations of the minimal clinically important difference for imaging [^72f785d9]. The Journal of Rheumatology (2001). Low credibility.

This article develops a generic conceptual framework for defining and validating the concept of minimal clinically important difference. We propose 3 approaches. The first uses statistical descriptions of the population ("distribution based"), the second relies on experts ("opinion based"), and a third is based on sequential hypothesis formation and testing ("predictive/data driven based"). The first 2 approaches serve as proxies for the third, which is an experimentally driven approach, asking such questions as "What carries the least penalty?" or "What imparts the greatest gain?" As an experimental approach, it has the expected drawbacks, including the need for greater resources, and the need to tolerate trial and error en route, compared to the other 2 models.

---

### Guidance on community viral load: a family of measures, definitions, and method for calculation [^b1513dd5]. CDC (2011). Medium credibility.

Table 1b—Minimum sample size for detecting geometric mean (GM) ratio k with α = 0.05 and W = 0.9—presents required sample sizes by standard deviation (S) strata and defines parameters; α is significance level, W is power, GM is geometric mean, and S is standard deviation, noting that 1.2 is the standard deviation of national viral load (VL) data. Each jurisdiction will need to assess the standard deviation of their local VL data and then determine the appropriate sample size needed to assess VL, and if the sample size is inadequate to meet the recommended case inclusion criterion, an alternate method may need to be used, such as combining multiple years of data. For k = 3, sample sizes across S = 1, 1.1, 1.2, 1.3, 1.4, 1.5 are 75, 91, 108, 127, 147, 169, and Table 1b uses power=90%; jurisdictions may also explore differences in means of viral loads, including categorical differences in the proportion with undetectable or very low VL.

---

### Advanced statistics: how to determine whether your intervention is different, at least as effective as, or equivalent: a basic introduction [^c348bbfc]. Academic Emergency Medicine (2005). Low credibility.

The majority of studies published in the emergency medicine literature attempt to show a difference between two interventions, but often fail to do so. Failing to detect a difference, however, is not the same as demonstrating that one intervention is at least as effective as or better than the other intervention, or that the two interventions are equivalent--a fine point that is often overlooked. The purpose of this paper is to review classical hypothesis testing and then introduce the methodology to determine whether one intervention is at least as effective as another intervention, or whether two interventions are equivalent. Appreciating the conceptual differences between failing to find a difference, demonstrating that one intervention is at least as effective as another, and demonstrating equivalence may lead to a better understanding of the true significance or potential significance of study results.

---

### The brain represents people as the mental States they habitually experience [^f0506a28]. Nature Communications (2019). High credibility.

Discussion

The current findings support the hypothesis that the mind and brain represent other people in terms of their habitual mental states. Specifically, we find that neural representations of people are composed of combinations of representations of the mental states those people are perceived to frequently experience. The summed state account outperformed an optimal version of the established trait account of person perception. That is, across multiple independent neural, behavioral, and text data sets, summed states provided a more robust explanation than traditional traits for how people perceive others. Together, the present findings suggest that we track other people’s idiosyncrasies using differences in the frequencies with which they experience specific thoughts and feelings.

The direct test lends strong support to the summed state hypothesis. This analysis predicted brain activity elicited by thinking about people using brain activity elicited by reasoning about mental states in different samples. None of the three imaging samples were aware of one another’s existence, nor the hypothesis that their responses would help test. Despite differences in participants, scanners, and tasks, summed states accurately reconstructed person-specific neural patterns. This finding suggests that encoding dispositions in terms of habitual mental states is spontaneous, generalizable, and reliant on a common neural code shared across brains. These reconstructions based on states are specific to individual targets, even though all target patterns were elicited with identical sets of situation items (Supplementary Table 1).

Notably, summed states were able to reconstruct person-specific patterns even when they were not particularly trait-like or long-lasting. The more trait-like a state is perceived to be, or the longer it is perceived to last, the more it contributes to pattern reconstruction accuracy (see Supplemental Methods). Interestingly, trait-diagnosticity has the opposite effect: more trait-diagnostic summed states contribute less to accurately reconstructing person-specific patterns. Importantly, even the shortest, least trait-like states (e.g. ecstasy), and minimally trait-diagnostic states could be summed to recover neural representations of people. This finding helps to further differentiate summed states from traits, by demonstrating a value of summed states that cannot be attributed to any trait-like qualities, nor to any trait impressions formed while considering a state. This latter possibility is particularly unlikely, since states elicited in the State Studies often suggested contradictory traits, if any.

---

### Fentanyl (Subsys) [^b18e70d7]. FDA (2021). Medium credibility.

14 CLINICAL STUDIES

The efficacy of SUBSYS was demonstrated in a double-blind, placebo-controlled, crossover study in opioid tolerant adult patients with cancer and breakthrough pain. The dose range studied was from 100 mcg per dose to 1600 mcg per dose. Patients entering the trial must have had on average 1-4 episodes of pain per day not controlled on stable, chronic maintenance doses of opioid medication of at least 60 mg/day of morphine, 25 mcg/hr of transdermal fentanyl, or an equianalgesic dose of another opioid for at least 7 days.

The study began with an open-label dose titration period followed by a double-blind treatment period. The goal of titration was to find the dose of SUBSYS that provided adequate analgesia with acceptable side effects. Patients were titrated from a 100 mcg starting dose. Once a successful dose was established, patients were enrolled into the double-blind period and randomized to a sequence of 10 treatments; 7 with SUBSYS and 3 with placebo.

Patients assessed pain intensity on a 100 mm visual analog scale that rated the pain as 0=none to 100=worst possible pain. With each episode of breakthrough pain, pain intensity was assessed first and then treatment was administered. Pain intensity (0-100) was then measured at 5, 10, 15, 30, 45 and 60 minutes after the start of administration. The summed pain intensity difference from baseline to 30 minutes after dosing was the primary efficacy measure.

Out of 130 patients who entered the titration phase, 98 (75%) were able to titrate to a dose that adequately reduced pain with tolerable side effects and entered into the double-blind period.

The breakdown of successful dose for the patients entering the double-blind period of the study is as follows:

SUBSYS produced a statistically significantly greater reduction in pain intensity compared to placebo as measured by the Summed Pain Intensity Differences scale (SPID) at 30 minutes.

The primary outcome measure, the mean sum of the pain intensity difference at 30 minutes (SPID30), was statistically significantly higher for SUBSYS than for placebo. The difference in mean pain intensity based on a 100 mm visual analog scale is displayed in Figure 3 .

Figure 3. Pain Intensity Differences over Time

---

### Minimal important change and difference in health outcome: an overview of approaches, concepts, and methods [^58a52044]. Osteoarthritis and Cartilage (2024). Medium credibility.

Objective

To provide an overview of approaches, concepts, and methods used to define and assess minimal important change and difference in health outcome.

Method

A narrative review of the literature, guided by a conceptual framework.

Results

We distinguish between (i) interpretation of health outcome in individuals versus groups, (ii) change within individuals or groups versus difference between change within individuals or groups; and (iii) the responder approach (based on the proportion of patients that obtain a defined response) versus the group average approach (based on the average amount of change in a group). We review approaches, concepts, and methods.

Conclusion

By bringing together and juxtaposing various approaches, concepts, and methods, we set a precursory step in the direction of consensus building in the field concerned with defining and assessing minimal important change and difference in health outcome. We emphasize the need for conceptual clarification and terminological standardization. We argue that assessing minimal importance of change and difference in health outcome is essentially a value judgment involving a range of considerations and perspectives.

---

### Agreement analysis: what He said, she said versus you said [^60d2f4d8]. Anesthesia and Analgesia (2018). Low credibility.

Correlation and agreement are 2 concepts that are widely applied in the medical literature and clinical practice to assess for the presence and strength of an association. However, because correlation and agreement are conceptually distinct, they require the use of different statistics. Agreement is a concept that is closely related to but fundamentally different from and often confused with correlation. The idea of agreement refers to the notion of reproducibility of clinical evaluations or biomedical measurements. The intraclass correlation coefficient is a commonly applied measure of agreement for continuous data. The intraclass correlation coefficient can be validly applied specifically to assess intrarater reliability and interrater reliability. As its name implies, the Lin concordance correlation coefficient is another measure of agreement or concordance. In undertaking a comparison of a new measurement technique with an established one, it is necessary to determine whether they agree sufficiently for the new to replace the old. Bland and Altman demonstrated that using a correlation coefficient is not appropriate for assessing the interchangeability of 2 such measurement methods. They in turn described an alternative approach, the since widely applied graphical Bland-Altman Plot, which is based on a simple estimation of the mean and standard deviation of differences between measurements by the 2 methods. In reading a medical journal article that includes the interpretation of diagnostic tests and application of diagnostic criteria, attention is conventionally focused on aspects like sensitivity, specificity, predictive values, and likelihood ratios. However, if the clinicians who interpret the test cannot agree on its interpretation and resulting typically dichotomous or binary diagnosis, the test results will be of little practical use. Such agreement between observers (interobserver agreement) about a dichotomous or binary variable is often reported as the kappa statistic. Assessing the interrater agreement between observers, in the case of ordinal variables and data, also has important biomedical applicability. Typically, this situation calls for use of the Cohen weighted kappa. Questionnaires, psychometric scales, and diagnostic tests are widespread and increasingly used by not only researchers but also clinicians in their daily practice. It is essential that these questionnaires, scales, and diagnostic tests have a high degree of agreement between observers. It is therefore vital that biomedical researchers and clinicians apply the appropriate statistical measures of agreement to assess the reproducibility and quality of these measurement instruments and decision-making processes.

---

### A simple guide to effect size measures [^1a20b8b8]. JAMA Otolaryngology-- Head & Neck Surgery (2023). High credibility.

Importance

Effect size quantifies the magnitude of the difference or the strength of the association between variables. In clinical research it is important to calculate and report the effect size and the confidence interval (CI) because it is needed for sample size calculation, meaningful interpretation of results, and meta-analyses.

Observations

There are many different effect size measures that can be organized into 2 families or groups-d family and r family. The d family includes measures that quantify the differences between groups. The r family includes measures that quantify the strength of the association. Effect sizes that are presented in the same units as the characteristic being measured and compared are known as nonstandardized or simple effect sizes. The nonstandardized effect sizes have the advantage of being more informative, easier to interpret, and easier to evaluate in the light of clinical significance or practical relevance. Standardized effect sizes are unit-less and are helpful for combining and comparing effects of different outcome measures or across different studies (ie, meta-analysis).

Conclusions and Relevance

The choice of the correct effect size measure depends on the research question, study design, targeted audience, and the statistical assumptions being made. For a complete and meaningful interpretation of results from a clinical research study, the investigator should make clear the type of effect size being reported, its magnitude and direction, degree of uncertainty of the effect size estimate as presented by the CIs, and whether the results are compatible with a clinically meaningful effect.

---

### Claims of' no difference' or' no effect' in cochrane and other systematic reviews [^99180db5]. BMJ Evidence-Based Medicine (2021). High credibility.

These findings suggest that pedagogical and editorial efforts to deal with this problem remain. We are pleased to note that invalid claims of ‘no difference/effect’ are now addressed in the Cochrane handbook.Another example of a relevant initiative is the RevManHAL software.This uses the analyses in the data tables of a completed review; the outcome labels, numerical findings and CIs; and the number of studies and participants contributing to the outcome; and then formats these and pastes them into the Results section of the review. The software also holds two banks of phrases relevant to findings that are either clearly different or are not. Depending on the result, the software randomly selects a single phrase from the appropriate bank of phrases and adds this to the Results section under the appropriate heading and before the relevant formatted numerical data, thus producing text that is less repetitive and more readable.We are grateful to an anonymous reviewer of this article for suggesting the phrases ‘we did not find any eligible evidence of a difference’, and ‘we did not find any eligible evidence of a clear difference’, and these have now been included in the RevManHAL software.

It remains important to recognise the uncertainties inherent in statistical estimates of treatment differences, and the need to distinguish between ‘no evidence of a difference/effect’ and ‘evidence of no difference/effect’. In practical terms, this implies using CIs to assess how confidently important treatment differences can be ruled out and using wording that reflects the probabilistic approach entailed.

Systematic reviews of healthcare interventions need to be as clear as the evidence will support. Many people will read only the abstracts of systematic reviews. Leaving readers with the impression that there is no difference between alternative treatments may result in dangerously misinformed clinical decisions and failure to address important uncertainties in additional research.

---

### Antidepressants and suicidality: a re-analysis of the re-analysis [^ce898552]. Journal of Affective Disorders (2020). Medium credibility.

Background

A recent study by Hengartner and Plöderl describes a strong increase for suicides (odds ratio (OR) of 2.83, 95% CI=1.13-9.67) and suicide attempts (OR=2.38 95%, CI=1.63-3.61) in antidepressant treated patients as compared to placebo. The authors re-analyzed data presented by Khan et al. who found no drug-placebo differences in suicide and suicide attempt rates. Hengartner and Plöderl base their findings on calculating the OR from a 2×2 table of the sum of the events and the totals of the sample sizes across studies. We here argue that pooling data from all drugs may not be the adequate approach.

Methods

We applied a meta-analytical approach to account for between-drug variance and conducted several statistical analyses as a sensitivity analysis. We argue that a more suitable approach for finding an overall effect from several observations is a meta-analytical approach namely the Mantel-Haenszel method without continuity correction.

Results

Our analysis leads to different conclusions as opposed to Hengartner and Plöderl. With the recommended method we estimate an OR of 1.98, 95% CI 0.71-5.50 for suicides and 1.63 (95%CI=1.09-2.43) for suicide attempts.

Limitations

The conducted analysis was restricted to the data available from the previous studies. Possibly, a more extensive search of the literature would lead to different results. However, we showed that re-analysing the re-analysis with several different approaches underlines the necessity of sensitivity analysis.

Conclusion

We could show that, in the case of rare events, the data is very sensitive to different analytical approaches underlining the importance of further investigations.

---

### The minimum clinically important difference: which direction to take [^6104a658]. European Journal of Neurology (2019). Medium credibility.

Minimum clinically important difference: methods

The MCID concept is generally categorized into two main streams: the anchor‐based method and the distribution‐based method 13, 14. Extensive information regarding these (and newer) methods have been published in several excellent reviews 15, 16, 17.

Anchor‐based method

Anchor‐based methods involve comparing the change in the situation of a patient as captured by an outcome measure to an external criterion. This external criterion is often a patient's own categorization of their personal change, e.g. after an intervention. Examples of this method are using a pain score like the visual analogue scale, or a patient global impression of change scale (much worse, somewhat worse, about the same, somewhat better, much better).

Most often researchers will look at the change in a single patient over time, the so‐called ‘within‐patient’ change 18. In a study population, the group who scored ‘somewhat better’ or ‘much better’ is of interest since these people have informed the researcher they have clinical improvement (from the patient's point of view). The next step is to look at the (median) change of the score of the instrument used that is representing the level of assessment of interest, which is often considered as the minimum change that correlates with clinical improvement.

Another anchor‐based method is looking between patients at a single point in time, the so‐called ‘between‐patient’ difference 18. Patients are grouped based on their rating on the external criterion: e.g. pain (I have no pain, I have moderate pain, I have extreme pain). Next, one would look at the (median) scores of the instrument of interest in these groups and then determine the MCID as the difference between the median score of the groups ‘I have moderate pain’ and ‘I have no pain’.

Less commonly adaptations are a combination of within‐person and between‐person and a method in which patients rate their health state in comparison to other patients 19.

---

### Recommendations for genetic testing of inherited eye diseases: report of the American Academy of Ophthalmology task force on genetic testing [^efb2ad15]. Ophthalmology (2012). Medium credibility.

The definition of genetic testing—For the purposes of this document, a genetic test is defined as the sum of 5 parts: (1) the clinical determination that a genetic eye disease is likely to be present, (2) the molecular investigation of genomic DNA samples from 1 or more individuals, (3) analysis of the resulting molecular data in the context of relevant published literature and public databases using appropriate statistical methods, (4) interpretation of the data in the context of the clinical findings, and (5) counseling of the patient about the interpreted findings and their implications, and it is important to consider the cost of all 5 components. The primary differences between modern DNA-based testing and other diagnostic methods are that DNA-based methods (1) can establish the predisposition to a genetic disease decades before the disease will be detectable by even the most sensitive clinical tools and (2) can evaluate numerous molecular hypotheses concurrently.

---

### Minimal clinically important difference: a review of outcome measure score interpretation [^8196dbb8]. Rheumatic Diseases Clinics of North America (2018). Low credibility.

Clinicians, researchers, and outcome stakeholders have the crucial, albeit difficult, task of quantifying when a person or group experiences important change or difference on any given outcome measure, often in response to a specific intervention. The minimal clinically important difference (MCID) provides this quantified value of change/difference for a measure. There are many methods for MCID derivation, which can result in multiple values for the same measure. Thus, it is important for potential users of MCID values to be aware of the nuances of MCID development and cautions for interpreting values. This review outlines MCID-related definitions, methods, and guidelines.

---

### Mean difference, standardized mean difference (SMD), and their use in meta-analysis: as simple as It gets [^265f2068]. The Journal of Clinical Psychiatry (2020). Medium credibility.

In randomized controlled trials (RCTs), endpoint scores, or change scores representing the difference between endpoint and baseline, are values of interest. These values are compared between experimental and control groups, yielding a mean difference between the experimental and control groups for each outcome that is compared. When the mean difference values for a specified outcome, obtained from different RCTs, are all in the same unit (such as when they were all obtained using the same rating instrument), they can be pooled in meta-analysis to yield a summary estimate that is also known as a mean difference (MD). Because pooling of the mean difference from individual RCTs is done after weighting the values for precision, this pooled MD is also known as the weighted mean difference (WMD). Sometimes, different studies use different rating instruments to measure the same outcome; that is, the units of measurement for the outcome of interest are different across studies. In such cases, the mean differences from the different RCTs cannot be pooled. However, these mean differences can be divided by their respective standard deviations (SDs) to yield a statistic known as the standardized mean difference (SMD). The SD that is used as the divisor is usually either the pooled SD or the SD of the control group; in the former instance, the SMD is known as Cohen's d, and in the latter instance, as Glass' delta. SMDs of 0.2, 0.5, and 0.8 are considered small, medium, and large, respectively. SMDs can be pooled in meta-analysis because the unit is uniform across studies. This article presents and explains the different terms and concepts with the help of simple examples.

---

### Repeated behavioral testing and the use of summary measures reveal trait anxiety in preclinical rodent models [^b5910353]. Translational Psychiatry (2025). Medium credibility.

We also examined whether transcripts strongly and consistently associated with individual TA in the mPFC also correlated with TA in the amygdala. Although these regions are functionally connected, their molecular profiles differ due to distinct neuronal subtypes and roles in anxiety regulation. The observed 17.8% overlap in TA-associated genes, though modest, is biologically meaningful - reflecting conserved pathways that may underlie cross-regional coordination within anxiety circuits. This shared subset suggests broader molecular shifts across the network, while the >80% divergence underscores region-specific mechanisms. Identifying genes linked to TA in both regions provides a basis for targeting common molecular nodes and developing more effective pharmacological interventions.

To propose a versatile and feasible protocol for measuring TA, we compared the predictive value of SiMs and SuMs of different tests across all paradigms. We compared the performance of the LD and EPM tests in all conditions, representing opposite ends of the robustness spectrum and this way providing a strong framework for understanding how different anxiety measures behave under varying conditions. We found that the predictive strength for behavior or molecular correlates varies across paradigms. While a single LD test was enough to predict behavior in an aversive environment, two were needed for novel contexts, and all three tests were required to reliably link behavior to molecular outcomes. Our findings demonstrated that SuMs were correlated with fear generalization, but not with the acoustic startle response. In humans, high trait anxiety is predictive of fear generalization, therefore these findings support our hypothesis that SuMs are able to capture a construct closely related to trait anxiety. Our analysis of behavioral predictions showed that the LD test consistently outperformed the EPM across all paradigms. A single LD test provided similar insight comparable to multiple EPM trials; two LD tests achieved 96% of the maximum predictive power, while SuMs based on three LD trials yielded the strongest molecular associations, identifying four times more anxiety-related genes than any EPM-based variable. Based on these findings, we recommend conducting three LD tests (using time and frequency variables) with one day inter-test intervals to achieve more precise behavioral and molecular predictions. Furthermore, using multiple tests that capture different aspects of anxiety, such as the EPM and LD in combination, can yield a more nuanced understanding of anxiety phenotypes. In summary, here we provide a novel behavioral sampling and analysis pipeline to measure TA in preclinical research. We demonstrate that more complex sampling correlates with deeper phenotypic insight, which was confirmed under various conditions, including baseline and aversive testing environments, multiple different test types, in naïve as well as chronic stress-exposed animals, using different cohorts, and across species and sexes of subjects. Notably, the molecular profiling of TA in female rodents is an important next step to examine the potential sex-specific mPFC differences. Using SuMs in experiments boosts behavioral and molecular phenotyping and predictions, consequently reducing the minimally sufficient sample sizes while maximizing the discovery rate of novel treatment candidates. In addition, SuMs reveal a distinct, plasticity-focused gene profile associated with TA. We encourage the adoption of this refined phenotyping approach, to help bridge the translational gap between preclinical and clinical anxiety research.

---

### The elusive goal of pedigree weights [^0c166aa0]. Genetic Epidemiology (2007). Low credibility.

Non-parametric linkage analysis methods generally involve calculating an allele-sharing statistic for each pedigree in a data set, then standardizing and summing the statistics over pedigrees. Pedigrees of different sizes can be weighted differently in the sum, though it is perhaps most common to weight all standardized pedigree statistics equally. Most other common weighting schemes are based on the number of affected individuals in the pedigree. It is also possible to derive optimal weights, which maximize power to detect linkage under particular trait models. We started by investigating three different analytical and simulation-based methods to calculate power and derive optimal weights. We found that simulation methods produce noticeably more accurate power calculations than the other methods. However, although the different calculation methods give different "optimal" weights, the power at those weights is very similar. That is, the analytical calculation methods are sufficient for finding good weights even though the simulation methods are most appropriate for calculating power. In comparing optimal weights for different trait models, we found that the weights vary quite a bit with the model, such that optimal weights for one model are not necessarily powerful at all for other models. Finally, we studied the power of a number of general weighting schemes, and of some new ones that incorporate information on how closely the affected individuals are related. We were able to find some schemes that performed well in the sense of giving reasonably powerful weights for most of the trait models and pedigree types we considered.

---

### Understanding variability: the role of meta-analysis of variance [^a5ed2088]. Psychological Medicine (2024). Medium credibility.

Meta-analyses traditionally compare the difference in means between groups for one or more outcomes of interest. However, they do not compare the spread of data (variability), which could mean that important effects and/or subgroups are missed. To address this, methods to compare variability meta-analytically have recently been developed, making it timely to review them and consider their strengths, weaknesses, and implementation. Using published data from trials in major depression, we demonstrate how the spread of data can impact both overall effect size and the frequency of extreme observations within studies, with potentially important implications for conclusions of meta-analyses, such as the clinical significance of findings. We then describe two methods for assessing group differences in variability meta-analytically: the variance ratio (VR) and coefficient of variation ratio (CVR). We consider the reporting and interpretation of these measures and how they differ from the assessment of heterogeneity between studies. We propose general benchmarks as a guideline for interpreting VR and CVR effects as small, medium, or large. Finally, we discuss some important limitations and practical considerations of VR and CVR and consider the value of integrating variability measures into meta-analyses.

---

### PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews [^cc7a22b3]. BMJ (2021). Excellent credibility.

Effect measures

Item 12. Specify for each outcome the effect measure(s) (such as risk ratio, mean difference) used in the synthesis or presentation of results

Explanation: To interpret a synthesised or study result, users need to know what effect measure was used. Effect measures refer to statistical constructs that compare outcome data between two groups. For instance, a risk ratio is an example of an effect measure that might be used for dichotomous outcomes.The chosen effect measure has implications for interpretation of the findings and might affect the meta-analysis results (such as heterogeneity). Authors might use one effect measure to synthesise results and then re-express the synthesised results using another effect measure. For example, for meta-analyses of standardised mean differences, authors might re-express the combined results in units of a well known measurement scale, and for meta-analyses of risk ratios or odds ratios, authors might re-express results in absolute terms (such as risk difference).Furthermore, authors need to interpret effect estimates in relation to whether the effect is of importance to decision makers. For a particular outcome and effect measure, this requires specification of thresholds (or ranges) used to interpret the size of effect (such as minimally important difference; ranges for no/trivial, small, moderate, and large effects).

Essential elements

Specify for each outcome or type of outcome (such as binary, continuous) the effect measure(s) (such as risk ratio, mean difference) used in the synthesis or presentation of results.
State any thresholds or ranges used to interpret the size of effect (such as minimally important difference; ranges for no/trivial, small, moderate, and large effects) and the rationale for these thresholds.
If synthesised results were re-expressed to a different effect measure, report the methods used to re-express results (such as meta-analysing risk ratios and computing an absolute risk reduction based on an assumed comparator risk).

---

### Editorial commentary: the power of interpretation: utilizing the P value as a spectrum, in addition to effect size, will lead to accurate presentation of results [^14424881]. Arthroscopy (2022). Medium credibility.

Statistics have helped develop evidence-based medicine. Comparing groups and rejecting (or not) a null hypothesis is a main principle of the scientific method. Many studies have demonstrated that drawing conclusions based on the statistical result of a dichotomic P value instead of a spectrum can mislead us to conclude that there is "no difference" between two groups, or two treatments. In addition to the P value, the utilization of effect size (magnitude of difference between studied groups), may help us obtain a better global understanding of the statement "no effect". Although statistical significance does not mean clinical significance, by learning to adequately interpret data, we can disclose transparent results and conclusions, as we ward off our own bias. After all, without appropriate interpretation, we may be blinded from the truth.

---

### 'But is the difference clinically significant?' [^a5c29e21]. Clinical Rehabilitation (2005). Low credibility.

The statement that a difference or change found in a research study is statistically significant is frequently met with the response, 'but is it clinically significant?'. This question seems entirely reasonable and uncontentious until one asks how to determine or define clinical significance. Significance must always have an object; significant to whom? Furthermore it needs elaboration; significant in what way? Once these questions are raised, it becomes apparent that the slick, apparently sensible question is in fact extremely difficult to answer and may have multiple answers: the patient may value being free of discomfort, but the payer may only value achieving less cost in long-term care and the clinician may wish to see change in activities. The use of this question by funding organizations may disadvantage rehabilitation. This Editorial explores the substance of this question, concluding that the question can only be answered by the individual patient concerned, and that research studies should perhaps explore more fully what is actually of significance to patients.

---

### ASNC imaging guidelines for nuclear cardiology procedures: standardized reporting of nuclear cardiology procedures [^42ccf2f5]. Journal of Nuclear Cardiology (2017). Medium credibility.

ASNC standardized reporting—sample template for exercise myocardial perfusion imaging outlines fields for indication, clinical history, technique, stress testing, and findings. Under Indication it states “(select one) (Diagnosis of coronary artery disease/known coronary artery disease/chest pain/shortness of breath/Preoperative assessment/Evaluation of myocardial viability/Risk Stratification/Other).” The clinical history section prompts entries for “Cardiac History,” “Cardiac Risk Factors,” “Prior cardiac imaging and procedures,” “Prior nuclear stress test date,” and “Current symptoms.” Technique instructions include “At rest, the patient received x mCi of x tracer. X minutes later, resting tomographic images of the heart were obtained,” followed by exercise test performance and imaging acquisition details, and note that images were obtained “with ECG gating, for assessment of left ventricular systolic function” and that “All imaging was performed on a x camera and data were analyzed using x software.” Findings specify overall quality, motion, and attenuation, detailed perfusion defect characterization and quantitative reporting—“Quantitative evaluation shows a summed stress score of x, a summed rest score of x, and a summed difference score of x. This represents a myocardial ischemic fraction of x%”—and gated SPECT interpretation that “shows that the left ventricle is normal/enlarged in size and shows normal systolic function.”

---

### Towards a definition of "difference" in osteoarthritis [^eba5c602]. The Journal of Rheumatology (2001). Low credibility.

To assess existing information regarding detectable differences in osteoarthritis (OA), a systematic literature search was conducted up to December 1999. Thirty-three articles were considered methodologically relevant to the definition and categorization of detectable differences in OA. It was determined that the musculoskeletal literature contains a wealth of information that relates to observed changes, much of which is derived from the clinical trials literature, but there have been relatively few methodological studies that have systematically evaluated the nature, categorization, and relevance of the change. Furthermore, most of those that have been published take the perspective of an individual or groups of experts other than that of the patient. This summary of the current literature reveals that the diverse sources of information go part way towards developing an understanding of detectable differences and their importance in the area of OA research and clinical practice. Stakeholders' interests as well as factors that modulate perceptions of importance need to be taken under consideration. In particular, the patient's perspective of the importance of change at an individual level requires further evaluation. This area of clinical research is relatively underdeveloped, but there is considerable opportunity for progress.

---

### Methodology for ACOEM's occupational medicine practice guidelines-2025 revision [^ddfcda33]. ACOEM (2025). High credibility.

ACOEM methodology—baseline comparability measures how well the baseline groups are comparable (e.g., age, gender, prior treatment) and defines scoring criteria: Ratings include a combined assessment for both demographic and outcomes variables. Statistical significance does not need to be present for baseline comparability dissimilarity; a score of “0” may apply if a characteristic(s) or outcome variable(s) difference is likely to affect the study conclusions. Rating is “0” if analyses show that the groups were dissimilar at baseline or it cannot be assessed, and a score of “0” may occur if the baseline comparability is too sparse or key elements are not included pre-intervention. Rating is “0.5” if there is general comparability, though one variable may not be comparable, and a rating of 0.5 should not be given if that variable is a key outcome variable. Rating is “1.0” if there is good comparability for all demographic and outcome variables between the groups at baseline.

---

### Elacestrant (Orserdu) [^25e5bc7d]. FDA (2024). Medium credibility.

The dosage of elacestrant PO for treatment of breast cancer in postmenopausal female adults with ESR1 mutation (advanced or metastatic, ER-positive, HER2-negative, progression after ≥ 1 line of endocrine therapy) is 345 mg PO daily until disease progression or unacceptable toxicity

---

### 2022 ASNC / AAPM / SCCT / SNMMI guideline for the use of CT in hybrid nuclear / CT cardiac imaging [^5d396d58]. Journal of Nuclear Cardiology (2022). High credibility.

CT attenuation correction (AC) for myocardial perfusion imaging (MPI)—performing only one CT for AC of both rest and stress MPI images can be problematic; in a study of 45 females, left breast position changed in 13 (29%), and changes in cardiac position were noted in nearly one-third of studies of men and women; in a retrospective study of 20 patients using the CT attenuation map from other hybrid scans, there was high variability in defect scoring and defect size assessment; on the other hand, another study including 154 patients reprocessed using one CT for both stress and rest images reported high concordance with a kappa (κ) ≥ 0.84 and no significant differences in the summed difference score; similar findings were observed in a study that utilized thallium imaging.

---

### Individual differences among deep neural network models [^58de4c70]. Nature Communications (2020). High credibility.

Fig. 7 
Category centroids are highly consistent across network instances.

a Centroid-based representational consistency (green) remains comparably high throughout, whereas the consistency of within-category distances decreases significantly with increasing network depth (error bars indicate 95% confidence intervals, average data shown, computed from 45 network comparisons across 10 network instances). This indicates that differences in the arrangement of individual category exemplars, rather than large-scale differences between class centroids are the main contributor to the observed individual differences. b High centroid-based representational consistency cannot be explained by the smaller RDMs or the averaging of multiple response patterns, as centroids of randomly sampled classes show a significantly lower mean consistency (95% CI in the light gray background).

The reliable arrangement of category centroids suggests that a main source of the observed individual differences lies in the arrangement of category exemplars within the category clusters themselves. This view was corroborated by computing consistency, not on the whole exemplar-based RDM that contains all pairwise distances, but only on the dissimilarities of exemplars of the same categories (within-category consistency, see “Methods” section). Focusing on within-category distances, we observe a drop in consistency that is largely comparable to the original decrease for exemplar-based consistency computed based on the whole RDM (Fig. 7a).

---

### The gender similarities hypothesis [^e5056dd2]. The American Psychologist (2005). Low credibility.

The differences model, which argues that males and females are vastly different psychologically, dominates the popular media. Here, the author advances a very different view, the gender similarities hypothesis, which holds that males and females are similar on most, but not all, psychological variables. Results from a review of 46 meta-analyses support the gender similarities hypothesis. Gender differences can vary substantially in magnitude at different ages and depend on the context in which measurement occurs. Overinflated claims of gender differences carry substantial costs in areas such as the workplace and relationships.

---

### Guidelines for the standardization of adult echocardiography reporting: recommendations from the American Society of Echocardiography [^5fd207c0]. Journal of the American Society of Echocardiography (2025). High credibility.

Echocardiography report comparisons to prior studies—comparative statements should address technical differences of the comparison study, include the date of the study being compared and whether findings are new, unchanged, resolved, improved, or worsened, and conclude with a summary statement on the clinical significance of the comparison.

---

### Laboratory recommendations for scoring deep molecular responses following treatment for chronic myeloid leukemia [^36b1f427]. Leukemia (2015). Low credibility.

Examples

BCR-ABL1 detected in at least one replicate

Example 1 (Lab CF=0.8):

– BCR-ABL1 replicate 1: detectable in 2 μl cDNA, estimated 7 copies.

– BCR-ABL1 replicate 2: detectable in 2 μl cDNA, estimated 3 copies.

– ABL1 replicate 1: 24 000 copies in 2 μl cDNA.

– ABL1 replicate 2: 28 000 copies in 2 μl cDNA.

Result=(sum BCR-ABL1 =10)/(sum ABL1 =52 000) × 0.8 × 100=0.015% = MMR but not MR 4.

Example 2 (Lab CF=1.8):

– BCR-ABL1 replicate 1: undetectable in 5 μl cDNA.

– BCR-ABL1 replicate 2: detectable in 5 μl cDNA, estimated 3 copies.

– GUSB replicate 1: 43 000 copies in 5 μl cDNA.

– GUSB replicate 2: 49 000 copies in 5 μl cDNA.

Result=(sum BCR-ABL1 =3)/(sum GUSB =92 000) × 1.8 × 100=0.0059% = MR 4.

Comment : Testing laboratories use different amounts of RNA to make cDNA, make different volumes of cDNA and use different volumes of cDNA for individual qPCR assays. The number of reference gene transcripts should be estimated in the same volume of cDNA used to test for BCR-ABL1. The use of other reference genes, for example, BCR, is possible, but the number of transcripts required to define different levels of MR remain to be determined.

Example 3 (Lab CF=0.5):

– BCR-ABL1 replicate 1: undetectable in 5 μl cDNA.

– BCR-ABL1 replicate 2: detectable in 5 μl cDNA, estimated 3 copies.

– ABL1 replicate 1: 9000 copies in 5 μl cDNA.

– ABL1 replicate 2: 8000 copies in 5 μl cDNA.

Result=inevaluable for MR.

Comment : Although the ((sum of BCR-ABL1)/(sum of reference gene)) × CF × 100 is <0.01%, the sample should be considered as inevaluable for the assessment of MR as the ABL1 copy number in each replicate is <10 000.

---

### Single photon emission computed tomography (SPECT) myocardial perfusion imaging guidelines: instrumentation, acquisition, processing, and interpretation [^1c726ccd]. Journal of Nuclear Cardiology (2018). Medium credibility.

Myocardial perfusion SPECT—perfusion defect assessment requires Location (17 segments) and Extent with Qualitative Required; Semiquantitative Optional defined as small 1-2 segments, medium 3-4 segments, and large ≥ 5 segments; and Quantitative Required defined as small <10%, medium 10-20%, and large ≥20%; Severity has Qualitative Optional and Semiquantitative Required with score 0 = normal; mild or score 1 = 10% to <25% count reduction; moderate or score 2 = 25% to <50% count reduction; severe or score 3 = ≥50% reduction in counts; severe or score 4 (background counts); Quantitative (computer generated scores) is Recommended; Reversibility is Required with categories fixed = no reversibility; mildly reversible; moderately reversible; predominantly reversible; predominantly fixed; and Quantitative scores (summed stress score, summed rest score, summed difference score) plus Quantitative % myocardium abnormal, ischemic, scarred are Recommended.

---

### Antibody response in immunocompromised patients after the administration of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) vaccine BNT162b2 or mRNA-1273: a randomized controlled trial [^a61250f5]. Clinical Infectious Diseases (2022). Medium credibility.

Table 1. 
Demographics and Clinical Characteristics of the Study Population at Baseline

Overall, 92.1% of participants randomized to mRNA-1273 (95% CI: 88.4–95.8; 186/202) had an antibody response (Elecsys S test) compared with 94.3% (95% CI: 91.2–97.4; 198/210) randomized to BNT162b2. With a difference of -2.2% (95% CI: -7.1 to 2.7), the vaccine mRNA-1273 from Moderna was noninferior to BNT162b2 from Pfizer-BioNTech (Table 2). This result was confirmed by the ABCORA 2 test for which a total of 89.3% (95% CI: 86.3–92.3; 368/412) had an antibody response (mRNA-1273: 89.1%; 95% CI: 84.8–93.4; 180/202 vs BNT162b2: 89.5%; 95% CI: 85.4–93.7; 188/210). When assessing the ABCORA 2 sum S1 threshold of 17, 83.5% (95% CI: 79.9–87.1; 344/412) had neutralizing antibodies (mRNA-1273: 84.7%; 95% CI: 79.7–89.6; 171/202 vs BNT162b2: 82.4%; 95% CI: 77.2–87.5; 173/210; Table S4). The analyses conducted on the per-protocol dataset were in line with the findings from the intention-to-treat dataset (Table 2 and Table S4). Although all PLWH (341/341) showed an immune response, only 60.6% (95% CI: 49.2–71.9; 43/71) of solid organ transplant recipients had an immune response (Elecsys S test). This number decreased to 39.4% (95% CI: 28.1–50.8; 28/71) among organ transplant recipients when using the more stringent ABCORA 2 test and to 21.1% (95% CI: 11.6–30.6; 15/71) when using the ABCORA 2 sum S1 threshold. Results from prespecified subgroup analyses (Tables S4–6) suggest that fewer patients with a lung transplant had an immune response (48.7%; 95% CI: 33.0–64.1; 19/39) compared with kidney transplant recipients (75.0%; 95% CI: 60.0–90.0; 24/32). Furthermore, 85.7% (95% CI: 67.4–100.0; 12/14) of transplant recipients with less intensive immunosuppressive therapy had an immune response, whereas this was only the case for 54.4% (95% CI: 41.5–67.3; 31/57) of transplant patients with an intensive immunosuppressive therapy. When using a cutoff of 100 U/mL for Elecsys S, the proportion of patients with an immune response decreased to 86.4% (95% CI: 83.1–89.7; 356/412) for all patients, 99.4% (95% CI: 98.6–100.0; 339/341) for PLWH, and 23.9% (95% CI: 14.0–33.9; 17/71) for transplant recipients (Tables S4–6). Sensitivity analyses excluding patients with a reactive antibody test to the protein at baseline were in line with the previously mentioned results (Tables S7–9).

---

### Hip pain and mobility deficits – hip osteoarthritis: clinical practice guidelines linked to the international classification of functioning, disability, and health from the orthopaedic section of the American Physical Therapy Association [^64971058]. The Journal of Orthopaedic and Sports Physical Therapy (2009). Medium credibility.

Hip osteoarthritis—Western Ontario and McMaster Universities Osteoarthritis Index (WOMAC) scoring, reliability, and minimal clinically important difference are detailed as follows: the ordinal-scale version has 24 questions (5 pain, 2 stiffness, 17 physical function) scored between 0 (extreme) and 4 (none), summed to a raw score ranging 0 (best) to 96 (worst) and normalized to 0% (best) to 100% (worst); test–retest reliability by intraclass correlation coefficients ranges 0.74 to 0.86; reported minimal clinically important difference is 12% to 22%, with study-specific findings of 17% to 22% improvement in a sample of 192 lower extremity osteoarthritis patients and a 12% change in a cohort of 122 hip or knee osteoarthritis inpatients.

---

### Evidence-based clinical practice guideline on nonrestorative treatments for carious lesions: a report from the American dental association [^a52e68d8]. Journal of the American Dental Association (2018). Medium credibility.

American Dental Association guideline—eTable 3 (continued) reports network meta-analysis results for Sealant versus no treatment. Total number of studies in network (pooled) is 7. For Sealant, the relative risk is 1.98 (1.62 to 2.44). Absolute effects per 100 at different baseline risks are: without intervention 70 per 100 versus with intervention 139 per 100, a difference of 69 per 100 more (From 43 more to 101 more); without intervention 50 per 100 versus with intervention 99 per 100, a difference of 49 per 100 more (From 31 more to 72 more); and without intervention 20 per 100 versus with intervention 40 per 100, a difference of 20 per 100 more (From 12 more to 29 more). Certainty in the evidence is reported as Moderate (risk of bias†††) with P-score 0.40 (4/7) and Interpretation of findings Superior. No treatment is the reference comparator with P-score 0.00 (7/7).

---

### Thermodynamic control of-1 programmed ribosomal frameshifting [^62363b31]. Nature Communications (2019). High credibility.

Metropolis with Bayesian Inference

The aim is to find the individual base-pair free-energy differences ΔG bp that best reproduce the measured frameshift efficiencies FS experiment. Using Bayesian inference, the probability for the base-pair free-energies iswhere P (ΔG bp) is the prior probability of the base-pair free-energy differences, and P (FS experiment | ΔG bp) is the probability of observing specific frameshift efficiencies FS experiment for given base-pair free-energy differences ΔG bp,where σ experiment, i is the standard deviation of FS experiment, i obtained from repeated measurements (Fig. 1b, Supplementary Table 1), and FS model, i is the i th entry of the vector of frameshift efficiencies FS model estimated from ΔG bp, using Eqs. (1) and (2).

The prior distribution P (ΔG bp) of the vector of base-pair free-energy differences ΔG bp iswhere P (Δ G bp, j) is the prior distribution of free-energy difference of the j th base pair. This prior distribution was chosen to be a uniform distribution between − 25 and 25 kJ/mol.

P (ΔG bp | FS experiment) was sampled using the Metropolis Monte Carlo algorithmin two independent calculations with 10 6 steps. To that aim, we used the functionwhich is proportional to the desired probability distribution (compare to Eq. (4)).

The initial free-energy difference values Δ G bp, j were set to 0 kJ/mol and the function f was evaluated. For each metropolis step, n sub-steps were carried out. For each substep j, first, a new value for the Δ G bp, j was drawn from a normal distribution centered on the current value with a σ of 0.2 kJ/mol. Then, the function f was evaluated with the new Δ G bp, j, and the ratio α of the new and previous value of f was used as the acceptance ratio: If α > 1, the new Δ G bp, j was accepted. If α < 1, a random number u between 0 and 1 was drawn and the new Δ G bp, j value was accepted if u ≤ α and rejected otherwise.

---

### Lessons from COVID-19 mortality data across countries [^d4c1c929]. Journal of Hypertension (2021). Medium credibility.

ALL-CAUSE EXCESS DEATHS FOR COMPARING THE SCALE OF COVID-19 IMPACT

Monitoring all-cause excess deaths (i.e. observed deaths during the epidemic compared with those expected based on mortality in the same periods of previous years) is recommended by several international organizations, including the WHO and the European Centre for Disease Prevention and Control as a more reliable metric for comparing countries.

There are several advantages to using all-cause excess deaths. One is that as well as including deaths directly due to COVID-19 it provides a more comprehensive picture of the crisis impact, including mortality due to reduced access of timely healthcare. Second, because all-cause excess mortality is not based on clinical diagnosis of the cause of death, incomparability due to different diagnostic criteria does not affect its value. Third, because each country is compared with itself, the comparison is not affected by between-country differences in age and comorbidity structure. Fourth, because the all-cause excess mortality rate is much larger than the COVID-19-specific mortality rate, its monitoring on a weekly basis and distribution for age, sex and social strata are less affected by random uncertainty. For example, 1.2-fold excess mortality is detectable as significant where the expected deaths are at least 200 (by accepting a type-1 error of 5% and requiring 80% power). Assuming an eight deaths per 1000 person-year mortality rate, 200 deaths occur every week in a population of 1.3 million residents. Therefore, excess mortality can be investigated on a weekly basis in almost all European and North American countries, and even in several counties/regions. In summary, all-cause excess mortality makes it possible to better understand the overall impact of COVID-19 on population health, and its specific impact on more frail groups within a population. It also facilitates tracking the impact of the pandemic in real-time, if data are reported on at least a weekly basis.

---

### Interpreting trial results-time for confidence and magnitude and not P values please [^f6868fcd]. Kidney International (2019). Medium credibility.

The problems with the P value as the single metric to summarize the results of a study are being recognized. It captures a single domain-random error-but it is relatively uninformative about more critical domains for deciding whether the results should be applied to clinical care and policy. Alternatives include the components of the outcomes reported (relevance, magnitude, frailty, and net benefit) and confidence (risk of bias and directness).

---

### Point-of-care tests detecting HIV nucleic acids for diagnosis of HIV-1 or HIV-2 infection in infants and children aged 18 months or less [^26209b7a]. The Cochrane Database of Systematic Reviews (2021). Medium credibility.

Age

Pooled sensitivity (95% CI) at birth, ≤ 12 months, and ≤ 18 months were 99.0% (98.0 to 100.0), 96.6% (94.3 to 98.0) and 97.9% (91.9 to 99.5), respectively. Sensitivity was statistically different between birth and ≤ 12 months (difference sensitivity (95% CI) 3.4% (1.5 to 5.2)). Sensitivity was not statistically different between birth and ≤ 18 months (difference sensitivity (95% CI) 2.1% (−0.8 to 5.0)) and between ≤ 12 months and ≤ 18 months (difference sensitivity (95% CI) −1.3% (−4.7 to 2.2)). Specificity results were as follows: at birth 99.8% (99.7 to 99.9); at ≤ 12 months 99.6% (99.0 to 99.9); and at ≤ 18 months 99.8% (99.5 to 99.9).

Test type

The pooled sensitivity (95% CI) for the index tests Xpert, Alere, and SAMBA was 99.2% (88.1 to 100), 96.6% (94.0 to 98.1), and 97.3% (94.4 to 98.7), respectively. Specificity results were as follows: Xpert 99.7 (99.5 to 99.8), Alere 99.9% (99.8 to 100), and SAMBA 99.0% (97.5 to 99.7).

Location

The pooled sensitivity (95% CI) was 97.4% (94.8 to 98.7) for index tests conducted in laboratory settings and 98.7% (93.4 to 99.8) for index tests conducted in a field setting (at or near patient site). There was no statistically significant difference in sensitivity between settings: lab minus field was −1.3% (−4.1 to 1.5). Specificity results were as follows: lab 99.6% (99.0 to 99.8) and field 99.8% (99.7 to 99.9).

---

### Mild traumatic brain injury: tissue texture analysis correlated to neuropsychological and DTI findings [^b38debf6]. Academic Radiology (2010). Low credibility.

Rationale and Objectives

The aim of this study was to evaluate whether texture analysis (TA) can detect subtle changes in cerebral tissue caused by mild traumatic brain injury (MTBI) and to determine whether these changes correlate with neuropsychological and diffusion tensor imaging (DTI) findings.

Materials and Methods

Forty-two patients with MTBIs were imaged using 1.5T magnetic resonance imaging within 3 weeks after head injury. TA was performed for the regions corresponding to the mesencephalon, centrum semiovale, and corpus callosum. Using DTI, the fractional anisotropic and apparent diffusion coefficient values for the same regions were evaluated. The same analyses were performed on a group of 10 healthy volunteers. Patients also underwent a battery of neurocognitive tests within 6 weeks after injury.

Results

TA revealed textural differences between the right and left hemispheres in patients with MTBIs, whereas differences were minimal in healthy controls. A significant correlation was found between scores on memory tests and texture parameters (sum of squares, sum entropy, inverse difference moment, and sum average) in patients in the area of the mesencephalon and the genu of the corpus callosum. Significant correlations were also found between texture parameters for the left mesencephalon and both fractional anisotropic and apparent diffusion coefficient values.

Conclusions

The data suggest that heterogeneous texture and abnormal DTI patterns in the area of the mesencephalon may be linked with verbal memory deficits among patients with MTBIs. Therefore, TA combined with DTI in patients with MTBIs may increase the ability to detect early and subtle neuropathologic changes.

---

### The neural correlates of value representation: from single items to bundles [^17ab55c0]. Human Brain Mapping (2023). Medium credibility.

In principle, if a subject's choices are well represented by the Random Utility Model, we should observe that most choices are consistent with estimates and implicit rankings. For each individual, we computed the percentages of choices that were consistent with the value estimates (and henceforth with the implicit rankings) across all conditions and within each condition. We call these percentages Consistency Rates. Note that because implicit ranks are only best estimates, a trial that contradicts the ranking and is categorized as inconsistent may not contradict the true underlying preferences (which are not observed). This means that consistency makes sense as an aggregate measure across choices, but it cannot be used to classify individual trials. Note that there is a connection between Consistency Rates and consistency across trials (in a revealed preference argument sense). When a person never reverts their choices, the value estimates reflect no reversals and the choices all agree with the estimates. The estimates reflect how easy/difficult it is to rank an option with respect to the reference option in a way that matches the proportions of reversals. The Consistency Rate aggregates this information across all options. Last, there is also a relationship between the overall Consistency Rate and λ. The Random Utility Model predicts that reversals are more likely when v j is close to v 0 to an extent modulated by λ. If behavior is consistent with this premise, a low consistency rate is driven by frequent reversals when values are close, which corresponds to a high λ. Said differently, Consistency Rates provide an ex post diagnostic of the uncertainty the person faces to compute subjective values.

2.6 Analysis of reaction times

We recorded the onset of the stimulus and the time at which a choice was made in each trial. We looked at whether trials deemed to be more difficult, as measured by a smaller distance between the estimated value of the on‐screen and off‐screen options, were also taking longer. We also looked for systematic differences across conditions and across the type of choices (on screen vs. off‐screen). For each participant, we computed the mean Reaction Time it took them to deliberate in each of the three conditions. These measures were designed to analyze individual differences across conditions.

---

### Diagnosis of acute appendicitis with sliding slab ray-sum interpretation of low-dose unenhanced CT and standard-dose I.V. contrast-enhanced CT scans [^579a9c37]. AJR: American Journal of Roentgenology (2009). Low credibility.

Objective

The purpose of this study was to compare low-dose unenhanced CT with standard-dose i.v. contrast-enhanced CT in the diagnosis of appendicitis.

Materials and Methods

Two hundred seven adults with suspected appendicitis underwent CT with mean effective doses of both 4.2 and 8.0 mSv. Two radiologists retrospectively reviewed thin-section images by sliding a 5-mm-thick ray-sum slab. They rated the likelihood of appendicitis and appendiceal visualization on 5- and 3-point scales, respectively, and proposed alternative diagnoses. Likelihood > or = 3 was considered a positive diagnosis. Receiver operating characteristics analysis, the McNemar test, and the Wilcoxon's signed-rank test were used.

Results

Seventy-eight patients had appendicitis. The values of the area under the receiver operating characteristics curve were 0.98 for the low-dose unenhanced acquisition and 0.97 for the standard-dose contrast-enhanced acquisition for reader 1 (95% CI for the difference, -0.02 to 0.03) and 0.99 and 0.98 (-0.02 to 0.02) for reader 2. Sensitivity was 98.7% for low-dose unenhanced CT and 100% for standard-dose contrast-enhanced CT for reader 1 (p = 1.00) and 100% for both techniques for reader 2. Specificity was 95.3% and 93.0% (p = 0.25) and 96.9% and 96.9%. The interpretation was indeterminate (score 3) in 0.5% and 1.4% of cases for reader 1 (p = 0.63) and 0.5% and 0% for reader 2 (p = 1.00). A normal appendix was not visualized in 5.4% and 3.9% of cases by reader 1 (p = 0.63) and 3.9% and 2.3% of cases by reader 2 (p = 0.50). None of the patients whose appendix was not visualized had appendicitis. Diagnostic confidence, visualization score for a normal appendix, and correct alternative diagnosis tended to be compromised with use of low-dose unenhanced CT, showing a significant difference for a reader's confidence in the diagnosis of appendicitis (p = 0.004). The two techniques were comparable in the diagnosis of appendiceal perforation.

Conclusion

Low-dose unenhanced CT is potentially useful in the diagnosis of appendicitis.

---

### First-dose ChAdOx1 and BNT162b2 COVID-19 vaccines and thrombocytopenic, thromboembolic and hemorrhagic events in scotland [^f879c23e]. Nature Medicine (2021). Excellent credibility.

ITP

For ITP, the aRR in the period 0–27 d after vaccination for ChAdOx1 was 5.77 (95% CI, 2.41–13.83). This represents an estimated incidence of 1.13 (0.62–1.63) cases per 100,000 doses. This increased risk was first found at 7–13 d after vaccination (aRR = 4.60, 95% CI, 1.37–15.42) and was most pronounced at 21–27 d (aRR = 14.07, 95% CI, 2.46–80.31) (Table 1). The wide CIs reflect the small number of incident ITP cases over the study period. The SCCS post hoc analysis RR for ChAdOx1 vaccination and ITP (28 d after vaccination versus 14 d and 104 d before vaccination) was 1.98 (95% CI, 1.29–3.02) (Supplementary Tables 3 and 4). The difference in expected versus observed events for ITP during the post-ChAdOx1 vaccination period for 40–49-year-old individuals was 0.62 events (95% CI, 0.01–1.36) per 100,000 doses (Table 3). In the adult population studied, the difference in expected versus observed events was 0.46 events (95% CI, −0.44–1.33) per 100,000 doses.

Table 3 
Observed versus expected thrombocytopenia and ITP events after COVID-19 vaccination

a The observed events were incident cases after vaccination counted for the observed duration of the post-vaccination period. b The expected events are the number of events per day in the pre-vaccination period divided by the population and multiplied by the days at risk in the post-vaccination period for all vaccinated and then summed. c The difference between expected (the number of events per day in the pre-vaccination period divided by the population and multiplied by the days at risk in the post-vaccination period for all vaccinated and then summed) and observed events during the post-vaccination period, with CIs obtained from a parametric bootstrap, was based on the Poisson distribution using 10,000 samples. There was limited opportunity for matching in this analysis, and the findings, therefore, need to be interpreted with caution. d n ≤ 5 denotes minimum allowable reported value.

---

### Comparison of different methods of calculating CT radiation effective dose in children [^888e9b66]. AJR: American Journal of Roentgenology (2012). Low credibility.

Objective

CT radiation dose is a subject of intense interest and concern, especially in children. Effective dose, a summation of whole-body exposure weighted by specific organ sensitivities, is most often used to compute and compare radiation dose; however, there is little standardization, and there are numerous different methods of calculating effective dose. This study compares five such methods in a group of children undergoing routine chest CT and explores their advantages and pitfalls.

Materials and Methods

Patient data from 120 pediatric chest CT examinations were retrospectively used to calculate effective dose: two scanner dose-length product (DLP) methods using published sets of conversion factors by Shrimpton and Deak, the imaging performance and assessment of CT (ImPact) calculator method, the Alessio online calculator, and the Huda method.

Results

The Huda method mean effective dose (4.4 ± 2.2 mSv) and Alessio online calculator (5.2 ± 2.8 mSv) yielded higher mean numbers for effective dose than both DLP calculations (Shrimpton, 3.65 ± 1.8 mSv, and Deak, 3.2 ± 1.5 mSv) as well as the ImPact calculator effective dose (3.4 ± 1.7 mSv). Mean differences ranged from 10.2% ± 10.1% lower to 28% ± 37.3% higher than the Shrimpton method (used as the standard for comparison). Differences were more marked at 120 kVp than at 80 or 100 kVp and varied at different ages. Concordance coefficients relative to the Shrimpton DLP method were Deak DLP, 0.907; Alessio online calculator, 0.735; ImPact calculator, 0.926; and Huda, 0.777.

Conclusion

Different methods of computing effective dose for pediatric CT produce varying results. The method used must be clearly described to allay confusion about documenting and communicating dose for archiving as well as comparative research purposes.

---

### The effects of contemporaneous peer punishment on cooperation with the future [^c0626dd4]. Nature Communications (2020). High credibility.

Design

Figure 1 illustrates the game structure and procedures. Exactly 12 participants take part in each session and they are randomly divided into four groups consisting of three participants each. In the baseline condition, participants are informed that they will make (at most) one decision and that there are a total of four sequential groups. Moreover, they are informed about the position of their group in the succession of groups and learn that the allocation of participants to the groups is random. After reading a printout of the instructions (reproduced in Supplementary Note 3) and being given an opportunity to ask clarifying questions, the experiment starts. In the baseline condition, each member of Group 1 is endowed with €10. The three members of this group simultaneously face the same decision: they are required to divide their endowment between a private account and a group account. More precisely, they are required to decide how much money to allocate to the group account while the rest of the endowment automatically remains in their private account. If individual contributions to the group account sum to less than €15, the experiment ends instantly and all participants of later groups are informed that the experiment has ended and that their earning from the experimental task are zero. However, if the sum of contributions to the group account amounts to €15 or more (i.e. at least 50% of the total group endowment), the game continues and moves to the next group (Group 2). Independent from the sum of total contributions in the group account, members of Group 1 earn the respective amounts in their private accounts (i.e. the initial endowment of €10 minus their individual contribution to the group account). If the game is sustained, the same procedure applies for members of Groups 2 and 3. The experiment ends with the decision of the members of Group 3. If the contributions of Group 3’s members to the group account sum to €15 or more, then the members of Group 4 each earn €5. Otherwise, members of Group 4 earn nothing. Reaching the threshold exactly costs €15 to the current generation but provides an endowment of €30 to the subsequent generation(s). There is hence a gain in total earnings (across multiple generations) from reaching the threshold. These potential gains from contributing are largest for members of the first generation, but smaller for participants in subsequent generations (with no such gains from Group 3). Choosing €15 as a threshold value has the advantage of facilitating coordination between group members by allowing for individual contributions of €5 (i.e. 50% of the endowment) to be sufficient for reaching the threshold. Hence, it is a symmetric focal point for coordination. At the same time, individual endowments are smaller than the threshold. Hence, no single group member can unilaterally provide the public good and successful provision requires the cooperation of at least two group members.

---

### Injectable and topical local anesthetics for acute dental pain: 2 systematic reviews [^88f608ae]. Journal of the American Dental Association (2023). High credibility.

Topical benzocaine adverse effects and evidence gaps indicate that there may be no important difference between 20% benzocaine and 10% benzocaine in the proportion experiencing any adverse effect measured from 90 through 120 minutes after application (RD, 0.0%; 95% CI, −3% to 3%; low certainty). Three RCTs also suggest that there may be an important difference favoring benzocaine 10% compared with placebo with regard to the incidence of adverse effects anytime from 10 through 120 minutes after application (RD, −1%; 95% CI, −4% to 3%; low certainty), and evidence from 4 RCTs indicates that there may be an important difference favoring 20% benzocaine compared with placebo with regard to the risk of any adverse effect anytime from 10 through 120 minutes after application (RD, −1%; 95% CI, −4% to 3%; low certainty). Pain levels (measured as sum of pain relief combined with pain intensity difference) at 60 minutes—We did not find any evidence reporting this outcome.

---

### Atlas for reporting PET myocardial perfusion imaging and myocardial blood flow in clinical practice: an information statement from the American Society of Nuclear Cardiology [^fa04c1a7]. Journal of Nuclear Cardiology (2023). High credibility.

Perfusion findings—overall study quality Good with Extra Cardiac Activity Normal and Study Artifacts Motion artifact; LV myocardial perfusion defects state LV perfusion is normal; TID Ratio: 1.09, Normal; LV perfusion quantitative results list Summed Stress Score = 0, Summed Rest Score = 0, and Summed Difference Score = 0.

---

### Quantitative sonographic assessment of the quadriceps femoris muscle in healthy Japanese adults [^047a5b3a]. Journal of Ultrasound in Medicine (2017). Low credibility.

Objectives

The aim of this study was to evaluate the relationships among aging, muscle strength, and image feature analysis of the quadriceps femoris muscle and to evaluate the relationship between aging, muscle strength, and sonographic findings.

Methods

One hundred forty-five healthy volunteers participated in the study. The participants were classified into 6 groups on the basis of sex and age. To assess muscle quality, texture analysis was defined with the following parameters: mean, skewness, kurtosis, inverse difference moment, sum of entropy, and angular second moment. The knee extension force in the sitting position and thickness of the quadriceps femoris muscle were also measured.

Results

The quadriceps femoris thickness, skewness, kurtosis, inverse difference moment, angular second moment, and muscle strength were significantly decreased in elderly participants versus those in the younger and middle-aged groups (P < .05). In contrast, the mean and sum of entropy were significantly decreased in the younger group compared with the middle-aged and elderly groups.

Conclusions

Sonography has the capacity to quantitatively assess muscular morphologic changes due to aging and could be a valuable tool for early detection of musculoskeletal disorders.

---

### Glofitamab (Columvi) [^b4199bb8]. FDA (2025). Medium credibility.

COLUMVI Step-up Dose Schedule

COLUMVI dosing begins with a step-up dose schedule. Following completion of pretreatment with obinutuzumab on Cycle 1 Day 1, administer COLUMVI as an intravenous infusion according to the step-up dose schedule in Table 1 . Administer premedications for each dose of COLUMVI as described in Table 3 [see Dosage and Administration (2.3)].

Continue COLUMVI for a maximum of 12 cycles (inclusive of Cycle 1 step-up dosing) or until disease progression or unacceptable toxicity, whichever occurs first.

Monitoring for Cytokine Release Syndrome [see Warnings and Precautions (5.1)]

Administer the COLUMVI infusions intravenously in a healthcare setting with immediate access to medical support to manage CRS, including severe CRS.
For the first COLUMVI step-up dose (2.5 mg on Cycle 1 Day 8), patients should be hospitalized during and for 24 hours after completion of the COLUMVI infusion.
Patients who experienced any grade CRS during step-up dose 1 should be hospitalized during and for 24 hours after completion of step-up dose 2 (10 mg on Cycle 1 Day 15). CRS with step-up dose 2 can occur in patients who did not experience CRS with step-up dose 1.
For subsequent infusions (30 mg on Day 1 of Cycle 2 or subsequent cycles), patients who experienced Grade ≥ 2 CRS with their previous infusion should be hospitalized during and for 24 hours after completion of the next COLUMVI infusion.
For monitoring after delayed or missed doses of COLUMVI, follow the recommendations in Table 2 .

Delayed or Missed Doses

If a dose of COLUMVI is delayed, restart therapy based on the recommendations made in Table 2, then resume the treatment schedule accordingly.

For repeat of the 2.5 mg dose patients should be hospitalized during and for 24 hours after completion of the COLUMVI infusion. For the repeat of the 10 mg dose, patients should be hospitalized during and for 24 hours after completion of the COLUMVI infusion if any grade CRS occurred during the most recent 2.5 mg dose.

---

### Bigger versus smaller: children's understanding of size comparison words becomes more precise with age [^cdd372c6]. Child Development (2024). Medium credibility.

Comparison— the process of assessing the similarities and differences among objects, events, or concepts—plays a key role in how humans reason and learn (Gentner,; Gentner et al.). It affects how children learn language, identify categories, and reason analogically. While many studies have shown how children benefit from the process of comparing and how this changes as children develop, less work has investigated how children talk about comparisons and how the language used to describe comparisons develops. Here, we investigate how children learn the meaning of a specific subset of comparative words, size comparison words (e.g. bigger, smaller), and how their interpretation of these words changes across development.

The ability to make comparisons is a cornerstone of higher reasoning abilities and a powerful method for acquiring and reasoning about information (Gentner et al.). Comparison facilitates the learning and retention of new information (Gentner et al.; Kurtz & Loewenstein,; Loewenstein & Gentner,; Oakes et al.; Richland et al.), creativity in problem‐solving (e.g. Gentner et al.; Gentner & Markman,; Gick & Holyoak,), and the acquisition of abstract rules and categories (Doumas & Hummel,; Gentner & Medina,; Gick & Holyoak,; Kurtz et al.). Learning outcomes are facilitated by comparison in academic settings such as science (Gentner et al.; Jee et al.) and mathematics (Rittle‐Johnson & Star,,). Comparison also facilitates the acquisition of various skills across development. Comparing multiple exemplars of objects or events improves children's ability to learn and remember labels paired with those exemplars (Childers,; Childers et al.; Gentner & Namy,; Twomey et al.), facilitates the acquisition of abstract concepts and categories (Anderson et al.; Christie & Gentner,; Ferry et al.; Namy & Clepper,; Namy & Gentner,; Vukatana et al.), and improves children's ability to reason about the social world (Christie,; Hoyos et al.). Thus, the ability to make comparisons is foundational to higher‐order reasoning and plays a key role in how humans think and learn, across a large number of domains.

---

### Reputations for treatment of outgroup members can prevent the emergence of political segregation in cooperative networks [^de653b8e]. Nature Communications (2023). High credibility.

To be clear, political identities also affect decision-making when the stakes are monetary. For example, empirical evidence shows that partisanship affects the wages demanded by workers, as well as consumers’ willingness to purchase items. Our findings complement this prior work on how partisanship infiltrates cold economic calculations by showing how cooperation patterns can lead to the emergence of political segregation in networks, and how the extent of that segregation depends on the types of reputations that can be formed.

It remains to be seen whether an alternate version of our experiment where rewards are more symbolic, as is more typical of social media, or where cooperation is beset by zero-sum thinking, would generate different results. It may be that we would observe an overall increase in political segregation across all political identity conditions, but the differences between reputation conditions would remain. It is also possible that the differences we observe between conditions would not withstand the more acrimonious partisanship and zero-sum thinking common among partisans on social media. Indeed, a recent reviewof interventions to reduce partisan animosity concludes that any single intervention is unlikely to be effective by itself, given that partisan animosity arises from, and is reinforced by, processes at three different levels—thoughts (e.g. misperceptions of the other side), relationships (relative absence of ties across party lines) and institutions (norms and political structures that promote partisanship). Thus, beyond the question of whether our findings would apply in more acrimonious, zero-sum, contexts, our work only addresses how different types of reputation systems impact relationships across party lines. It does not address thoughts or institutions. And while a central tenet of intergroup contact theory is that ties to outgroups can reduce outgroup prejudice and misperceptions (i.e. change thoughts), the arguably more difficult problem of changing institutions would remain.

---

### Genomic landscape associated with potential response to anti-CTLA-4 treatment in cancers [^af1ab5ac]. Nature Communications (2017). Medium credibility.

Significance of IS score according to genomic alterations

The significance of global correlation between IS scores and number of mutations or CIN scores was estimated by linear regression analysis or generalized additive models (GAM) using R-Project statistical package. The significance of IS score difference according to clinicopathologic features such as the presence of virus, and mutation was estimated by Wilcox rank-sum test or analysis of variance (if more than three groups were compared). For each cancer type, we performed logistic analysis with IS score as the independent variable, and dichotomized status in genomic data such as higher or lower than median mutation number or CIN scores as the dependent variables. P < 0.05 was considered a significant difference.

To find specific mutations significantly associated with IS scores, Wilcoxon rank-sum tests were applied to the mean difference of IS score according to each mutation status (mutated versus wild-type). Likewise, significant difference of IS score by amplified or deleted genes were also identified by Wilcoxon rank-sum tests. To facilitate analysis, we limited analysis with previously recognized 373 driver genesfor mutation analysis and 87 amplified and 123 deleted genesfor CIN analysis. To estimate the significance of correlation in each cancer type, subgroup analysis of logistic regression was carried out to compute odds ratio (OR) of mutation rate or CIN score. False discovery rates were applied to control type I errors.

Data availability

The genomic data that support findings of this study are available from the NCBI Gene Expression Omnibus (GEO,) under accession number GSE35640, GSE63557, and GSE78220. Genomic data from TCGA project are available from the National Cancer Institute’s Genomic Data Commons. All other data supporting the findings of this study are available within the article and its supplementary information files or from the corresponding author upon reasonable request.

---

### Limits on fundamental limits to computation [^98c96d2d]. Nature (2014). Excellent credibility.

An indispensable part of our personal and working lives, computing has also become essential to industries and governments. Steady improvements in computer hardware have been supported by periodic doubling of transistor densities in integrated circuits over the past fifty years. Such Moore scaling now requires ever-increasing efforts, stimulating research in alternative hardware and stirring controversy. To help evaluate emerging technologies and increase our understanding of integrated-circuit scaling, here I review fundamental limits to computation in the areas of manufacturing, energy, physical space, design and verification effort, and algorithms. To outline what is achievable in principle and in practice, I recapitulate how some limits were circumvented, and compare loose and tight limits. Engineering difficulties encountered by emerging technologies may indicate yet unknown limits.

---

### Elranatamab-bcmm (Elrexfio) [^ad17527e]. FDA (2025). Medium credibility.

2.1 Important Dosing Information

Administer ELREXFIO subcutaneously according to the step-up dosing schedule to reduce the incidence and severity of cytokine release syndrome (CRS).

Administer pre-treatment medications prior to each dose in the ELREXFIO step-up dosing schedule, which includes step-up dose 1, step-up dose 2, and the first treatment dose as recommended [see Dosage and Administration (2.2, 2.3)] .

ELREXFIO should only be administered by a qualified healthcare professional with appropriate medical support to manage severe reactions such as CRS and neurologic toxicity, including ICANS [see Warnings and Precautions (5.1, 5.2)] .

Due to the risk of CRS, patients should be hospitalized for 48 hours after administration of the first step-up dose, and for 24 hours after administration of the second step-up dose.

2.2 Recommended Dosage

For subcutaneous injection only.

The recommended dosing schedule for ELREXFIO is provided in Table 1. The recommended dosages of ELREXFIO subcutaneous injection are: step-up dose 1 of 12 mg on Day 1, step-up dose 2 of 32 mg on Day 4, followed by the first treatment dose of 76 mg on Day 8, and then 76 mg weekly thereafter through week 24.

For patients who have received at least 24 weeks of treatment with ELREXFIO and have achieved a response [partial response (PR) or better] and maintained this response for at least 2 months, the dose interval should transition to an every two-week schedule. For patients who have received at least 24 weeks of treatment with ELREXFIO at the every two-week dosing schedule and have maintained the response, the dose interval should transition to an every four-week schedule.

Continue treatment with ELREXFIO until disease progression or unacceptable toxicity.

Administer pre-treatment medications prior to each dose in the ELREXFIO step-up dosing schedule, which includes step-up dose 1, step-up dose 2, and the first treatment dose as recommended [see Dosage and Administration (2.3)] .

---

### 2022 AHA / ACC key data elements and definitions for cardiovascular and noncardiovascular complications of COVID-19: a report of the American college of cardiology / American Heart Association task force on clinical data standards [^9816a89d]. Journal of the American College of Cardiology (2022). High credibility.

COVID-19 data standards—physical examination vital signs define heart rate as the number of heartbeats per unit of time (typically 1 min) recorded closest to presentation to the health care facility or on discharge (for inpatient), with permissible values of numeric bpm or unknown; systolic and diastolic blood pressure values are recorded closest to the time of presentation to the health care facility and permit numeric mm Hg or unknown; pulse pressure is the force of a heart contraction measured by the difference between the diastolic and systolic blood pressure measurements, with numeric mm Hg or unknown allowed.

---

### Ticagrelor [^bd8f6a37]. FDA (2025). Medium credibility.

A wide range of demographic, concurrent baseline medications, and other treatment differences were examined for their influence on outcome. Some of these are shown in Figure 11. Such analyses must be interpreted cautiously, as differences can reflect the play of chance among a large number of analyses. Most of the analyses show effects consistent with the overall results, but there are two exceptions: a finding of heterogeneity by region and a strong influence of the maintenance dose of aspirin. These are considered further below.

Most of the characteristics shown are baseline characteristics, but some reflect post-randomization determinations (e.g., aspirin maintenance dose, use of PCI).

Figure 11 – Subgroup analyses of (PLATO)

Note: The figure above presents effects in various subgroups most of which are baseline characteristics and most of which were pre-specified. The 95% confidence limits that are shown do not take into account how many comparisons were made, nor do they reflect the effect of a particular factor after adjustment for all other factors. Apparent homogeneity or heterogeneity among groups should not be over-interpreted.

Regional Differences

Results in the rest of the world compared to effects in North America (US and Canada) show a smaller effect in North America, numerically inferior to the control and driven by the US subset. The statistical test for the US/non-US comparison is statistically significant (p=0.009), and the same trend is present for both CV death and non-fatal MI. The individual results and nominal p-values, like all subset analyses, need cautious interpretation, and they could represent chance findings. The consistency of the differences in both the CV mortality and non-fatal MI components, however, supports the possibility that the finding is reliable.

---

### Bigger versus smaller: children's understanding of size comparison words becomes more precise with age [^5be2a8a3]. Child Development (2024). Medium credibility.

In sum, the previous work on comparative words has offered mixed results for how representations of these words develop in children. These mixed results may be due to differences in the tasks used, differences in age groups tested (including some studies with wide age ranges collapsed), differences in the words used (and collapsing analyses across different words), and unrelated task demands (e.g. complex syntax, memory demands). Our goal in the present study, then, was to determine how precisely children interpret the meaning of size comparison words and how that changes as they develop. To do this, we designed a block‐building task that worked equally well across a wide age range and allowed us to compare different words in the same participants. An experimenter built a baseline structure that was either four blocks long or four blocks tall. Four blocks were selected to allow structures to be easily built with more or fewer blocks. Long and tall baseline structures were used to capture any specifics related to dimensionality. Children were asked to build their own structure that was either bigger, smaller, taller, shorter, or longer than the baseline. This allowed us to see how children interpreted the meaning of each word. This design allowed more flexibility to demonstrate the interpretation than the forced‐choice tasks used previously (e.g. Bishop & Bourne,; Layton & Stick,), by allowing us to see how the child freely interpreted the word, both with the number of blocks used, and the dimensions that were changed from the baseline. The design also controls for key age‐related changes such as differences in syntactic processing (by using a simple question with the target word at the end) and memory demands (by keeping the baseline structure in view of the participants as they build). This allowed us to examine differences between the words, without interference from other changes in cognitive development. We selected these words because they are relatively common in children's input and include positive and negative polarity words and words with and without dimensional attributes. We coded trials for both overall accuracy and the type of structures built. To capture developmental changes in the perceived meanings, we tested children from 3‐ through 8‐years of age.

---

### ASNC imaging guidelines for nuclear cardiology procedures: standardized reporting of nuclear cardiology procedures [^bf86ea4e]. Journal of Nuclear Cardiology (2017). Medium credibility.

Pharmacologic Stress Myocardial Perfusion Imaging with LV function analysis—sections include Indication selections, Clinical history, and Technique covering pharmacologic stress agent options “adenosine/dipyridamole/dobutamine/regadenoson” and ECG-gated acquisition to assess left ventricular systolic function. Findings capture overall study quality, motion during acquisition, and attenuation artifacts, plus perfusion interpretation with quantitative “summed stress score,” “summed rest score,” “summed difference score,” and “myocardial ischemic fraction.” Gated SPECT fields document left ventricular size, systolic performance, LVEF at rest and on post-stress images, and regional wall motion. Transient ischemic dilation is marked as a high-risk marker, and the Impression section classifies perfusion as normal or abnormal with extent and arterial distribution, reports left ventricular systolic function with regional wall motion and ventricular hypertrophy/dilation, and notes comparison with a previous study.

---

### Patterns of aortic dilation in tetralogy of Fallot: an analysis of 100 fetal echocardiograms compared with matched controls [^0b9710e2]. Journal of the American Heart Association (2023). Medium credibility.

As we know, TOF‐PA represents the most severe form of TOF. Although the typical incidence of pulmonary atresia in TOF is 10% to 20%, as a large referral center for TOF‐PA, our sample was skewed toward fetuses with pulmonary atresia.Given this atypical distribution, we ultimately opted to analyze TOF in 3 different cohorts. Somewhat surprisingly, when including TOF‐PA patients in our analysis, we found that the sums of great artery dimensions were significantly lower than in TOF‐PS fetuses and matched controls. This was true for all parameters, with the exception of the sum of the cross‐sectional areas (at the ascending aorta and main pulmonary artery level only). Overall, the smaller dimensions seen in TOF‐PA as compared with TOF‐PS and normal controls is a new finding and perhaps represents a different underlying pathology of the TOF‐PA disease. In regard to possible causes of this finding, animal models have shown that neural crest cell ablation and thus interruption of associated signaling during development leads to a broad spectrum of outflow tract abnormalities such as TOF.We did not assay neural crest cell numbers in this study and thus cannot comment directly on their potential role in TOF‐PA development. More targeted investigations, such as the gathering and comparison of direct tissue samples from the 2 TOF subpathologies, are certainly needed. However, our findings do prompt the question of whether TOF‐PA may be a unique entity with a different developmental pattern from TOF with antegrade flow. Given the well‐described differences in postnatal interventions and outcomes between the various TOF subtypes, this distinction is of particular clinical interest.A more comprehensive understanding of the molecular genetics of the TOF‐PA entity is the first crucial step to developing focused and novel therapies for intervention. When a reproducible animal model is developed for TOF, both the paradigms for aortic dilation and the differences between TOF‐PS and TOF‐PA can be tested more directly.

---

### Hydrocodone bitartrate (hysingla ER) [^0c03a0bc]. FDA (2023). Medium credibility.

Warnings and precautions regarding the use of hydrocodone bitartrate ER PO (also known as Hysingla ER): 
- Adrenal insufficiency: use caution in patients taking the drug for a prolonged period (> 1 month).
- Central sleep apnea: use caution in patients taking higher doses.
- Decreased serum hydrocodone level: use caution in patients taking CYP3A4 inducers (such as rifampin, carbamazepine, or phenytoin) or discontinuing CYP3A4 inhibitors (such as macrolide antibiotics, azole antifungals, or protease inhibitors).
- Erectile dysfunction, infertility: use caution in patients taking the drug for a prolonged period.
- Exacerbation of increased ICP: use caution in patients with increased ICP, brain tumor, or head injury.
- Growth suppression: use caution in patients with chronic corticosteroid therapy. Monitor growth regularly in pediatric patients receiving chronic corticosteroid therapy. Reassess the need for hydrocodone regularly and adjust the corticosteroid therapy as appropriate.
- Hypotension, syncope: use caution in patients with reduced blood volume or taking other CNS depressants. Monitor BP after initiation and dose titration. Avoid use in patients with circulatory shock.
- Mask symptoms of head injury: use caution in patients with head injury. Avoid use in patients with impaired consciousness or coma.
- Opioid overdose: use caution in patients taking CNS depressants or with a history of opioid use disorder or prior opioid overdose. Consider prescribing naloxone based on the patient's risk factors for overdose.
- Opioid withdrawal syndrome: do not discontinue abruptly in patients physically dependent on opioids.
- Opioid withdrawal syndrome: use caution in patients taking CYP3A4 inducers (such as rifampin, carbamazepine, or phenytoin) or discontinuing CYP3A4 inhibitors (such as macrolide antibiotics, azole antifungals, or protease inhibitors).
- Opioid withdrawal syndrome: use extreme caution in patients taking mixed agonist/antagonist analgesics (such as pentazocine, nalbuphine, or butorphanol) or partial agonist analgesics (such as buprenorphine).
- Prolonged QT interval: use caution in patients with congestive HF, bradyarrhythmia, electrolyte abnormalities, or taking drugs prolonging QT interval. Avoid use in patients with congenital long QT syndrome. Do not exceed 90 mg BID in patients developing QT prolongation.
- Seizure: use caution in patients with seizure disorder.
- Serotonin syndrome: use caution in patients taking serotonergic drugs.
- Serotonin syndrome: use extreme caution in patients taking MAOIs or within 14 days of stopping treatment.
- Somnolence: use extreme caution in patients performing activities requiring mental alertness, such as driving or operating machinery.
- Sphincter of Oddi dysfunction: use caution in patients with biliary tract disease and acute pancreatitis.

---

### Benefits and harms associated with analgesic medications used in the management of acute dental pain: an overview of systematic reviews [^80bdde78]. Journal of the American Dental Association (2018). Medium credibility.

Acute dental pain—efficacy of analgesic agents is organized by number needed to treat for benefit (NNTB) with outcomes for at least 50% maximum pain relief over 4-6 hours and mean or median time to remedication. Ibuprofen Plus Acetaminophen, 400 Milligrams/1,000 mg shows NNTB 1.5 (95% confidence interval 1.4 to 1.7), Active 72% versus Placebo 6% achieving at least 50% maximum pain relief over 4-6 hours, and mean or median time to remedication 8.3 versus 1.7 hours. Acetaminophen Plus Oxycodone, 1,000 mg/10 mg shows NNTB 1.8 (1.6 to 2.2), 68% versus 13%, and 9.8 versus 1.5 hours. Diclofenac (Potassium), 100 mg shows NNTB 1.9 (1.7 to 2.3), 65% versus 13%, and 6.3 versus 2.0 hours. Acetaminophen Plus Codeine, 800-1,000 mg/60 mg shows NNTB 2.2 (1.8 to 2.9), 53% versus 7%, and 5.0 versus 2.3 hours. Diclofenac (Fast-Acting), 50 mg shows NNTB 2.4 (2.0 to 3.0), 61% versus 20%, and 7.6 versus 3.8 hours. Naproxen, 500-550 mg shows NNTB 2.7 (2.3 to 3.3), 52% versus 15%, and 8.9 versus 2.0 hours. Acetaminophen, 975-1,000 mg shows NNTB 3.6 (3.2 to 4.1), 46% versus 18%, and 3.9 versus 2.7 hours. Acetaminophen Plus Codeine, 600-650 mg/60 mg shows NNTB 3.9 (3.3 to 4.7), 43% versus 17%, and 4.1 versus 2.4 hours. For some rows, dagger symbols indicate alternative reporting in the time-to-remedication column: “Percentage remediating within 6 hours” (†) or “Percentage remediating within 8 hours” (‡).

---

### The timescale and direction of influence of a third inferior alternative in human value-learning [^eb7260f5]. Communications Psychology (2025). Medium credibility.

Basic performance

During the learning phase (Fig. 2B), participants were sequentially exposed to the value associated with each alternative. The value was shown by a cloud of moving dots, with the number of dots representing the reward magnitude (i.e. number of points) associated with the coin (see “Methods” section). Participants completed 99.91% (95% CI = [99.84%, 99.97%]) of all learning trials with an average reaction time of 623.66 milliseconds (ms) (95% CI = [593.56 ms, 653.76 ms]) in Experiment 1, and 99.3% (95% CI = [98.94%, 99.66%]) of all learning trials with an average reaction time of 411.92 ms (95% CI = [386.66 ms, 437.18 ms]) in Experiment 2, indicating that they properly engaged with the learning phase. We found no statistically significant evidence for differences between the reaction times across learning trials that involved the higher-value (HV), lower-value (LV), and distractor value (DV) alternatives across different contexts in either experiment (2-way ANOVA on log (RT) in Experiment 1: alternatives: F (2, 174) = 0.004, p = 0.99, partial η² < 0.01, 95% CI = [0.00, 0.02], contexts: F (1, 174) = 0.15, p = 0.69, partial η² < 0.01, 95% CI = [0.00, 0.03], interaction: F (2, 174) = 0.02, p = 0.98, partial η² = 0.00, 95% CI = [0.00, 0.02]; and in Experiment 2: alternatives: F (2, 402) = 0.03, p = 0.97, partial η² = 0.00, 95% CI = [0.00, 0.01], contexts: F (1, 402) = 0.06, p = 0.81, partial η² < 0.01, 95% CI = [0.00, 0.01], interaction: F (2, 402) = 0.04, p = 0.97, partial η² < 0.01, 95% CI = [0.00, 0.01]).

---

### Errors in tables 1 and 2 [^b7e829e9]. JAMA Network Open (2021). High credibility.

In the Original Investigation titled “Association of Social and Economic Inequality With Coronavirus Disease 2019 Incidence and Mortality Across US Counties,”published January 20, 2021, there was an inconsistency in the presentation of data between Tables 1 and 2. The data in Table 2 regarding population aged younger than 20 years, population aged 70 years or older, and population density should have been calculated using the same measurement units as in Table 1. Table 1 has also been amended to fix incorrect values that were given for population density. This article has been corrected.

---

### Hourly step recommendations to achieve daily goals for working and older adults [^9509c890]. Communications Medicine (2024). Medium credibility.

Table 3 
Step counts (based on increments of 500 steps) to accumulate in the evenings to achieve 10,000 steps by the end of the day

Details on how these recommendations were derived are provided in the Supplementary Method.

*Same as the “Overall” group.

The step counts required in the evenings to achieve 10,000 steps among participants aged 17–59 were similar but were generally more than those required for participants aged 60 and above (Table 3). There were also differences in the step counts required in the evenings to achieve 10,000 steps among participants with BMI less than 27.5 kg/m 2 on weekdays.

Across different demographics, participants aged between 30 and 39 who had accumulated fewer than 7500 steps between 6 p.m. and 10 p.m. were associated with lower mean step counts for the rest of the day compared to participants aged 60 and above (Supplementary Fig. S6). Males who had accumulated fewer than 5000 steps between 6 p.m. and 10 p.m. were associated with lower mean step counts for the rest of the day compared to females on weekdays, and no sex differences among those who accumulated 5000 steps or more. Participants with normal BMI were associated with lower mean step counts for the rest of the day on weekdays, but they could also have higher mean step counts on weekends compared to participants with obese BMI. The mean step difference between participants with normal BMI and participants with obese BMI decreased with time, with little difference at 10 p.m.

---

### When is equal not equal? [^e623ac00]. Journal of Clinical Lipidology (2010). Low credibility.

The meta-analysis of the Emerging Risk Factor Collaboration demonstrated that the hazard ratios (HR) of the major cholesterol markers and the major apolipoproteins for vascular disease did not differ significantly in the studies they examined. Their conclusion was that they were functionally interchangeable. We believe there are important limitations in the execution of this study. Nevertheless, even if their findings are correct for groups, their conclusions do not follow for individuals. Conventionally, the HR expresses the increase in risk per standard deviation change for that parameter in a group. However, the predicted risk of vascular disease from an atherogenic parameter depends on its concentration within the individual. Depending on the composition of the apoB lipoproteins, individuals may have either concordant or discordant levels of cholesterol and apoB. For those who are concordant, the two markers predict equal risk. For those who are discordant, the predicted risks for the individual are different. We demonstrate that substantial discordance in the individual HR of non-high-density lipoprotein cholesterol and apoB is common. The result is that even with identical overall HR, apoB points to higher risk in a substantial number of individuals whereas the converse is the case for non- high-density lipoprotein cholesterol. Because we are concerned with risks in individuals, not groups, this discordance is important to appreciate and analyze. Our objective should be to learn how to combine the information from parameters rather than eliminate them and we need to focus on evaluation of risk in individuals and not just groups.

---

### Understanding statistical terms: 1 [^50f69b79]. Drug and Therapeutics Bulletin (2009). Low credibility.

An increasing number of statistical terms appear in journal articles and other medical information. A working knowledge of these is essential in assessing clinical evidence. With this in mind, we are producing a series of explanatory articles covering various statistical terms and their uses. This, the first article in the series, will focus on some of the most common terms used in randomised controlled trials.

---

### Semantic maturation during the comprehension-expression gap in late and typical talkers [^e8b9d342]. Child Development (2022). Medium credibility.

In sum, our findings suggest that semantic maturation during the comprehension‐expression gap is partly driven by contextual diversity, and differences in the threshold for semantic maturation help to explain the differences between TTs and LTs as well as the differences between nouns and verbs.

---

### Understanding statistical terms: 2 [^351bd399]. Drug and Therapeutics Bulletin (2009). Low credibility.

An increasing number of statistical terms appear in journal articles and other medical information. A working knowledge of these is essential in assessing clinical evidence. With this in mind, we are producing a series of explanatory articles covering various statistical terms and their uses. This, the second article in the series, will focus on some of the most common terms used in reporting the results of randomised controlled trials.1.

---

### Meta-analysis of molecular response of kidney to ischemia reperfusion injury for the identification of new candidate genes [^9a3d012e]. BMC Nephrology (2013). Low credibility.

The scores from different species were converted into the common weighted scores (W -score) using our heuristic scoring algorithm. The calculation was based on the score of individual expression signal (m) and the number of tested species (i) where this signal was detected. The W -score (W) of a gene was then defined as a sum of m reduced (penalized) by the unidirectional coefficient (bracketed expression of the formula). The unidirectional coefficient was computed as a total number of tested species reduced by the number of species, in which a given gene was not changed (i ns) and by the double number of species, in which a given gene was oppositely expressed; then divided by the number of tested species. Thus, if all species demonstrate unidirectional expression for a given gene, the W of the gene is simply the sum of individual scores for each tested species.

To eliminate the species bias all arrays from the same species were combined, scored using the described algorithm and converted back to the representative FC using the resulting score divided by the number of biological replicates. As an example we offer the description of scoring for the CCL2 gene at time point 24 h - 36 h: FC rat1 = 2.0, FC rat2 = 2.1 gave (2 + 2)*1 → score = 4 = > 4/2 = 2 or FC = 3.0] [FC mouse1 = 1.3, FC mouse2 = 7.8 gave (1 + 3)*1 → score = 4 = > 4/2 = 2 or FC = 3.0. The scores of all four species were summed up and multiplied by the number of species: FC human = 2.8, FC pig = 21.4, FC rat = 3.0, FC mouse = 3.0 [score = (2 + 5 + 2 + 2)*4] =44.

---

### On the utility of diagnostic instruments for pediatric delirium in critical illness: an evaluation of the pediatric anesthesia emergence delirium scale, the delirium rating scale 88, and the delirium rating scale-revised R-98 [^511d03ac]. Intensive Care Medicine (2011). Low credibility.

Sum score analysis

Of 154 patients, the PAED could be rated, applying the a priori criteria for rateability specified above, in 144 (93.5%), the DRS-88 in 103 (66.9%), and the DRS-R-98 in 73 (46.8%). For the DRS-88, the mean age of rateable (8.0 years) and non-rateable patients (4.3 years) differed significantly from each other (F (1,152) = 20.39; SD = 5.05; p < 0.001). This also held for the DRS-R-98 (rateable patients 9.6 years, non-rateable patients 4.3 years, F (1,152) = 57.68; SD = 5.05; p < 0.001). For the PAED, the difference between rateable and non-rateable groups was in the same direction albeit smaller and not significant (6.9 and 4.9 years respectively; F (1,152) = 1.45; SD = 5.05; p > 0.05). Owing to non-rateability, the PAED missed 3, the DRS-88 12, and the DRS-R-98 22 of the 26 diagnoses of delirium made by the gold standard.

Of the 144 cases in which the PAED could be assessed, 23 were diagnosed with delirium by the gold standard, and 21 of these were correctly identified by the PAED (Table 2). The PPV and NPV were 91.3 and 98.3%, respectively. The LR for a positive diagnosis was 55.2 and the AUC was 0.99 (Fig. 1). The optimum cutoff score was 8 (sensitivity = 100%; specificity = 92.6%). Secondly, out of 103 cases in which the DRS-88 could be assessed, 12 were diagnosed with delirium by the gold standard. Eleven of these patients were correctly identified by the DRS-88. The PPV and NPV were 98.9 and 100%, respectively (Table 2). Finally, out of 73 cases in which the DRS-R-98 could be assessed, 4 were diagnosed with delirium by the gold standard. The DRS-R-98 identified 3. The PPV and NPV were 100 and 98.6%, respectively (Table 2).

---

### 2022 AHA / ACC key data elements and definitions for cardiovascular and noncardiovascular complications of COVID-19: a report of the American college of cardiology / American Heart Association task force on clinical data standards [^eee38472]. Journal of the American College of Cardiology (2022). High credibility.

COVID-19 Data Standards hemodynamic measures define mean pulmonary capillary wedge pressure as “The pressure measured by wedging a pulmonary catheter with an inflated balloon into a small pulmonary arterial branch” and note it “May be recorded with or without V-wave.” Cardiac output is defined as “The total volume of blood pumped by the heart over a set period of time, conventionally 1 min; it is calculated as heart rate times stroke volume and is additionally dependent on preload and afterload for functional output.” Cardiac index is described as “The measure of an individual’s cardiac output as divided by their body surface area). This calculation is a useful function to determine an individual’s cardiac performance in relation to their body size, providing an overview of global cardiovascular function.” Transpulmonary gradient is the “Difference between mean pulmonary artery pressure and mean pulmonary capillary wedge pressure.” Pulmonary vascular resistance is calculated as “Pulmonary vascular resistance is calculated as (mean PA pressure minus mean pulmonary capillary wedge pressure) divided by cardiac output” with permissible values “Numeric, Wood units or dynes/s/cm^5,” and is described as “The resistance to blood flow generated by the pulmonary vasculature, which is normally one-sixth of systemic vascular resistance” with the caution that “Prolonged elevated pulmonary vascular resistance can cause right HF.” Systemic vascular resistance is calculated as “Systemic vascular resistance is calculated as the systemic mean arterial blood pressure minus right arterial pressure divided by cardiac output” with permissible values “Numeric, dynes/s/cm^5,” and reflects “The resistance to blood flow generated by all systemic vasculature, excluding pulmonary vasculature” where “The major determinant of systemic vascular resistance is arteriolar tone, but blood viscosity and vascular capacitance are also contributing factors.” Mixed venous O2 saturation is “Saturation measured via a sample of blood from a pulmonary artery catheter measures the end result of O2 consumption and delivery, used in the ICU as a measure of O2 extraction by the body.”

---

### An official American Thoracic Society workshop report: developing performance measures from clinical practice guidelines [^369e6d46]. Annals of the American Thoracic Society (2014). Medium credibility.

Agency for Healthcare Research and Quality performance measure attributes—Desirable features of performance measures include relevance to stakeholders and addressing important aspects of health, with evidence of a need for the measure; evidence should be explicitly stated, results should be reproducible and truly measure what they purport to measure, and specifications should explicitly define the numerator and denominator with understandable data collection requirements; necessary data sources should be available within the measurement timeframe and data collection costs justified by potential improvement in care or health.

---

### Local dimensionality determines imaging speed in localization microscopy [^4b790224]. Nature Communications (2017). Medium credibility.

Similarly, when the FRC measure is calculated for only those localizations classified as good, we no longer see a continuous improvement (see Fig. 1g). Although noisy (due to the stochastic nature of FRC calculations and the comparatively small number of good matches at high activation densities), each structure has a clear optimum. This optimum, for which both the values and variance of the FRC is minimized, falls at a slightly higher activation density than that estimated by considering the minimum acquisition time. The optimal density and corresponding best FRC values differ for the 1D and 2D cases, with the optimum FRC of the 1D structure lower than that of the 2D structure. This indicates a better resolution reconstruction for the 1D structure, as expected from the theory.

It is worth noting that we only show classification results for the 1D and 2D case. For our 0D sample, as the simulated structure only consisted of a single 8 × 8 nm region, the localizations were so concentrated that distortions due to multiple fluorophores being mistaken for a single activation were not discernible by the eye. This will not be the case for all 0D structures one encounters in practice—a sample consisting of many point-like structures randomly scattered across the field of view, for example, may feature groupings of points that are sufficiently dense to cause errors in the localization algorithm, whereas still changing the apparent PSF enough that an experienced user can clearly see the difference. In addition, for many applications, errors localizing fluorescent molecules within a 0D structure may be unimportant due to the small absolute size of the actual position error. However, this case does illustrate an important limitation of this method (namely that it can only learn to correct errors that the user can first identify) and to correct for it would require using a different measure of error to that applied to the 2D and 1D cases; hence, we have let the results stand as they are.

---

### Excess deaths in the United States during the first year of COVID-19 [^b9a073b5]. Preventive Medicine (2022). Medium credibility.

Accurately determining the number of excess deaths caused by the COVID-19 pandemic is hard. The most important challenge is determining the counterfactual count of baseline deaths that would have occurred in its absence. Flexible estimation methods were used here to provide this baseline number and plausibility of the resulting estimates was evaluated by examining how changes between baseline and actual prior year deaths compared to historical year-over-year changes during the previous decade. Similar comparisons were used to examine the reasonableness of excess death estimates obtained in prior research. Total, group-specific and cause-specific excess deaths in the U.S. from March 2020 through February 2021 were calculated using publicly available data covering all deaths from March 2009 through December 2020 and provisional data for January 2021 and February 2021. The estimates indicate that there were 649,411 (95% CI: 600,133 to 698,689) excess deaths in the U.S. from 3/20-2/21, a 23% (95% CI: 21%-25%) increase over baseline, with 82.9% (95% CI: 77.0% - 89.7%) of these attributed directly to COVID-19. There were substantial differences across population groups and causes in the ratio of actual-to-baseline deaths, and in the contribution of COVID-19 to excess mortality. Prior research has probably often underestimated baseline mortality and so overstated both excess deaths and the percentage of them attributed to non-COVID-19 causes.

---

### Clinical consensus methodology [^4a5dcf27]. ACOG (2021). High credibility.

ACOG clinical consensus methodology—development of the recommendations and manuscript explains how recommendations are crafted from the mapped evidence. Authoring team members review the evidence included in the evidence maps and propose key recommendations, and Clinical Consensus recommendations include a description of the relevant population, intervention, comparator, outcome, timing, setting, and dosing regimens as appropriate. When evaluating evidence, authors consider benefits and harms, patients’ values and preferences, resource use, cost, effect on equity, and generalizability, and they identify evidence related to specific segments of the U.S. population that may be disproportionately or differentially affected and propose specific recommendations based on the evidence review when possible. Articles in the evidence map not cited in the draft manuscript undergo additional review, and if after additional review it is determined that an article should not be included, the article is then removed from the evidence summary.

---

### Summary benchmarks-full set – 2024 [^e2c40ddc]. AAO (2024). High credibility.

Preferred Practice Pattern (PPP) guidelines—GRADE recommendation categories are specified as: “Strong recommendation (SR): Used when the desirable effects of an intervention clearly outweigh the undesirable effects or clearly do not” and “Discretionary recommendation (DR): Used when the trade-offs are less certain—either because of low-quality evidence or because evidence suggests that desirable and undesirable effects are closely balanced.”

---

### Estimating the impact of COVID-19 vaccine inequities: a modeling study [^ed35a91d]. Nature Communications (2023). High credibility.

The model accounts for vaccinations. We assume that all individuals except the infectious can receive the vaccine. The per-capita rate at which susceptible individuals, that received a dose of vaccine, get infected (i.e. force of infection) is reduced by a factor (1 − V E S 1). If these individuals get infected, their IFR is also reduced by a factor 1 − V E M 1. Hence, the overall efficacy of a single dose of vaccine against death is V E 1 = 1 − (1 − V E S 1)(1 − V E M 1). The force of infection for susceptible individuals that received two doses, and the IFR are reduced, respectively, by (1 − V E S 2) and (1 − V E M 2), implying an overall efficacy of V E 2 = 1 − (1 − V E S 2)(1 − V E M 2). We also assume that vaccinated individuals that get infected are less infectious by a factor (1 − V E I). Since vaccine protection is not immediate, we introduce a delay of Δ V days between administration (of both 1st and 2nd dose) and the actual effect of the vaccine. For example, an individual who received the 1st dose on day t, will be protected with efficacy V E 1 only, on average, after Δ V days. We set Δ V = 14 days. As we do not have detailed information about the age of individuals receiving vaccines in all the countries considered, we assume that the rollout proceeds prioritizing the elderly. This is the strategy followed by the vast majority of governments worldwide,,. Vaccines are distributed in decreasing age order until all 50+ individuals are vaccinated, after vaccines are distributed homogeneously to the age groups 10−50. We inform the model with the number of daily 1st and 2nd doses in different countries from Ref. We set V E 1 = 80% (V E S 1 = 70%), V E 2 = 90% (V E S 2 = 80%), and V E I = 40%.

---

### Clinical policy: critical issues in the evaluation and management of adult patients presenting to the emergency department with acute headache [^582f1755]. Annals of Emergency Medicine (2019). High credibility.

Emergency department acute headache discharge therapy—randomized naproxen versus sumatriptan trial results are as follows: Adults aged 18 to 64 y with primary headache who had received parenteral medication and were being discharged home were randomized in a double-blind, comparative efficacy trial to naproxen 500 mg or sumatriptan 100 mg orally; the primary outcome was an 11-point verbal numeric rating scale (NRS) recorded before taking the pain medication and 2 h later. N=196 were enrolled with 98 in each arm; among migraine without aura, mean pain improvement during 2 h was 4.3 NRS points with naproxen versus 4.2 points with sumatriptan (95% CI for a difference of 0.1 points: −1.3 to 1.5 points); among all primary headache patients, mean improvement was 4.3 points for naproxen versus 4.1 points for sumatriptan (95% CI for difference of 0.2 points: −0.7 to 1.1 points).

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^68907dd4]. Journal of the American College of Cardiology (2025). High credibility.

Table 2. Reference case for high-quality CEAs—design and scope—states that both trial-based economic evaluations or population-based economic evaluations can be used to inform economic value statements. The reference case should adopt a health care sector perspective, with results from the societal perspective or a modified societal perspective reported if relevant data are available. The analytic horizon should be long enough to fully capture meaningful differences in health outcomes and costs, and the reference case should consider adopting a lifetime analytic horizon with sensitivity analyses that examine the effect of varying the time horizon and key assumptions. The reference case study population should be as similar as possible to the target population, with subgroup analyses that explore variation in cost effectiveness in key subpopulations reported when findings are meaningfully different. The intervention should be clearly defined, including mode of implementation, any essential concurrent diagnostics or therapies, and a follow-up protocol if relevant. The reference case should consider all appropriate comparator(s) that are indicated and accessible, and it is not appropriate to exclusively compare with a comparator known to have high costs or low effectiveness (“comparator gaming”).

---

### Immune response to SARS-CoV-2 after a booster of mRNA-1273: an open-label phase 2 trial [^563a07f1]. Nature Medicine (2022). Excellent credibility.

Table 2 
Pseudovirus nAb titers (ID 50 ; against D614G or Delta) of mRNA-1273 after the booster compared to the phase 3 COVE primary series titers (per-protocol immunogenicity set)

n indicates the number of individuals with no missing data at the corresponding time point. Antibody values reported as below the LLOQ were replaced by 0.5× LLOQ. Values greater than the ULOQ were replaced by the ULOQ if actual values are not available.

The log-transformed antibody titers were analyzed using an ANCOVA model with the group variable (phase 2 part B and phase 3 COVE) as fixed effect. The resulted least squares means, difference of least squares means and 95% CIs were back-transformed to the original scale for presentation.

Seroresponse rates (assay-specific definition) (95% CI) were 93.5% (90.1, 96.1) and 98.9% (98.0, 99.4) in the pooled phase 2 part B booster group (compared to pre-boost) and after the primary series in the phase 3 COVE trial, respectively (Table 3). The seroresponse rates (four-fold rise from baseline) (95% CI) were 90.1% (86.1, 93.3) and 98.4% (97.4, 99.1) in the booster group and after the primary series in the phase 3 COVE trial, respectively (Table 3). The seroresponse rates (four-fold rise from baseline) (95% CI) were 100% (98.7, 100.0) and 98.3% (96.0, 99.4) in the pooled phase 2 part B booster group and in the pooled phase 2 part A priming group (50 µg or 100 µg), respectively (Table 3). The seroresponse rates in the pseudovirus nAb assay were non-inferior for the phase 2 part B group after the booster injection compared to the phase 3 COVE trial after the primary series (Table 3), based on the assay-specific seroresponse definition. Given that the lower limit of the 95% CI for the group difference in seroresponse rates (four-fold rise from baseline) was greater than 0, the observed seroresponse rates were statistically significantly higher after the booster dose than after the second dose in part A of the phase 2 study, and the seroresponse rate difference met the pre-specified criterion for non-inferiority.

---

### 2025 AHA / ACC statement on cost / value methodology in clinical practice guidelines (update from 2014 statement): a report of the American college of cardiology / American Heart Association joint committee on clinical practice guidelines [^9d0e2219]. Journal of the American College of Cardiology (2025). High credibility.

Supporting text requirements for economic value statements specify that supporting text should include key elements: a summary of the high-quality CEAs used to generate the statement with rationale for which studies were included and details such as study population, intervention, comparator, clinical outcomes, sources of key effectiveness and safety parameters, perspective, analytic horizon, base-case treatment cost, and source of funding; point estimates and the proportion of simulations that were cost-effective at a specified threshold; and results of key sensitivity analyses, noting that a 1-way sensitivity analysis of intervention cost variation can be helpful, that additional information about sensitivity to intervention cost should be provided, and that inclusion of a figure similar to Figure 4 is encouraged if available.

---

### Pain management for tubal sterilization by hysteroscopy [^0e6dab17]. The Cochrane Database of Systematic Reviews (2012). Low credibility.

Background

Tubal sterilization by hysteroscopy involves inserting a foreign body in both fallopian tubes. Over a three-month period, the tubal lumen is occluded by tissue growth stimulated by the insert. Tubal sterilization by hysteroscopy has advantages over laparoscopy or mini-laparotomy, including the avoidance of abdominal incisions and the convenience of performing the procedure in an office-based setting. Pain, an important determinant of procedure acceptability, can be a concern when tubal sterilization is performed in the office.

Objectives

To review all randomized controlled trials that evaluated interventions to decrease pain during tubal sterilization by hysteroscopy.

Search Methods

From January to March 2011, we searched the computerized databases of MEDLINE, POPLINE, CENTRAL, EMBASE, LILACS, and CINAHL for relevant trials. We searched for current trials via Clinicaltrials.gov. We also examined the reference lists of pertinent articles and wrote to known investigators for information about other published or unpublished trials.

Selection Criteria

We included all randomized controlled trials that evaluated pain management at the time of sterilization by hysteroscopy. The intervention could be compared to another intervention or placebo.

Data Collection and Analysis

Initial data were extracted by one review author. A second review author verified all extracted data. Whenever possible, the analysis was conducted with all women randomized and in the original assigned groups. Data were analyzed using RevMan software. Pain was measured using either a 10-cm or 100-point visual analog scale (VAS). When pain was measured at multiple points during the procedure, the overall pain score was considered the primary treatment effect. If this was not measured, a summation of all pain scores for the procedure was considered to be the primary treatment effect. For continuous variables, the mean difference with 95% confidence interval was computed.

Main Results

Two trials met the inclusion criteria. The total number of participants was 167. Using a 10-cm VAS to measure pain, no significant difference emerged in overall pain for the entire procedure between women who received a paracervical block with lidocaine versus normal saline (mean difference -0.77; 95% CI -2.67 to 1.13). No significant difference in pain score was noted at the time of injection of study solution to the anterior lip of the cervix (mean difference -0.6; 95% CI -1.3 to 0.1), placement of the device in the tubal ostia (mean difference -0.60; 95% CI -1.8 to 0.7), and postprocedure pain (mean difference 0.2; 95% CI -0.8 to 1.2). Procedure time (mean difference -0.2 minutes; 95% CI -2.2 to 1.8 minutes) and successful bilateral placement (OR 1.0; 95% CI 0.19 to 5.28) was not significantly different between groups. During certain portions of the procedure, such as placement of the tenaculum (mean difference -2.03; 95% CI -2.88 to -1.18), administration of the paracervical block (mean difference -1.92; 95% CI -2.84 to -1.00), and passage of the hysteroscope through the external (mean difference -2.31; 95% CI -3.30 to -1.32) and internal os (mean difference -2.31; 95% CI -3.39 to -1.23), use of paracervical block with lidocaine resulted in lower pain scores.Using a 600-point scale calculated by adding 100-point VAS scores from six different portions of the procedure, no significant difference emerged in overall pain between women who received intravenous conscious sedation versus oral analgesia (mean difference -23.00; CI -62.02 to 16.02). Using a 100-point VAS, no significant difference emerged at the time of speculum insertion (mean difference 4.0; 95% CI -4.0 to 12.0), cervical injection of lidocaine (mean difference -1.8; 95% CI -10.0 to 6.4), insertion of the hysteroscope (mean difference -8.7; 95% CI -19.7 to 2.3), placement of the first device (mean difference -4.4; 95% CI -15.8 to 7.0), and removal of the hysteroscope (mean difference 0.9; 95% CI -3.9 to 5.7). Procedure time (mean difference -0.2 minutes; 95% CI -2.0 to 1.6 minutes) and time in the recovery area (mean difference 3.6 minutes; 95% CI -11.3 to 18.5 minutes) was not different between groups. However, women who received intravenous conscious sedation had lower pain scores at the time of insertion of the second tubal device compared to women who received oral analgesia (mean difference -12.60; CI -23.98 to -1.22).

Authors' Conclusions

The available literature is insufficient to determine the appropriate analgesia or anesthesia for sterilization by hysteroscopy. Compared to paracervical block with normal saline, paracervical block with lidocaine reduced pain during some portions of the procedure. Intravenous sedation resulted in lower pain scores during insertion of the second tubal device. However, neither paracervical block with lidocaine nor conscious sedation significantly reduced overall pain scores for sterilization by hysteroscopy.

---

### Selective effects of serotonin on choices to gather more information [^5659349a]. Journal of Psychopharmacology (2021). Medium credibility.

To test formally that participants were guided by the informational content of samples rather than their quantity, we performed an additional analysis to measure the consistency of behaviour across trials according to the measures. Consistent behaviour on a measure is taken as an indication that participants are more likely to be guided by information represented by that measure (e.g. p(correct) vs. number of samples). We used coefficients of variation (CVs), defined as the measure’s ratio of standard deviation to its mean within each participant’s data. CVs are used to assess the consistency of measure on ratio scales with different mean values (;). A lower CV indicates greater consistency. We computed a CV for each participant on each measure (p(correct), expected utility and sample number), averaging the former measures across the three prior models described in the following paragraph (see). We compared CVs of p(correct) and expected utility to CVs of sample number using paired t -tests. These tests confirmed the appropriate use of p(correct) and expected utility.

We then considered that since there were relatively few trials and the distribution was not specified to subjects in advance, there is little experience to build up an accurate prior, and the discrete structure has few possible outcomes. So, it is feasible for participants to keep approximate track of the outcomes, deliberately or otherwise. We sought a principled approach to accounting for this possibility in our analysis that did not require a complex inference and made minimal assumptions. This was the categorical distribution, where observed frequencies of outcomes added to the probability mass for the prior of the next decision. We refer to this as the learned prior model of choice probability and value. To solve the problem of the unknown personal prior (i.e. the participant’s personal a priori interpretation of the probability structure of the task) for the first trial in which no experience had been gained of the board, data from the first trial were excluded from analysis. So, no information or distributional assumptions beyond the feedback presented and the current trial’s information set was required.

---

### Worldwide divergence of values [^fce106c7]. Nature Communications (2024). High credibility.

Results

Value divergence at the item level

We first examined general trends towards value convergence or divergence using our value variation measure, which allowed us to estimate effects at the item level. Our results strongly supported value divergence. A mixed effects model with value variation nested in the 40 items found that timepoint has been significantly associated with greater value variation, b = 0.004, SE = 0.0007, t (239) = 5.12, p < 0.001,= 0.17, 95% CIs [0.002, 0.005]. We replicated this result using a different approach in which we correlated timepoint with value variation separately for each of the 40 value items. Of the 40 values, we found that 27 have diverged over time, with a positive median correlation of 0.28 between timepoint and value variation, t (39) = 3.30, p = 0.002, M diff = 0.28, 95% CIs [0.11, 0.45]. Coefficients associated with each item are displayed in Fig. 1.

---

### Enhancing the diagnosis of functionally relevant coronary artery disease with machine learning [^ec674e06]. Nature Communications (2024). High credibility.

Adjudication of fCAD

Adjudication of fCAD was based on expert interpretation of MPI-SPECT/CT images combined with information obtained from invasive coronary angiography and fractional flow reserve measurements, whenever available. All patients underwent a routine standard rest/stress dual isotope (201 Tl for rest, 99m Tc sestamibi for stress) or a single isotope (99m Tc sestamibi for stress and rest) MPI-SPECT/CT protocol. MPI-SPECT/CT images were scored semi-quantitatively using a 17-segment model with a 5-point scale (0 = normal, 1 = mildly reduced tracer uptake, 2 = moderately reduced uptake, 3 = severely reduced uptake and 4 = no uptake). Summed stress score and summed rest score were calculated by adding the scores of the 17 segments in the stress and rest images. Summed difference score was the difference between summed stress score and summed rest score. A summed difference score of at least 2 or positive transient ischaemic dilation ratio (≥1.22 for the dual isotope protocol and 1.12 for the single isotope protocol) was considered as fCAD –. Summed stress score and summed rest score were derived by visual assessment of two expert readers and compared with the software result. Differences in the visual assessment were resolved by finding consensus. In case of equivocal findings from MPI-SPECT/CT and coronary angiography, an adjudication committee of two independent cardiologists (one interventional cardiologist, one general cardiologist) that were blinded to study biomarker results reviewed the case using all clinically available data. A positive perfusion scan was overruled when coronary angiography showed normal coronary arteries, while a negative perfusion scan was overruled if coronary angiography (within 3 months) either revealed a high-grade coronary lesion (>75%) or if there was fractional flow reserve below 0.80. In total the adjudication committee reviewed 147 cases or 21% of the 701 patients that underwent coronary angiography within 90 days.

---

### Characterization of dosimetric differences in strut-adjusted volume implant treatment plans calculated with TG-43 formalism and a model-based dose calculation algorithm [^7b8451e5]. International Journal of Radiation Oncology, Biology, Physics (2021). Medium credibility.

Purpose

To comprehensively characterize dosimetric differences between calculations with a commercial model-based dose calculation algorithm (MBDCA) and the TG-43 formalism in application to accelerated partial breast irradiation (APBI) with the strut-adjusted volume implant (SAVI) applicator.

Methods

Dose for 100 patients treated with the SAVI applicator was recalculated with an MBDCA for comparison to dose calculated via TG-43. For every pair of dose calculations, dose-volume histogram (DVH) metrics including V90%, V95%, V100%, V150%, and V200% for the PTV_EVAL were compared. Features were defined for each case including (1) applicator size, (2) ratio between PTV_EVAL contour and 1-cm rind surrounding SAVI applicator, (3) ratio between dwell time in central catheter and total dwell time, and (4) mean computed tomography (CT) number within the lumpectomy cavity. Wilcoxon rank sum tests were performed to test whether treatment plans could be stratified according to feature values into groups with statistically significant dosimetry differences between MBDCA and TG-43.

Results

For all DVH metrics, differences between TG-43 and MBDCA calculations were statistically significant (P < .05). Minimum (maximum) relative percent differences between the MBDCA and TG-43 for V90%, V95%, and V100% were -2.1% (0.1%), -3.1% (-0.1%), and -5.0% (-0.5%), respectively. The median relative percent difference in mean PTV_EVAL dose between the MBDCA and TG-43 was -3.9%, with minimum (maximum) difference of -6.5% (-1.8%). For V90%, V95%, and V100%, plan quality worsened beyond defined thresholds in 26, 23, and 31 cases with no instances of coverage improvement. Features 1, 2, and 4 were shown to be able to stratify treatment plans into groups with statistically significant differences in dosimetry metrics between MBDCA and TG-43.

Conclusions

Investigated dose metrics for SAVI treatments were found to be systematically lower with MBDCA calculation in comparison to TG-43. Plans could be stratified according to several features by the magnitude of dosimetric differences between these calculations.

---