# Medical Question & Answer

**Sample ID**: 8e2ae96b-5648-5db1-5091-12ffb31ef718
**Dataset Index**: 26557

---

## Question

Example. Find the flux of the vector field

a = x i + (y + z) j + (z − y) k

through the part of the surface

x² + y² + z² = 9

cut by the plane z = 0 (z ≥ 0) (the normal is external to the closed surface formed by these surfaces).

---

## Answer

> Let's see… What do we have here? The user is asking to find the flux of the vector field a = x i + (y + z) j + (z − y) k through the upper hemisphere of radius 3 (z ≥ 0), with the normal pointing outward from the closed surface formed by the hemisphere and the disk at z = 0. Let's break this down step-by-step. First, I need to think about the geometry and whether to use the divergence theorem. Then, I should verify the divergence of the vector field. Next, I will compute the flux through the closed surface using the divergence theorem. After that, I need to calculate the flux through the flat disk at z = 0 with the correct normal orientation. Finally, I will subtract the disk flux from the total to get the hemisphere flux and double-check the sign convention and arithmetic.

> Let me first confirm the geometry and strategy. The surface of interest is the upper hemisphere of radius 3, and the problem specifies that the normal is external to the closed surface formed by the hemisphere plus the disk at z = 0. That means I can treat the hemisphere plus the disk as a closed surface and apply the divergence theorem, then subtract the flux through the disk to isolate the hemisphere flux, which is a standard approach for open surfaces like this [^notfound].

> I need to check the divergence of the vector field. The divergence of a = x i + (y + z) j + (z − y) k is ∂x/∂x + ∂(y + z)/∂y + ∂(z − y)/∂z = 1 + 1 + 1 = 3, which is constant everywhere, so the volume integral will be straightforward [^notfound].

> Next, I should review the divergence theorem. The flux through a closed surface equals the integral of the divergence over the enclosed volume, so for the closed hemisphere-plus-disk surface, Φ_total = ∫∫∫ (∇ · a) dV = 3 × Volume of hemisphere = 3 × (2/3 π r³) = 2π r³. With r = 3, that gives Φ_total = 2π (3)³ = 54π, which I should confirm is correct before moving on [^notfound].

> Wait, let me verify the volume calculation. The volume of a full sphere is 4/3 π r³, so the volume of a hemisphere is half of that, which is 2/3 π r³. Multiplying by 3 gives exactly 2π r³, so 54π is correct for the total flux through the closed surface [^notfound].

> Now I will examine the flux through the flat disk at z = 0. On the disk, z = 0, so the vector field becomes a = x i + y j − y k, and the outward normal for the closed surface points downward, i.e., n = −k. Therefore, a · n = (x i + y j − y k) · (−k) = y, and the flux through the disk is ∫∫_disk y dA. By symmetry, the integral of y over a disk centered at the origin is zero, so Φ_disk = 0. Hold on, I should verify that symmetry argument: yes, for every y there is a corresponding −y, so the integral vanishes, which is correct [^notfound].

> I should double-check the orientation. The problem states the normal is external to the closed surface, so for the disk that means pointing downward, which is why n = −k is appropriate here. If I mistakenly used +k, I would get the wrong sign for the disk contribution, but in this case the dot product would flip and the integral would still be zero by symmetry, so the final answer would be unchanged, though the reasoning would be inconsistent with the stated normal direction [^notfound].

> Finally, I will compute the hemisphere flux by subtraction. Since Φ_total = Φ_hemisphere + Φ_disk and Φ_disk = 0, we have Φ_hemisphere = Φ_total = 54π. Let me reconsider whether any steps could have introduced an error: the divergence is correct, the volume is correct, the disk integral is correct by symmetry, and the subtraction is straightforward, so the result should be reliable [^notfound].

---

The flux of the vector field (a = x i + (y + z) j + (z − y) k) through the upper hemisphere (x² + y² + z² = 9) with (z ≥ 0) is **(54π)**. This result is obtained by applying the divergence theorem to the closed surface formed by the hemisphere and the disk (z = 0), then subtracting the flux through the disk. The divergence of (a) is 3, so the total flux through the closed surface is (3 × [2/3]π (3)³ = 54π), and the flux through the disk is zero by symmetry, leaving the hemisphere flux as (54π).

---

## Step 1: Understand the problem and the surface

The surface is the **upper hemisphere** of radius 3 centered at the origin, defined by (x² + y² + z² = 9) with (z ≥ 0). The normal vector is **outward-pointing** relative to the closed surface formed by the hemisphere and the disk (z = 0).

---

## Step 2: Apply the divergence theorem

The divergence theorem states that the flux of a vector field through a closed surface is equal to the triple integral of the divergence of the field over the enclosed volume:

∬_S a · dS = ∭_V (∇ · a) dV

First, compute the **divergence** of (\\vec{a}):

∇ · a = ∂/∂x (x) + ∂/∂y (y + z) + ∂/∂z (z − y) = 1 + 1 + 1 = 3

Next, compute the **volume** of the hemisphere:

V = [1/2] × [4/3]π r³ = [2/3]π (3)³ = 18π

Then, the **total flux** through the closed surface is:

∬ over S_closed a · dS = ∭_V 3 dV = 3 × 18π = 54π

---

## Step 3: Calculate the flux through the disk

The closed surface consists of the hemisphere and the disk (z = 0). The flux through the disk is:

∬ over disk a · dS = ∬ over disk (x i + (y + z) j + (z − y) k) · (−k) dA = ∬ over disk (y − z) dA

On the disk, (z = 0), so the integrand becomes (y). By symmetry, the integral of (y) over the disk is zero:

∬ over disk y dA = 0

---

## Step 4: Determine the flux through the hemisphere

The total flux through the closed surface is the sum of the flux through the hemisphere and the flux through the disk:

54π = ∬ over hemisphere a · dS + ∬ over disk a · dS

Since the disk flux is zero, the **hemisphere flux** is:

∬ over hemisphere a · dS = 54π

---

The flux of the vector field (\\vec{a}) through the upper hemisphere is **(54\\pi)**.

---

## References

### Active carpets drive non-equilibrium diffusion and enhanced molecular fluxes [^0119199e]. Nature Communications (2021). High credibility.

The resulting velocity correlation function (VCF) and mean-squared displacement (MSD) are shown in Fig. 2 b and c, respectively. The tracer dynamics are ballistic at short times, t ≪ τ, called the Holtsmark regime. However, at long times they are diffusive with a linear relation 〈Δ x 2 〉 = 2 D x x t, and similarly in the other directions. Hence, we determine the components of the diffusion tensor as a function of z 0 (Fig. 2 d). Like the flow variances, the vertical component D z z is five times stronger than the horizontal components, leading to anisotropic diffusion, and they all decay asin all three directions.

This system can be solved analytically when considering the limit of small displacements, when the noise amplitude is small. This ensures that we determine the local diffusivity, D i j (z) with small variations in z. Using information from the variance of the active fluctuations and their temporal correlations, the motion can then be integrated (see 'Methods: Derivation of the mean-squared displacement and space-dependent diffusivity'). This gives the MSD, which captures both the short-term ballistic motion and the diffusivity after long times (Fig. 2 c, dashed red lines). Thus, for the vertical Stokeslets for example, we find the space-dependent diffusion, which is compared with the simulations in Fig. 2 d. Because our theoretical approximation is formulated for small amplitudes of active fluctuations, the expression only holds far from the surface, when(Eq. (54)). Beyond this distance we find a good agreement between the simulations and the theory.

Overall, we find that the diffusion driven by an active carpet can be much stronger than Brownian thermal diffusion. Considering a carpet of Vorticella with cell radius a ~25 μm, h ~150 μm, n ~1/(100 μm) 2, τ ~1 s and 8 π μ f ⊥ ~500 pN, the active diffusion can be dominant up to distances ofmm for small nutrient molecules of D th ~ 500 μm 2 /s. That is much larger than the cell size. Moreover, for micron-sized prey of D th ~0.5 μm 2 /s, we find z th ~7 mm, orders of magnitude larger than the organism itself. Hence, we expect these results to be highly relevant across the scales, for non-equilibrium transport from molecular to organismic sizes.

---

### Similarity and economy of scale in urban transportation networks and optimal transport-based infrastructures [^196ef8b8]. Nature Communications (2024). High credibility.

Having introduced the main problem and ideas, we now briefly describe the model. Consider a surface in 2D and a set of points on it. Specifically, we denote a set of origins and destinations as f + and f −, respectively. These contain the reference points where people enter and exit the transportation network. By defining f = f + − f −, mass conservation can be enforced with the constraint ∫ f d x = 0. The two main quantities of interest are denoted with μ (x, t), the transport density (or conductivity), and u (x, t) the transport potential. The former can be seen as a quantity proportional to the size of a network edge, while the latter determines the fluxes traveling along them. The dynamical equations in this continuous setting areEquation (1) determines the spatial balance of the flux, assumed to be governed by the Fick–Poiseuille flux as q = − μ ∇ u; Eq. (2) enforces optimal solutions, and represents the P. polycephalum dynamics in the continuous domain; Eq. (3) is the initial condition. The parameter β captures different optimization mechanisms: β < 1 enforces congested transportation, β = 1 is the shortest path-like and β > 1 is branched transportation. In Fig. 1 f–h we show examples of different optimal configurations, with β = 1, β = 1.5 and β = 2.0. Here, we consider the cases 1 < β ≤ 2, where the approximate support of the conductivity μ displays a network-like structure. Under the lenses of a network, the conductivities can be viewed as the traffic capacities on the edges, hence Eq. (3) defines how the initial traffic capacities are distributed along the network, while Eq. (2) describes how these capacities evolve in response to the fluxes. As time evolves (i.e.), the equilibrium solution pair (μ *, u *) is reached. In refs. the authors show that under certain assumptions, this equilibrium solution is a minimizer of the functionalThis can be interpreted as the network transportation cost, where the first term is a network operating cost (or power dissipation, it is the Dirichlet energy to the solution of the first partial differential equation), while the second is a non-linear cost to build the infrastructure. When β > 1, this second term corresponds to a principle of economy of scale, where it is more convenient to consolidate traffic into fewer (but larger) edges. This is the scenario we consider here. By changing β, one can tune their relative contribution to the total transportation cost, thus tuning the impact of the principle of economy of scale and how much concentrated path trajectories are. Besides being relevant for urban transportation, this strategy seems to be a fundamental mechanism in various natural systems, e.g. tree branches and roots, blood vessels or river networks.

---

### Terahertz rectification in ring-shaped quantum barriers [^92c6ddcf]. Nature Communications (2018). Medium credibility.

Terahertz (THz) tunneling in a ring-shaped barrier

Suppose that an electromagnetic wave impinges on a perfect electric conductor film placed on the x – y plane; the incident magnetic field H inc induces an eddy current per length K PEC = × (2 H inc) on the film, which reflects back the incident light and blocks field smearing into the perfect conductor. For a realistic metal film, the amount of induced current is similar to the case of a perfect conductor but now the current per area, J (z), flows inside the film, whose behavior is characterized by the skin depth. We can simplify the expression of J (z) by introducing an effective surface currentwhere h is the metal thickness. Similar to the perfect conductor case, it can be expressed by K ~× H 0 where H 0 (≈2 H inc) denotes the magnetic field outside the top metal surface (i.e. illuminating side). In the presence of subwavelength gaps perforated in the metal film, the induced surface current K charges the gap and applies a potential difference, across the tunnel junction positioned at an arc length l and n denotes the unit vector perpendicular to the contour, directed outward from the loop (Fig. 2a). As the gap width decreases down to the nanometre scale, the induced electric field in the gap is further enhanced by the induced charges of the opposite sides of the gap pulling each other, making enough potential gradient to drive non-negligible tunneling current across the point junctions. Temporal response of the resulting current is straightforwardly determined by the time profile of the incoming electromagnetic field. However, if the tunnel junctions are adjoined together forming a closed-loop, the resulting total current flowing through the loop, I (t), would be a sum over all the point junctions, expressed by the following contour integration, where J t (l, t) is the tunneling current flux determined by the electric potential V (l, t) and d A = hdl = hd l ×and h are the area element vector and height of the wall surrounding the contour, respectively. Depending on the incident polarization, the vector relation (integrand of Eq. 2) determines the amplitude and direction of the local current. The contour integration is naturally affected by the loop symmetry. Therefore, the response of the integrated junctions under the rapidly oscillating field is fundamentally different from the response on each junction element, which introduces an entirely new degree of freedom for manipulating the tunneling current.

---

### High spin axion insulator [^04d001d4]. Nature Communications (2024). High credibility.

Fig. 2
Transport properties of the spin-3/2 HSAI.

a Schematic current flow in a HSAI. The red arrows denote the quantized helical hinge currents. b Energy spectrum and the average position 〈 z / L z 〉 on the front surface for a HSAI nanowire with L y = 30, L z = 16. c Spectrum density A (k x, E) for the front lower hinge as labeled by the blue line in (a) on the k x − E plane. Here, the system size is L y = 30, L z = ∞ /2. The white dashed line represents the Fermi energy E F = 0.1. The white stars that mark the intersects between the Fermi energy and the spectrum are the Fermi momenta k F 1 and k F 2. d Top and middle panels are the current density J x (z), current flux I x (z) and its z -averaged flux 〈 I x (z)〉 versus the layer index z for a semi-infinite system with size L y = 30, L z = ∞ /2. The blue dots are the fitting data. Bottom panel shows the distribution of the moving averaged currenton the front surface with system size L y = 30, L z = 150. e Bird's eye view (top panel) and high-angle shot (bottom panel) for the six terminal device. f Ensemble-averaged non-reciprocal conductances versus the Fermi energy in the clean limit (W = 0), with non-magnetic Anderson disorders of strength W = 1 and with magnetic Anderson disorders of strength W z = 0.3. Here, the system size is L x = 31, L y = 20, L z = 21, and the size of transverse terminals is 10 × 10. g Experimental setup to detect the non-reciprocal conductance. In this setup, terminals 2, 4, 5, and 6 are grounded. The voltage is applied alternatively to terminal 1 or terminal 3. h Corresponding temporal dependent current output with parameters G 13 = 4.5 e 2 / h, G 31 = 2.5 e 2 / h. i F (ω) as a function of the frequency ω.

---

### Physical realization of topological roman surface by spin-induced ferroelectric polarization in cubic lattice [^2bff8ca9]. Nature Communications (2022). High credibility.

Introduction

Topological physics is one of the most successful integrations of the mathematics and physics field. As one of the branches of pure mathematics, topology has recently been employed to describe and understand many intriguing physical phenomena, such as the quantum Hall effect, topological insulators, topological semimetals, and topological superconductors –. These topological electronic states are classified by various topological invariants, such as the Chern number N, topological classes Z 2 and Z 4, and Euler class χ –. It is known that the Chern number is defined as the integral of the vector field, i.e. the Berry curvature over the first Brillouin zone of a two-dimensional (2D) periodic system, which is considered as a torus (T 2) and serves as the base manifold. Meanwhile, the magnetic spins and electric dipoles in real space can form topological objects or defects such as skyrmions, polar skyrmions, and polar merons. These can be identified with an integer winding numberbased on the field of spin or electrical dipole orientations over the base manifold of a sphere (S 2). In this sense, topological invariants are global characteristics, and topology-related physical properties are typically robust against perturbations.

In addition to torus and sphere, there are three other fundamental 2D manifolds found in algebraic topology (see Supplementary Table 1): the Möbius strip, Klein bottle, and Roman surface. The torus and sphere are orientable and have two sides. The Berry curvature flux enclosed by them can be a nonzero quantized value and taken as a topological invariant, such as the Chern number. By contrast, the Möbius strip, Klein bottle, and Roman surface are non-orientable surfaces with only one side. The flux of any vector field through them is zero. A well-known example is that a one-sided Klein bottle cannot be filled with water, but a two-sided bottle can. Moreover, the non-orientable surfaces feature a geometrical property in which a body can be mirror-reflected when traveling along a special loop path on the surface, such as along the Möbius strip without crossing the boundary, and recovers after the second loop of travel. It will be intriguing to realize a physical system that can evolve globally on a non-orientable surface to reflect such unique geometrical properties.

---

### Multi-scale turbulence simulation suggesting improvement of electron heated plasma confinement [^e923f47d]. Nature Communications (2022). High credibility.

Definition of the velocity–space-dependent turbulent energy flux

Instead of calculating trajectories of large numbers of particles, we have solved the time evolution of plasma distribution functions. Then, the correlation between a turbulent radial E × B flow and a perturbed distribution function is obtained by taking the average in homogeneous directions x and y in a simulation box L x × L y and over a range of time t 0 < t < t 0 + T. When the particle kinetic energy is multiplied, the velocity–space-dependent turbulent energy flux in Fig. 3c is expressed aswhere we retain the poloidal angle θ = z dependence to analyse the trapped-passing boundary, which is regarded as a microscopic heat flux per unit of velocity–space volume. Taking velocity–space and poloidal integrals, one obtains the time-averaged turbulent energy flux Q e = 〈∫ d v 3 Q e v 〉 θ, where angle brackets 〈⋯〉 θ denote the flux-surface average.

Definition of the turbulent energy flux spectrum

Because the turbulent transport is a convolution of a turbulent radial E × B flow and a perturbed distribution function, the time-averaged perpendicular wavenumber spectrum of the turbulent energy flux is given by

The gyrophase-averaged perturbed electron pressure is denoted by p e k = ∫ d v 3 (m e v || 2 /2+ μB 0) J 0 (k ⊥ ρ e) f e k with the zeroth-order Bessel function J 0 and the perpendicular wavenumber k ⊥. The poloidal wavenumber spectra are calculated by taking the summation of Q e k over k x ρ ti, Q e ky = ∑ kx Q e k. In Fig. 4, the plot is normalised to compare the simulations with different minimum wavenumber Δ k y = k y, min on an equal footing, Q e = ∑ ky Q e ky = ∫d k y (Q e ky /Δ k y).

---

### Bayesian tomography of high-dimensional on-chip biphoton frequency combs with randomized measurements [^b26a4537]. Nature Communications (2022). High credibility.

In addition to the parameters forming ρ, the scale factor K must also be suitably parameterized. Following ref. we find it convenient to write K = K 0 (1 + σ z), where K 0 and σ are hyperparameters defined separate of the inference process, and z is taken to follow a standard normal distribution, leading to a normal prior on K of mean K 0 and standard deviation K 0 σ. We take σ = 0.1 and K 0 equal to the sum of the counts in all d 2 bins for the first JSI measurement (r = 1), where the absence of modulation ensures that all initial photon flux remains in measured bins, i.e. This provides an effectively uniform prior, since a fractional deviation of 0.1 is much larger than the maximum amount of fractional uncertaintyexpected from statistical noise at our total count numbers; the use of a normal distribution simplifies the sampling process.

The total parameter set can therefore be expressed as the vector, with the prior distribution

We note that this parameterization entails a total of 4 d 4 + 1 independent real numbers (2 d 4 complex parameters for ρ, one real parameter for K) — noticeably higher than the minimum of d 4 − 1 required to uniquely describe a density matrix. Nevertheless, this ρ (y) parameterization is to our knowledge the only existing constructive method to produce Bures-distributed states, and is straightforward to implement given its reliance on independent normal parameters only.

Following Bayes' rule, the posterior distribution becomeswhereis a constant such that ∫ d x π (x) = 1. We have adopted this notation for Bayes' theorem — rather than the more traditional — to emphasize the functional dependencies on x, which are all that must be accounted for in the sampling algorithm below. From π (x), the Bayesian mean estimator f B of any quantity (scalar, vector, or matrix) expressible as a function of x can be estimated aswhere, in lieu of direct integration, S samples { x (1),…, x (S) } are obtained from the distribution π (x) through Markov chain Monte Carlo (MCMC) techniques, as described below.

---

### An analytic approximation of the feasible space of metabolic networks [^e63ca097]. Nature Communications (2017). Medium credibility.

Assuming a steady-state condition within a cell, metabolic fluxes satisfy an underdetermined linear system of stoichiometric equations. Characterizing the space of fluxes that satisfy such equations along with given bounds (and possibly additional relevant constraints) is considered of utmost importance for the understanding of cellular metabolism. Extreme values for each individual flux can be computed with linear programming (as flux balance analysis), and their marginal distributions can be approximately computed with Monte Carlo sampling. Here we present an approximate analytic method for the latter task based on expectation propagation equations that does not involve sampling and can achieve much better predictions than other existing analytic methods. The method is iterative, and its computation time is dominated by one matrix inversion per iteration. With respect to sampling, we show through extensive simulation that it has some advantages including computation time, and the ability to efficiently fix empirically estimated distributions of fluxes.

---

### Revised estimates of ocean-atmosphere COflux are consistent with ocean carbon inventory [^a2131bcd]. Nature Communications (2020). High credibility.

The ocean is a sink for ~25% of the atmospheric CO 2 emitted by human activities, an amount in excess of 2 petagrams of carbon per year (PgCyr -1). Time-resolved estimates of global ocean-atmosphere CO 2 flux provide an important constraint on the global carbon budget. However, previous estimates of this flux, derived from surface ocean CO 2 concentrations, have not corrected the data for temperature gradients between the surface and sampling at a few meters depth, or for the effect of the cool ocean surface skin. Here we calculate a time history of ocean-atmosphere CO 2 fluxes from 1992 to 2018, corrected for these effects. These increase the calculated net flux into the oceans by 0.8–0.9 PgC yr -1, at times doubling uncorrected values. We estimate uncertainties using multiple interpolation methods, finding convergent results for fluxes globally after 2000, or over the Northern Hemisphere throughout the period. Our corrections reconcile surface uptake with independent estimates of the increase in ocean CO 2 inventory, and suggest most ocean models underestimate uptake.

---

### Field theory for recurrent mobility [^ac9e94cd]. Nature Communications (2019). High credibility.

Understanding human mobility is crucial for applications such as forecasting epidemic spreading, planning transport infrastructure and urbanism in general. While, traditionally, mobility information has been collected via surveys, the pervasive adoption of mobile technologies has brought a wealth of (real time) data. The easy access to this information opens the door to study theoretical questions so far unexplored. In this work, we show for a series of worldwide cities that commuting daily flows can be mapped into a well behaved vector field, fulfilling the divergence theorem and which is, besides, irrotational. This property allows us to define a potential for the field that can become a major instrument to determine separate mobility basins and discern contiguous urban areas. We also show that empirical fluxes and potentials can be well reproduced and analytically characterized using the so-called gravity model, while other models based on intervening opportunities have serious difficulties.

---

### Confirmation of the topology of the wendelstein 7-X magnetic field to better than 1: 100, 000 [^6de1b984]. Nature Communications (2016). Medium credibility.

Evaluation of an important error field component

For the first measurements of the n = 1 error field, a special magnetic surface configuration was used, where ɩ varies slowly and passes through the resonance ɩ = 1/2, see Fig. 6.

In the complete absence of error fields, a small n = 5, m = 10 island chain would appear at the ɩ = 1/2 location at around 25 cm distance from the innermost magnetic surface, but in the presence of even a small n = 1 error field, an n = 1, m = 2 island chain, visible in a Poincaré plot as two 'bubbles', will appear.

The B 21 error field is too small to create an island structure large enough to be measured clearly. This is in part due to the good news that it is small, and in part due to ɩ being so close to 1/2, that the electron beam comes very close to its launch position (the electron gun) after two toroidal transits, thus running the risk of hitting the back of the electron gun and disappearing.

It is nevertheless possible to indirectly measure the B 21 field error, despite this shadowing problem, by adding an n = 1 error field with a well-defined amplitude and phase, using the set of five large external coils, four of which are shown in yellow in Fig. 1. The primary purpose of these coils is to trim away the unwanted n = 1 error field components, but the trim coils are used here to create an extra n = 1 error field, and thus generate an n / m = 1/2 island chain wide enough to be measurable.

Light fibres installed in the vessel along with detailed measurements of their location allow the pixels of the image plane to be mapped to physical dimensions. In this way, the width of the island in physical units can be inferred from a measurement in pixels. Error bars account for both the physical width of the flux surface traces and the step size going from outside the island chain to inside it. A best attempt is made to report the maximum width of the magnetic islands.

---

### Topology, landscapes, and biomolecular energy transport [^fb4f96c1]. Nature Communications (2019). High credibility.

We employ this kinetic approach with an intermediate timescale (Δ t = 100 fs), long enough to average over most coherent motion but short enough not to obscure the evolution of energy in time. The distribution of backbone fluxes J BB is parameterized by an effective temperature gradient Δ ij T eff = 2[E i − (f j / f i) E j]/3 Nk B between residues i and j, where the flux is incident on a residue containing N atoms. While transport is explicitly quantified through J BB for simplicity, the effect of hydrogen bonding is present when fitting the backbone flux distribution at hydrogen bonding sites. The results for J BB are presented in Fig. 3a. A complimentary analysis for J HB and a validation of fitting methods are presented in Supplementary Figs. 10–15.

Fig. 3
Flux and thermal gradient distributions. a Backbone flux distributions (J BB) for helical Aib 10 conformers. Fluxes are parameterized by the effective temperature gradient Δ ij T eff between adjacent residues, and a positive flux corresponds to flow away from the heater along the backbone. Transport regimes are labeled parallel to the text (A through D) and with orange lines for visibility. b The J BB distribution may be partitioned into low–temperature (blue; 230–270 K) and high–temperature (red; 290–330 K) regimes. c Distribution of local temperature gradients Δ ij T eff versus average elevation Δ T B, j (t) = 〈 T j (t)〉 − T B over the bath temperature and d versus simulation time t for the ensemble of MD trajectories. Labels (a – d) correspond to the regimes described in the text. Time series data from MD simulation is averaged with Δ t = 100 fs for fits to the master equation, Eq. (1), and the resulting fluxes are block averaged in 1.0 K bins. The error bars are plus/minus one standard error

---

### Quantifying dissipation using fluctuating currents [^2479585e]. Nature Communications (2019). High credibility.

Suppose, however, that it is not simple to measure the heat flux. Rather, we imagine directly observing the bead positions as a function of time. Those measurements are sufficient to extract the entropy production rate, but to do so we must go beyond the thermodynamics and explicitly consider the system's dynamics, an approach known as stochastic thermodynamics. The starting point is to mathematically describe the bead-spring dynamics with a coupled overdamped Langevin equation, where x = (x 1, x 2) T is the vector consisting of each bead's displacement from its equilibrium position, ξ = (ξ 1, ξ 2) T is a vector of independent Gaussian white noises, andThe matrix A captures deterministic forces acting on the beads due to the springs, while F describes the random forces imparted by the medium. The strength of these random forces depends on the temperature and the Boltzmann constant k B, consistent with the fluctuation-dissipation theorem.

It is useful to cast the Langevin equation as a corresponding Fokker-Planck equation for the probability of observing the system in configuration x at time t, ρ (x, t):with D = FF T /2. Though we are modeling a two-particle system, it can be helpful to think of the entire system as being a single point diffusing through x space with diffusion tensor D and with deterministic force γ Ax. The second equality in Eq. (3) defines the probability current j (x, t). These probability currents (and their fluctuations) will play a central role in our strategies for inferring the rate of entropy production.

Due to its analytic and experimental tractability, this bead-spring system and related variants have been extensively studied as models for nonequilibrium dynamics –. In particular, the steady-state properties are well-known. Correlations between the position of bead i at time 0 and that of bead j at time t are given by C ij (t) = 〈 x i (0) x j (t)〉. The expectation value is taken over realizations of the Gaussian noise to giveThe steady-state density and current are expressed simply asin terms of the long-time limit of the correlation matrix

---

### Learning non-stationary langevin dynamics from stochastic observations of latent trajectories [^88ab8311]. Nature Communications (2021). High credibility.

Fig. 3
Contribution of non-stationary components to the accurate inference of latent Langevin dynamics.

The spike data are generated from the Langevin dynamics with a linear potential and absorbing boundaries (Fig. 2 b). a The inference incorporates the non-equilibrium initial state distribution p 0 (x), absorbing boundary conditions, and the absorption operator (graphical diagram, inset in the left panel). When the likelihood of the fitted model approaches the likelihood of the ground-truth model (left panel, the relative log-likelihood is), the inferred potential shape closely matches the ground truth (right panel, colors correspond to the iterations marked with dots on the left panel). b Same as a, but omitting the absorption operator in the inference. The relative log-likelihood is with respect to the likelihood for the ground-truth potential, with the absorption operator omitted in the likelihood calculation for both the ground-truth and fitted potentials. c Same as b, but replacing the absorbing with reflecting boundary conditions in the inference and in the likelihood calculation for both the fitted and ground-truth potentials. d Same as c, but replacing p 0 (x) with the equilibrium density p eq (x) in the inference and in the likelihood calculation for both the fitted and ground-truth potentials. Omitting any of the non-stationary components results in artifacts in the inferred potentials.

To reveal how each non-stationary component contributes to the inference, we replace all components one by one with their stationary counterparts and evaluate the inference quality under these modified conditions. First, we test the importance of the absorption operator by performing the inference with the initial distribution p 0 (x) and absorbing boundary conditions, but omitting the absorption operator (Fig. 3 b). In this scenario, the likelihood includes all trajectories that terminate anywhere in the latent space and do not reach the domain boundaries before the trial end. The inferred potential shows the correct linear slope, but develops a large barrier near the right boundary, where the ground-truth potential is low. This behavior arises since the spurious potential barrier reduces the probability flux through the absorbing boundary and hence increases the model likelihood. Accordingly, the likelihood is lower for the ground-truth potential than for the potential with the spurious barrier when the absorption operator is omitted in the likelihood calculation Eq. (4). The absorption operator corrects for this mismatch by ensuring that only trajectories terminating at the boundaries contribute to the likelihood.

---

### Functional decomposition of metabolism allows a system-level quantification of fluxes and protein allocation towards specific metabolic functions [^ca13579f]. Nature Communications (2023). High credibility.

Given a flux pattern obtained via FBA, we sought a general method to quantify how much a given metabolic reaction contributes to another metabolic process γ, e.g. how much of the carbon intake flux is used for the production of a given amino acid, or how much of the flux through a given glycolytic reaction is associated with the regeneration of ATP. Answering these questions is tantamount to expressing the metabolic fluxes in the network in terms of the consumption (demand) fluxes of biomass building blocks or the production of energy in each growth condition.

It is possible to provide an explicit expression that relates the FBA-derived flux vector v, which has entries v i for each reaction i, to the demand fluxes J γ. The set of the demand fluxes appearing in such expression is not arbitrary and it depends on the specific FBA formulation used to model the metabolic fluxes. As discussed in depth in Supplementary Note 2, each non-dimensionless constraint applied to the network must be associated with a demand flux; In the case shown in Fig. 1, demand fluxes are associated with the synthesis fluxes of each biosynthetic building block and the maintenance ATP flux. (We will discuss the effect of additional constraints later below.) Because of the linear properties of the optimization problem, and as long as the flux solution is unique, the nonzero fluxes can be expressedas a linear combination of the demand fluxes J γ :This expression represents a parameterization of the optimal fluxes in terms of the demand fluxes J γ, and allows to analyze how the flux v changes in response to perturbations of the demand fluxes. The terms ξ (γ) determine how variations in the demand fluxes J γ affect each reaction. To determine these coefficients we note that they match the derivatives of the fluxes with respect to the demand fluxes. Thus, they can be obtained numerically by computing the optimal fluxes upon a small perturbation of each demand flux J γ. Taken to face value, Eq. (1) suggests that the flux pattern v can be partitioned into the sum of several flux componentswhere each component v (γ) satisfies the mass-balance constraints of the network and is associated with a single demand flux J γ. For example, if γ represents the production of the amino acid glutamine, then both ξ (γ) and v (γ) represent a complete pathway transforming the carbon and nitrogen sources to glutamine; the two only differ by an overall normalization factor. We will use this example to illustrate our results later below.

---

### A chip-scale atomic beam clock [^d08bbd3c]. Nature Communications (2023). High credibility.

Fig. 2
Spectroscopic beam cell characterization.

a Source cavity absorption (gray) and drift cavity fluorescence at z = 1 mm (red) and z = 11 mm (blue) measures the Rb number density, flux, and the velocity distribution normal to the device surface at 363 K. b Fluorescence at z = 11 mm includes narrow peaks from the atomic beam signal as well as a broad signal corresponding to background Rb vapor (light blue curve). Passive and differential pumping generates a large (≈6500×) Rb partial pressure differential between the source and drift cavities. c The measured atomic beam flux F meas and spectral FWHM are plotted versus distance from the capillary array at 363 K. Flux prediction based on n Rb,1 (black dashed lines) and the geometrical FWHM limit set by the fluorescence imaging (red dotted line) are shown. Inset shows the estimated total capillary flux F tot versus device temperature and comparison to the total expected capillary array flux(dashed line). Error bars represent 68% confidence intervals.

The flux and angular divergence of the atomic beams are measured using fluorescence spectroscopy in the drift cavity. Fluorescence is collected using a 1:1 imaging system with ≈1.9% collection efficiency mounted at 45° from the beam axis in the x-z plane. The imaged area corresponds to a 1 mm × 1.4 mm region in the x-y plane. Fluorescence spectra scanning around the 85 Rb F = 3 → F' = 4 transition (labeled as zero optical detuning) are measured at varying distances along z from the capillary array. Example spectra at z = 1 mm and z = 11 mm at 363 K (shown in Fig. 2a, b) demonstrate narrow spectral features corresponding to the atomic beam signal and broader features arising from thermal background Rb vapor. The measured atomic beam flux is calculated from the number of detected atoms in the imaged volume N det (see methods) aswhereis the most probable longitudinal velocity of the atomic beam and L is the length over which the atoms interact with the probe beam. At 363 K and z = 1 mm, = 5 × 10 11 s −1 and the FWHM of the fluorescence lines is ≈150 MHz, corresponding to a transverse velocity FWHM of ≈120 m/s. At this distance, ≈65% of the total capillary array is probed and the total atomic beam flux is estimated to be = 7.7 × 10 11 s −1, consistent with the measured density in the source cavity and molecular flow predictions through the capillaries (see Fig. 2c inset).

---

### Edge States and skyrmion dynamics in nanostripes of frustrated magnets [^e7f3bb35]. Nature Communications (2017). Medium credibility.

Figure 1b shows three types of evanescent edge states induced by the easy plane surface anisotropy in one or more rows at the edges of the magnetic stripe. The type I edge state with collinear in-plane spin components is induced by K ′ ≤ −0.434 in the first row; K ′ = 0 in the first row and K ′ ≤ −0.808 in the second row induces type II state — the evanescent conical spiral state with the wave vector along the boundary (x direction) and the in-plane magnetization vector rotating around the z axis. K ′ = −0.406 in the first row and K ′ = −0.203 in the second row give rise to type III state, in which the in-plane magnetization vector shows fan-like oscillations around a fixed direction in the xy plane. Importantly, in all edge states the in-plane magnetization oscillates with the decaying amplitude along the y axis normal to the edge (Fig. 1c).

These oscillations are a characteristic property of frustrated magnets and the three types of edge states are generic. The origin of the oscillations can be understood by considering asymptotic of the in-plane magnetization vector, m ⊥ (x)∝e i q · x, deep inside the magnetic stripe. In the continuum limit,

where the first two terms originate from the expansion of the exchange energy of a frustrated magnet in powers of q (a = (3 J 2 − J 1) > 0, b = (9 J 2 − J 1) > 0). This bi-quadratic equation with real coefficients has four solutions: ± q = ± (q ′+ iq ″) and ± q ✱ = ± (q ′− iq ″). In the situation when modulated states are suppressed in the bulk, all four wave vectors have a nonzero imaginary part q ″. They can be grouped into two pairs according to the sign of q ″: (+ q ′+ iq ″,− q ′+ iq ″) and (+ q ′− iq ″,− q ′ − iq ″). One pair describes m ⊥ with an amplitude decreasing away from the upper edge and another pair describes the evanescent state near the lower edge. The real parts of the two wave vectors in each pair have opposite signs. The interference between the modulations with positive and negative q ′ leads to spin oscillations.

---

### Microfluidic multipoles theory and applications [^31dd0050]. Nature Communications (2019). High credibility.

Upon inspection, the problem can be transformed to streamline coordinates (Fig. 2a) using the function

In the streamline domain Φ, the problem is equivalent to a channel geometry with flows of concentration c = 1 and c = 0 separated by a no-flux boundary condition on the origin. At the stagnation point, the no-flux condition is dropped, and the flows are free to mix (Fig. 2a) (see Supplementary Table 2 for more details on the streamline problem). The separating streamline going from the stagnation point to the aspiration aperture corresponds to the semi-infinite segment of the horizontal axis where the fluids can mix. If the Péclet number is high enough (higher than about 10, which is always realized in microfluidics applications), this segment can be taken to have concentration c = 1/2 and the walls of the channel geometry can be safely ignored (Supplementary Note 1). The problem can thus be decomposed in two problems of advection-diffusion around semi-infinite obstacles of fixed concentration. The problem of advection-diffusion around such a semi-infinite obstacle has been extensively studied in theoretical fluid mechanics, notably in the theory of dendrite solidification, and in the study of out of plane flow in Burgers vortex sheets. It yields the solutionwhere Φ stag is the image of the stagnation point and erf(x) is the error function. The sign of ± is determined by whether we have an incoming flow of concentration c = 0 or c = 1. However, neither of these concentration profiles represent the full dipole footprint when transformed. This can be seen physically in the flow dipole, in which there is both incoming fluid at concentration 0 (aspirated from the system's surroundings), and incoming fluid at concentration 1 (injected by the aperture). To solve this issue, we separate the problem into an "interior" and an "exterior" domain at the streamline of concentration c = 1/2 (see checkerboard insets in Fig. 2). There remains a discontinuity in our solution due to the branch cut of the logarithm functions in Eq. (1), but the solution can be made continuous by placing the singularities on the real axis and using it as an axis of symmetry. The final step is then to obtain the entire solution as a piecewise function assembling the "interior" and "exterior" solutions, given by transforming Eq. (6) back to the dipole flow domain Z. The interior and exterior domains can be defined either by checking the sign of Φ in the streamline domain or by using the expression for the separating line in the Z domain in polar coordinates (see Supplementary Note 2).

---

### Flow perturbation to accelerate boltzmann sampling [^1b7f5228]. Nature Communications (2025). High credibility.

To address this computational challenge, we introduce the flow perturbation method. This method is based on the fact that the reweighting scheme applies not only to deterministic flows but also to stochastic processes. For stochastic trajectories, reweighting is performed using the exponential of the negative work, just as in the deterministic case. However, the key difference is that the entropy term for a stochastic trajectory is determined by the conditional probability ratio between this trajectory with its corresponding reverse trajectory, which offers a potential way to avoid the computationally intensive Jacobian calculation.

To implement the flow perturbation method, we add the following stochastic perturbations to the flow and the inverse flow, which create a forward and backward stochastic process:Hereare random noises drawn from a standard Gaussian distribution, andare matrices that scales the forward and backward noise, respectively. An illustration of the perturbed flow is shown in Fig. 1 b.

With the forward and backward process defined in Eqs. (3) and (4), the entropy of a forward trajectory z → x is given bywhereis the exact noise needed to bring x back to z. A detailed derivation for this expression of entropy can be found in Supplementary Sec. A.

While this entropy formulation eliminates the need for Jacobian calculations, it does not guarantee an increase in the efficiency of Boltzmann sampling. In fact, its efficiency largely depends on the choice of the forward and backward scaling matrices σ f (z) and σ b (x). Poorly chosen σ f (z) and σ b (x) can significantly increase the forward path Kullback–Leibler (KL) divergence of the perturbed flow (as defined in Eq. (26) in the "Methods" section), in which case a far greater number of trajectories would be required for accurate reweighting. This additional burden may outweigh the computational savings achieved by avoiding Jacobian evaluations.

---

### Flow perturbation to accelerate boltzmann sampling [^54c2e174]. Nature Communications (2025). High credibility.

Even with low-dimensional representations, training scaling matrices incurs additional computational costs. However, under certain limiting conditions, the entropy term defined in Eq. (5) simplifies significantly, removing its dependence on these scaling matrices entirely. These conditions are: (1) both scaling matrices, σ f (z) and σ b (x), become isotropic and reduce to scalar functions; (2) both scalar functions are scaled by a global parameter α; and (3) the limit α → 0 is taken. Under these specific constraints, the entropy term simplifies to the compact form:whereis a random unit vector drawn from the uniform distribution on the unit D -dimensional sphere, andis the Jacobian of the inverse flow evaluated at x = f (z). This simplified expression, termed the Simplified Flow Perturbation Entropy Estimator, is derived in Supplementary Sec. B, where we also show that reweighting with this estimator preserves unbiased sampling of the target Boltzmann distribution.

---

### Reverberant 3D optical coherence elastography maps the elasticity of individual corneal layers [^4196d1b7]. Nature Communications (2019). High credibility.

If the particle velocity in Eq. (1) is measured along the z -axis, then, whereis a unit vector in the z direction. Figure 1b shows V z (ε, t 0) for an instant t 0 in a cube of 20 × 20 × 20 mm 3 of uniform elastic material after conducting a Monte Carlo analysis. Four uniformly distributed random variables were considered: angles φ and θ, each one covering a range of [0, 2π] radians, for the definition of; angle α, covering a range of [0, 2π] radians for the definition of; and the scalar value v ql, covering a range of [− v max, v max], where v max is the maximum particle velocity amplitude supported in the system. In the analysis, the frequency of shear waves was defined as f 0 = 2 kHz, leading to ω 0 = 2π f 0, and a constant shear wave speed of c s = 4 ms −1 within the cube, where c s = ω 0 / k. A total of 10,000 realizations of all random variables were considered in order to recreate the reverberant field. Detailed description about the Monte Carlos Analysis can be found in the Methods section.

Given the reverberant field V z (ε, t 0) shown in Fig. 1b, closed-form complex analytical solutions can be found for the spatial auto-correlation of such fields along parallel and orthogonal directions to the measurement axis. In the orthogonal case, the auto-correlation of the reverberant field along the x -axis (or y -axis) is given by (complete theoretical derivations are explained in Supplementary Methods):where β is the expected value of squared particle velocity magnitudeover both q and l realizations; j 0 and j 1 are spherical Bessel functions of the first kind of zero and first order, respectively; and, withas a unit vector along the x -axis. It is important to note thatandhave the same solution since both correlation axis, andare perpendicular to measurement axis. Therefore, is symmetric around the origin for any Δ ε such that.

---

### X-ray rheography uncovers planar granular flows despite non-planar walls [^b6e6d84b]. Nature Communications (2018). Medium credibility.

Image correlation and convolution analysis

Images are preprocessed by dividing through by the average intensity, calculated from 5000 radiographs taken from the same scanning direction during flow. This highlights the intensity fluctuations, or equivalently density fluctuations, from the baseline values, which are significant in our system due to the relatively large particle size compared to the overall system. With increasing numbers of particles, the radiographs will become more homogeneous and the subsequent analysis will be less effective.

The processed images are then subdivided into interrogation windows of size 128 × 128 px 2, with an overlap of 75%. Note that such an overlap is only used in the first stage of the reconstruction process, where it is employed, as for regular PIV, to improve spatial resolution and accuracy. In the later stages, we neglect the overlapping nature of the windows, considering all information to be associated with the cell centre only. It may be interesting in future to carry the overlapping cells through the whole process, formulating new discretisation and optimisation procedures that take this extra detail into account.

For a given successive pair of processed images with intensities I 1 and I 2, we then calculate, in each interrogation window, the 2D auto-correlation (A) and cross-correlation (C) functionswith m, n representing discrete pixel displacements and p, q pixel locations in the two in-plane directions. In the above, and σ 1, σ 2 denote the mean and standard deviation of the intensities taken over each window. To reduce computational time, these correlation functions are made one-dimensional by averaging over each dimension in turn, which gives two sets of functions A ξ (m), A η (n), C ξ (m), C η (n), corresponding to displacements in the two in-plane directions. Such a one-dimensionalisation has previously been shown to not significantly influence results. At the recording frame rate of 30 fps, a typical displacement is only an equivalent distance of a few detector panel pixels or less. To increase the spatial resolution, we therefore correlate sliding pairs of images registered 10 frames apart, i.e. image 1 and 11, 2 and 12, and so on. The one-dimensional auto- and cross-correlation functions are then averaged over 100 such pairs to minimise the noise present from false matches of particles.

---

### Network dynamics: jamming is limited in scale-free systems [^a0568062]. Nature (2004). Excellent credibility.

A large number of complex networks are scale-free — that is, they follow a power-law degree distribution. Here we propose that the emergence of many scale-free networks is tied to the efficiency of transport and flow processing across these structures. In particular, we show that for large networks on which flows are influenced or generated by gradients of a scalar distributed on the nodes, scale-free structures will ensure efficient processing, whereas structures that are not scale-free, such as random graphs, will become congested.

---

### Controllable quantum point junction on the surface of an antiferromagnetic topological insulator [^9967c6ab]. Nature Communications (2021). High credibility.

STM tip modeling

To model the effects of the magnetic and electrostatic STM tips we extend the QPJ Hamiltonian (H QPJ) with two spatially dependent termswhere the second term modifies the Zeeman interaction in a region Ω Z and the third term shifts the energy of all orbitals and spins uniformly inside a region Ω G.

For a positive V Z in Eq. (9), we choose the region Ω Z such that it restricts the sum to surface orbitals that lie within a radius r of the tip, and that already experience a negative Zeeman field from the bulk Hamiltonian of Eq. (8). Thus, V Z = m Z is just enough to remove the Zeeman field from these sites, and V Z = 2 m Z makes the surface-layer Zeeman field equal on both sides of the domain wall or step, as in Fig. 4 a. We can then tune between these extremes by taking V Z ∈ [0, 2 m Z], thus modeling cases in which the magnetic tip has only partially reversed the surface field. Similarly, for V Z < 0, Ω Z is chosen such that the second term in Eq. (9) is restricted to surface orbitals experiencing a positive Zeeman field in the bulk Hamiltonian.

The region of influence of the electrostatic tip, Ω G in Eq. (9), is defined to be a rectangle centered at (x 0, y 0) relative to the QPJ and one unit cell deep, as shown by the gray shading in Fig. 4 d. A WP propagating for a distance ℓ along any domain-wall or step channel lying inside the quantum well defined by Ω G acquires an additional phase proportional to ℓ Δ k, where Δ k is the shift of the Fermi wavevector of the channel. In the approximation of linear dispersion, we have Δ k = V G / ℏ υ F, where V G corresponds to a local gate voltage and υ F is the Fermi velocity (equal to υ dw and υ st for domain-wall and step channels respectively). Thus, the off-centering of Ω G defined by (x 0, y 0) allows us to control the travel distances ℓ along each of the four "legs" near the junction, introducing extra phases that are given byin Eq. (7).

---

### Half-quantum mirror hall effect [^12d57ae1]. Nature Communications (2024). High credibility.

After projection, we identify a series of Dirac bands: four are gapless, while the remaining bands are gapped and topologically trivial. The topological phenomena manifest in the four gapless bands; here, the low-energy states correspond to surface states, and the high-energy states within these bands transition to bulk states (as shown in Supplementary Fig. 2). In the eigenbasis of mirror symmetry, the wave functions of the surface states in each sectorare symmetric (χ = +1) or antisymmetric (χ = −1) about z, in which the sites z and − z are connected and breaks the locality property on the lattice. By solving the three-dimensional model for a TI film, we find it essential to incorporate a term that breaks the symmetry to provide and accurate representation of the surface states:where the Pauli matricesact on the spaces spanned byandfor the χ = + and χ = − sectors respectively and Δ(k) = Θ [− m 0 (k)] m 0 (k) with Θ (x) as a step function and. m 0 is the bulk gap of TI. For each mirror sector χ, we can define a parity operator, which transforms (k x, k y) → (− k x, k y) and is represented byin the 2 × 2 subspace. In the vicinity of k = 0, when m 0 (k) > 0, Δ(k) is zero, allowing H surf, χ to preserve the parity symmetry. Conversely, in high energy states when m 0 (k) < 0, Δ(k) ≃ m 0 (k) ≠ 0, explicitly breaking the parity symmetry. For the details of the derivation, see Supplementary Information. With the inclusion of the symmetry-breaking term, the gapless states described by the Hamiltonian in Eq. (7) diverge significantly from the conventional Dirac surface states. As shown in Fig. 2 d, we present a schematic diagram to illustrate the main difference between the proposed gapless Dirac cone model with broken parity symmetry and the conventional Dirac surface states: in the parity invariant regime (m 0 (k) > 0), the pseudo-spin texture is confined to the x y -plane, whereas outside this regime, the pseudo-spin texture acquires z components that break the parity symmetry explicitly. The time-reversal symmetry, which is antiunitary, commutes with the mirror symmetry: Then for an eigenstateofthat satisfies, it follows that. This implies that after the transformation of, the stateflips its eigenvalue of. Therefore, the time-reversal symmetrymaps one mirror sector onto the other. In Fig. 2 b, the spectrum of the four-band Hamiltonian [Eq.(7)] are plotted as blue dashed lines, demonstrating that it accurately reproduces the spectrum not only at low energies but also at the corners of the Brillouin zone (as shown in Supplementary Fig. 1). In this way, a single Dirac cone may exist in the first Brillouin zone as a consequence of the symmetry breaking to avoid the fermion doubling problem. This is distinct from the conventional effective model for the surface states which is only valid for a small k. As explained in Supplementary Note 3, we elucidate the relationship and distinction between our lattice-based theory and the quantum anomaly originating from an effective k ⋅ p model. The mass term can be interpreted as a natural regularization that emerges on a lattice and resolves the divergence in the charge-charge and mirror-mirror polarization tensors inherent in the effective k ⋅ p model. Additionally, it serves as the topological origin of the half-quantum mirror Hall effect.

---

### Edge States and skyrmion dynamics in nanostripes of frustrated magnets [^a5dcbcda]. Nature Communications (2017). Medium credibility.

Results

Edge states and edge channels in frustrated magnets

The nontrivial skyrmion topology gives rise to a high energy barrier that prevents the decay of skyrmions into magnons. However, near the boundaries of a magnet this barrier can be significantly lower or may not exist at all. Therefore, the practical use of skyrmions crucially depends on their repulsion from edges of magnetic nanostructures. In chiral magnets such a repulsion is naturally provided by the bulk DM interaction, which tilts the magnetization vector away from the magnetic field direction at the edges of a magnet, giving rise to the so-called edge states.

Competing spin interactions in frustrated magnets do not necessarily induce similar spin tilts. However, exchange interactions and magnetic anisotropies at surfaces or interfaces of magnetic materials can be significantly different from those in bulk, because of a lower symmetry of magnetic ions at the edges. We have found that a strong surface anisotropy gives rise to edge states in frustrated magnets with a variety of complex structures, which confine skyrmions to a nanostripe.

We studied minimal-energy states in a stripe of a frustrated magnet (Fig. 1a),

where m i is the unit vector in the direction of the magnetization at the site i of a triangular lattice. The first and the second terms in the energy describe the competing ferromagnetic nearest-neighbour and antiferromagnetic next-nearest-neighbour interactions (J 1, J 2 > 0), h is the magnetic field applied in the z direction normal to the stripe, K > 0 is the bulk easy axis magnetic anisotropy and < 0 is the easy plane anisotropy added near the edges. The rich phase diagram of this model counts 8 different phases including the skyrmion crystal state. Important for our present study is a large region of the field-induced collinear ferromagnetic state, where isolated skyrmions are stable. We use the set of bulk model parameters, J 2 = 0.5, h = 0.4, K = 0.2 (in units of J 1 = 1), for which spins inside the stripe are normal to the stripe plane. The easy plane edge anisotropy favors a conical spiral state near the edges, which gives rise to edge states with complex spin structures.

---

### Symmetry breaking in optimal transport networks [^30e99d16]. Nature Communications (2024). High credibility.

Engineering multilayer networks that efficiently connect sets of points in space is a crucial task in all practical applications that concern the transport of people or the delivery of goods. Unfortunately, our current theoretical understanding of the shape of such optimal transport networks is quite limited. Not much is known about how the topology of the optimal network changes as a function of its size, the relative efficiency of its layers, and the cost of switching between layers. Here, we show that optimal networks undergo sharp transitions from symmetric to asymmetric shapes, indicating that it is sometimes better to avoid serving a whole area to save on switching costs. Also, we analyze the real transportation networks of the cities of Atlanta, Boston, and Toronto using our theoretical framework and find that they are farther away from their optimal shapes as traffic congestion increases.

---

### An analytic approximation of the feasible space of metabolic networks [^98e46319]. Nature Communications (2017). Medium credibility.

An shown in Fig. 2 in real cases, variances of the marginal distributions can span several orders of magnitude. This range of variability implies that also the variances of the approximation need to allow both very small and huge values. To cope with the numeric problems that may arise, we allow parameters d to vary in a finite range of values with the drawback of limiting the set of allowed Gaussian densities of the approximation. For instance, a flat distribution cannot be perfectly approximated through a Gaussian whose variance cannot be arbitrary large; in the opposite extreme, imposing a lower bound on variances prevents the approximation of posteriors that are too concentrated on a single point. Thus, this range needs to be reasonably designed in order to catch as many 'true' variances as possible. In this work, we have tried to impose a very large range of values, typically (10 −50, 10 50), to include as many distributions as possible without compromising the convergence of the algorithm. Moreover, the Gaussian profile itself is surely a limitation of the approximation as true marginals can have in principle arbitrary profiles.

EP performances are sensitive to the parameter β and equations become numerically unstable for too large β (for example, 10 11–10 12). On the other hand, β can be seen as the inverse-variance of a Gaussian noise affecting the conservation laws. The nature of this noise could depend on localization properties on the cell and real thermal noise. In this case, an optimization of the free energy with respect to β can in principle lead to better predictions.

---

### Dynamic simulation of articulated soft robots [^661da5b7]. Nature Communications (2020). High credibility.

As soft robots are often intended for locomotion on unstructured terrain, we require a method to account for contact and friction with the ground. Importantly, the surface normal can vary with the horizontal x axis. We model the nonpenetration constraints and frictional contact forces that resist sliding along interfaces based on Coulomb's law. At each time step, we apply continuous collision detection to the predicted trajectory to gather contact constraints into a contact set, shown in Fig. 1c. For these calculations, the velocity(subscript denotes element number in a vector), and the reaction force, at the j th node (the contact point) satisfy the conditionwhere μ = 0.8 is the friction coefficient characterized by experiments (Supplementary Methods), and the superscript ∥ (and ⊥) denotes the component along (and perpendicular to) the ground. At the normal and tangential subspaces of a contact node x j, we either know its perpendicular velocity u ⊥ (u ∥ for tangential component) or the perpendicular reaction force R ⊥ (R ∥ for tangential component), so the Coulombic frictional contact law can be treated as a Second Order Linear Complementary Problem (SOLCP). We employ the modified mass methodto solve this SOLCP such that a contact node x j can be free (degrees of freedom is 2, taking off), constrained along the normal to the ground p (degrees of freedom is 1, sliding), or fully constrained (degrees of freedom is 0, sticking). The two modified equations of motion for the j th node (j = 1,…, N) arewhereis the left hand side of the (2 j −1)-th equation of motion, M j is the mass associated with j th node, Δ z k +1 is the change in velocity we want to enforce along the constrained direction(s), and the modified mass matrix iswhere ndof is the number of free DOF at j th node andis the 2 × 2 identity matrix. Note that when a node is free, Δ z k +1 = 0, and Equation (4) reduces to Equation (2). If the node is fully constrained (S k +1 = 0), Equation (4) reduces toand the change in velocity (as well as the position) is enforced to take the value prescribed by Δ z k +1.

---

### Mesoscale atmosphere ocean coupling enhances the transfer of wind energy into the ocean [^8dc6b971]. Nature Communications (2016). Medium credibility.

Eddy identification

We employed two automated eddy detection methods: the first is based on the Okubo–Weiss parameter, where eddies are identified from sea-level height anomalies, and the second is a vector geometry based eddy detection method where eddies are identified based on their velocity sign reversal.

To create the eddy composites for the observed atmospheric and oceanic variable, we used the results from the Okubo–Weiss detection scheme and computed the fields by averaging across all detected eddies after scaling and rotating them. The observed wind speed data stem from collocated satellite data provided by SeaWinds on QuikSCAT. Ocean velocities were estimated from geostrophy for wind energy input composites.

Model-based atmospheric and oceanic variable composites were computed from 6-hourly model output fields using both Okubo–Weiss and vector-geometry eddy detection algorithms for comparison.

One-dimensional wavenumber spectra calculation

The power spectrum displayed in Fig. 1b, c were calculated as follows (here described for the wind stress; however, the same calculation is performed for the ocean with wind stress, τ, replaced by the ocean velocity, v.

The power spectrum is calculated for the region denoted by the red box in Fig. 2. From the autocorrelationwhere *denotes the complex conjugate and n, m are gridpoints such that n = 1,2,3…, N m = 1,2,3…, M with N = M in this case. F i is the Fourier transform of each component of the wind stress field denoted i = x, y.

The two-dimensional power spectrum is then calculated asfrom which the one-dimensional power spectrum is computed by binning and averaging all components N k with the same wavenumber

The one-dimensional power spectrum is calculated for each time step and then averaged over the total simulation time.

Coherency magnitude squared

The magnitude-squared coherence was computed as, whereis the cross spectral density, andandare the autospectrum of the wind stress and ocean surface velocity, respectively. Assuming a linear response between the wind and ocean velocities, estimates the power transfer, where, and a value of 1 indicates that the ocean velocity can be predicted entirely from the wind stress via a linear function.

---

### Deep-subwavelength control of acoustic waves in an ultra-compact metasurface lens [^9be7d753]. Nature Communications (2018). Medium credibility.

Near-field lens for patterned sub-diffraction focusing

At present, sub-diffraction focusing has received considerable interest because of its close relation to super-resolution imaging. As mentioned, the near-field evanescent waves should be incorporated and delivered to the target focus to create a sub-diffraction focus. Our scheme provided a conceptual advantage for sub-diffraction focusing, as the unit elements were deep-subwavelength sized and arranged. Moreover, the microscopic model can accurately reproduce the near fields because no assumptions such as far-field approximation were made in the derivation. We demonstrated a metasurface-based near-field lens for sub-diffraction focusing through the direct manipulation of evanescent waves.

To produce a desired pattern at the focal plane, that is, P (x, z = f), the first step is to find the field distribution on the exit surface of the near-field lens, that is, the aperture field, through back-propagationwhere k x andare the wave vectors along x and z directions, respectively. As a particular design, the focal length and pattern were defined as 0.1 λ and, where M 0 is an amplification factor and x 0 represents the lens center. Figure 4d shows the profiles of pressure amplitude at the aperture plane (z = 0) and at the focal plane for the case of M 0 = 2 and FWHM = λ /6. Then, we set the thickness, spacing, and slit number to 0.38 λ, 0.1 λ, and 11, respectively. Note that the thickness of the near-field metasurface lens was set beyond the deep-subwavelength scale. This is because, for the sub-diffraction focusing with a loose spot at a considerable depth, the contributions mainly came from the evanescent waves of low spatial frequencies, and a relative large thickness was employed to efficiently couple these evanescent waves from the input surface to the output side. In contrast to the optimization on the phase profile for far-field focusing, the near-field metasurface lens was optimized to yield the aperture field, which in turn produced the focusing pattern at the focal plane.

---

### In silico voltage-sensitive dye imaging reveals the emergent dynamics of cortical populations [^b30c5aa6]. Nature Communications (2021). High credibility.

To model the effects of scattering and absorption in the tissue, we used a Monte Carlo simulation-based approach (see Point Spread Function) to compute an effective PSF for increasing depths along an axis perpendicular to the cortical surface. We used the PSF at each depth to determine the standard deviation of a Gaussian kernel, which we convolved with the horizontal data slice at that depth:

(Eq. (2.2)) is a horizontal data slice at depth j, whereand. In Eq. (2.3), is the filtered data slice at depth j, is the original data slice, andis a Gaussian kernel, with depth-dependent standard deviation. The union of all filtered slices yields the filtered data volume(Eq. (2.4)). Post-convolution, each vertical (j -axis) column of voxels was accumulated into a single value, resulting in a two-dimensional matrix of pixels, which we stored as an image (Eq. (2.5)). VSDI signals were computed as a fractional change in fluorescence over resting intensity. This gives raw and normalized signal intensities for each pixel in an image matrix:

whereis a baseline fluorescence image obtained by averaging the first 100 frames (50 ms of data sampled at 2000 Hz). We used Eq. (2.6) to calculate voltage-sensitive dye signals in this work. The software for the pipeline (Eqs. (2.2) through (2.6)) described above is open source and freely available for download (see "Code Availability" statement).

---

### In situ single-shot diffractive fluence mapping for X-ray free-electron laser pulses [^07e76957]. Nature Communications (2018). Medium credibility.

Grating design

We consider an FEL diffraction experiment that detects scattered radiation as a function of momentum transfer q on a two-dimensional pixelated detector, as shown in Fig. 2. Note that this geometry also includes standard spectroscopy of the photon beam, where the beam at a selected momentum transfer (such as q = 0) is detected as a function of wavelength. In material and life sciences, thin membranes of Si 3 N 4, Si, or polymers are commonly used to administer samples to the FEL beam. We equip these membranes with a grating structure, that gives rise to an additional scattering signal at a selected detector position. The key idea of this work is to design the gratings such that each point on the sample surface diffracts the incoming light to a separate position on the detector while preserving the spatial relationship of the originating sample points. Figure 3 sketches the basic idea of our concept as a step-wise evolution from regular, to segmented, and finally to the spatially resolving gratings we discuss here.

Fig. 2
Experiment geometry and sample design. a An optical system focuses the incoming beam (red lines) onto the sample. Downstream, a 2D pixelated detector records the scattered radiation (red cone). b Enlarged view of the sample and the scattering geometry. The sample bears a suitably tailored, continuously varying grating with local periodicity p (ξ, η) and local orientation angle φ (ξ, η), where ξ and η are the coordinates in the sample plane. Incident light is diffracted away from the undeflected beam (q = 0) with a momentum transfer of ± q (p, φ) according to the local grating parameters. We design the grating such that it maps an enlarged image of the incident illumination, centered around ± (x 0, y 0) in the detector plane at distance z det.

---

### In situ fully vectorial tomography and pupil function retrieval of tightly focused fields [^1d924fee]. Nature Communications (2025). High credibility.

Application in field manipulation

Here we demonstrate that our method enables fully vectorial manipulation of the PSF vec in situ using a gradient-based algorithm (Supplementary Sections 6.1–6.2). In previous works, the amplitude and phase of the PSF vec can not be flexibly controlled –. In addition, the in situ manipulation remains missing. In contrast to these methods, we generate the desired PSF vec in situ given the experimentally retrieved VPF. For this demonstration, we optimize the VPF's phase with the constraints of previously retrieved amplitude and polarization in Fig. 2. We adopted radial polarization because it offers sufficient E z strength, which facilitates the 3D polarization manipulation.

We first generated an optical focus array with predefined 3D polarization states (Fig. 3 a–c), where the optimized PSF vec reaches 76% accuracy. Besides, the reconstructed VPF and PSF vec further verify the optimized counterparts in experimental realization. The dark areas in the VPF's amplitude are caused by phase singularities. Discrepancies in the reconstructed PSF vec are attributed to the amplitude and polarization constraints of the VPF during optimization since they vary with the phase in experiments when involving high-frequency features.

Fig. 3
Created complicated 3D polarization in situ.

a The reference VPF (left column), and the reconstructed one (right column). In the reference VPF, the middle row displays the phase optimized for the desired PSF vec. The top row illustrates the amplitude captured by the Stokes camera when the optimized phase is loaded onto a spatial light modulator (SLM). The bottom row shows the polarization constraint applied during phase optimization. b The optimized PSF vec (top row), and the reconstructed counterpart (bottom row). Only regions with significant intensity are shown in the phase visualization. The electric fields of the target four foci are, and E D = [0, 0, 1] ⊤, respectively, where ⊤ denotes matrix transpose. c The polarization and intensity of the target (left column), the optimized (middle column), and the reconstructed (right column) PSF vec. The gray and rainbow colormaps indicate the intensity and the 3D polarization ellipticity, respectively. The normal directions of 3D polarization ellipses are omitted, as E z may dominate. d – f are for continuous PSF vec. The electric field of the target continuous field is, where r and φ represent the position vector and the azimuthal angle on the focal plane, respectively.

---

### Twist, splay, and uniform domains in ferroelectric nematic liquid crystals [^e863ecd9]. Nature Communications (2025). High credibility.

Critical cell thickness for π -twists

We now consider an N F confined to a cell with certain imposed nematic orientation n 0 at the top and bottom of the cell, as in the samples shown in Fig. 1 with strong anchoring. There is a critical thickness h * for which we get twisted domains if h > h * and domains with uniform P orientation for h < h *. When h > h *, the sample thickness h will set the periodicity of the twist along the z direction (see Fig. 1 e–j).

We can calculate the critical thickness h * by considering a square domain with dimension L. We assume that P remains in the x y plane and that P runs alongon the top and bottom surfaces. We compare two polarization configurations: a uniformand a π -twisted, with all polarizations vanishing outside of the region − L /2 < x, y < L /2 and 0 < z < h. The Fourier transforms areSubstituting Eq. (14) into Eq. (2) and assuming that L κ ≫ 1 (strong screening or large sample size) yields the dipolar energyThe electrostatic energy cost of the polarization configuration gets a four-fold decrease from the π -twist along the z -axis.

The π -twisted configuration incurs an elastic energy penalty given by F n = K 2 L 2 π 2 /(2 h), which follows from substitutinginto the Frank free energy, Eq. (3). The balance between elastic and electrostatic energies yields a critical thicknessEven for large domains with L ≈ 1 cm, we find a small h * ≈ (0.2 − 2) μm, for a wide range of screening lengths λ D = κ −1 ≈ (0.01 − 1) μm. In the experiments, we find that essentially all domains are twisted for thicknesses h > 2 μm, consistent with this result. Confinement can induce chirality (twist) in solid state ferroelectrics, as well, especially in nanostructured materials, although intrinsically chiral solid ferroelectrics are also possible.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^89cdccc2]. Annals of the American Thoracic Society (2023). High credibility.

V_A/Q distribution modeling — derived from cumulative plots of ventilation or perfusion versus V_A/Q — is binned into 50 equally spaced log-scale compartments, with shunt and dead space handled separately. Specifically, V_A/Q ratios < 0.005 (shunt) and > 100 (dead space) are calculated as separate components, and relative dispersion and gravitational gradients may also be assessed.

---

### Topological superconducting vortex from trivial electronic bands [^e44deb81]. Nature Communications (2023). High credibility.

Fig. 1
Topological superconducting vortex in a Luttinger semimetal (LSM).

a shows the quadratic band touching around Γ point of a LSM. In (b), the superconducting (SC) pairing function Δ(x, y) is illustrated for the k z = 0 plane, where the vortex phase winding is denoted by in-plane arrows surrounding the vortex core. Four vortex zero modes are expected to occur for LSM at k z = 0 due to an emergent chiral winding number. The vortex-line low-energy spectra E qp /Δ 0 are illustrated in (c) for m 1 = m 2 = v z = 0 with four zero-energy flat bands labeled by angular momenta J z; and in (d) for m 1 = 0, m 2 > 0, v z = 0. Two pairs of vortex nodal bands show up in (e) for v z = 0, while only the ones formed by J z = ± 1 are symmetry protected. Turning on v z ≠ 0 will gap out the unprotected crossings within J z = 0 sector, as shown in (f), leading to a Kitaev vortex. The final vortex state of an LSM consists of a nodal vortex coexisting with a Kitaev vortex. e, f are numerically simulated in a disk geometry with band parameters.

The origin of topological vortex-line modes in LSMs can be understood in a perturbative manner, which is schematically depicted in Fig. 1. This is motivated by a key observation that the normal statewith

Here k ± = k x ± i k y. The unperturbed part h (0) describes two identical copies of 2D massless quadratic Dirac fermions, each of which carries a 2 π Berry phase and is similar to those live in bilayer grapheneand on the surfaces of topological crystalline insulators. While a 2D linear Dirac fermion carries a single vortex MZM, we naturally expect h (0) to support four vortex MZMs if going superconducting, with each quadratic Dirac fermion contributing a pair of MZMs in Fig. 1c.

---

### MRI-based axis-referenced morphometric model corresponding to lamellar organization for assessing hippocampal atrophy in dementia [^bb172475]. Human Brain Mapping (2024). Medium credibility.

A radial flow from the reparameterized IMS to the boundary surface of the hippocampus can provide a way to index any position within the hippocampus. We specify the target of the radial flow to be on the boundary surface, and then the radial mapping can be represented as a vector field. These vectors are called "spokes" in medial axis geometry. Letdenote the original surface boundary of the target hippocampus, andbe the reconstructed surface. Spokes on the IMS need to satisfy the following conditions: (1)should agree with; (2) spokes are vertical to the boundary surface; and (3) the lengths of superior spokes are equal to the corresponding inferior spokes. We initialize the spokes on the IMS by unit normal vectors on the IMS. Then, we use an iterative scheme to refine the initial spokes. First, to ensure the accuracy of the reconstructed shape, we need condition (1) to strictly hold. Second, we set a proper threshold to measure the non‐orthogonality of spokes to the boundary surface, that is, wheredenotes the angle between the spoke direction at vertexon the IMS and the normal vector of the boundary surface at the nearest vertex to the spoke tips. Third, because the spokes at bends of the hippocampal head often cross the boundary surface, pointing to wrong places, we solve the problem by enforcing condition (3), then gradually adjust these spokes directions to be approximately orthogonal to the boundary surface. Finally, we iterate above three steps and once more implement condition (1) to get the final refined spokes.

Suppose that the medial surfaceis parameterized by, and a spokeis placed at each location. Then, any points on the hippocampal surface can be uniquely indexed byin this coordinate system. Figure 2d shows the superior and inferior spokes attached on the IMS of the hippocampus.

---

### Switching of band inversion and topological surface States by charge density wave [^31fd6ae0]. Nature Communications (2020). High credibility.

We further perform the hν -dependent ARPES to confirm the two-dimensionality of the Dirac surface states and to clarify the k z -dependent bulk electronic structure that is relevant to the band inversion. Figure 4h –j displays the ARPES images of 1 T -V 0.90 Ti 0.10 Te 2 near thepoint (see the red arrow in Fig. 4g), recorded at 320 K with different photon energies, hν = 63, 69, and 78 eV, respectively corresponding to k z ~ 0, π/2 c, and π/ c. Circle markers with vertical (horizontal) error bars represent the peak positions of EDCs (MDCs) (see Supplementary Note 7). Figure 4k displays the schematic band dispersions overlaid with the experimental peak plots extracted from Fig. 4h–j. Here we find that the bulk bands A and B clearly show the finite k z -dispersions (respectively larger than 0.1 and 0.4 eV at). As can be seen in Fig. 4b, this k z -dispersion is essential for the band inversion at (a* /2, 0, k z), the origin of the topological surface state appearing around thepoint. On the other hand, the Dirac surface state, that is highlighted by the overlaid orange curves in Fig. 4k, is almost independent of hν, indicating the two-dimensional nature of the topological surface state.

---

### Dichotomy of heavy and light pairs of holes in the t-J model [^cd8b815a]. Nature Communications (2023). High credibility.

The t −XXZ model

We now consider a modification of the t − J model, where the SU(2) invariant spin interactions are replaced by in-plane and Ising-type spin interactions with coupling constants J ⊥ and J z :In the limit of J ⊥ ≪ J z, also called the t − J z model, the lack of spin dynamics facilitates our theoretical understanding. Experimentally, the anisotropic interactions can for example be realized by employing Rydberg interactions, or using ultracold molecules in tweezer arrays.

Remarkably, the two-hole spectral function, Fig. 2, exhibits a highly dispersive peak with a mass proportional to 1/ t, best identified at k y = π (bottom panel); I.e. we find a long-lived, tightly bound state of two holes, which can move as fast as the hole hopping t. This is in stark contrast to the case of a single hole in the same model, which has a very high effective mass ≫ 1/ t and thus an almost flat dispersion, since it can only move due to Trugman loops, which are higher-order processes.

Fig. 2
Two-hole rotational spectra in the t −XXZ model for t / J z = 3 and J ⊥ / J z = 0.1 on a 40 × 4 cylinder, based on time evolution up to T max / J z = 10 and bond dimension χ = 600.

The colormap corresponds to numerical matrix product state simulations of the singlet two-hole rotational spectrum, blue lines are geometric string theory predictions for the position of states (all shifted by −0.35 J z), and the black line is a cosine fit. The upper (lower) plot corresponds to k y = 0 (k y = π) at m 4 = 2, d -wave (m 4 = 0, s -wave), and data are shown as a function of momentum k x and frequency ω / J z. In the top panel, the overall ground state energy for two holes is marked by orange circles for k y = 0, and the green dashed line corresponds to twice the energy of a single hole (indicating a small pairing gap on the order of J z).

---

### Quantification of network structural dissimilarities [^3cf663e0]. Nature Communications (2017). Medium credibility.

Identifying and quantifying dissimilarities among graphs is a fundamental and challenging problem of practical importance in many fields of science. Current methods of network comparison are limited to extract only partial information or are computationally very demanding. Here we propose an efficient and precise measure for network comparison, which is based on quantifying differences among distance probability distributions extracted from the networks. Extensive experiments on synthetic and real-world networks show that this measure returns non-zero values only when the graphs are non-isomorphic. Most importantly, the measure proposed here can identify and quantify structural topological differences that have a practical impact on the information flow through the network, such as the presence or absence of critical links that connect or disconnect connected components.

---

### Switching of band inversion and topological surface States by charge density wave [^979e2a0f]. Nature Communications (2020). High credibility.

Bulk and surface band structures in 1 T normal phase

Here we introduce the topological aspect that can be relevant to the 1 T -1 T ″ CDW transition. In the normal 1 T phase, the band calculation suggests the band inversion involving V3 d and Te5 p orbitals at around the M and L points. The calculations of 1 T -V 0.87 Ti 0.13 Te 2 at several k z, plotted along the direction parallel to Γ-M (k ΓM, see Fig. 4a) are displayed in Fig. 4b. The colors of curves show the weight of atomic orbitals depicted by a false color-scale (see Supplementary Note 3 for detailed orbital components), whereas the black broken curves are the results without SOC. Focusing on the topmost two bands at M and L, labelled as A and B, we find that their orbital characters of mainly V3 d (blue-like, even parity) and Te5 p x + p y (red-like, odd parity) get inverted at a finite k z (~0.76 π/ c). In the corresponding (0 0 1) slab calculation (Fig. 4c), a new band dispersing around E − E F = −0.6 eV nearcan be recognized, that does not exist in the bulk calculations. It roughly follows the trajectory of the virtual crossing points of bulk bands A and B for no SOC. This is a surface state topologically protected by the band inversion at (a */2, 0, k z) occurring due to the moderate k z dispersions of V3 d and Te5 p bands. Indeed, in thedirection (Fig. 4d), this surface state shows a Dirac cone-like dispersion connecting bands A and B. Figure 4e shows the ARPES image of normal-state V 0.90 Ti 0.10 Te 2 along(350 K, hν = 21.2 eV). By carefully analyzing the EDC/MDC (see Supplementary Note 7), we can indeed quantify the bottom of bulk band A (E B ~ 0.30 eV), the top of bulk band B (~0.90 eV), and the crossing point of the surface Dirac cone (DP, ~0.66 eV). We note that this bulk band A forms the triangular Fermi surfaces centered atpoints in the k z = 0 plane, as shown in the Fermi surface image in Fig. 4f (V 0.87 Ti 0.13 Te 2, 300 K, hν = 83 eV).

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^59d10d7c]. Annals of the American Thoracic Society (2023). High credibility.

Ventilation–perfusion (V A /Q) distribution modeling is binned into 50 equally spaced (log scale) compartments, with V A /Q ratios < 0.005 (shunt) and > 100 (dead space) separately calculated, and relative dispersion and gravitational gradients may also be assessed.

---

### Machine learning assisted vector atomic magnetometry [^f370d5de]. Nature Communications (2023). High credibility.

The strategy we used for calibration is similar to that used in reference. We consider a coil system with imperfect orthogonality among the three sets of coils which yield magnetic fieldsalong X c, Y c, Z c axis respectively, as shown in Fig. S3. First, for each set of coil we obtain the relation between the field amplitude and the current through the NMOR spectra with only this coil in operation. Then, without losing generality, we can set small angles ξ, η, ζ (see Fig. S3) to describe the deviation of (X c, Y c, Z c) from a normal orthogonal coordinate system (X, Y, Z), and we have:The total magnetic field is, which can be written as:or:Here B, θ, φ are respectively the amplitude, altitude angle and azimuth angle of the total magnetic field we intend to measure.are the components of the residual magnetic field along X, Y, Z respectively. The total magnetic field's amplitude B as expressed by Eq. (5) can be measured from the NMOR spectra. By traversing the currents in the three coils and measuring the total field amplitude B for each set of, we can determine parametersusing Eq. (5) through non-linear least squares fitting. Then, to set a total magnetic field with parameters B, θ, φ as we intend, we can solve Eq. (4) to find what magnetic field should be generated in each coil, i.e.

---

### Two-edge-resolved three-dimensional non-line-of-sight imaging with an ordinary camera [^cb69ea4e]. Nature Communications (2024). High credibility.

The second step of the reconstruction approach aims to fit a new accurate range for each identified cluster, shown in Fig. 2 d, by operating on greyscale mappings of the RGB observations and radiosities estimated in the first step. Assumingclustersare computed, for each cluster j we form a greyscale radiosity vectorby setting to zero entries incorresponding to surface elements not present in cluster, with j = 1, 2,…, J. (See the Supplementary Note 4 (S4.1) for more details on this step.) With their angular extents fixed, the clusters collectively produce a contribution to the measured photograph that depends non-linearly on their respective unknown rangesand constituent surface elements (i.e.). The greyscale photograph y grey computed as the sum of the three colour channels is related to the unknown cluster scalar rangesand the estimated vector of radiositiesby:with matrix-vector form, where the weighting factors w j 's allow the radiosity of each cluster to vary correspondingly when estimating their unknown continuous-valued ranges arranged into the J -dimensional vector, andis a matrix whose (m, j)-entry models the contribution of cluster j to measurement pixel m. The vectors v, n, b and matrix B are defined as before. We estimate the ranges of all J clusters by solving the optimisation problem, using an accelerated projected gradient algorithm which is detailed in Supplementary Note 4 (S4.1). As confirmed by our FI analyses detailed in Supplementary Note 2, choosing to estimate a single range for each clusterleads to a better-conditioned inverse problem because J ≪ N θ N ψ, compared to the alternative approach that attempts to recover a range for every surface element. Using the estimated ranges, visualised in Fig. 2 e with the corresponding clusters, to construct the forward model, the final 3D full-colour reconstruction (depicted in Fig. 2 f) of the hidden scene is computed by solving the total variation regularised problem:for each of the three colour channels. The total variation seminorm denoted asis used here to encourage piecewise smooth solutions, whilecontrols the trade-off between data consistency and piecewise smoothness. One may bypass the total-variation-constrained reconstruction and directly combine the recovered ranges with the initial full-colour shape reconstructions (in Fig. 2 c) to obtain the fully 3D colour reconstruction of the hidden scene. This simplified variant of TERI which achieves impressive results at comparably lower computational complexity and three alternative reconstruction approaches are investigated in Supplementary Note 6. A narrated overview of the reconstruction procedure is provided in Supplementary Movie 1.

---

### Single photon emission computed tomography (SPECT) myocardial perfusion imaging guidelines: instrumentation, acquisition, processing, and interpretation [^097e8756]. Journal of Nuclear Cardiology (2018). Medium credibility.

Table 2 — typical performance parameters for low-energy (< 150 keV) parallel-hole collimators — reports resolution (full width at half maximum [FWHM]) at 10 cm, efficiency (%), and relative efficiency: Ultra-high resolution: 6.0 mm, 0.005, 0.3; High resolution: 7.8 mm, 0.010, 0.6; All/general purpose: 9.3 mm, 0.017, 1.0*; High sensitivity: 13.2 mm, 0.035, 2.1. A footnote specifies that a relative efficiency of 1 corresponds approximately to a collimator efficiency of 0.017%, and defines efficiency as the fraction of gamma rays and X-rays passing through the collimator per gamma ray and X-ray emitted by the source.

---

### Fermi surface tomography [^d54e3cd0]. Nature Communications (2022). High credibility.

Fermi surfaces are essential for predicting, characterizing and controlling the properties of crystalline metals and semiconductors. Angle-resolved photoemission spectroscopy (ARPES) is the only technique directly probing the Fermi surface by measuring the Fermi momenta (k F) from energy- and angular distribution of photoelectrons dislodged by monochromatic light. Existing apparatus is able to determine a number of k F -vectors simultaneously, but direct high-resolution 3D Fermi surface mapping remains problematic. As a result, no such datasets exist, strongly limiting our knowledge about the Fermi surfaces. Here we show that using a simpler instrumentation it is possible to perform 3D-mapping within a very short time interval and with very high resolution. We present the first detailed experimental 3D Fermi surface as well as other experimental results featuring advantages of our technique. In combination with various light sources our methodology and instrumentation offer new opportunities for high-resolution ARPES in the physical and life sciences.

---

### Manipulation and control of droplets on surfaces in a homogeneous electric field [^8213fddb]. Nature Communications (2022). High credibility.

Fig. 3
Origin and magnitude of electrostatic repulsion.

Schematic illustration of a presents electrostatic problem and b exemplary numerical solution. a Vertical cross section through the droplets (cyan) along the distance vector. A thin lubricant film (magenta) cloaks the droplets and forms a small wetting ridge. Between the lower electrode (blue) and upper electrode (red) a potential difference Δ ϕ > 0 is applied. The effective interfaces of the idealized droplets considered in the simulations are symbolized by dashed black lines. The corresponding apparent contact angle is denoted as. Red and blue shaded spheres symbolize positive and negative induced surface charges, respectively. The induced surface charges on either side of the idealized footprint, which are encircled by a green rectangle, just compensate each other from a macroscopic point of view. b Cross section (x z -plane cutting through the centers of the droplets) showing the numerically computed normalized electrostatic potential ϕ /Δ ϕ (colormap) and electric field lines. The applied voltage difference Δ ϕ is 4.5 kV, the droplets have volumes of V 1 = 9.5 μL (left) and V 2 = 20 μL (right). The lateral distance between their centers of mass d is 6 mm. The red arrows represent the Maxwell stress acting on the liquid surface. Their length and width scales linearly with the magnitude of the stress. In the upper left corner, a scale for the arrows is provided. The plot shows only a small fraction of the actual computational domain that extends further in lateral direction.

---

### Antibody binding reports spatial heterogeneities in cell membrane organization [^df8d4f4d]. Nature Communications (2023). High credibility.

Molecular dynamics simulations

To validate theoretical predictions for the surface crowding profile, we performed coarse-grained molecular dynamics simulations using a graphics processing unit (GPU)-enabled HOOMD-Blue simulation package. We simulated membrane-bound PEG-conjugated FITC sensors using the Kremer-Grest bead-spring modelfor polymers chains, with bead diameter σ = 0.33 nm to represent the ethylene glycol monomer. One polymer end was confined to the bottom of the simulation box using wall potentials but was allowed to diffuse laterally. We imposed periodic boundary conditions along x and y while the z = ± L z /2 boundaries were impenetrable. We used a system box size of V = L 2 L z where L z = 50 − 200 σ and L was adjusted to achieve the specified surface density and number of chains. All particle pair interactions and wall potentials are modeled using the Weeks-Chandler-Anderson potential. The bond potentials were modeled using the finite extensive nonlinear elastic (FENE) potential with spring constant k = k B T / σ 2. The semiflexibility of polymer chains was imposed through a harmonic angle potential U B = ϵ B (1 − c o s (θ i j k − θ 0)), where θ i j k is the bond angle between adjacent particles (i, j, k), θ 0 is the resting angle, and ϵ B = k B T L P / L B is the bending energy, defined with persistence length L P = 0.97 σ and bond length L B = σ. We first simulated the experimental surface density of ~1000 chains/μm 2 and averaged over ~2000 polymers to verify that chains were dilute and non-interacting. We then simulated single chains and varied the degrees of polymerization to span PEG0.5k to PEG10k. Using simulation snapshots, we binned the spatial distribution of the FITC sensor normal to the surface, P FITC. Single-chain dynamics were averaged over 15 simulations of 1000 snapshots each.

---

### Machine learning enables completely automatic tuning of a quantum device faster than human experts [^ec395356]. Nature Communications (2020). High credibility.

Results

Description of the algorithm

The algorithm starts with an initialization stage. This stage begins with setting V bias. The current is then measured at the two extremes of the gate voltage space, V j = 0 and V j = −2 V for j = 1. N, where N is the number of gate electrodes. For the most negative extreme, the measured current should be 0, but current offsets might change this value for different measurement setups. The difference between the currents at these two extremes is the full-scale current which is used to set the threshold that defines the hypersurface. The search range was chosen as the typical gate voltage range used when tuning similar devices from scratch.

The algorithm then begins an iterative process during which it alternates between the sampling and investigation stages. In each iteration, the sampling stage identifies a candidate location on the hypersurface in voltage space, attempting to select locations with a high probability of desirable transport features. The investigation stage then explores the nearby region of voltage space, attempting to identify whether current maps measured in this region show Coulomb peaks and honeycomb patterns. The presence of Coulomb peaks is reported back to the sampling stage as an evaluation result, which it uses in future iterations to inform its selection of new candidates. The steps that make up each iteration will now be described in detail.

---

### An integrated imaging sensor for aberration-corrected 3D photography [^34b60a14]. Nature (2022). Excellent credibility.

Motion correction

For highly dynamic samples moving during the scanning process of the meta-imaging sensor, motion artefacts arise after pixel realignment. In previous scanning light-field techniques, a time-weighted algorithm was developed to eliminate the motion artefacts at the cost of spatial resolution degradation. Here we propose an optical-flow-based algorithm for motion correction without reducing the spatiotemporal resolution by exploiting the spatiotemporal continuity in nature. The whole pipeline and pseudocode are shown in Fig. 4e and Extended Data Fig. 3d. We find that motion artefacts originate from incorrect pixel realignment of the pixels from different light-field images captured at different time points, because the actual spatial sampling positions of these microlenses are shifted with the sample movements. Fortunately, most of these shifts still fall in the wide FOV of the meta-imaging sensor, because objects usually move continuously in the scene. Otherwise, it is also hard for conventional imaging sensors to capture the dynamics owing to the motion blur. As long as we can estimate the sample motions accurately, we can still retrieve dense measurements from adjacent frames with accurate spatial sampling coordinates. Therefore, we conduct the motion correction algorithm on each view separately during pixel realignment based on the optical-flow maps. For the motions induced by samples, we use the same optical-flow map estimated from the central view (or the view with the highest sharpness for the conditions without a central view) for all the views. For motions induced by dynamic aberrations, the optical flow maps of different views should be estimated separately. Taking the scanning mode of 5 × 5 as an example, we apply a sliding window to synthesize the high-resolution image V h (x, y, u, v, t) at the time point t from adjacent low-resolution images V l (x, y, u, v, t + k − (T + 1)/2) (k = 1, 2, 3,…, T) (with a low spatial sampling density at the interval of the microlens diameter) across the scanning period T = 25 without reducing the temporal sampling density. To obtain the accurate coordinates of all the measurements at the time t, we apply a state-of-the-art optical flow algorithmto calculate the flow maps (∆ x, ∆ y) from all the low-resolution images V l (x, y, u, v, t + k − (T + 1)/2) to the low-resolution image V l (x, y, u, v, t) at the time point t. Then the corresponding sampling coordinates of the low-resolution measurements in the high-resolution mesh grid can be represented as:

---

### Metamaterials with index ellipsoids at arbitrary k-points [^01be2dad]. Nature Communications (2018). Medium credibility.

Forming closed equifrequency surfaces

The twisting of a single bundle in real space in the z -direction shifts the zero-frequency solution along k z and generates modes with linear dispersion along k z. However, we do not have a closed equifrequency surface, which requires a three-dimensional (3D) periodic structure. As such, we construct a 3D wire metamaterial by arranging helical wire – bundles in a two-dimensional (2D) hexagonal lattice with a lattice constant of a in the x – y plane as shown in Fig. 3a. The calculated band structure is shown in Fig. 3e. As expected, this bundle array supports quasistatic modes locating atfor m = ± 1, ± 2, ± 3. In the vicinity of, linear bands emerges along the Γ - A direction as shown in Fig. 3e. Their group velocities are plotted in Fig. 3g by black dotted lines, which are almost the same as that of a single bundle in Fig. 2c (colored lines in Fig. 3g). There is weak coupling between neighboring bundles since the eigenfields of the quasistatic modes localize strongly between the wires of the same bundle. The group velocities of m = ± 1 mode deviates from the single bundle case more than that of m = ± 2, ± 3, because the quasistatic mode with smaller m decays more slowly according to Eq. (3). Due to the weak coupling, the dispersion is nearly flat in the k x – k y plane for any value of k z. In other words, the band dispersions along the k z direction are almost independent of k x and k y (see Supplementary Note 4 and Supplementary Fig. 3). Similar flat equifrequency surfaces have been found in 2D wire arrays, which can be used for subwavelength imaging. Apart from the linear bands emerging at(m = ± 1, ± 2, ± 3), two linear bands emerge from the Γ point (the lowest two bands from k z = 0 to k z = 0.1 π / d), whose eigenfields resemble the plane-wave solutions with circular polarization (see Supplementary Fig. 4). As a chiral hyperbolic medium, its equifrequency surface consists of an ellipse and two flat sheets centered at the Γ point (see Fig. 3i for equifrequency surfaces at frequency 0.02 c / d). The other 10 flat sheets in Fig. 3i stem from the quasistatic modes at(m = ± 1, ± 2, ± 3).

---

### Energetic optimization of ion conduction rate by the K + selectivity filter [^100aa0c8]. Nature (2001). Excellent credibility.

The K+ selectivity filter catalyses the dehydration, transfer and rehydration of a K+ ion in about ten nanoseconds. This physical process is central to the production of electrical signals in biology. Here we show how nearly diffusion-limited rates are achieved, by analysing ion conduction and the corresponding crystallographic ion distribution in the selectivity filter of the KcsA K+ channel. Measurements with K+ and its slightly larger analogue, Rb+, lead us to conclude that the selectivity filter usually contains two K+ ions separated by one water molecule. The two ions move in a concerted fashion between two configurations, K+-water-K+-water (1,3 configuration) and water-K+-water-K+ (2,4 configuration), until a third ion enters, displacing the ion on the opposite side of the queue. For K+, the energy difference between the 1,3 and 2,4 configurations is close to zero, the condition of maximum conduction rate. The energetic balance between these configurations is a clear example of evolutionary optimization of protein function.

---

### Engineering phase and polarization singularity sheets [^352c3afb]. Nature Communications (2021). High credibility.

Engineered phase-singularity sheet

As a proof-of-concept for singularity sheet engineering, we design a 2D phase-singularity sheet with a heart-shaped cross-section (Fig. 3). The heart-shaped singularity is centered at z = 10 mm and is designed for the scalar field associated with the x -polarized electric field at λ 0 = 532 nm emitted from a 0.8 mm × 0.8 mm patterned aperture. The paraxial scalar field approximation (qualitatively supported by the propagation distance to the target plane being much larger than the aperture size) is justified by a full vectorial propagationof the electromagnetic fields, which shows that the time-averaged energy density associated with the y (transverse) and z (axial) polarization components over the volume of interest is much smaller (in this case, < 0.05%) than that of the x -polarization. The sheet singularity is constructed by maximizing the phase gradient in the directions oriented normally to a heart-shape at the target z = 10 mm plane. The free parameters are the propagation phase delay (from 0 to 2 π) at each pixel on the patterned aperture located at z = 0 mm. The optimized phase pattern is shown in Fig. 3b and does not exhibit any discernible long-scale pattern apart from a series of concentric rings, which appear to apply a focusing effect. Figure 3a shows a field intensity isosurface of the singularity profile to depict its orientation in 3D space (real and imaginary zero-isosurfaces are plotted in Supplementary Fig. 3), along with the locations and directions at which the phase gradient maximization was performed. This surface represents the points at which the phase gradient is very large, nearly reaching 100 times the wavenumber k 0. Simulated cross-sectional intensity and phase plots at the z = 10 mm plane are depicted in Fig. 3d, g, respectively. There is a visible phase jump of π radians across the singularity boundary as the field changes sign. The phase profile is in fact continuously differentiable with a well-defined phase gradient and just achieves a large gradient value at the singularity boundary. In Fig. 3c, we plot this phase gradient magnitude |∇ ⊥ ϕ | 2 = (∂ x ϕ) 2 + (∂ y ϕ) 2 profile alongside the intensity and phase profiles for the linear cut indicated in Fig. 3d. These profiles are qualitatively similar to those of a transverse cut through the singular optical axis of a fundamental LG 0,1 vortex beam of the same wavelength (with a beam waist diameter equal to the diagonal of the 0.8 mm × 0.8 mm square aperture), which are plotted using dotted lines in Fig. 3c. The transverse phase gradient over the transverse plane is plotted in Supplementary Fig. 4. This phase gradient achieves large magnitudes near the heart-shaped boundary and even exceeds k 0 by an order of magnitude, thereby exhibiting superoscillatory behavior. The longitudinal behavior of this cut profile with z is displayed in Supplementary Fig. 5, which shows that |∇ ⊥ ϕ | exceeds k 0 for a superoscillatory region ~150 μm in front of and behind the target z = 10 mm plane. The characteristic depth of this singularity sheet using this superoscillatory region is thus around 300 μm. The depth of a singularity sheet can be extended by maximizing the phase gradient over more than one transverse plane. We also exhibit additional phase-singularity sheet shapes (flat sheet and double-walled cylinders) in Supplementary Fig. 6 to demonstrate the versatility of this algorithm.

---

### Realizing repeated quantum error correction in a distance-three surface code [^fd3ee942]. Nature (2022). Excellent credibility.

Quantum computers hold the promise of solving computational problems that are intractable using conventional methods 1. For fault-tolerant operation, quantum computers must correct errors occurring owing to unavoidable decoherence and limited control accuracy 2. Here we demonstrate quantum error correction using the surface code, which is known for its exceptionally high tolerance to errors 3–6. Using 17 physical qubits in a superconducting circuit, we encode quantum information in a distance-three logical qubit, building on recent distance-two error-detection experiments 7–9. In an error-correction cycle taking only 1.1μs, we demonstrate the preservation of four cardinal states of the logical qubit. Repeatedly executing the cycle, we measure and decode both bit-flip and phase-flip error syndromes using a minimum-weight perfect-matching algorithm in an error-model-free approach and apply corrections in post-processing. We find a low logical error probability of 3% per cycle when rejecting experimental runs in which leakage is detected. The measured characteristics of our device agree well with a numerical model. Our demonstration of repeated, fast and high-performance quantum error-correction cycles, together with recent advances in ion traps 10, support our understanding that fault-tolerant quantum computation will be practically realizable.

---

### Reduced order modeling with shallow recurrent decoder networks [^2f1541f1]. Nature Communications (2025). High credibility.

Fig. 5
Fluidic pinball.

a Ground truth (first row), SHRED-ROM reconstructions (second row), and absolute errors (third row). The following test cases are considered: state reconstruction from 3 fixed sensors with μ = [−1.38, −4.56, −2.54] ⊤ at t = 1 s (first column) and t = 3 s (second column); state reconstruction from the coordinates of 1 mobile sensor with μ = [−1.42, 4.65, 2.68] ⊤ at t = 1 s (third column) and t = 3 s (fourth column). b SHRED-ROM mean relative errors on test data for different lag values, while considering different sensor placements. c SHRED-ROM mean relative errors on test data for different number of sensors, while considering different sensor placements. The sparse sensors exploited by SHRED-ROM are depicted with magenta dots.

Flow around an obstacle

The last test case is devoted to the reconstruction of fluid flows where both time-dependent, physical, and geometrical parametric dependencies are employed. Let us consider a 2D channel [0, 10] × [0, 2] with a circular obstacle centered in (1, 1) and with radius equal to 0.2. Through radial basis function interpolation, it is possible to deform the reference setting in order to obtain different obstacle shapes, without changing the number of degrees of freedom N h. In particular, we lengthen the circle to the left and right, so that the surface of the deformed obstacle passes through the points (1.0 − γ l, 1.0), (1.0, 1.2), (1.0 + γ r, 1.0), and (1.0, 0.8). Let us also consider an incompressible fluid flow around the obstacle, whose dynamics is described by the unsteady Navier–Stokes equationsin terms of the velocityand pressure, where Ω(γ l, γ r) stands for the spatial parametric domain and ν = 0.01. Starting from a zero velocity at time t = 0, the fluid enters the domain from the left boundary with angle of attack α in and intensity γ in, that iswhere the parabolic profile x 2 (2 − x 2) is useful to prevent discontinuities. Moreover, free-slip and no-slip boundary conditions are employed to, respectively, the walls and the obstacle.

---

### Dynamically induced cascading failures in power grids [^af922f15]. Nature Communications (2018). Medium credibility.

Cascade propagation

So far, we have shown that network cascades, i.e. secondary failures following an initial trigger, can well be caused by transient dynamical effects. We have proposed a model for power grids that takes this into account, and we have also developed a reliable method to predict whether additional lines can be affected by an initial damage, potentially triggering a cascade of failures. However, knowing whether a cascade develops or not does not answer another important question that is to understand how the cascade evolves throughout the network, and which nodes and links are affected and when. Intuitively, we expect that network components farther away from the initial failure should be affected later by the cascade. We have indeed observed that the time a line fails and its distance from the initial triggering link are correlated. Instead of merely using the graph topology to measure distances, we use a more sophisticated distance measure, the effective distance, based on the characteristic flow from one node to its neighbors. This idea has been first introduced in ref.in the context of disease spreading, where the effective distance has been shown to be capable of capturing spreading phenomena better than the standard graph distance. The effective distance between two vertices i and j can be defined in our case as:Here, we used the coupling matrix K ij as a measure of the flows between nodes. All pairs of nodes not sharing an edge, i.e. such that K ij = 0, have infinite effective distance d ij = ∞. At each node the cascade spreads to all neighbors but those that are coupled tightly, get affected the most and hence get assigned the smallest distance d ij. Furthermore, the effective distance is an asymmetric measure, since d ij ≠ d ji in general. The quantity d ij is a property of two nodes, while the most elementary damage in our cascade model affects edges. Hence, the concept of distance has to be extended from couples of nodes to couples of links. For instance, in the case of an unweighted network, it is possible to define the (standard) distance between two edges as the number of hops along a shortest path connecting the two edges. In the case of a weighted graph, we make use of the measure of effective distance in Eq. (12) to define a distance between two edges as the minimal path length of all weighted shortest paths between two edges. The distance between two edges can then be obtained based on the definition of distances between nodes { d ij }. Given the trigger edge (a, b), the distance from edge (a, b) to edge (i, j) is given by:i.e. it is the minimum length of the shortest paths, plus the effective distance between the two vertices a and b.

---

### Quantifying the contribution of dominance deviation effects to complex trait variation in biobank-scale data [^52c0b0a3]. American Journal of Human Genetics (2021). Medium credibility.

Method-of-moments for estimating variance components

To estimate the variance components, we use a method-of-moments (MoM) estimator that estimates parameter values so that the population moments are close to the sample moments. Since E[y] = 0, we derived the MoM estimates by equating the population covariance to the empirical covariance. The population covariance is given by:

Here is the additive (dominance) genetic relatedness matrix (GRM) computed from all SNPs of k th category. Using yy T as our estimate of the empirical covariance, we need to solve the following least-squares problem to find the variance components.

For simplicity, we denote K i = K A, i for i = 1,…, K, K K+j = K D, j for j = 1,…, L, and J = K + L. The MoM estimator satisfies the following normal equations:

Here, T is a J × J matrix with entries, b is a J -vector with entries b k = tr (K k) = N (because X k s and D k s are standardized), and c is a J -vector with entries c k = y T K k y. Each GRM K k can be computed in timeandmemory. Given J GRMs, the quantities T k, l, c k, can be computed in. Given the quantities T k, l, c k, the normal Equation 5 can be solved in. Therefore, the total time complexity for estimating the variance components is.

Randomized estimator of multiple variance components

The key bottleneck in solving the normal Equation 5 is the computation of T k, l, which takes. Instead of computing the exact value of T k, l, we use an unbiased estimator of the tracebased on the following identity: for a given N × N matrix C, z T Cz is an unbiased estimator of tr (C), where z is a random vector with mean zero and covariance I N. Hence, we can estimate the values, as follows:where E i matrix can be standardized additive X i or dominance D i matrix. Here z 1,…, z B are B independent random vectors with zero mean and covariance I N. We draw these random vectors independently from a standard normal distribution. Computing T k, l using the unbiased estimator involves four multiplications of sub-matrices of the genotype matrix with a vector, repeated B times. Therefore, the total running time for estimating the matrix T is.

---

### Arrays of individually controlled ions suitable for two-dimensional quantum simulations [^ee7134ad]. Nature Communications (2016). Medium credibility.

Results

Trap arrays and control potentials

Our surface ion trap chip is fabricated in similar manner to that described in ref.and consists of two equilateral triangular trap arrays with side length of ≃40 and ≃80 μm, respectively (Fig. 1a, b), both with a distance of ≃40 μm between the ions and the nearest electrode surface. The shapes of radio-frequency (RF) electrodes of the arrays are optimized by a linear-programming algorithm that yields electrode shapes with low fragmentation, and requires only a single RF-voltage source for operation. To design different and even non-periodic arrays for dedicated trap distances, we can apply the same algorithm to yield globally optimal electrode shapes. Resulting electrode shapes may look significantly different, but will have comparable complexity, spatial extent and the same number of control electrodes per trap site. Therefore, we expect that different arrays will not require different fabrication techniques (Methods). The two arrays are spaced by ≃5 mm on the chip, and only one of them is operated at a given time. Although we achieve similar results in both arrays, the following discussion is focussed on the 80 μm array.

Three-dimensional confinement of 25 Mg + ions is provided by a potential φ RF oscillating at Ω RF from a single RF electrode driven at Ω RF /(2 π) = 48.3 MHz with an approximate peak voltage U RF = 20 V. Setting the origin of the coordinate system at the centre of the array and in the surface plane of the chip, the RF potential features three distinct trap sites at T0 ≃(−46,0,37) μm,… Owing to the electrode symmetry under rotations of ± 2 π /3 around the z -axis, it is often sufficient to consider T0 only, as all our findings apply to T1 and T2 after an appropriate rotation. Further, the RF potential exhibits another trap site at ≃(0,0,81) μm (above the centre of the array); this 'ancillary' trap is used for loading as well as for re-capturing ions that escaped from the other trap sites. We approximate the RF confinement at position r by a pseudopotential, cp. ref. where Q denotes the charge and m the mass of the ion, and E RF (r) is the field amplitude produced by the electrode. Calculations of trapping potentials are based on ref.and utilizing the software package. Equipotential lines of φ ps are shown in Fig. 1c–e.

---

### Causal mediation analysis for time-varying heritable risk factors with mendelian randomization [^177f8c95]. Nature Communications (2025). High credibility.

Model on summary statistics

Denote γ k j ≡ argmin γ Var[X k − γ Z j] as the marginal association between continous trait X k and Z j, and letas the projection of the genetic and environmental direct effects of trait X k onto SNP Z j, which can be heuristically understood as the direct genetic effect of SNP j on X k. Then by projecting the structural Eq. (2) onto a single SNP Z j, we can obtain a linear model (1) with measurement error on the GWAS summary statistics (for mathematical details, see SI Text). These equations can be more conveniently expressed in matrix form as:where P is the number of SNPs and the matrices are defined asHere, the matrix Γ represents the marginal SNP-trait associations, A denotes the direct effects of the SNPs on each trait and B is the matrix of direct causal relationships of earlier traits on later traits that we would like to infer. Equation (3) can be alternatively represented aswhere I is the K × K identity matrix, andis the lower-triangular matrix that solvesCompared to (3), the parametrization in (4) avoids matrix inversion, making it more amenable for statistical estimation. It is easy to show thatcan be written as a Neumann series: Intuitively, the (k, l) entry of the matrixdenotes the total causal effects of X l on X k through all directed pathways.

Since the GWAS cohort size is typically large, for each SNP Z j, the summary statisticsapproximately follow a normal distribution, where Γ j: = (γ 1 j, γ 2 j,…, γ K j) is a vector of marginal associations and Σ j is a covariance matrix obtained from the GWAS standard errors and a correlation matrix that depends on the extent of sample overlap and the correlation between the traits. This correlation matrix is shared across the SNPs and can be estimated from the non-statistically significant GWAS summary statistics using the method described in ref.(SI Text).

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^075005b9]. Magnetic Resonance in Medicine (2021). Medium credibility.

Regions A and B are geometrically symmetric about the z = 0 plane, with minimum energy solutions (assuming no E‐field constraint) yielding z‐symmetric field solutions and zero B 0 concomitant fields. Hence, the open diamond starting point (representing the minimum energy solution with no E‐field constraints) for the solid and dashed curves (in both black and green cases) coincide. The symmetry is broken by the addition of a patient model with an E‐field constraint.

The knee in the curves marks the point where magnetic energy, current density, and winding complexity increase rapidly as E max is driven to lower values. These complexities render unrealizable or impractical any gradient designs on the vertical portions of the curves to the left of the knee. Examination of winding patterns indicates that solutions that exhibit energy increases > 25% (or even less depending on coil type) above the global minimum energy become unrealizable (eg, demonstrating two or more "eyes" per half coil [four or more total eyes for an x or y coil] in the fingerprint wire patterns).

The red and purple dotted curves in Figure 2 represent two practical cases in which the primary coil currents are restricted to a single inner surface near the patient and the shield coil currents to an outer cylinder, while at the same time adding torque and eddy current constraints. Line segments acd of Figure 1 represent a primary winding surface consisting of a cone and a cylinder, whereas line segment ab represents its cylindrical shield winding; this yields designs similar to those proposed by previous literature 8, 22 and results in the red dotted curves in Figure 2. A second case is defined by restricting primary currents to the cylinder represented by line segment cd and shield currents to the cylinder ab; this yields designs similar to those proposed by previous literature 28 and produces the purple dotted curves in Figure 2. For both configurations, the eddy current surface is a 1‐m‐long, 620‐mm‐diameter cylinder, centered about the gradient isocenter and placed outside the shield winding of the gradient coil. The time = 0 eddy current error is constrained to a peak deviation less than 0.1% of the ideal gradient field on the surface of a 20‐cm‐diameter volume, corresponding to 100 µT for a 1 T/m step change in gradient strength. The torque constraint is set to zero for a uniform z‐directed B 0 main magnetic field. There is no net force for a perfectly uniform main B 0 field in all calculations.

---

### Measurements of the size and correlations between ions using an electrolytic point contact [^ebb36881]. Nature Communications (2019). High credibility.

For each current trace, the data acquired within 15 s after a change in voltage was expunged to guarantee a steady-state reading of current with no capacitive influence. Two properties were then extracted from these traces; the mean open pore current I 0 and the amplitude, S 1/ f (1 Hz). To determine, the PSD was plotted as a function ofand a weighted fit of the 1/ f noise component of the trace was performed using a force fit slope of β = −1. The fit was preferentially weighted to low frequencies such that a hard cutoff on the higher frequency bound was unnecessary. Specifically, every two decades, the weight dropped an order of magnitude, so a PSD value at 100 Hz was 10 times less significant to the fit than the PSD recorded at 1 Hz and so on. Separately, the mean logarithmic PSD was determined in the intermediate range 1–5 KHz, where pink noise was not evident for the range of bias voltages used here. The parameter S 0 was defined as the mean PSD in this range. The intercept of these two lines was found and iterated to minimize the residuals to the piece-wise fit using custom MATLAB code and produce optimal S 1/ f (1 Hz) values.

---

### Helicity dependent photocurrent in electrically gated (BiSb) tethin films [^76abd65a]. Nature Communications (2017). Medium credibility.

We now address the physical origin of the HDPC. Up to second order in the laser electric field, the HDPC can be attributed to two principal mechanisms, namely the CPGE and the circular photon drag effect (CPDE). Macroscopically, the CPGE is described by the expressionand the CPDE is given by, where j, k, s = x, y, z and e, q and J denote the unit vector of the electric field, the momentum of the incident light and its intensity, respectively. The termidentifies the helicity of the light, which varies from −1 to +1 and is zero for linearly polarized light. The non-zero components of the tensors γ andare restricted by the crystal symmetry. For the bulk of (Bi 1− x Sb x) 2 Te 3, γ is zero because of inversion symmetry. However, for the surface of (Bi 1− x Sb x) 2 Te 3 with a reduced symmetry of C 3 v, a detailed symmetry analysis (Supplementary Note 1) suggests that the CPGE photocurrent along the y -axis is proportional to sin(2 φ) sin(θ), while that from CPDE is proportional to sin(2 φ) sin(2 θ). Therefore, even though both effects have the same φ dependence and contribute to the coefficient C in Eq. (1), they can be differentiated through their distinct dependences on the incident angle θ. Figure 1d shows a linear dependence of the coefficient C with respect to sin θ, thus confirming the CPGE as the physical mechanism of the HDPC and ruling out any observable contributions from CPDE.

---

### Seasonal and diurnal variations of kelvin-helmholtz instability at terrestrial magnetopause [^90e7672b]. Nature Communications (2023). High credibility.

B and ρ stand for magnetic field and mass density, respectively. V is the bulk velocity. The indices I and M are for the Interplanetary (Magnetosheath values) and Magnetosphere sides, respectively. The instability is driven by velocity shear aligned with the k vector, while the magnetic field component aligned with the k vector acts to stabilize the instability across the Magnetopause (MP) boundary. The stabilizing terms due to magnetic tension are the interplanetary term (k ⋅ B I), and the magnetospheric term (k ⋅ B M). The first term states the role of IMF as processed by the bow shock, thus resulting in the magnetosheath magnetic tension on the KHI. The second term expresses the role of Earth's magnetic dipole field, the magnetosphere magnetic tension, on KHI. The contribution of these magnetic tension terms is minimized when the orientation of the magnetospheric field is perpendicular to the shear flow direction and when the interplanetary field and magnetospheric field become more aligned.

Earth's magnetic dipole axis is tilted toward or away from the Sun with a dipole tilt angle φ, the angle between the dipole axis and the Geocentric Solar Magnetospheric (GSM) Z-axis. The value of φ modulates the maximum and minimum of the magnetic tension term due to the magnetospheric field (k ⋅ B M). When the angle φ is 0°, the dipole is along the GSM Z-axis and perpendicular to the velocity shear (in the GSM X-Y plane), i.e. the magnetosphere magnetic tension is zero, and dipole field lines cannot exert a stabilizing influence on the KHI growth rate. These dipole orientations occur at the equinoxes on March 21 and September 21 at 10:30 and 22:30 UT, respectively. Figure 1a shows the most stable situation near the summer solstice at 16:30 UT when the dipole tilt φ is maximum (+35 °). The parallel component of a magnetic dipole in the X-Z GSM plane is B M (φ) as illustrated in Fig. 1a.

---

### Step-by-step state-selective tracking of fragmentation dynamics of water dications by momentum imaging [^9ec320e6]. Nature Communications (2022). High credibility.

The double photoionization of a molecule by one photon ejects two electrons and typically creates an unstable dication. Observing the subsequent fragmentation products in coincidence can reveal a surprisingly detailed picture of the dynamics. Determining the time evolution and quantum mechanical states involved leads to deeper understanding of molecular dynamics. Here in a combined experimental and theoretical study, we unambiguously separate the sequential breakup via D + +OD + intermediates, from other processes leading to the same D + +D + +O final products of double ionization of water by a single photon. Moreover, we experimentally identify, separate, and follow step by step, two pathways involving the b 1 Σ + and a 1 Δ electronic states of the intermediate OD + ion. Our classical trajectory calculations on the relevant potential energy surfaces reproduce well the measured data and, combined with the experiment, enable the determination of the internal energy and angular momentum distribution of the OD + intermediate.

---

### Electron stochastic acceleration in laboratory-produced kinetic turbulent plasmas [^9db73297]. Nature Communications (2024). High credibility.

Fig. 3
Simulation revealing the Weibel instability features.

The plasma flows are injected into the simulation area from the left and right ends of the simulation box, and the number density and velocity of injection plasma are obtained via a radiation hydrodynamics simulation. Three distinct moments of interest are selected, 1.0 ns, 3.0 ns, and 6.0 ns, which correspond to linear and nonlinear stages of the evolution of WI, respectively. Panels (a – c) display the spatial distribution of the number density (n e), x -directional current density (J x), and z-directional magnetic field (B z) at 1.0 ns. Correspondingly, panels (d – f) portray the corresponding data at 3.0 ns, and panels (g – h) are the corresponding data at 6.0 ns. The iso-contours in panel (f) and panel (i) represent the magnetic vector potential at 3.0 ns and 6.0 ns, and the black, red, and gold lines denote the iso-contours of the magnetic vector potential, indicating values of 2 × 10 10, 3 × 10 10, 4 × 10 10 Gs cm −1 respectively. Panel (j) plots the magnetic field energy spectra ε B (k, t) = B (k) 2 obtained by a fast Fourier transform at different times, and the red and blue circles represent the energy spectrum extracted from the reconstructed path-integrated magnetic field in experiments. Panel (k) shows the peak wave number k peak evolving with time.

---

### Using grid cells for navigation [^30eebe08]. Neuron (2015). Low credibility.

The Vector Navigation Problem

The 1D vector navigation problem can be stated thus: given the grid cell representations of two locations a and b, calculate the displacement between those locations d = b − a (Figure 3 A). More specifically, the grid cell representations of locations a and b correspond to the spatial phases of activity bumps in each grid module { p i (a) | i = 1 to M } = { p 1 (a), p 2 (a),…, p M (a)} and { p i (b) | i = 1 to M } = { p 1 (b), p 2 (b),…, p M (b)}. As an example, consider three grid cell modules with scales s 1 = 50 cm, s 2 = 30 cm and s 3 = 20 cm. If the distance between the current location a and goal location b is d = 75 cm, and (for the sake of simplicity, but without loss of generalization) the phase of each module is 0 at the current location a — i.e. p 1 (a) = 0, p 2 (a) = 0 and p 3 (a) = 0 — then at b the phase of each module will be proportional to the distance d modulo grid scale s i:

The 1D vector navigation problem is to recover the displacement d from these values of { p i (b)} (Figure 3 A).

Similarly, the 2D vector navigation problem can be stated thus: given the grid cell representations of two locationsand, calculate the displacement vector between those locations. More specifically, the grid cell representations of locations a and b correspond to the sets of spatial phasesandthat define positionin module i along principal axes x and y (which, in this case, are separated by 60°; see Figures 2 B and 2C). Again, consider three grid cell modules with scales s 1 = 50 cm, s 2 = 30 cm and s 3 = 20 cm. If the displacement vector between the current locationand goal locationis, and the phase of each module on each axis is 0 at the current location, then atthe phases of the modules will be:

The 2D vector navigation problem is to recover the displacement vectorfromand(Figure 3 B). Note that this corresponds to a simple generalization of the 1D vector navigation problem to multiple axes.

---

### Morphology-independent general-purpose optical surface tractor beam [^671751fc]. Nature Communications (2024). High credibility.

Fig. 1
Geometric sketches.

a Schematic illustration of the optical pulling system. The incident surface wave (SW) (white arrow) is scattered by the particle positioned immediately above the metamaterial and converted into scattered SWs (yellow arrows), freely propagating waves (FPWs) in the air (blue arrows) and within the metamaterial (purple arrows). The SWs are confined on the interface (xoy plane), whereas the FPWs can radiate in all directions. b Schematic of the cross section of the system on the x‒z plane. Arbitrary surfaces S 1 and S 4 are illustrated, along with planar surfaces S 2 and S 3, which are positioned infinitesimally above and below the interface, respectively. The intersection curves between these surfaces and the x‒z plane are drawn as dashed lines.

General theory of optical force for particles of arbitrary morphology

For an arbitrary particle, the optical force can be rigorously calculated using the formula, whereis the Maxwell stress tensor, S is any surface in the air that encloses the particle, andis the unit outward normal vector on S. Here, we consider S as the combination of S 1 and S 2, where S 2 is a planar surface immediately above the metamaterial substrate, and S 1 is a cap that encompasses the particle when combined with S 1, as shown in Fig. 1b. Given that the outward normal vector of S 2 points in the negative- z direction, the longitudinal optical force can be alternatively expressed as follows:

Given that, in air, the Maxwell stress tensor is the same as the Minkowski stress tensor, we can substitutewithin Eq. (2), and the last term of Eq. (2) can be rewritten as, where. Becauseare continuous across the interface, is also continuous, yielding the following equation:where S 3 is immediately below the interface and mirrors S2 symmetrically; see Fig. 1b. In the case of a lossless homogeneous metamaterial, the integration ofover any closed surface within the metamaterial is zero, for example, the closed surface formed by S 3 + S 4, as shown in Fig. 1b. As a part of the closed surface S 3 + S 4, the outward normal of S 3 points in the positive- z direction. Therefore

---

### Lorentz-violating type-II dirac fermions in transition metal dichalcogenide PtTe [^e6ef7390]. Nature Communications (2017). Medium credibility.

Fig. 2
The electronic structure of PtTe 2. a, b Band dispersions along the Γ-M (a) and Γ-K (b) direction at photon energy of 22 eV. Red and gray arrow indicate the bulk Dirac cone and the surface state Dirac cone respectively. c, d Calculated band dispersion along the Γ-M (c) and Γ-K (d) directions using Wannier function. e Measured Fermi surface map at photon energy of 21.2 eV. Black dashed line indicates surface Brillouin zone. f Calculated Fermi surface map. g, h Three-dimensional E– k x – k y plots of the bulk Dirac cone around the Γ point g and the surface state Dirac cone h

To reveal the bulk versus surface properties of these Dirac cones, we show in Fig. 3 ARPES data measured along the Γ-K and Γ-M directions using different photon energies. The corresponding k z values are calculated using an inner potential of 13 eV, which is determined by comparing the experimental data with theoretical calculations. Figure 3a–e shows the measured dispersions. The calculated bulk band dispersions at each k z value are overplotted on the curvature image in Figs. 3f–j. A good agreement is obtained for the bulk Dirac cone at the Γ point and its evolution with k z. The Dirac point discussed above is at k z = 0.35 c * (c ✱ = 2 π / c), which is labeled as D in Fig. 1e. Away from this special point along the Γ-A direction, the valence and conduction bands begin to separate, and the separation becomes larger when k z moves further away from 0.35 c *. The strong k z dependence confirms its three-dimensional nature. We note that at k z = 0.30 c *, some signatures of the dispersion at k z = 0.35 c * are also observed (pointed by gray arrow), suggesting that there is significant k z broadening due to a finite escape depth of photoelectrons. In addition to the bulk bands discussed above, there are surface states between −0.5 to −1 eV at the BZ center (highlighted by yellow dashed line in Figs. 3f–j) and at deeper energy (gray dashed line) that do not change with photon energy.

---

### Quantum error correction below the surface code threshold [^75556dae]. Nature (2025). Excellent credibility.

When we examine the detection patterns for these high-distance logical failures, we observe two different failure modes (Supplementary Information). The first failure mode manifests as one or two detectors suddenly increasing in the detection probability by more than a factor of 3, settling to their initial detection probability tens or hundreds of cycles later (Supplementary Information). These less-damaging failures could be caused by transient TLSs appearing near the operation frequencies of a qubit, or by coupler excitations, but might be mitigated using methods similar to refs. The second and more catastrophic failure mode manifests as many detectors simultaneously experiencing a larger spike in the detection probability; an example is shown in Fig. 3b. Notably, these anisotropic error bursts are spatially localized to neighbourhoods of roughly 30 qubits (Fig. 3b, inset). Over the course of our 2 × 10 10 cycles of error correction, our processor experienced six of these large error bursts, which are responsible for the highest-distance failures. These bursts, such as the event shown in Fig. 3b, are different from previously observed high-energy impact events. They occur approximately once an hour, rather than once every few seconds, and they decay with an exponential time constant of around 400 μs, rather than tens of milliseconds. We do not yet understand the cause of these events, but mitigating them remains vital to building a fault-tolerant quantum computer. These results reaffirm that long repetition codes are a crucial tool for discovering new error mechanisms in quantum processors at the logical noise floor. However, surface codes are larger and sensitive to more errors than repetition codes; therefore, these events may affect the surface code performance differently.

Furthermore, although we have tested the scaling law in equation (1) at low distances, repetition codes enable us to scan to higher distances and lower logical errors. Using a similar coherent error injection method as that in the surface code, we show the scaling of logical error versus physical error and code distance in Fig. 3c, d, observing good agreement with O (p (d +1)/2) error suppression. For example, reducing the detection probability by a factor of 2 manifests in reduction by a factor of 250 in logical error at distance 15, consistent with the expected O (p 8) scaling. This shows the considerable error suppression that should eventually enable large-scale fault-tolerant quantum computers, provided we can reach similar error suppression factors in surface codes.

---

### Roflumilast (Zoryve) [^e2de6cd7]. FDA (2024). Medium credibility.

The dosage of roflumilast TOP for treatment of plaque psoriasis in adults is 1 application(s) TOP daily (0.3% cream or foam)

---

### Validation of V-SS-PARSE for single-shot flow measurement [^f1569ac0]. Magnetic Resonance Imaging (2007). Low credibility.

As a variant of Single-Shot Parameter Assessment by Retrieval from Signal Encoding, Velocity Single-Shot Parameter Assessment by Retrieval from Signal Encoding, a single-shot imaging method, has been developed to realize fast and straightforward flow quantification by solving inverse problems. A robust signal model, including its local magnetization and its phase evolution during signaling (resulting in a more precise representation of the sampled signal) is described here. Magnitude, velocity, relaxation rate and frequency information can be retrieved without any extra reference image acquisitions, as demonstrated by phantom studies. In the presence of stationary background, retrieved magnitude maps and velocity maps show results comparable to those obtained by phase-contrast methods (r > .99, P = 0.005), even with brief single-shot 70-ms acquisition.

---

### Optimal design of k-space trajectories using a multi-objective genetic algorithm [^9fca0db2]. Magnetic Resonance in Medicine (2004). Low credibility.

Spiral, radial, and other nonrectilinear k-space trajectories are an area of active research in MRI due largely to their typically rapid acquisition times and benign artifact patterns. Trajectory design has commonly proceeded from a description of a simple shape to an investigation of its properties, because there is no general theory for the derivation of new trajectories with specific properties. Here such a generalized methodology is described. Specifically, a multi-objective genetic algorithm (GA) is used to design trajectories with beneficial flow and off-resonance properties. The algorithm converges to a well-defined optimal set with standard spiral trajectories on the rapid but low-quality end, and a new class of trajectories on the slower but high-quality end. The new trajectories all begin with nonzero gradient amplitude at the k-space origin, and curve gently outward relative to standard spirals. Improvements predicted in simulated imaging experiments were found to correlate well with improvements in actual experimental measures of image quality. The impact of deviations from the desired k-space trajectory is described, as is the impact of using different phantoms.

---

### Transition path times of coupled folding and binding reveal the formation of an encounter complex [^3f0e736b]. Nature Communications (2018). Medium credibility.

Brownian dynamics simulations of transition paths

To validate our method of finding the transition path time distribution, we performed Brownian dynamics simulations to generate transition paths for different barrier shapes. We then simulated fluorescence time traces based on these transition paths and analyzed them as described in Transition path time distribution analysis to test whether we could correctly identify the barrier shape on which the simulations were based. We used three different representative potentials for the Brownian dynamics simulations (see Supplementary Fig. 4A):

Barrier with transition state:

Flat barrier top:

Barrier with intermediate:

We adjusted the effective diffusion coefficient, D, for each potential so that 〈 t TP 〉 between r 0 = 0.8 and r 1 = 1.2 (dashed lines in Supplementary Fig. 4A, B) was ~80 µs. We then simulated transitions with time steps of 0.1 µs (see Supplementary Fig. 4B) and converted distances into transfer efficiencies using the Förster equation:with the Förster radius R 0 = 1. The transfer efficiency time traces were then discretized into 20 states in steps of Δ E = 0.05. To ensure that the photon statistics are equivalent to those of the experimental data (dataset at 1.28 cP), we used the measured photon count rates to calculate the donor and acceptor photon count rates of each state, and simulated photon time traces based on the simulated state trajectories and the determined photon count rates as described in Transition path time distribution analysis. These photon time traces were then analyzed in the same way as the measured data. Both the χ 2 -distance and the k -sample Anderson−Darling test correctly identify the original barrier shapes (Supplementary Fig. 4C).

---

### A space-time tradeoff for implementing a function with master equation dynamics [^57fa10b0]. Nature Communications (2019). High credibility.

Master equations are commonly used to model the dynamics of physical systems, including systems that implement single-valued functions like a computer's update step. However, many such functions cannot be implemented by any master equation, even approximately, which raises the question of how they can occur in the real world. Here we show how any function over some "visible" states can be implemented with master equation dynamics-if the dynamics exploits additional, "hidden" states at intermediate times. We also show that any master equation implementing a function can be decomposed into a sequence of "hidden" timesteps, demarcated by changes in what state-to-state transitions have nonzero probability. In many real-world situations there is a cost both for more hidden states and for more hidden timesteps. Accordingly, we derive a "space-time" tradeoff between the number of hidden states and the number of hidden timesteps needed to implement any given function.

---

### A 3D hybrid-shot spiral sequence for hyperpolarizedimaging [^242fa3e6]. Magnetic Resonance in Medicine (2021). Medium credibility.

2 Theory

Numerous strategies for designing spiral trajectories exist in the literature. Given upper limits for gradient amplitude and slew rate, analytical formulae can be derived to design constant densityand variable densityspiral trajectories. A hybrid-density trajectory has been proposed for functional MRI with a single-shot inner region up to a fraction of the maximum design k-space radius beyond which the sampling density decreases. In this work, the target HSS trajectory (shown in Figure 1) consists of two connected regions of constant sampling density with a transition that is smooth but relatively abrupt as opposed to a gradual change in sampling density common with VDS designs using the aforementioned algorithms.

Iterative algorithms compute each point of the trajectory by solving a coupled set of differential equations with the previous point as the initial condition. A widely used example of an iterative VDS design algorithm represents the sampling density as an effective FOV, which is a function of k-space radius. In this algorithm, the spiral trajectory is defined aswhere k = k x + ik y, θ is the polar angle and a is the rate of increase of k-space radius (k r = | k) with respect to θ, which is defined by

If FOV is allowed to vary as a function of k-space radius, a variable density spiral can be constructed. Differentiating Equation (1) gives an equation for the gradient vector (G)which can be further differentiated to give an equation for the slew rate (S)

By taking the magnitude of Equation (3) and setting | G | = G max, the gradient limited value ofcan be found

Similarly, solving Equation (4) in the same way, gives an expression for the slew rate limited (| S | = S max) value ofwhere A, B, and C are the quadratic coefficients used to solve the equation

This gives the following equation for, subject to the dual constraints of G max and S max where Δ t is the scanner dwell time.can then be found with the expression

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^c3299e03]. Annals of the American Thoracic Society (2023). High credibility.

Proton MRI V_A/Q quantification pathway — formula and processing — shows that V_A is computed as V_A = f_resp * SV * (1-Density); quantified density images are used as a measure of regional gas content and are combined with SV images to provide an estimate of regional V_A, after which the smoothed ventilation image is divided by the quantified and smoothed Q image to give a map of regional V_A/Q ratio, with voxels consistent with large conduit vessels masked because they do not represent local Q; the caption defines f_resp as respiratory frequency.

---

### Bloch surface waves confined in one dimension with a single polymeric nanofibre [^53b7d781]. Nature Communications (2017). Medium credibility.

The schematic diagrams in Fig. 4i, j illustrates the formation of the thin ring and horizontal lines, and also present the correlations between the FFP and BFP images. For the nanofibre on Multilayer-240, the BFP image (Fig. 4b) displays a bright ring; therefore, we know that there are surface waves propagating on the multilayer, as illustrated in Fig. 4i (top plane). These surface waves are not as clearly visible in the FFP image (Fig. 4a), because their intensity is masked by the fluorescence from the fibre itself. The surface waves (BSW-2D) show leakage radiation into the glass substrate and form the thin ring (Fig. 4b). In contrast, the schematic in Fig. 4j shows that coupled emission from the BSW-1D structure results in straight line perpendicular to the wire. There is no bright thin ring in Fig. 4f–h, which indicates that the Multilayer-165 sample cannot sustain a BSW-2D mode at a wavelength of 632.8 nm. The horizontal lines with constant K z / K 0 signify that the wave vector (Z -component, K z) of the propagating wave in the nanofibre is constant. There are two horizontal lines on a BFP image, which means that the waves propagate in both the + Z and − Z direction. The horizontal line fills the detection window along the K x axis, which means that the K x / K 0 (X -component of the wave vector) value has a wide range. The mechanism behind this phenomenon can be explained as follows: as we know, the BFP image is a Fourier transform of the FFP image. The formation of the horizontal line is merely a property of the Fourier transform of optical waves confined by a 1D structure. For example, the Fourier transform of a Dirac pulse (infinitely small range of x) is a constant (meaning infinitely large range of the reciprocal parameter, K x). Similarly, a laterally confined optical field (that is, finite, small range of x) would give rise to a large spread of wave vector values. The smaller the spatial range of x, the greater the range of K x. In our experiment, we see the optical field confined by the nanofibre whose lateral dimension (along the X axis, Fig. 4e) is very small (radius R = 125 nm, small range of x); therefore, its Fourier transform gives rise to a large spread of K x (X -component wave vector).

---

### Fluorescein sodium (C20H10Na2O5 fluorescein sodium ophthalmic strips) [^58dfc8a7]. FDA (2025). Medium credibility.

HOW SUPPLIED:

Dispenser carton containing 50, 100, or 300 strips.

---

### Bimekizumab (Bimzelx) [^bfdeb329]. FDA (2025). Medium credibility.

Step 9: Gently pinch and hold a fold of skin where you cleaned the injection site with one hand. With the other hand, insert the needle into your skin at about a 45-degree angle.

Push the needle all the way in to make sure that you inject your full dose. Then gently let go of your skin. Make sure the needle is in place (see Figure F).

Step 10: Firmly push the plunger head all the way down until all the medicine is injected. (see Figure G).

All the medicine is injected when you cannot push the plunger head any further (see Figure H).

Step 11: Lift your thumb off the plunger head (see Figure I). The needle will automatically move back in and lock in place.

Press a clean cotton ball or gauze pad over the injection site for a few seconds. Do not rub the injection site. You may see slight bleeding or a drop of liquid. This is normal. You may cover the injection site with a small adhesive bandage, if needed.

Step 12: Dispose of (throw away) the used BIMZELX prefilled syringe (see Figure J).

Put the used BIMZELX prefilled syringe in an FDA-cleared sharps disposal container right away after use. Do not throw away (dispose of) the BIMZELX prefilled syringe in your household trash. If you do not have an FDA-cleared sharps disposal container, you may use a household container that is:
made of a heavy-duty plastic,
can be closed with a tight-fitting, puncture-resistant lid, without sharps being able to come out,
upright and stable during use,
leak-resistant, and
properly labeled to warn of hazardous waste inside the container.
When your sharps disposal container is almost full, you will need to follow your community guidelines for the right way to dispose of your sharps disposal container. There may be state or local laws about how you should throw away needles and syringes. For more information about safe sharps disposal, and for specific information about sharps disposal in the state you live in, go to the FDA's website at: http://www.fda.gov/safesharpsdisposal.
Do not recycle your used sharps disposal container.

---

### Evidence for dynamic kagome ice [^6bf5429e]. Nature Communications (2018). Medium credibility.

Evidence for a dynamic kagome ice mode

In zero field, as previously mentioned, a dynamic spin ice mode is observedat an energy of about 70 μeV. In the scattering plane perpendicular to [111], this mode is characterized by the star-like pattern shown in Fig. 3a, with a strong intensity around q = 0. On increasing the field, one could expect this feature to disappear at H c. However, the star-like pattern persists up to 0.25 T, where it changes into a pattern with a new structure, at about the same energy, as shown in Fig. 3b: six arms appear, while the scattering intensity decreases around q = 0 and the (2, −2, 0) q -vectors. Upon increasing the field, the intensity of the arms decreases, but clearly persists up to at least 1 T (see Fig. 3c).

Fig. 3
Dynamic kagome ice state seen in inelastic neutron scattering for H || [111]. Inelastic intensity averaged around E = (50 ± 5) μeV (corresponding to the energy shown by the red arrow in Fig. 4). a Zero-field measurements at 60 mK and Random Field Approximation (RPA) calculations for the pseudo-spin 1/2 model described in the text with J x = −0.36 K, J y = 0.066 K, J z = 0.86 K, and J xz = 0.44 K at T = 0. b Measurements in 0.25 T at 60 mK and calculations with the same parameters. The crossed circles mark the position of the expected pinch points, which appear blurred in the measurements. c Measurements at 0.5 and 1 T. The black full and dashed lines indicate the directions of the slices along (−1− h, 1− h, 2 h) and (−2, h, 2− h) shown in Fig. 4

---

### Reconstruction of stochastic temporal networks through diffusive arrival times [^3c835452]. Nature Communications (2017). Medium credibility.

Temporal networks have opened a new dimension in defining and quantification of complex interacting systems. Our ability to identify and reproduce time-resolved interaction patterns is, however, limited by the restricted access to empirical individual-level data. Here we propose an inverse modelling method based on first-arrival observations of the diffusion process taking place on temporal networks. We describe an efficient coordinate-ascent implementation for inferring stochastic temporal networks that builds in particular but not exclusively on the null model assumption of mutually independent interaction sequences at the dyadic level. The results of benchmark tests applied on both synthesized and empirical network data sets confirm the validity of our algorithm, showing the feasibility of statistically accurate inference of temporal networks only from moderate-sized samples of diffusion cascades. Our approach provides an effective and flexible scheme for the temporally augmented inverse problems of network reconstruction and has potential in a broad variety of applications.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^6e468ce5]. Annals of the American Thoracic Society (2023). High credibility.

General principles of biophysical computational models — biophysical computational models can be used for forward simulations of function or inverse identification of system structure and parameters. Forward models are described as useful for sensitivity analyses to evaluate the contribution of normal subject variability to imaging metrics to define a threshold for abnormal and can also predict emergent behavior after parameter changes at the cellular or tissue level. Inverse models are described as useful for deriving information that cannot be measured directly, including distributions of airway or vascular obstruction that produce specific V˙A/Q˙ patterns. Both forward and inverse models can be used to analyze, interpret, and predict.

---

### Roflumilast (Zoryve) [^11a5acd0]. FDA (2024). Medium credibility.

The dosage of roflumilast TOP for treatment of plaque psoriasis in both children (in patients 6–12 years) is 1 application(s) TOP daily (0.3% cream)

---

### Rotating curved spacetime signatures from a giant quantum vortex [^a8d978a0]. Nature (2024). Excellent credibility.

These spatial patterns (or modes) can be retrieved from the height-fluctuation field by a discrete Fourier transform. For example, by transforming with respect to the angle θ, we can single out individual azimuthal modes (Fig. 2b–e). To study wave dynamics in time, we must also transform the temporal coordinate and inspect the resulting two-dimensional spectra, showcased in Fig. 2f, g for two distinct radii. Notable high-amplitude signals in the m = ± 1 bands are exclusively a consequence of how mechanical vibrations of the set-up imprint themselves on our detection method. Of physical interest are modes with higher azimuthal numbers. These excitations, observed in both solid-core and hollow-core regimes, represent micrometre waves excited on the interface. In the steady state, the waves dissipate their energy, in part by viscous damping and in part by scattering into the draining core of the vortex. Although this is balanced by the stochastic drive originating from the fluid flow and/or aforementioned mechanical vibrations, we notice that only a certain region of the spectral space (m, f) is populated with excitations, a feature that varies when examining smaller (Fig. 2f) and larger (Fig. 2g) radii. We observe that only some high-frequency (equivalent to high-energy) waves have the capability to propagate on the interface. Through the solution of equation (2), we can pinpoint the minimum frequency, f min, permissible for propagation for the given radius, azimuthal number and background velocity (see Methods) and, in line with the methodology introduced above, we exploit this particular frequency to extract the underlying velocity field, as we now describe. We search the parameter space produced by two velocity components (v r, v θ) and determine values that produce the best match between f min and the lowest excited frequency in the experimental data across several azimuthal modes (coloured lines in Fig. 2f, g). By carrying out this procedure for every examined radius, we can reconstruct the velocity distribution in the draining vortex flow.

---

### Interim guidance for medical screening and hazard surveillance for workers potentially exposed to engineered nanoparticles [^ce7938d8]. CDC (2009). Medium credibility.

Interim guidance — state of evidence on engineered nanoparticle toxicity notes that assessing the potential toxicity of engineered nanoparticles is at an early stage, and at this time only a few types of engineered nanoparticles have been studied so a clear and consistent picture of the relevant endpoints for workers has not yet emerged. Various physicochemical parameters of nanoparticles, including composition, size, shape, surface characteristics, charge, functional groups, crystal structure, and solubility, appear to affect toxicity, and it is not known whether size is the overriding parameter. Some nanoscale particles may pose a health concern.

---

### Implementation of quantum and classical discrete fractional fourier transforms [^60c10e08]. Nature Communications (2016). Medium credibility.

Results

Theoretical approach

Similarly to its continuous counterpart, the DFrFT can be interpreted physically as a continuous rotation of the associated wave functions through an angle Z in phase space (see Fig. 1a). The idea is thus to construct finite circuits that are capable of imprinting such rotations to any light field. In quantum mechanics, three-dimensional spatial rotations of complex state vectors are generated via operations of the angular momentum operators J k (k = x, y, z) on the Hilbert space of the associated system. In particular, the rotation imprinted by the J x -operator turns out to be an elaborated definition of the DFrFT (see Methods section for discussion). These concepts can be readily translated to the optical domain by mapping the matrix elements of the J x -operator over the inter-channel couplings of engineered waveguide arrays (Fig. 1b–e). The coupling matrix of such waveguide arrays is thus given by(ref.). Here, κ 0 is a scaling factor introduced for experimental reasons. The indices m and n range from − j to j in unit steps. Meanwhile, j represents an arbitrary positive integer or half-integer that determines the total number of waveguides via N = 2 j +1 (Fig. 1b).

Coupled mode theory states that the evolution of light in the J x -waveguide array is governed by the following set of equations

Here, E n (Z) denotes the complex electric field amplitude at site n. In the quantum optics regime, single photons traversing such devices are governed by a set of Heisenberg equations that are isomorphic to equation (1). The only difference is that in the quantum case E n (Z) must be replaced by the photon creation operator. In a spintronic context, the evolution parameter Z is associated with time, whereas in the framework of integrated quantum optics, Z represents the propagation distance, see Fig. 1b–e. A spectral decomposition of the J x -matrix yields the eigenvectors, which in combination with the eigenvalues, render the closed-form point-spread function

---

### Dislocation majorana bound States in iron-based superconductors [^a5d4aec7]. Nature Communications (2024). High credibility.

Our last ingredient, the lattice dislocations, is intuitively a "gluing fault" when combining two identical copies of our setup. For example, as schematically shown in Fig. 1 a, the screw dislocations are formed when the left parts of the two crystals are combined perfectly, while the right parts mismatch with each other by a displacement vector b = (0,0,1), i.e. the Burgers vector. While a screw or an edge dislocation appears one-dimensional, it must be attached to a 2D cutting planethat only terminates at either another dislocation to form a dislocation dipole or the crystal boundary. An example of a cutting plane is highlighted by the orange line in Fig. 1 a.

Fig. 1
Nested domain wall theory for the class-D embedded second-order topological phase (ET 2).

a A single screw dislocation with a Burgers vector b = (0, 0, 1) along with other key ingredients for ET 2: weakindex in the normal state, bulk SC, and surface magnetism. In (b), we cut the crystal in halves following the orange cutting plane in (a), which leads to two disjoint magnetism-gapped top surfaces and two SC-gapped side surfaces. Further folding the top surfaces following the trajectory arrows leads to the "bilayer" configurations of Dirac surface states in (c). The competition between magnetism (M) and SC leads to a pair of counterpropagating 1D Majorana modes once δ M > δ SC. In (d), we glue everything together to restore the crystal, and the introduction of a dislocation decorates the intersurface hopping between Dirac particles on the orange cutting plane with a phase factor of e i π b ⋅ ν. This gaps out the Majorana modes in a nontrivial way shown in (e), which can be mapped to a 1D Jackiw-Rebbi domain wall problem and results in a localized Majorana zero mode at the surface dislocation core. We carry out a numerical simulation of a pair of screw dislocations for FeTe 1− x Se x on a 28 × 28 × 28 lattice. Four zero-energy modes are found and their spatial wavefunctions are found to be localized around each dislocation core, as shown in (f).

---

### Filgrastim (Neupogen) [^bf3ac22c]. FDA (2025). Medium credibility.

Important: Throw the gray needle cap into the sharps disposal container.

Your healthcare provider has prescribed either a "full" syringe dose or a "partial" syringe dose of NEUPOGEN.

If you are prescribed a full dose, you will inject all of the medicine from your prefilled syringe. For a full dose, go directly to Step 3: Subcutaneous (under the skin) injection.
If you are prescribed a partial dose of NEUPOGEN, start with Step G below.

G Point the needle up and tap gently until the air rises to the top.

Important: Do not slide the orange safety guard over the needle before you give the injection. This will "activate" or lock the orange safety guard.

As you push the plunger rod up, air and extra medication is removed. Check to make sure the plunger lines up with the syringe markings for your prescribed dose. If you remove too much medicine, get a new prefilled syringe and start again at Step 1.

Call your healthcare provider if you have problems measuring your prescribed dose.

Step 3: Subcutaneous (under the skin) injection

I Pinch your injection site to create a firm surface.

Important: Keep skin pinched while injecting.

J Hold the pinch. Insert the needle into the skin at 45 to 90 degrees.

---

### Sodium fluoride (zap neutral) [^1cb4a527]. FDA (2022). Medium credibility.

Other Information:

Do not store above 25°C/77°F.
Do not freeze.

---

### Reactivity of shape-controlled crystals and metadynamics simulations locate the weak spots of alumina in water [^d323d858]. Nature Communications (2019). High credibility.

The kinetic stability of any material in water relies on the presence of surface weak spots responsible for chemical weathering by hydrolysis. Being able to identify the atomistic nature of these sites and the first steps of transformation is therefore critical to master the decomposition processes. This is the challenge that we tackle here: combining experimental and modeling studies we investigate the stability of alumina in water. Exploring the reactivity of shape-controlled crystals, we identify experimentally a specific facet as the location of the weak spots. Using biased ab initio molecular dynamics, we recognize this weak spot as a surface exposed tetra-coordinated Al atom and further provide a detailed mechanism of the first steps of hydrolysis. This understanding is of great importance to heterogeneous catalysis where alumina is a major support. Furthermore, it paves the way to atomistic understanding of interfacial reactions, at the crossroad of a variety of fields of research.

---

### Using grid cells for navigation [^fac508c8]. Neuron (2015). Low credibility.

Discussion

We have described an algorithmic solution to the computational problem of large-scale vector navigation with grid cells. That is, how to accurately compute translation vectors between arbitrary locations in large-scale 2D space using the grid cell representations of those locations. This problem is the inverse of that thought to be performed by grid cells during path integration — extracting the translation vector between current and goal locations, as opposed to combining a previously known location with a subsequent movement vector to estimate the current location. Specifically, we have shown how the spatial phases of activity in grid cell modules of different spatial scales at start and goal locations can be used to extract the distance and direction between those locations. This is achieved by finding the maximum slope of a plane that fits the family of points defined by the phase difference in each grid module and the inverse scale of that module on at least two non-collinear axes (Figure 4 C). Importantly, this solution is robust to differences in grid orientation between grid modules and ellipticity (i.e. differences in scale between axes) within each grid module. This solution relates to the Fourier shift theorem, whereby the 2D translation applied to a basis set of Fourier components can be recovered from the phase changes across components.

We have also described several neural network implementations of this algorithmic solution, building on a large body of previous work that has explored how grid cells efficiently encode location and might contribute to vector navigation. These models assume only that the grid representations of current and goal locations are known and produce direct vectors between those locations that may traverse previously unknown terrain. Each proposed implementation can decode 2D translation vectors with an accuracy and range that is comparable to the theoretical capacity of the grid cell system, and each model offers specific strengths, weaknesses, and experimental predictions. Several computational implementations that make use of the Chinese Remainder Theorem to perform this conversion have previously been proposed. These models have limitations, however, such as requiring a hard-wired energy landscape or readout weights, producing linear outputs that are only correct modulo the lowest common multiple of grid scales or performing gradient descent on an energy landscape with multiple local minima.

---

### Spin dephasing under nonlinear gradients: implications for imaging and field mapping [^eaf2803c]. Magnetic Resonance in Medicine (2012). Low credibility.

This work examines the prototypical MR echo that would be expected for a voxel of spins evolving in a strong nonlinear field, specifically focusing on the quadratic z(2) - ½(x(2) + y(2)) field. Dephasing under nonlinear gradients is increasingly relevant given the growing interest in nonlinear imaging, and here, we report several notable differences from the linear case. Most notably, in addition to signal loss, intravoxel dephasing under gradients creating a wide and asymmetric frequency distribution across the voxel can cause skewed and nonlinear phase evolution. After presenting the qualitative and analytical origins of this difference, we experimentally demonstrate that neglecting these dynamics can lead to significant errors in sequences that assume phase evolution is proportional to voxel frequency, such as those used for field mapping. Finally, simplifying approximations to the signal equations are presented, which not only provide more intuitive forms of the exact expression but also result in simple rules to predict key features of the nonlinear evolution.

---

### Single photon emission computed tomography (SPECT) myocardial perfusion imaging guidelines: instrumentation, acquisition, processing, and interpretation [^bc9edc29]. Journal of Nuclear Cardiology (2018). Medium credibility.

Dead-time effects and count-rate performance — SPECT detector performance can be described by the count rate at which dead-time effects cause a loss of 20% of the expected count rate, and while dynamic imaging of myocardial blood flow may encounter very high count rates during initial frames, incorrectly accounting for dead-time losses can cause errors in quantitative blood flow measurement; however, for all cardiac myocardial perfusion radiotracers, protocols, and imaging systems currently in clinical use, dead-time effects are not a clinical concern.

---

### 1.1% sodium fluoride (Sf) [^3e9dbd06]. FDA (2016). Low credibility.

STORAGE

Store at Controlled Room Temperature, 20–25 C (68–77 F).

Rx only

---