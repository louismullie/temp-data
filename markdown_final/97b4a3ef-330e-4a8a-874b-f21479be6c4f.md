# Medical Question & Answer

**Sample ID**: 97b4a3ef-330e-4a8a-874b-f21479be6c4f
**Dataset Index**: 2437

---

## Question

approchs study

---

## Answer

> Let's see… What do we have here? The user is asking how to select and apply research approaches across disease study contexts, with explicit stepwise thinking and self-verification preserved. Let's break this down step-by-step. First, I need to think about how to frame the research question using structured frameworks. Then, I should classify the disease context and its methodological constraints. Next, I will map study designs to question types and constraints, followed by selecting analytic methods and bias-mitigation strategies. After that, I need to consider special populations and rare diseases, and finally integrate emerging technologies and synthesize a practical decision algorithm, ensuring each step is supported by appropriate references and self-checks throughout.

> Let me first confirm the foundational step of question formulation, because if I get the question wrong, everything downstream will be misaligned; the PICO framework (Population, Intervention, Comparator, Outcome) and its extensions like PICOT and Target Trial Emulation help specify the clinical question and align design choices with the evidence needed, and I should double-check that the Estimand framework is considered when intercurrent events could distort interpretation [^1144itL4] [^113qBHvf].

> Hold on, let's not jump to conclusions about design until I classify the disease context; I need to check whether the condition is rare, infectious with transmission dynamics, chronic and progressive, acute with short-term effects, or primarily genetic, because each context imposes different feasibility, endpoint, and comparator constraints that will shape the viable study options and analytic strategies [^1144nfK1] [^112o4XkL] [^113k14KV] [^1159J3zB].

> Next, I should review how question type maps to design, and I need to ensure I don't overstate RCTs as the only valid option; for therapy effects, RCTs are preferred when feasible, but for rare diseases, adaptive, crossover, n-of-1, or Bayesian designs can be more efficient, whereas for prognosis, prospective cohorts are appropriate, for etiology when RCTs are infeasible, case-control or Mendelian randomization can help, and for diagnosis, cross-sectional accuracy studies or nested case-control designs are suitable, so I should verify that the chosen design matches the causal target and the disease context [^115WA4DU] [^112m1cWn] [^1164kQdp] [^111WeLg3] [^112rwHNs].

> Wait, let me verify the analytic layer because design alone does not guarantee valid inference; I should confirm that the analysis plan aligns with the design and addresses key threats such as confounding, selection bias, and multiplicity, using intention-to-treat for RCTs, propensity scores or instrumental variables for observational comparisons, and appropriate methods for rare events and small samples, while also planning for missing data and sensitivity analyses to test assumptions [^113XYDAj] [^116uNMaW] [^112tYXnh].

> I will now examine special populations, especially rare diseases, because standard RCTs often fail; I need to check whether adaptive designs, crossover or n-of-1 trials, Bayesian borrowing, or sequential methods can reduce sample size and ensure more patients receive active treatment, and I should confirm whether trial networks or registry-based platforms can mitigate geographic dispersion and accelerate recruitment, while remembering that observational methods like self-controlled designs and propensity scores remain important when randomization is infeasible [^112m1cWn] [^111KPizQ] [^114gHPLT] [^116uNMaW].

> But wait, what if the disease is infectious with indirect effects; I should double-check whether transmission-dynamic models and simulations are needed to design and interpret cluster or stepped-wedge trials, and I need to ensure that the analysis captures both direct and indirect effects, since standard individual-level models can misestimate population impact without accounting for transmission [^112o4XkL].

> Let me consider emerging technologies and systems approaches, and I should confirm that multi-omic integration, network medicine, and machine learning are not just buzzwords but tools that can reveal disease modules, biomarkers, and precision targets; I need to ensure translational distance is addressed by anchoring discovery in human tissues and validating in models that capture relevant biology, and I should verify that disease-progression modeling and time-series analytics can help characterize trajectories and identify intervention windows [^114nvJNP] [^114UDdt3] [^113Ho1Xy] [^111zkE3C] [^1176koi8].

> Hold on, I should verify that my synthesis remains practical; a stepwise decision pathway that starts with PICO, then disease context, then question type, then design, then analysis, and finally special-population adaptations keeps the process reproducible, and I need to ensure that each branch is justified by feasibility, ethics, and scientific rigor rather than convenience, documenting why conventional RCTs were not used when they were infeasible and how alternative designs preserve validity [^115ibjGD] [^1144itL4].

> Hmm, wait a minute, I initially thought "observational studies cannot establish causality", but I should correct that overstatement; while confounding limits causal inference in observational designs, methods like Mendelian randomization, negative controls, and target trial emulation can strengthen causal claims under specific assumptions, so I need to be precise and qualify that statement by design and analytic strategy rather than dismiss observational evidence outright [^111WeLg3] [^113qBHvf].

> Finally, I need to ensure reporting and appraisal are aligned with best practices; PRISMA 2020 for systematic reviews, SWiM when meta-analysis is not performed, and GRADE for certainty grading help communicate methods and conclusions transparently, and I should double-check that risk-of-bias tools appropriate to the design are applied consistently to both RCTs and observational studies to support trustworthy inference and decision-making [^1152pu9q] [^113xiq4B] [^1144itL4].

---

The "approchs study" likely refers to **approaches to studying disease** — the methods and designs researchers use to investigate disease mechanisms, progression, and treatments. Key approaches include **observational studies** (cohort, case-control, cross-sectional) for risk factors and natural history [^1164kQdp]; **randomized controlled trials (RCTs)** for causal inference and treatment effects [^115WA4DU]; **molecular and genetic methods** (GWAS, sequencing, omics) for mechanistic insights [^111iQqbr]; **systems biology** for network-level understanding [^114UDdt3]; and **modeling/simulation** for disease dynamics and trial design [^112o4XkL]. Selection depends on the research question, disease rarity, and available data, with rare diseases often requiring **innovative designs** [^112m1cWn] and **observational methods** [^116uNMaW].

---

## Observational study designs

Observational studies are essential for generating hypotheses, identifying risk factors, and understanding disease natural history. The main types include **cohort studies**, which follow exposed and unexposed groups over time to assess incidence and risk factors [^117KPuTg]; **case-control studies**, which compare cases with controls to identify risk factors, especially for rare diseases or outcomes [^1164kQdp]; and **cross-sectional studies**, which measure exposure and outcome simultaneously to estimate prevalence and generate hypotheses [^1164kQdp].

---

## Experimental study designs

Experimental designs, particularly **randomized controlled trials (RCTs)**, are the gold standard for evaluating interventions. Key variants include **pragmatic RCTs**, which test interventions in real-world settings to improve external validity, and **adaptive RCTs**, which allow preplanned modifications to improve efficiency and ethical conduct [^112tYXnh].

---

## Molecular and genetic approaches

Advances in molecular biology and genetics have transformed disease research. Key methods include **genome-wide association studies (GWAS)** to identify genetic variants associated with disease [^114UDdt3]; **whole-genome sequencing** to discover rare variants and structural changes [^notfound]; and **multi-omics integration** (genomics, transcriptomics, proteomics, metabolomics) to provide a comprehensive view of disease mechanisms [^114nvJNP].

---

## Systems biology and network medicine

Systems biology integrates multi-omics data to model disease as perturbed networks, enabling identification of **network biomarkers** and therapeutic targets [^114UDdt3]. Network medicine extends this by mapping disease modules and their interconnections, revealing shared mechanisms across diseases [^114UDdt3].

---

## Computational modeling and simulation

Modeling and simulation are increasingly used to study disease dynamics, predict outcomes, and design interventions. Key applications include **disease progression modeling** to simulate natural history and treatment effects [^111zkE3C] and **agent-based models** to simulate infectious disease transmission and evaluate interventions [^notfound].

---

## Innovative approaches for rare diseases

Studying rare diseases requires tailored methods due to small populations. Innovative approaches include **adaptive designs** to reduce sample size and increase efficiency [^111KPizQ], **basket and umbrella trials** to test therapies across related conditions, and **natural history studies** to define disease course and biomarkers [^112W8PUB].

---

## Mixed-methods and interdisciplinary approaches

Mixed-methods and interdisciplinary research combine quantitative and qualitative data to provide a holistic understanding of disease. These approaches integrate **social, behavioral, and environmental factors** into disease research [^notfound].

---

## Emerging technologies and future directions

Emerging technologies are shaping future disease research. Key trends include **single-cell and spatial omics** for high-resolution tissue maps [^notfound], **machine learning and AI** for pattern recognition and prediction [^1158cb5q], and **digital health and wearables** for continuous, real-world data collection.

---

## Challenges and limitations

Despite advances, challenges remain, including **data quality and integration**, **reproducibility**, and **ethical considerations** in genetic and digital health research. Addressing these requires robust methods, transparency, and stakeholder engagement [^117Mk9Hc].

---

In sum, disease research spans observational and experimental designs, molecular and systems approaches, modeling, and emerging technologies, with **method selection guided by the research question, disease context, and data availability**.

---

## References

### Models for disease progression: new approaches and uses [^111zkE3C]. Clinical Pharmacology and Therapeutics (2012). Low credibility.

Disease-progression models are useful tools in drug development. They increase the information obtained from clinical trials, improve study designs, and allow in silico evaluations of new treatment combinations and dose regimens. Disease-progression modeling can save time and strengthen "go/no-go" criteria. The use of meta-based modeling and the linking of disease progression to discrete clinical end points have improved the utility of this valuable approach. This article provides an overview of disease-progression evaluations using these new approaches.

---

### Innovative research methods for studying treatments for rare diseases: methodological review [^116yLg8A]. BMJ (2014). Excellent credibility.

Discussion

In this review of methods that have been proposed for and used to study health outcomes in rare diseases, we identified a wide variety of non-traditional approaches. The majority of the identified articles were published in 2008 or later, highlighting the increasing interest in this area. Most articles also focused on innovations in methods for clinical trials intended to minimize the number of participants needed to meet the study goals or to maximize the proportion of participants who receive active treatment to encourage enrollment.

Implications for randomized trials

Advances in clinical trial design relevant to rare diseases are well developed, having been discussed in several technical articles and applied in many clinical scenarios. Cornu and colleagues provide examples of studies that have used each of 12 different randomized designs in the setting of rare diseases. They and Gupta and colleagues have also proposed frameworks to aid selection of randomized clinical trial methods for studying health outcomes in rare diseases. Both algorithms pose similar questions to address whether the assumptions of crossover and n-of-1 trials are likely to hold, such as whether the intervention of interest has only a short term effect on the outcome. Gupta and colleagues' algorithm asks about whether sufficient numbers of patients are likely to be recruited for a given design and offers alternatives when this is not the case. Cornu and colleagues' algorithm explicitly asks about whether objectives of the study include minimizing the time patients are receiving placebo or ensuring that patients receive active treatment by the end of the trial. Until a unified framework is developed, both algorithms can be used to help decide the most appropriate design to study health outcomes in patients with rare diseases.

---

### Innovative research methods for studying treatments for rare diseases: methodological review [^1144nfK1]. BMJ (2014). Excellent credibility.

Introduction

Though an individual rare disease is by definition uncommon, according to the statutory definitions set in the United States (prevalence < 200 000 people each year; equating to a prevalence of approximately < 64 per 100 000 people) and European Union (< 50 per 100 000 people), more than 6800 different conditions qualify as rare diseases and 6–8% of the population is affected. This translates to about 60 million people in the United States and EU alone. Rare diseases comprise a heterogeneous set of conditions that afflict various organ systems, have wide ranging prognoses, and even vary along a gradient of rareness.

Many barriers exist to advancing knowledge of and treatment options for rare diseases. The small patient populations can dampen commercial interest in development of treatments. Yet even for those rare conditions where funding is plentiful and manufacturers of therapeutics are engaged, methodological and data constraints limit the ability to generate evidence on patient health outcomes. The most obvious challenge to conducting rigorous research is the small number of eligible participants for a given study. In addition, geographic dispersion of patients, lack of knowledge about the clinical course of disease, and lack of appropriate comparator treatments further hinder the generation of evidence. As a result relatively little is known about the clinical course of many rare diseases and few treatment options exist.

However, there may be pathways for collectively advancing the study of rare diseases. Although rare diseases may present unique clinical problems, the methodological challenges to studying health outcomes are often communal. In recent years, innovative epidemiological and clinical trial methods have been developed that offer promise for promoting more efficient and effective research. Because rare diseases are so clinically dissimilar, clinicians, scientists, and other stakeholders working in one medical specialty may not be familiar with methods being applied in other disciplines. Thus, we conducted a methodological review to catalogue and describe innovative approaches to studying health outcomes in patients with rare diseases. Our goal was to identify innovative approaches to research that have been, or can be, applied to overcome the methodological challenges inherent in the study of rare diseases.

---

### Adult asthma disease management: an analysis of studies, approaches, outcomes, and methods [^112BV3Dj]. Respiratory Care (2009). Low credibility.

Background

Disease management has been implemented for patients with asthma in various ways. We describe the approaches to and components of adult asthma disease-management interventions, examine the outcomes evaluated, and assess the quality of published studies.

Methods

We searched the MEDLINE, EMBASE, CINAHL, PsychInfo, and Cochrane databases for studies published in 1986 through 2008, on adult asthma management. With the studies that met our inclusion criteria, we examined the clinical, process, medication, economic, and patient-reported outcomes reported, and the study designs, provider collaboration during the studies, and statistical methods.

Results

Twenty-nine articles describing 27 studies satisfied our inclusion criteria. There was great variation in the content, extent of collaboration between physician and non-physician providers responsible for intervention delivery, and outcomes examined across the 27 studies. Because of limitations in the design of 22 of the 27 studies, the differences in outcomes assessed, and the lack of rigorous statistical adjustment, we could not draw definitive conclusions about the effectiveness or cost-effectiveness of the asthma disease-management programs or which approach was most effective.

Conclusions

Few well-designed studies with rigorous evaluations have been conducted to evaluate disease-management interventions for adults with asthma. Current evidence is insufficient to recommend any particular intervention.

---

### The use and interpretation of quasi-experimental studies in infectious diseases [^112HqzYR]. Clinical Infectious Diseases (2004). Low credibility.

Quasi-experimental study designs, sometimes called nonrandomized, pre-post-intervention study designs, are ubiquitous in the infectious diseases literature, particularly in the area of interventions aimed at decreasing the spread of antibiotic-resistant bacteria. Little has been written about the benefits and limitations of the quasi-experimental approach. This article outlines a hierarchy of quasi-experimental study design that is applicable to infectious diseases studies and that, if applied, may lead to sounder research and more-convincing causal links between infectious diseases interventions and outcomes.

---

### A systems approach to infectious disease [^112cLQAs]. Nature Reviews: Genetics (2020). High credibility.

Ongoing social, political and ecological changes in the 21st century have placed more people at risk of life-threatening acute and chronic infections than ever before. The development of new diagnostic, prophylactic, therapeutic and curative strategies is critical to address this burden but is predicated on a detailed understanding of the immensely complex relationship between pathogens and their hosts. Traditional, reductionist approaches to investigate this dynamic often lack the scale and/or scope to faithfully model the dual and co-dependent nature of this relationship, limiting the success of translational efforts. With recent advances in large-scale, quantitative omics methods as well as in integrative analytical strategies, systems biology approaches for the study of infectious disease are quickly forming a new paradigm for how we understand and model host-pathogen relationships for translational applications. Here, we delineate a framework for a systems biology approach to infectious disease in three parts: discovery - the design, collection and analysis of omics data; representation - the iterative modelling, integration and visualization of complex data sets; and application - the interpretation and hypothesis-based inquiry towards translational outcomes.

---

### Candidate-gene approaches for studying complex genetic traits: practical considerations [^112XXtAy]. Nature Reviews: Genetics (2002). Medium credibility.

Association studies with candidate genes have been widely used for the study of complex diseases. However, this approach has been criticized because of non-replication of results and limits on its ability to include all possible causative genes and polymorphisms. These challenges have led to pessimism about the candidate-gene approach and about the genetic analysis of complex diseases in general. We believe that these criticisms can be usefully countered with an appeal to the principles of epidemiological investigation.

---

### Natural history of diseases: statistical designs and issues [^113k14KV]. Clinical Pharmacology and Therapeutics (2016). Low credibility.

Understanding the natural history of a disease is an important prerequisite for designing studies that assess the impact of interventions, both chemotherapeutic and environmental, on the initiation and expression of the condition. Identification of biomarkers that mark disease progression may provide important indicators for drug targets and surrogate outcomes for clinical trials. However, collecting and visualizing data on natural history is challenging, in part, because disease processes are complex and evolve in different chronological periods for different subjects. Various epidemiological designs are used to elucidate components of the natural history process. We briefly discuss statistical issues, limitations, and challenges associated with various epidemiological designs.

---

### Systems biology and personalized medicine: a network approach to human disease [^111BVi1a]. Proceedings of the American Thoracic Society (2011). Low credibility.

Human diseases have historically been classified on the basis of their end-organ manifestations, using a traditional clinicopathological approach dating to the 19th century. With the advent of rigorous molecular methodologies at the end of the 20th century, many specific disease determinants were identified and more targeted therapeutic strategies developed. Although the conventional reductionist approach underlying these strategies for understanding disease served us well in the pregenomic era, it hampers our understanding of the complex molecular networks within which disease develops that are increasingly manifest in the current era. This article presents a novel, holistic method for classifying human diseases that can serve as a template for understanding disease pathobiology, prognosis, and treatment.

---

### Simulations for designing and interpreting intervention trials in infectious diseases [^112o4XkL]. BMC Medicine (2017). Low credibility.

Background

Interventions in infectious diseases can have both direct effects on individuals who receive the intervention as well as indirect effects in the population. In addition, intervention combinations can have complex interactions at the population level, which are often difficult to adequately assess with standard study designs and analytical methods.

Discussion

Herein, we urge the adoption of a new paradigm for the design and interpretation of intervention trials in infectious diseases, particularly with regard to emerging infectious diseases, one that more accurately reflects the dynamics of the transmission process. In an increasingly complex world, simulations can explicitly represent transmission dynamics, which are critical for proper trial design and interpretation. Certain ethical aspects of a trial can also be quantified using simulations. Further, after a trial has been conducted, simulations can be used to explore the possible explanations for the observed effects.

Conclusion

Much is to be gained through a multidisciplinary approach that builds collaborations among experts in infectious disease dynamics, epidemiology, statistical science, economics, simulation methods, and the conduct of clinical trials.

---

### Decoding disease: from genomes to networks to phenotypes [^111iQqbr]. Nature Reviews: Genetics (2021). High credibility.

Interpreting the effects of genetic variants is key to understanding individual susceptibility to disease and designing personalized therapeutic approaches. Modern experimental technologies are enabling the generation of massive compendia of human genome sequence data and associated molecular and phenotypic traits, together with genome-scale expression, epigenomics and other functional genomic data. Integrative computational models can leverage these data to understand variant impact, elucidate the effect of dysregulated genes on biological pathways in specific disease and tissue contexts, and interpret disease risk beyond what is feasible with experiments alone. In this Review, we discuss recent developments in machine learning algorithms for genome interpretation and for integrative molecular-level modelling of cells, tissues and organs relevant to disease. More specifically, we highlight existing methods and key challenges and opportunities in identifying specific disease-causing genetic variants and linking them to molecular pathways and, ultimately, to disease phenotypes.

---

### Systematic reviews and meta-analysis of published studies: an overview and best practices [^1136qFp5]. Journal of Thoracic Oncology (2011). Low credibility.

Systematic reviews and meta-analytic approaches are widely used in the clinical arena to integrate outcome data from published studies in a patient population that address a set of related research hypotheses. The credibility of this line of research is dependent on how the studies are chosen, how the data are assembled, and how the results are reported. In this brief report, we provide an overview of the minimum set of reporting requirements for systematic reviews and meta-analyses based on the Preferred Reporting Items of Systematic reviews and Meta-Analyses guidelines. As with any research, following a set of established guidelines is essential for quality and consistency of the findings across studies and for assessment of clinical utility.

---

### Innovative research methods for studying treatments for rare diseases: methodological review [^112m1cWn]. BMJ (2014). Excellent credibility.

Objective

To examine methods for generating evidence on health outcomes in patients with rare diseases.

Design

Methodological review of existing literature.

Setting

PubMed, Embase, and Academic Search Premier searched for articles describing innovative approaches to randomized trial design and analysis methods and methods for conducting observational research in patients with rare diseases.

Main Outcome Measures

We assessed information related to the proposed methods, the specific rare disease being studied, and outcomes from the application of the methods. We summarize methods with respect to their advantages in studying health outcomes in rare diseases and provide examples of their application.

Results

We identified 46 articles that proposed or described methods for studying patient health outcomes in rare diseases. Articles covered a wide range of rare diseases and most (72%) were published in 2008 or later. We identified 16 research strategies for studying rare disease. Innovative clinical trial methods minimize sample size requirements (n = 4) and maximize the proportion of patients who receive active treatment (n = 2), strategies crucial to studying small populations of patients with limited treatment choices. No studies describing unique methods for conducting observational studies in patients with rare diseases were identified.

Conclusions

Though numerous studies apply unique clinical trial designs and considerations to assess patient health outcomes in rare diseases, less attention has been paid to innovative methods for studying rare diseases using observational data.

---

### Innovative research methods for studying treatments for rare diseases: methodological review [^116ptgK6]. BMJ (2014). Excellent credibility.

Objective To examine methods for generating evidence on health outcomes in patients with rare diseases.

Design Methodological review of existing literature.

Setting PubMed, Embase, and Academic Search Premier searched for articles describing innovative approaches to randomized trial design and analysis methods and methods for conducting observational research in patients with rare diseases.

Main outcome measures We assessed information related to the proposed methods, the specific rare disease being studied, and outcomes from the application of the methods. We summarize methods with respect to their advantages in studying health outcomes in rare diseases and provide examples of their application.

Results We identified 46 articles that proposed or described methods for studying patient health outcomes in rare diseases. Articles covered a wide range of rare diseases and most (72%) were published in 2008 or later. We identified 16 research strategies for studying rare disease. Innovative clinical trial methods minimize sample size requirements (n = 4) and maximize the proportion of patients who receive active treatment (n = 2), strategies crucial to studying small populations of patients with limited treatment choices. No studies describing unique methods for conducting observational studies in patients with rare diseases were identified.

Conclusions Though numerous studies apply unique clinical trial designs and considerations to assess patient health outcomes in rare diseases, less attention has been paid to innovative methods for studying rare diseases using observational data.

---

### How do you design randomised trials for smaller populations? A framework [^115ibjGD]. BMC Medicine (2016). Low credibility.

Methods: The framework

The first step of the framework (Fig. 1) is to work out an ideal sample size and consider whether it is feasible. If it is not, the following sections describe how to apply different elements of the framework and how to approach evaluating them.

Reviewers, funders, collaborators, patients and regulators at the beginning, and regulators, journal editors, readers and patients at the end, will all need to be persuaded that the chosen design was the best approach and any unusual features were necessary. All these parties need to be persuaded of the key problem that the condition is not common enough to deliver the trial that would traditionally be expected, and that all efforts were made to maximise the number of patients available and the information obtained from them. Trials often take many years to design and deliver. Putting in many months to get the design right from the outset should not be considered disproportionate in terms of time or effort.

An important premise is to understand what we term a societal perspective: the view from the society affected by a specific disease. The aim of RCTs should be to find a way to improve outcomes for future patients.

---

### Adapting systems biology to address the complexity of human disease in the single-cell era [^113Ho1Xy]. Nature Reviews: Genetics (2025). High credibility.

Systems biology aims to achieve holistic insights into the molecular workings of cellular systems through iterative loops of measurement, analysis and perturbation. This framework has had remarkable success in unicellular model organisms, and recent experimental and computational advances - from single-cell and spatial profiling to CRISPR genome editing and machine learning - have raised the exciting possibility of leveraging such strategies to prevent, diagnose and treat human diseases. However, adapting systems-inspired approaches to dissect human disease complexity is challenging, given that discrepancies between the biological features of human tissues and the experimental models typically used to probe function (which we term 'translational distance') can confound insight. Here we review how samples, measurements and analyses can be contextualized within overall multiscale human disease processes to mitigate data and representation gaps. We then examine ways to bridge the translational distance between systems-inspired human discovery loops and model system validation loops to empower precision interventions in the era of single-cell genomics.

---

### The future of model organisms in human disease research [^116wdATo]. Nature Reviews: Genetics (2011). Medium credibility.

Model organisms have played a huge part in the history of studies of human genetic disease, both in identifying disease genes and characterizing their normal and abnormal functions. But is the importance of model organisms diminishing? The direct discovery of disease genes and variants in humans has been revolutionized, first by genome-wide association studies and now by whole-genome sequencing. Not only is it now much easier to directly identify potential disease genes in humans, but the genetic architecture that is being revealed in many cases is hard to replicate in model organisms. Furthermore, disease modelling can be done with increasing effectiveness using human cells. Where does this leave non-human models of disease?

---

### Innovative research methods for studying treatments for rare diseases: methodological review [^114gHPLT]. BMJ (2014). Excellent credibility.

Tan and colleagues described a bayesian approach to combining previous data with data from a new randomized controlled trial by creating scores that are then used to weight the pieces of evidence according to their pertinence, validity, and precision. The validity scores enable investigators to down-weight evidence based on studies with flaws or other concerns, such as confounding in non-randomized trials. Pertinence scores are based on how closely the information from each source relates to the information to be gained in the trial. In theory, pertinence scores could also be based on the degree to which the evidence streams are relevant to patients' decision making and could therefore support patient centered decision making. The authors make the case that such a bayesian approach can increase the robustness of information from small trials and can be used to help design and provide justification for such trials. However, bayesian approaches require appropriate specification of a prior distribution, which may be subjective or based on limited information.

Maximizing on-treatment participants

Trials that guarantee participants receive an intervention can enhance recruitment for patients with rare diseases who have limited treatment options. Some of these designs can also reduce recruitment requirements compared with alternative conventional parallel group randomized controlled trials. For example, crossover trials involve randomizing patients to treatment at one time (or several times) and to no treatment (or treatment with a comparator) at another time (or other times). In addition to guaranteeing treatment, crossover designs are more statistically efficient than their parallel group randomized controlled trial counterparts. Crossover trials are particularly well suited to studying treatments for chronic conditions in which the treatments provide immediate relief of symptoms. But crossover trials generally cannot be used to study treatments that have curative effects or conditions that are rapidly changing. Many rare diseases are chronic conditions that progress over time. Changes in the disease over time that are unrelated to the treatment under study can cause bias in crossover trials. Crossover trials also require a transient treatment effect to minimize carryover effects into the subsequent treatment periods.

---

### Network medicine: a network-based approach to human disease [^114UDdt3]. Nature Reviews: Genetics (2011). Medium credibility.

Given the functional interdependencies between the molecular components in a human cell, a disease is rarely a consequence of an abnormality in a single gene, but reflects the perturbations of the complex intracellular and intercellular network that links tissue and organ systems. The emerging tools of network medicine offer a platform to explore systematically not only the molecular complexity of a particular disease, leading to the identification of disease modules and pathways, but also the molecular relationships among apparently distinct (patho)phenotypes. Advances in this direction are essential for identifying new disease genes, for uncovering the biological significance of disease-associated mutations identified by genome-wide association studies and full-genome sequencing, and for identifying drug targets and biomarkers for complex diseases.

---

### Innovative research methods for studying treatments for rare diseases: methodological review [^1133k3H5]. BMJ (2014). Excellent credibility.

Limitations of this study

This survey of research methods for rare diseases has several limitations. Firstly, our literature search was focused on articles that mentioned "rare disease" in a searchable field. Because of the large number of unique rare diseases, we were not able to search for applications of innovative methods related to each specific disease. In addition, our review was intended to provide a general overview of non-traditional methods that have been proposed or applied to studying rare diseases. If other non-traditional methods exist that might be applicable to rare diseases but have not yet been discussed in a publication in the databases we searched, we may not have identified them. Moreover, our review is intended to enhance awareness of the availability and use of innovative methods for studying health outcomes in rare diseases and is not intended to provide a technical review of these methods, which can be found in the cited references. Finally, while we searched three databases, two of which include biomedical journals and a third that covers disciplines including psychology, physics, and engineering, it is possible that we missed relevant methods that have been used in other specialties, such as the social sciences.

Conclusions and future directions

Despite these limitations, we found several promising strategies that may contribute substantial advances to the study of health outcomes in patients with rare diseases. Some of these methods (for example, crossover designs and propensity scores) are already used in studies of common conditions. Awareness of the armamentarium of research tools available will help investigators design studies in patients with specific rare diseases and will help clinicians interpret the results of these studies when treating patients with these conditions. Observational studies are an important approach for studying health outcomes in rare diseases, particularly as patient registries and electronic healthcare databases continue to grow and offer richer clinical information. However, greater attention to innovative methods for using observational data to study rare disease health outcomes is needed.

---

### Pivotal evaluation of the accuracy of a biomarker used for classification or prediction: standards for study design [^112rwHNs]. Journal of the National Cancer Institute (2008). Low credibility.

Research methods for biomarker evaluation lag behind those for evaluating therapeutic treatments. Although a phased approach to development of biomarkers exists and guidelines are available for reporting study results, a coherent and comprehensive set of guidelines for study design has not been delineated. We describe a nested case-control study design that involves prospective collection of specimens before outcome ascertainment from a study cohort that is relevant to the clinical application. The biomarker is assayed in a blinded fashion on specimens from randomly selected case patients and control subjects in the study cohort. We separately describe aspects of the design that relate to the clinical context, biomarker performance criteria, the biomarker test, and study size. The design can be applied to studies of biomarkers intended for use in disease diagnosis, screening, or prognosis. Common biases that pervade the biomarker research literature would be eliminated if these rigorous standards were followed.

---

### Integrative omics for health and disease [^114nvJNP]. Nature Reviews: Genetics (2018). Medium credibility.

Advances in omics technologies - such as genomics, transcriptomics, proteomics and metabolomics - have begun to enable personalized medicine at an extraordinarily detailed molecular level. Individually, these technologies have contributed medical advances that have begun to enter clinical practice. However, each technology individually cannot capture the entire biological complexity of most human diseases. Integration of multiple technologies has emerged as an approach to provide a more comprehensive view of biology and disease. In this Review, we discuss the potential for combining diverse types of data and the utility of this approach in human health and disease. We provide examples of data integration to understand, diagnose and inform treatment of diseases, including rare and common diseases as well as cancer and transplant biology. Finally, we discuss technical and other challenges to clinical implementation of integrative omics.

---

### The emerging paradigm of network medicine in the study of human disease [^116PWgpa]. Circulation Research (2012). Low credibility.

The molecular pathways that govern human disease consist of molecular circuits that coalesce into complex, overlapping networks. These network pathways are presumably regulated in a coordinated fashion, but such regulation has been difficult to decipher using only reductionistic principles. The emerging paradigm of "network medicine" proposes to utilize insights garnered from network topology (eg, the static position of molecules in relation to their neighbors) as well as network dynamics (eg, the unique flux of information through the network) to understand better the pathogenic behavior of complex molecular interconnections that traditional methods fail to recognize. As methodologies evolve, network medicine has the potential to capture the molecular complexity of human disease while offering computational methods to discern how such complexity controls disease manifestations, prognosis, and therapy. This review introduces the fundamental concepts of network medicine and explores the feasibility and potential impact of network-based methods for predicting individual manifestations of human disease and designing rational therapies. Wherever possible, we emphasize the application of these principles to cardiovascular disease.

---

### Genetic approaches to solving common diseases [^111obwst]. Journal of Neurology (2004). Low credibility.

The pathway to solving simple Mendelian inherited neurological disease is now well established. Barely a month goes by without new linkage data or mutations in a novel gene being reported. These developments are giving insights into a range of neurological conditions from the cortex to the muscle. However, most of these diseases are individually rare, and one of the major challenges facing neuroscience is to devise methods to find the genetic variants that confer risk of common diseases and differential response to treatment. This latter area is an important emerging field known as pharmacogenomics. Unlike Mendelian genetics where effective strategies are well established, the strategies for detecting moderate genetic effects in populations have been problematic. It is likely that a combination of techniques will be used, involving both linkage analysis and linkage disequilibrium mapping. In this review we consider some of the approaches that can be taken to resolve the common genetic variation underlying common disease.

---

### Innovative research methods for studying treatments for rare diseases: methodological review [^116uNMaW]. BMJ (2014). Excellent credibility.

Implications for observational studies

In addition to dealing with considerations about general design and analysis (for example, outcome selection, incorporation of evidence into larger context), our methodological review is the first to go beyond randomized trial methods for studying rare diseases. This is important because in small sample sizes, randomization will not always achieve its goal of balancing patient characteristics between treatment groups. In contrast with the body of literature on clinical trial methods in rare diseases, however, the literature on observational methods is considerably less mature. Several observational studies presented only descriptive frequencies of outcomes after a treatment and often with no comparison group, limiting the inferences that can be drawn about the treatment and subsequent outcomes. In general, observational studies of rare diseases used the same methods that are used to study health outcomes in more common conditions. However, several advanced observational methods that are used to study outcomes in common conditions — including propensity scores and self controlled designs — are particularly well suited for tackling confounding in the setting of rare events. Propensity scores deal with confounding in between person comparisons, whereas self controlled designs implicitly tackle time invariant confounding by making within person comparisons. It is important to note, however, that statistically controlling for confounding may not always be possible, even with propensity scores in studies with few participants.

In addition to the often small samples, studies of patient health outcomes in rare diseases using observational data face other important challenges. For example, there is often no appropriate group against which to compare outcome frequencies in patients with rare diseases and, even when there is, controlling for confounding can be difficult because the risk factors of those outcomes are usually not well understood. Yet, little work has been done to develop or apply methods to directly deal with these challenges. We did not identify any novel observational methods that have been developed to study outcomes in rare diseases. As observational data on rare diseases become more ubiquitous, greater attention is needed on methods to analyze these data to validly evaluate health outcomes in patients with rare diseases.

---

### Causal inference in health and disease: a review of the principles and applications of mendelian randomization [^111WeLg3]. Journal of Bone and Mineral Research (2024). Medium credibility.

Conclusions

MR studies can complement conventional epidemiological methods to enable researchers to infer causal effects in health and disease. Novel approaches to MR analyses are actively evolving and can provide insights into disease pathophysiology by overcoming many of the limitations that surround observational and interventional methods. However, despite the benefits that MR can confer, MR is subject to limitations and evaluating the assumptions made is crucial when performing and interpreting MR studies.

---

### An official American Thoracic Society workshop report: translational research in rare respiratory diseases [^113qEEh8]. Annals of the American Thoracic Society (2017). Medium credibility.

Preclinical models and mechanisms — preclinical cell-based and animal models are a crucial component of the translational research pipeline and can be employed to test mechanistic hypotheses from clinical observations, discover new mechanisms of disease initiation, susceptibility, or progression, conduct screens for novel therapies, and identify or validate biomarkers while testing therapeutic approaches; these models can also incorporate environmental factors that interact with genetic determinants.

---

### Important role of translational science in rare disease innovation, discovery, and drug development [^1159J3zB]. Journal of General Internal Medicine (2014). Low credibility.

Rare diseases play a leading role in innovation and the advancement of medical and pharmaceutical science. Most rare diseases are genetic disorders or atypical manifestations of infectious, immunologic, or oncologic diseases; they all provide opportunities to study extremes of human pathology and provide insight into both normal and aberrant physiology. Recently, drug development has become increasingly focused on classifying diseases largely on genetic grounds; this has allowed the identification of molecularly defined targets and the development of targeted therapies. Clinical trials are now focusing on progressively smaller subgroups within both common and rare disease populations, often based on genetic tests or biomarkers. Drug developers, researchers, and regulatory agencies face a variety of challenges throughout the life cycle of drug research and development for rare diseases. These include the small numbers of patients available for study, lack of knowledge of the disease's natural history, incomplete understanding of the basic mechanisms causing the disorder, and variability in disease severity, expression, and course. Traditional approaches to rare disease clinical research have not kept pace with advances in basic science, and increased attention to translational science is needed to address these challenges, especially diagnostic testing, registries, and novel trial designs.

---

### The international rare diseases research consortium: policies and guidelines to maximize impact [^112W8PUB]. European Journal of Human Genetics (2017). Low credibility.

Natural history

Performing natural history studies will facilitate the identification of disease characteristics that can be used when planning and conducting clinical investigations for rare disease therapies. Moreover, this knowledge will also serve to define a trial's target population, develop biomarkers for disease progression and therapeutic response, determine appropriate surrogate and relevant clinical endpoints, and decide on the study duration. As rare diseases are highly diverse in nature, there is no one set of data elements that can be recommended for data collection in all natural history rare disease studies; rather the disease characteristics should reflect the prominent features of the rare disease.

Therapeutics

Clinical trials represent a major challenge for the development of therapies intended to treat, cure, or prevent rare diseases. It is well recognized that clinical investigation in this field is associated with several hurdles that may jeopardize the performance of these investigations, when compared with common diseases. Small patient populations, together with geographical dispersion, add complexity to the design and performance of trials aimed at providing efficacy and safety information supporting a marketing authorization/approval of these therapies. However, introduction of rare diseases legislation and orphan designation procedures have brought a large number of investigational products into the development pipeline. Combined efforts are required of investigators, industry, patients' representatives, research institutions, and regulatory authorities to overcome all bottlenecks associated with clinical trials in low-prevalence conditions. Among the incentives provided by orphan designations, protocol assistance and scientific advice from regulatory bodies play a key role in guiding the conduct of studies to address the benefit/risk analysis for marketing authorization and approval. Thanks to these strategies, in the US, 47% and 41% of novel drugs approved by the Food and Drug Administration (FDA) in 2015 and 2016, respectively, were for rare indications. The trend observed in the success rates of clinical development between 2006 and 2015 in the US shows higher rates of approval for orphan products moving on from one phase of clinical studies to another when compared to drugs for chronic conditions.

Models

Currently, we only understand the biological function of a fraction of human genes. Animal and cellular models, including humanized models, provide insight into the function of genes and the mechanisms underlying rare diseases can be manipulated experimentally much more readily than humans for both ethical and technical reasons, allowing important questions that cannot be addressed in patients to be approached. Model systems enable experimental interventions that can establish causal mechanisms of gene action, thereby putting disease genes into biological context and can yield pathologic insight that facilitates the development of targeted therapeutics.

---

### Toward proof of concept of a one health approach to disease prediction and control [^1159JDK6]. Emerging Infectious Diseases (2013). Low credibility.

Discussion

This review of proof of concept for the One Health approach to emerging disease threats provides evidence that transdisciplinary integration among the sectors of human, animal, and environmental health is feasible. Our Working Group also found that simultaneously considering human, animal, and environmental health aspects when attempting to predict and control infectious pathogens and toxic hazards as well as chronic disease risks is beneficial.

Our findings of the feasibility of intersectoral cooperation efforts between human, animal, and environmental health professionals is consistent with recent international policy recommendations for better horizontal integration of such efforts. Our finding of evidence in support of a One Health approach to disease prediction based on linking human, animal, and environmental data supports a National Academies report on the need for integrated surveillance to detect emerging global infectious disease threats. Although animals can clearly serve as sentinels for human health hazards in the environment, cases of disease in humans can also indicate increased risk for animals. A study of the spread of pandemic influenza A(H1N1)2009 virus found that human cases in a country preceded animal outbreaks, indicating "reverse zoonotic" transmission of the virus and that human cases can serve as sentinels for animal risk. Integrated disease surveillance could therefore help identify infectious disease risk to human and animal populations.

Similarly, our findings of successful intervention studies that involve human, animal, and environmental health in the intervention and outcome assessments raise the possibility that such approaches could be successful in the long run and more sustainable than disease prevention projects with a more human-centric focus. At the same time, our search of the literature found only a small number of either disease prediction or intervention studies that simultaneously tracked outcomes in humans, animals, and the environment and that seemed to consider the underlying environmental factors affecting humans and animals. Of note, none of the intervention studies (or prediction studies) that the Working Group identified specifically mentioned a One Health approach in their methods. This finding is understandable because the widespread consideration of this approach is relatively recent. However, the fact that the term is not yet in wide use might have limited the ability of our literature search to identify additional studies.

---

### Observational research methods. research design II: cohort, cross sectional, and case-control studies [^1164kQdp]. Emergency Medicine Journal (2003). Low credibility.

Cohort, cross sectional, and case-control studies are collectively referred to as observational studies. Often these studies are the only practicable method of studying various problems, for example, studies of aetiology, instances where a randomised controlled trial might be unethical, or if the condition to be studied is rare. Cohort studies are used to study incidence, causes, and prognosis. Because they measure events in chronological order they can be used to distinguish between cause and effect. Cross sectional studies are used to determine prevalence. They are relatively quick and easy but do not permit distinction between cause and effect. Case controlled studies compare groups retrospectively. They seek to identify possible predictors of outcome and are useful for studying rare diseases or outcomes. They are often used to generate hypotheses that can then be studied via prospective cohort or other studies.

---

### Innovative research methods for studying treatments for rare diseases: methodological review [^111KPizQ]. BMJ (2014). Excellent credibility.

A third approach to the sample size problem is to build networks to allow broader access to trials. Development of clinical trial networks for rare diseases can facilitate the conduct of multicenter and even multinational randomized trials. Trial networks facilitate the recruitment of larger and more geographically diverse patient populations than may be permitted by single center studies. The existence of such networks can also decrease the time required to complete a trial. For example, Goss and colleagues provide a comprehensive overview of clinical trial networks for rare diseases in the context of the Cystic Fibrosis Therapeutics Development Network.

Finally, we found investigators who proposed and used novel trial design strategies to account for small pools of patients with rare diseases. Trials featuring an "adaptive design" allow modification of some aspects of the trial based on prospectively planned interim data analyses. The two basic types of adaptive designs are adaptive randomization and sequential trials. In trials using adaptive randomization, the probability of being randomized to an intervention changes during the enrollment period. The goal of adaptive randomization may be to minimize imbalance in baseline covariates among treatment groups (covariate-adaptive randomization) or to increase the proportion of patients assigned to the seemingly more effective treatment while reducing overall trial enrollment (response-adaptive randomization). By contrast, in sequential trials, data are analyzed intermittently to guide decisions on termination when safety concerns, futility, efficacy, or a combination of these factors is demonstrated. Trials that are stopped early because of important interim results require fewer patients. However, to control for multiple testing, trials that are not stopped early generally require larger sample sizes compared with similarly designed non-sequential trials. Chow and colleagues, Gupta and colleagues, and Cornu and colleagues have all summarized adaptive and sequential design methods in clinical trials and provide examples of applications to rare diseases. Gupta and colleagues also provide a framework for selecting among these approaches for studies of rare diseases.

---

### Getting from genes to function in lung disease: a National Heart, Lung, and Blood Institute workshop report [^1153Bpwr]. American Journal of Respiratory and Critical Care Medicine (2010). Low credibility.

Genome-wide association studies (GWAS) have revealed novel genes and pathways involved in lung disease, many of which are potential targets for therapy. However, despite numerous successes, a large proportion of the genetic variance in disease risk remains unexplained, and the function of the associated genetic variations identified by GWAS and the mechanisms by which they alter individual risk for disease or pathogenesis are still largely unknown. The National Heart, Lung, and Blood Institute (NHLBI) convened a 2-day workshop to address these shortcomings and to make recommendations for future research areas that will move the scientific community beyond gene discovery. Topics of individual sessions ranged from data integration and systems genetics to functional validation of genetic variations in humans and model systems. There was broad consensus among the participants for five high-priority areas for future research, including the following: (1) integrated approaches to characterize the function of genetic variations, (2) studies on the role of environment and mechanisms of transcriptional and post-transcriptional regulation, (3) development of model systems to study gene function in complex biological systems, (4) comparative phenomic studies across lung diseases, and (5) training in and applications of bioinformatic approaches for comprehensive mining of existing data sets. Last, it was agreed that future research on lung diseases should integrate approaches across "-omic" technologies and to include ethnically/racially diverse populations in human studies of lung disease whenever possible.

---

### Epidemiological methods for studying genes and environmental factors in complex diseases [^113DszLC]. Lancet (2001). Excellent credibility.

Exploration of the human genome presents new challenges and opportunities for epidemiological research. Although the case-control design is quicker and cheaper for study of associations between genotype and risk of disease than the cohort design, cohort studies have been recommended because they can be used to study gene-environment interactions. Although the scientific relevance of statistical interaction is pertinent, the main disadvantage of the case-control design-susceptibility to bias when estimating effects of exposures that are measured retrospectively-does not necessarily apply when studying statistical interaction between genotype and environmental exposure. Because correctly designed genetic association studies are equivalent to randomised comparisons between genotypes, conclusions about cause can be drawn from genetic associations even when the risk ratio is modest. For adequate statistical power to detect such modest risk ratios, the case-control design is more feasible than the cohort design.

---

### A precision environmental health approach to prevention of human disease [^1158cb5q]. Nature Communications (2023). High credibility.

Data science approaches

Advancing risk stratification and disease prevention using genomic, epigenomic, exposomic, proteomic, and metabolomic data will require data science approaches that integrate large datasets across multi-omic platforms. In this regard, artificial intelligence, which includes machine learning (ML) and natural language processing, can identify patterns in complex multidimensional datasets that include measurements of environmental exposures, and then apply that knowledge to identify individuals or populations most at-risk for adverse outcomes. ML is particularly well suited to unlocking knowledge and detailed information from semi-structured or unstructured data for precision environmental health, because time-dependent and high-throughput genome-scaled data types, such as epigenomic, transcriptomic, proteomic, or metabolomic data, are similar in structure. Some approaches are completely data-driven, only making the general assumption that the data will identify subgroups of individuals with characteristics of interest. For instance, ML approaches can help to differentiate cases and controls or to identify individuals with higher exposures and/or at increased risk of developing a certain disease. Hence, ML may reveal patterns that can inform personalized approaches that might not be discoverable using traditional statistical techniques.

Because precision environmental health adds another dimension — the environment — to already high-dimensional data, robust data science approaches become even more critical to tease out the impacts of environmental exposures and develop approaches for risk stratification. As environmental exposures can affect biological processes at many different levels that contribute to disease, integrating multi-omic inputs in precision environmental health research can yield more comprehensive and accurate insights into how exposures impact health, for example, by moving beyond phenotype to endotype, (Box 3). Approaches that allow for modeling the interactions among different "omic" data, such as the "interactome", which uses a more multi-axial systems approach to identify the relevant networks that underlie environmental-driven diseases, may provide additional advantages. Incorporating mechanistic understandings of how exposures contribute to disease, their associated molecular responses (endotypes), and "omic-based" determinants of disease risk, will enable the identification of target populations and individuals who will most benefit from targeted interventions — enabling a precision approach to disease prevention.

---

### Addressing sex as a biological variable in preclinical models of lung disease: an official American Thoracic Society research statement [^115yZz9Q]. American Journal of Respiratory and Critical Care Medicine (2025). High credibility.

Conclusions on SABV in preclinical lung disease research — females and males have variable manifestations of major acute and chronic lung diseases across the life course, and study designs need to include experimental approaches that support the disaggregation of data by sex and investigate the role of sex chromosomes and gonadal influences. Preclinical and in vitro models of lung diseases have been critical for understanding pathophysiology, but modeling sex differences in pulmonary processes has lagged and lacked rigor, and careful study design focused on powered analyses in a 2 × 2 factorial design may yield the most detailed data to address outcomes between treated vs. controls, males vs. females, and interactions between biological sex and interventions. This research statement has provided support that SABV needs to be considered in preclinical and cellular models of lung diseases, and standardized approaches to experimental design and reporting of sex differences are integral for accelerating the discovery for all pulmonary diseases.

---

### Adding flexibility to clinical trial designs: an example-based guide to the practical use of adaptive designs [^112tYXnh]. BMC Medicine (2020). Medium credibility.

Conclusions

Research into adaptive designs has become more prevalent across all stages of clinical development, although this increase is not necessarily reflected by their uptake in practice. The suitability of adaptive methods depends largely on the clinical question being addressed. We have presented four key clinical questions for which adaptive designs may be of use across a wide range of disease areas, study settings, and endpoints. For each possible design, there are advantages and disadvantages with some key themes: increase in efficiency of the design in terms of the expected number of patients or a clear benefit in understanding the question of scientific interest, clear ethical advantages to ensuring the right patients are given the best available treatment whenever possible, and the key disadvantage is the additional burden, both in planning the trial and the interim analyses. Importantly, while the adaptive methods can be highly effective when used in the correct scenario, an adaptive method is not always the best choice, so careful consideration must be taken before their use.

At the design stage of any trial (adaptive or not), some design assumptions must be made. These will influence the performance of the trial and inadequate assumptions can lead to a sub-optimal design. With the additional complexity of many adaptive designs, there are more assumptions to be made and it is critical that these are well understood by the trial team to consider the impact of these choices, although for a corresponding fixed sample design many of these assumptions must be made anyway. As noted in the "Summary" of the "Does the treatment work?" section, many such problems have been well worked out for group sequential designs and are not insurmountable for the other designs discussed. Communication and establishing a common practice between the methodology and trial community will be key in seeing the wider spread application of such methods.

---

### Telomere length and common disease: study design and analytical challenges [^114uDDLg]. Human Genetics (2015). Low credibility.

Conclusions

The observed associations between TL and the risk of many different diseases suggest a role that is fundamental to health at the level of the cell and the organism. However, despite these strong associations, it is still unclear whether TL is itself causal or is a biomarker of underlying disease-related mechanisms. Interventions aimed at increasing TL for the purpose of halting or reversing the ageing process or preventing disease, are thus not supported by current evidence. Even as a biomarker of disease, TL does not currently have clinical utility in a population setting; associations with disease are complex, TL alone is not sufficiently predictive of risk and is subject to considerable measurement error. As understanding develops and evidence accumulates, TL may in the future provide a useful biomarker of risk or of disease progression.

Ideally, large prospective studies would be conducted with longitudinal measures of TL, extensive genotyping and detailed measures of phenotype and exposure to further understanding of the relationship with health. Since the measurement of TL is unstable, a key requirement is that sample collection and processing should be as uniform as possible. Such prospective studies would allow investigation of the relationship between genetic predictors of TL on disease risk, while adjusting for measured TL.

Further insights are also needed into telomere biology. It seems likely that the sole focus on TL, rather than other features of telomere maintenance and stability, is too simplistic. Similarly, the assumption that leukocyte TL is reflected in disease-relevant tissue needs further investigation, and consideration should be given to measuring TL at more than one time point. The observation that longer telomeres are associated with greater risk of some cancers also complicates the prevailing view that longer telomeres are always advantageous.

Large-scale prospective studies of disease that consistently and reliably measure TL are rare and expensive to conduct. However, large-scale datasets specifically designed to study the relationship between germline variation and disease risk have been established for most common disorders. The majority of these will not be suitable for the measurement of TL, given the sensitivity of TL measurement to sample handling and the variability of TL over time. Thus, at least until more reliable cost-effective methods of TL measurement become available, one of the most promising approaches to understanding the relationship between telomere features and disease is to study the genetic factors that underlie them.

---

### Estimating disease prevalence in large datasets using genetic risk scores [^113Vzbos]. Nature Communications (2021). High credibility.

Introduction

The development and refinement of polygenic analysis techniques is greatly increasing our understanding of many diseases. Using polygenic risk has allowed insights into disease etiology and through Mendelian randomization evaluation of causality. Clinically, capturing polygenic susceptibility through genetic risk scores (GRS) can be used to determine individuals at the highest risk of a disease –. This paper concentrates on an innovative use of polygenic risk to genetically estimate disease prevalence (proportion of individuals with and without a disease) within a cohort. Currently estimating disease prevalence is difficult as it requires robust clinical classification. Disease-specific investigations are rarely available in population-level data and inaccuracies associated with self-reported diagnosis are well recognized. Given the increasing availability of population-level genetic data, novel polygenic estimates of disease prevalence are an extremely attractive alternative.

The basis of genetically determining disease prevalence is fundamentally that the distribution of a specific disease GRS within a cohort will reflect the mixture of GRS of those with the disease (cases) and those without (non-cases). This mixture GRS distribution will lie between reference groups of cases and non-cases and will reflect the relative proportion of cases to non-cases (Fig. 1a). The location of the mixture cohort's GRS distribution in comparison to the GRS distribution of known cases and non-cases allows the respective proportion of each group to be determined which provides a genetic-based estimate of disease prevalence. Furthermore, using the genetically calculated proportion of a disease within a cohort allows the additional benefit of associated clinical features of the genetically defined disease cohort to be determined. It is worth emphasising that in almost all polygenic risk situations, even those at the highest genetic risk are unlikely to develop the relevant disease and therefore this concept does not remain valid at an individual level. Nonetheless, at a group level the average GRS will be higher in a cohort with disease versus those without.

---

### A weighted cohort approach for analysing factors modifying disease risks in carriers of high-risk susceptibility genes [^1161V5rx]. Genetic Epidemiology (2005). Low credibility.

The authors propose a novel approach to evaluate the effects of risk factors on disease risks in carriers of high-penetrance alleles in disease susceptibility genes. Most studies to date have utilised data collected on carriers identified through ongoing genetic testing programs. The advantage of this approach is that it allows relatively large numbers of affected and unaffected carriers to be identified rapidly. However, genetic testing is targeted at individuals with a strong family history of disease, so that the selection of carriers is not random with respect to disease status. Risk factors are often analysed by standard cohort analysis methods, but these can be biased in retrospective studies if subjects are selected on the basis of phenotype. To overcome this problem, a weighted cohort approach is proposed, under which individuals are weighted according to certain sampling probabilities in order to mimic a true cohort. The method is illustrated by analyses of data from the International BRCA1/2 Carrier Cohort Study (IBCCS). Simulations demonstrate that the method gives rate ratio estimates that are close to unbiased provided that the absolute disease risks are well estimated. The power to detect associations is, however, reduced compared with an unweighted approach.

---

### Disease proteomics [^112R9Y8F]. Nature (2003). Excellent credibility.

The sequencing of the human genome and that of numerous pathogens has opened the door for proteomics by providing a sequence-based framework for mining proteomes. As a result, there is intense interest in applying proteomics to foster a better understanding of disease processes, develop new biomarkers for diagnosis and early detection of disease, and accelerate drug development. This interest creates numerous opportunities as well as challenges to meet the needs for high sensitivity and high throughput required for disease-related investigations.

---

### Reconstructing disease dynamics for mechanistic insights and clinical benefit [^1176koi8]. Nature Communications (2023). High credibility.

Introduction

Diseases are dynamic processes encompassing a multitude of changes. These range from intra-cellular molecular states, such as those occurring following cellular differentiation or activation, to changes in systemic molecular, cellular and physiological states. Identifying the underlying dynamics of diseases at high-resolution enables their quantitative comparison and is critical for designing novel preventive and therapeutic strategies to improve health. Time-series experimental designs provide an opportunity for studying disease dynamics and the variability across patients. However, while disease progression rate is patient-specific, time-series data is usually collected at fixed intervals. This reduces the efficiency of comparing progression dynamics when using time as a predictive variable and forces the clustering of data from different time points to obtain some level of shared dynamics (Fig. 1A). Such attempts are further confounded by the fact that disease progression dynamics are often orchestrated by multiple biological processes simultaneously, requiring modeling to be performed in a high dimensional space. Dimensionality reduction methods, such as Principal Component Analysis (PCA), Factor Analysis (FA), as well as state-of-the-art trajectory inference methods such as diffusion maps (DMs), may be driven by time-independent variation, yielding low interpretability and making the inference of patients' disease progression dynamics non trivial. Recent advances in this area focused on the calculation of differentially expressed features over time, but only when comparing extreme states, such as disease versus controls, rather than describing the global dynamics of the disease. Therefore, forming a model for disease progression remains challenging, even when large time-series data are available.

---

### Challenges and opportunities in understanding genetics of fungal diseases: towards a functional genomics approach [^115ZqGCf]. Infection and Immunity (2021). Medium credibility.

Infectious diseases are a leading cause of morbidity and mortality worldwide, and human pathogens have long been recognized as one of the main sources of evolutionary pressure, resulting in a high variable genetic background in immune-related genes. The study of the genetic contribution to infectious diseases has undergone tremendous advances over the last decades. Here, focusing on genetic predisposition to fungal diseases, we provide an overview of the available approaches for studying human genetic susceptibility to infections, reviewing current methodological and practical limitations. We describe how the classical methods available, such as family-based studies and candidate gene studies, have contributed to the discovery of crucial susceptibility factors for fungal infections. We will also discuss the contribution of novel unbiased approaches to the field, highlighting their success but also their limitations for the fungal immunology field. Finally, we show how a systems genomics approach can overcome those limitations and can lead to efficient prioritization and identification of genes and pathways with a critical role in susceptibility to fungal diseases. This knowledge will help to stratify at-risk patient groups and, subsequently, develop early appropriate prophylactic and treatment strategies.

---

### Applying the dissemination and implementation sciences to allergy and immunology: a Work group report from the AAAAI quality, adherence, and outcomes committee [^113CK5fQ]. The Journal of Allergy and Clinical Immunology (2024). High credibility.

Approaches to study design in dissemination and implementation (D&I) research are 'broadly categorized as observational, experimental, quasi-experimental, hybrid, and pragmatic trial designs'. In observational designs, studies 'focus on collecting data, often utilizing both qualitative and quantitative approaches, to identify the barriers and facilitators influencing an implementation strategy's efficacy and use'. In experimental designs, 'either an intervention or implementation strategy is tested in a randomized, controlled approach', with the stepped wedge design described as 'dividing intervention sites into equal numbers (or wedges) and then randomly allocating each wedge to a time period for the same intervention delivery'. When randomization is infeasible, 'investigators can use quasi-experimental designs that use statistical methods to minimize bias'.

---

### Population-based cohort studies: still relevant? [^1113ZAoR]. Journal of the American College of Cardiology (2011). Low credibility.

This commentary discusses the question whether observational epidemiology studies using a population-based cohort design continue to make an impact on the prevention and treatment of cardiovascular disease. Although these studies are large and comprehensive, have they advanced from the early recognition of traditional risk factors to become relevant in the current complex research environment? Five themes are discussed: 1) their role in scientific discovery, including in the context of clinical trials' role in interventional research; 2) their value in encompassing diverse ethnic and age groups to remain relevant to the changing diversity of the United States; 3) the research potential of combining these datasets into large consortia; 4) the ability to use advances in biomedical research technologies; and 5) the recognition that these are national resources that allow outside research community to analyze the collected data and to originate novel ancillary studies. The National Heart, Lung, and Blood Institute longitudinal cohort studies offer opportunities that hold great promise in improving evaluation of personal risk, identifying mechanisms of disease, and directing potential targets for behavior and medical interventions.

---

### Disease coverage of human genome-wide association studies and pharmaceutical research and development [^114CMtnf]. Communications Medicine (2024). Medium credibility.

Background

Despite the growing interest in the use of human genomic data for drug target identification and validation, the extent to which the spectrum of human disease has been addressed by genome-wide association studies (GWAS), or by drug development, and the degree to which these efforts overlap remain unclear.

Methods

In this study we harmonize and integrate different data sources to create a sample space of all the human drug targets and diseases and identify points of convergence or divergence of GWAS and drug development efforts.

Results

We show that only 612 of 11,158 diseases listed in Human Disease Ontology have an approved drug treatment in at least one region of the world. Of the 1414 diseases that are the subject of preclinical or clinical phase drug development, only 666 have been investigated in GWAS. Conversely, of the 1914 human diseases that have been the subject of GWAS, 1121 have yet to be investigated in drug development.

Conclusions

We produce target-disease indication lists to help the pharmaceutical industry to prioritize future drug development efforts based on genetic evidence, academia to prioritize future GWAS for diseases without effective treatments, and both sectors to harness genetic evidence to expand the indications for licensed drugs or to identify repurposing opportunities for clinical candidates that failed in their originally intended indication.

---

### Dietary patterns, insulin resistance, and incidence of type 2 diabetes in the whitehall II study [^115kNTqX]. Diabetes Care (2008). Low credibility.

The worldwide prevalence of type 2 diabetes is alarmingly high. Diabetes is an important cause of morbidity and a major risk factor for cardiovascular disease. Dietary intake is a potentially modifiable risk factor, and although there is convincing evidence for the role of excess calorie intake in the development of type 2 diabetes, the evidence surrounding other diet-related risk factors is far less complete or convincing. Further research is required to identify optimal eating patterns for the prevention of type 2 diabetes and provide the evidence base for dietary targets.

In much of the work surrounding diet and chronic disease, a single nutrient approach has been adopted. Increasingly, dietary patterns are thought to be important determinants of chronic disease. A dietary patterns approach recognizes that foods are consumed in many complex combinations and that nutrients may have interactive and synergistic effects.

Approaches to studying dietary patterns fall into two categories, using either dietary scores determined by a priori dietary guidelines or multivariate statistical techniques. To date, multivariate statistical approaches have tended to use factor and cluster analysis techniques. However, a new approach to dietary pattern analysis has emerged that combines multivariate approaches with existing knowledge of diet-disease relationships. In reduced rank regression (RRR) analysis, variations in food intake are used to predict intermediate outcomes such as nutrient intakes, biomarkers of intakes, or biomarkers of the disease process and subsequently relationships between the identified dietary patterns and disease are investigated. This approach has been used to study obesity, diabetes, cardiovascular disease, and all-cause mortality. Previous studies of type 2 diabetes and dietary patterns using RRR relied on self-report of diabetes status without an oral glucose tolerance test (OGTT) to identify incident disease.

The aim of this study was to identify a dietary pattern using RRR that is associated with insulin resistance, a phenotype closely associated with development of type 2 diabetes, and, subsequently, to investigate the prospective association between the dietary pattern and disease.

---

### Formulating the future research agenda for postexposure prophylaxis for HIV: methodological challenges and potential approaches [^116zddju]. Clinical Infectious Diseases (2015). Low credibility.

Background

During a World Health Organization-convened Guideline Development Group meeting, recommendations for postexposure prophylaxis (PEP) for human immunodeficiency virus were made and research gaps identified.

Methods

We used the PEP clinical management pathway and the Grading of Evidence, Assessment, Development and Evaluation (GRADE) system as a framework to formulate future research questions, describe the most feasible study design, and identify potential biases.

Results

Three key study design formats were identified to address 12 research questions: (1) survey- and interview-driven research to identify barriers to access to PEP and related clinical care; (2) establishment of a global PEP registry to generate data to inform the choice of an optimal PEP drug regimen, record drug toxicities arising from specific PEP regimens, and track follow-up and linkage to care (including transition from PEP to preexposure prophylaxis); and (3) randomized controlled trials to determine the optimal adherence promotion strategies necessary for successful outcomes following PEP.

Conclusions

Positioning key clinical and programmatic research questions within the GRADE framework facilitates the formulation of an evidence-based research agenda and future revisions of guidelines.

---

### Quantification of lung PET images: challenges and opportunities [^113KUeBy]. Journal of Nuclear Medicine (2017). Low credibility.

Millions of people are affected by respiratory diseases, leading to a significant health burden globally. Because of the current insufficient knowledge of the underlying mechanisms that lead to the development and progression of respiratory diseases, treatment options remain limited. To overcome this limitation and understand the associated molecular changes, noninvasive imaging techniques such as PET and SPECT have been explored for biomarker development, with 18 F-FDG PET imaging being the most studied. The quantification of pulmonary molecular imaging data remains challenging because of variations in tissue, air, blood, and water fractions within the lungs. The proportions of these components further differ depending on the lung disease. Therefore, different quantification approaches have been proposed to address these variabilities. However, no standardized approach has been developed to date. This article reviews the data evaluating 18 F-FDG PET quantification approaches in lung diseases, focusing on methods to account for variations in lung components and the interpretation of the derived parameters. The diseases reviewed include acute respiratory distress syndrome, chronic obstructive pulmonary disease, and interstitial lung diseases such as idiopathic pulmonary fibrosis. Based on review of prior literature, ongoing research, and discussions among the authors, suggested considerations are presented to assist with the interpretation of the derived parameters from these approaches and the design of future studies.

---

### Study design and "evidence" in patient-oriented research [^112rbbGx]. American Journal of Respiratory and Critical Care Medicine (2013). Low credibility.

Individual studies in patient-oriented research, whether described as "comparative effectiveness" or using other terms, are based on underlying methodological designs. A simple taxonomy of study designs includes randomized controlled trials on the one hand, and observational studies (such as case series, cohort studies, and case-control studies) on the other. A rigid hierarchy of these design types is a fairly recent phenomenon, promoted as a tenet of "evidence-based medicine", with randomized controlled trials receiving gold-standard status in terms of producing valid results. Although randomized trials have many strengths, and contribute substantially to the evidence base in clinical care, making presumptions about the quality of a study based solely on category of research design is unscientific. Both the limitations of randomized trials as well as the strengths of observational studies tend to be overlooked when a priori assumptions are made. This essay presents an argument in support of a more balanced approach to evaluating evidence, and discusses representative examples from the general medical as well as pulmonary and critical care literature. The simultaneous consideration of validity (whether results are correct "internally") and generalizability (how well results apply to "external" populations) is warranted in assessing whether a study's results are accurate for patients likely to receive the intervention-examining the intersection of clinical and methodological issues in what can be called a medicine-based evidence approach. Examination of cause-effect associations in patient-oriented research should recognize both the strengths and limitations of randomized trials as well as observational studies.

---

### Confirmation of fixed quarterly riliprubart regimen in patients with cold agglutinin disease using population PK / PD and exposure-response analyses [^1145kuEb]. Clinical Pharmacology and Therapeutics (2025). Medium credibility.

Study Highlights

WHAT IS THE CURRENT KNOWLEDGE ON THE TOPIC?

Riliprubart, a second‐generation humanized immunoglobulin G4 that inhibits only the activated form of the C1s component of the proximal classical complement pathway, is currently in clinical development for complement‐mediated diseases.
WHAT QUESTION DID THIS STUDY ADDRESS?

Model‐informed drug development (MIDD) approaches were used to propose a dose regimen utilizing available clinical data. The safety, efficacy, and PK/PD were evaluated in 9 cold agglutinin disease patients.
WHAT DOES THIS STUDY ADD TO OUR KNOWLEDGE?

A fixed quarterly dose regimen was successfully proposed by MIDD approaches.
HOW MIGHT THIS CHANGE CLINICAL PHARMACOLOGY OR TRANSLATIONAL SCIENCE?

The use of MIDD approaches could lead to fewer subjects and improved efficiency for drug development, particularly in rare diseases. A fixed quarterly dosing regimen could benefit patients and healthcare providers.

---

### Clinical evidence 2030 [^113qBHvf]. Clinical Pharmacology and Therapeutics (2025). Medium credibility.

PRINCIPLE 3: EVIDENCE GAPS ARE FORMULATED IN CLEAR RESEARCH QUESTIONS THAT DRIVE THE CHOICE OF EVIDENCE GENERATION

A "research question"‐driven approach, clearly articulating one or several research questions, strengthens clinical evidence generation through optimal study design, particularly if supported by scientific advice that involves different stakeholder voices. This approach should drive the selection of the suitable study method, with some questions best answered through experiments (including clinical trials) and others through observations (including non‐interventional studies).

Scientific advice and regulatory support for research and development (R&D) are key to better evidence generation, and should be strengthened, further rationalized and simplified.

Different clinical research frameworks exist for the formulation of scientific research questions. These include the PICOT framework (Population‐Intervention‐Comparator‐Outcome‐Time), historically used in the field of pharmacoepidemiology research, and the Target Trial Emulation framework, which allows clear specification of the population, intervention, comparator, outcome and time horizon for the research. The increasing understanding and use of the Estimand framework, already used to optimize clinical trial design, complements existing frameworks by stimulating further specification of research questions through considerations of intercurrent events.

---

### Disease-targeted sequencing: a cornerstone in the clinic [^114peczz]. Nature Reviews: Genetics (2013). Medium credibility.

With the declining cost of sequencing and the ongoing discovery of disease genes, it is now possible to examine hundreds of genes in a single disease-targeted test. Although exome- and genome-sequencing approaches are beginning to compete, disease-targeted testing retains certain advantages and still holds a firm place in the diagnostic evaluation. Here I examine the current state of clinical disease-targeted sequencing and evaluate the benefits and challenges of incorporating sequencing tests into patient care.

---

### Case / control studies with follow-up: constructing the source population to estimate effects of risk factors on development, disease, and survival [^111S4xMX]. Clinical Infectious Diseases (2012). Low credibility.

If individuals in a case/control study are subsequently observed as a cohort of cases and a cohort of controls, weighted regression analyses can be used to estimate the association between the exposures initially recorded and events occurring during the follow-up of the 2 cohorts. Such analyses can be conceptualized as being undertaken on a reconstructed source population from which cases and controls stem. To simulate this population, the cohort of cases is added to the cohort of controls expanded with the reciprocal of the case disease incidence odds (the sampling weight) to include all individuals in the source population who did not develop the case disease. We use a simulated dataset to illustrate how weighted generalized linear model regression can be used to estimate the association between an exposure captured during the case/control study component and an outcome that occurs during follow-up.

---

### Summary benchmarks-full set – 2024 [^111fkzSC]. AAO (2024). High credibility.

Preferred Practice Pattern (PPP) guidelines — evidence grading and development describe that for each major disease condition, recommendations for the process of care, including the history, physical exam and ancillary tests, are summarized, and that for each PPP, a detailed literature search of PubMed and the Cochrane Library is conducted, with results reviewed by an expert panel and given a rating that shows the strength of evidence when sufficient evidence exists. To rate individual studies, a scale based on the Scottish Intercollegiate Guideline Network (SIGN) is used with levels: I++ high-quality meta-analyses, systematic reviews of randomized controlled trials (RCTs), or RCTs with a very low risk of bias; I+ well-conducted meta-analyses, systematic reviews of RCTs, or RCTs with a low risk of bias; I- meta-analyses, systematic reviews of RCTs, or RCTs with a high risk of bias; II++ high-quality systematic reviews of case-control or cohort studies; high-quality case-control or cohort studies with a very low risk of confounding or bias and a high probability that the relationship is causal; II+ well-conducted case-control or cohort studies with a low risk of confounding or bias and a moderate probability that the relationship is causal; II- case-control or cohort studies with a high risk of confounding or bias and a significant risk that the relationship is not causal; and III nonanalytic studies (e.g., case reports, case series).

---

### PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews [^1152pu9q]. BMJ (2021). Excellent credibility.

Objectives

Item 4. Provide an explicit statement of the objective(s) or question(s) the review addresses

Explanation: An explicit and concise statement of the review objective(s) or question(s) will help readers understand the scope of the review and assess whether the methods used in the review (such as eligibility criteria, search methods, data items, and the comparisons used in the synthesis) adequately address the objective(s). Such statements may be written in the form of objectives ("the objectives of the review were to examine the effects of… ") or as questions ("what are the effects of… ?").

Essential elements

Provide an explicit statement of all objective(s) or question(s) the review addresses, expressed in terms of a relevant question formulation framework (see Booth et aland Munn et alfor various frameworks).
If the purpose is to evaluate the effects of interventions, use the Population, Intervention, Comparator, Outcome (PICO) framework or one of its variants to state the comparisons that will be made.

Example of item 4 of PRISMA 2020 checklist

"Objectives: To evaluate the benefits and harms of down‐titration (dose reduction, discontinuation, or disease activity‐guided dose tapering) of anti‐tumour necrosis factor-blocking agents (adalimumab, certolizumab pegol, etanercept, golimumab, infliximab) on disease activity, functioning, costs, safety, and radiographic damage compared with usual care in people with rheumatoid arthritis and low disease activity".

---

### Institutionalising an evidence-informed approach to guideline development: progress and challenges at the World Health Organization [^112oQPWT]. BMJ Global Health (2018). Medium credibility.

Two design features of WHO's guideline development process seem to particularly need adaptation to fully incorporate the evidence base needed to inform recommendations. The first design feature is the use of systematic reviews to critically appraise relevant research underpinning WHO recommendations. Systematic reviews are among the cornerstones of guideline development processes and are critical for reducing the risk of bias and reaching reliable evidence-informed conclusions. By way of background, systematic reviews are commonly conducted by formulating a clear and specific question most commonly using the PICO format (population, intervention, comparison, outcome) and by having explicit inclusion/exclusion criteria. This rigorous approach helps to identify and include studies that are comparable and able to respond to questions about effectiveness of interventions (what works). This approach works sufficiently well for evaluating the effectiveness of a medical treatment. However, many health systems and public health interventions are 'complex' interventions, characterised by multiple interacting components, requiring the involvement of different organisational levels, having a number of different points of interactions between interventions and the settings in which the interventions are implemented and affecting different outcomes. For complex interventions, framing systematic review questions too narrowly and relying solely on assessing evidence of effectiveness risks excluding the broader range of relevant evidence needed to inform recommendations. This includes evidence for factors important for implementing an intervention, for bringing an intervention to scale, for assessing the resources needed to implement interventions across different settings, for understanding the feasibility and acceptability of an intervention, for identifying the interactions among various components of complex interventions and for probing the systems in which the interventions were implemented. These represent factors that are not easily identifiable if systematic review questions are narrow and solely include experimental intervention studies focused on safety and effectiveness. Currently, the WHO Handbook for Guideline Development do not offer comprehensive guidance for adapting the PICO format or considering alternative frameworks when dealing with systematic reviews for health systems and public health interventions. In light of new tools and frameworks for conducting systematic reviews for complex interventions, WHO might consider adapting its guidance.

---

### Epidemiology and clinical research design, part 1: study types [^116euxvN]. NeoReviews (2014). Low credibility.

Selecting the best available preventive and therapeutic measures to avoid disability and death is an important goal for all health care practitioners. To achieve this goal, we need to perform studies that determine the value of these measures. In this article, we discuss the possible study designs that can be used for evaluating new approaches to prevention and treatment. The gold standard study design is a randomized, controlled, double-blind trial. In many instances, a randomized controlled trial may not be ethically or practically feasible. Other study types, such as case series, case-control studies, cohort studies, cross-sectional studies, crossover designs, and open-label studies, may be required to hypothesize and evaluate the link between an exposure or predictor variable and an outcome variable. Various study types pertaining to neonatal-perinatal medicine are reviewed in this article.

---

### Research techniques made simple: an introduction to qualitative research [^1113x4hM]. The Journal of Investigative Dermatology (2021). Medium credibility.

Qualitative research has gained increasing prominence in health-related research and is experiencing greater use in dermatology. A major strength of and reason to perform qualitative research is that it allows one to gain an understanding of the insider (e.g., patient, medical provider, other players in the healthcare system) perspectives on health and insights about their behaviors, motivations, and expectations. This is particularly important in the field of dermatology where most diseases are, fortunately, not directly fatal but have major effects on affected individuals' lives in ways that are often not readily quantifiable. As such, it is important for dermatologists, both researchers and clinicians, to understand the basic tenets of qualitative methodology to properly utilize qualitative methods, evaluate the qualitative literature, and identify relevant findings to apply to clinical practice. In this article, we provide an overview of qualitative research and some of the more commonly used qualitative methods with an aim to increase awareness and appreciation of the power of qualitative studies.

---

### An official American Thoracic Society workshop report: translational research in rare respiratory diseases [^113UHZP1]. Annals of the American Thoracic Society (2017). Medium credibility.

Preclinical models — key messages and challenges in RRDs indicate that preclinical cell-based and animal models are critical to the translational pipeline, that new technologies, improved design, and incorporation of chronicity can strengthen models even if they do not precisely replicate human disease, and that induced pluripotent stem cells and in vivo lineage tracking are promising for early pathogenesis; challenges include developing appropriate models for genetic and environmental effects, establishing integrated translational platforms, and formulating standard protocols and endpoints for rapid regulatory assessment into human trials.

---

### Prospects of disease-modifying osteoarthritis drugs [^116CdCxz]. Rheumatic Diseases Clinics of North America (2024). Medium credibility.

Osteoarthritis (OA) causes a massive disease burden with a global prevalence of nearly 23% in 2020 and an unmet need for adequate treatment, given a lack of disease-modifying drugs (DMOADs). The author reviews the prospects of active DMOAD candidates in the phase 2/3 clinical trials of drug development pipeline based on key OA pathogenetic mechanisms directed to inflammation-driven, bone-driven, and cartilage-driven endotypes. The challenges and possible research opportunities are stated in terms of the formulation of a research question known as the PICO approach: (1) population, (2) interventions, (3) comparison or placebo, and (4) outcomes.

---

### Systems approaches to studying the immune response in tuberculosis [^112SPch8]. Current Opinion in Immunology (2013). Low credibility.

Tuberculosis (TB) remains a disease of considerable mortality and morbidity. Studies employing microarrays to derive transcriptional profiles of the host response during TB, which combined with data from experimental systems have highlighted a potentially detrimental role for type I interferons during infection, with important implications for vaccine and therapeutic development. In addition, these studies have provided candidate biomarkers which may advance diagnosis and treatment monitoring. These studies thus exemplify the promise of a systems biology approach to study complex infectious disease such as TB.

---

### Applying the dissemination and implementation sciences to allergy and immunology: a Work group report from the AAAAI quality, adherence, and outcomes committee [^117Mk9Hc]. The Journal of Allergy and Clinical Immunology (2024). High credibility.

Dissemination and implementation (D&I) sciences in allergy and immunology emphasize that "Goals of the D&I sciences are to spread EBP and inform strategies promoting the uptake of scientific discoveries and to translate clinical guidelines into real-world clinical settings", and "The D&I sciences provide us with comprehensive approaches that prioritize intervention efficacy, fidelity, sustainability, and health equity as we translate EBP for asthma, allergy, and immunologic diseases into real-world clinical settings". Practical study guidance includes that "A useful process in conducting such studies is to start with a planning phase inclusive of a systematic analysis of the clinical gap of care", with "Convening a multidisciplinary study team as well as a scientific advisory board inclusive of health organizational leadership and community advisors is a critical initial step", followed by "Subsequent study progression would involve careful consideration of research design, the D&I framework, and study sites" and "Research results should be adapted to inform future implementation strategy — and, when appropriate, the development of consistent local or national policy". For end users, "For clinicians, policy leaders, health care systems, and other partners, the findings of D&I research offer strategies to improve delivery of evidence-based asthma, allergy, and immunology care", and "Allergists and immunologists should be receptive to practice changes based on findings from D&I studies and should leverage this area of research to develop and adapt health care interventions". The report underscores equity and capacity building: "While the D&I sciences can provide effective tools to address health inequities, careful study of the contextual factors leading to a specific disparity is important and can be achieved through community collaboration and effective stakeholder engagement", and "Increasing grant support, improving training opportunities, and emphasizing the need to broaden research networks to include implementation scientists and health disparities researchers will further promote translation of EBP, thereby promoting health equity and a future evolution of the D&I sciences in allergy and immunology". It also cautions that "For the D&I sciences, a study's cost could be high if multiple sites are involved, and it may be complicated by competing operational costs and pressures from health systems when conducting research in real-world settings", and calls for methodological rigor: "To effectively achieve this, we, as a scientific community, need to understand and apply scientific methodologies as we study how clinicians, patients, communities, and health care systems use EBP in their everyday lives".

---

### Evaluating agreement between bodies of evidence from randomized controlled trials and cohort studies in medical research: a meta-epidemiological study [^117PCAHG]. BMC Medicine (2022). Medium credibility.

Potential implications

RCTs are considered the gold standard to evaluate causal inference for medical interventions. Due to a variety of reasons such as low external validity and limited availability of RCTs, health care professionals and other decision-makers increasingly rely on results from observational studies. However, results from RCTs and observational studies can differ and efforts to understand under which circumstances this occurs are ongoing. Our study provides valuable insights into the field of general and internal medicine, but also into other important research fields such as public health. We showed that BoE from RCTs and cohort studies included in systematic reviews from high-impact factor medical journals often differ in terms of study populations (e.g. different disease status), interventions and comparators (e.g. different intervention-timing, different drugs of the same class), or outcomes (e.g. late-stage disease versus any disease). Our data highlight the importance of PI/ECO-differences — especially those of interventions — in explaining differences of effect estimates. As a perspective, evaluating differences in factors such as study size, follow-up time, or publication date may serve to further explore disagreement between the two study design types. However, other factors require equal attention. Appropriate adjustment for confounding is a necessary precondition to consider results from observational studies and residual confounding remains a major concern. To deal with these uncertainties evaluating the risk of bias is of tremendous importance to assess the trustworthiness of findings. In our sample, the Cochrane risk of bias tool for RCTs and the Newcastle Ottawa scale (NOS) for cohort studies were mainly used, along with a variety of other instruments to rate the risk of bias/study quality. We assume that the increased use of the ROBINS-I tool may facilitate integrating both BoE in evidence syntheses and facilitate analyses by the risk of bias and certainty of the evidence in methodological studies. The ROBINS-I tool is based on the target trial approach and permits to better compare evidence from RCTs and observational studies. This will be useful to investigate the influence of bias on differences between findings from RCTs and cohort studies. In general, cohort studies may serve as a source for complementary or sequential information, or even replace findings from RCTs. In evidence synthesis, cohort studies are sometimes included as a complementary source of evidence to increase the precision and/or generalizability of findings. However, caution is warranted when pooling both BoE since, as shown in our study, PI/ECO-differences are common between both BoE, and cohort studies showed higher statistical heterogeneity.

---

### The nested case-control study in cardiology [^116vrwwi]. American Heart Journal (2003). Low credibility.

Background

The nested case-control study is an efficient epidemiological design whereby a case-control approach is employed within an established cohort. The large number of recent prospective studies and randomized trials conducted in cardiology provide cohorts within which the nested case-control approach is increasingly used.

Methods

This paper describes the design of the nested case-control study, and evaluates its role in cardiology by reviewing all such studies indexed in Medline from 1966 to 2000. The example of homocysteine is used to illustrate how discrepancies between results of nested case-control and case-control studies played an important role in the decisions and recommendations of national and international organizations.

Results

Seventy-seven nested case-control studies in cardiology were reviewed. The number of studies per year has been increasing since the first publication in 1987. The majority (96%) of studies evaluated potential risk factors for cardiovascular disease while the remainder evaluated drugs with cardiac adverse effects. In studies of homocysteine and coronary artery disease, nested case-control studies did not confirm the strong association suggested by early case-control studies that may have been influenced by bias (eg, selection, publication, or reverse causality). This led national and international organizations to advise against routine screening.

Conclusions

The nested case-control study is increasingly used to study causal relationships in cardiology. The large cohorts of cardiac patients created by prospective studies, clinical trials, and administrative databases should be exploited using this methodology to assess potential cardiac risk factors and other causal relationships that cannot be studied in randomized trials.

---

### Observational studies [^112ABYFd]. Respiratory Care (2023). Medium credibility.

Studies can be observational or experimental. With an observational study, the investigator does not determine the assignment of subjects, and there might not be a control group. If there is a control group, assignment of the independent variable (exposure or intervention) is not under the control of the investigator. Observational studies can be rigorously conducted, but the lack of random assignment of the exposure/intervention introduces confounding and bias. Thus, the quality of evidence resulting from observational studies is lower than that of experimental randomized controlled trials (RCTs). An observational study might be performed if an RCT is unethical, impractical, or outside the control of the investigator. There are many types of prospective and retrospective observational study designs. However, an observational study design should be avoided if an experimental study is possible. Sophisticated statistical approaches can be used, but this does not elevate an observational study to the level of an RCT. Regardless of quality, an observational study cannot establish causality.

---

### The American Society of Pain and Neuroscience (ASPN) practical guidelines to study design and scientific manuscript preparation in neuromodulation [^114jLjxL]. Journal of Pain Research (2021). Medium credibility.

Clinical Trial Design

The Research Question

The research question seeks to answer an important problem by defining a hypothesis that is challenged, examined, and analyzed to provide interpretable inferences. A well-formulated research question should be precise, clinically relevant, and build on hypotheses from existing literature to generate data from patient populations of interest.

Inspiration for framing an effective clinical research question is often derived from unanswered problems in the current clinical practice, unexpected clinical outcomes, or alternative therapies. PICO (population, intervention, control, and outcomes) criteria may assist investigators by providing step-by-step guidance on the formulation of a research question and eventual initiation of a research project.

PICO Method

Problem: Patient/Problem/Population

When designing an effective research question, investigators will inevitably consider numerous questions, which should generally be classified into background and foreground questions. The former are universal questions about a clinical issue, commonly inquiring what, when, how, and where about the disease, disorder, or treatment. A comprehensive literature review will usually provide the answers to these types of questions. In contrast, foreground questions are patient-oriented queries relating to the interpretation of a treatment or clinical condition and consideration of risk versus benefit. These sorts of clinical queries are answered by reviewing previous studies in the literature and typically comparing the different treatments.

The PICO format is considered a broadly accepted method for formulating a "foreground" research question. Sackett et al emphasized that dividing the question into four components will enable the researcher to identify the relevant information:

---

### Made to measure: designs tailored to your study needs [^112CaFUX]. The Journal of Foot and Ankle Surgery (2015). Low credibility.

What is the best study design? Why would we prefer one to another? With many different designs, what should we be looking for in our critical reading of the literature? We discuss a variety of designs, and their appropriate use.

---

### A summary of the methods that the national clinical guideline centre uses to produce clinical guidelines for the national institute for health and clinical excellence [^115WA4DU]. Annals of Internal Medicine (2011). Medium credibility.

NICE preferred study designs by question type — The information scientist searches for evidence appropriate to each review question; for effectiveness of an intervention, a randomized, controlled trial is usually the best study design; questions on the clinical value of a diagnostic test are best answered by randomized, controlled trials, while questions on test accuracy are best answered by cross-sectional studies in which the index test and reference standard are performed in the same patients; questions on prognoses are best answered by prospective cohort studies.

---

### A critical evaluation of clinical research study designs [^113EsepC]. The Journal of Investigative Dermatology (2014). Low credibility.

Interventional and observational studies have important roles in dermatology. The results from any study must be put in the context of the appropriate research design selection. RCTs are most useful in determining causality and effectiveness of treatment. Observational studies provide information about epidemiology and possible links between exposure and disease. Understanding the fundamentals underlying the various study designs is critical to both investigators and clinicians alike.

---

### Commonalities among dietary recommendations from 2010 to 2021 clinical practice guidelines: a meta-epidemiological study from the American college of lifestyle medicine [^1129Tuvj]. Advances in Nutrition (2023). High credibility.

Dietary recommendations across clinical practice guidelines — study objectives, scope, and methods — are outlined, stating the primary objective was to conduct a meta-epidemiologic study (with guidelines as the unit of analysis) comparing dietary recommendations from clinical practice guidelines (CPGs) developed by governments, major medical professional societies, and large health stakeholder associations for adults with prespecified chronic diseases (cardiovascular disease [CVD], type 2 diabetes [T2D], cancer, autoimmune diseases, chronic obstructive pulmonary disease, digestive diseases, and weight-related conditions). Primary dietary outcomes were dietary patterns, food groups, and food components, with secondary outcomes of macronutrient and micronutrient recommendations, and the report includes an assessment of dietary messaging consistency across CPGs; it did not assess the evidence used to develop CPGs or formally evaluate aspects such as guideline group composition or grading of evidence. Methods used a systematic review approach following the National Academy of Medicine's Standards for Systematic Reviews; a risk-of-bias assessment was not completed per meta-epidemiologic guidelines, results are reported according to those guidelines including an adapted PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) statement, and a protocol was registered on PROSPERO (PROSPERO 2021 CRD42021226281). The significance statement notes this is the first study to compare dietary recommendations across current CPGs for multiple major chronic diseases and that guidelines are closely aligned in recommending daily intake of plant sources of food with limited consumption of alcohol and salt or sodium, concluding that clinicians should feel confident making these recommendations in accordance with their respective practice guidelines; background context cites a 2019 analysis in 195 countries attributing more than half of diet-related deaths to nonoptimal intake of whole grains, fruit, and sodium.

---

### Study design algorithm [^11514UQM]. Journal of Lower Genital Tract Disease (2015). Low credibility.

Objectives

To aid authors in correctly naming their study design, to assist readers and reviewers who must decide what the design was for some published studies, and to provide consistency in evaluating the design of published studies, especially for those conducting systematic reviews and evidence synthesis.

Methods

An annotated algorithm method is used to prompt serial questions and analysis to identify a single study design.

Results

The algorithm begins with a research article. Primary clinical research is divided into experimental and observational studies. Key determinants include identifying the study question and the population, intervention, comparison, and outcome. Experimental therapy and prognosis studies are subdivided into 4 design types. Observational therapy and prognosis studies are subdivided into 7 design types. Experimental diagnosis and screening studies are subdivided into 2 types. Observational diagnosis and screening studies are subdivided into 5 types.

Conclusions

An annotated algorithm may be used by authors, readers, and reviewers to consistently determine the design of clinical research studies.

---

### Methodological aspects of outcomes research [^112bnGoM]. European Spine Journal (2006). Low credibility.

A critical evaluation of existing scientific evidence of treatment efficacy can be an important part of communicating risk and benefits of treatment options to patients during the course of clinical practice. A checklist of key methodological issues to examine when reading a research study is presented and discussed. Steps in reading a paper include: identifying the research question; identifying the manner in which subjects get enrolled in the study; identifying the treatments and outcomes used; identifying the study design and the comparisons being made; evaluating the study methods for the possibility of bias and uncontrolled confounding; assessing whether the statistical analysis used is appropriate for the study design; assessing whether the study has sufficient statistical power to demonstrate hypotheses being tested. Finally, procedures for grading and evaluating evidence, as used by systematic review groups and international best evidence synthesis consensus groups is briefly described.

---

### Current status and future opportunities in lung precision medicine research with a focus on biomarkers. An American Thoracic Society / National Heart, Lung, and Blood Institute research statement [^111hnuSZ]. American Journal of Respiratory and Critical Care Medicine (2018). Medium credibility.

Gaps in current research and suggestions for future studies — An impediment to precision medicine shared across most diseases considered was the lack of effective translation of promising biomarkers into widely used clinical tests. There are limited options for validating biomarkers in prospective trials because of the high costs associated with this endeavor, and despite this difficulty, additional translational studies to clinically validate biomarkers are needed, in which significance is valued over innovation. More biomarker discovery research, in which hypothesis generation is viewed favorably, is necessary, and this includes gathering cohorts for specimen collection. Efforts to integrate relevant existing datasets are required, including careful merging of heterogeneous data types within cohorts as well as merging of data across cohorts to facilitate biomarker discovery research via appropriate data-mining strategies.

---

### Cohort studies: marching towards outcomes [^117KPuTg]. Lancet (2002). Excellent credibility.

A cohort study tracks two or more groups forward from exposure to outcome. This type of study can be done by going ahead in time from the present (prospective cohort study) or, alternatively, by going back in time to comprise the cohorts and following them up to the present (retrospective cohort study). A cohort study is the best way to identify incidence and natural history of a disease, and can be used to examine multiple outcomes after a single exposure. However, this type of study is less useful for examination of rare events or those that take a long time to develop. A cohort study should provide specific definitions of exposures and outcomes: determination of both should be as objective as possible. The control group (unexposed) should be similar in all important respects to the exposed, with the exception of not having the exposure. Observational studies, however, rarely achieve such a degree of similarity, so investigators need to measure and control for confounding factors. Reduction of loss to follow-up over time is a challenge, since differential losses to follow-up introduce bias. Variations on the cohort theme include the before-after study and nested case-control study (within a cohort study). Strengths of a cohort study include the ability to calculate incidence rates, relative risks, and 95% CIs. This format is the preferred way of presenting study results, rather that with p values.

---

### Methodologies for the development of the management of cough: CHEST guideline and expert panel report [^1131Cxg4]. Chest (2014). Low credibility.

Background

This series of guidance documents on cough, which will be published over time, is a hybrid of two processes: (1) evidence-based guidelines and (2) trustworthy consensus statements based on a robust and transparent process.

Methods

The CHEST Guidelines Oversight Committee selected a nonconflicted Panel Chair and jointly assembled an international panel of experts in each clinical area with few, if any, conflicts of interest. PICO (population, intervention, comparator, outcome)-based key questions and parameters of eligibility were developed for each clinical topic to inform the comprehensive literature search. Existing guidelines, systematic reviews, and primary studies were assessed for relevance and quality. Data elements were extracted into evidence tables and synthesized to provide summary statistics. These, in turn, are presented to support the evidence-based graded recommendations. A highly structured consensus-based Delphi approach was used to provide expert advice on all guidance statements. Transparency of process was documented.

Results

Evidence-based guideline recommendations and consensus-based suggestions were carefully crafted to provide direction to health-care providers and investigators who treat and/or study patients with cough. Manuscripts and tables summarize the evidence in each clinical area supporting the recommendations and suggestions.

Conclusions

The resulting guidance statements are based on a rigorous methodology and transparency of process. Unless otherwise stated, the recommendations and suggestions meet the guidelines for trustworthiness developed by the Institute of Medicine and can be applied with confidence by physicians, nurses, other health-care providers, investigators, and patients.

---

### European Heart Rhythm Association (EHRA) / Heart Rhythm Society (HRS) / Asia Pacific Heart Rhythm Society (APHRS) / Latin American Heart Rhythm Society (LAHRS) expert consensus on arrhythmias and cognitive function: what is the best practice? [^112wGMed]. Europace (2018). Medium credibility.

General dementia-related research domains — further research priorities include "Large international population-based longitudinal studies of aging and dementia", investigation of the "Contribution of vascular conditions, inflammation, oxidative stress, and the immune system to neurodegenerative processes causing dementia", and "Interactions of modifiable and non-modifiable dementia risk factors in population-based studies". Additional needs are to assess the "Feasibility, administration and effectiveness of interventions addressing dementia risk factors", develop "Interventions for timely and accurate diagnosis of cognitive impairment or dementia at the primary health-care level; better characterization of different dementia types", and implement "Strategies for longitudinal surveillance of healthy individuals to distinguish (and timely diagnose) pre-clinical neurodegenerative diseases with cognitive impairment vs. normal aging". Methodological and biomarker work is emphasized, including "Validation and standardization of available cerebrospinal fluid and brain imaging biomarkers of dementia for research and clinical use", "Development and validation of novel biological, genetic, behavioural or cognitive biomarkers with predictive value at pre-dementia stages", and "Exploring single- and multi-domain approaches for primary and secondary prevention of dementia based on evidence on risk/protective factors and the relationship with other chronic diseases". Prevention and trial design priorities include that "Prevention studies need to start in mid-life and have a follow-up up to elderly windows as opportunity for effective interventions", along with better "outcome measures", "Improvement in differentiation of dementia types", "Improvement in the selection of patients eligible for clinical trials of cognitive impairment or dementia", and "Investigation of combination therapies for dementia and diversification of investigational therapeutic approaches (pharmacological and non-pharmacological interventions)".

---

### Mixed-methods research in nephrology [^116jN2nQ]. Kidney International (2022). Medium credibility.

Mixed-methods research involves the mixing of at least 1 qualitative and 1 quantitative method in the same research project or set of related projects. Combined use of qualitative and quantitative research methods in nephrology has increased over the last 10 years. In this review, we aim to advance the understanding of mixed-methods research within the kidney community. Qualitative and quantitative techniques provide different but noncompeting representations of what exists in the world; findings from qualitative research do not generalize to a large population, whereas those from quantitative research may not apply to individuals within the diverse and heterogeneous larger population. Mixed-methods research combines these complementary representations, allowing the strengths of each method to be combined and the strengths of 1 method to address the limitations of the other. Mixed-methods approaches can be used to: (i) gain a more complete understanding of a research problem, (ii) explain initial results from one method with results from another, (iii) generate instruments, for example, survey tools and interventions, (iv) evaluate services, and (v) optimize clinical trial design and delivery. There are 3 core mixed-methods designs: explanatory sequential, exploratory sequential, and convergent parallel, which can be combined. We discuss each design in turn before discussing analysis and integration of findings from the different methods. We provide case studies that illustrate the application of these study designs to kidney research questions. We briefly discuss mixed-methods systematic reviews and evidence synthesis before finally highlighting guidance on how to appraise published mixed-methods research.

---

### Optimal two-stage genotyping in population-based association studies [^113DK3kZ]. Genetic Epidemiology (2003). Low credibility.

We propose a cost-effective two-stage approach to investigate gene-disease associations when testing a large number of candidate markers using a case-control design. Under this approach, all the markers are genotyped and tested at stage 1 using a subset of affected cases and unaffected controls, and the most promising markers are genotyped on the remaining individuals and tested using all the individuals at stage 2. The sample size at stage 1 is chosen such that the power to detect the true markers of association is 1-beta(1) at significance level alpha(1). The most promising markers are tested at significance level alpha(2) at stage 2. In contrast, a one-stage approach would evaluate and test all the markers on all the cases and controls to identify the markers significantly associated with the disease. The goal is to determine the two-stage parameters (alpha(1), beta(1), alpha(2)) that minimize the cost of the study such that the desired overall significance is alpha and the desired power is close to 1-beta, the power of the one-stage approach. We provide analytic formulae to estimate the two-stage parameters. The properties of the two-stage approach are evaluated under various parametric configurations and compared with those of the corresponding one-stage approach. The optimal two-stage procedure does not depend on the signal of the markers associated with the study. Further, when there is a large number of markers, the optimal procedure is not substantially influenced by the total number of markers associated with the disease. The results show that, compared to a one-stage approach, a two-stage procedure typically halves the cost of the study.

---

### Taking account of context in systematic reviews and guidelines considering a complexity perspective [^115BQpjT]. BMJ Global Health (2019). High credibility.

Considering contextual factors on completion of a review, using applicability checklists and decision-making frameworks, helps to make review findings more useful to guideline developers. Alternatively, strengthening the conduct of the systematic reviewcan lead a review team to consider a complexity perspective a priori using an EtD-making framework.

Context is pivotal when localising guideline recommendations. Guidance from the GRADE Working Group directs guideline developers in deciding when to adopt (use a guideline 'as is'), adapt (introduce local evidence and expertise to rework guidelines) or contextualise (reframe recommendations in light of local resources and constraints) and when to initiate guideline development de novo.

Describe implications for future research

An important outcome of any systematic review, or guideline, is articulating gaps in knowledge or evidence on the topic. However, often reports of reviews and guidelines provide only general observations and miss the opportunity to identify important gaps relating to different contexts. Where important contexts are missing, resulting in 'absolute gaps' or 'synthesis gaps'the review team can identify implications for future research. The Evidence Population Intervention Comparison Outcome Timestamp (EPICOT) framework, developed by organisations involved in commissioning or summarising research, is recommended for formulating research recommendations. Optional elements in the framework (current state of evidence (E), appropriate study type (s), disease burden and relevance (d) and timeliness (t)) help to ensure more detailed definition of context. The WHO Guidelines on Indoor Air Qualityused this EPICOT reporting structure. However, the EPICOT framework shares limitations of the PICO question framework in providing a static linear framework and it does not take into account other important characteristics of the immediate setting or the wider environment.

---

### An official multi-society statement: the role of clinical research results in the practice of critical care medicine [^117MNYyR]. American Journal of Respiratory and Critical Care Medicine (2012). Medium credibility.

An official multi-society statement — background, methods, results, and conclusions on clinical research in critical care explains that while the results of clinical research are clearly valuable in the care of critically ill patients, the limitations of such information and the role of other forms of medical knowledge for clinical decision making have not been carefully examined. The methods describe that the leadership of three large professional societies representing critical care practitioners convened a diverse group to develop a document to serve as a basis for agreement and a framework for ongoing discussion. Results indicate consensus on several issues, including that while rigorous clinical research is important in arriving at the best course of action for an individual critically ill patient, other forms of medical knowledge, including clinical experience and pathophysiologic reasoning, remain essential; no single source of knowledge is sufficient to guide clinical decisions, nor does one kind of knowledge always take precedence over others; clinicians will find clinical research compelling for a variety of reasons that go beyond study design; and while clinical practice guidelines and protocols based upon clinical research may improve care and decrease variability in practice, clinicians must be able to understand and articulate the rationale for protocol use or alternative approaches, with explicit clinical reasoning necessary to understand practice variability. The conclusions state that understanding the strengths and weaknesses of different kinds of medical knowledge for clinical decision making and factors beyond study design that make clinical research compelling to clinicians can provide a framework for understanding the role of clinical research in practice.

---

### An official American Thoracic Society workshop report: translational research in rare respiratory diseases [^1125CUBW]. Annals of the American Thoracic Society (2017). Medium credibility.

Phenotyping and biomarker development — key messages and challenges in rare respiratory disease (RRD) emphasize that simultaneous innovations in physiological, imaging-based, molecular, and genetic biomarker discovery have improved patient care and enabled clinical trials using surrogate endpoints; a common infrastructure for pediatric and adult RRDs could support bidirectional preclinical/clinical investigation and screening for early markers in otherwise asymptomatic patients; and detailed phenotypic analysis of common disease cohorts might uncover unknown rare diseases with translatable insights. Current challenges include health disparities related to age, race, sex, socioeconomic class, or geographical location that complicate care and representative cohort recruitment, and persistent interinstitutional hurdles such as subcontracting and institutional review board agreements, for which widely adopted standard operating protocols and centralized, multicenter processes represent a promising approach.

---

### Synthesis without meta-analysis (SWiM) in systematic reviews: reporting guideline [^113xiq4B]. BMJ (2020). Excellent credibility.

Summary points

Systematic reviews of health related interventions often use alternative methods of synthesis to meta-analysis of effect estimates, methods often described as "narrative synthesis"
Serious shortcomings in reviews that use "narrative synthesis" have been identified, including a lack of description of the methods used; unclear links between the included data, the synthesis, and the conclusions; and inadequate reporting of the limitations of the synthesis
The Synthesis Without Meta-analysis (SWiM) guideline is a nine item checklist to promote transparent reporting for reviews of interventions that use alternative synthesis methods
The SWiM items prompt users to report how studies are grouped, the standardised metric used for the synthesis, the synthesis method, how data are presented, a summary of the synthesis findings, and limitations of the synthesis
The SWiM guideline has been developed using a best practice approach, involving extensive consultation and formal consensus

Decision makers consider systematic reviews to be an essential source of evidence. Complete and transparent reporting of the methods and results of reviews allows users to assess the validity of review findings. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA;) statement, consisting of a 27 item checklist, was developed to facilitate improved reporting of systematic reviews. Extensions are available for different approaches to conducting reviews (for example, scoping reviews), reviews with a particular focus (for example, harms), and reviews that use specific methods (for example, network meta-analysis.) However, PRISMA provides limited guidance on reporting certain aspects of the review, such as the methods for presentation and synthesis, and no reporting guideline exists for synthesis without meta-analysis of effect estimates. We estimate that 32% of health related systematic reviews of interventions do not do meta-analysis, instead using alternative approaches to synthesis that typically rely on textual description of effects and are often referred to as narrative synthesis. Recent work highlights serious shortcomings in the reporting of narrative synthesis, including a lack of description of the methods used, lack of transparent links between study level data and the text reporting the synthesis and its conclusions, and inadequate reporting of the limitations of the synthesis. This suggests widespread lack of familiarity and misunderstanding around the requirements for transparent reporting of synthesis when meta-analysis is not used and indicates the need for a reporting guideline.

---

### Synthesis of guidance available for assessing methodological quality and grading of evidence from qualitative research to inform clinical recommendations: a systematic literature review [^114cEisF]. RMD Open (2024). Medium credibility.

WHAT IS ALREADY KNOWN ON THIS TOPIC

The importance of qualitative research in informing clinical practice is widely recognised.
Various tools exist to assess the quality of studies using qualitative methodologies.
There is lack of clarity on how to best use qualitative evidence in formulating clinical recommendations within European Alliance of Associations for Rheumatology (EULAR).
This includes a lack of guidance on grading the quality of the included qualitative studies and assessment of the strength of recommendations based on qualitative studies.

---

### Methodologies for the development of CHEST guidelines and expert panel reports [^1147a6dJ]. Chest (2014). Medium credibility.

CHEST guideline study quality assessment — content and methodology experts select studies using PICO-based criteria, then apply design-appropriate tools; guidelines are compared with the Appraisal of Guidelines, Research and Evaluation (AGREE) II instrument and IOM standards, systematic reviews are assessed with the Document and Appraisal Review Tool (DART), and QUADAS is used for diagnostic studies; randomized controlled trials (RCTs) typically address benefits while observational studies can inform harms, and the overall quality for each recommendation is displayed in evidence profiles.

---

### Conducting a high-quality systematic review [^114Dg6aM]. The Journal of Rheumatology (2025). Medium credibility.

Systematic reviews (SRs) are a structured means of knowledge synthesis used by a variety of healthcare practitioners to aid in medical decision making. The SR, if conducted rigorously, is considered to be at the top of the hierarchy for research studies. In addition to synthesizing evidence, SRs identify research priorities, address questions that may not be answerable by individual studies, and identify gaps to be addressed in future primary research. There are several steps that need to be taken when developing SRs to provide the best available evidence-the most essential being the assessment of risk of bias (ROB). Several ROB tools have been developed for use according to study design. Increasingly used is the assessment of certainty of evidence using approaches such as those developed by the Grading of Recommendations Assessment, Development, and Evaluation (GRADE) working group. Whereas ROB is assessed for individual studies, the certainty of evidence is assessed for each critical or important outcome across studies. Analysis can be quantitative (metaanalysis) or qualitative (narrative), with the former intended to develop estimates of the effect measure (ie, the statistic that compares collated data), with confidence limits around that estimate. This review will focus on the steps required to develop SRs, from registration of the review protocol to the conduct, analysis, and reporting, with a focus on the assessment of ROB and certainty of evidence to ensure the development of a methodological and rigorous process.

---

### Observational methods in comparative effectiveness research [^113XYDAj]. The American Journal of Medicine (2010). Low credibility.

Comparative effectiveness research (CER) may be defined informally as an assessment of available options for treating specific medical conditions in selected groups of patients. In this context, the most prominent features of CER are the various patient populations, medical ailments, and treatment options involved in any particular project. Yet, each research investigation also has a corresponding study design or "architecture", and in patient-oriented research a common distinction used to describe such designs are randomized controlled trials (RCTs) versus observational studies. The purposes of this overview, with regard to CER, are to (1) understand how observational studies can provide accurate results, comparable to RCTs; (2) recognize strategies used in selected newer methods for conducting observational studies; (3) review selected observational studies from the Veterans Health Administration; and (4) appreciate the importance of fundamental methodological principles when conducting or evaluating individual studies.

---

### Understanding observational studies [^113VZhcz]. Drug and Therapeutics Bulletin (2016). Low credibility.

The development of evidence-based medicine has encouraged clinicians to consider the best available evidence when making clinical decisions, individualised for the patient.(1,2) A hierarchy of levels of evidence about therapy is described, with the highest being meta-analyses and large, well-designed randomised controlled trials.(3–5) Lower down the hierarchy are observational studies, a group that includes cohort, case-control and cross-sectional studies. Here we describe the benefits and limitations of observational studies, and how to assess their quality.

---

### Core GRADE 1: overview of the core GRADE approach [^1144itL4]. BMJ (2025). Excellent credibility.

This first article in a seven part series presents an overview of the essential elements of the GRADE (Grading of Recommendations Assessment, Development and Evaluation) approach that has proved extremely useful in systematic reviews, health technology assessment reports, and clinical practice guidelines. GRADE guidance has appeared in many articles dealing with both core issues and more specialised and complex guidance, and it has evolved over time. This series of articles presents GRADE essentials, Core GRADE, focusing on the core judgments necessary to summarise the comparative evidence about alternative care options and to make recommendations that apply to the care of individual patients. This article presents detailed guidance on formulating questions using the PICO (population, intervention, comparison, outcome) structure, and refining the question considering possible differences in relative and absolute effects across patient groups. The article then provides an overview of the remainder of the Core GRADE approach, including decisions about the certainty of the evidence and considerations in moving from evidence to guidance and recommendations.

---

### Laboratory perspectives in the development of polygenic risk scores for disease: a points to consider statement of the American College of Medical Genetics and genomics (ACMG) [^115yNa2G]. Genetics in Medicine (2023). High credibility.

ACMG — Testing in the context of Mendelian conditions: If the PRS is being used within a joint prediction model for Mendelian disease risk, there are additional challenges in validating the use of these combined tests. The target populations for testing differ, as Mendelian testing is usually done in high-risk populations with significant family history and challenges exist with testing of healthy populations and should be given careful consideration keeping in mind the potential benefits and risks. The risk information conveyed by each test type differs; Mendelian variant curation frameworks rely on an understanding of disease mechanisms, PRS describes a statistical association, and high-risk does not indicate an underlying disease pathology, and PRS is solely considered screening information. There is no clear guidance on how these different types of risk information can be accurately combined or related to one another. The predicted phenotype of a PRS may not be appropriate for Mendelian diseases. When designing reports including both monogenic high-penetrance variants and PRS in a joint model, the potential effect on medical management must be considered, and many thresholds for prophylactic action or screening recommendations are dependent on lifetime or absolute risk of disease, which are traditionally dependent on well-established risks conferred by Mendelian conditions.

---

### Synthesis of guidance available for assessing methodological quality and grading of evidence from qualitative research to inform clinical recommendations: a systematic literature review [^116GxpGa]. RMD Open (2024). Medium credibility.

Objective

To understand (1) what guidance exists to assess the methodological quality of qualitative research; (2) what methods exist to grade levels of evidence from qualitative research to inform recommendations within European Alliance of Associations for Rheumatology (EULAR).

Methods

A systematic literature review was performed in multiple databases including PubMed/Medline, EMBASE, Web of Science, COCHRANE and PsycINFO, from inception to 23 October 2020. Eligible studies included primary articles and guideline documents available in English, describing the: (1) development; (2) application of validated tools (eg, checklists); (3) guidance on assessing methodological quality of qualitative research and (4) guidance on grading levels of qualitative evidence. A narrative synthesis was conducted to identify key similarities between included studies.

Results

Of 9073 records retrieved, 51 went through to full-manuscript review, with 15 selected for inclusion. Six articles described methodological tools to assess the quality of qualitative research. The tools evaluated research design, recruitment, ethical rigour, data collection and analysis. Seven articles described one approach, focusing on four key components to determine how much confidence to place in findings from systematic reviews of qualitative research. Two articles focused on grading levels of clinical recommendations based on qualitative evidence; one described a qualitative evidence hierarchy, and another a research pyramid.

Conclusion

There is a lack of consensus on the use of tools, checklists and approaches suitable for appraising the methodological quality of qualitative research and the grading of qualitative evidence to inform clinical practice. This work is expected to facilitate the inclusion of qualitative evidence in the process of developing recommendations at EULAR level.

---

### Work-relatedness [^113s8Kdx]. Journal of Occupational and Environmental Medicine (2018). Medium credibility.

Work-relatedness — Table 1 steps for evaluating epidemiological evidence list procedural actions and criteria: "Collect all epidemiological literature reported on that disorder", "Identify the design of each study", and "Assess each study's methods" including "Exposure assessment methods and potential biases", "Disease ascertainment methods and potential biases", "Absence of significant uncontrolled confounders; consideration of residual confounding", "Addressing of other potential biases", "Adequacy of biostatistical methods and analytical techniques", and "Ascertainment of statistical significance — degree to which chance may have produced those results". The table then directs to "Assess the studies using the Updated Hill's Criteria" including "Temporality", "Strength of association", "Dose–response", "Consistency", "Coherence", "Specificity", "Plausibility", "Reversibility", "Prevention/Elimination", "Experiment", and "Predictive Performance", and to make a "Conclusion regarding the degree to which such a causal association is/is not met".

---

### Hepatic encephalopathy in chronic liver disease: 2014 practice guideline by the American Association for the Study of Liver Diseases and the European Association for the Study of the Liver [^116seSeZ]. Hepatology (2014). Medium credibility.

Hepatic encephalopathy guideline (American Association for the Study of Liver Diseases [AASLD] and European Association for the Study of the Liver [EASL]) — recommendation grading and scope are defined as follows: the AASLD/EASL Practice Guidelines Subcommittee has adopted the classification used by the Grading of Recommendation Assessment, Development, and Evaluation (GRADE) workgroup, with minor modifications (Table 1). The classifications and recommendations are based on three categories: the source of evidence levels I through III; the quality of evidence designated by high (A), moderate (B), or low quality (C); and the strength of recommendation classified as strong (1) or weak (2). Intended for use by physicians, these recommendations suggest preferred approaches to the diagnostic, therapeutic, and preventive aspects of care, and they are intended to be flexible, in contrast to standards of care, which are inflexible policies to be followed in every case; specific recommendations are based on relevant published information.

---

### An official American Thoracic Society workshop report: translational research in rare respiratory diseases [^11543119]. Annals of the American Thoracic Society (2017). Medium credibility.

Phenotyping and biomarker development in rare respiratory diseases (RRDs) emphasizes exploiting phenotypic heterogeneity to guide study design and subgroup analyses, and linking clinical phenotypes to molecular etiology through large-scale DNA sequencing; workshop participants also described how population phenotyping informs well-defined surrogate endpoints for clinical trials.

---

### Best practices in the development and use of experimental models of bacterial pneumonia: an official American Thoracic Society workshop report [^113VoBEE]. American Journal of Respiratory Cell and Molecular Biology (2025). High credibility.

Human challenge model — experimental human challenge protocols using respiratory pathogens have been developed to address limitations of animal models; studies build on experience with experimentally inoculated healthy, closely monitored adult volunteers and emphasize upper respiratory tract colonization from intranasal inoculation, with one team safely challenging more than 2,600 individuals and using pneumococcal carriage to study lung host defenses and to test licensed and candidate vaccines in small, highly controlled efficacy studies.