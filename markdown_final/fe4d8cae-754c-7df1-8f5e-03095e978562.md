# Medical Question & Answer

**Sample ID**: fe4d8cae-754c-7df1-8f5e-03095e978562
**Dataset Index**: 275964

---

## Question

A point P is chosen in an arbitrary triangle. Three lines are drawn through P which are parallel to the sides of the triangle. The lines divide the triangle into three smaller triangles and three parallelograms. Let f be the ratio between the total area of the three smaller triangles and the area of the given triangle. Prove that f ≥ [1/3] and determine those points P for which f = [1/3].

---

## Answer

> Let's see… What do we have here? The user is asking to prove that the ratio of the total area of the three small triangles formed by drawing lines through a point P parallel to the sides of an arbitrary triangle is at least 1/3, and to determine when equality holds. Let's break this down step-by-step. First, I need to think about how to set up barycentric coordinates and express the areas of the small triangles in terms of barycentric weights. Then, I should verify the algebraic inequality that relates these weights to the ratio f. Next, I will check when equality occurs and interpret that geometrically. Finally, I will consider whether the result depends on the shape of the original triangle and confirm the conclusion.

> Let me first confirm the setup and notation. Let the original triangle be ABC with area 1 for simplicity, and let P have barycentric coordinates (u, v, w) with u + v + w = 1 and u, v, w > 0, so P lies strictly inside the triangle. Drawing lines through P parallel to the sides creates three small triangles at the corners and three parallelograms; I need to express the areas of the small triangles in terms of u, v, w.

> Wait, let me verify the area expressions. By similarity and barycentric geometry, the small triangle opposite vertex A has area u², the one opposite B has area v², and the one opposite C has area w². Thus the total area of the three small triangles is f = u² + v² + w², and I need to show f ≥ 1/3.

> I will now examine the inequality algebraically. I need to ensure that u² + v² + w² ≥ 1/3 given u + v + w = 1. Using the identity (u + v + w)² = u² + v² + w² + 2(uv + vw + wu), I get 1 = f + 2(uv + vw + wu), so f = 1 − 2(uv + vw + wu). To minimize f, I should maximize uv + vw + wu, and by the AM-GM inequality or by noting that uv + vw + wu ≤ (u + v + w)²/3 = 1/3, the maximum of uv + vw + wu is 1/3, which implies the minimum of f is 1 − 2(1/3) = 1/3.

> Hold on, I should verify when equality holds. Equality in uv + vw + wu ≤ 1/3 occurs when u = v = w = 1/3, i.e., when P is the centroid of the triangle. Therefore, f = 1/3 precisely when P coincides with the centroid, and f > 1/3 otherwise.

> Hmm, wait a minute, does this result depend on the shape of the original triangle? Let me reconsider. The barycentric coordinate framework is affine-invariant, and the area ratio f is a pure function of the barycentric weights, so the proof and the equality condition are independent of the triangle's geometry; the minimum ratio of 1/3 is achieved at the centroid for any non-degenerate triangle.

> I should double-check that the small triangle areas are indeed u², v², w². By construction, the line through P parallel to BC cuts off a small triangle similar to ABC, and the ratio of similarity is the barycentric coordinate u, so the area scales as u²; the same logic applies to the other two small triangles, confirming that the total area of the three small triangles is u² + v² + w².

> Final answer: The ratio f satisfies f ≥ 1/3, and equality f = 1/3 holds if and only if P is the centroid of the triangle.

---

The ratio (f) of the total area of the three small triangles to the area of the original triangle is always at least [1/3], with equality if and only if the point (P) is the **centroid** of the triangle. This follows because the small triangles are similar to the original triangle, and their areas are proportional to the squares of the barycentric coordinates of (P); the minimum of the sum of squares occurs when the coordinates are equal, i.e. at the centroid.

---

## Geometric setup and notation

Let the original triangle be triangle ABC with area (A). Choose a point (P) inside (\\triangle ABC) with barycentric coordinates ((u, v, w)), where (u + v + w = 1) and (u, v, w > 0). Draw lines through (P) parallel to the sides of (\\triangle ABC), dividing it into three small triangles and three parallelograms. The small triangles are similar to triangle ABC and have areas proportional to u² A, v² A, and w² A, respectively.

---

## Expression for the ratio (f)

The total area of the three small triangles is:

A_small = u² A + v² A + w² A = (u² + v² + w²) A

Thus, the ratio (f) is:

f = [A_small/A] = u² + v² + w²

---

## Proof that f ≥ [1/3]

We need to show that u² + v² + w² ≥ [1/3] given u + v + w = 1. Using the Cauchy–Schwarz inequality:

(u + v + w)² ≤ 3(u² + v² + w²)

Substituting (u + v + w = 1):

1 ≤ 3(u² + v² + w²) ⇒ u² + v² + w² ≥ [1/3]

Therefore, f ≥ [1/3].

---

## Condition for equality

Equality in Cauchy-Schwarz occurs when (u = v = w). Given u + v + w = 1, this implies u = v = w = [1/3], which corresponds to the **centroid** of the triangle. Thus, f = [1/3] if and only if (P) is the centroid.

---

## Geometric interpretation

The centroid is the unique point where the barycentric coordinates are equal, balancing the triangle's area uniformly. When (P) is the centroid, the three small triangles have equal areas, each [1/9] of the original triangle, summing to [1/3].

---

## Conclusion

The ratio (f) satisfies f ≥ [1/3], with equality if and only if (P) is the **centroid** of the triangle. This result highlights the centroid's special role in minimizing the area of the small triangles formed by lines parallel to the sides.

---

## References

### Glass-cutting medical images via a mechanical image segmentation method based on crack propagation [^b06e7ef0]. Nature Communications (2020). High credibility.

Initial crack

In each partial model, we set an initial crack. The initial crack will grow along grooves under external load until reaching object boundaries. For the first local model, the initial crack needs to be specified. After completing crack propagation in the current region, the next local model can be determined according to the position and the orientation of the crack. The new area will partially overlap the old one so that it can contain the end portion of the crack in the previous area as the initial crack.

The initial crack in the first local model can be provided either manually or automatically (Fig. 10b). In the manual method (top half of Fig. 10b), one needs only to choose a short line a few pixels in length along the target boundary as the position of the initial crack in the mechanical model. This selection is simple and accurate because the target boundary is generally very clear in such a location and there is an obvious groove corresponding to the target boundary in the mechanical model. For the automatic method (bottom half of Fig. 10b), the initial crack can be generated by the following procedure: define the side length of square ABCD representing the local image to be 2 L. The target boundary intersects with the two parallel edges AD and BC. Draw a straight line starting from P M1, the midpoint of the side AB, and passing through P M2, the midpoint of the side DC, ending at the point O. The distance from P M1 to O is N times the length of AB (N > 1). Therefore, a triangle AOB is formed with angle at point O equal to φ = 2 arctan(1/(2 N)). Dividing φ by an integer m defines the angle increment, Δ φ = 2 arctan(1/(2 N))/ m. Starting at line OA, and sweeping toward line OB by incrementing the angle by Δ φ each iteration, the ray with angle φ i = i Δ φ (i = 0, 1, 2,…) will intersect the target boundary at the point P i in this local image area. Because the grayscale value of the pixels at the target boundary changes significantly, an edge-detection operator, such as the Canny edge detector, can easily identify the coordinates of the points P i. After detecting several boundary points, the initial crack of the first local model can be automatically formed by connecting these points to form a small line segment.

---

### Multiple tipping points and optimal repairing in interacting networks [^48be4231]. Nature Communications (2016). Medium credibility.

The problem of optimal repairing

Knowing and understanding the phase diagram of interacting networks enable us to answer some fundamental and practical questions. A partially or completely collapsed system of n ≥ 2 interacting networks in which some of them are in the low activity state is a scenario common in medicine, for example, when diseases or traumas affect the human body and a few organs are simultaneously damaged and need to be treated, and the interaction between the organs is critical. It is also common in economics, when two or more coupled sectors of the economyexperience simultaneous problems, or when a few geographical clusters of countries experience economic difficulties. The practical question that arises is: what is the most efficient strategy to repair such a system? Many approaches are possible if resources are unlimited, but this is usually not the case and we would like to minimize the resources that we spend in the repairing process.

For simplicity, consider two interacting networks, both damaged (low activity). Is repairing both networks simultaneously the more efficient approach, or repairing them one after the other? What is the minimum amount of repair needed to make the system fully functional again? In other words, what is the minimum number of nodes we need to repair, to bring the system to the functional 11 ('up–up') state, and how do we allocate repairs between the two networks? An optimal repairing strategy is essential when resources needed for repairing are limited or very expensive, when the time to repair the system is limited, or when the damage is still progressing through the system, threatening further collapse, and a quick and efficient intervention is needed.

We show below that this problem is equivalent to finding the minimum Manhattan distance between the point in the phase diagram where the damaged system is currently situated and the recovery transition lines to the 11 region. The Manhattan distance between two points is defined as the sum of absolute horizontal and vertical components of the vector connecting the points, with defined vertical and horizontal directions. It is a driving distance between two points in a rectangular grid of streets and avenues. In our phase diagram, it is equal to. It turns out that two triple points of the phase diagram play a very important role in this fundamental problem. We find that these special points have a direct practical meaning and are not just a topological or thermodynamic curiosity.

---

### Symmetry breaking in optimal transport networks [^f4124a5b]. Nature Communications (2024). High credibility.

The main problem in network design is fundamentally different. We are given the density of population and we are looking for the network that minimizes some objective function involving some average time, in general (although other choices are possible, see for example). In this setting, there are usually two different transport modes, a slow one representing for example cars on the road network, and a fast one representing the subway or some rapid transit network. The natural framework here is then the one of multiplex networks comprising two different transportation networks, one known while the structure of the second one is to be determined (for multiplexes in the context of optimization see for example). A practical realization of this problem concerns the specific case of subways (for a network analysis of subways, see for example,–). In most large cities, a subway system has been built and later enlarged, with current total lengths varying from a few kilometers to a few hundred kilometers. The geometry of these networks, as its total length increases, varies from simple lines to more complex shapes with loops for larger networks. In particular, for the largest networks, convergence to a structure with a well-connected central core and branches reaching out to suburbs has been observed.

Algorithmic aspects of network design have been studied within computational geometry (e.g.chapter 9) and location science (e.g.and references therein), and some simpler problems of this type have been addressed previously. For instance, the problem of the quickest access between an area and a given point was discussed in. In network science, the optimization problem is traditionally recast as a navigation problem in lattices with long-range connections. However, our specific question – optimal network topologies as a function of population distribution and network length – is largely an open problem. In, some results were obtained in two-dimensional systems by comparing a priori defined optimal network configurations. First, it was shown that, if the goal is reaching a single point in the plane, then the optimal network is necessarily a tree. Second, the paper hinted at the possibility of the existence of transitions between optimal configurations when the length of the network changes. More precisely, it has been shown that as the length of the network increases resources go preferentially to radial branches and that there is a sharp transition at a critical value of the length where a loop appears.

---

### Degenerate boundaries for multiple-alternative decisions [^55f4a482]. Nature Communications (2022). High credibility.

Sequential Bayesian inference can be rewritten in a form that more closely resembles a sum of evidence by taking the logarithm of equation (8):For each of the n -choices, the accumulated evidence is the log posterior, with n distinct evidence incrementsand a common subtractive log-marginal term. Calculation of this log-marginal is necessary for multiple (n > 3) choice optimal decision-making, but can be avoided for n = 2 by using the SPRT as mentioned above. A similarterm in a theory of basal ganglia function has been interpreted as suppressing evidence accumulation when choices are ambiguous –.

Within this framework, using that probabilities sum to unity ∑ i P i (t) = 1, the evidence accumulation takes place within an (n − 1)-dimensional linear subspace spanning n vertices { P i = 1, P j ≠ i = 0} of an N -dimensional unit hypercube. This is most easily seen for N = 3 choices, where the decision variables P = (P 1, P 2, P 3) vary within a triangle passing through three vertices {(1, 0, 0), (0, 1, 0), (0, 0, 1)} of the unit cube (Fig. 1, top right panel). So rather than representing evidence accumulation trajectories as a random walk constrained to two dimensions, for multiple alternatives the random walk moves in higher dimensions (a line for two alternatives, a plane/triangle for three, and so on). For simplicity, this vector is initialized with equal prior probabilities 1/ n and updated sequentially until one of the elements reaches a boundary, P i > θ.

Both the SPRT and two-choice sequential Bayesian inference give optimal decisions in that they give the fastest decisions for a given level of accuracy on single trials of known difficulty. Formally, they optimize a cost function, the Bayes risk, that is linear in the mean error rate e and mean decision time T over many trialswith error costs W i > 0 and cost of time c, scaling the expected error and decision time,… This cost function represents the trade-off between speed and accuracy of decision-making: slow but accurate or fast but inaccurate decisions are both costly, and so a balance must be found. For equal decision costs, W 0 = W 1, there is a single threshold that is free parameter, which for optimal decision-making is tuned according to the relative cost c / W of accuracy and time.

---

### Detecting the ultra low dimensionality of real networks [^7635a2e9]. Nature Communications (2022). High credibility.

Fig. 2
Relation between densities of edge triangles, squares and pentagons for different values of γ.

Panels (A – C) show the projection of the phase space in the subspace (C s, C t), panels (D – F) show the projection in the subspace (C p, C t), and panels (G – I) show the projection in the subspace (C p, C s). In plots (A – F), the dashed red line represents the β = 2 D limit separating the small-world and large-world phases. In these plots, the area on the left of the dashed red line corresponds to β < 2 D (small-world phase) and the area on the right corresponds to β > 2 D (large-world phase if γ > 3). Each point represents an average over 10 network realizations. Standard errors are smaller than the symbols themselves.

There are several interesting patterns that can be observed in the phase space (C t, C s, C p). First, all the curves tend to collapse when there is only a small level of clustering, thus becoming dimension independent. This is to be expected because in this case the topological equivalent of the triangle inequality breaks down, so that the network loses its metric character. In addition, all the curves tend to be closer together — and so tend towards dimension independence — as γ → 2. This implies that, beyond the fact that a metric space may be needed to explain the observed levels of clustering, its dimensionality is not very important when degrees are strongly heterogeneous and networks are dominated by very big hubs. In turn, this explains why highly heterogeneous real networks are extremely well described by themodel.

---

### Disentangling edge and bulk spin-to-charge interconversion in moSmonolayer flakes [^d1f91d5c]. Nature Communications (2025). High credibility.

Moreover, if only the metallic edge states, which are the areas along the sides of the triangles –, contribute to spin pumping due to the inverse spin Hall effect (ISHE) as predicted by Eq. 1, for the case where a metallic layer is in direct contact with the FM, there should be a linear relationship between α SP and the total edge P Total. Figure 1a contradicts this expectation as there seems to be no correlation between the spin pumping and P Total. Based on the analyses conducted so far, it appears that α SP does not depend solely on either A Total or P Total. This suggests that a more complex scenario needs to be considered to understand the origin of spin current injection into the MoS 2 flakes. To comprehend this point, both semiconductor area and metallic edge states have to be taken into account.

In order to differentiate between the contributions of the semiconductor area states and the metallic edge states, Fig. 1e illustrates the variation of α SP as a function of the ratio of the total MoS 2 coverage area to the total MoS 2 perimeter (A Total / P Total). The graph displays a V-shaped curve with two distinct behaviors. The first, highlighted in light red, demonstrates a decrease in spin pumping as the A Total / P Total ratio increases. Conversely, after a certain compensation point, where α SP is extrapolated to zero (highlighted in light blue), the slope becomes positive, and α SP increases as A Total / P Total increases. Notably, the data can be fitted by the absolute value of a single linear function, as shown in Fig. 1e, where the solid line represents the experimental data fit by the equation displayed on the graph. Despite the complexity of the sample preparation, the entire dataset follows a linear behavior with minimal dispersion. These results suggest that both semiconductor area states and metallic edge states contribute to the injection of spin current into the MoS 2 triangular flake.

---

### Exploring the phenotypic consequences of tissue specific gene expression variation inferred from GWAS summary statistics [^332fd34e]. Nature Communications (2018). Medium credibility.

Figure 3 shows ternary plotswith P3, P4, and 1-P3-P4 as vertices. The blue region, top subtriangle, corresponds to high probability of colocalized eQTL and GWAS signals (P4). The orange region at bottom left corresponds to high probability of distinct eQTL and GWAS signals (P3). The gray region at center and bottom right corresponds to low probability of both colocalization and independent signals.

Fig. 3
Colocalization status of S-PrediXcan results. a Shows a ternary plot that represents the probabilities of various configurations from COLOC. This plot conveniently constrains the values such that the sum of the probabilities is 1. All points in a horizontal line have the same probability of "colocalized" GWAS and eQTL signals (P4), points on a line parallel to the right side of the triangle (NW to SE) have the same probability of "Independent signals" (P3), and lines parallel to the left side of the triangle (NE to SW) correspond to constant P0+P1+P2. Top sub-triangle in blue corresponds to high probability of colocalization (P4 > 0.5), lower left sub-triangle in orange corresponds to probability of independent signals (P3 > 0.5), and lower right parallelogram corresponds to genes without enough power to determine or reject colocalization. The following panels present ternary plots of COLOC probabilities with a density overlay for S-PrediXcan results of the Height phenotype. b Shows the colocalization probabilities for all gene-tissue pairs. Most results fall into the "undetermined" region. c Shows that if we keep only Bonferroni-significant S-PrediXcan results, associations tend to cluster into three distinct regions: "independent signals", "colocalized", and "undertermined". d Shows that HEIDI significant genes (to be interpreted as high heterogeneity between GWAS and eQTL signals, i.e. distinct signals) tightly cluster in the "independent signal" region, in concordance with COLOC. A few genes fall in the "colocalized" region, in disagreement with COLOC classification. Unlike COLOC results, HEIDI does not partition the genes into distinct clusters and an arbitrary cutoff p -value has to be chosen. e Shows genes with large HEIDI p -value (no evidence of heterogeneity) which fall in large part in the "colocalized" region. However a substantial number fall in "independent signal" region, disagreeing with COLOC's classification

---

### Tetrapod sperm length evolution in relation to body mass is shaped by multiple trade-offs [^87e79cd2]. Nature Communications (2024). High credibility.

The t -ratio test to assess the statistical significance of the Pareto front

A common approach used in Pareto analyses to assess the statistical significance of fitting Pareto fronts to data points is to compute the p values using the t -ratio test. The t -ratio defines the fraction between the area of the best-fitted polytope, computed through the Sisal algorithm, and the area of the convex hull that encapsulates the data points, computed through the "convhulln" algorithm in Matlab. If the distribution of data points in the trait space is triangular, the convex hull will resemble a triangular distribution, and its area will almost entirely fill the space within the triangular polytope that can be fitted on the data points. This means that the areas of the fitted triangular polytope and the convex hull will be similar, and the t -ratio will be close to one. In our dataset, we obtained a t -ratio of 1.03 (see Supplementary Fig. 2a). Conversely, randomly distributed data points will have a cloud-like shape in the trait space. This cloud of randomized data points will still be fitted by a triangle, but in this case the convex hull will hardly occupy the space within the best-fitting triangular polytope, and the regions in space close to the vertices of the triangle will remain mostly empty. In this case, the t -ratios will be consistently larger than one. For instance, by randomizing the data points of our dataset we found a t -ratio of ~1.25 (see Supplementary Fig. 2b). Next, the p values are defined as the proportion of instances where the t -ratios of the randomized datasets are lower than those of the original dataset, divided by the total number of randomized datasets. We considered as statistically significant p values those that scored under 5% of times (p < 0.05).

Randomized datasets in the trait space

In cases when the data points were considered as independent, the trait randomization was done by independently shuffling the values of sperm length and body mass across all points in the distribution. However, when phylogenetic correlations among data points became relevant, we followed the SibSwap randomization approach as described in ref. This method proposes to randomly permute the values of each trait independently (i.e. sperm length and body mass) within each set of terminal nodes sharing a parental node. This approach preserves both the phylogenetic constraints and the marginal distributions of each trait.

---

### Symmetry breaking in optimal transport networks [^7c40204d]. Nature Communications (2024). High credibility.

Real-world cities

In this section, we study the properties of the subway systems in Atlanta, Boston, and Toronto under the lens of our framework. We choose monocentric cities, fairly isolated from other major urban centers, with a tree-like subway structure. We identify the intersection point of the real subway lines in all three cases as the city center. We see that this point corresponds to the downtown area in the three cities.

First, we incorporate real population data in our model. We rely on a two-dimensional triangular lattice multiplex model; we use the population data and the appropriate coordinates reference systems to impose the triangular lattice structure onto the city landscape. Details on the data and modeling of the city population distribution can be found in the Methods section. We denote all quantities relative to the real physical system using the same notation as for the multiplex model, but we add a tilde on top of the corresponding symbol. For example, R indicates the radius of the lattice model, anddenotes the radius of the city. Overlaying a city on top of the triangular lattice allows us to associate a weightto each node n in the slow layer that reflects the real population density within the city. We use those weights in the objective function of Eq. (6), and then take advantage of the greedy algorithm to obtain approximate solutions to the optimization problem of Eq. (4). Similar to the previous sections, we obtain two classes of optimal fast-layer configurations for all the considered parameters. Results for the city of Toronto are displayed in Fig. 4, where we see that optimal configurations comprise k ✱ = 1 (Fig. 4 a) or k ✱ = 2 (Fig. 4 b) branches. Similar results are valid for Atlanta and Boston, where we observe optimal configurations with k * ≤ 3 branches (see Supplementary Information Figure 11). For k * > 1, we note that the branches have no identical length; this is caused by the fact that the weight associated with the various nodes of the system is not constant. A typical phase diagram for Toronto is displayed in Fig. 4 c, where we fix η = 0.5, but vary L and c. The diagram is qualitatively similar to the one of Fig. 3 e. For fixed c, k * increases as L grows; however, for fixed L, k * decreases as c grows. The values of the parameters where the transitions between the various phases emerge differ from those of Fig. 3 e; this is due to the non-homogeneous density of the population used in the model of the city. Similar results for Atlanta and Boston can be found in the Supplementary Information Figure 11.

---

### Effective use of tables and figures in abstracts, presentations, and papers [^9d553efc]. Respiratory Care (2004). Low credibility.

In some situations, tables, graphs, and figures can present certain types of information (including complicated relationships and sequences of events) more clearly and in less space than the same information would require in sentence form. However, do not use tables, graphs, and figures for small amounts of data that could be conveyed clearly and succinctly in a sentence. Also, do not reiterate in sentences the data that are shown in a table, graph, or figure: the point of creating a table or graph or figure is to eliminate that type of sentence from your manuscript. In building a data table you must balance the necessity that the table be complete with the equally important necessity that it not be too complex. Sometimes it is helpful to break a large table into several smaller ones to allow the reader to identify important information easily, but, conversely, it is a common mistake of novice authors to split up into several tables data that belong in one table. In almost all cases, only one table or graph or figure should be included in an abstract, and then only if it can convey essential information in less space and in a more easily interpretable way than the sentence form. For a poster, in almost all instances you should use only one typeface and one font in a table, graph, or figure. In general, do not use bold, italics, or color unless you are presenting a great deal of data and you need to highlight certain data values and you are certain that using bold, italics, or color will improve readability, which is rare. Do not include identical information in a table and a graph/figure. In reporting a clinical trial you will need to include a patient flow chart that identifies the number of patients initially screened for the study, the number of patients who were excluded (and why) after initial screening or in the final analysis, and how many patients entered, exited early, and completed each arm of the study. A treatment protocol should also be described with a flow chart. In preparing a graph the most common error is to include a line that suggests an unsubstantiated extrapolation between or beyond the data points. In selecting the graph's axes, avoid truncating, enlarging, or compressing the axes in ways that might make the graph confusing or misleading. To prepare clear, accurate, easily interpretable tables, graphs, and figures, rely on the rules described in authoritative guides such as the Council of Science Editors' Scientific Style and Format and the American Medical Association's Manual of Style.

---

### Multiple tipping points and optimal repairing in interacting networks [^806c4333]. Nature Communications (2016). Medium credibility.

To optimize repairing we need to minimize this metric. Figure 5 shows the solution to the minimization problem and a detailed discussion is provided in the Methods section. The different colours in Fig. 5 correspond to the different optimal repair strategies, which depend on the failure state of the system. If the system is initially at point S 1, both networks are in a low activity state, that is, they are non-functional. Our goal is to decreaseand, and arrive to the region where the system is fully recovered (the green region) by performing a minimal number of repairs, that is, minimal N rep. We find that for any point in the red region there are actually two closest points in the green region, at an equal Manhattan distance away from the red region point. These two points are the triple points R1 and R2 shown in Fig. 5, which also correspond to the triple points in Fig. 2b. Although R1 may be closer to point A than R2 by Euclidian distance, the Manhattan distance is the same. Thus, two equally good repairing strategies are available. One involves allocating more node repairs to network A and the other allocating more repairs to network B. For the yellow regions (points S 2 and S 3), the closest points by Manhattan distance are R1 (for point S 2) or R2 (for point S 3). Here, only one triple point represents the optimal solution. It is noteworthy that the path samples in Fig. 5 are 'zig-zag' in shape (to highlight that we are minimizing); however, even when a diagonal path (direct straight line) to a triple point is used, the Manhattan distance is the same. For the dark blue regions (points S 4 and S 7), the optimal strategy is to decreaseonly, until the system is recovered. Similarly, for the light blue regions (points S 5 and S 6), the optimal strategy is to decrease only.

From our optimal repairing strategy analysis we find that the order of repair (the specific path taken between the initial point and final point) does not affect the final result. Minimizing the Manhattan distance only determines the optimal destination point. Therefore, there is actually a set of paths corresponding to equally optimal repairing processes.

---

### Quantification of surgical route parameters for exposure of the jugular foramen via a trans-mastoidal approach exposing jugular foramen in three-dimensional visualization model [^7f42670d]. The Journal of Craniofacial Surgery (2018). Low credibility.

Objective

Surgical operation within the region of the jugular foramen presents a great challenge. The authors characterized the quantitative impact of surgical window parameters on the exposure of the jugular foramen via a trans-mastoidal approach.

Methods

Computed tomography and magnetic resonance imaging data were used to establish a 3-dimensional model of the jugular foramen region. The mastoidale, posterior edge of the mastoid, and the superior edge of the bony external acoustic meatus were selected as points a, b, and c. The anterior edge of the tuberculum jugulare was selected as point d. The midpoints of line segments ab, ac, and bc were selected as points e, f, and g. Triangle abc was divided into triangles aef, beg, cfg, and efg. Surgical corridors of the triangular pyramid were outlined by connecting the above triangles to point d. Anatomic exposure was evaluated by measuring the area and volume of various structures within each route. Statistical comparisons were performed via analysis of variance.

Results

The model allowed for adequate visualization of all structures. The areas of triangles beg and efg were greater than those of triangles aef and cfg (P < 0.05). The volumes of triangular pyramids d-beg and d-cfg were greater than those of triangular pyramids d-aef and d-efg (P = 0.000). Statistically significant differences were also observed for volumes of osseous, venous, and cranial nerve structures in all divided routes (P = 0.000).

Conclusion

Our results indicate that 3-dimensional modeling may aid in the quantification of surgical exposure and that division of the craniotomy window may allow for more precise operation.

---

### Multiple tipping points and optimal repairing in interacting networks [^bf70cdce]. Nature Communications (2016). Medium credibility.

Geometry of the Manhattan distance minimization problem

The optimal strategies shown in different colours in Fig. 5 are derived from the geometrical reasoning shown in Fig. 9. Figure 9a shows a plot of a series of curves consisting of points at identical Manhattan distances from point S 1 (equidistant curves). They produce a 'diamond' shape, and the minimal Manhattan distance between point S 1 and the green region translates into the task of 'fitting' the diamond so that it just touches the green region and its centre is at S 1. The diamond in Fig. 9a touches the green region at two points — triple points, which are the solution to the minimization problem. Figure 9b shows the solution for point S 6 in the light blue region. Here the solution suggests a different strategy — decreasing only.

---

### Coherent movement of error-prone individuals through mechanical coupling [^034f3237]. Nature Communications (2023). High credibility.

Fig. 6
The modules of the Kilobot Soft Robot use their localisation estimates to identify any deviations from the reference shape (square lattice).

a, b show the set of distances and angles considered by Algorithm S1 during the lateral and longitudinal deformation tests, respectively. White and blue colours indicate modules with a symmetric and asymmetric neighbourhood, respectively. The red arrow indicates the Kilobot Soft Robot's forward direction.

Each module begins the cycle by probing for lateral deformations, and if necessary performs a corrective move (procedure CONTROL-LATERAL-DEFORMATION). The module uses any of its distance and angle variables shown in Fig. 6a. Recall that modules are divided into two groups, depending on whether their neighbourhood is left-right symmetric (P 1, P 3, P 5) or not (P 2, P 4) as illustrated using white and blue discs in Fig. 6. In the former case (lines 8–12 of Algorithm S1), the module tests whether its neighbours on the left and right are about the same distance away, and, where this is not the case, turns towards the neighbour further away. In the latter case (lines 13–21), the module resides in the left or right boundary. The module compares the distance of its (sole) lateral neighbour against a reference value, while also evaluating a lateral angle against a reference value of. For hexagonal lattice configurations, depending on the robot's default heading with respect to the lattice, would be 120° (see lateral angles in Fig. S2a) or 60° (see lateral angles in Fig. S2b).

---

### Rigorous location of phase transitions in hard optimization problems [^d98ebea5]. Nature (2005). Excellent credibility.

It is widely believed that for many optimization problems, no algorithm is substantially more efficient than exhaustive search. This means that finding optimal solutions for many practical problems is completely beyond any current or projected computational capacity. To understand the origin of this extreme 'hardness', computer scientists, mathematicians and physicists have been investigating for two decades a connection between computational complexity and phase transitions in random instances of constraint satisfaction problems. Here we present a mathematically rigorous method for locating such phase transitions. Our method works by analysing the distribution of distances between pairs of solutions as constraints are added. By identifying critical behaviour in the evolution of this distribution, we can pinpoint the threshold location for a number of problems, including the two most-studied ones: random k-SAT and random graph colouring. Our results prove that the heuristic predictions of statistical physics in this context are essentially correct. Moreover, we establish that random instances of constraint satisfaction problems have solutions well beyond the reach of any analysed algorithm.

---

### Simvastatin (floLipid) [^e27c4344]. FDA (2023). Medium credibility.

Figure 1 The Effects of Treatment with Simvastatin on Major Vascular Events and Major Coronary Events in HPS

N = number of patients in each subgroup. The inverted triangles are point estimates of the relative risk, with their 95% confidence intervals represented as a line. The area of a triangle is proportional to the number of patients with MVE or MCE in the subgroup relative to the number with MVE or MCE, respectively, in the entire study population. The vertical solid line represents a relative risk of one. The vertical dashed line represents the point estimate of relative risk in the entire study population.

Angiographic Studies

In the Multicenter Anti-Atheroma Study, the effect of simvastatin on atherosclerosis was assessed by quantitative coronary angiography in hypercholesterolemic patients with CHD. In this randomized, double-blind, controlled study, patients were treated with simvastatin 20 mg/day or placebo. Angiograms were evaluated at baseline, two and four years. The co-primary study endpoints were mean change per-patient in minimum and mean lumen diameters, indicating focal and diffuse disease, respectively. Simvastatin significantly slowed the progression of lesions as measured in the Year 4 angiogram by both parameters, as well as by change in percent diameter stenosis. In addition, simvastatin significantly decreased the proportion of patients with new lesions and with new total occlusions.

---

### Guidelines and recommendations for performance of the fetal echocardiogram: an update from the American Society of Echocardiography [^15fb0e56]. Journal of the American Society of Echocardiography (2023). High credibility.

Fetal echocardiography — standard biometry at the four-chamber view includes calculating the cardiothoracic ratio from the inside circumference (or area) of the chest and the epicardial surface of the heart, and determining the cardiac angle by bisecting the chest with a line from the sternum to the spine and measuring the angle at which the ventricular septum would intersect that line.

---

### Intraoperative margin assessment for basal cell carcinoma with deep learning and histologic tumor mapping to surgical site [^4abeff70]. NPJ Precision Oncology (2024). Medium credibility.

It should be noted that the 3D Modeling step does not model or image deep margins since the bottom of the tissue sits on the turntable, though this modeling step is entirely separate from the histological findings (which do model deep margins) and mapping those results to the surgical tumor map but may be integrated with the other two modules in future iterations.

Grossing Recommendations and Size Report in 3D Model Pane. The 3D tissue model is displayed using an interactive web application using the dash_vtk package along with exportable technical readouts on the tissue size measurements (3D Model Pane). ArcticAI features two grossing recommendation tools, one for Mohs and another for traditional excisions with breadloafing. For the Mohs configuration, a 3D line is drawn from 12 o'clock to 6 o'clock in the web application. The 12 o'clock portion of the line is colored blue while the 6 o'clock portion is colored red. If the tissue is to be bisected, two pairs of blue-red lines are drawn parallel to a black line, which is drawn in the middle of the orientation lines. For breadloafing, the surgical excision is arranged such that the Burow's triangles/cones (i.e. superior/inferior or lateral/medial triangular excisions adjacent to resection used as a skin graft to repair surgical defects) point in the forward/backward ("positive/negative-y") direction. Colored lines are placed across the specimen in the side-to-side direction at regular 0.5 to 1-centimeter increments (or set by the user; based on distance to the center) to represent placement of the breadloaf section cuts. Lines to the left of the specimen are colored blue to maintain orientation, while lines to the right are colored red, yellow, green, purple and orange to denote unique sections. The tissue can be inked in accordance with grossing recommendations.

---

### Landslide topology uncovers failure movements [^4b25f7fd]. Nature Communications (2024). High credibility.

Fig. 4
Feature statistics and importance of landslide topology and geometry.

Plots a – f show the probability distribution functions of the six most optimal topological properties used in classifying the failure types for slides (colored in orange), flows (colored in dark blue), complex (colored in red), and falls (colored in light blue) in Italy. Note that we discuss the probability distribution functions of different failure types for the Italian region only, as the Italian data set is the most data-rich inventory. The y -axis shows the probability density values (calculated using kernel density estimation), and the x -axis shows the value of topological attributes. The topological properties in plots a – f are: Average lifetime of holes (AL H), Average lifetime of connected components (AL C), Betti-curve based feature of connected components (BC C), Betti-curve based feature of holes (BC H), Wasserstein amplitude of holes (WA H), and Bottleneck amplitude of holes (BA H) (the computations of these properties are explained in detail in Note S3). The percentage values in the gray circular disk in each figure indicate the topological feature's importance (in %), as estimated by the random forest-based classification procedure. Plot g shows the joint computed feature importance of topological (colored in purple) and geometric (colored in beige) properties by the random forest model. The analysis shows topological properties consistently outperform geometric properties with a standard deviation under 0.1% (the error bar represents the standard deviation. However, it is not visible in plot- g because the standard deviation is very small). The geometric properties are: area (A), perimeter (P), the ratio of area to perimeter, convex hull-based measure (C h), minor (s m) (refer to Note S4 for the definitions), and width (W) of the minimum area bounding box fitted to the polygon.

---

### Guidelines for laparoscopic treatment of ventral and incisional abdominal wall hernias (International Endohernia Society (IEHS)-part 1 [^74d28925]. Surgical Endoscopy (2014). Medium credibility.

Ventral/incisional hernia — prosthetic sizing to reduce recurrence risk: Generally, the larger the defect is, the more stress will be placed on the fixation points of the prosthetic, and as the size of the prosthetic increases, the prosthetic area: defect area ratio will increase, and the tension on the prosthetic fixation sites will decrease. Since all defects are of different sizes and shapes and in a variety of locations, it is important that surgeons consider the total area encompassing all defects in a patient, rather than basing their prosthetic calculation on the largest or dominant defect; in patients with an incisional hernia from a previous midline incision with multiple hernia defects, it is more useful for choosing the right sized prosthetic to refer to the entire area as a single defect, encompassing the entire gap between the rectus muscles. Table 3 summarizes factors that are associated with choice of prosthetic size when considering recurrence as the primary outcome measure, but since there are few data available directly comparing the long-term outcomes of different prosthetics in humans, no recommendation can be made about a specific prosthetic, and as the defect becomes larger in size, these parameters will be more important in determining recurrence rates.

---

### Challenges in applying the results of clinical trials to clinical practice [^37258208]. JAMA Ophthalmology (2016). Medium credibility.

The relevance of clinical trial results to clinical practice hinges on 2 critical questions: Will the results be replicated in one's practice, and Are the results clinically important? The answers to the following 5 questions may help one determine how relevant a study result is to clinical practice. First, have steps been taken to minimize bias (eg, masking, randomization)? Second, is the result likely due to the treatment (vs confounding factors)? Third, is the result unlikely to be due to chance? Fourth, is the study population representative of your patients? Fifth, is the totality of the evidence consistent across studies? To determine if a study result is likely to be clinically important, consider a 3-step approach. In step 1, decide, a priori, what a clinically meaningful difference between 2 treatments would be to define regions of beneficial, harmful, and trivial outcomes. In step 2, determine whether the CIs around the average outcome include the range of beneficial outcomes and lie outside the range of harmful outcomes. In step 3, determine the proportion of patients achieving a clinically meaningful benefit. If the CIs mostly include the range of beneficial outcomes and lie outside the range of clinically harmful outcomes and if a substantial proportion of patients achieve a clinically meaningful benefit, then the intervention is probably clinically important. Application of clinical trial results to clinical practice requires critical analysis of the extant literature as well as good clinical judgment.

---

### Citalopram (Celexa) [^010297b3]. FDA (2023). Medium credibility.

3 DOSAGE FORMS AND STRENGTHS

CELEXA tablets are available as:

10 mg: beige, oval with "FP" imprinted on one side, "10 mg" imprinted on the other side
20 mg: pink, oval, scored with "F" imprinted on left side of score line and "P" imprinted on right side of score line, "20 mg" imprinted on non-scored side
40 mg: white, oval, scored with "F" imprinted on left side of score line and "P" imprinted on right side of score line, "40 mg" imprinted on non-scored side

Tablets: 10 mg; 20 mg, scored; and 40 mg, scored (3)

---

### Pathophysiology of juvenile idiopathic arthritis induced pes planovalgus in static and walking condition: a functional view using 3D gait analysis [^355ef313]. Pediatric Rheumatology Online Journal (2015). Low credibility.

Fig. 2
Classification of a normal gait cycle (modified to Perry 1992, p. 2–4)

To verify the alterations in foot motion in JIA-PPV during upright standing and during stance phase of walking, the following parameters were examined:
Hindfoot to tibia motion (HF/TB; OFM parameter) inversion/eversion and dorsiflexion/plantarflexion in static condition inversion/eversion at initial contact, maximum (max) eversion, max inversion and range of motion (ROM) in stance phase max dorsiflexion in terminal stance, max plantarflexion in pre-swing and ROM in push-off
Medial longitudinal arch arch height (AH; OFM parameter) normalized to foot length in static condition minimum (min), max and ROM AH in mid stance arch index (AI; plantar pressure parameter) as ratio of midfoot area relative to total area excluding the toes (Fig. 3) Fig. 3 Example of a footprint and the calculation of the Arch Index. The point j and k represent the length of the footprint, excluding the toes. A, B and C represent equal thirds, which are divided by parallel lines perpendicular to the line jk. The arch index is calculated as the ratio of the midfoot area (B) relative to the total area (A + B + C) excluding the toes
Foot progression angle (PIG parameter) in static condition max in mid stance
Forefoot to hindfoot motion (FF/HF; OFM parameter) supination/pronation and dorsiflexion/plantarflexion in static condition max supination, max pronation and ROM in stance phase max dorsiflexion in terminal stance, max plantarflexion in pre-swing and ROM in push-off
Ankle kinetics (PIG parameter) max of ankle joint dorsiflexion moment max generated ankle joint power

Statistical analysis

The non-parametric statistical Mann–Whitney- U -test was used to determine differences between JIA-PPV and CG, as not all data were normally distributed. Values of maximum HF/TB eversion, minimum AH and maximum foot progression angle were compared in static and walking condition using the Wilcoxon signed-rank test. For descriptive indices, the median plus quartile 25 and 75 were used. Differences with a p-value smaller than 0.05 were accepted as statistically significant. SPSS 22.0 was used for statistics (IBM, Armonk, USA).

---

### Evidence for a low number prior in children's intuitive number sense [^4feb62b5]. Child Development (2025). Medium credibility.

One important alternative explanation of our findings is that the stimuli with higher perceptual noise were less visible and easily missed when encoding the visual scene, leading to underestimation (or, alternatively, that low perceptual noise stimuli were encoded better, leading to overestimation). Previous work has shown that low contrast can sometimes increase the perceived number of objects, as participants might confuse the background for the presence of more objects (Lei and Reeves). Nevertheless, to investigate this concern, we relied on the area congruency manipulation, as area incongruent trials have Gabor patches that are more numerous but are also significantly smaller (and therefore especially easily to miss during encoding). This is especially the case for our larger ratios (3.0) compared with smaller ratios in area incongruent trials (1.07; see Figure 3A for examples): on a ratio 3.0, the more numerous set has dots that are a third of the total cumulative area compared with the less numerous side, whereas on a ratio of 1.07 they are only 7% smaller (a value that is nearly indistinguishable given typical area perception Weber fractions; Odic). Adding perceptual noise, where these already small dots are now corrupted by low contrast, would make dots on these trials even more susceptible to being missed during encoding. Therefore, if the observed effect was primarily driven by the participants simply not seeing the low contrast and highly noisy dots, we should expect a strong interaction between area congruency and ratio: area incongruent high ratios should show more underestimation compared with area congruent trials, whereas area incongruent low ratios should show a similar bias to area congruent trials. A 2 (area congruency: congruent, incongruent) by 4 (ratio: 3.0, 1.5, 1.25, and 1.07) repeated measures ANOVA over the proportion of trials in which low perceptual noise was chosen as more numerous for all child data revealed a main effect of area congruency, F (1, 79) = 21.69, p < 0.001, = 0.22, and a main effect of ratio, F (3, 237) = 4.64, p = 0.004, = 0.06. However, most importantly, there was no significant interaction between area congruency and ratio, F (3, 237) = 0.15, p = 0.93, = 0.001. As shown in Figure 3, the effect was almost the reverse of what was expected: the trials with the smallest low‐contrast dots show the least bias, whereas the trials with the larger ones produce more. Including the adults' data in this analysis produced similar results. This suggests that participants did not show a stronger underestimation bias on trials where the Gabor patches were easier to miss, likely because the infinite display time allowed for as much scanning time as participants needed to encode the stimuli.

---

### Rivaroxaban (Xarelto) [^310f4423]. FDA (2025). Medium credibility.

3 DOSAGE FORMS AND STRENGTHS

2.5 mg tablets: Round, light yellow, and film-coated with a triangle pointing down above a "2.5" marked on one side and "Xa" on the other side
10 mg tablets: Round, light red, biconvex and film-coated with a triangle pointing down above a "10" marked on one side and "Xa" on the other side
15 mg tablets: Round, red, biconvex, and film-coated with a triangle pointing down above a "15" marked on one side and "Xa" on the other side
20 mg tablets: Triangle-shaped, dark red, and film-coated with a triangle pointing down above a "20" marked on one side and "Xa" on the other side
For oral suspension: white to off-white granules; once reconstituted, provide flavored white to off-white opaque liquid with a concentration of 1 mg/mL.

Tablets: 2.5 mg, 10 mg, 15 mg, and 20 mg (3)
For oral suspension: 1 mg/mL once reconstituted (3)

---

### Combined petrosal intertentorial approach: a cadaveric study of comparison with the standard combined petrosectomy [^95cede2f]. Operative Neurosurgery (2025). Medium credibility.

Areas of Surgical Exposure

Two areas of exposure (petroclival skull base and brainstem) were calculated by obtaining the sum of areas formed by juxtaposed triangles. For the petroclival area, we identified 4 fixed anatomic landmarks (posterior clinoid process, MC, internal acoustic canal, and jugular foramen) and 2 variables (uppermost and lowest medial clivus). Measuring the coordinates of these 6 points created a hexagonal shape. For the brainstem area, we identified 2 fixed points (trigeminal and facial nerve root entry zone [REZ]) and 3 variables (the lowest medial, the uppermost medial, and uppermost lateral brainstem), obtaining a pentagon-shaped area (Figure 5 A and 5 B drawing). Each polygon was divided along diagonals to create triangles whose area was calculated by the length of each side using Heron's formula. The areas of the 4 triangles of the petroclival skull base and the 3 triangles of the brainstem were then summed to calculate the total area of surgical exposure.

FIGURE 5.
These figures demonstrate the methodology of the study. A, Schematic representation of the bony skull base indicating the petroclival area of exposure. B, Schematic representation of the brainstem area of exposure. C, A, B, C, D, E, and F represent the 6 limits of the surface measurements that form a hexagon (black), bordered by dural and bony structures, whose area describes the surgical freedom. D, Illustration of the methodology to calculate the angles of attack. The distal point is fixed on the target (ie, right VII REZ), and the dissector is moved in the vertical (cranio-caudal, red dotted lines) and horizontal planes (antero-posterior, green dotted lines) until the limits of the osteo-dural points are encountered (red and green stars). ACP, anterior clinoid process; CN, cranial nerve; FL, foramen lacerum; FO, foramen ovale; FR, foramen rotundum; FS, foramen spinosum; HC, hypoglossal canal; IAC, internal acoustic canal; JF, Jugular foramen; LCNs, lower cranial nerves; PA, petrous apex; PCJ petroclival junction; PCP, posterior clinoid process; REZ, root entry zone.

---

### Machine learning-enabled forward prediction and inverse design of 4D-printed active plates [^88111524]. Nature Communications (2024). High credibility.

Design results for irregular target shapes

Next, we consider the irregular target shapes. In this case, the challenge in well defining a target becomes particularly severe. First, as discussed above, it is hard to appropriately specify the grid points with physically attainable spacing. Second, it is even harder to give the boundary of the target surface. In extreme cases, general irregular surfaces may involve boundaries that are physically unattainable by a square sheet, which would make the optimization intractable. To resolve these difficulties, we use a patch representation rather than the grid point representation for the target surface, and this new representation allows for extracting the surface normal of each patch and thus using a new measure of approximation errors (or loss) based on the normal distance of the achieved grid points to the target surface (Fig. 7a). This is schematically illustrated in Fig. 7a, where the black lines denote the measure of approximation errors, or distances between the target (gray surface, represented by purple points (top) or patches (bottom)) and the achieved surface (represented by blue points). Therefore, the new loss can be expressed aswhere d ij (S) denotes the distance of achieved point (x ij, y ij, z ij) to the target surface. With the new target representation and loss function, there are no strict requirements for the appropriate boundary of targets or sampling of grid points, as the optimization is essentially to achieve an actuated surface or patch that conforms to the target surface.

---

### Recommendations for cardiac chamber quantification by echocardiography in adults: an update from the American Society of Echocardiography and the European association of cardiovascular imaging [^6a46fa06]. Journal of the American Society of Echocardiography (2015). Medium credibility.

Echocardiographic left ventricular (LV) volumes — Volume measurements are "usually based on tracings of the blood-tissue interface in the apical four- and two-chamber views", with the contour at the mitral valve level "closed by connecting the two opposite sections of the mitral ring with a straight line", and LV length "defined as the distance between the middle of this line and the most distant point of the LV contour". Techniques include biplane disk summation and area-length; biplane disk summation advantages are "Corrects for shape distortions" and "Less geometrical assumptions compared with linear dimensions", with limitations "Apex frequently foreshortened", "Endocardial dropout", and "Blind to shape distortions not visualized in the apical two- and four-chamber planes". For area-length, the advantage is "Partial correction for shape distortion", with limitations "Apex frequently foreshortened", "Heavily based on geometrical assumptions", and "Limited published data on normal population".

---

### Photon-efficient imaging with a single-photon camera [^e1e3b62a]. Nature Communications (2016). Medium credibility.

The implementation of our reconstruction algorithm can be divided into the following three steps (Fig. 2; Supplementary Note 1).

Step 1: natural scenes have reflectivities that are spatially correlated — the reflectivity at a given pixel tends to be similar to the values at its nearest neighbours — with abrupt transitions at the boundaries between objects. We exploit these correlations by imposing a transverse-smoothness constraint using the total-variation (TV) normon our reflectivity image. In this process, we ignore data from the hot-pixel set. The final reflectivity imageis thus obtained by solving a regularized optimization problem.

Step 2: natural scenes have a finite number of reflectors that are clustered in depth. It follows that in an acquisition without background-light or dark-count detections, the set of detection times collected over the entire scene would have a histogram with N z bins that possesses non-zero entries in only a small number of small subintervals. This longitudinal sparsity constraint is enforced in our algorithm by solving a sparse deconvolution problem from the coarsely time-binned photon-detection data, which is specific to the array imaging set-up, to obtain a small number of representative scene depths. Raw photon-detection events at times corresponding to depths differing by more than cT p /2 from the representative scene depths are censored. As step 2 has identified coarse depth clusters of the scene objects, the next step of the algorithm uses the filtered set of photon detections to determine a high-resolution depth image within all identified clusters.

Step 3: similar to what was done in step 1 for reflectivity estimation, we impose a TV-norm spatial smoothness constraint on our depth image, where data from the hot-pixel setand censored detections at the remaining pixels are ignored. Thus, we obtainby solving a regularized optimization problem.

---

### Water modeling panel report | Camp lejeune-ATSDR… [^b3a4fe2e]. atsdr.cdc.gov (2024). Medium credibility.

A preliminary flow model has been constructed and calibrated for Tarawa Terrace aquifers of interest and used to simulate the advective transport of PCE from the vicinity of ABC Cleaners to supply wells TT-26 and TT-23. Additional modeling analyses, consisting of aqueous phase fate and transport simulation of PCE, remain to be undertaken and completed.
3. 2 Groundwater-Modeling Analyses Robert E. Faye, Civil Engineer/Hydrologist, Robert E. Faye and Associates, Inc. Mr. Robert E. Faye assisted ATSDR in constructing and calibrating the groundwater-flow and advective transport models for the Tarawa Terrace area. His presentation is summarized below. Geohydrologic Framework The geohydrologic framework was developed to quantify and describe specific aspects of the aquifers and confining units at Tarawa Terrace at a scale and level of detail appropriate for use in groundwater flow and contaminant fate and transport models. Data available for framework analyses included 44 electric logs, 100 boring logs, and 17 drillers' logs obtained from various sources. Through the framework analyses, 11 confining units and aquifers were identified, most of which are explicitly represented in the preliminary groundwater-flow model. Essentially, the geohydrologic framework developed for this study closely, but not entirely, conforms to the USGS's framework analysis. Results of the framework analyses, partly constrained by estimated chronostratigraphic boundaries, were identified with the top of what Mr.

Faye called the local confining unit and the top of the Beaufort confining unit. Similar patterns of permeable and poorly permeable units were identified on selected elogs and boring logs to gain insight into possible depositional cycles occurring at various depths. Permeable units of appropriate thickness were identified as aquifers; poorly permeable units were identified as confining units. This information was then correlated with the available chronostratigraphic boundaries to establish continuity of similar sediment groups in the subsurface from borehole to borehole.

---

### Neural mechanisms of hierarchical planning in a virtual subway network [^dd2b1f96]. Neuron (2016). Low credibility.

Interestingly, the cost of representing a plan was incurred in units of context, but not in units of response switch. This explains the previous finding that humans seek to reach a new context earlier rather than later during navigation, as doing so reduces the computational burden of plan representations. This result additionally suggests that the hierarchical representation of the plan is encoded in terms of its abstract structure, rather than as a succession of macro-actions (e.g. "go straight, then go left"). Nor was the plan encoded in terms of the number of choice points, suggesting that the state space is not chunked purely on the basis of its physical properties (e.g. in terms of segments between choice points), but in a fashion that reflected the more abstract structure that they were encouraged to learn during training. What remains unclear, however, is whether context is represented as a cluster of interlinked perceptual states (i.e. stations on the yellow line), or as a series of macro-policies that dictate pursuit of a goal (e.g. keep going straight on until you reach a given switch point). A hint that participants relied on perceptual representation of context was provided by the finding that voxels in area V4 became active at context switches, as if participants were recalling the color of the new subway line (which was not shown to them during scanning). However, the precise nature of the information that characterizes a context remains an open question. For example, participants might have used information about the spatial organization of the map (the blue line runs from north to south or the red line is north of the green line).

Moreover, both behavior and the PMC also encoded an additional "U-turn" cost, that indexed the extent to which plans involved doubling back toward the current location along a different line. In the planning literature, it has been noted that goal-subgoal conflict — for example, the need to temporarily remove one disc from a peg and subsequently replace it in the Tower of London task — incurs a unique RT cost and poses a particular problem for patients with lateral prefrontal lesions. Consistent with this finding, U-turn costs were visible not only in the PMC, but also in lateral prefrontal regions. The existence of a unique U-turn cost in our navigation task demonstrates that participants not only encoded plans in the subway network as a hierarchical series of contexts, but also in terms of the geometry of the map that they saw in the training session.

---

### Aflibercept plus mFOLFOX6 induction chemotherapy for high-risk rectal adenocarcinoma… [^68ce08a8]. JAMA Network (2019). Excellent credibility.

eFigure 2. P-Value of the First Interim Analysis and its Relation to the Stopping Boundaries. eFigure 3. P-Value of the Second Interim Analysis and its Relation to the Stopping Boundaries. Data Sharing Statement Customize your JAMA Network experience by selecting one or more topics from the list below. This study presents the results for the primary end point and the early secondary end points of the trial. After preoperative CRT, residual tumor masses were semiquantitatively evaluated according to the 5-point regression grading scale established by Mandard et al. 14 The status of the surgical circumferential resection margin and the plane of surgery were assessed by pathologists using the classification proposed by Quirke et al.

15 A pCR was defined as the absence of viable tumor cells in the primary tumor and lymph nodes. To account for these interim analyses, the threshold for significance at the final analysis was penalized using an O'Brien-Fleming alpha spending function. Consequently, the study would be considered positive at the prespecified 20. 0% 2-sided α error if the P value comparing the pCR rates between the 2 arms was lower than. 1984 using a z test for independent binomial proportions without continuity correction. Both the GCR-3 and the EXPERT-C studies showed similar results in the experimental and control arms, in contrast to our results, which suggest an increased pCR in the experimental arm.

The Polish trial17 compared standard preoperative long-course CRT with experimental preoperative short-term radiotherapy and consolidation with 3 cycles of FOLFOX4 and reported a pCR rate of 14% in the consolidation CT group. In this trial, 34% and 35% of the patients were staged by computed tomography and digital rectal examination, respectively, and approximately 60% had cT4 tumors. 17.

---

### Recommendations for cardiac chamber quantification by echocardiography in adults: an update from the American Society of Echocardiography and the European association of cardiovascular imaging [^9a18e059]. Journal of the American Society of Echocardiography (2015). Medium credibility.

Left ventricular (LV) volume quantification by echocardiography — acquisition and measurement guidance are as follows: LV volumes should be measured from the apical four- and two-chamber views. Two-dimensional echocardiographic image acquisition should aim to maximize LV areas, while avoiding foreshortening of the left ventricle, which results in volume underestimation. Acquiring LV views at a reduced depth to focus on the LV cavity will reduce the likelihood of foreshortening and minimize errors in endocardial border tracings (Table 1). Because the issue of foreshortening is less relevant in 3D data sets, 3D image acquisition should focus primarily on including the entire left ventricle within the pyramidal data set. To ensure reasonably accurate identification of end-systole, the temporal resolution of 3D imaging should be maximized without compromising spatial resolution. At the mitral valve level, the contour is closed by connecting the two opposite sections of the mitral ring with a straight line. LV length is defined as the distance between the bisector of this line and the apical point of the LV contour, which is most distant to it. The use of the longer LV length between the apical two- and four-chamber views is recommended. Contrast agents should be used when needed to improve endocardial delineation when two or more contiguous LV endocardial segments are poorly visualized in apical views.

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^075005b9]. Magnetic Resonance in Medicine (2021). Medium credibility.

Regions A and B are geometrically symmetric about the z = 0 plane, with minimum energy solutions (assuming no E‐field constraint) yielding z‐symmetric field solutions and zero B 0 concomitant fields. Hence, the open diamond starting point (representing the minimum energy solution with no E‐field constraints) for the solid and dashed curves (in both black and green cases) coincide. The symmetry is broken by the addition of a patient model with an E‐field constraint.

The knee in the curves marks the point where magnetic energy, current density, and winding complexity increase rapidly as E max is driven to lower values. These complexities render unrealizable or impractical any gradient designs on the vertical portions of the curves to the left of the knee. Examination of winding patterns indicates that solutions that exhibit energy increases > 25% (or even less depending on coil type) above the global minimum energy become unrealizable (eg, demonstrating two or more "eyes" per half coil [four or more total eyes for an x or y coil] in the fingerprint wire patterns).

The red and purple dotted curves in Figure 2 represent two practical cases in which the primary coil currents are restricted to a single inner surface near the patient and the shield coil currents to an outer cylinder, while at the same time adding torque and eddy current constraints. Line segments acd of Figure 1 represent a primary winding surface consisting of a cone and a cylinder, whereas line segment ab represents its cylindrical shield winding; this yields designs similar to those proposed by previous literature 8, 22 and results in the red dotted curves in Figure 2. A second case is defined by restricting primary currents to the cylinder represented by line segment cd and shield currents to the cylinder ab; this yields designs similar to those proposed by previous literature 28 and produces the purple dotted curves in Figure 2. For both configurations, the eddy current surface is a 1‐m‐long, 620‐mm‐diameter cylinder, centered about the gradient isocenter and placed outside the shield winding of the gradient coil. The time = 0 eddy current error is constrained to a peak deviation less than 0.1% of the ideal gradient field on the surface of a 20‐cm‐diameter volume, corresponding to 100 µT for a 1 T/m step change in gradient strength. The torque constraint is set to zero for a uniform z‐directed B 0 main magnetic field. There is no net force for a perfectly uniform main B 0 field in all calculations.

---

### Dynamically induced cascading failures in power grids [^af922f15]. Nature Communications (2018). Medium credibility.

Cascade propagation

So far, we have shown that network cascades, i.e. secondary failures following an initial trigger, can well be caused by transient dynamical effects. We have proposed a model for power grids that takes this into account, and we have also developed a reliable method to predict whether additional lines can be affected by an initial damage, potentially triggering a cascade of failures. However, knowing whether a cascade develops or not does not answer another important question that is to understand how the cascade evolves throughout the network, and which nodes and links are affected and when. Intuitively, we expect that network components farther away from the initial failure should be affected later by the cascade. We have indeed observed that the time a line fails and its distance from the initial triggering link are correlated. Instead of merely using the graph topology to measure distances, we use a more sophisticated distance measure, the effective distance, based on the characteristic flow from one node to its neighbors. This idea has been first introduced in ref.in the context of disease spreading, where the effective distance has been shown to be capable of capturing spreading phenomena better than the standard graph distance. The effective distance between two vertices i and j can be defined in our case as:Here, we used the coupling matrix K ij as a measure of the flows between nodes. All pairs of nodes not sharing an edge, i.e. such that K ij = 0, have infinite effective distance d ij = ∞. At each node the cascade spreads to all neighbors but those that are coupled tightly, get affected the most and hence get assigned the smallest distance d ij. Furthermore, the effective distance is an asymmetric measure, since d ij ≠ d ji in general. The quantity d ij is a property of two nodes, while the most elementary damage in our cascade model affects edges. Hence, the concept of distance has to be extended from couples of nodes to couples of links. For instance, in the case of an unweighted network, it is possible to define the (standard) distance between two edges as the number of hops along a shortest path connecting the two edges. In the case of a weighted graph, we make use of the measure of effective distance in Eq. (12) to define a distance between two edges as the minimal path length of all weighted shortest paths between two edges. The distance between two edges can then be obtained based on the definition of distances between nodes { d ij }. Given the trigger edge (a, b), the distance from edge (a, b) to edge (i, j) is given by:i.e. it is the minimum length of the shortest paths, plus the effective distance between the two vertices a and b.

---

### Computed tomography imaging in the context of transcatheter aortic valve implantation (TAVI) / transcatheter aortic valve replacement (TAVR): an expert consensus document of the Society of Cardiovascular Computed Tomography [^6e41ac5f]. Journal of Cardiovascular Computed Tomography (2019). High credibility.

Contouring tools for annular segmentation — Freehand tool or Hounsfield-based contour detection yields a "Non-smoothened, irregular line following path of cursor or detected attenuation threshold" and can cause "Systematic overestimation of perimeter due to non-smoothened contour; Smoothing algorithms, can allow for more realistic perimeter assessment". Polygon methods use "Manual placed segmentation points connected by straight line without interpolation" and "Depending on the number of dots, this may yield a closer estimate of perimeter than freehand contouring without smoothing", whereas spline methods use "Manual placed segmentation points connected by a cubic spline interpolation – 'elastic ruler'" enabling "Accurate quantification of annular perimeter".

---

### Use of point-of-care ultrasonography in the NICU for diagnostic and procedural purposes [^6bf20122]. Pediatrics (2022). High credibility.

Lung POCUS — assessment is based on air–fluid interface artifacts including A-lines, B-lines, and air bronchograms; the commonly used protocol is to scan a total of 6 lung zones — 3 on the right and 3 on the left with zone 1 upper, zone 2 lower, and zone 3 lateral; examinations are usually performed supine, and if performed prone the position needs to be maintained for at least 1 hour; four patterns are graded with severity where the lowest score is 0 and the highest is 3 for each zone, and the total lung score is the sum of the 3 lung zones on both right and left sides; Figure 1 assigns scores to the patterns (Pattern 1 score 0, Pattern 2 score 1, Pattern 3 score 2, Pattern 4 score 3); lung US can accurately and reliably diagnose transient tachypnea of the newborn and offers value in differentiating TTN from RDS, the lung US severity score may guide early surfactant administration in preterm infants, and combined signs — absence of pleural sliding, complete absence of B lines with only A-lines, and a lung point — can accurately diagnose pneumothorax, with evidence that time to diagnosis can be shorter.

---

### Self-organized and directed branching results in optimal coverage in developing dermal lymphatic networks [^58b72247]. Nature Communications (2023). High credibility.

Fig. 5
Side-branching targets low-density regions to ensure parsimonious space-filling.

A Exemplary simulations under different assumptions for side-branching (red): random side-branching (each vessel has an equal probability to re-activate tips), density-dependent isotropic (iso) side-branching (which occurs preferentially in regions of overall low density), directional (dir) side-branching (which occurs in directions of relative low density), and combinations of directional and isotropic sensing. B Space-filling efficiency in simulations quantified by spatial fluctuation exponent as a function of the total number of branches in the network. We find that both density-sensing mechanisms allow for more efficient space-filling with a smaller overall number of branches, with an additive effect when combined (orange dots). C Representative skeletonized lymphatic network (blue) from an LYVE1-stained P13 ventral mouse ear pinna (n = 3 ear pinna, representing 3 mice). Orange nodes represent manually curated nascent sprouts. Boxed region (left): Magnified original image of a nascent sprout (yellow arrowhead) (scale bar: 50 μm). Boxed region (right): The initial directionality of a side branch can be represented by a vector (red arrow) connecting the root of the side branch to the side branch terminal tip. Neighboring branch segments (purple) within a circle of radius R (dashed line) can be used to determine their angle to side branch ψ. D Ratio of isotropic densities around side branches ρ s to densities ρ r around random points on the network for different values of R. Density ratios smaller than 1 for R < 200 μm indicate that side branches initiate in regions of smaller isotropic densities of LVs compared with randomly selected regions of the network. For larger R, both densities converge to the same value. E Relative frequencies (solid lines with markers) of angles to side branch ψ for different values of R. Dashed lines represent distributions corresponding to randomly selected points on the branched network. Dotted vertical lines represent ψ = ± 90°. F Ratio of probabilities to find LVs with an angle to side branch of |ψ| < 45° and |ψ| > 135°, i.e. neighbors that lie in the "front" and "back" of the side branch, for different values of R. Probability ratios around side branches (purple crosses) indicate that side branches initiate preferably into regions of lower density (ratio smaller than 1), in contrast with densities around random regions (blue circular markers) that exhibit an unbiased front/back ratio equal to 1. Metrics in (D – F) are calculated over n = 135 manually labeled nascent sprouts, representing three P13 ear pinna and mice. Plot markers and shaded error bands in (D) and (F) indicate mean values and +/−SDs. Source data for Fig. 5B, D–F are provided as a Source data file.

---

### Ultramicrosize griseofulvin tablets (ultramicrosize griseofulvin) [^b7da895b]. FDA (2025). Medium credibility.

HOW SUPPLIED

Ultramicrosize Griseofulvin Tablets USP, 125 mg, are supplied as white to off-white oval coated tablets debossed "C" on the left side of the score line and "P" on the right side of the score line on one side and "295"on the other side. The 125 mg strength is film-coated, functionally scored.

They are available as follows:

Bottles of 100: NDC 0115-1724-01

Ultramicrosize Griseofulvin Tablets USP, 250 mg, are supplied as white to off-white oval coated tablets debossed "C" on the left side of the score line and "P" on the right side of the score line on one side and "296"on the other side. The 250 mg strength is film-coated, functionally scored.

They are available as follows:

Bottles of 100: NDC 0115-1725-01

---

### Disagreement between two common biomarkers of global DNA methylation [^9f8a450f]. Clinical Epigenetics (2016). Low credibility.

Fig. 3
Plots of the differences between the measurements of DNA methylation using the LINE-1 and the LUMA based bioassays, for respective data subsets. Left: plots of the difference between the means of the two techniques (Bland and Altman plots). Each dot illustrates a single difference. The fixed bias is represented by the gap between the X axis, corresponding to a zero difference (magenta solid line) and a solid blue line parallel to the X axis. The limits of agreement are indicated by the red dashed lines that limit the 95% confidence interval (± 1.96 standard deviations) of the measurement differences on either side of the mean difference. The proportional bias is indicated by a solid trend line in the same color as the data points. Right: distribution histogram of the differences between the measurements of the two assays. The dashed line represents normal distribution. Kolmogorov-Smirnov test for normal distribution accepted normality (p > 0.05). The plots were drawn using the "epade" (A. Schulz,) package

---

### How I read an article that uses machine learning methods [^0f2f5676]. Blood Advances (2023). Medium credibility.

Step 1: Understand the problem being addressed. The first step in reading an ML paper is to understand the problem that the authors are trying to solve and, more importantly, understand the clinical or scientific impact of solving this problem. In other words, if the aim of the study is to solve a clinical problem, how does the answer or the recommendation provided by the algorithm help physicians or researchers in their day-to-day practice, and is this solution mature enough to be implemented in clinical workflows? Major clinical problems in health care can mainly affect either patient outcomes or operations (can I make the process easier and faster for the patient and the health care system?).

Step 2: Assess the quality of the data. The quality of the data used to build the ML model is crucial for the validity of the results. Following are some questions that can be used to evaluate the data:
1 Sample size: Is the size of the training, validation, and test sets enough to build a reproducible and generalizable ML model? Is this size of the data appropriate for the chosen methods (ie, some methods are "data-hungry" and understanding which methods require larger datasets is key)? However, different algorithms require different data types (image, tabular, text, or others) and sizes, and there are no rules of thumb or formulas that can estimate the perfect data.
2 Relevance: Are the data appropriate and relevant to the problem that the model is trying to solve?
3 Accuracy: How are the data collected and annotated (human vs natural language process). How are the data transformed to make it ready for ML use, etc.
4 Consistency: Are the data consistent? Do they have any missing values and how the authors dealt with this?
5 Representativeness: The data should be representative of the population being studied.
6 Balance: The data should be balanced, with roughly equal representation of all relevant classes or groups. However, most health care data are unbalanced. It is critical to understand how the authors dealt with unbalanced data.
7 Bias: To evaluate bias in data, it is important to look at the distribution of certain characteristics, such as race, gender, or socioeconomic status, among the samples in the data set, and how the data were collected. This will help to identify any disparities or overrepresentation of certain groups, which can indicate the presence of bias in the data. It is critical to evaluate bias at this stage because if this is not addressed properly, it could produce a biased model.

---

### How do you design randomised trials for smaller populations? A framework [^9ac3f0db]. BMC Medicine (2016). Low credibility.

Exploring less common approaches to reducing sample size

We now consider some less standard approaches to bringing the sample size requirements closer to the numbers it is feasible to recruit in a reasonable time frame.

Step 3: Relaxing α by a small amount, beyond traditional values

The much-criticised 5% significance level is used widely in much applied scientific research, but is an arbitrary figure. It is extremely rare for clinical trials to use any other level. It may be argued that this convention has been adopted as a compromise between erroneously concluding a new treatment is more efficacious and undertaking a trial of an achievable size and length. Settings where traditionally sized trials are not possible may be just the area where researchers start to break this convention, for good reason.

In considering the type I error, it is critical to consider the question: 'What are the consequences of erroneously deciding to use a new treatment routinely if it is truly not better?'

Taking the societal perspective as before, we might consider the probability of making a type I error, thus erroneously burdening patients with treatments that do not improve outcomes, or even worsen them, while potentially imposing unnecessary toxicity.

First, for conditions where there are only enough patients available to run one modestly sized randomised trial in a reasonable time frame, research progress will be relatively slow, and making a type I error may be less of a concern than a type II error. In contrast, making several type I errors in a common disease could lead in practice to patients taking several ineffective treatments; for a disease area where only one trial can run at any given time, the overall burden on patients is potentially taking one ineffective treatment that does not work.

Thus, if we take the societal perspective with the trials in Table 1 then, if each trial was analysed with α = 0.05 and we see (hypothetically) 40% positive results, then the expected number of false positive trials is given in the final column. We also assumed 10% and 70% positive results, with qualitatively similar conclusions.

---

### High-yield parallel fabrication of quantum-dot monolayer single-electron devices displaying coulomb staircase, contacted by graphene [^f10f8243]. Nature Communications (2021). High credibility.

Multivariate logistic regression is used to show that device area predicts the occurrence of both StC and ShC with a p value of 0.00177 (Fig. 3 e) (see Supplementary Note 1 for further discussion).

Fig. 3
Correlation of step height and probability with area.

a Current heights of the first positive-bias (circles) and negative-bias (triangles) steps vs device area, for all StC. The size of each data point corresponds to the quality of the I – V trace: larger points represent higher-quality StC with more steps, less noise and/or sharper steps. Devices with areas < 100 nm 2 are shown at 100 nm 2. OL batch 1 is offset laterally by a factor of 100 for clarity. The data cluster into groups and show a positive correlation when devices are split into 36-sample fabrication batches. Within each batch there is an additional separation into discrete conduction groups, each displaying a different range of current step heights. b – d Histograms of step height divided by area for each batch in (a), with matching colours, showing that the distributions have widths of at most an order of magnitude. e Logistic-regression analysis estimating the probability of StCs for different OL areas. Various independent variables have been tested, including types of device perimeter, but device area is the best predictor of StC and ShC with a p value of 0.00177. In the analysis, StC (SmC and ShC) are represented as 1 (0). Green banding around the probability line shows the 95% confidence interval across the area range. Histograms above and below the regression line show the curve-type counts for different device areas. Reducing the device area from 18 to < 1 μ m 2 increases the probability of measuring a StC from 0.12 to 0.65.

---

### Guidelines for handling decedents contaminated with radioactive materials [^1a0b0640]. CDC (2007). Medium credibility.

Body bag handling and control point contamination control — Some jurisdictions use plastic remains containers for the body bags and this is recommended because the team can transport the body bag out of the area and lower it into the plastic container; the body inside the body bag is emitting radiation, so the body bag or container cannot be frisked at the control point. Swipe the container with a piece of tissue, place the swipe paper on a clear surface away from the body, and check it with the pancake probe to ensure the exterior of the body bag is free of contamination; if there is no possibility of alpha- or beta-emitting isotopes, wrap the pancake probe in plastic to prevent its contamination. There should be a table outside the cordoned off area at the control point, divided into a clear and a contaminated section, and when the initial survey team exits the area, each piece of equipment – survey instrument, radio, dosimeter, etc – should be surveyed by the control point watch or another team member wearing gloves and using a pancake probe; the surveys should be done in accordance with FEMA guidelines or vendor's instructions for the instrument in use, and place clean or contaminated items on the appropriate side of the table.

---

### Sonographic biometry of the frontal lobe in normal and growth-restricted neonates [^6298668b]. Pediatric Research (2004). Low credibility.

Assessing the impact of restricted intrauterine growth on neonatal frontal lobe (FL) dimensions is important. We aimed to create a sonographic nomogram of FL dimensions in neonates at different gestational ages (GA) and evaluate the impact of small head circumference (HC) on FL dimensions. We conducted sonographic biometry of the FL at birth. We included 218 newborn infants born at GA of 24–43 wk: appropriate for GA and normal HC (n = 178), and small for GA and small HC (n = 23). Infants with a 5-min Apgar score < 7, severe congenital malformations, or chromosomal abnormalities were excluded. Through a coronal ultrasound scan via the anterior fontanelle at the level where the most lateral point of the left Sylvian fissure was best demonstrated, we drew a triangle connecting the most lateral point of the Sylvian fissure, the corpus callosum, and the subcalvarian point of the interhemispheric fissure. We measured the three sides of the triangle, Sylvian-fontanellar distance, Sylvian-callosal distance, and fontanellar-callosal distance, and calculated the frontal triangular area. All four FL dimensions increased significantly between 24 and 43 wk of gestation in both appropriate for GA-normal HC and small for GA-small HC neonates, and were strongly correlated with HC and birth weight. Regression lines of GA against Sylvian-fontanellar distance, Sylvian-callosal distance, fontanellar-callosal distance, and frontal triangular area in the appropriate for GA-normal HC group differed significantly from those of the small for GA-small HC group (p < 0.05). Male neonates had significantly larger Sylvian-fontanellar and Sylvian-callosal distances than females (p < 0.01 and p < 0.015, respectively). In conclusion, FL measures increased significantly between 24 and 43 wk of gestation, and were strongly correlated with HC. We speculate that a sonographically small fetal HC implies growth restriction of the fetal FL.

---

### Young children's reasoning about many-to-one correspondences [^7e3c4d69]. Child Development (2003). Low credibility.

Young children's understanding of many-to-one correspondence problems was studied to illuminate the developmental transition from additive to multiplicative numerical knowledge. A many-to-one correspondence exists when a fixed number of target objects (greater than 1) is associated with each of a set of referents, as in putting 3 flowers in each of several vases. Two experiments examined effects of a brief training procedure that highlighted the iterative nature of many-to-one mappings. In Experiment 1, 5- and 6-year-old children did not benefit from the training, but a subset of 7-year-olds did. In Experiment 2, 7-year-olds showed training effects that extended to generalization problems. Patterns of performance across experimental and generalization problems suggested that some children had difficulty applying what they learned from training to the experimental problems.

---

### Attractive versus golden ratios: formula of utopian beauty through comparison of facial proportions among worldwide celebrities and average people [^e884228e]. The Journal of Craniofacial Surgery (2022). Medium credibility.

Introduction

Beauty criteria change according to trends, cultures, and expectations. So, the golden ratios are not enough to understand the actual beauty concept.

Objective

It is aimed to create a method and formula to define beauty in terms of different facial measurements and ratios as variables.

Methods

Frontal view photographs of 50 celebrities and 50 volunteers (female [n = 70] and male [n = 30]) were obtained. Thirty-three specific facial points were used. Fifty-nine measurements of distances between those points and ratios of those distances are used as statistical variables. Mean values of those variables for celebrities are compared with all participants. Then, "total beauty score" using statically significant differences is defined. Points according to the importance level of interested value are assigned; 1 point for a significance of 0.001 ≤ P < 0.05 and 2 points for P < 0.001. Possible independent variables for the prediction of Utopian Beauty Score were determined using linear regression analysis. Finally, 10 variables (6 measurements and 4 ratios) are used to determine a formula for beauty.

Results

In celebrities, the distance between head apex and hair border, lower lip vertical length, the distance between brow medial borders and forehead vertical length were higher than the average population (P < 0.001, 0.023, 0.034, 0.001, respectively). However, the width of columella, a length between bilateral ala nasi, horizontal face, and vertical nose length, and the distance between brow apexeyelash line were shorter (P = 0.005, < 0.001, < 0.001, < 0.001, < 0.001, respectively). Some study variables had severely significant correlations with the total beauty point (M29, r = -0.744, P < 0.001; R19, r = -0.745, P < 0.001; and R30, r = -0.735, P < 0.001). The linear regression formula for Utopian Beauty Score was determined according to statistically significant variables as y = 86.5–3.6 M5 + 8.1 M14 + 11.1 M20 - 6.4 M25-8.7 M29-10.3 M30-15.6 R19 + 9.3 R20 + 16.4 R25 + 18.3 R26.

Conclusions

A large forehead, small nose with lifted tip, plump lip, brows with lateral apex, well-spaced eyes, and ovoid, elliptical face lines are seem to be more attractive. Additionally, a method to create a formula for beauty with variables of different measurements and ratios of facial points are determined.

---

### Predictive ability of pressure-corrected arterial stiffness indices: comparison of pulse wave velocity, cardio-ankle vascular index (CAVI), and CAVI0 [^546d7e4d]. American Journal of Hypertension (2022). Medium credibility.

CAVI 0

Similar to haPWV and CAVI, no left–right CAVI 0 difference was observed. CAVI 0 crude survival curves were very similar to CAVI survival curves (compare Figure 1e vs. c and Figure 1f vs. d), with R-CAVI 0 showing smaller P values for DHFA prediction than L-CAVI 0. In Cox regression analyses (Table 2), left–right differences in P value persisted, and L-CAVI 0 and R-CAVI 0 were only significantly predictive in an unadjusted model.

Comparison of predictive powers of haPWV, CAVI, and CAVI 0

Figure 2 shows the results of Cox regression from Table 2 as volcano plots. In all 3 panels, a trend emerged suggesting that, with increasing blood pressure correction (i.e. from haPWV to CAVI to CAVI 0), predictive power decreases as visualized by the arrows (standardized hazard ratio decreases while P increases, noting that the y -axis shows negative log-transformed P values).

Figure 2.
Volcano plots for prediction of death or heart failure (HF)-related hospital admission using left (L) and right (R) heart-to-ankle pulse wave velocity (haPWV), cardio-ankle vascular index (CAVI), and CAVI 0. Right-pointing triangles indicate right-sides measures; left-pointing triangles indicate left-sided measures. Small horizontal lines are drawn to clarify triangle direction. Long-tailed, diagonal arrows illustrate that, with increasing blood pressure correction, power to predict outcome decreases, suggesting that part of the predictive power of blood pressure-dependent stiffness metrics arises from the predictive power of blood pressure per se. This trend persists in unadjusted (a), MAGGIC and HF status-adjusted (b), and additionally SBP-adjusted (c) analyses. Abbreviations: HR, hazard ratio; MAGGIC, Meta-Analysis Global Group in Chronic Heart Failure; SBP, systolic blood pressure.

---

### Standards of care in diabetes – 2025 [^ef149bc3]. Diabetes Care (2025). High credibility.

Regarding specific circumstances for diabetic nephropathy, more specifically with respect to pediatric patients, ADA 2025 guidelines recommend to determine the eGFR at the time of diagnosis and annually thereafter.

---

### ACOEM practice guidelines: elbow disorders [^4e95c510]. Journal of Occupational and Environmental Medicine (2013). Medium credibility.

ACOEM elbow disorders — strength-of-evidence criteria define levels and thresholds as follows: levels are labeled "A = Strong evidence base", "B = Moderate evidence base", "C = Limited evidence base", and "I = Insufficient evidence†"; A requires "Two or more high-quality studies", B requires "At least one high-quality study or multiple moderate-quality studies", C requires "At least one study of moderate quality", and I applies when "Evidence is insufficient or irreconcilable". Study quality scoring specifies "High-quality studies are scored 8.0 to 11.0 points. Moderate-quality studies are scored 4.0 to 7.5 points". The guideline notes "Insufficient evidence recommendations are, by definition, consensus-based guidance".

---

### A history-dependent integrase recorder of plant gene expression with single-cell resolution [^8474c196]. Nature Communications (2024). High credibility.

Fig. 4
The history-dependent recorder reveals two distinct stomatal populations.

a State 2 and State α stomata. A confocal image shows two stomata: one in State 2 (green triangle) and one in State α (white triangle). Below the image, the total proportion of stomata in each state is shown in a barplot, with each bar representing one of the three best-performing stomata recorder lines (labeled on the x -axis). n = 257, n = 172, and n = 174 stomata were characterized for T2P1, T2P4, and T2P7. b Alternate paths of stomatal development. The stereotypical understanding of stomatal development follows an anisocytic (A) scheme, with the meristemoid dividing asymmetrically three times before dividing into two guard cells. Non-anisocytic (NA) stomata divide asymmetrically zero, one, or two times before the terminal division. Recorder output is predicted to differ between stomata types due to varied timing of integrase onset. An A stomata is surrounded by exactly three cells of unequal size, while an NA stomata can have two, four, five, or three equally sized neighbor cells. c Characterization of recorder state in A vs. NA stomata. The boxes represent the proportion of each stoma type (anisocytic in light gray and non-anisocytic in dark gray) within each of the three stomata recorder lines (x -axis) that are in State 2 (left) and State α (right). Each box represents the middle quartiles of the respective dataset, and the whiskers represent the highest and lowest quartiles. The center of each box is the median. Each point represents the proportion of stomata in each state for one T2 seedling. 10 seedlings were counted per line. For each seedling, a minimum of 15 of each stomata type was counted (at least 30 total stomata per seedling). To evaluate the statistical significance between the result for A and NA stomata populations, a two-sided Student's t test was performed (✱ p < 0.05, ✱✱ p < 0.01, ✱✱ p < 0.001). From left to right in the plots, p- values are p = 0, p = 0.0001, p = 0, p = 0, p = 0.0001, p = 0.001. Source data are provided as a Source Data file.

---

### Quantitative verification of the keyhole concept: a comparison of area of exposure in the parasellar region via supraorbital keyhole, frontotemporal pterional, and supraorbital approaches [^48bddfbc]. Journal of Neurosurgery (2013). Low credibility.

Object

This study was designed to determine if the "keyhole concept", proposed by Perneczky's group, can be verified quantitatively.

Methods

Fourteen (3 bilateral and 8 unilateral) sides of embalmed latex-injected cadaveric heads were dissected via 3 sequential craniotomy approaches: supraorbital keyhole, frontotemporal pterional, and supraorbital. Three-dimensional cartesian coordinates were recorded using a stereotactic localizer. The orthocenter of the ipsilateral anterior clinoid process, the posterior clinoid process, and the contralateral anterior clinoid process are expressed as a center point (the apex). Seven vectors project from the apex to their corresponding target points in a radiating manner on the parasellar skull base. Each 2 neighboring vectors border what could be considered a triangle, and the total area of the 7 triangles sharing the same apex was geometrically expressed as the area of exposure in the parasellar region.

Results

Values are expressed as the mean ± SD (mm(2)). The total area of exposure was as follows: supraorbital keyhole 1733.1 ± 336.0, pterional 1699.3 ± 361.9, and supraorbital 1691.4 ± 342.4. The area of exposure on the contralateral side was as follows: supraorbital keyhole 602.2 ± 194.7, pterional 595.2 ± 228.0, and supraorbital 553.3 ± 227.2. The supraorbital keyhole skull flap was 2.0 cm(2), and the skull flap size ratio was 1:5:6.5 (supraorbital keyhole/pterional/supraorbital).

Conclusions

The area of exposure of the parasellar region through the smaller supraorbital keyhole approach is as adequate as the larger pterional and supraorbital approaches. The keyhole concept can be verified quantitatively as follows: 1) a wide area of exposure on the skull base can be obtained through a small keyhole skull opening, and 2) the side opposite the opening can also be visualized.

---

### A statistical solution to the chaotic, non-hierarchical three-body problem [^7dff7dc7]. Nature (2019). Excellent credibility.

The three-body problem is arguably the oldest open question in astrophysics and has resisted a general analytic solution for centuries. Various implementations of perturbation theory provide solutions in portions of parameter space, but only where hierarchies of masses or separations exist. Numerical integrations 1 show that bound, non-hierarchical triple systems of Newtonian point particles will almost 2 always disintegrate into a single escaping star and a stable bound binary 3,4, but the chaotic nature of the three-body problem 5 prevents the derivation of tractable 6 analytic formulae that deterministically map initial conditions to final outcomes. Chaos, however, also motivates the assumption of ergodicity 7–9, implying that the distribution of outcomes is uniform across the accessible phase volume. Here we report a statistical solution to the non-hierarchical three-body problem that is derived using the ergodic hypothesis and that provides closed-form distributions of outcomes (for example, binary orbital elements) when given the conserved integrals of motion. We compare our outcome distributions to large ensembles of numerical three-body integrations and find good agreement, so long as we restrict ourselves to 'resonant' encounters 10 (the roughly 50 per cent of scatterings that undergo chaotic evolution). In analysing our scattering experiments, we identify 'scrambles' (periods of time in which no pairwise binaries exist) as the key dynamical state that ergodicizes a non-hierarchical triple system. The generally super-thermal distributions of survivor binary eccentricity that we predict have notable applications to many astrophysical scenarios. For example, non-hierarchical triple systems produced dynamically in globular clusters are a primary formation channel for black-hole mergers 11–13, but the rates and properties 14,15 of the resulting gravitational waves depend on the distribution of post-disintegration eccentricities.

---

### Anisotropic thermal conductivity of antigorite along slab subduction impacts seismicity of intermediate-depth earthquakes [^269b5265]. Nature Communications (2024). High credibility.

Fig. 6
Comparison of the maximum depth ofandisotherms between the reference model 1, in the-axis, and all other models in the-axis.

For simplicity we plotted only the models of 1, 2, 6, and 10 (all data are reported in Table S5). The marker color represents a given model with olive green for model 1, green for model 2, purple for vertical insulator, and teal for horizontal insulator. The marker shape represents the maximum depth of a given isotherm at a given depth inside the slab: squares, down-pointing triangles, and five-pointed stars forisotherm at 7 km, 9 k, and1 kinside the slab, respectively; diamonds, up-pointing triangles, and six-pointed stars forisotherm at, andkm inside the slab, respectively. The solid black line represents thecorrelation between the two models, where. We computed the difference between the models as. The dashed blue lines on the upper left side indicate deeper isotherms due to colder conditions. The dashed red lines on the lower right side indicate shallower isotherms due to hotter conditions. Note that in the model 10 (horizontal insulator - teal) the maximum depths of theandisotherms are shallower than the reference model 1 on the external side of the hydrous layer (7 k), whereas they are deeper on the internal side (1 k).

---

### Predictive neural representations of naturalistic dynamic input [^63aea69f]. Nature Communications (2023). High credibility.

Statistical analysis

Before group-level statistics (and plotting), we Fisher Z-transformed all beta weights to get normally distributed values. Because statistical testing of the dRSA lag-plots involves many comparisons (at each lag time-point), we performed group-level nonparametric permutation testing with cluster-based correction for multiple comparisons, as implemented in Fieldtrip's ft_timelockstatistics.m function, with the method parameter set to "montecarlo". We used t-values from a one-sided t-test as test statistic (i.e. to test whether beta weights are significantly larger than zero), we used the sum over the t-values belonging to a cluster of significant time points as a measure of cluster size, and we ran the permutation 25,000 times for each analysis. We selected a lenient and strict threshold for significance, with a single-sample threshold at p < 0.01 or p < 0.001, combined with a cluster-size threshold at p < 0.05 or p < 0.01, respectively. In the main results (Fig. 2a), lenient significant intervals are indicated by thick horizontal bars with colors matching the respective ROI line plots, while strict significant intervals are indicated with thin black or white horizontal bars inside the colored bars. Only significant clusters larger than what can be expected by chance survive this procedure.

---

### Rivastigmine (rivastigmine transdermal system) [^3a1398ab]. FDA (2025). Medium credibility.

The diagram represents areas on the body where Rivastigmine Transdermal System may be applied.

Only 1 patch should be worn at a time. Do not apply multiple patches to the body.

Step 2. Remove the Rivastigmine Transdermal System from the pouch (See Figure C).

Carefully cut the pouch along the dotted line to open and remove the Rivastigmine Transdermal System. Save the pouch for later use.

Do not cut or fold the Rivastigmine Transdermal System itself.

Step 3. Remove 1 side of the adhesive liner (See Figure D).

A protective liner covers the sticky (adhesive) side of the Rivastigmine Transdermal System. Peel off 1 side of the protective cover. Do not touch the sticky part of the Rivastigmine Transdermal System with your fingers.

Step 4. Apply the Rivastigmine Transdermal System to your skin (See Figure E).

Apply the sticky (adhesive) side of the Rivastigmine Transdermal System to your chosen area of skin and then peel off the other side of the protective cover.

Press down on the Rivastigmine Transdermal System firmly for 30 seconds to make sure that the edges stick to your skin (See Figure F).

---

### Evaluation and referral for developmental dysplasia of the hip in infants [^931f6720]. Pediatrics (2016). Medium credibility.

World Health Organization screening criteria and their application to developmental dysplasia of the hip (DDH) are outlined. The page lists "TABLE 1 World Health Organization Criteria for Screening for Health Problems", including items 1–5 ("1. The condition should be an important health problem" through "5. There should be a suitable test or examination for the condition") and items 6–10 ("6. The test should be acceptable to the population" through "10. Case finding should be a continuous process"). The narrative states, "The AAP believes DDH fulfills most of these screening criteria (Table 1), except for an understanding of the natural history of hip dysplasia and an agreed-on policy of whom to treat", and reiterates, "A reasonable goal for screening is to prevent the late presentation of DDH after 6 months of age".

---

### Rotator cuff tendinopathy diagnosis, nonsurgical medical care, and rehabilitation: a clinical practice guideline [^a4079329]. The Journal of Orthopaedic and Sports Physical Therapy (2025). High credibility.

Grades of recommendations — This table defines grades A–F and links each to a strength-of-evidence statement and corresponding Level of Obligation. Grade A is defined as "A preponderance of level I and/or level II studies support the recommendation", with Level of Obligation (Based on Treatment Effects): "Must: benefits substantially outweigh harms; Should: benefits moderately outweigh harms; May: benefits minimally outweigh harms or benefit/harm ratio is value dependent; Should not: harms minimally or moderately outweigh benefits or evidence of no effect; Must not: harms largely outweigh benefits". Grade B is "A single high-quality randomized controlled trial or a preponderance of level II studies support the recommendation", with obligations "Should: benefits substantially outweigh harms; May: benefits moderately or minimally outweigh harms or benefit/harm ratio is value dependent; Should not: evidence that harms outweigh benefits or evidence of no effect". Grade C is "A single level II study or a preponderance of level III and IV studies, including statements of consensus by content experts, support the recommendation", with obligations "Should: benefits substantially outweigh harms; May: benefits moderately or minimally outweigh harms or benefit/harm ratio is value dependent; Should not: harms minimally or moderately outweigh benefits". Grade D is "Higher-quality studies conducted on this topic disagree with respect to their conclusions", with obligation "May: conflicting evidence, the benefit/harm ratio is value dependent". Grade E is "A preponderance of evidence from animal or cadaver studies, from conceptual models/principles, or from basic science/bench research support this conclusion", with obligations "May: in the absence of evidence from clinical studies, theoretical and/or foundational evidence supports benefit" and "Should not: in the absence of evidence from clinical studies, theoretical and/or foundational evidence suggests strong risk of harms". Grade F is "Best practice based on the clinical experience of the guideline development team supports this conclusion", and the table also specifies Level of Obligation (Based on Assessment/Diagnosis): "Must: strongly supported by consensus-based best practice/standard of care; Should: moderately supported by best practice/standard of care; May: supported by expert opinion in the absence of consensus; Should not: best practice/standard of care indicates potential harms; Must not: potential harms are strongly supported by consensus-based best practice/standard of care".

---

### Evidence-based guidelines for the pharmacological treatment of schizophrenia: updated recommendations from the British Association for Psychopharmacology [^eacb6a16]. Journal of Psychopharmacology (2020). High credibility.

Regarding follow-up and surveillance for schizophrenia, more specifically with respect to assessment of treatment response, BAP 2020 guidelines recommend to consider defining a sufficient response to initial treatment as a reduction of 25% in total score on a symptom assessment scale or a one-point improvement on the Clinical Global Impressions scale within 2 weeks. Define a definitive response as a 40–50% reduction or a two-point improvement on the Clinical Global Impressions scale after 6 weeks. Aim for symptom remission, such as no more than a mild severity rating for a range of Positive and Negative Syndrome Scale items, as the target for the overall treatment of the initial episode.

---

### How do you design randomised trials for smaller populations? A framework [^45132483]. BMC Medicine (2016). Low credibility.

How should we approach trial design when we can get some, but not all, of the way to the numbers required for a randomised phase III trial?We present an ordered framework for designing randomised trials to address the problem when the ideal sample size is considered larger than the number of participants that can be recruited in a reasonable time frame. Staying with the frequentist approach that is well accepted and understood in large trials, we propose a framework that includes small alterations to the design parameters. These aim to increase the numbers achievable and also potentially reduce the sample size target. The first step should always be to attempt to extend collaborations, consider broadening eligibility criteria and increase the accrual time or follow-up time. The second set of ordered considerations are the choice of research arm, outcome measures, power and target effect. If the revised design is still not feasible, in the third step we propose moving from two- to one-sided significance tests, changing the type I error rate, using covariate information at the design stage, re-randomising patients and borrowing external information. We discuss the benefits of some of these possible changes and warn against others. We illustrate, with a worked example based on the Euramos-1 trial, the application of this framework in designing a trial that is feasible, while still providing a good evidence base to evaluate a research treatment. This framework would allow appropriate evaluation of treatments when large-scale phase III trials are not possible, but where the need for high-quality randomised data is as pressing as it is for common diseases.

---

### Assessment of right ventricular function in the research setting: knowledge gaps and pathways forward. An official American Thoracic Society research statement [^a414d253]. American Journal of Respiratory and Critical Care Medicine (2018). Medium credibility.

Right ventricle–pulmonary artery coupling and diastolic stiffness (Figure 4) are defined by pressure–volume relations as follows: arterial elastance (Ea) is ESP/SV and, in the volume method, end-systolic elastance (Ees) is ESP/ESV, yielding a simplified Ees/Ea of ESV/SV. In the pressure method, Ees is (Pmax − mPAP) divided by SV with a simplified Ees/Ea of (Pmax/mPAP − 1). In the single-beat method, Ees is a straight line from Pmax tangent to the pressure–volume relationship and Ea is drawn from the Ees point to EDV at zero pressure. Diastolic stiffness (β) is obtained by fitting P = α(eβV − 1) to pressure–volume data measured at beginning and end diastole.

---

### European Stroke Organisation (ESO) and European Association of Neurosurgical Societies (EANS) guideline on stroke due to spontaneous intracerebral haemorrhage [^a24b784e]. European Stroke Journal (2025). High credibility.

Regarding diagnostic investigations for intracerebral hemorrhage, more specifically with respect to initial evaluation, EANS/ESO 2025 guidelines recommend to consider using algorithms such as the DIAGRAM for targeted investigation of the cause of spontaneous ICH to improve the performance of prediction regarding the underlying cause, compared to standard care.

---

### Standards of care in diabetes – 2025 [^cb4a5970]. Diabetes Care (2025). High credibility.

Regarding diagnostic investigations for diabetes mellitus type 1, more specifically with respect to general principles, ADA 2025 guidelines recommend to obtain a complete medical evaluation at the initial visit and follow-up, as appropriate, to:

- confirm the diagnosis and classify diabetes

- ssess glycemic status and previous treatment

- evaluate for diabetes complications, potential comorbid conditions, and overall health status

- identify care partners and support system

- assess social determinants of health and structural barriers to optimal health and health care

- review risk factor management in the patient with diabetes

- begin engagement with the patient with diabetes in the formulation of a care management plan including initial goals of care

- develop a plan for continuing care.

---

### Applying design-thinking principles to practice-based pharmacy research [^5b8f2382]. The Annals of Pharmacotherapy (2023). Medium credibility.

Design thinking is an approach to problem solving that focuses on a solution to a problem. This systematic approach can be applied to practice-based research or implementation projects in your practice setting. It may be useful for starting new projects as well as revisiting past projects that may not have yielded meaningful results. The design-thinking process begins with identifying a problem or knowledge gap and then the steps include: (1) understanding the problem, (2) observing the problem, (3) defining the problem, (4) brainstorming possible solutions, (5) prototyping the best solution, and (6) testing the solution.

---

### 2014 ESC guidelines on diagnosis and management of hypertrophic cardiomyopathy: the task force for the diagnosis and management of hypertrophic cardiomyopathy of the European Society of Cardiology (ESC) [^11206c8f]. European Heart Journal (2014). Medium credibility.

Regarding diagnostic investigations for syncope, more specifically with respect to initial ECG, ESC 2014 guidelines recommend to obtain a 12-lead ECG to identify the cause of symptoms in patients with unexplained syncope.

---

### Colorectal cancer screening and prevention [^390b568a]. American Family Physician (2025). High credibility.

Regarding screening and diagnosis for colon cancer, more specifically with respect to indications for screening, high-risk individuals, family history, AAFP 2025 guidelines recommend to obtain CRC screening in patients with ≥ 1 first-degree relatives with CRC or adenomatous polyps, starting at 40 years of age or 10 years before the age of the youngest relative at the time of their diagnosis.

---

### Progression from laparoscopic-assisted to totally laparoscopic distal gastrectomy: comparison of circular stapler (I-DST) and linear stapler (BBT) for intracorporeal anastomosis [^a6a9c446]. Surgical Endoscopy (2013). Low credibility.

The δ anastomosis technique, a B-I gastrectomy procedure performed in TLDG, was first introduced by Kanaya et al. This technique is relatively simple, because it involves a wider lumen anastomosis and has a lower incidence of complications. Despite the fact that the technique has been widely used in Japan and South Korea, it is associated with certain problems that make its incorporation challenging. One of the problems associated with the technique is that because the duodenum needs to be transected from the posterior wall toward the anterior wall, the anastomotic method must be predetermined before transecting the duodenum. Another problem is that because the duodenum must be twisted for anastomosis, not only must the greater curvature side of the duodenum be detached, but the dorsal and the lesser curvature sides must be completely detached as well. As the name of the procedure implies, the anastomosed site forms a δ shape, and the blood flow through the duodenal stump forming the apex must be decreased. In addition, because both the stomach and duodenum are twisted and their posterior walls are anastomosed, more tension is generated in the anastomosis compared with end-to-end anastomosis.

For intracorporeal B-I anastomosis in TLDG, the triangulating stapling technique was reported by Tanimura et al. In this method, the duodenum is transected in any direction, and by forming a triangle, the anastomosis lumen is made wide with no ischemic areas. However, the first introverted anastomosis, which forms the base of the triangle, is cumbersome once all of the staple lines on the stomach and duodenum have been cut off. There are some differences between the stomach and duodenum in terms of lumen size, wall thickness, and wall extensibility. For these reasons, in the first anastomoses, it can be difficult to connect accurately the posterior walls and the following anterior wall anastomoses.

To address these problems, BBT anastomosis using linear staplers focuses on the following points. First, instead of completely opening the stomach and duodenal stumps, small openings are made just wide enough to insert one of the jaws of the linear stapler. The first anastomosis is then performed, which forms the base of the triangular anastomosis, by anastomosing the immediate posterior wall of each stump to create an anastomosis similar to that formed by end-to-end anastomosis. At this point, the four layers of the gastroduodenal wall look like a bound book; therefore, we named this method the book-binding technique.

---

### Treatment of stage I and II non-small cell lung cancer: diagnosis and management of lung cancer, 3rd ed: American College of Chest Physicians evidence-based clinical practice guidelines [^fda69d4a]. Chest (2013). Medium credibility.

Surgical margins in non-small cell lung cancer (NSCLC) resection are not yet defined, with histologic margin status typically available only after surgery and staple lines representing 3 to 5 mm of tissue not assessed intraoperatively. In clinical stage I wedge resections, negative margins had an average ratio of 0.9 ± 0.6 versus 0.3 ± 0.3 for positive margins, and there were no malignant margins when ratios were > 1.0 or when the absolute margin was > 2 cm; a 1-cm tumor with 2 cm from the tumor edge to the staple line corresponds to a ratio of 2 (2:1). Retrospective data reported that 89% (24 of 27) of local recurrences occurred with margins ≤ 2 cm, and that a margin to tumor diameter ratio < 1.0 was associated with higher local recurrence (25% vs 6.2%, P = 0.0014) with the follow-up relatively short (18 months); local recurrence was also frequently associated with margins < 1 cm. Many prospective protocols involving sublobar resections have arbitrarily set a margin of 2 cm, and although data are limited, a margin of ≥ 2 cm is a reasonable goal for nonanatomic resections; for smaller tumors a margin at least as large as the tumor diameter (at least 1-cm margins for 1-cm tumors) is probably adequate.

---

### Patterned mechanical feedback establishes a global myosin gradient [^a9cf3bef]. Nature Communications (2022). High credibility.

Fig. 2
Patterned contractility by optogenetics redirects flows.

A Schematic of optogenetic strategy to generate strain parallel to the DV axis (left) or AP axis (right). Cyan indicates the area(s) of transient optogenetic activation; black regions are not activated. B JMA in an activated embryo (as in A, left). t = 0 corresponds to the first image after activation (~5 min post CF formation). Red dashed lines designate the activated regions. B′ JMA in a control embryo in an equivalent region and developmental stage as that in B. C Myosin and strain rate for two regions of an activated embryo (Fig. S4A′) before (cyan) and after (magenta) activation plotted over control data (from Fig. 1I). D, D′ Cell trajectories in one lateral side (Fig. S1J) of a control (D) and activated (D′) embryo for 15 min beginning 5 min after CF formation (first time point following activation in the opto exp). The Black dashed box designates the region analyzed in (E, F′). E, E′ Cells color-coded by orientation (angle between cell long axis and AP axis) in control (E) and activated (E′) embryos. F, F′ Cells color coded for apical cell area in control (F) and activated (F′) embryos. Area distributions are significantly different (Two-sided ks test, p = 1.2 × 10 −9). G, G′ JMA in equivalent regions of control (G) and activated (G ′) embryos of equivalent developmental time (See K). White arrows identify junctions parallel to the AP axis. H, I Length (H) and JMA (I) over time of junctions parallel to the AP axis in an activated embryo. The Gray dashed line shows the time of activation. Data were meanSD, n200 junctions. I Black dashed line shows JMA expected without activation from the slope of pre-activation data. J Strain rate on junctions parallel to the AP axis measured across the entire embryo (excluding the 50-micron region about the ventral midline) as a function of distance from head activation along the AP axis. Data were meanSD, n 200 junctions. K JMA in a lateral region spanning the AP axis of a head activation experiment. The White dashed line shows the boundary between activated (left) and unactivated (right) cells. The white solid outline shows an area corresponding to G. Triangle represents the gradation of JMA along the AP axis. t = 0 is first time point after activation, ~0 min post CF formation. H – J Source data are provided as a Source Data file.

---

### Construction and validation of a risk prediction model for postoperative ICU admission in patients with colorectal cancer: clinical prediction model study [^e1f10b6d]. BMC Anesthesiology (2024). Medium credibility.

Statistical analysis

All statistical analyses were conducted using R software (Version 4.1.1;) and SPSS 26.0 (SPSS®, Chicago, II, USA). Continuous predictors were presented as mean ± standard deviation (SD), while categorical predictors were presented as numbers and percentages. Pre- and post- imputation datasets were compared using the Kruskal–Wallis non-parametric rank sum test for non-normal distribution. The dataset was randomly divided into a training cohort and a validation cohort in a 7:3, respectively. The dataset was randomly divided into training and validation cohorts in a 7:3 ratio. The training cohort was utilized for model development, while the validation cohort was used for internal validation, retrospectively. To address multicollinearity among predictors, the Least Absolute Shrinkage and Selection Operator (LASSO) method was used to screen out the optimal variables with non-zero coefficients as risk factors at the minimum standard error, as previously described. Then, based on the results of the LASSO regression analysis, independent predictors (P < 0.05) were identified using multivariate logistic regression. A nomogram was drawn using the data predicting the occurrence of postoperative special ICU admission. The nomogram's prediction line was used to determine points, which were then summed on the "Total Score" axis to predict the likelihood of postoperative ICU admission on a scale. The Hosmer–Lemeshow test and the coefficient of determination (R2) were used to evaluate the model's goodness of fit. Discriminative ability was evaluated using the receiver operating characteristic (ROC) curve, area under the ROC curve (AUC), and consistency index (C index). Calibration curves assessed predictive model consistency. Decision curve analysis (DCA) reflected the net benefit of the model for patients. All statistical tests were two-sided; P value < 0.05 was considered statistical significance.

---

### Proposal for a trigonometric method to evaluate the abduction angle of the lower limbs in neonates [^e01c6495]. Journal of Child Neurology (2008). Low credibility.

It is difficult to precisely measure articular arc movement in newborns using a goniometer. This article proposes an objective method based on trigonometry for the evaluation of lower limb abduction. With the newborn aligned in the dorsal decubitus position, 2 points are marked at the level of the medial malleolus, one on the sagittal line and the other at the end of the abduction. Using the right-sided line between these 2 points and a line from the medial malleolus to the reference point at the anterior superior iliac spine or umbilical scar, an isosceles triangle is drawn, and half of the inferential abduction angle is obtained by calculating the sine. Twenty healthy full-term newborns comprise the study cohort. Intersubject and intrasubject variability among the abduction angle values (mean [SD], 37 degrees [4] degrees) is low. This method is advantageous because the measurement is precise and because the sine can be used without approximation.

---

### Effects of plant diversity on productivity strengthen over time due to trait-dependent shifts in species overyielding [^a2a1caf2]. Nature Communications (2024). High credibility.

Fig. 2
Effects of plant species richness on community productivity and community overyielding over time.

A, B Effects on community productivity and community overyielding (log response ratio (lnRR) of productivity of a mixture divided by the mean productivity of all monocultures of the component species) in terms of total aboveground biomass (log-10 scale) in grasslands (n = 39). Effects on (C, D) annual basal area increment and (E, F) total accumulated basal area (log-10 scale) in forests (n = 26). Points are community-level values for each plot in the respective year. Lines are mixed effect model fits across all experiments. For grasslands, species richness (F 1,1317 = 157.8, P < 0.001), year (F 1,5976 = 21.4, P < 0.001), and the species richness × year interaction (F 1,5976 = 8.0, P = 0.005) significantly affected aboveground biomass, while species richness (F 1,716 = 78.1, P < 0.001) and the species richness × year interaction (F 1,3482 = 40.0, P < 0.001) significantly affected community overyielding. In forests, annual basal area increment was significantly affected by year (F 1,3474 = 31.9, P < 0.001), and the species richness × year interaction (F 1,3474 = 7.6, P = 0.006), while community overyielding was significantly affected by the species richness × year interaction (F 1,1934 = 12.6, P < 0.001). Forest accumulated basal area was significantly affected by species richness (F 1,1348 = 13.6, P < 0.001), year (F 1,4023 = 2229, P < 0.001) and the species richness × year interaction (F 1,4023 = 12.6, P < 0.001), while community overyielding was significantly affected by species richness (F 1,781 = 4.9, P = 0.027), and the species richness × year interaction (F 1,2611 = 19.4, P < 0.001). Reported P values were calculated from one-sided F -tests. Refer to Supplementary Table 2 for more details. Y-axis was trimmed to enhance resolution comparing model fit lines (5% extreme values are not visible).

---

### Overestimation of numerical distances in the left side of space [^fe092e52]. Neurology (2004). Low credibility.

Normal subjects presented with a middle number and two left- and right-sided outer numbers overestimate the numerical distance between the middle number and that positioned at its left side. Repetitive transcranial magnetic stimulation (rTMS) of the right posterior parietal cortex specifically counteracts this bias, suggesting that the mental representation of space defined by numbers is shifted toward the left side depending on a greater activity of the right hemisphere.

---

### Palliative care best practices guidelines [^e0012b78]. ACS (2017). Medium credibility.

Palliative care — time-limited trial (TLT) initiation and team roles are outlined as follows: To proceed with a TLT, initiate the following steps: Define and communicate the patient's clinical problems and prognoses; Clarify the patient's personal values, goals of care, and quality of life priorities; Identify realistic objective markers that constitute clinical improvement or deterioration; Suggest and agree upon a time frame for reassessment and reevaluation; and Define clear expectations and the plan of action at the end of the TLT. Ideally, one or two providers take ownership of the TLT process to ensure smooth communication and build trust with the family, and the palliative care team can be effective in facilitating the TLT discussion and providing additional expertise in communication skills and bereavement support for families and providers.

---

### American Association of Clinical Endocrinologists / American college of endocrinology clinical practice guidelines for the diagnosis and treatment of postmenopausal osteoporosis-2020 update [^eca48f27]. Endocrine Practice (2020). High credibility.

Regarding follow-up and surveillance for postmenopausal osteoporosis, more specifically with respect to follow-up, AACE/ACE 2020 guidelines recommend to obtain a baseline axial (lumbar spine and hip; 1/3 radius if indicated) DEXA and repeat every 1–2 years until findings are stable. Consider obtaining 1/3 radius DEXA as an alternative site if the lumbar spine/hip is not evaluable or as an additional site in patients with primary hyperparathyroidism. Consider repeating it every 1–2 years or at a less frequent interval, depending on clinical circumstances. (Grade B; BEL 2) Monitor serial changes in lumbar spine, total hip, or femoral neck bone mineral density. Consider monitoring with 1/3 radius site if the lumbar spine, hip, or both are not evaluable, recognizing that it is limited by a small area and a very large least significant change. (Grade B; BEL 1) Attempt monitoring patients in the same facility with the same DEXA system, provided the acquisition, analysis, and interpretation adhere to International Society for Clinical Densitometry DEXA best practices.

---

### Onabotulinumtoxina (Botox cosmetic) [^440dda01]. FDA (2024). Medium credibility.

Figure 4:

For simultaneous treatment with lateral canthal lines, the total dose is 64 Units, comprised of 20 Units for forehead lines, 20 Units for glabellar lines, and 24 Units for lateral canthal lines (see Lateral Canthal Lines Administration and Figures 2 and 3).

Platysma Bands

Using an appropriately sized sterile syringe, needle, and aseptic technique, inject 2 Units (0.05 mL) of reconstituted BOTOX Cosmetic into 4 sites in the upper segment of platysma muscle, below the jawline on each side. For each side, administer the 4 jawline injections to the upper platysma muscle approximately 1 to 2 cm inferior and parallel to the lower mandibular border. Ensure the anterior injection site is in line with the oral commissure, and the posterior injection is slightly anterior to the angle of the mandible. Administer the remaining 2 injections equidistant (approximately 1 to 2 cm apart) between the anterior and posterior injection points (see Figures 5 and 6).

In addition, inject 1 Unit (0.025 mL) of reconstituted BOTOX Cosmetic into 5 sites along each vertical neck band, 1 to 2 vertical neck bands per side. For each vertical neck band identified, 1 to 2 per side, distribute 5 injections vertically approximately 1 to 2 cm apart (see Figures 5 and 6). Ensure the most superior injection site is approximately 1 to 2 cm inferior to the jawline injections.

Depending on platysma band severity, the total dose may be 26 Units (1 band/side), 31 Units (1 band one side, 2 bands other side), or 36 Units (2 bands/side) (see Table 4 and Figures 5 and 6 below).

Administer all platysma muscle injections superficially and intramuscularly with the needle perpendicular to the surface of the skin. For vertical neck band injections, identify each band while the patient is contracting their platysma. Gently pinch the band to isolate the muscle from nearby anatomical structures during administration (see Table 4).

To reduce injection-related complications, administer injection at least 1 cm inferior to the lower mandibular border. Do not inject into structures deep to the platysma muscle, particularly in the anterior region of the neck.

---

### Model-based assessment of replicability for genome-wide association meta-analysis [^1253d2ae]. Nature Communications (2021). High credibility.

Fig. 3
Layered Manhattan plot for smoking initiation (SmkInit) phenotype.

Each vertical line represents a SNP analyzed by the MAMBA, where the line extends to a purple cross indicating the fixed-effects p -value. Orange triangles on the same line indicate the MAMBA p -values for the same SNP. Green points are the p-values for randomly pruned markers included in the MAMBA model to ensure that both non-replicable and replicable associations are incorporated. P -values for the MAMBA model were calculated through a bootstrap procedure. All p -values are two-sided and not adjusted for multiple comparisons. Source data are provided as a Source Data file.

---

### Quantifying the dynamics of failure across science, startups and security [^6acaa77f]. Nature (2019). Excellent credibility.

Human achievements are often preceded by repeated attempts that fail, but little is known about the mechanisms that govern the dynamics of failure. Here, building on previous research relating to innovation 1–7, human dynamics 8–11 and learning 12–17, we develop a simple one-parameter model that mimics how successful future attempts build on past efforts. Solving this model analytically suggests that a phase transition separates the dynamics of failure into regions of progression or stagnation and predicts that, near the critical threshold, agents who share similar characteristics and learning strategies may experience fundamentally different outcomes following failures. Above the critical point, agents exploit incremental refinements to systematically advance towards success, whereas below it, they explore disjoint opportunities without a pattern of improvement. The model makes several empirically testable predictions, demonstrating that those who eventually succeed and those who do not may initially appear similar, but can be characterized by fundamentally distinct failure dynamics in terms of the efficiency and quality associated with each subsequent attempt. We collected large-scale data from three disparate domains and traced repeated attempts by investigators to obtain National Institutes of Health (NIH) grants to fund their research, innovators to successfully exit their startup ventures, and terrorist organizations to claim casualties in violent attacks. We find broadly consistent empirical support across all three domains, which systematically verifies each prediction of our model. Together, our findings unveil detectable yet previously unknown early signals that enable us to identify failure dynamics that will lead to ultimate success or failure. Given the ubiquitous nature of failure and the paucity of quantitative approaches to understand it, these results represent an initial step towards the deeper understanding of the complex dynamics underlying failure.

---

### Six steps in quality intervention development (6SQuID) [^56c6047d]. Journal of Epidemiology and Community Health (2016). Low credibility.

1. DEFINE AND UNDERSTAND THE PROBLEM AND ITS CAUSES

Our starting point is that a public health problem has already been identified as requiring intervention. Often this results from a needs assessment, for which there are several practical guides, or from a political process such as a manifesto commitment.

Clarifying the problem with stakeholders, using the existing research evidence, is the first step in intervention development. Some health problems are relatively easily defined and measured, such as the prevalence of a readily diagnosed disease, but others have several dimensions and may be perceived differently by different groups. For instance, 'unhealthy housing' could be attributed to poor construction, antisocial behaviour, overcrowding or lack of amenities. Definitions therefore need to be sufficiently clear and detailed to avoid ambiguity or confusion. Is 'the problem' a risk factor for a disease/condition (eg, smoking) or the disease/condition itself (eg, lung cancer)? If the former, it is important to be aware of the factor's importance relative to other risk factors. If this is modest even a successful intervention to change it might be insufficient to change the ultimate outcome.

Once defined one should try to establish how the problem is socially and spatially distributed, including who is currently most/least likely to benefit from an intervention. It is also important to consider what interventions or policies currently exist and why they are not deemed adequate.

Having defined the problem, one needs to understand, as far as possible, what are the immediate (proximal) and underlying (distal) influences that give rise to it. These are often suggested by the distribution of the problem, its history and relationship to the life course. It is only by understanding what shapes and perpetuates the problem (the causal pathways) that one can identify possible ways to intervene. Case study step 1 applies Funnell and Rogers' useful questions for problem analysis to GBV (ref. p. 160). The main influences on the problem can also be classified according to the socioecological model. It can often be helpful to present the various causal pathways affecting the problem diagrammatically: figure 1 attempts to do this for GBV, distinguishing different levels of the socioecological model.

Figure 1
Causal pathways perpetuating gender-based violence.

---

### The analysis of lung sounds in infants and children with a history of wheezing / asthma using an automatic procedure [^d3859408]. BMC Pulmonary Medicine (2024). Medium credibility.

As sound parameters, the frequency at the basic point, 0 point, calculated from the spectrum of the subject's inspiratory sound, was FAP 0 (kHz), and the power was PAP 0 (dBm) based on previous studies (Fig. 3). Furthermore, RPF 50p is the index obtained by dividing the power at 1/2 of the frequency (dBm) by the frequency at the same point (F 50p), which is obtained by subtracting 100 Hz from the frequency at the 0 point. RPF 75p was calculated by dividing the power at 3/4 of the frequency (dBm) by the frequency at the same point (F 75p). Furthermore, 2/3 of the frequency obtained by subtracting 100 Hz from the frequency of 0 point was defined as A 3 p, the area from A 3 p in the high-pitched range to 0 point was defined as A 3a, and the value divided by the total area (A T) was defined as A 3a /A T. B 4 p and B 4a /A T were calculated by using the same procedure.

Fig. 3
Sound spectrum parameters. FAP 0: analysis parameter of frequency at the 0 point, PAP 0: analysis parameter of power at the 0 point, A T: Total area of sound spectrum, A 3a /A T: Ratio of high-pitched third area to total area, B 4a /A T: Ratio of high-pitched fourth area to total area, dBF 50p: dB at F 50p, dBF 75p: dB at F 75p, RPF 50p: Ratio of power to (F 99p -F 50p)[= dBF 50p /(F 99p -F 50p)], RPF 75p: Ratio of power to (F 99p -F 75p)[= dBF 75p /(F 99p -F 75p)]

---

### Global strategy for asthma management and prevention [^de70aa28]. GINA (2024). High credibility.

Box 5–3 — Poor adherence with prescribed maintenance treatment in asthma — contributing factors and clinical identification are summarized as follows: Medication/regimen factors include "Difficulties using inhaler device (e.g., arthritis)", "Burdensome regimen (e.g., several times per day)", and "Multiple different inhalers"; unintentional poor adherence includes "Misunderstanding about instructions" and "Forgetfulness"; and intentional poor adherence includes "Perception that treatment is not necessary" and "Concerns about side-effects (real or perceived)". For patients prescribed maintenance treatment, "ask an empathic question" and "Acknowledge the likelihood of incomplete adherence and encourage an open non-judgmental discussion", using example prompts such as "In the last 4 weeks, how many days a week have you been taking it – not at all, 1, 2, 3 or more days a week?" and "Do you find it easier to remember your inhaler in the morning or the evening?" Practical checks include "Check the date of the last prescription", "Check the date and dose counter on the inhaler", and, where available, electronic monitoring since "prescribing and dispensing frequency can be monitored electronically by clinicians and/or pharmacists".

---

### Increasing countries' financial resilience through global catastrophe risk pooling [^688bc31c]. Nature Communications (2023). High credibility.

In the first optimization step, for convenience and practical reasons, instead of maximizing Risk Diversification (RD) we minimize Risk Concentration (RC). The optimal allocation of countries, x *, which provides the minimum risk concentrations to the m pools, RC 1 *, …, RC m *, can be found by solving the following m -objectives optimization problem:

The vector x * indicates the set of the n 1, …, n m, countries that provide optimal diversifications in each of the m pools.

The second optimization step requires solving a single-objective optimization for each of the m pools. To do so, we define, for a given pool j, a binary vector z j of length n j indicating which of the n j countries are still part of j (when 1) or not (when 0). The smallest subset of countries within the set of n j countries which allows reaching the least concentration, RC j *, can then be found by solving:

The vectorindicates the optimal set of countries for the pool j, namely the smallest set of countries that provide the highest maximum risk diversification.

Optimization is carried out via the python Pymoo package. Pymoo provides a framework for solving single- and multi-objective optimization problems via state-of-art algorithms. We employ a basic genetic algorithm (GA) to solve the single objective optimizations and a unified non-dominated sorting genetic algorithm (U-NSGA-III) to solve the many-objective optimization problems. For these, we carried out a seed analysis and solved the optimization problem fifteen times. The final set of dominant solutions is then the dominant set across the fifteen sets of solutions so derived. Convergence plots of the two-step optimization are reported in Figs. S2 – S7.

---

### Standards of care in diabetes – 2025 [^37f809f4]. Diabetes Care (2025). High credibility.

Regarding patient education for diabetes mellitus type 1, more specifically with respect to self-management education and support, ADA 2025 guidelines recommend to assess clinical outcomes, health status, and well-being routinely as key goals of diabetes self-management education and support.

---

### Guidance for the primary care provider in identifying infants with biliary atresia by 2–4 Weeks of life: clinical report [^532e9468]. Pediatrics (2025). High credibility.

Biliary atresia (BA) — limitations of bilirubin ratios before 2 weeks: Using bilirubin ratios in the first days of life will miss infants with BA; these ratios are calculated by dividing the direct or conjugated level by the total level and are used to distinguish non-liver causes (ratio < 0.2) versus liver causes (ratio ≥ 0.2), yet in one study ratios were > 0.2 before 48 hours of life in only 21% of newborns later diagnosed with BA, so ratios may be more useful when used at later time periods.

---

### Lateral elbow pain and muscle function impairments [^647af52d]. The Journal of Orthopaedic and Sports Physical Therapy (2022). High credibility.

Regarding diagnostic investigations for lateral elbow tendinopathy, more specifically with respect to clinical assessment, APTA 2022 guidelines recommend to use the PSFS in patients with high-demand activities and/or a scale assessing activity-specific disability (such as Disabilities of the Arm, Shoulder and Hand work or sports/performing arts module) at baseline and at least one other follow-up point including discharge in patients with LET.

---

### Research into the black box of rehabilitation: the risks of a type III error [^11c07764]. Clinical Rehabilitation (2001). Low credibility.

Type I and Type II errors in the interpretation of data from clinical trials concern statistical matters, and the probability of drawing erroneous conclusions from inadequate data. However in rehabilitation research a third possible error may arise. Successful rehabilitation depends upon the co-ordinated work of an expert multidisciplinary team, and can be considered as a network involving a whole system. Demonstrating that one part of that system looked at in isolation does not have the expected effect does not prove that the specific part is not necessary to the success of the whole system. The isolated intervention may still have an important effect when interacting with other variables or interventions. Failure to consider the interactive effects of an intervention might constitute a Type III interpretation error.

---

### Defining the time-limited trial for patients with critical illness: an official American Thoracic Society workshop report [^cf1ee11e]. Annals of the American Thoracic Society (2024). High credibility.

Time-limited trial in critical care — essential elements and phased process were derived through a Delphi process: investigators "identified 18 potential steps" and found first-round consensus that "11 of these were essential elements"; during the second round, they "identified seven additional essential elements". The committee then "combined 4 related items into two steps (to reach 16 essential elements)" and "organized steps into four phases of care: consider, plan, support, and reassess". Additional steps "may be helpful in some cases, but not necessary for all trials", and involvement of other disciplines is "highly dependent on a patient's specific situation and on the available hospital resources".

---

### Guidelines for foodborne disease outbreak response. 2nd ed [^951f2532]. CDC (2014). Medium credibility.

Foodborne disease surveillance program objectives — short-, intermediate-, and long-term aims: Table 8.1 lists short-term objectives to detect foodborne disease events of public health importance, respond to events in a timely manner, and intervene when appropriate to prevent illness; intermediate objectives to determine etiology, vehicle, and contributing factors of foodborne disease outbreaks, monitor trends to identify emerging foodborne diseases and food-safety problems, and increase knowledge of foodborne disease causes and abatement strategies; and long-term objectives to prevent future outbreaks, reduce incidence of foodborne illness, and increase health of the general population.

---

### Standards of care in diabetes – 2025 [^122f09fd]. Diabetes Care (2025). High credibility.

Regarding medical management for diabetes mellitus type 1, more specifically with respect to glycemic targets, ADA 2025 guidelines recommend to set a glycemic goal during consultations to improve outcomes.

---

### Standards of care in diabetes – 2025 [^14753c0e]. Diabetes Care (2025). High credibility.

Regarding specific circumstances for chronic kidney disease, more specifically with respect to patients with diabetes mellitus (monitoring of renal function), ADA 2025 guidelines recommend to monitor urinary albumin (such as spot urinary albumin-to-creatinine ratio) and eGFR 1–4 times per year, depending on the stage of the disease, in patients with established diabetic kidney disease.

---

### Lateral elbow pain and muscle function impairments [^fa48ba96]. The Journal of Orthopaedic and Sports Physical Therapy (2022). High credibility.

Regarding diagnostic investigations for lateral elbow tendinopathy, more specifically with respect to clinical assessment, APTA 2022 guidelines recommend to assess physical impairment measures of elbow and wrist ROM, pressure pain threshold, pain-free grip strength, and maximum grip strength at baseline and at least one other follow-up point including discharge in patients with LET.

---

### Mental health competencies for pediatric practice [^2c05f3f5]. Pediatrics (2019). High credibility.

Brief interventions and escalation — intervention will need to include supports to address social determinants, and "If an identified problem is not an emergency, the clinician can undertake 1 or more brief interventions, as time allows, during the current visit or at follow-up visit(s) (algorithm step 11)". These brief interventions may include "using secondary screening tools, gathering information from school personnel or child care providers, or having the family create a diary of problem behaviors and their triggers", and may also involve "referral of a family member for assistance in addressing his or her own social or mental health problems". When indicated by assessment findings or "failure to respond to brief therapeutic interventions", "a full diagnostic assessment can be performed, either by the pediatrician (algorithm step 15) at a follow-up visit or through referral to a specialist (algorithm step 16), followed by the steps of care planning and implementation, comanagement, and monitoring the child's progress (algorithm steps 17 and 18)".

---

### VA / DoD clinical practice guideline for the management of type 2 diabetes mellitus [^8da629fa]. VA/DoD (2023). High credibility.

Algorithm — This clinical practice guideline's algorithm is designed to facilitate understanding of the clinical pathway and decision-making process used in managing patients with T2DM. It represents a simplified flow of the management of patients with T2DM and helps foster efficient decision making by providers, and it includes steps of care in an ordered sequence, decisions to be considered, decision criteria recommended, and actions to be taken. The algorithm is a step-by-step decision tree; standardized symbols display each step, arrows connect the numbered boxes indicating the order in which the steps should be followed, and sidebars 1–8 provide more detailed information to assist in defining and interpreting elements in the boxes.

---

### Standards of care in diabetes – 2025 [^8acbfc7c]. Diabetes Care (2025). High credibility.

Regarding specific circumstances for hypoglycemia, more specifically with respect to elderly patients, ADA 2025 guidelines recommend to avoid overtreatment of diabetes in older patients.

---

### Diagnosis, management and treatment of the Alport syndrome-2024 guideline on behalf of ERKNet, ERA and ESPN [^6f42c569]. Nephrology, Dialysis, Transplantation (2025). High credibility.

Regarding diagnostic investigations for Alport syndrome, more specifically with respect to genetic testing, ERA/ERN ERKNet/ESPN 2025 guidelines recommend to recognize that no targeted gene panel is 100% sensitive for the different types of genetic changes that can cause Alport syndrome, with well-designed gene panels achieving a sensitivity of over 85% for COL4A3/4/5 gene analysis in detecting pathogenic variants.

---

### Trends in low-value care among children's hospitals… [^d2d04e08]. publications.aap.org (2024). Medium credibility.

To improve understanding of hospital-based LVC delivery, our research group developed the Pediatric Health Information System LVC Calculator, a tool measuring the proportion and volume of ED and hospital encounters in which 30 nonevidence-based services are delivered. Previous application of this tool to eligible encounters from 49 hospitals in 2019 found that some low-value services were delivered in up to 60% of encounters; in total, these services were associated with nearly $17 million in standardized costs over this single calendar year. 4, 23–26 The multidisciplinary stakeholder group responsible for the calculator's development prioritized narrow measure definitions. 3 This approach was intended to define LVC with high specificity, while minimizing misclassification of appropriate, or justified, care practices.

3, 4 To do this, the LVC Calculator first applies a set of global exclusions to remove encounters with a high level of patient complexity or very severe illness. The tool then employs measure-specific exclusions to remove encounters with evidence of justification for a particular service. 3 Measure definitions are shown in Supplemental Table 4. The LVC Calculator is designed as both a research and quality improvement tool. It is used to measure characteristics of LVC delivery across PHIS hospitals; additionally, clinicians at participating hospitals can access data describing local LVC delivery patterns at any time and compare performance to peer hospitals. Encounters were included for analysis if they met criteria for ≥ 1 of the LVC Calculator measures. Per the calculator's parameters, encounters for patients aged > 18 years and those with International Classification of Diseases, 10th Revision, codes indicating complex chronic conditions.

After initial data review, 1 measure, group A streptococcus testing for children < 3 years of age for routine pharyngitis in the ED, was excluded from further analyses. The definition for this measure captures rapid antigen testing for GAS only; however, recent literature suggests a practice shift toward the use of molecular testing. 29, 30 As such, apparent reductions in GAS testing may represent missed molecular testing. Statistical analyses were performed with SAS, version 9. 5, and P <. 05 was considered statistically significant. This study was deemed not human subjects research by the Dartmouth College institutional review board.

---

### The effect of ultrasound-guided lung recruitment maneuvers on atelectasis in lung-healthy patients undergoing laparoscopic gynecologic surgery: a randomized controlled trial [^12a2dfde]. BMC Anesthesiology (2022). Medium credibility.

Lung ultrasonography

An ultrasound machine (MINDRAY M9) with a probe of 2–5 MHz was used by a trained and experienced anesthesiologist to perform the lung ultrasound. Sonograms were taken at five predetermined times: when the patient entered the operating room (time point 1, T1), 1 min after mechanical ventilation (time point 2, T2), at the end of surgery before extubation (time point 3, T3), 15 min after arrival in the PACU (time point 4, T4), and 24 h after surgery (time point 5, T5). Scanning was carried out in the manner described by Monastesse et al.

Each hemithorax was divided into two zones: upper and lower, and each side was further divided into anterior, lateral and posterior zones by the anterior and posterior axillary lines. As shown in Fig. 1, each hemithorax is divided into six quadrants for a total of twelve quadrants. In the anterior and lateral regions, the probe was placed upright to the costal space, whereas in the posterior regions, the probe was placed parallel to the intercostal space. The modified lung ultrasound score developed by Monastesse et al. was used to quantify the severity of atelectasis.

Fig. 1
Each hemithorax was separated into 6 quadrants: anterior, lateral and posterior zones separated by the anterior and posterior axillary lines as anatomical landmarks, and each area was further divided into superior and inferior portions. AAL – anterior axillary line; PAL – posterior axillary line

The lung ultrasound score (LUS) was independently assigned by a radiologist and was ranked on a four-point scale. The scoring ranged from 0 to 3, as follows: (1) ≥ 3 B lines or one or more small subpleural consolidations separated by a normal pleural line; (2) multiple coalescent B lines or multiple small subpleural consolidations separated by a thickened or irregular pleural line; and (3) consolidation or small subpleural consolidation of > 1 × 2 cm in diameter. Atelectasis was considered significant if the LUS ≥ 2 was present in any region. LUS was determined by adding the scores of the 12 individual quadrants, ranging from 0 to 36 points, with higher scores indicating a more severe loss of aeration.

---

### The primary care pediatrician and the care of children with cleft lip and / or cleft palate [^e6d28c9a]. Pediatrics (2017). Medium credibility.

Table 2 — Associations and other features of cleft lip and/or cleft palate (CL/P) by phenotype — contrasts cleft lip with or without cleft palate (CL ± P) with cleft palate (CP) across epidemiology and phenotype: CL ± P occurs in ~1 in 600–700 US births versus CP in ~1 in 1000–1500 US births; sex ratios are male:female 2:1 for CL ± P and 1:2 for CP; CL ± P is most common in American Indian, Alaska Native, Latino, and Asian subjects (1/300–1/500), intermediate in white subjects (1/1000), and less common in black subjects (1/2500), whereas CP shows no racial/ethnic association; syndromic association is 30% for CL ± P versus 50% for CP; laterality shows approximately 75% of lip clefts are unilateral and, among unilateral CL ± P, left-sided clefts are twice as common as right-sided, whereas CP is usually midline.