# Medical Question & Answer

**Sample ID**: 5881947b-5acb-e601-77ff-c395b48b081e
**Dataset Index**: 292795

---

## Question

Discuss whether you will be collecting quantitative or qualitative data?

---

## Answer

> Let's see… What do we have here? The user is asking whether to collect quantitative or qualitative data. Let's break this down step-by-step. First, I need to think about the research question and whether it is "what/how much" versus "how/why". Then, I should verify the strengths and limitations of quantitative and qualitative methods. Next, I will consider mixed methods as a bridge when both are needed. After that, I need to check feasibility constraints like time, resources, and team expertise. Finally, I will align the choice to the study's purpose and provide a clear recommendation with contingencies for integration and quality assurance.

> Let me first confirm the foundational principle: the research question drives the method, not the other way around. Quantitative approaches are best for measuring prevalence, associations, or effects ("what" or "how much"), whereas qualitative approaches are best for exploring mechanisms, meanings, or context ("how" or "why") [^1d0c28f6] [^4d908261]. Hold on, I should verify that this alignment is consistently emphasized across sources; yes, multiple high-credibility sources reiterate that method selection should be anchored to the question rather than a methodological preference [^1d0c28f6] [^4d908261].

> Now, I will examine quantitative data. Strengths include precise measurement, statistical inference, and generalizability when sampling is appropriate; common tools include surveys, structured instruments, and routinely collected metrics, and good survey research requires attention to validity, reliability, and response rates to minimize bias [^c44856f5] [^18c7b4f6]. Wait, let me verify the limitations: quantitative methods can miss nuanced context, cannot easily capture emergent or unexpected themes, and may not explain why observed effects occur, which is precisely where qualitative methods add value [^50164602] [^3f2d3d3c].

> Next, I should review qualitative data. Strengths include rich, contextual insights into experiences, processes, and mechanisms; methods include in-depth interviews, focus groups, observations, and open-ended survey items, with analysis focused on coding, themes, and interpretive rigor rather than statistical tests [^f51708df] [^823553ce]. Hold on, I should verify limitations: findings are not statistically generalizable, sample sizes are smaller and purposive, and results can be influenced by researcher reflexivity and analytic choices, so trustworthiness must be actively demonstrated [^f51708df] [^c7c08aff].

> But wait, what if the question is compound or the phenomenon is complex? Mixed methods intentionally integrate quantitative and qualitative strands to answer both "what" and "why", leveraging complementarity and often yielding insights neither method alone could provide; core designs include convergent, explanatory sequential, and exploratory sequential, with integration planned a priori to avoid a bolted-on qualitative add-on [^c7c08aff] [^85e43f07]. I should double-check that this is not just a trend; mixed methods are increasingly used in pragmatic trials, implementation science, and guideline processes to address complexity and context dependence [^6b802fd6] [^b0cc517f].

> I need to ensure feasibility is addressed. Quantitative studies often require larger samples and validated instruments but can be faster to administer and analyze; qualitative studies require trained interviewers, transcription, and iterative analysis, which is time- and labor-intensive; mixed methods compound these demands and require explicit integration planning and multidisciplinary expertise, so I should confirm team capacity and resource availability before committing [^c44856f5] [^f51708df] [^c7c08aff]. Hold on, I should verify that under-resourced mixed methods can degrade quality; yes, poor integration and underpowered components are common pitfalls that undermine inference, so design must match capacity [^c7c08aff].

> Let me consider the study's purpose and end users. If the goal is to estimate prevalence, test hypotheses, or compare outcomes, quantitative data are appropriate; if the goal is to understand experiences, refine interventions, or explain unexpected quantitative findings, qualitative data are appropriate; if the goal is comprehensive evaluation or guideline development, mixed methods are often preferred to integrate effect sizes with implementation insights [^4d908261] [^b0cc517f]. I should confirm that this aligns with how guidelines increasingly operate; indeed, major guideline frameworks now incorporate both quantitative effectiveness and qualitative acceptability/feasibility evidence in decision-making [^b0cc517f] [^d347f3a7].

> Putting this together, my default recommendation is to let the research question dictate the method, and if the question is "how much" or "does it work", I would collect quantitative data; if the question is "how does it work" or "why did it fail", I would collect qualitative data; if the question is "what works, for whom, and under what circumstances", I would collect both in a mixed methods design with pre-specified integration [^1d0c28f6] [^c7c08aff]. Hmm, wait a minute, I almost implied mixed methods are inherently superior; I should correct that: mixed methods are not universally better, they are better when the question is compound and when the team has the expertise and resources to integrate rigorously, otherwise a well-executed single-method study is preferable [^db9773ab].

> If I must choose only one and the question is ambiguous, I should prioritize quantitative data when decision-making requires magnitude, statistical significance, or generalizability, and prioritize qualitative data when the problem is poorly understood, the context is critical, or when developing or adapting interventions; in both cases, I need to state the limitation explicitly and plan for follow-up with the complementary method if needed [^c44856f5] [^f51708df]. Hold on, I should verify that this contingency approach is consistent with best practices; yes, iterative, question-driven method selection is encouraged when uncertainty exists about mechanisms or context [^1d0c28f6].

> Finally, I need to ensure quality safeguards are explicit. For quantitative data, I will pre-specify hypotheses, use validated instruments, plan for adequate power, and assess response bias; for qualitative data, I will document sampling logic, use a coding framework with intercoder reliability, maintain an audit trail, and conduct reflexive debriefings; for mixed methods, I will define integration points, use joint displays where appropriate, and align conclusions across strands to enhance credibility [^c44856f5] [^c7c08aff] [^07fd37b4]. I should double-check that these steps are aligned with methodological standards; they are consistent with contemporary guidance for patient-centered outcomes and mixed methods research [^c7c08aff] [^4d908261].

---

I will collect **both quantitative and qualitative data** because they answer different but complementary questions: quantitative data will quantify outcomes, associations, and test hypotheses, while qualitative data will explore mechanisms, context, and patient experiences [^4d908261] [^b0b90061]. Mixed methods are essential for complex health interventions where **context and implementation matter** [^1d0c28f6], and integrating both yields richer, more actionable insights than either alone [^c7c08aff]. I will use a convergent design to collect both strands concurrently, then integrate findings to explain quantitative results with qualitative insights and identify unexpected patterns [^85e43f07] [^719debdf].

---

## Rationale for collecting quantitative data

Quantitative data are **necessary to**:

- **Measure outcomes**: Quantify intervention effects, associations, and test hypotheses with statistical precision [^c44856f5].

- **Generalize findings**: Enable inference from sample to population when sampling is representative [^e39186e7].

- **Compare groups**: Assess differences between interventions or populations using standardized metrics [^f64bf45a].

- **Detect trends**: Identify patterns or changes over time with longitudinal data [^98feb86b].

Common quantitative methods include surveys, questionnaires, structured observations, and administrative or clinical records; these tools provide numerical data suitable for statistical analysis and hypothesis testing [^c44856f5] [^e39186e7].

---

## Rationale for collecting qualitative data

Qualitative data are **essential to**:

- **Explore mechanisms**: Understand how and why interventions work or fail in real-world contexts [^50164602].

- **Capture experiences**: Document patient and provider perspectives, values, and preferences [^eda13585].

- **Identify barriers and facilitators**: Reveal contextual factors that influence implementation and outcomes [^55dfaf03].

- **Generate hypotheses**: Discover unexpected themes and refine future quantitative instruments [^5ddff877].

Common qualitative methods include in-depth interviews, focus groups, participant observation, and open-ended survey items; these yield textual or observational data analyzed thematically or with grounded theory [^f51708df] [^823553ce].

---

## Integration of quantitative and qualitative data

Mixed methods integration **enhances validity** by triangulating findings across data types, improves interpretability by explaining quantitative results with qualitative insights, and strengthens implementation by aligning interventions with patient needs and context [^c7c08aff] [^8f4ec2f6]. I will use a convergent design, collecting both strands concurrently with equal priority, then integrate during analysis to produce a comprehensive, context-aware interpretation [^85e43f07] [^719debdf].

---

## Practical considerations

- **Resources**: Mixed methods require time, funding, and multidisciplinary expertise; plan accordingly [^c7c08aff].

- **Sampling**: Use purposive sampling for qualitative depth and probability sampling for quantitative generalizability [^f51708df] [^e39186e7].

- **Analysis**: Apply rigorous quantitative statistics and established qualitative coding with intercoder reliability and reflexivity [^fbc8831d] [^c7c08aff].

- **Reporting**: Use joint displays to transparently present integrated findings and facilitate interpretation [^07fd37b4].

---

## Conclusion

I will collect **both quantitative and qualitative data** to answer "what works" and "why/how it works", leveraging mixed methods to produce robust, context-sensitive evidence that informs clinical practice and policy [^4d908261] [^b0cc517f].

---

## References

### Data collection techniques [^f8c33dd8]. Journal of the American Academy of Child and Adolescent Psychiatry (2001). Low credibility.

We have provided an overview of techniques used to assess variables in the applied behavioral sciences. Most of the methods are used by both quantitative/positivist and qualitative/constructivist researchers but to different extents. Qualitative researchers prefer more open-ended, less structured data collection techniques than do quantitative researchers. Direct observation of participants is common in experimental and qualitative research; it is less common in so-called survey research, which tends to use self-report questionnaires. It is important that investigators use instruments that are reliable and valid for the population and purpose for which they will be used. Standardized instruments have manuals that provide norms and indexes of reliability and validity. However, if the populations and purpose on which these data are based are different from yours, it may be necessary for you to develop your own instrument or provide new evidence of reliability and validity.

---

### Synthesising quantitative and qualitative evidence to inform guidelines on complex interventions: clarifying the purposes, designs and outlining some methods [^41e8b5cf]. BMJ Global Health (2019). High credibility.

Data extraction

The way in which data and evidence are extracted from primary research studies for review will be influenced by the type of integrated synthesis being undertaken and the review purpose. Initially, decisions need to be made regarding the nature and type of data and evidence that are to be extracted from the included studies. Method-specific reporting guidelinesprovide a good template as to what quantitative and qualitative data it is potentially possible to extract from different types of method-specific study reports, although in practice reporting quality varies. Online supplementary file 5 provides a hypothetical example of the different types of studies from which quantitative and qualitative evidence could potentially be extracted for synthesis.

The decisions around what data or evidence to extract will be guided by how 'integrated' the mixed-method review will be. For those reviews where the quantitative and qualitative findings of studies are synthesised separately and integrated at the point of findings (eg, segregated or contingent approaches or sequential synthesis design), separate data extraction approaches will likely be used.

Where integration occurs during the process of the review (eg, integrated approach or convergent synthesis design), an integrated approach to data extraction may be considered, depending on the purpose of the review. This may involve the use of a data extraction framework, the choice of which needs to be congruent with the approach to synthesis chosen for the review. The integrative or theoretical framework may be decided on a priori if a pre-developed theoretical or conceptual framework is available in the literature. The development of a framework may alternatively arise from the reading of the included studies, in relation to the purpose of the review, early in the process. The Cochrane Qualitative and Implementation Methods Group provide further guidance on extraction of qualitative data, including use of software.

Synthesis and integration

Relatively few synthesis methods start off being integrated from the beginning, and these methods have generally been subject to less testing and evaluation particularly in a guideline context (see table 1). A review design that started off being integrated from the beginning may be suitable for some guideline contexts (such as in case study 3 — risk communication in humanitarian disasters — where there was little evidence of effect), but in general if there are sufficient trials then a separate systematic review and meta-analysis will be required for a guideline. Other papers in this series offer guidance on methods for synthesising quantitativeand qualitative evidencein reviews that take a complexity perspective. Further guidance on integrating quantitative and qualitative evidence in a systematic review is provided by the Cochrane Qualitative and Implementation Methods Group.

---

### Synthesis of guidance available for assessing methodological quality and grading of evidence from qualitative research to inform clinical recommendations: a systematic literature review [^a7094fdc]. RMD Open (2024). Medium credibility.

Conclusion

Various checklists exist to assess the methodological quality of qualitative research. However, no hierarchy of evidence is applicable to categorise the level of evidence, in contrast with quantitative research. The findings of this review suggest that the quality of papers retrieved from systematic literature reviews needs to be consistently and rigorously checked, using an established checklist that assesses the methodological appropriateness, research design, recruitment strategy, data collection, data analysis and theoretical underpinnings. By presenting these tools and checklists, we hope to encourage EULAR task forces to include qualitative research into the body of evidence of the developed guidelines where this methodology will in fact most precisely provide answers to the question.

A regular review of the evidence in this rapidly evolving field, with input from qualitative research methodology experts and leaders in the field, will be necessary to remain up to date and to give qualitative research the deserved attention in the development of relevant guidelines.

---

### Qualitative research: standards, challenges, and guidelines [^b0b90061]. Lancet (2001). Excellent credibility.

Qualitative research methods could help us to improve our understanding of medicine. Rather than thinking of qualitative and quantitative strategies as incompatible, they should be seen as complementary. Although procedures for textual interpretation differ from those of statistical analysis, because of the different type of data used and questions to be answered, the underlying principles are much the same. In this article I propose relevance, validity, and reflexivity as overall standards for qualitative inquiry. I will discuss the specific challenges in relation to reflexivity, transferability, and shared assumptions of interpretation, which are met by medical researchers who do this type of research, and I will propose guidelines for qualitative inquiry.

---

### Mixed methods research: a design for emergency care research? [^341c4653]. Emergency Medicine Journal (2011). Low credibility.

This paper follows previous publications on generic qualitative approaches, qualitative designs and action research in emergency care by this group of authors. Contemporary views on mixed methods approaches are considered, with a particular focus on the design choice and the amalgamation of qualitative and quantitative data emphasising the timing of data collection for each approach, their relative 'weight' and how they will be mixed. Mixed methods studies in emergency care are reviewed before the variety of methodological approaches and best practice considerations are presented. The use of mixed methods in clinical studies is increasing, aiming to answer questions such as 'how many' and 'why' in the same study, and as such are an important and useful approach to many key questions in emergency care.

---

### Synthesising quantitative and qualitative evidence to inform guidelines on complex interventions: clarifying the purposes, designs and outlining some methods [^111bb018]. BMJ Global Health (2019). High credibility.

Following a scoping exercise and definition of key questions, the next step in the guideline development process is to identify existing or commission new systematic reviews to locate and summarise the best available evidence in relation to each question. For example, case study 2, 'Optimising health worker roles for maternal and newborn health through task shifting', included quantitative reviews that did and did not take an additional complexity perspective, and qualitative evidence syntheses that were able to explain how specific elements of complexity impacted on intervention outcomes within the wider health system. Further understanding of health system complexity was facilitated through the conduct of additional country-level case studies that contributed to an overall understanding of what worked and what happened when lay health worker interventions were implemented. See table 1 online supplementary file 2.

There are a few existing examples, which we draw on in this paper, but integrating quantitative and qualitative evidence in a mixed-method synthesis is relatively uncommon in a guideline process. Box 2 includes a set of key questions that guideline developers and review authors contemplating combining quantitative and qualitative evidence in mixed-methods design might ask. Subsequent sections provide more information and signposting to further reading to help address these key questions.

Box 2
Key questions that guideline developers and review authors contemplating combining quantitative and qualitative evidence in a mixed-methods design might ask

WHY: Why is a mixed-method synthesis being planned? To answer Compound questions requiring both quantitative and qualitative evidence? Questions requiring mixed-methods studies? Separate quantitative and qualitative questions?
WHAT: What type of evidence is likely to be available? Separate quantitative and qualitative research studies? Related quantitative and qualitative research studies? Mixed-methods studies? Quantitative unpublished data and/or qualitative unpublished data, eg, narrative survey data?
WHEN: At what point will quantitative and qualitative evidence be integrated? Throughout the review? Following separate reviews? At the question point? At the synthesis point? At the evidence to recommendations stage? Or a combination?
HOW: How easy is it to disaggregate quantitative and qualitative data from mixed-method studies? How will quantitative and qualitative evidence be integrated? Through a: Narrative synthesis or summary? Quantitising approach, eg, frequency analysis? Qualitising approach, eg, thematic synthesis? Tabulation? Logic model? Conceptual model/framework? Matrix? Graphical approach? Or a combination?
WHICH: Which mixed-method designs, methodologies and methods best fit into a guideline process to inform recommendations?

---

### Methodological standards for qualitative and mixed methods patient centered outcomes research [^c7c08aff]. BMJ (2020). Excellent credibility.

QM-3: Link the qualitative data analysis, interpretations, and conclusions to the study question

Qualitative analysis transforms data into information that can be used by the relevant stakeholder. It is a process of reviewing, synthesizing, and interpreting data to describe and explain the phenomena being studied. The interpretive process occurs at many points in the research process. It begins with making sense of what is heard and observed during data gathering, and then builds understanding of the meaning of the data through data analysis. This is followed by development of a description of the findings that makes sense of the data, in which the researcher's interpretation of the findings is embedded. Many research proposals state that the data will be coded, but it is unclear by whom, their qualifications, or the process. Very little, if any, description is provided as to how conclusions will be drawn and how they will be related to the original data, and this standard highlights the need for detailed information on the analytical and interpretive processes for qualitative data and its relationship to the overall study.

QM-4: Establish trustworthiness and credibility of qualitative research

The qualitative research design should incorporate elements demonstrating validity and reliability, which are also known by terms such as trustworthiness and credibility. Studies with qualitative components can use several approaches to help ensure the validity and reliability of their findings, including audit trail, reflexivity, negative or deviant case analysis, triangulation, or member checking (see table 1 for definitions).

MM-1: Specify how mixed methods are integrated across design, data sources, and/or data collection phases

This standard requires investigators to declare and support their intent to conduct a mixed methods approach a priori in order to avoid a haphazard approach to the design and resulting data. Use of mixed methods can enhance the study design, by using the strengths of both quantitative and qualitative research as investigators are afforded the use of multiple data collection tools rather than being restricted to one approach. Mixed methods research designs have three key factors: integration of data, relative timing, and implications of linkages for methods in each component. Additionally, the standards for mixed methods, quantitative, and qualitative methodologies must be met in the design, implementation, and reporting stages. This is different from a multimethod research design in which two or more forms of data (qualitative, quantitative, or both) are used to resolve different aspects of the research question independently and are not integrated.

---

### Mixed methods and survey research in family medicine and community health [^aa14dd10]. Family Medicine and Community Health (2019). Medium credibility.

Box 1
Key characteristics of a well-designed mixed methods study

Researcher collects and analyses both quantitative and qualitative data.
Researcher engages in rigorous procedures with both databases, such as systematic sampling, adequate sample size, use of good instruments and protocols, multistep analysis and standards of qualitative such as validity, replicability, generalisability and accuracy of the findings.
Researcher combines (or mixes) the two databases in a systematic procedure called 'integration', where the overall intent is to bring the databases together, and to conduct analysis that accomplishes this aim and provides new insights.
Researcher conducts the integration within a type of mixed methods design, such as converging or comparing the responses, explaining the findings of one phase, or exploring first before measuring or assessing perspectives to build in a contextual, cultural feature of the study.
Researcher frames the study within larger philosophical assumptions, beliefs or orientations that the researcher brings to a study and incorporates into the study design a theory or conceptual model that informs what the researcher hopes to learn from the study.

Understanding the etiology of mixed methods research, how integration operates and the key characteristics of a good mixed methods project are essential understandings that lead to a contribution of mixed methods in family medicine. For researchers in the health sciences, the 'Best Practices in Mixed Methods in the Health Sciences' from the National Institute of Healthis a useful guideline for understanding an applying mixed methods research.

---

### Mixed methods and survey research in family medicine and community health [^0920ee6b]. Family Medicine and Community Health (2019). Medium credibility.

What were the steps they engaged in to conduct this study? These steps could be applied to many mixed methods projects using survey research. See table 3 for information from the Sonnenberg et al example.

Table 3
Steps in a mixed methods survey investigation as illustrated by the Sonnenberg study

Step 1. Rationale for mixed methods. Determine if mixed methods research is the best methodology to use to answer your research questions. Provide a reason for the use of mixed methods in the project.

Step 2. Quantitative and qualitative databases. Identify the types of quantitative and qualitative data to be collected and analysed. Consider these two types of data as distinct databases. In a mixed method research study, it is important to collect and analyse both quantitative and qualitative data. Use rigorous survey procedures and rigorous qualitative procedures.

Step 3. Mixed methods design. Determine what mixed methods design you will use. Draw a diagram of the design. Mixed methods researchers like to have a visual picture of their procedures. The diagram needs to be simple and straightforward without complicated components.

Step 4. Analyse and report the results of the quantitative and qualitative databases. Present the results of the study showing the quantitative statistical results and the qualitative thematic results. Keep these discussions of analysis separate under distinct headings. They should also mirror the steps in the design, and show a clear linkage between the quantitative and qualitative components in the study.

Step 5. Present and show integration. Pay attention to the point of integration of the two databases and make it specific in the diagram of the design. Use an arrow in the diagram to show the point of integration of the two databases. Discuss the ways integration appears in the study. There are two major ways of representing integration. One is to simply discuss the quantitative and qualitative results side by side in a discussion. The other way is becoming popular in mixed methods research: a joint display. A joint display is typically a table in which the quantitative and qualitative results appear side by side. In this way, comparisons can be made between the quantitative and qualitative results. In an explanatory sequential design, the quantitative results are first reported in a first column, and the qualitative results that help explain the quantitative results appear in a second column. Further, a third separate column shows the impact of the integration in the study. A template is useful for considering the type of joint display that can emerge using an explanatory sequential design as an example.

---

### Synthesising quantitative and qualitative research in evidence-based patient information [^9800e5d4]. Journal of Epidemiology and Community Health (2007). Low credibility.

Background

Systematic reviews have, in the past, focused on quantitative studies and clinical effectiveness, while excluding qualitative evidence. Qualitative research can inform evidence-based practice independently of other research methodologies but methods for the synthesis of such data are currently evolving. Synthesising quantitative and qualitative research in a single review is an important methodological challenge.

Aims

This paper describes the review methods developed and the difficulties encountered during the process of updating a systematic review of evidence to inform guidelines for the content of patient information related to cervical screening.

Methods

Systematic searches of 12 electronic databases (January 1996 to July 2004) were conducted. Studies that evaluated the content of information provided to women about cervical screening or that addressed women's information needs were assessed for inclusion. A data extraction form and quality assessment criteria were developed from published resources. A non-quantitative synthesis was conducted and a tabular evidence profile for each important outcome (eg "explain what the test involves") was prepared. The overall quality of evidence for each outcome was then assessed using an approach published by the GRADE working group, which was adapted to suit the review questions and modified to include qualitative research evidence. Quantitative and qualitative studies were considered separately for every outcome.

Results

32 papers were included in the systematic review following data extraction and assessment of methodological quality. The review questions were best answered by evidence from a range of data sources. The inclusion of qualitative research, which was often highly relevant and specific to many components of the screening information materials, enabled the production of a set of recommendations that will directly affect policy within the NHS Cervical Screening Programme.

Conclusions

A practical example is provided of how quantitative and qualitative data sources might successfully be brought together and considered in one review.

---

### Collecting and analyzing qualitative data | Field epi manual… [^f51708df]. CDC (2024). Medium credibility.

Source: Melissa Corkum, personal communication Choosing When to Apply Qualitative Methods Similar to quantitative approaches, qualitative research seeks answers to specific questions by using rigorous approaches to collecting and compiling information and producing findings that can be applicable beyond the study population. The fundamental difference in approaches lies in how they translate real-life complexities of initial observations into units of analysis. Data collected in qualitative studies typically are in the form of text or visual images, which provide rich sources of insight but also tend to be bulky and time-consuming to code and analyze. As discussed herein, qualitative study designs allow flexibility in sample size to accommodate the need for more or fewer interviews among particular groups to determine the root cause of an issue.

In the context of field investigations, such methods can be extremely useful for investigating complex or fast-moving situations where the dimensions of analysis cannot be fully anticipated. Sampling and Recruitment for Qualitative Research Selecting a Sample of Study Participants Fundamental differences between qualitative and quantitative approaches to research emerge most clearly in the practice of sampling and recruitment of study participants. Qualitative samples are typically small and purposive. In-depth interview informants are usually selected on the basis of unique characteristics or personal experiences that make them exemplary for the study, if not typical in other respects. Determining Sample Size Sample size determination for qualitative studies also follows a different logic than that used for probability sample surveys. For example, whereas some qualitative methods specify ideal ranges of participants that constitute a valid observation, there are no rules on how many observations it takes to attain valid results. In theory, sample size in qualitative designs should be determined by the. Managing, Condensing, Displaying, and Interpreting Qualitative Data Analysis of qualitative data can be divided into four stages: data management, data condensation, data display, and drawing and verifying conclusions. Condensing Qualitative Data Condensing refers to the process of selecting, focusing, simplifying, and abstracting the data available at the time of the original observation, then transforming the condensed data into a data set that can be analyzed. In qualitative research, most of the time investment required to complete a study comes after the fieldwork is complete. Drawing and Verifying Conclusions Analyzing qualitative data is an iterative and ideally interactive process that leads to rigorous and systematic interpretation of textual or visual data.

At least four common steps are involved:

---

### Surveys: an introduction [^18c7b4f6]. Respiratory Care (2004). Low credibility.

Surveys are a valuable research tool for studying the knowledge, attitudes, and behavior of a study population. This article explores quantitative analyses of written questionnaires as instruments for survey research. Obtaining accurate and precise information from a survey requires minimizing the possibility of bias from inappropriate sampling or a flawed survey instrument, and this article describes strategies to minimize sampling bias by increasing response rates, comparing responders to nonresponders, and identifying the appropriate sampling population. It is crucial that the survey instrument be valid, meaning that it actually measures what the investigator intends it to measure. In developing a valid survey instrument, it can be useful to adapt survey instruments that were developed by other researchers and to conduct extensive pilot-testing of your survey instrument.

---

### Qualitative research methods: key features and insights gained from use in infection prevention research [^50164602]. American Journal of Infection Control (2008). Low credibility.

Infection control professionals and hospital epidemiologists are accustomed to using quantitative research. Although quantitative studies are extremely important in the field of infection control and prevention, often they cannot help us explain why certain factors affect the use of infection control practices and identify the underlying mechanisms through which they do so. Qualitative research methods, which use open-ended techniques, such as interviews, to collect data and nonstatistical techniques to analyze it, provide detailed, diverse insights of individuals, useful quotes that bring a realism to applied research, and information about how different health care settings operate. Qualitative research can illuminate the processes underlying statistical correlations, inform the development of interventions, and show how interventions work to produce observed outcomes. This article describes the key features of qualitative research and the advantages that such features add to existing quantitative research approaches in the study of infection control. We address the goal of qualitative research, the nature of the research process, sampling, data collection and analysis, validity, generalizability of findings, and presentation of findings. Health services researchers are increasingly using qualitative methods to address practical problems by uncovering interacting influences in complex health care environments. Qualitative research methods, applied with expertise and rigor, can contribute important insights to infection prevention efforts.

---

### Using mixed methods for genetic counseling research [^935183f6]. Journal of Genetic Counseling (2025). Medium credibility.

Mixed methods research encompasses methodological approaches that involve the collection, analysis, and integration of qualitative and quantitative data. Mixed methods are useful for complex research questions, applied research settings, and when end users value multiple forms of evidence, which makes mixed methods suitable for many areas of genetic counseling research. High-quality rigorous research methods are required to generate useful knowledge that can advance the field of genetic counseling. The goal of this paper was to provide an introduction to mixed methods research and discuss the rationale, research paradigms, study designs, methodological considerations, opportunities, and challenges in genetic counseling research.

---

### Mixed methods research: a primer for the vascular surgeon [^be4103e0]. Seminars in Vascular Surgery (2022). Medium credibility.

Mixed methods research is an approach that intentionally integrates both quantitative and qualitative research methods to answer a research question. The hallmark of mixed methods research is a focus on designing studies that integrate both quantitative and qualitative data, yielding greater results than either method could yield on its own. There are a number of fundamental concepts that are essential to conducting mixed methods research. These include a methodological approach that employs one of the three core study designs, involvement of a multidisciplinary team that includes both methodological and subject matter experts, and meticulous planning to ensure that the data collected can ultimately be integrated to yield findings that answer the original research question to the investigators' (and funders') satisfaction. In this article, we will discuss mixed methods research designs, data sources typically used in mixed methods research, and common data analysis and integration strategies. We will also provide examples of mixed methods research projects that have been used in vascular surgery. The intent of this article was to provide an overview of the field of mixed methods research, enabling the reader to critically assess mixed methods research studies in the literature and consider how this methodology might benefit their own research endeavors.

---

### The American Society of Addiction Medicine clinical practice guideline development methodology [^003556e5]. Journal of Addiction Medicine (2024). High credibility.

Synthesis of evidence — systematic reviews include a qualitative synthesis that is a narrative description of what the evidence shows at a high level, including similarities and differences across studies, key studies that contribute the most, applicability to different populations or settings, and clarifying what is known and gaps in evidence; some systematic reviews may also include a quantitative synthesis (meta-analysis), and the study team determines whether clinical heterogeneity across studies is too great to conduct a meta-analysis and notes that clinical trials lend themselves more readily to meta-analysis than observational studies (with some exceptions); if there are many meaningful differences across studies a meta-analysis could be misleading, whereas assessing results across studies with some small differences can be an advantage, and the team – usually with a statistician with expertise in meta-analysis – can explore heterogeneity statistically and conduct subgroup and sensitivity analyses and even meta-regression analyses for larger bodies of literature; the systematic review team will also note the certainty of evidence supporting each finding using well-established criteria such as those proposed by the GRADE working group.

---

### Synthesising quantitative and qualitative evidence to inform guidelines on complex interventions: clarifying the purposes, designs and outlining some methods [^1d0c28f6]. BMJ Global Health (2019). High credibility.

Introduction

Recognition has grown that while quantitative methods remain vital, they are usually insufficient to address complex health systems related research questions. Quantitative methods rely on an ability to anticipate what must be measured in advance. Introducing change into a complex health system gives rise to emergent reactions, which cannot be fully predicted in advance. Emergent reactions can often only be understood through combining quantitative methods with a more flexible qualitative lens. Adopting a more pluralist position enables a diverse range of research options to the researcher depending on the research question being investigated. As a consequence, where a research study sits within the multitude of methods available is driven by the question being asked, rather than any particular methodological or philosophical stance.

Publication of guidance on designing complex intervention process evaluations and other works advocating mixed-methods approaches to intervention research have stimulated better quality evidence for synthesis. Methods for synthesising qualitativeand mixed-method evidence have been developed or are in development. Mixed-method research and review definitions are outlined in box 1.

Box 1
Defining mixed-method research and reviews

Pluye and Hongdefine mixed-methods research as "a research approach in which a researcher integrates (a) qualitative and quantitative research questions, (b) qualitative research methods* and quantitative research designs, (c) techniques for collecting and analyzing qualitative and quantitative evidence, and (d) qualitative findings and quantitative results". A mixed-method synthesis can integrate quantitative, qualitative and mixed-method evidence or data from primary studies.† Mixed-method primary studies are usually disaggregated into quantitative and qualitative evidence and data for the purposes of synthesis. Thomas and Harden further define three ways in which reviews are mixed.

The types of studies included and hence the type of findings to be synthesised (ie, qualitative/textual and quantitative/numerical).
The types of synthesis method used (eg, statistical meta-analysis and qualitative synthesis).
The mode of analysis: theory testing AND theory building.

---

### The research burden of randomized controlled trial participation: a systematic thematic synthesis of qualitative evidence [^63fc6aaa]. BMC Medicine (2020). Medium credibility.

Quantitative data extraction

One review author (NN) extracted the following descriptive information from the qualitative reports using a standard data extraction form (Additional file 1): study design, data collection methods, data analysis methods, number of participants in the qualitative study, number of RCTs the participants were sourced from, whether the study was nested in the RCT, and which clinical domain(s) were involved.

Two review authors (NN, VNT) independently appraised the methodological quality by using the Critical Appraisal Skills Program (CASP) tool (Additional file 1), a widely used qualitative research appraisal checklist. Disagreements were resolved by consensus and when needed, a third reviewer (IB). The weighted Cohen's Kappa for agreement on CASP criteria ranged from 0.80 to 0.92.

We extracted the following information from the associated RCT reports by using a standard data extraction form (Additional file 1): clinical setting, geographical location, funding sources, number of trial arms, intervention, comparator, estimated sample size, number randomized, masking of allocation, and issues encountered.

---

### Methodologic issues in systematic reviews and meta-analyses [^211217eb]. Clinical Orthopaedics and Related Research (2003). Low credibility.

Systematic reviews of original research are increasing in number. Systematic reviews are distinct from narrative reviews because they address a specific clinical question, require a comprehensive literature search, use explicit selection criteria to identify relevant studies, assess the methodologic quality of included studies, explore differences among study results, and either qualitatively or quantitatively synthesize study results. Systematic reviews that quantitatively pool results of more than one study are called meta-analyses. Several organizations are collaboratively involved in producing high quality systematic reviews and meta-analyses. Familiarity with how to do a systematic review and meta-analysis will lead to greater skill in using this type of article. For clinicians, teachers, and investigators, systematic reviews and meta-analyses are useful sources of evidence.

---

### Methodological standards for qualitative and mixed methods patient centered outcomes research [^1d9eec6f]. BMJ (2020). Excellent credibility.

MM-2: Select and justify appropriate mixed methods sampling strategy

Mixed methods research aims to contribute insights and knowledge beyond that obtained from quantitative or qualitative methods only, which should be reflected in the sampling strategies as well as in the design of the study and the research plan. Qualitative and quantitative components can occur simultaneously or sequentially, and researchers must select and justify the most appropriate mixed method sampling strategy and demonstrate that the desired number and type of participants can be achieved with respect to the available time, cost, research team skillset, and resources. Those sampling strategies that are unique to mixed methods (eg, interdependent, independent, and combined) should focus on the depth and breadth of information across research components.

MM-3: Integrate data analysis, data interpretations, and conclusions

Qualitative and quantitative data often are analyzed in isolation, with little thought given to when these analyses should occur or how the analysis, interpretation, and conclusions integrate with one another. There are multiple approaches to integration in the analysis of qualitative and quantitative data (eg, merging, embedding, and connecting). As such, the approach to integration should determine the priority of the qualitative and quantitative components, as well as the temporality with which analysis will take place (eg, sequentially, or concurrently; iterative or otherwise). Either a priori or emergently, where appropriate, researchers should define these characteristics, identify the points of integration, and explain how integrated analyses will proceed with respect to the two components and the selected approach.

---

### Fundamentals of qualitative analysis in family medicine [^1657588c]. Family Medicine and Community Health (2019). Medium credibility.

Other components of a qualitative research report include a concise summary of the relevant literature included in several key sections of the manuscript, usually placed in the introduction, statement of the problem, findings and conclusions sections. In qualitative research, the investigator typically positions oneself in the research process outlining her or his worldview, theoretical lens and stated biases of the research. As in all research, the author should clearly define key terms and how they are used in the study, a rationale for why qualitative research was selected over quantitative or mixed-methods research, the type of qualitative research design and subapproach selected and why, as well as information regarding institutional review board and ethical considerations and permissions granted from sponsoring agencies to conduct the research. Sample selection procedures need to be documented and explained that specify why and how participants and sites will be chosen and how participants will reciprocally benefit from the study. Data collection procedures and protocols should be documented, designed and implemented. The process of coding and data analysis needs to be clearly outlined along with the discussion and presentation of the research findings (eg, categories, themes, models and theories), conclusions, strengths, limitations and suggestions for future research, references cited pages, and other materials such as data collection instruments included in the appendices.

---

### Advanced and alternative research methods for the acute care surgeon scientist [^3f2d3d3c]. Trauma Surgery & Acute Care Open (2024). Medium credibility.

Mixed methods

Mixed methods research methods purposefully and intentionally combine both quantitative and qualitative data to study a research question. In the field of trauma and acute care surgery, the vast majority of studies have been performed using quantitative research, or the study of numbers with the applications of statistics to determine the amplitude of effect sizes. While quantitative research can reach conclusions about questions such as 'whether' and 'how much', these analyses sometimes lack the ability to answer questions about 'why' or 'how'. Qualitative research uses the collection of non-numerical data, such as text, video, or audio to understand concepts, opinions, and experiences. Common data sources for qualitative research include interviews, focus groups, and surveys, which can be used to gather in-depth insights or generate new ideas. Qualitative studies can help us understand why an intervention does not work in the real world, how patients experience care, and how practitioners think.

There are a number of approaches to mixed methods study design, and some of the most commonly used include: triangular (also known as convergent), exploratory sequential, explanatory sequential, and embedded or nested (figure 1). These designs use integration, or mixing, of results of the quantitative and qualitative results at different points of the study and can be tailored to the specific research question.

Figure 1
This is a representation of the four common approaches to mixed methods research: (1) triangular design, (2) exploratory sequential design, (3) explanatory sequential design, and (4) embedded design. The exploratory and explanatory sequential designs are named for the qualitative component.

Triangular: quantitative and qualitative data are collected simultaneously and the results are mixed and interpreted together. In general, the interpretation of results emphasizes the results from both methods.
Exploratory sequential: qualitative data analysis occurs first, and the analysis of qualitative data is used to develop a theory or an instrument which can be used or tested quantitatively. Quantitative analysis can help to generalize or test qualitative results.
Explanatory sequential: quantitative data analysis occurs first, and the results are used to develop a qualitative data collection strategy. Here, the quantitative results can be clarified, explained, or elaborated using the qualitative results.
Embedded: a quantitative design is the main study methodology, and subjects from the study are enrolled in a nested qualitative study, where the qualitative analysis enhances or explains findings from the quantitative study. Here, the interpretation generally focuses on the quantitative outcomes.

---

### Qualitative research: adding drive and dimension to clinical research [^5ddff877]. Critical Care Medicine (2009). Low credibility.

Qualitative research and its methods stem from the social sciences and can be used to describe and interpret complex phenomena that involve individuals' views, beliefs, preferences, and subjective responses to places and people. Thus, qualitative research explores the many subjective factors that may influence patient outcomes, staff well-being, and healthcare quality, yet fail to lend themselves to the hypothesis-testing approach that characterizes quantitative research. Qualitative research is valuable in the intensive care unit to explore organizational and cultural issues and to gain insight into social interactions, healthcare delivery processes, and communication. Qualitative research generates explanatory models and theories, which can then serve to devise interventions, whose efficacy can be studied quantitatively. Thus, qualitative research works synergistically with quantitative research, providing new impetus to the research process and a new dimension to research findings. Qualitative research starts with conceptualizing the research question, choosing the appropriate qualitative strategy, and designing the study; rigorous methods specifically designed for qualitative research are then used to conduct the study, analyze the data, and verify the findings. The researcher is the data-collecting instrument, and the data are the participants' words and behaviors. Data coding methods are used to describe experiences, discover themes, and build theories. In this review, we outline the rationale and methods for conducting qualitative research to inform critical care issues. We provide an overview of available qualitative methods and explain how they can work in close synergy with quantitative methods. To illustrate the effectiveness of combining different research methods, we will refer to recent qualitative studies conducted in the intensive care unit.

---

### The quality of qualitative research [^fe69d193]. Medical Humanities (2025). Medium credibility.

In this contribution, we discuss criteria for the quality of qualitative research. We consider reliability and validity as specifications of the comprehensive requirement for 'intersubjective replicability', with which qualitative research should comply. In the data collection phase, 'argumentative' reliability generally must suffice; in the data analysis phase, attention must also be given to 'technical' reliability. Validation of qualitative research has to take place via three approaches: 'communicative', 'critical' or 'empirical' validation. This clarifies the relative validity or 'authenticity' of qualitative research.

---

### Synthesising quantitative and qualitative evidence to inform guidelines on complex interventions: clarifying the purposes, designs and outlining some methods [^4af2bc29]. BMJ Global Health (2019). High credibility.

Searching

Once key questions are clearly defined, the guideline development group typically needs to consider whether to conduct a single sensitive search to address all potential subtopics (lumping) or whether to conduct specific searches for each subtopic (splitting). A related consideration is whether to search separately for qualitative, quantitative and mixed-method evidence 'streams' or whether to conduct a single search and then identify specific study types at the subsequent sifting stage. These two considerations often mean a trade-off between a single search process involving very large numbers of records or a more protracted search process retrieving smaller numbers of records. Both approaches have advantages and choice may depend on the respective availability of resources for searching and sifting.

Screening and selecting studies

Closely related to decisions around searching are considerations relating to screening and selecting studies for inclusion in a systematic review. An important consideration here is whether the review team will screen records for all review types, regardless of their subsequent involvement ('altruistic sifting'), or specialise in screening for the study type with which they are most familiar. The risk of missing relevant reports might be minimised by whole team screening for empirical reports in the first instance and then coding them for a specific quantitative, qualitative or mixed-methods report at a subsequent stage.

Assessment of methodological limitations in primary studies

Within a guideline process, review teams may be more limited in their choice of instruments to assess methodological limitations of primary studies as there are mandatory requirements to use the Cochrane risk of bias toolto feed into Grading of Recommendations Assessment, Development and Evaluation (GRADE)or to select from a small pool of qualitative appraisal instruments in order to apply GRADE; Confidence in the Evidence from Reviews of Qualitative Research (GRADE-CERQual)to assess the overall certainty or confidence in findings. The Cochrane Qualitative and Implementation Methods Group has recently issued guidance on the selection of appraisal instruments and core assessment criteria. The Mixed-Methods Appraisal Tool, which is currently undergoing further development, offers a single quality assessment instrument for quantitative, qualitative and mixed-methods studies. Other options include using corresponding instruments from within the same 'stable', for example, using different Critical Appraisal Skills Programme instruments. While using instruments developed by the same team or organisation may achieve a degree of epistemological consonance, benefits may come more from consistency of approach and reporting rather than from a shared view of quality. Alternatively, a more paradigm-sensitive approach would involve selecting the best instrument for each respective review while deferring challenges from later heterogeneity of reporting.

---

### Understanding qualitative research in health care [^931077e9]. Drug and Therapeutics Bulletin (2017). Low credibility.

Qualitative studies are often used to research phenomena that are difficult to quantify numerically. 1,2 These may include concepts, feelings, opinions, interpretations and meanings, or why people behave in a certain way. Although qualitative research is often described in opposition to quantitative research, the approaches are complementary, and many researchers use mixed methods in their projects, combining the strengths of both approaches. 2 Many comprehensive texts exist on qualitative research methodology including those with a focus on healthcare related research. 2–4 Here we give a brief introduction to the rationale, methods and quality assessment of qualitative research.

---

### Protocol for a mixed-methods study of supplemental oxygen in pulmonary fibrosis [^4d41bc20]. BMC Pulmonary Medicine (2014). Low credibility.

Study overview

Quantitative data will be collected through questionnaires and GPS and accelerometer devices (see section titled "Quantitative data collection" for more details on these modes of data collection). Quantitative data will be captured once for patients in category 1 and at four time points for patients in category 4 (the longitudinal study): 1) at enrollment; 2) just prior to daily-use O₂ initiation; 3) one month after starting daytime O₂; and 4) 9–12 months after starting daytime O₂.

For patients in the longitudinal arm, beginning at enrollment, we will also collect monthly response data for the University of California San Diego Shortness of Breath Questionnaire (or UCSD). Doing so gives us the opportunity to plot rich trajectories for dyspnea and to detect subtleties that might be missed with a less frequent data collection schedule for this outcome.

Qualitative data will be collected via semi-structured, in-depth telephone interviews and used to clarify and enrich findings from the quantitative data. The interviews will be conducted either once (for patients in category 1) or, for some patients in the longitudinal study, at the four time points described above (see section titled "Qualitative data collection" for a more detailed description of the interviews). The National Jewish Health Institutional Review Board has approved the study protocol (HS-2790), and the study is registered on ClinicalTrials.gov (NCT01961362).

Quantitative data collection

Figure 1 gives an overview of the longitudinal arm of the study. In keeping with the mission and mandates of our program's funder, the Patient-Centered Outcomes Research Institute (PCORI), our team selected outcome measures by democratic process. During round table discussions, questionnaires were selected from groups of candidate instruments. Questionnaires will be administered and completed online, or, for those who wish, via paper and pencil and returned via pre-paid envelope. Online questionnaires will be completed via REDCap software.

Figure 1
Longitudinal study design.

---

### Survey research [^c44856f5]. Anesthesiology (2019). Medium credibility.

Surveys provide evidence on practice, attitudes, and knowledge. However, conducting good survey research is harder than it looks. The authors aim to provide guidance to both researchers and readers in conducting and interpreting survey research. Like all research, surveys should have clear research question(s) using the smallest possible number of high-quality, essential, survey questions (items) that will interest the target population. Both researchers and readers should put themselves in the position of the respondents. The survey questions should provide reproducible results (reliable), measure what they are supposed to measure (valid), and take less than 10 min to answer. Good survey research reports provide results with valid and reliable answers to the research question with an adequate response rate (at least 40%) and adequate precision (margin of error ideally 5% or less). Possible biases among those who did not respond (nonresponders) must be carefully analyzed and discussed. Quantitative results can be combined with qualitative results in mixed-methods research to provide greater insight.

---

### Methodological standards for qualitative and mixed methods patient centered outcomes research [^4d908261]. BMJ (2020). Excellent credibility.

Rigorous methodologies are critical for ensuring the trustworthiness of research results. This paper will describe the process for synthesizing the current literature providing guidance on the use of qualitative and mixed methods in health research; and the process for development of methodology standards for qualitative and mixed methods used in patient centered outcomes research. Patient centered outcomes research is comparative clinical effectiveness research that aims to evaluate the clinical outcomes resulting from alternative clinical or care delivery approaches for fulfilling specific health and healthcare needs. By focusing on outcomes that are meaningful to patients, studies on patient centered outcomes research strengthen the evidence base and inform the health and healthcare decisions made by patients, clinicians, and other stakeholders.

The methods used in patient centered outcomes research are diverse and often include qualitative methodologies. Broadly, qualitative research is a method of inquiry used to generate and analyze open ended textual data to enhance the understanding of a phenomenon by identifying underlying reasons, opinions, and motivations for behavior. Many different methodologies can be used in qualitative research, each with its own set of frameworks and procedures. This multitude of qualitative approaches allows investigators to select and synergize methods with the specific needs associated with the aims of the study.

Qualitative methods can also be used to supplement and understand quantitative results; the integration of these approaches for scientific inquiry and evaluation is known as mixed methods. This type of approach is determined a priori, because the research question drives the choice of methods, and draws on the strengths of both quantitative and qualitative approaches to resolve complex and contemporary issues in health services. This strategyis achieved by integrating qualitative and quantitative approaches at the design, methods, interpretation, and reporting levels of research. Table 1 lists definitions of qualitative methods, mixed methods, and patient centered outcomes research. The methodology standards described here are intended to improve the rigor and transparency of investigations that include qualitative and mixed methods. The standards apply to designing projects, conducting the studies, and reporting the results. Owing to its focus on patient centered outcomes research, this article is not intended to be a comprehensive summary of the difficulties encountered in the conduct of qualitative and mixed methods research.

---

### Synthesis of guidance available for assessing methodological quality and grading of evidence from qualitative research to inform clinical recommendations: a systematic literature review [^260ccd7f]. RMD Open (2024). Medium credibility.

Discussion

This systematic literature review highlights that various tools exist to assess the quality of qualitative studies. However, no validated hierarchy of evidence exists to integrate the evidence from qualitative research to inform the development of clinical recommendations. This is relevant in the context of formulating recommendations, which is how this work began in the first place: a systematic review of available evidence, to inform the EULAR SOP on the development of recommendations, specifically when dealing with qualitative studies. As in the case for quantitative research, a similar 'standard' was necessary for qualitative research, to ensure appropriate handling of qualitative evidence when formulating recommendations.

We found five tools (including checklists) that had been applied to assess the quality of qualitative studies. All tools had similarities in evaluating the research design of the qualitative study, recruitment, ethical rigour, data collection and data analysis.

One of the tools used for appraising the quality of qualitative studies had a 'total score' to determine the overall level of quality. However, it can be argued that this approach could be problematic as it may overlook specific limitations of the study. This issue has also been found in quantitative tools, resulting in Cochrane revising their Risk of Bias tool for randomised controlled trials into a domain-based instrument. The remaining four were based on evaluation of domains in which critical assessments are made separately for different domains. For the purpose of EULAR, a more domain-based approach to appraising qualitive studies may be more appropriate.

The GRADE-CERqual approach was also identified in our review, where researchers aim to determine the level of confidence to place in the findings from qualitative evidence synthesis/systematic reviews of qualitative research. In this approach, confidence is determined by considering four key components: (1) methodological limitations; (2) coherence; (3) adequacy of the data and (4) relevance. In line with the GRADE process for quantitative research, it is important to note the aim of the GRADE CERQual approach is to provide transparency in the process of moving from evidence to recommendation by evaluating these four key components. Users are advised to make a written note explaining their decision, and then reread and evaluate the decisions for all four components to reach an overall confidence assessment. As a 'process', it emphasises the usefulness of qualitative evidence in decision-making but still highlights the need for qualitative evidence not to be used alone, when making decisions about interventions.

---

### Mixed methods and survey research in family medicine and community health [^9d9c6804]. Family Medicine and Community Health (2019). Medium credibility.

Step 6. Explicate the value of using mixed methods. In a discussion section at the end of the study, include comments about the value of using mixed methods as a methodology. In this way, readers of the study will see the utility of mixed methods in research. This means drawing the implications of using both quantitative and qualitative data in a mixed methods study.

---

### Specialist antenatal clinics for women at high risk of preterm birth: a systematic review of qualitative and quantitative research [^46c24b16]. BMC Pregnancy and Childbirth (2017). Low credibility.

Methodological quality assessments

The risk of bias of studies of a quantitative type were assessed by applying the Cochrane Effective Practice and Organization of Care group (EPOC) criteria. The tool assesses the risk of bias for the following domains: sequence generation, allocation concealment, blinding, incomplete outcome data, selective reporting, baseline characteristics, baseline outcomes, protection against contamination and other bias. Each domain was given one of the following ratings: "yes", "no" or "unclear".

The Critical Appraisal Skills Programme (CASP) for evaluating the risk of bias of studies of qualitative design was implemented. This tool has a checklist of ten questions covering the study objectives and rationale, study methods, study design, study value, recruitment strategies, method of data collection, information on ethical approval, researcher-participant relationship, reliability and validity method of analysing data and reporting of findings. Each domain was given "yes", "no" or "unclear".

The quality assessment was conducted independently by the two reviewers and any discrepancies in quality rating were resolved by discussion. For low risk of bias studies the low risk should be given to all domains in the risk of bias tool; for medium risk of bias studies at least 1 of the risk-of-bias criteria was not met, and a high risk of bias studies was assigned to studies with two or more risk-of-bias domains of the risk of bias tool. Unclear risk of bias was assigned for the studies when risk-of-bias criteria was poorly reported.

Data collection and analysis

Individual data extraction forms were designed for the quantitative and qualitative studies. The form for quantitative studies holds information about the study design, participants' characteristics, components of care provided in the clinics, outcome variables and reported results. For qualitative studies the study setting, study aims, ethics, participants' characteristics, and recruitment and sampling methods, methods used for data collection and analysis, reported themes and study conclusion were extracted.

Studies were summarized and grouped by their study designs and sub-grouped by their reported outcomes. A narrative synthesis only was implemented for data extracted from quantitative studies, as we identified heterogeneity and variation across the included studies. The heterogeneity arose from different study designs, variation in study inclusion criteria, intervention and reported outcomes. We originally planned to undertaken a meta-synthesis of data extracted from qualitative studies, however we only reported the common themes from one qualitative study found eligible for inclusion in this review.

All data were extracted and cross checked independently by the two reviewers.

---

### Systematic reviews and meta-analysis for the surgeon scientist [^f64bf45a]. The British Journal of Surgery (2006). Low credibility.

Background

Understanding of data-reporting methods is imperative for correct interpretation of the medical literature as well as for proper performance of future clinical research. Recent developments in biostatistics have greatly changed the types of statistical analyses used and the minimum quality standards that must be maintained.

Method

Different types of review are described, including systematic review with and without meta-analysis. Minimum reporting standards, sources of bias, both quantitative and qualitative, and references are discussed.

Results and Conclusion

Meta-analysis has become a clearly defined technique, with reporting standards for both randomized controlled trials and observational studies. It is assuming a wider role in the surgical literature. Although many sources of bias exist, there are clear reporting standards and readers should be aware of these when studying the literature.

---

### Synthesis of guidance available for assessing methodological quality and grading of evidence from qualitative research to inform clinical recommendations: a systematic literature review [^dcb40a63]. RMD Open (2024). Medium credibility.

Introduction

There has been increasing recognition over time on the role of qualitative research, including in complementing quantitative, epidemiological research and informing clinical practice. In recent years, the patients' and carers' perspectives, specifically on the acceptability and feasibility of interventions and services, have been considered in the development of clinical guidelines and recommendations. Additionally, it is becoming more widely acknowledged that qualitative research has a significant role to play in addressing issues and concerns with complex interventions, and the guideline development process.

Depending on the nature of the topic and research question (RQ), a range of different qualitative methods may be applied. These include structured interviews (eg, following a topic guide closely, where all participants are asked exactly the same questions), semistructured interviews (eg, including a range of closed and open-ended questions, and the interviewer may adapt the topic guide according to the responses of the participants); focus groups (often held with 8–12 participants from the target population, where group dynamics and collective perceptions on a topic are required) and observations (where researchers observe participants to gain an insight into their experiences). Furthermore, many different methodologies are applied to analyse qualitative research (ie, thematic analysis, grounded theory, qualitative content analysis).

---

### Collecting comprehensive and… [^563a0cad]. FDA (2025). Medium credibility.

PUBLIC WORKSHOP ON GUIDANCE 1 COLLECTING COMPREHENSIVE AND REPRESENTATIVE INPUT DISCUSSION DOCUMENT Workshop Date: December 18, 2017. Studies Using Quantitative Methods. 21 2.
4.
2.
2. Studies Using Qualitative Methods. 22 2.
5. Constructing a Sampling Frame. 22 2.
6. Additional Considerations to Achieve Sufficient Representation.
23. 3.

1.

1.
2. Social Media. 25 3.

1.
2. Selecting qualitative methods. 26 3.

1.
3. Analyzing qualitative data. 26 3.
2. Quantitative Research Methods. 27 3.
2.

1. Analyzing quantitative data. 27 3.
3. Mixed Methods. 27 3.
3.

1. Analyzing data from mixed methods.
28. 21 understood by a wide range of patients and others. 22 Guidance 2 will provide discussion on methods for gathering information about what aspects 23 of symptoms, impacts of their disease, and other issues are important to patients. It will discuss 24 how to do qualitative research including interviews, interview guides, types of survey.

25 questions, and considerations for collecting demographics and survey information. It will also 26 discuss survey methods and qualitative research topics to help avoid misleading results such as 27 inadvertently priming patients in ways that can lead to results that poorly represent what is 28 important to patients.
29. 153 kinds of research approaches to consider and will detail suggested approaches for 154 summarization/tabulation, presentation and subsequent submission of the collected information 155 for review. Guidances 2 through 4 can then be used to inform relevant 156 stakeholders of subsequent steps necessary for the development and testing of COAs that may be. 239 al., 2014). 240 241 How do you collect patient experience data. FDA recommends using qualitative, quantitative, 242 or mixed methods to collect 243 robust and meaningful patient experience data.

These methodological approaches are discussed.

---

### Methodological standards for qualitative and mixed methods patient centered outcomes research [^e7a2e1c7]. BMJ (2020). Excellent credibility.

Application of methodology standards in research design

The standards can be used across the research continuum, from research design and application development, conduct of the research, and reporting of research findings. We provide an example for researchers on how these standards can be used in the preparation of a research application (table 3).

Table 3
Guidance for researchers on how to use Patient-Centered Outcomes Research Institute's (PCORI) methodology standards for qualitative and mixed methods research in application preparation

QM-1: State the qualitative approach to research inquiry, design, and conduct

Many research proposals on patient centered outcomes research or comparative effectiveness research propose the use of qualitative methods but lack adequate description of and justification for the qualitative approach that will be used. Often the rationale for using qualitative methods is not tied back to the applicable literature and the identified evidence gap, missing the opportunity to link the importance of the approach in capturing the human experience or patient voice in the research aims. The approach to inquiry should be explicitly stated along with the rationale and a description of how it ties to the research question(s). The research proposal should clearly define how the qualitative approach will be operationalized and supports the choice of methods for participant recruitment, data collection, and analysis. Moreover, procedures for data collection should be stated, as well as the types of data to be collected, when data will be collected (that is, one point in time v longitudinal), data management, codebook development, intercoder reliability process, data analysis, and procedures for ensuring full confidentiality.

QM-2: Select and justify appropriate qualitative methods and sampling strategy

While the number of participants who will be recruited for focus groups or in-depth interviews is usually described, the actual sampling strategy is often not stated. The description of the sampling strategy should state how it aligns with the qualitative approach, how it relates to the research question(s), and the variation in sampling that might occur over the course of the study. Furthermore, most research proposals state that data will be collected until thematic saturation is reached, but how this will be determined is omitted. As such, this standard outlines the information essential for understanding who is participating in the study and aims to reduce the likelihood of making unsupported statements, emphasizing transparency in the criteria used to determine the stopping point for recruitment and data collection.

---

### Qualitative approaches in health services research: a methodological primer [^e1d239ac]. Hospital Pediatrics (2025). Medium credibility.

Qualitative methods are essential in health services research. Unlike quantitative methods, qualitative approaches are most effective in exploring the "how" and "why" of complex social phenomena, offering rich insights into attitudes, beliefs, and experiences that might otherwise be overlooked. Aimed at research teams new to qualitative work, this paper introduces qualitative research methods, explaining key terms, data collection strategies, and analytic approaches. We also discuss the theoretical foundations of and methodological rigor in qualitative research. Additionally, we present a novel model that conceptualizes qualitative research as the scaffolding for other research methods within the hierarchy of evidence, highlighting its role in generating hypotheses and adding greater context to quantitative findings. By providing an accessible overview of rigorous approaches to qualitative research, we hope to encourage greater application of qualitative methods in health services research.

---

### Fundamentals of qualitative analysis in family medicine [^823553ce]. Family Medicine and Community Health (2019). Medium credibility.

A background to qualitative research in the social and health sciences

Characteristics of qualitative research

Qualitative research can be defined as an umbrella term used to designate a family of approaches that emphasise inductive reasoning, collecting data in natural settings and understanding participants' points of view. Qualitative researchers use interviews, participant observation, document analysis and so on to generate patterns or themes to describe and explain phenomena in depth. Other terms describing this type of research are naturalistic, ethnographic, interpretive and symbolic interactionist. In addition to inductive data analysis, long-term immersion of the researcher in naturalistic settings, and thick and rich description, other characteristics delimiting qualitative research include the researcher as the primary data collection instrument, an overarching concern with process, an emphasis on emergent and flexible design, non-random purposeful sample selection, and a holistic understanding fostered through collection and analysis of multiple forms of data and perspectives. Qualitative researchers aspire to shift the mantle of authority from the investigator to the participant, the latter viewed and purposefully selected as the expert on the central phenomenon of study and therefore assuming more status and a greater role in the research than historically accorded by more paternalistic forms of quantitative enquiry. Conceptualised in this manner, the qualitative researcher has the means to get closer to the participants and topic of enquiry than that afforded by quantitative designs.

---

### Synthesising quantitative and qualitative evidence to inform guidelines on complex interventions: clarifying the purposes, designs and outlining some methods [^f67fceaf]. BMJ Global Health (2019). High credibility.

Questions as anchors or compasses

Questions can serve as an 'anchor' by articulating the specific aspects of complexity to be explored (eg, Is successful implementation of the intervention context dependent?). Anchor questions such as "How does intervention x impact on socioeconomic inequalities in health behaviour/outcome x" are the kind of health system question that requires a synthesis of both quantitative and qualitative evidence and hence a mixed-method synthesis. Quantitative evidence can quantify the difference in effect, but does not answer the question of how. The 'how' question can be partly answered with quantitative and qualitative evidence. For example, quantitative evidence may reveal where socioeconomic status and inequality emerges in the health system (an emergent property) by exploring questions such as " Does patterning emerge during uptake because fewer people from certain groups come into contact with an intervention in the first place? " or " are people from certain backgrounds more likely to drop out, or to maintain effects beyond an intervention differently? " Qualitative evidence may help understand the reasons behind all of these mechanisms. Alternatively, questions can act as 'compasses' where a question sets out a starting point from which to explore further and to potentially ask further questions or develop propositions or hypotheses to explore through a complexity perspective (eg, What factors enhance or hinder implementation?). Other papers in this series provide further guidance on developing questions for qualitative evidence syntheses and guidance on question formulation.

---

### How to summarise and report written qualitative data from patients: a method for use in cancer support care [^7575b9e6]. Supportive Care in Cancer (2007). Low credibility.

Goals Of Work

The goal of this study is the determination of key themes to aid the analysis of qualitative data collected at three cancer support centres in England, using the Measure Yourself Concerns and Wellbeing (MYCaW) questionnaire.

Patients and Methods

People with cancer who use complementary therapies experience and value a wide range of treatment effects, yet tools are urgently required to quantitatively measure these outcomes. MYCaW is an individualised questionnaire used in cancer support centres providing complementary therapies, scoring 'concerns or problems' and 'well-being' and collecting qualitative data about other major events in a patient's life and what has been most important to the patient. Content analysis on 782 MYCaW questionnaires from people at these cancer support centres was carried out. The 'concerns', 'other things going on in their life' and 'important aspects of centre' were thematically categorised and externally validated by a focus group, and the inter-rater reliability was calculated.

Main Results

Clinical information from a cancer patient's perspective was collected that is not measured on standard quality-of-life questionnaires; furthermore, some themes acknowledge the multi-faceted aspects of complementary and alternative medicine provision, rather than information only relating to the therapeutic intervention. Categories for qualitative MYCaW analysis have been established providing a tool for future research and/or service delivery improvement within cancer support centres such as these.

Conclusions

The established themes provide a framework to aid analysis of qualitative aspects of complementary therapy care for people with cancer, improving our understanding of how the patient's cancer experience can be aided by complementary therapies in specialised cancer centres.

---

### [pdf] collecting comprehensive and representative input… [^5e650ec9]. FDA (2025). Medium credibility.

Table 6. Advantages and Disadvantages of Different Qualitative Data Collection Methods. 16 Table 7. Coding Types. 19 Table 8. Modes for Displaying Qualitative Data. 20 Table 9. Quantitative Research Aims. 21 Table 10. Data Types. 22 Figure 1. Factors to Determine Appropriate Sample Size for Focus Groups. 15 Figure 2. Coding by Themes Example.
19. Quantitative Research Mixed Methods Research Scientific Approach Exploratory or "bottom-up" — The researcher generates or constructs knowledge, hypotheses, and grounded theory from data collected during fieldwork  Confirmatory or "top- down" — the researcher tests.

controlled conditions; isolate the causal effect of single variables  Study multiple contexts, perspectives, or conditions; study multiple factors as they operate together Data Collection  Qualitative data such as in-depth interviews, participant observations, field notes, and open- ended questions  Quantitative data generated through precise measurement using structured data-collection instruments  Both qualitative and quantitative data. 10 Data Characteristics  Words, images, categorizations  Quantifiable variables  Mixture of quantifiable variables, words, categorizations, and images Data Analysis  Use descriptive analysis to identify patterns, themes,… holistic features of qualitative data  Identify statistical relationships among variables  Quantitative and qualitative analysis used separately and in combination Source: Johnson and Christensen 2017 124 2. Qualitative Research Methods 125 Some of the aims of qualitative research are shown in Table
2.

One-on-one interviews  Most common source of qualitative data in outcomes research.  A one-on-one interview is a conversation between a research participant and interviewer, directed toward producing information about participants' experiences, feelings, and opinions and subsequently deriving meaning out of what participants say. the participant within the conversation. During the discussion, the interviewer provides little direction toward an a priori research agenda.

---

### Use of qualitative methods alongside randomised controlled trials of complex healthcare interventions: methodological study [^83eac609]. BMJ (2009). Excellent credibility.

Quality of the qualitative studies

Ten qualitative studies (including the seven with no formal analysis of the qualitative data) did not provide sufficient data to allow assessment of methodological quality. Quality assessment was therefore carried out on 20 studies (table 2). This showed high variability, with the most common weaknesses including lack of a clear justification for the qualitative approach used (no information in 16 studies); inadequate descriptions of context, sampling, data collection, and analysis methods; little reflection on the researcher's role in the research process (no information in 17 studies); lack of clarity on how ethical issues had been taken into consideration (no information in 15 studies), and insufficient evidence to support the claims made in the paper.

Table 2
Methodological quality of 20 of 30 included qualitative studies that had sufficient information to carry out a quality assessment

*For five studies for which the details of methods of data collection were not clearly described or were unclear (for example, where and when data were collected), the data collection method itself, such as individual interviews or focus group discussions, was assessed as appropriate to research question.

We did not identify any relation between interventions that reported using an explicit theoretical framework and the quality of qualitative studies carried out alongside trials of those interventions.

---

### Reporting guidelines for allergy and immunology survey research [^70b081b5]. Annals of Allergy, Asthma & Immunology (2023). Medium credibility.

Although survey reports are common, fewer than 10% of medical journals provide clear guidelines to investigators for survey research. In this special article, we provide guidance on minimum recommendations in the form of a CHecklist for Allergy and Immunology Reporting of Survey research (CHAIRS). Key components to consider include providing background information, such as a clear statement of the research hypothesis and question, and rationale for the study. When considering sample selection, a clear understanding of the relationship between the target population, sampling frame, sample scheme, representativeness, and sample size is needed. Review of the survey tool by content experts and assessment of threats to survey validity should occur early in questionnaire development with consideration of cognitive interviews and pretesting to facilitate accurate measurement. Last, a transparent description of data collection and qualitative and quantitative characteristics of response rate is needed to ensure that appropriate inferences and conclusions can be drawn from the survey research.

---

### Qualitative research in emergency care part I: research principles and common applications [^d17884c4]. Academic Emergency Medicine (2015). Low credibility.

Qualitative methods are increasingly being used in emergency care research. Rigorous qualitative methods can play a critical role in advancing the emergency care research agenda by allowing investigators to generate hypotheses, gain an in-depth understanding of health problems or specific populations, create expert consensus, and develop new intervention and dissemination strategies. This article, Part I of a two-article series, provides an introduction to general principles of applied qualitative health research and examples of its common use in emergency care research, describing study designs and data collection methods most relevant to our field, including observation, individual interviews, and focus groups. In Part II of this series, we will outline the specific steps necessary to conduct a valid and reliable qualitative research project, with a focus on interview-based studies. These elements include building the research team, preparing data collection guides, defining and obtaining an adequate sample, collecting and organizing qualitative data, and coding and analyzing the data. We also discuss potential ethical considerations unique to qualitative research as it relates to emergency care research.

---

### Common errors in statistics and methods [^9bb4c344]. BMJ Paediatrics Open (2024). High credibility.

Quality assessment of studies

Quality assessment should be performed as a quantitative assessment of the studies included in meta-analysis using a set of predefined safeguards to reduce the risks of bias. Quality assessment tools should be used as they were designed to be used, with any user-defined adaptations clearly justified. Any issues of quality or potential risk of bias, which may impact on meta-analysis results, should be briefly described. Quality 'scores' should only be assigned according to scoring systems defined by the tool, and user-defined scores (ie, user-defined thresholds for high, moderate, low quality, etc) should be avoided. While a study with the best 'score' does not ensure high quality, it ensures that predefined safeguards to reduce risks of bias are met.

Lack of grading the certainty of the main results in meta-analysis

It is common practice to accept the combined results of a meta-analysis at face value and categorise them as significant or non-significant without considering the importance of the findings as well as potential biases and flaws in both the individual studies included in the meta-analysis and the overall estimation (particularly heterogeneity, publication bias or small study bias). To be valuable in clinical practice, the results of a meta-analysis should also be evaluated for certainty and quality using methods such as GRADE.

Incomplete info to understand/reproduce the search results in meta-analysis

This is another illustration of the general rule that your paper should have enough information to allow other researchers to duplicate what you did. Some authors simply list terms (and not search engines or detailed search structure) or do not give dates.

---

### Advanced and alternative research methods for the acute care surgeon scientist [^8f4ec2f6]. Trauma Surgery & Acute Care Open (2024). Medium credibility.

A key justification for the use of mixed methods in research of health-related questions is to examine diverse types of research questions, such as how patients experience health conditions and care, how organizations provide care, as well as the context and complexity of decisions and outcomes. Mixed research methods can provide a more complete picture than a standalone quantitative or qualitative study, as their strengths and weaknesses complement one another. Advantages of mixing methods over using either method alone include contextualization, as the two methods can uncover data which is dissonant and help explain discrepancies, credibility, as the two methods can enhance the validity of findings if they reach similar findings, and generalizability, as quantitative methods can improve external validity of a qualitative study. Teams with diverse methodological training are instrumental to the design and implementation of mixed methods studies.

---

### Synthesis of guidance available for assessing methodological quality and grading of evidence from qualitative research to inform clinical recommendations: a systematic literature review [^ce605bcb]. RMD Open (2024). Medium credibility.

Objective

To understand (1) what guidance exists to assess the methodological quality of qualitative research; (2) what methods exist to grade levels of evidence from qualitative research to inform recommendations within European Alliance of Associations for Rheumatology (EULAR).

Methods

A systematic literature review was performed in multiple databases including PubMed/Medline, EMBASE, Web of Science, COCHRANE and PsycINFO, from inception to 23 October 2020. Eligible studies included primary articles and guideline documents available in English, describing the: (1) development; (2) application of validated tools (eg, checklists); (3) guidance on assessing methodological quality of qualitative research and (4) guidance on grading levels of qualitative evidence. A narrative synthesis was conducted to identify key similarities between included studies.

Results

Of 9073 records retrieved, 51 went through to full-manuscript review, with 15 selected for inclusion. Six articles described methodological tools to assess the quality of qualitative research. The tools evaluated research design, recruitment, ethical rigour, data collection and analysis. Seven articles described one approach, focusing on four key components to determine how much confidence to place in findings from systematic reviews of qualitative research. Two articles focused on grading levels of clinical recommendations based on qualitative evidence; one described a qualitative evidence hierarchy, and another a research pyramid.

Conclusion

There is a lack of consensus on the use of tools, checklists and approaches suitable for appraising the methodological quality of qualitative research and the grading of qualitative evidence to inform clinical practice. This work is expected to facilitate the inclusion of qualitative evidence in the process of developing recommendations at EULAR level.

---

### Step 5-generate and support conclusions… [^fbc8831d]. CDC (2025). Medium credibility.

Planning Data Analysis A data analysis plan includes how and by whom the data would be organized, analyzed, and synthesized. A plan that is feasible, appropriate, and aligns to the evaluation questions and data collection methods identified in earlier steps is more likely to produce findings that will be used by the interest holders. Evaluators will want to collaboratively engage interest holders to obtain agreement on the techniques for analysis and interpreting findings before data collection begins to promote transparency. Conducting Data Analysis Common steps for quantitative and qualitative analysis are described below. Common key steps for quantitative data analysis:

- Clean and pre-process raw data for accuracy and consistency. Check for missing data, standardize data formats, and make any other corrections needed.
- Import data into a statistical software program such as SAS, STATA, SPSS, R, or Excel.
- Analyze data based on the indicators defined in Step 4.
- Calculate descriptive statistics to describe, summarize, and compare key characteristics about the data. For some indicators, data will need to be stratified or grouped based on variables of interest first.
- Explore distributions and variations within the data. Analyze trends, patterns, and relationships within the data.
- Draw conclusions from the findings.
- Evaluation questions looking to determine the association between program activities and the intervention or desired outcomes will require more advanced statistical analyses such as means comparisons or regression analysis. Common key steps for qualitative data analysis:

- Transcribe recordings from interviews or focus groups and/or enter narrative comments from surveys or field notes into a word processing or qualitative analysis software such as nVivo, Excel, MAXQDA, or ATLAS. ti.
- Review and annotate the data to understand and familiarize yourself with the content. This could involve reading interview transcripts or listening to recordings.
- Organize the data for instance, by date, by data collection type, or by question asked.
- Code the text to identify and label key themes that correspond to your evaluation questions.
- Group text by key themes.
- Review the themes and codes for refinement and to identify any sub-themes that emerge.
- Draw conclusions from the findings.
- More advanced qualitative analysis techniques include the use of multiple coders, calculation of interrater reliability, and within or between-case analysis.

---

### Multi-level factors affecting adolescent and youth engagement in HIV-research in low-and middle-income countries: a qualitative evidence synthesis [^3744ad3b]. The Cochrane Database of Systematic Reviews (2025). Medium credibility.

Types of studies

We will include primary studies that use qualitative study designs, such as ethnography, phenomenology, case studies, grounded theory studies, and qualitative process evaluations. We will include studies that use both qualitative methods for data collection (e.g. focus group discussions, individual interviews, observation, diaries, document analysis, open‐ended survey questions) and qualitative methods for data analysis (e.g. thematic analysis, framework analysis, grounded theory). We will exclude studies that collect data using qualitative methods but do not analyse the data using qualitative analysis methods (e.g. open‐ended survey questions where the response data are analysed using descriptive statistics only).

We will include mixed‐methods studies if it is possible to extract the data that were collected and analysed using qualitative methods.

We will not exclude studies based on our assessment of methodological limitations. We will use this information about methodological limitations to assess our confidence in the review findings.

Setting

As evident in the objectives, this review is based on the experiences of young people living in LMICs. Therefore, we will only include countries that meet these criteria. We will use the country income classifications used by the World Bank (World Bank 2024).

---

### Systematic debriefing after qualitative encounters: an essential analysis step in applied qualitative research [^4083d21c]. BMJ Global Health (2018). Medium credibility.

Table 1
Organization of qualitative research and qualitative data collection teams

This practice paper focuses on the data collection phase of the table with an emphasis on debriefings, the process where a research lead interviews data collectors soon after a data collection activity. We view debriefings as a necessary element in qualitative research, particularly as the field comes to embrace styles beyond the conventional academic ideal (one person enacting the research process from conception to publication). Furthermore, while we observe a general consensus regarding the rationale and process for undertaking many points in the five-step table (table 1), we see that debriefings receive relatively little attention in the literature and in trainings on qualitative research for public health. When debriefings are mentioned in publications, including our own, there is minimal insight into what the debriefing entailed, how it was conducted or how debriefings fundamentally informed the data collection or analysis process. Finally, given that in AQR, much of the data are collected by individuals who have limited training in qualitative research or are more familiar with quantitative survey administration, we urge researchers to more thoughtfully consider discussions on process (ensuring that the data are collected in an iterative i fashion, that the data set is responding to the research question and that the skills of data collectors are strengthened in real time) rather than on outputs (transcription and coding). We now outline what debriefings are, how their purpose shifts in the process of data collection and how debriefings have amplified trustworthiness in our own research.

---

### An overview of survey research [^e39186e7]. Respiratory Care (2023). Medium credibility.

Surveys provide evidence for the social sciences for knowledge, attitudes, and other behaviors, and, in health care, to quantify qualitative research and to assist in policymaking. A survey-designed research project is about asking questions of individuals, and, from the answers, the researcher can generalize the findings from a sample of respondents to a population. Therefore, this overview can serve as a guide to conducting survey research that can provide answers for practitioners, educators, and leaders, but only if the right questions and methods are used. The main advantage of using surveys is their economical access to participants online. A major disadvantage of survey research is the low response rates in most situations. Online surveys have many limitations that should be expected before conducting a search, and then described after the survey is complete. Any conclusions and recommendations are to be supported by evidence in a clear and objective manner. Presenting evidence in a structured format is crucial but well-developed reporting guidelines are needed for researchers who conduct survey research.

---

### Practical mixed methods strategies used to integrate qualitative and quantitative methods in community-based primary health care research [^719f3bc6]. Family Practice (2019). Medium credibility.

Conclusions

This review described practical strategies used for integrating qualitative and quantitative phases, results and data. Specifically, the combinations of integration strategies described in this manuscript provide ideas and possibilities to guide CBPHC researchers for planning and reporting their future MM studies. Additionally, this review has emphasized a need of advocacy of guidance for transparent reporting of MM studies among CBPHC researchers and editors, which can contribute to publish reproducible MM studies.

---

### Applying a new concept of embedding qualitative research: an example from a quantitative study of carers of people in later stage dementia [^094bd542]. BMC Geriatrics (2019). Medium credibility.

Background

"Almost every simple question, you get some kind of story"

(Research interviewer)

Mixed methods research offers the opportunity to combine the benefits of research approaches with the inclusion of qualitative methods extending the depth of understanding of people's perceptions, experiences and feelings. There are many different designs used for mixed methods including an increasing interest in embedding qualitative studies within larger quantitative research. However, to our knowledge, none have considered the naturally embedded data that occur through unsolicited conversation during structured interviews frequently used in quantitative studies. This paper reports the findings from an exploratory qualitative study using such data from carers of people in later stage dementia during their participation in a structured interview. The study drew upon ethnographic principles in relation to data collection approaches (the unobtrusive collection of data on usual life) to appreciate "the ways that people understand and account for their day-to-day situation". A larger observational quantitative study of the effects of different approaches to home care services for people with dementia and their carers provided the context for the embedded qualitative study.

This article has two aims: to demonstrate the value of the novel method of qualitative data collection and to illustrate how this can be employed to gain and analyse data from carers involved in structured interviews of people with dementia. More specifically, by gathering qualitative data during a single structured interview, that is, one which uses standardised quantitative measures, we aimed to explore whether comments embedded within them could facilitate a 'sociological lens' that could allow us to access the views of carers as expressed while they were engaged in completing standardised measures. In addition we consider whether the burden for families participating in research could be minimised by streamlining the research process through 'doubling up' on the data collection, avoiding the need for the separate collection of qualitative and quantitative data.

We begin by presenting the background to the study, considering existing evidence about dementia that motivated the wider research. We then describe the rationale for the development and use of the embedded method. Next, in order to illustrate and examine the utility of using incidental conversational data collected via the embedded qualitative method, we present key findings from the data analysis. The discussion considers how this addressed the two aims of the embedded study and the impact of the research process on participants revealed by the findings.

---

### Fundamentals of qualitative analysis in family medicine [^1a21d418]. Family Medicine and Community Health (2019). Medium credibility.

Significance statement

Historically viewed as a soft alternative to what many scholars consider more scientifically legitimate quantitative approaches, qualitative research continues to gain ground in both stature and application across disciplines. Although there are parallels between quantitative and qualitative methodologies in design and implementation, qualitative research has its own unique characteristics, underlying assumptions and modus operandi that distinguish it from other forms of research. Considered the most elusive task in a qualitative research project, data analysis can be challenging to both novice and experienced researchers. Drawing from approaches outlined in popular texts and employing an exemplar from the Minority Health Disparities Study, an accessible 10-step approach to qualitative data analysis to guide qualitative researchers in the field of family medicine is advanced.

---

### Guidelines for assessment of and intervention with persons with disabilities [^9296428f]. The American Psychologist (2012). Medium credibility.

Guidelines for assessment and intervention with persons with disabilities — qualitative research informs assessment and intervention design. It has been "described [as] a means to explore the subjective experience of disabled individuals, something for which quantitative methods are not designed". "These data are useful in learning more directly about experiential aspects of disability to design appropriate interventions and policies", and "a primary way for psychologists to gain an understanding about the experience of relevant disability subgroups is to read this type of research".

---

### Qualitative data collection and analysis methods: the INSTINCT trial [^7a5bfbfb]. Academic Emergency Medicine (2007). Low credibility.

Patient care practices often lag behind current scientific evidence and professional guidelines. The failure of such knowledge translation (KT) efforts may reflect inadequate assessment and management of specific barriers confronting both physicians and patients at the point of treatment level. Effective KT in this setting may benefit from the use of qualitative methods to identify and overcome these barriers. Qualitative methodology allows in-depth exploration of the barriers involved in adopting practice change and has been infrequently used in emergency medicine research. The authors describe the methodology for qualitative analysis within the INcreasing Stroke Treatment through INteractive behavioral Change Tactics (INSTINCT) trial. This includes processes for valid data collection and reliable analysis of the textual data from focus group and interview transcripts. INSTINCT is a 24-hospital, randomized, controlled study that is designed to evaluate a system-based barrier assessment and interactive educational intervention to increase appropriate tissue plasminogen activator (tPA) use in ischemic stroke. Intervention hospitals undergo baseline barrier assessment using both qualitative as well as quantitative (survey) techniques. Investigators obtain data on local barriers to tPA use, as well as information on local attitudes, knowledge, and beliefs regarding acute stroke treatment. Targeted groups at each site include emergency physicians, emergency nurses, neurologists, radiologists, and hospital administrators. Transcript analysis using NVivo7 with a predefined barrier taxonomy is described. This will provide both qualitative insight on thrombolytic use and importance of specific barrier types for each site. The qualitative findings subsequently direct the form of professional education efforts and system interventions at treatment sites.

---

### Mixed methods and survey research in family medicine and community health [^719debdf]. Family Medicine and Community Health (2019). Medium credibility.

Integration and basic characteristics

Further, mixing or 'integration' of the two forms of data has become a central feature of mixed methods research. Integration has developed as the buzzword for the innovative feature of mixed methods research, and it provides insight beyond what is learnt from the quantitative and qualitative databases separately. For example, the ability to compare the results of both databases provides a more complete understanding than either database alone. This procedure is called a 'convergent mixed methods design'. It provides the opportunity to check one database against the other (how do people respond when they rate questions on a questionnaire vs when they are asked in person in an interview?). Insight can emerge from collecting survey data initially and then following up with interviews to help explain the survey results in more detail. This type of design is call an 'explanatory sequential design'. Insight can also emerge from exploring first with interviews to understand the culture and specific perspectives of individuals, and then designing questionnaires or experimental interventions that respond to these cultural features (called an 'exploratory sequential design'). A new feature to emerge in mixed methods is to think beyond these insights that come through integrating these 'core designs' into more complex procedures, such as experimental trials, social network analyses, evaluation procedures or into community-based health practices. These designs are called 'complex mixed methods designs'. In short, what has evolved in recent years is an understanding of the key characteristics of a well-designed mixed methods study as shown in box 1.

---

### Mixed methods and survey research in family medicine and community health [^06b146b7]. Family Medicine and Community Health (2019). Medium credibility.

Many family medicine and community health researchers use surveys as an original research methodology. Our purpose is to illustrate how survey research provides an important form of quantitative research that can be effectively combined with qualitative data to form a mixed methods study. We first provide an overview of the key principles in survey research and in mixed methods research. We review the various ways that survey can be used in mixed methods studies, citing options such as beginning a study with a survey, using a survey as the second form of data collection, or combining a survey and a form of qualitative data in a single data collection procedure. Finally, we illustrate in a specific example six steps in conducting a mixed methods study using survey research. In a mixed methods study using a survey, primary care researchers should consider six steps. Step 1. Articulate the rationale for mixed methods study. Step 2. Detail quantitative and qualitative databases. Step 3. Identify a mixed methods design. Step 4. Analyse and report the results of the quantitative and qualitative databases. Step 5. Present and show integration. Step 6. Explicate the value of using mixed methods. The ability to combine and integrate survey research into a mixed methods study provides a more rigorous approach to research than conducting only a survey or conducting just a qualitative interview. While requiring skills beyond traditional survey approaches, surveys in primary care offers an opportunity for a high level of sophistication in research methodology.

---

### Mixed methods and survey research in family medicine and community health [^511b3bbb]. Family Medicine and Community Health (2019). Medium credibility.

Designs and philosophies

Over time, probably during the mid-1990s, the idea began to form that mixed methods was collecting and analysing both quantitative and qualitative data, and also that additional insight might be gained from combining or integrating the two databases and linking them in a creative way. Thus, qualitative research explores phenomenon while quantitative explains the results of tests of hypotheses or research questions. Combined, mixed methods provides the insight of both exploration and explanation. By 2003, in the Handbook of Mixed Methods in Social and Behavioral Research, authors advanced specific designs or procedures for conducting mixed methods research. This was not an unusual development in research methodology in that specific designs were well known in types of quantitative research, such as experimental research, and in forms of qualitative research such as grounded theory. At the same time, individuals were developing an increased understanding of the philosophical underpinnings of mixed methods research that have unfolded in approaches such as pragmatism, critical realism, dialectic pluralism and yin/yang Eastern philosophy. These philosophical assumptions advanced the key idea that researchers bring to their mixed methods study core assumptions or beliefs that shape the types of procedures used in their studies. These twin developments — the designs or procedures and the philosophies — have led us to today a complete methodology called 'mixed methods research'. Thus, to characterise mixed methods is to consider how it spans the process of research that includes a philosophy, an orientation to research problems and questions, specific approaches to collecting and analysing quantitative and qualitative data, and implications from the research that provides additional insight beyond what might be gained from simply collecting and analysing quantitative data or qualitative data.

---

### Mixed-methods research in nephrology [^e02f0d75]. Kidney International (2022). Medium credibility.

Mixed-methods research involves the mixing of at least 1 qualitative and 1 quantitative method in the same research project or set of related projects. Combined use of qualitative and quantitative research methods in nephrology has increased over the last 10 years. In this review, we aim to advance the understanding of mixed-methods research within the kidney community. Qualitative and quantitative techniques provide different but noncompeting representations of what exists in the world; findings from qualitative research do not generalize to a large population, whereas those from quantitative research may not apply to individuals within the diverse and heterogeneous larger population. Mixed-methods research combines these complementary representations, allowing the strengths of each method to be combined and the strengths of 1 method to address the limitations of the other. Mixed-methods approaches can be used to: (i) gain a more complete understanding of a research problem, (ii) explain initial results from one method with results from another, (iii) generate instruments, for example, survey tools and interventions, (iv) evaluate services, and (v) optimize clinical trial design and delivery. There are 3 core mixed-methods designs: explanatory sequential, exploratory sequential, and convergent parallel, which can be combined. We discuss each design in turn before discussing analysis and integration of findings from the different methods. We provide case studies that illustrate the application of these study designs to kidney research questions. We briefly discuss mixed-methods systematic reviews and evidence synthesis before finally highlighting guidance on how to appraise published mixed-methods research.

---

### Synthesising quantitative and qualitative evidence to inform guidelines on complex interventions: clarifying the purposes, designs and outlining some methods [^b0cc517f]. BMJ Global Health (2019). High credibility.

Guideline developers are increasingly dealing with more difficult decisions concerning whether to recommend complex interventions in complex and highly variable health systems. There is greater recognition that both quantitative and qualitative evidence can be combined in a mixed-method synthesis and that this can be helpful in understanding how complexity impacts on interventions in specific contexts. This paper aims to clarify the different purposes, review designs, questions, synthesis methods and opportunities to combine quantitative and qualitative evidence to explore the complexity of complex interventions and health systems. Three case studies of guidelines developed by WHO, which incorporated quantitative and qualitative evidence, are used to illustrate possible uses of mixed-method reviews and evidence. Additional examples of methods that can be used or may have potential for use in a guideline process are outlined. Consideration is given to the opportunities for potential integration of quantitative and qualitative evidence at different stages of the review and guideline process. Encouragement is given to guideline commissioners and developers and review authors to consider including quantitative and qualitative evidence. Recommendations are made concerning the future development of methods to better address questions in systematic reviews and guidelines that adopt a complexity perspective.

---

### A guide to reading and using systematic reviews of qualitative research [^eda13585]. Nephrology, Dialysis, Transplantation (2016). Low credibility.

There is an increasingly widespread policy momentum to increase patient-centred care and to improve quality of life outcomes within health services. Qualitative research methods are used to elicit in-depth and detailed insights into people's attitudes, beliefs, emotions and experiences-much of which may remain unspoken during clinical encounters. Questions about patients' beliefs and preferences for treatment can be addressed by qualitative research and inform evidence-based strategies for delivering patient-centred care. Systematic reviews of multiple primary qualitative studies bring together findings from different studies to offer new and more comprehensive understandings of social phenomena across various healthcare contexts and populations and are an emerging methodology in the literature including for care in chronic kidney disease. This article will provide a framework for the systematic review of qualitative research so readers can make sense of these study types and use them in clinical care and policy.

---

### Using mixed methods for genetic counseling research [^85e43f07]. Journal of Genetic Counseling (2025). Medium credibility.

Typologies to describe mixed methods research vary according to purpose, but they all seek to describe and justify, at a minimum, the:
purpose for mixing methods,
timing of qualitative and quantitative data collection and analysis,
relative importance or priority of the types of data, and
level of interaction between the qualitative and quantitative data.

Creswell and Plano Clark outline and describe the purpose, timing, priority, and level of interaction of the most common uses of three core mixed methods designs. The three core study designs for mixed methods research are convergent, explanatory sequential, and exploratory sequential. In convergent designs, the qualitative and quantitative strands of data are collected simultaneously or within the same time period, given equivalent priority, and then integrated during data analysis. In explanatory sequential designs, the quantitative data are collected and analyzed first, followed by the qualitative data collection and analysis with the goal of expanding on or explaining the findings from the qualitative data. For exploratory sequential designs, the qualitative data collection and analysis occur first, typically to inform the quantitative data collection and analytic approach. When designing a mixed methods study, it is also important to outline where and when integration is going to take place. It can occur through data collection, analytical methods (described below), and interpretation and reporting; however, mixed methods approaches that only engage in integration at the data collection stage (i.e. using one dataset to recruit participants for a subsequent research study) rarely reflect high‐quality mixed methodology (Creswell & Plano Clark; Fetters et al; Zhang & Creswell). More details about these study design types are provided in Table 2. It is also worth noting that there are deviations from these core designs, described as "complex" study designs by Creswell and Plano Clark. Complex study designs may involve multistep data collection, a combination of fixed and emergent study designs, or differences in whether the quantitative or qualitative strand is given higher priority within a core study design. For example, a researcher could plan to conduct a fixed exploratory sequential study design, where interviews are conducted to help inform items to include on a survey of patient experiences with a new genetic counseling service. Upon completion of the survey, however, the researcher identifies responses that warrant further qualitative investigation to better understand the survey. This example combines fixed and emergent designs and exploratory and explanatory sequential designs in the service of generating evidence for a cohesive research question.

---

### Evaluating an integrated primary care approach to improve well-being among frail community-living older people: a theory-guided study protocol [^830f09b3]. BMC Geriatrics (2018). Low credibility.

Qualitative analyses

All interviews are audio-taped with permission of the patient or professional. After the transcription of the audio-taped interviews, latent content analysis is used in which the focus is primarily on analyzing the underlying meaning of the content. The Dutch texts derived from the interviews will be translated into English. All texts will be read several times by researchers with expertise in qualitative research to ensure a holistic understanding. We will extract, code, and categorize meaning units. Underlying meanings of categories will be expressed in themes.

Integration of qualitative and quantitative data

An embedded mixed methods design is used where qualitative data is added to the quasi-experimental design. During the study both quantitative and qualitative data will be collected and analyzed. For example, qualitative data will be collected during the study to explore how participants experience the FFF approach. By using this embedded design the qualitative data augment the (cost)effectiveness study, which is a popular approach within implementation and dissemination research similar to the FFF approach. We will also use an explanatory design in which qualitative data helps to understand quantitative results. We will for example collect and analyze quantitative data with regard to the quality of (integrated) care as perceived by healthcare professionals. Subsequently, these results will be followed up with in-depth qualitative data to explain and expand the quantitative results (e.g. unexpected results, significant differences between the groups in perceived quality of care).

---

### Interview-based qualitative research in emergency care part II: data collection, analysis and results reporting [^5a0d45c8]. Academic Emergency Medicine (2015). Low credibility.

Qualitative methods are increasingly being used in emergency care research. Rigorous qualitative methods can play a critical role in advancing the emergency care research agenda by allowing investigators to generate hypotheses, gain an in-depth understanding of health problems or specific populations, create expert consensus, and develop new intervention and dissemination strategies. In Part I of this two-article series, we provided an introduction to general principles of applied qualitative health research and examples of its common use in emergency care research, describing study designs and data collection methods most relevant to our field (observation, individual interviews, and focus groups). Here in Part II of this series, we outline the specific steps necessary to conduct a valid and reliable qualitative research project, with a focus on interview-based studies. These elements include building the research team, preparing data collection guides, defining and obtaining an adequate sample, collecting and organizing qualitative data, and coding and analyzing the data. We also discuss potential ethical considerations unique to qualitative research as it relates to emergency care research.

---

### Synthesising quantitative and qualitative evidence to inform guidelines on complex interventions: clarifying the purposes, designs and outlining some methods [^ac0b963a]. BMJ Global Health (2019). High credibility.

Methods for conducting mixed-method reviews in the context of guidelines for complex interventions

In this section, we draw on examples where specific review designs and methods have been or can be used to explore selected aspects of complexity in guidelines or systematic reviews. We also identify other review methods that could potentially be used to explore aspects of complexity. Of particular note, we could not find any specific examples of systematic methods to synthesise highly diverse research designs as advocated by Petticrew et al and summarised in tables 2 and 3. For example, we could not find examples of methods to synthesise qualitative studies, case studies, quantitative longitudinal data, possibly historical data, effectiveness studies providing evidence of differential effects across different contexts, and system modelling studies (eg, agent-based modelling) to explore system adaptivity.

There are different ways that quantitative and qualitative evidence can be integrated into a review and then into a guideline development process. In practice, some methods enable integration of different types of evidence in a single synthesis, while in other methods, the single systematic review may include a series of stand-alone reviews or syntheses that are then combined in a cross-study synthesis. Table 1 provides an overview of the characteristics of different review designs and methods and guidance on their applicability for a guideline process. Designs and methods that have already been used in WHO guideline development are described in part A of the table. Part B outlines a design and method that can be used in a guideline process, and part C covers those that have the potential to integrate quantitative, qualitative and mixed-method evidence in a single review design (such as meta-narrative reviews and Bayesian syntheses), but their application in a guideline context has yet to be demonstrated.

---

### Research techniques made simple: an introduction to qualitative research [^01fd4948]. The Journal of Investigative Dermatology (2021). Medium credibility.

Qualitative research has gained increasing prominence in health-related research and is experiencing greater use in dermatology. A major strength of and reason to perform qualitative research is that it allows one to gain an understanding of the insider (e.g., patient, medical provider, other players in the healthcare system) perspectives on health and insights about their behaviors, motivations, and expectations. This is particularly important in the field of dermatology where most diseases are, fortunately, not directly fatal but have major effects on affected individuals' lives in ways that are often not readily quantifiable. As such, it is important for dermatologists, both researchers and clinicians, to understand the basic tenets of qualitative methodology to properly utilize qualitative methods, evaluate the qualitative literature, and identify relevant findings to apply to clinical practice. In this article, we provide an overview of qualitative research and some of the more commonly used qualitative methods with an aim to increase awareness and appreciation of the power of qualitative studies.

---

### How to perform a systematic review and meta-analysis of diagnostic imaging studies [^dd039253]. Academic Radiology (2018). Low credibility.

A systematic review is a comprehensive search, critical evaluation, and synthesis of all the relevant studies on a specific (clinical) topic that can be applied to the evaluation of diagnostic and screening imaging studies. It can be a qualitative or a quantitative (meta-analysis) review of available literature. A meta-analysis uses statistical methods to combine and summarize the results of several studies. In this review, a 12-step approach to performing a systematic review (and meta-analysis) is outlined under the four domains: (1) Problem Formulation and Data Acquisition, (2) Quality Appraisal of Eligible Studies, (3) Statistical Analysis of Quantitative Data, and (4) Clinical Interpretation of the Evidence. This review is specifically geared toward the performance of a systematic review and meta-analysis of diagnostic test accuracy (imaging) studies.

---

### Applying the dissemination and implementation sciences to allergy and immunology: a Work group report from the AAAAI quality, adherence, and outcomes committee [^55dfaf03]. The Journal of Allergy and Clinical Immunology (2024). High credibility.

Approaches to study design in dissemination and implementation (D&I) research are 'broadly categorized as observational, experimental, quasi-experimental, hybrid, and pragmatic trial designs'. In observational designs, studies 'focus on collecting data, often utilizing both qualitative and quantitative approaches, to identify the barriers and facilitators influencing an implementation strategy's efficacy and use'. In experimental designs, 'either an intervention or implementation strategy is tested in a randomized, controlled approach', with the stepped wedge design described as 'dividing intervention sites into equal numbers (or wedges) and then randomly allocating each wedge to a time period for the same intervention delivery'. When randomization is infeasible, 'investigators can use quasi-experimental designs that use statistical methods to minimize bias'.

---

### Assessment, measurement and data collection tools [^3d840148]. Clinical Rehabilitation (2004). Low credibility.

The terms 'measurement' and 'assessment' are often used interchangeably, especially when referring to the tools used to collect information. This leads to unclear thinking, and often to poor selection of a 'measure' or 'assessment'. This editorial suggests that we should distinguish between the identification of the data needed for some purpose, the methods used to collect data, and the use made of (interpretation of) the data collected. This would focus more attention on the three most important questions to consider when collecting data, whether in day-to-day clinical practice or in research: Why should the data be collected? How should the data be collected? and How should the results be interpreted?

---

### Systematic debriefing after qualitative encounters: an essential analysis step in applied qualitative research [^24910c71]. BMJ Global Health (2018). Medium credibility.

Conclusion

Systematic debriefings are a necessary complement to more conventional qualitative approaches. Debriefings make it possible to enhance the adaptable, thoughtful and empathetic-yet-questioning nature of qualitative research among data collection teams (thereby improving both the quality of data collected and the capacity of those collecting the data), to correct course in the event of unknowable changes, insights or challenges in a given context, and to quickly share emerging data with stakeholders in programmatic, policy and academic spheres. We have outlined herein a series of steps to conduct debriefings and demonstrated how we have used debriefings in studies across two contexts. We hope this article sparks interest and debate in the literature in terms of how debriefings could be used to improve the quality of qualitative data.

---

### Synthesising quantitative and qualitative evidence to inform guidelines on complex interventions: clarifying the purposes, designs and outlining some methods [^21858c65]. BMJ Global Health (2019). High credibility.

Discussion

Mixed-method review and synthesis methods are generally the least developed of all systematic review methods. It is acknowledged that methods for combining quantitative and qualitative evidence are generally poorly articulated. There are however some fairly well-established methods for using qualitative evidence to explore aspects of complexity (such as contextual, implementation and outcome complexity), which can be combined with evidence of effect (see sections A and B of table 1). There are good examples of systematic reviews that use these methods to combine quantitative and qualitative evidence, and examples of guideline recommendations that were informed by evidence from both quantitative and qualitative reviews (eg, case studies 1–3). With the exception of case study 3 (risk communication), the quantitative and qualitative reviews for these specific guidelines have been conducted separately, and the findings subsequently brought together in an EtD framework to inform recommendations.

Other mixed-method review designs have potential to contribute to understanding of complex interventions and to explore aspects of wider health systems complexity but have not been sufficiently developed and tested for this specific purpose, or used in a guideline process (section C of table 1). Some methods such as meta-narrative reviews also explore different questions to those usually asked in a guideline process. Methods for processing (eg, quality appraisal) and synthesising the highly diverse evidence suggested in tables 2 and 3 that are required to explore specific aspects of health systems complexity (such as system adaptivity) and to populate some sections of the INTEGRATE EtD framework remain underdeveloped or in need of development.

In addition to the required methodological development mentioned above, there is no GRADE approachfor assessing confidence in findings developed from combined quantitative and qualitative evidence. Another paper in this series outlines how to deal with complexity and grading different types of quantitative evidence, and the GRADE CERQual approach for qualitative findings is described elsewhere, but both these approaches are applied to method-specific and not mixed-method findings. An unofficial adaptation of GRADE was used in the risk communication guideline that reported mixed-method findings. Nor is there a reporting guideline for mixed-method reviews, and for now reports will need to conform to the relevant reporting requirements of the respective method-specific guideline. There is a need to further adapt and test DECIDE, WHO-INTEGRATEand other types of evidence to decision frameworks to accommodate evidence from mixed-method syntheses which do not set out to determine the statistical effects of interventions and in circumstances where there are no trials.

---

### Using mixed methods for genetic counseling research [^25650e2c]. Journal of Genetic Counseling (2025). Medium credibility.

2 DEFINITION OF MIXED METHODS RESEARCH

Mixed methods research has emerged as a unique approach with its own methodological considerations and techniques that incorporate both qualitative and quantitative elements, but is not simply the combination of these two methodological approaches.

Creswell and Plano Clark define the core characteristics of mixed methods research as (Creswell & Plano Clark,):
collecting and analyzing qualitative and quantitative data,
integrating the data and results,
conducting research according to rigorous study designs that describe the procedures and rationale for the study, and
grounding the research in applicable theories and philosophies.

Mixed methods research allows researchers to use different types of tools to answer questions that are not adequately answered through the use of either qualitative or quantitative approaches alone (Creswell & Tashakkori). It encourages researchers to use multiple paradigms and can be the bridge between the constructed dichotomy of qualitative and quantitative approaches (Creswell & Plano Clark).

Common applications of mixed methods research include:
explaining or exploring initial results from the use of a single methodological study,
psychometric instrument creation or validation,
multi‐part studies that involve the development, implementation, and evaluation of a program or intervention, and
studies that have multiple end users who value different types of evidence (Creswell & Plano Clark).

The use of mixed methods can either be planned from the outset of a study (fixed study design) or can develop over the research process to further explore incomplete results or investigate new insights (emergent study design) (Creswell & Plano Clark). The qualitative and quantitative approaches are often referred to as "strands" and they can have differing relative priorities depending on the study goals (Creswell & Plano Clark). Many of the examples of mixed methods genetic counseling research studies prioritize the quantitative strand; however, there are examples of qualitatively oriented mixed methods research and studies where the strands are given equal priority to answer a given research question (Creswell; Poth & Shannon‐Baker).

---

### "The patient is speaking": discovering the patient voice in ophthalmology [^0a5e4ae7]. The British Journal of Ophthalmology (2017). Low credibility.

Qualitative research methodologies have been developed over the last 50–60 years and are increasingly being used alongside quantitative health research to give complementary insights and understanding. Some qualitative methodologies were originally conceptualised and developed in sociology, philosophy and anthropology and then applied to health research, while others have been adapted to fit the specific requirements of pragmatic applied health research. Data collection and analysis will be influenced by the specific approach and research question.

Qualitative data collection techniques include in-depth interviewing, observations, focus group discussions and also visual forms of data collection, such as photo elicitation. In-depth interviews are common in health research and require in-depth participant-focused discussion between a researcher and a study participant. Qualitative observations may be undertaken by a researcher in natural settings, for example, as a non-participant observer of clinical practice, such as that taking place in an operating theatre, on a ward or during a patient consultation. As a consequence, qualitative data can be spoken, textual (transcripts and field notes from observations) or even visual (eg, photo elicitation or drawings). Analytical methods, which are specific to the research question, approach and data, produce findings that are represented by textual accounts and description, rather than quantitative measures reached by statistical means.

---

### Iterative categorisation (IC) (part 2): interpreting qualitative data [^166388c3]. Addiction (2021). Medium credibility.

Iterative categorisation (IC) is a systematic and transparent technique for analysing qualitative textual data, first presented in Addiction in 2016. IC breaks the analytical process down into stages, separating basic 'description' from more advanced 'interpretation'. This paper focuses on the interpretive analytical stage that is shown to comprise three core processes: (i) conceptualising (undertaken inductively, deductively or abductively); (ii) differentiating; and (iii) externalising. Each process is described, followed by published examples to support what has been explained. As qualitative analyses tend to be recursive rather than linear, the three processes often need to be repeated to account for all the data. Following the stages of IC will ensure that qualitative research generates improved understanding of the phenomena being studied, study findings contribute to and enhance the existing literature, the audience for any qualitative output is broad and international, and any practical implications or study recommendations are relevant to other contexts and settings.

---

### Healthcare workers' informal uses of mobile phones and other mobile devices to support their work: a qualitative evidence synthesis [^93a83bfa]. The Cochrane Database of Systematic Reviews (2024). Medium credibility.

Types of studies

Qualitative studies

We included primary studies that used qualitative study designs and epistemologies such as ethnography, phenomenology, case studies, grounded theory studies, and qualitative process evaluations. We included studies that used both qualitative methods for data collection (e.g. focus group discussions, individual interviews, observation, diaries, document analysis, open‐ended survey questions) and qualitative methods for data analysis (e.g. thematic analysis, framework analysis, grounded theory). We excluded studies that collected data using qualitative methods but did not analyse these data using qualitative analysis methods (e.g. open‐ended survey questions where the response data were analysed using descriptive statistics only).
We included mixed‐methods studies where it was possible to extract data that were collected and analysed using qualitative methods.
We included both published and unpublished studies; we included studies published in any language.
We did not exclude studies based on our assessment of methodological limitations. We used information about methodological limitations to assess our confidence in the review findings.

Topic of interest

---

### Qualitative research methods in renal medicine: an introduction [^8bc2217c]. Nephrology, Dialysis, Transplantation (2015). Low credibility.

Qualitative methodologies are becoming increasingly widely used in health research. However, within some specialties, including renal medicine, qualitative approaches remain under-represented in the high-impact factor journals. Qualitative research can be undertaken: (i) as a stand-alone research method, addressing specific research questions; (ii) as part of a mixed methods approach alongside quantitative approaches or (iii) embedded in clinical trials, or during the development of complex interventions. The aim of this paper is to introduce qualitative research, including the rationale for choosing qualitative approaches, and guidance for ensuring quality when undertaking and reporting qualitative research. In addition, we introduce types of qualitative data (observation, interviews and focus groups) as well as some of the most commonly encountered methodological approaches (case studies, ethnography, phenomenology, grounded theory, thematic analysis, framework analysis and content analysis).

---

### Synthesis of guidance available for assessing methodological quality and grading of evidence from qualitative research to inform clinical recommendations: a systematic literature review [^e2685e61]. RMD Open (2024). Medium credibility.

It is worth noting that despite some similarities in the criteria for each of the tools, it is still difficult to compare the validity. Thus, it is important that any tool that is recommended for evaluating qualitative evidence is clear, practical and easy to use. This task force, with members representing various key stakeholders including patients, clinicians and methodologists, aimed at providing simple guidance on how to use qualitative research for the purpose of standardising the approach to the development of EULAR recommendations, when formulated questions can primarily be answered by qualitative research. It was beyond the scope of this project to develop a new guideline.

With regards to methods that can be applied to summarise the quality of qualitative research for clinical recommendations, our review found one qualitative evidence hierarchyand a research pyramid that included a section on qualitative research. Both approaches share some similarities in their criteria for assessing qualitative research studies. Daly et al indicate at the top of the hierarchy are 'generalisable studies', which include evidence from qualitative systematic reviews. Similarly, within Tomlin and Borgetto'sresearch pyramid, the qualitative meta synthesis is placed at the top of the pyramid. Thus, while both approaches may not be mutually exclusive, both seem to suggest that qualitative studies with the most 'evidence' should be considered as the top level, similar to meta-analysis of randomised controlled trials in the quantitative evidence hierarchy of evidence.

The lack of a hierarchy of evidence to grade qualitative research has not come by surprise, simply because such hierarchies do not seem to provide any additional value or guidance as to the quality of the evidence available. This is particularly so since qualitative research addresses aspects such as people's experiences and factors that may influence barriers and facilitators to implementation, or acceptability and feasibility aspects.

As part of our data analysis, we also considered which of the included tools and approaches were endorsed or recommended by research bodies and funding organisations. The NIHRrecommended the use of two of the checklists as their preferred method of assessment, JBIand CASPand indicated when completing a qualitative evidence synthesis, the GRADE-CERQual approach can be used. Similarly, Cochrane recommends the use of GRADE-CERQual approach in their handbook on qualitative evidence synthesis, and in a supporting document (not the actual handbook)mention the use of the original CASP checklistand the modified CASP checklistin evaluating the quality of qualitative studies. The WHO also provides guidance on incorporating qualitative research when developing clinical guidelines.

---

### Healthcare workers' perceptions and experiences of primary healthcare integration: a scoping review of qualitative evidence [^49581f75]. The Cochrane Database of Systematic Reviews (2023). Medium credibility.

Abstract

Background

Primary healthcare (PHC) integration has been promoted globally as a tool for health sector reform and universal health coverage (UHC), especially in low‐resource settings. However, for a range of reasons, implementation and impact remain variable. PHC integration, at its simplest, can be considered a way of delivering PHC services together that sometimes have been delivered as a series of separate or 'vertical' health programmes. Healthcare workers are known to shape the success of implementing reform interventions. Understanding healthcare worker perceptions and experiences of PHC integration can therefore provide insights into the role healthcare workers play in shaping implementation efforts and the impact of PHC integration. However, the heterogeneity of the evidence base complicates our understanding of their role in shaping the implementation, delivery, and impact of PHC integration, and the role of contextual factors influencing their responses.

Objectives

To map the qualitative literature on healthcare workers' perceptions and experiences of PHC integration to characterise the evidence base, with a view to better inform future syntheses on the topic.

Search methods

We used standard, extensive Cochrane search methods. The latest search date was 28 July 2020. We did not search for grey literature due to the many published records identified.

Selection criteria

We included studies with qualitative and mixed methods designs that reported on healthcare worker perceptions and experiences of PHC integration from any country. We excluded settings other than PHC and community‐based health care, participants other than healthcare workers, and interventions broader than healthcare services. We used translation support from colleagues and Google Translate software to screen non‐English records. Where translation was not feasible we categorised these records as studies awaiting classification.

Data collection and analysis

For data extraction, we used a customised data extraction form containing items developed using inductive and deductive approaches. We performed independent extraction in duplicate for a sample on 10% of studies allowed for sufficient agreement to be reached between review authors. We analysed extracted data quantitatively by counting the number of studies per indicator and converting these into proportions with additional qualitative descriptive information. Indicators included descriptions of study methods, country setting, intervention type, scope and strategies, implementing healthcare workers, and client target population.

Main results

The review included 184 studies for analysis based on 191 included papers. Most studies were published in the last 12 years, with a sharp increase in the last five years. Studies mostly employed methods with cross‐sectional qualitative design (mainly interviews and focus group discussions), and few used longitudinal or ethnographic (or both) designs. Studies covered 37 countries, with close to an even split in the proportions of high‐income countries (HICs) and low‐ and middle‐income countries (LMICs). There were gaps in the geographical spread for both HICs and LMICs and some countries were more dominant, such as the USA for HICs, South Africa for middle‐income countries, and Uganda for low‐income countries. Methods were mainly cross‐sectional observational studies with few longitudinal studies. A minority of studies used an analytical conceptual model to guide the design, implementation, and evaluation of the integration study.

The main finding was the various levels of diversity found in the evidence base on PHC integration studies that examined healthcare workers' perceptions and experiences. The review identified six different configurations of health service streams that were being integrated and these were categorised as: mental and behavioural health; HIV, tuberculosis (TB) and sexual reproductive health; maternal, women, and child health; non‐communicable diseases; and two broader categories, namely general PHC services, and allied and specialised services. Within the health streams, the review mapped the scope of the interventions as full or partial integration. The review mapped the use of three different integration strategies and categorised these as horizontal integration, service expansion, and service linkage strategies. The wide range of healthcare workers who participated in the implementation of integration interventions was mapped and these included policymakers, senior managers, middle and frontline managers, clinicians, allied healthcare professionals, lay healthcare workers, and health system support staff. We mapped the range of client target populations.

Authors' conclusions

This scoping review provides a systematic, descriptive overview of the heterogeneity in qualitative literature on healthcare workers' perceptions and experience of PHC integration, pointing to diversity with regard to country settings; study types; client populations; healthcare worker populations; and intervention focus, scope, and strategies. It would be important for researchers and decision‐makers to understand how the diversity in PHC integration intervention design, implementation, and context may influence how healthcare workers shape PHC integration impact. The classification of studies on the various dimensions (e.g. integration focus, scope, strategy, and type of healthcare workers and client populations) can help researchers to navigate the way the literature varies and for specifying potential questions for future qualitative evidence syntheses.

---

### The American Society of Addiction Medicine clinical practice guideline development methodology [^d347f3a7]. Journal of Addiction Medicine (2024). High credibility.

Systematic review — background and processes describes that a quality clinical practice guideline should be based on a systematic review of the literature, which helps ensure that all relevant evidence is identified, critiqued, and synthesized using methods that help reduce the likelihood of bias, and is typically conducted prior to initiating work on the CPG by a group separate from the CPG Writing Group. Systematic reviews use well-established methods to search, identify, appraise, and synthesize the literature examining prespecified key questions of interest; they can contain a qualitative synthesis of evidence, a quantitative synthesis of evidence, or a combination of both; a meta-analysis is the quantitative synthesis of evidence and is based on a systematic review, although not all systematic reviews include a meta-analysis; narrative reviews broadly summarize a topic but do not adhere to strict inclusion and exclusion criteria and search parameters nor use explicit criteria to evaluate quality. Broadly speaking, processes include define the question(s) of interest and methods, conduct literature search, identify studies and other sources of information for inclusion, data abstraction, critical appraisal, and synthesis of evidence.

---

### Practice guideline for the treatment of patients with obsessive-compulsive disorder [^f11eed9a]. The American Journal of Psychiatry (2007). Medium credibility.

Obsessive-compulsive disorder practice guideline — reference evidence coding system states that the "following coding system is used to indicate the nature of the supporting evidence in the references:" [A] "Double-blind, randomized clinical trial. A study of an intervention in which subjects are prospectively followed over time; there are treatment and control groups; subjects are randomly assigned to the two groups; both the subjects and the investigators are blind to the assignments". [A–] "Randomized clinical trial. Same as above but not double-blind". [B] "Clinical trial. A prospective study in which an intervention is made and the results of that intervention are tracked longitudinally; study does not meet standards for a randomized clinical trial". [C] "Cohort or longitudinal study. A study in which subjects are prospectively followed over time without any specific intervention". [D] "Case–control study. A study in which a group of patients is identified in the present and information about them is pursued retrospectively or backward in time". [E] "Review with secondary data analysis. A structured analytic review of existing data, e.g., a meta-analysis or a decision analysis". [F] "Review. A qualitative review and discussion of previously published literature without a quantitative synthesis of the data". [G] "Other: Textbooks, expert opinion, case reports, and other reports not included above".

---

### Data collection-the office of research integrityori.hhs.gov › products › n_illinois_u › datamanagement › dctopic… [^034b3905]. ori.hhs.gov (1998). Low credibility.

Data collection is the process of gathering and measuring information on variables of interest, in an established systematic fashion that enables one to answer stated research questions, test hypotheses, and evaluate outcomes. The data collection component of research is common to all fields of study including physical and social sciences, humanities, business, etc. While methods vary by discipline, the emphasis on ensuring accurate and honest collection remains the same. The importance of ensuring accurate and appropriate data collection Regardless of the field of study or preference for defining data, accurate data collection is essential to maintaining the integrity of research. Both the selection of appropriate data collection instruments and clearly delineated instructions for their correct use reduce the likelihood of errors occurring.

Most, Craddick, Crawford, Redican, Rhodes, Rukenbrod, and Laws describe 'quality assurance' and 'quality control' as two approaches that can preserve data integrity and ensure the scientific validity of study results. Each approach is implemented at different points in the research timeline: Quality Assurance Since quality assurance precedes data collection, its main focus is 'prevention'. Prevention is the most cost-effective activity to ensure the integrity of data collection. This proactive measure is best demonstrated by the standardization of protocol developed in a comprehensive and detailed procedures manual for data collection. Poorly written manuals increase the risk of failing to identify problems and errors early in the research endeavor. These failures may be demonstrated in a number of ways:

Given the range of qualitative research strategies it is difficult to make generalized statements about how one should establish a research protocol in order to facilitate quality assurance. Certainly, researchers conducting non-participant/participant observation may have only the broadest research questions to guide the initial research efforts. Since the researcher is the main measurement device in a study, many times there are little or no other data collecting instruments. Indeed, instruments may need to be developed on the spot to accommodate unanticipated findings.

---

### Understanding the experience of stroke: a mixed-method research agenda [^6dc42394]. The Gerontologist (2009). Low credibility.

The use of both quantitative and qualitative strategies to examine a single research question has been a subject of considerable controversy and still remains a largely uncommon practice in the sociology of health and illness. Yet, when seeking to understand the meaning of a chronic disabling condition in later life from a social psychological perspective, a mixed-method approach is likely to provide the most comprehensive picture. This article provides an overview of the usefulness and appropriateness of a mixed-method approach to understanding the stroke experience. I comment on the current state of research on the experience of stroke, including epistemological and ontological orientations. Using real data examples, I address paradigmatic assumptions, methods of integration, as well as challenges and pitfalls in integrating methods. I conclude by considering future directions in this field of research.

---

### Synthesis of guidance available for assessing methodological quality and grading of evidence from qualitative research to inform clinical recommendations: a systematic literature review [^cf1f76c7]. RMD Open (2024). Medium credibility.

Data extraction and risk of bias assessment

A standardised, prepiloted MS Excel data extraction was applied to extract data on the following: guidance/tool/checklist core characteristics (eg, authors, name of guidance document/checklist/tool, target audience, clinical context/rationale, evidence base); details on validation process and robustness (if available), and details on instructions provided on how to apply the tools to assess quality of evidence for qualitative research/grade levels of evidence of qualitative research.

For all included tools/checklists, we also reviewed whether research bodies or organisations endorsed or recommended if any of the included checklists/tools should be applied to assess the quality of qualitative research. The research bodies we considered included The Oxford Centre for Evidence Based Medicine; National Institute for Health Research (NIHR); Cochraneand Scottish Intercollegiate Guidelines Networkand WHO. The strengths and weaknesses of the guidance documents available to assess quality of qualitative evidence and grade levels of qualitative research were noted and summarised.

Data analysis

A narrative synthesis was conducted manually to identify key themes within and between the included studies. Key themes focused on main aspects of the published guidance available to assess (a) methodological quality of qualitative research and (b) each of the methods described to grade levels of qualitative evidence. Areas which were considered to lack clarity across the guidance and methods available were also noted.

---

### Systematic debriefing after qualitative encounters: an essential analysis step in applied qualitative research [^0c38a708]. BMJ Global Health (2018). Medium credibility.

What are debriefings?

Debriefings are a discrete moment in the qualitative data collection process where a research manager sits with a data collector (or data collection team) to discuss the tenor, flow and resulting findings from a recently undertaken data collection activity. Ideally conducted after the close of a day's data collection, debriefings are an essential supplement to qualitative methods such as focus groups, interviews or observations. ii During debriefings, the research lead takes copious notes. These notes then serve as one component of the full qualitative data set, and methods used to analyze transcripts and observational memos are also applied to debriefing notes.

Debriefings spark immediate reflection on emerging findings; they force data collectors to think through the data that have emerged and to better position findings relative to data collected by fellow data collectors either that same day or to date. Debriefings allow research teams to identify gaps in the data collected and to redirect course — whether refining a line of inquiry, reconceptualizing a research question, opting when or whether to seek out alternative perspectives (such as negative or disconfirming cases), or adding or eliminating a respondent group or research method. Debriefings are the best protection against an unfortunate scenario where, long after the close of data collection, transcripts reveal that the research team did not pursue essential lines of inquiry, or worse, that the data collected will not be able to respond to research aims. For examples of debriefing templates, see online supplementary appendices 1 and 2.

---

### Survey design: to ask or not to ask? That is the question [^a93395c9]. Clinical Infectious Diseases (2013). Low credibility.

Surveys are one of the most frequent modes of observation and measurement. Survey research can be exploratory, descriptive, and/or explanatory. Modes of survey administration vary and include face-to-face, telephone, mail, and Internet. There are numerous considerations that that must be taken into account when designing and conducting a survey. Deciding what information is needed and why is important when developing questions for a survey; it is essential to define the purpose of the survey and to be as specific as possible in terms of the data to be collected. Response rate varies by target audience and is influenced by a number of factors such as incentives, survey length, and perceived burden. From question development to survey construction, the goal is to minimize measurement error with systematic planning and execution.

---

### Statistics review 8: qualitative data-tests of association [^ec7ce6ba]. Critical Care (2004). Low credibility.

This review introduces methods for investigating relationships between two qualitative (categorical) variables. The χ² test of association is described, together with the modifications needed for small samples. The test for trend, in which at least one of the variables is ordinal, is also outlined. Risk measurement is discussed. The calculation of confidence intervals for proportions and differences between proportions are described. Situations in which samples are matched are considered.

---

### Systematic review: the effect on surrogates of making treatment decisions for others [^dd0e2912]. Annals of Internal Medicine (2011). Low credibility.

Background

Clinical practice relies on surrogates to make or help to make treatment decisions for incapacitated adults; however, the effect of this practice on surrogates has not been evaluated.

Purpose

To assess the effect on surrogates of making treatment decisions for adults who cannot make their own decisions.

Data Sources

Empirical studies published in English and listed in MEDLINE, EMBASE, CINAHL, BIOETHICSLINE, PsycINFO, or Scopus before 1 July 2010.

Study Selection

Eligible studies provided quantitative or qualitative empirical data, by evaluating surrogates, regarding the effect on surrogates of making treatment decisions for an incapacitated adult.

Data Extraction

Information on study location, number and type of surrogates, timing of data collection, type of decisions, patient setting, methods, main findings, and limitations.

Data Synthesis

40 studies, 29 using qualitative and 11 using quantitative methods, provided data on 2854 surrogates, more than one half of whom were family members of the patient. Most surrogates were surveyed several months to years after making treatment decisions, the majority of which were end-of-life decisions. The quantitative studies found that at least one third of surrogates experienced a negative emotional burden as the result of making treatment decisions. The qualitative studies reported that many or most surrogates experienced negative emotional burden. The negative effects on surrogates were often substantial and typically lasted months or, in some cases, years. The most common negative effects cited by surrogates were stress, guilt over the decisions they made, and doubt regarding whether they had made the right decisions. Nine of the 40 studies also reported beneficial effects on a few surrogates, the most common of which were supporting the patient and feeling a sense of satisfaction. Knowing which treatment is consistent with the patient's preferences was frequently cited as reducing the negative effect on surrogates.

Limitations

Thirty-two of the 40 articles reported data collected in the United States. Because the study populations were relatively homogenous, it is unclear whether the findings apply to other groups. In some cases, the effect of making treatment decisions could not be isolated from that of other stressors, such as grief or prognostic uncertainty. Nine of the studies had a response rate less than 50%, and 9 did not report a response rate. Many of the studies had a substantial interval between the treatment decisions and data collection.

Conclusion

Making treatment decisions has a negative emotional effect on at least one third of surrogates, which is often substantial and typically lasts months (or sometimes years). Future research should evaluate ways to reduce this burden, including methods to identify which treatment options are consistent with the patient's preferences.

Primary Funding Source

National Institutes of Health.

---

### Synthesis of guidance available for assessing methodological quality and grading of evidence from qualitative research to inform clinical recommendations: a systematic literature review [^4f9499a7]. RMD Open (2024). Medium credibility.

RQ1: guidance (tools, checklists, frameworks) applied to assess the methodological quality of qualitative research

The Society for Critical Care Medicine Family — Centred Care Guidelines Coombs and colleagues acknowledge that the use of qualitative research to inform professional guidelines within family centred care in intensive care units has been explored previously. These studies have focused on exploring 'which' qualitative studies have been used in professional guidelines, rather than exploring 'how and when' qualitative research has been used in the guideline development process. Thus, the focus of their paper was to explore the importance, challenges and opportunities of using qualitive research to enhance development of clinical practice guidelines, specifically using recent guidelines published for family-centred care in the intensive care units as an example. The family-centred care guidelines were developed based on their own experience of guidelines available in family centred care and a qualitative systematic review. The results of the systematic review were analysed via thematic analysis, and key themes produced, which then inform the Population, Intervention, Comparison, Outcome and key areas to include in the guidelines. Three experts in qualitative research and data analysis reviewed the tool prior to use and developed guidance for the guideline taskforce on how to apply the tool. The tool includes 15 items (1) population; (2) age group; (3) methodology; (4) sampling method; (5) data collection method; (6) transferability/scale of population; (7) research design and methodology consistent with aim; (8) ethics review or IRB approval declared; (9) member checking/participant feedback; (10) coding analysis method description; (11) depth of reporting; (12) sample size methodology reported; (13) consistency; (14) paraphrased results; (15) major themes (aspects of FCC addressed). All items included various response options (see online supplemental file for full details of response options). Each taskforce member reviewed between 8 and 10 papers. Once all reviews were complete, appraisal sheets were checked by the taskforce team leaders. Key findings from individual studies were subjected to constant comparison and thematic analysis. Common themes were identified and discussed among the guideline taskforce and validated by patients and families engaged in the study.
Nursing Management of the Second Stage of Labour Evidence-Based Clinical Practice Guidelines Cesario et al describe the process by which members of an Association of Women's Health, Obstetric and Neonatal Nurses evidence-based clinical practice guideline development team created a scoring system based on specific criteria, for the evaluation of qualitative studies. Methods included an initial literature review on methods evaluating qualitative studies to inform the development of the criteria for the scoring tool were based on evaluating criteria for qualitative research proposed by Burns and Grove. The scoring tool was designed to place qualitative studies included within their systematic review on specific levels of evidence (based on the overall quality rating). There are 30 criteria items phrased as questions, broken down into five main categories in the tool: (1) descriptive vividness (eg, is essential descriptive information included?); (2) methodological congruence (eg, are all elements or steps of the study presented accurately and clearly?); (3) analytical preciseness (eg, are the study conclusions based on the data gathered?); (4) theoretical connectedness (eg, are the theoretical concepts adequately defined and/or validated by data?) and (5) heuristic relevance (eg, are the findings relevant to nursing practice?). Each of the items within the five categories should be scored from 0 to 3, with a score of 0 = no evidence that the criteria have been met ≤ 25% of criteria met, 1 = poor, 25%–49% criteria met, 2 = fair, 50%–74% criteria met and 4 = good, 75%–100% criteria met. The final quality of evidence rating is based on the total quality score across the 30 items, with three quality levels: QI = total score of 22.5–30 indicates that 75%–100% of the criteria had been met; QII = total score of 15–22.4 indicates that 50% to 74% of the criteria had been met and QIII = total score of less than 15 indicates less than 50% of the criteria were met. Two teams served as first evaluators of the validity of the tool and a subsequent guideline development team has used the tool too.
Jonna Briggs Institute Critical Appraisal of Qualitative Studies The Joanna Briggs Institute (JBI) is an international organisation dedicated to the promotion and adoption of evidence-based practice, offering a selection of critical appraisal tools. The qualitative appraisal tool has been designed to quality appraise papers for consideration in a qualitative literature review. The tool includes 10 critical appraisal questions, with four response categories (yes, no, unclear, not applicable) and an overall appraisal decision if the paper rated should be included, excluded, seek further information and a space for comments (eg, including reasons for exclusion).
Critical Skills Appraisal Programme CASP The Critical Appraisal Skills Programme (CASP) qualitative tool is the most used tool for quality appraisal in health-related qualitative evidence syntheses, with endorsement from the Cochrane Qualitative and Implementation Methods Group. The CASP tool is broken down into three sections, with 10 items that focus on three broad issues authors propose need to be considered when evaluating a qualitative study. These include section (A) are the results of the study valid?; section (B) What are the results and section (C) Will the results help locally. Response options for each of the items include yes, no and can't tell, with a space for comments to provide reasons for your answers. Several italicised prompts are given after each question, which are designed to remind researchers why the question is important. The first two questions are screening questions ((1) Was there clear statement of the aims of the research and (2) Is the qualitative methodology appropriate?). Researchers are advised that if the answer to both questions is 'yes', it is worth proceeding with the remaining questions.
Modified CASP Checklist The modified CASP tool was developed by Long et al, to consider issues related to the suitability and usability of the CASP tool for quality appraisal in qualitative evidence synthesis. The authors reflect on their practical experience of using the original CASP tool in systematic reviews and qualitive evidence synthesis. The main modification proposed by authors includes an item that that focuses on the study's underlying theoretical, ontological and epistemological framework. This item also includes a number of hints to consider when answering the item (see online supplemental file). Another modification includes a fourth response option to the previous response options included in the original CASP tool, 'somewhat'. The authors describe the 'somewhat' option to mean 'to some extent' or 'partly' for use when we deemed that the primary study authors had reported a reasonable attempt at fulfilling a particular quality domain but had clear strengths and limitations. In terms of validation, the authors have applied the modified CASP tool to 10 papers included in a systematic review (see Long et al for details).
GRADE CerQUAL There were seven papers included in our review, which describe one approach on assessing confidence in synthesised findings within a qualitative systematic review. This approach is known as GRADE-CERQual. This approach was developed in line with the G rading of R ecommendations, A ssessment, D evelopment and E valuation (GRADE) for quantitative research. The GRADE-CERQual approach provides guidance for assessing how much confidence to place in findings from systematic reviews of qualitative research (or qualitative evidence syntheses). The approach has been developed to support the use of findings from qualitative evidence syntheses in decision-making, including guideline development and policy formulation. The CERQual approach aims to 'systematise the process of assessing confidence in the evidence from qualitative evidence syntheses and make these assessments explicit and transparent'". According to this approach, there are four components that need to be considered when summarising the overall quality of the body of evidence based on qualitative data: (1) methodological limitations, (2) coherence, (3) adequacy of data and (4) relevance. The assessments of the four components collectively contribute to an overall assessment of whether findings from a qualitative evidence synthesis provide a reasonable representation of the health or social care issues, intervention or programme (phenomenon) of interest.

---

### Factors that impact on recruitment to randomised trials in health care: a qualitative evidence synthesis [^84ef9d78]. The Cochrane Database of Systematic Reviews (2020). Medium credibility.

Background

Randomised trials (also referred to as 'randomised controlled trials' or 'trials') are the optimal way to minimise bias in evaluating the effects of competing treatments, therapies and innovations in health care. It is important to achieve the required sample size for a trial, otherwise trialists may not be able to draw conclusive results leading to research waste and raising ethical questions about trial participation. The reasons why potential participants may accept or decline participation are multifaceted. Yet, the evidence of effectiveness of interventions to improve recruitment to trials is not substantial and fails to recognise these individual decision-making processes. It is important to synthesise the experiences and perceptions of those invited to participate in randomised trials to better inform recruitment strategies.

Objectives

To explore potential trial participants' views and experiences of the recruitment process for participation. The specific objectives are to describe potential participants' perceptions and experiences of accepting or declining to participate in trials, to explore barriers and facilitators to trial participation, and to explore to what extent barriers and facilitators identified are addressed by strategies to improve recruitment evaluated in previous reviews of the effects of interventions including a Cochrane Methodology Review.

Search Methods

We searched the Cochrane Library, Medline, Embase, CINAHL, Epistemonikos, LILACS, PsycINFO, ORRCA, and grey literature sources. We ran the most recent set of searches for which the results were incorporated into the review in July 2017.

Selection Criteria

We included qualitative and mixed-methods studies (with an identifiable qualitative component) that explored potential trial participants' experiences and perceptions of being invited to participate in a trial. We excluded studies that focused only on recruiters' perspectives, and trials solely involving children under 18 years, or adults who were assessed as having impaired mental capacity.

Data Collection and Analysis

Five review authors independently assessed the titles, abstracts and full texts identified by the search. We used the CART (completeness, accuracy, relevance, timeliness) criteria to exclude studies that had limited focus on the phenomenon of interest. We used QSR NVivo to extract and manage the data. We assessed methodological limitations using the Critical Skills Appraisal Programme (CASP) tool. We used thematic synthesis to analyse and synthesise the evidence. This provided analytical themes and a conceptual model. We used the GRADE-CERQual (Confidence in the Evidence from Reviews of Qualitative research) approach to assess our confidence in each finding. Our findings were integrated with two previous intervention effectiveness reviews by juxtaposing the quantitative and qualitative findings in a matrix.

Main Results

We included 29 studies (published in 30 papers) in our synthesis. Twenty-two key findings were produced under three broad themes (with six subthemes) to capture the experience of being invited to participate in a trial and making the decision whether to participate. Most of these findings had moderate to high confidence. We identified factors from the trial itself that influenced participation. These included how trial information was communicated, and elements of the trial such as the time commitment that might be considered burdensome. The second theme related to personal factors such as how other people can influence the individual's decision; and how a personal understanding of potential harms and benefits could impact on the decision. Finally, the potential benefits of participation were found to be key to the decision to participate, namely personal benefits such as access to new treatments, but also the chance to make a difference and help others. The conceptual model we developed presents the decision-making process as a gauge and the factors that influence whether the person will, or will not, take part.

Authors' Conclusions

This qualitative evidence synthesis has provided comprehensive insight into the complexity of factors that influence a person's decision whether to participate in a trial. We developed key questions that trialists can ask when developing their recruitment strategy. In addition, our conceptual model emphasises the need for participant-centred approaches to recruitment. We demonstrated moderate to high level confidence in our findings, which in some way can be attributed to the large volume of highly relevant studies in this field. We recommend that these insights be used to direct or influence or underpin future recruitment strategies that are developed in a participant-driven way that ultimately improves trial conduct and reduces research waste.

---

### Innovations in data collection, management, and archiving for systematic reviews [^c4804a3b]. Annals of Internal Medicine (2015). Low credibility.

Data abstraction is a key step in conducting systematic reviews because data collected from study reports form the basis of appropriate conclusions. Recent methodological standards and expectations highlight several principles for data collection. To support implementation of these standards, this article provides a step-by-step tutorial for selecting data collection tools; constructing data collection forms; and abstracting, managing, and archiving data for systematic reviews. Examples are drawn from recent experience using the Systematic Review Data Repository for data collection and management. If it is done well, data collection for systematic reviews only needs to be done by 1 team and placed into a publicly accessible database for future use. Technological innovations, such as the Systematic Review Data Repository, will contribute to finding trustworthy answers for many health and health care questions.

---

### Survey research: a primer for the academic radiologist [^e7d05c7b]. Academic Radiology (2018). Low credibility.

Survey research is appealing to many clinical researchers, including radiologists. Emerging interest in patient preferences and patient-centered outcomes related to imaging likely will stimulate additional use of questionnaires in our field. However, like other quantitative methods, survey-based research requires meticulous planning, execution, and analysis to generate reliable results and support meaningful conclusions. The purpose of this review is to provide a guideline for radiologists embarking on this type of research, with attention to questionnaire design, sampling, survey administration, and analysis.

---

### Proper analysis of secondary phenotype data in case-control association studies [^e214084b]. Genetic Epidemiology (2009). Low credibility.

Case-control association studies often collect extensive information on secondary phenotypes, which are quantitative or qualitative traits other than the case-control status. Exploring secondary phenotypes can yield valuable insights into biological pathways and identify genetic variants influencing phenotypes of direct interest. All publications on secondary phenotypes have used standard statistical methods, such as least-squares regression for quantitative traits. Because of unequal selection probabilities between cases and controls, the case-control sample is not a random sample from the general population. As a result, standard statistical analysis of secondary phenotype data can be extremely misleading. Although one may avoid the sampling bias by analyzing cases and controls separately or by including the case-control status as a covariate in the model, the associations between a secondary phenotype and a genetic variant in the case and control groups can be quite different from the association in the general population. In this article, we present novel statistical methods that properly reflect the case-control sampling in the analysis of secondary phenotype data. The new methods provide unbiased estimation of genetic effects and accurate control of false-positive rates while maximizing statistical power. We demonstrate the pitfalls of the standard methods and the advantages of the new methods both analytically and numerically. The relevant software is available at our website.

---

### Using mixed methods for genetic counseling research [^db9773ab]. Journal of Genetic Counseling (2025). Medium credibility.

TABLE 2
Aspects of mixed methods study designs (Creswell & Plano Clark).

Researchers can use the elements of these study designs in flexible combinations while maintaining high rigorous standards of research as long as there is methodological coherence and clear justification for the decisions made across the research process.

Within the qualitative and quantitative strands, researchers also need strong methodological procedures for recruitment, measurement, data collection, analysis, and interpretation. The data within these strands can be generated in many different ways (not simply surveys and interviews), and researchers can consider reviewing medical records or health services utilization data, analysis of policy documents, arts‐based methods, and others as guided by the goal of the research (Creswell & Plano Clark).

Another issue that researchers should consider when planning a mixed method study design is whether a research study is truly mixed method or if it is better conceptualized as multi‐method. Sometimes the data generated from qualitative and quantitative components is far apart and difficult to transform or analyze in a format where it can be effectively integrated and used for comparison or explanation, and under these circumstances, it might be useful to consider whether it is, in fact, better suited to a multi‐method approach (Bazeley). Although mixed methods research can be suitable for many genetic counseling research topics, there is no natural hierarchy of methodologies that makes mixed methods superior to single or sequential multi‐method approaches. The "best" methodological choice is the one that will lead to the most valid, rigorous, useful evidence in a given context or for a specific research question. In fact, it can actually be harmful to prioritize using a specific methodological approach rather than to prioritize the methodology that will yield the most valid results, and researchers should be mindful of making emotional decisions to justify using mixed methods approaches.

---

### Goals of frail older people living with chronic kidney disease: a mixed methods study [^fc8a7da1]. Journal of the American Geriatrics Society (2025). Medium credibility.

2 Methods

This research utilizes baseline data collected from participants in the GOAL trial, for which the protocol has been published elsewhere. It was a cluster‐randomized controlled trial that sought to understand whether frail older people living with CKD who received a comprehensive geriatric assessment (CGA) were better able to attain their goals than those who received usual care only.

2.1 Study Design

This is a mixed methods study using a triangulation design. The data transformation model variant of triangulation design was used to transform qualitative data into quantitative data, enabling analysis of these two data types in a complementary manner. Figure 1, adapted from Creswell and colleagues' seminal work on mixed methods research design, helps to conceptualize the relationship and sequence of the study's qualitative and quantitative research components. The transformation model enabled qualitative data (goals expressed as free‐text responses) to be converted into quantitative data (frequency counts). Doing so allowed for an interpretation of the described goal categories and participant characteristics, including a person's degree of frailty, quality of life scores, and severity of CKD. The checklist for mixed‐methods research manuscript preparation provided by Lee, recommended by the EQUATOR Network, helped guide the reporting of this study.

FIGURE 1
The relationship and sequence of qualitative and quantitative research components — adapted from Creswell et al. GAS, Goal Attainment Scaling; FI, Frailty Index; eGFR, Estimated glomerular filtration rate).

---

### Importance of mixed methods in pragmatic trials and dissemination and implementation research [^6b802fd6]. Academic Pediatrics (2013). Low credibility.

With increased attention to the importance of translating research to clinical practice and policy, recent years have seen a proliferation of particular types of research, including pragmatic trials and dissemination and implementation research. Such research seeks to understand how and why interventions function in real-world settings, as opposed to highly controlled settings involving conditions not likely to be repeated outside the research study. Because understanding the context in which interventions are implemented is imperative for effective pragmatic trials and dissemination and implementation research, the use of mixed methods is critical to understanding trial results and the success or failure of implementation efforts. This article discusses a number of dimensions of mixed methods research, utilizing at least one qualitative method and at least one quantitative method, that may be helpful when designing projects or preparing grant proposals. Although the strengths and emphases of qualitative and quantitative approaches differ substantially, methods may be combined in a variety of ways to achieve a deeper level of understanding than can be achieved by one method alone. However, researchers must understand when and how to integrate the data as well as the appropriate order, priority, and purpose of each method. The ability to demonstrate an understanding of the rationale for and benefits of mixed methods research is increasingly important in today's competitive funding environment, and many funding agencies now expect applicants to include mixed methods in proposals. The increasing demand for mixed methods research necessitates broader methodological training and deepened collaboration between medical, clinical, and social scientists. Although a number of challenges to conducting and disseminating mixed methods research remain, the potential for insight generated by such work is substantial.

---

### Factors that influence caregivers' and adolescents' views and practices regarding human papillomavirus (HPV) vaccination for adolescents: a qualitative evidence synthesis [^aef53de1]. The Cochrane Database of Systematic Reviews (2025). Medium credibility.

Data extraction

We extracted contextual and methodological data for each sampled study using a form designed specifically for this review. We recorded the following information.

First study author
Date of publication
Country of study
Context, including urban/rural, HIC, LIC, MIC, LMIC, WHO region
Participant group and gender of participants (parent, caregiver, adolescent; men, women)
Number of participants
HPV vaccine type
HPV vaccine gender focus
Study design
Objectives
Guiding theoretical or conceptual framework
Data collection and analysis methods

Assessment of the methodological limitations in included studies

Our inclusion criteria specified that included studies needed to use qualitative methods for both data collection and analysis. This constituted a basic quality threshold, as we excluded studies that used qualitative methods to collect data but not to analyse these data. In addition, two review authors (SC, NAJ) independently assessed methodological limitations for each study using criteria employed in previous Cochrane reviews (Ames 2017; Ames 2019b; Houghton 2020; Karimi‐Shahanjarini 2019; Munabi‐Babigumira 2017). These criteria were originally based on the Critical Appraisal Skills Programme (CASP) tool (CASP 2018), but they have since gone through several iterations. For instance, we did not include questions about the appropriateness of qualitative methodology or the specific research design used, as these were already covered in our inclusion criteria. We resolved disagreements through discussion between the two review authors (SC, NAJ) or through consultation with a third review author (BS). The adapted tool includes the following eight questions, which we used to assess methodological limitations.

Are the setting(s) and context described adequately?
Is the sampling strategy described, and is this appropriate?
Is the data collection strategy described and justified?
Is the data analysis described, and is this appropriate?
Are the claims made/findings supported by sufficient evidence?
Is there evidence of reflexivity?
Does the study demonstrate sensitivity to ethical concerns?
Any other concerns?

We conducted a pilot on three sampled studies to assess the feasibility of using this tool and to ensure the integrity of the assessment. We did not use our quality assessments to exclude studies, but rather to judge the relative contribution of each study to the review findings and as part of the assessment of how much confidence we have in each finding (see below). Our assessments for each study are reported in the methodological limitations table in Appendix 3.

---

### Peer support for parents of children with chronic disabling conditions: a systematic review of quantitative and qualitative studies [^8f6c3252]. Developmental Medicine and Child Neurology (2013). Low credibility.

Aim

To review the qualitative and quantitative evidence of the benefits of peer support for parents of children with disabling conditions in the context of health, well-being, impact on family, and economic and service implications.

Method

We comprehensively searched multiple databases. Eligible studies evaluated parent-to-parent support and reported on the psychological health and experience of giving or receiving support. There were no limits on the child's condition, study design, language, date, or setting. We sought to aggregate quantitative data; findings of qualitative studies were combined using thematic analysis. Qualitative and quantitative data were brought together in a narrative synthesis.

Results

Seventeen papers were included: nine qualitative studies, seven quantitative studies, and one mixed-methods evaluation. Four themes were identified from qualitative studies: (1) shared social identity, (2) learning from the experiences of others, (3) personal growth, and (4) supporting others. Some quantitative studies reported a positive effect of peer support on psychological health and other outcomes; however, this was not consistently confirmed. It was not possible to aggregate data across studies. No costing data were identified.

Conclusion

Qualitative studies strongly suggest that parents perceive benefit from peer support programmes, an effect seen across different types of support and conditions. However, quantitative studies provide inconsistent evidence of positive effects. Further research should explore whether this dissonance is substantive or an artefact of how outcomes have been measured.

---

### Joint display of integrated data collection for mixed methods research: an illustration from a pediatric oncology quality improvement study [^07fd37b4]. Annals of Family Medicine (2023). Medium credibility.

Purpose

Researchers often struggle to integrate quantitative and qualitative data. Joint displays of data collected using mixed methods provide a framework for supporting integration, yet the literature lacks methodologic articles illustrating in detail the iterative nature of constructing such displays. We demonstrate the process for creating a joint display for integrating the collection of data obtained by qualitative and quantitative methods.

Methods

Within a convergent mixed methods cohort study, the Early Discharge of Febrile Neutropenic Children with Cancer Study, we constructed a joint display to inform integrated collection of 2 forms of data (quantitative and qualitative) from 2 sources (a patient-caregiver mixed methods survey and a manual abstraction of medical records).

Results

In a first step, we used a data sources table to align related quantitative and qualitative data. The resulting table consisted of 2 side-by-side columns based on the mixed survey data. After several additional iterative steps, we constructed a final 6-column joint display. This final display delineated the separate data sources, linked constructs to the quantitative and qualitative variables within each source, and integrated the constructs across the separate data sources.

Conclusions

Challenges of integration, though not unique to prospective mixed methods cohort studies, stem from the sheer volume of qualitative and quantitative information and the need to logically organize the data in preparation for integrated data analysis. Tailoring joint displays to specific studies is challenging, but mixed methods researchers who embrace the methodologic malleability can produce effective joint displays to illustrate the mixed data collection linkages and create a preliminary structure ultimately for organizing mixed data findings.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^98feb86b]. Annals of the American Thoracic Society (2023). High credibility.

Quantitative imaging study design — precision versus bias and measurement efficiency emphasize that "Bias" refers to systematic errors leading to inaccuracy and "Precision" refers to measurement reproducibility; bias "can be neither detected in the data nor decreased by making more measurements" and is avoided a priori by rigorous design, whereas precision can be checked and adjusted by increasing sample size or number of measurements. Because "more measurements do not increase accuracy if bias exists at higher levels of study design", automated exhaustive measurements "could aggravate inaccuracy and reduce efficiency", and it is "more efficient to invest extra effort into the higher levels of study design"; with unbiased sampling "it is not always necessary to exhaustively analyze each voxel". In a well-designed study, precision is tuned so the within-subject coefficient of error is "significantly smaller than" between-subject variation; "repetitive imaging can often be made to assess response to intervention", and baseline between-subject variability is less important in longitudinal designs in which subjects act as their own controls.