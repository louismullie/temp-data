# Medical Question & Answer

**Sample ID**: e03f5f69-ba27-e53e-09d7-07cdc6d2e653
**Dataset Index**: 118386

---

## Question

Which of the following statements is TRUE concerning OLS estimation?

Answer Choices:
A. OLS minimises the sum of the vertical distances from the points to the line
B. OLS minimises the sum of the squares of the vertical distances from the points to the line
C. OLS minimises the sum of the horizontal distances from the points to the line
D. OLS minimises the sum of the squares of the horizontal distances from the points to the line.

---

## Answer

> Let's see… What do we have here? The user is asking which statement correctly describes what Ordinary Least Squares (OLS) estimation minimizes. Let's break this down step-by-step. First, I need to think about the core definition of OLS and whether it minimizes distances or squared distances. Then, I should verify whether those distances are vertical (residuals) or horizontal. Next, I will check the provided sources to confirm the exact wording. Finally, I will eliminate the incorrect options and select the best answer, making sure I don't overstate anything beyond what the references support.

> Let me first confirm the definition. OLS is the method of least squares, which finds the line that minimizes the sum of the squared differences between observed values and the values predicted by the model; in simple linear regression, those differences are the vertical distances from the observed points to the fitted line, i.e., the residuals, and OLS minimizes the sum of their squares, not the raw distances themselves [^6d47e996] [^18239641].

> Wait, let me verify the directionality. I initially wondered if "distances" could mean horizontal deviations, but that would imply errors in the predictor rather than the response, which is not the standard OLS formulation; OLS treats the predictor as fixed and minimizes vertical residuals, so the distances are vertical, not horizontal, and they are squared to penalize larger errors more heavily and to yield a differentiable objective function for optimization [^6d47e996] [^18239641].

> I should double-check the exact phrasing in the sources. The Nature Communications primer explicitly states that coefficients are estimated by minimizing the sum of the squared differences between observed values and model-predicted values, which are precisely the squared vertical residuals in the usual regression setup, confirming that OLS minimizes the sum of squared vertical distances from the points to the line [^6d47e996]. The emergency medicine tutorial likewise describes the method of least squares as minimizing the sum of squared errors, reinforcing the same interpretation [^18239641].

> Now, I will examine each option against this. Option A says OLS minimizes the sum of vertical distances; hold on, I should verify — this is incorrect because OLS minimizes the sum of squared vertical distances, not the raw distances, so squaring is missing here [^6d47e996]. Option B states OLS minimizes the sum of the squares of the vertical distances; yes, that matches the definition of minimizing squared residuals, so this is correct [^6d47e996]. Option C proposes horizontal distances; that would be a different problem formulation and is not what OLS does, so this is incorrect [^18239641]. Option D proposes the squares of horizontal distances; again, this misstates the direction of the errors OLS targets, so it is incorrect [^6d47e996].

> Conclusion: The correct statement is B, because OLS minimizes the sum of the squares of the vertical distances from the observed points to the fitted regression line, i.e., the sum of squared residuals [^6d47e996] [^18239641].

---

The correct answer is **B. OLS minimises the sum of the squares of the vertical distances from the points to the line**. This is the defining feature of ordinary least squares: it finds the line that minimizes the **sum of squared vertical residuals** (errors), not the raw distances or horizontal deviations [^6d47e996] [^18239641]. Options A, C, and D are incorrect because they either omit squaring or use horizontal distances, which do not correspond to the OLS objective function [^6d47e996].

---

## Mathematical formulation of OLS

OLS estimates the regression coefficients by minimizing the **sum of squared residuals**, where the residual for each observation is the vertical distance between the observed value and the fitted regression line [^6d47e996]. Formally, for a simple linear regression model:

yᵢ = β₀ + β₁ xᵢ + εᵢ

The OLS objective is to minimize:

Σ (i = 1 to n) (yᵢ − ŷᵢ)² = Σ (i = 1 to n) (yᵢ − (β₀ + β₁ xᵢ))²

Here, (yᵢ − ŷᵢ) is the **vertical distance** (residual) between the observed value yᵢ and the predicted value ŷᵢ on the regression line. Squaring these residuals ensures that positive and negative errors do not cancel out and that larger errors are penalized more heavily [^6d47e996].

---

## Geometric interpretation

Geometrically, OLS finds the line that minimizes the **sum of the squares of the vertical distances** from each data point to the regression line. These vertical distances are the residuals, and squaring them emphasizes larger deviations, making the estimator sensitive to outliers [^6d47e996].

---

## Why not horizontal distances?

OLS does not minimize horizontal distances because the regression model treats the dependent variable (y) as a function of the independent variable (x), with errors assumed to occur in the vertical direction (i.e. in the measurement of (y)). Minimizing horizontal distances would imply errors in (x), which is not the standard assumption in OLS regression [^18239641].

---

## Common misconceptions

- **Option A**: "OLS minimises the sum of the vertical distances from the points to the line" is incorrect because it omits the squaring of residuals, which is central to the OLS method [^6d47e996].
- **Option C**: "OLS minimises the sum of the horizontal distances from the points to the line" is incorrect because OLS focuses on vertical residuals, not horizontal deviations [^18239641].
- **Option D**: "OLS minimises the sum of the squares of the horizontal distances from the points to the line" is incorrect for the same reason as Option C, and it also incorrectly includes squaring of horizontal distances [^6d47e996].

---

## Conclusion

OLS regression minimizes the **sum of the squares of the vertical distances** (residuals) from the observed data points to the fitted regression line. This approach ensures that the regression line provides the best linear fit to the data by minimizing the overall squared error, making Option B the correct answer [^6d47e996].

---

## References

### Dependency and health utilities in stroke: data to inform cost-effectiveness analyses [^4db27171]. European Stroke Journal (2017). Low credibility.

Validation

Ordinary least squares (OLS) regression, is recommended as a method of estimating unknown parameters (such as HU) from existing data (e.g. mRS).OLS Regression examines error: the differences between predicted outcomes and reality, and attempts to fit a line through the data that minimises the sum of the squared errors. This method was also previously described by Rivero-Arias et al. We used OLS regression to generate an equation to estimate HU based on mRS scores from our international population. We examined the proportion of variation in HU that was explained by mRS, adjusting for patients' age and baseline NIHSS. The National Institute for Health and Clinical Excellence (NICE) caution against over-fitting covariates in an OLS regression; age and NIHSS were selected due to the strength of their association with post-stroke outcomes in our dataset (p < 0.0001).

For this regression analysis, we applied published value sets from the USA, UK, Spain, Germany, China and Poland. These value sets were selected as they were generated using the most robust sample sizes, were published in the EQ-5D-3L inventory and user guide, represented countries that were typically included in international multicentre RCTs, and/or represented areas where emerging stroke research datasets warranted the generation of robust HU estimates. Performance was assessed using goodness of fit (adjusted R -squared values). We described the clinical and demographic characteristics of our population to inform generalisability for application to other clinical stroke populations.

---

### Phylogenetically informed predictions outperform predictive equations in real and simulated data [^6d47e996]. Nature Communications (2025). High credibility.

Box 1 Phylogenetically informed prediction

In the context of ordinary least squares (OLS) regression, the relationship between the dependent variable (Y) and independent variables (X) is modelled with Eq. (1):whereis the intercept and,…, are the coefficients for the independent variables. The error term, describes the residual variance. The coefficients are estimated by minimising the sum of the squared differences between the observed values and the values predicted by the model. Mathematically, this involves solving forin Eq. (2):whereis the vector of observed values, is the matrix of independent variables, andis the vector of coefficients. Once the model is fitted and the coefficients are estimated, predictions for the dependent variable can be made using Eq. (3):

Phylogenetic generalised least squares regression (PGLS) extends the OLS framework by incorporating the phylogenetic variance-covariance matrixinto the error term to account for the non-independence of observations. The coefficients in PGLS regression are estimated by again solving forin Eq. (2), but hereand the GLS estimatoraccounts for the phylogenetic relationships.

Coefficients of both OLS and PGLS models are often used to generate predictive equations — from which unknown values of y are simply calculated given the value of the independent variable(s) (y = α + βx).

However, phylogenetically informed prediction explicitly incorporates the phylogenetic position of the unknown species relative to those used to inform the regression model. In this scenario, phylogenetically informed predictions for a species h can be made using Eq. (4):

These predictions use both the estimated coefficients and, whereis a n × 1 vector of phylogenetic covariances for all species i other than species h. Therefore, a phylogenetically informed prediction is computed by adjusting the prediction off the regression line by — a prediction residual. This method was first described by Garland & Ivesusing independent contrasts on a tree re-rooted at the node of interest, with various implementations having been introduced since (see Box 2).

---

### Predicting prognosis for adults with depression using individual symptom data: a comparison of modelling approaches [^4a8bd359]. Psychological Medicine (2023). Medium credibility.

Discussion

There were few differences in the performance of the majority of the predictive models. The first seven models all outperformed the null models on all metrics for primary and secondary outcomes. Those using weighted or unweighted sum scores (the first six models) performed better in the held-out test data than the individual-item models did, particularly model 8 (the OLS regression model using all of the individual BDI-II score items and eight CIS-R anxiety subscale scores instead of the sum scores for each). Any of the eight models could be used to predict the severity of depressive symptoms at 3–4 months after starting treatment based on pre-treatment data. The large difference in observed remission rates between those predicted to have high compared to low BDI-II scores at 3–4 months informs the potential clinical relevance of these models.

Strengths and limitations

This study was the first to provide robust tests of the ability of centrality statistics from FGL networks and factor loadings from a factor analytic model to develop weighted total scale scores to inform predictive models of treatment outcomes. This is something that has been proposed as a promising method for using individual symptom data to build informative predictive models (Boschloo et al.). We tested these methods against bone fide predictive models and simple comparison models, and in entirely held-out (test) data, and found there to be little evidence of any advantage to the above approaches. We used a large individual patient data dataset comprising six RCTs with a variety of widely available treatments for depression, all of the RCTs were situated in primary care, and five were pragmatic trials, increasing the generalisability of these results (Rothwell). However, the variability in the samples between the studies may have limited the overall performance of the models. We included a range of psychopathology measures at baseline, not just depression symptoms from a single measure, as there is good evidence that such factors are associated with prognosis for depressed adults (Buckman et al; Buckman et al.). We also used the most commonly utilised comprehensive measure of depressive and anxiety symptoms and diagnoses from RCTs of depression in primary care, to minimise bias in harmonising data, and ensure a broad range of depressive and anxiety based symptoms could be included in the models we developed.

---

### Effects of safe childbirth checklist on quality of care and birth outcomes in Indonesia… [^df8727fb]. JAMA Network (2021). Excellent credibility.

eTable 2. Minimal Detectable Effect Sizes for Health Outcomes eTable
3. Mortality eTable 4. Mortality and Morbidity eTable
5. Mortality and Morbidity. Data were analyzed from January 2020 to October 2021. As a primary outcome measure, we examined the application of essential practices. 20, 23 The basic intention-to-treat estimates used an approach of a binary outcome of essential practices on a binary indicator of treatment assignment via ordinary least-squares regressions, and thus, they represent linear probability models for binary outcome measures. Despite the aforementioned caveat regarding statistical power, we also estimated treatment effects for morbidity and mortality outcomes. We used equations 1 to 3 in the eAppendix in Supplement 2 and accounted for the rare events nature of mortality via a penalized maximum likelihood logistic regression.

33 If applicable, clustered SEs accounted for intracluster correlation at the facility level. For a qualitative analysis, F. D. and S. S. S. conducted 2 complementary focus group discussions with midwives at treatment facilities concerning their experience with the SCC. Questions focused on the coaching process and the perceived quality of care. In contrast, the point estimates for neonatal mortality and stillbirths were consistently negative. Whereas the ITT estimate was not significant, coefficients were significant after we accounted for covariates, considered the rare events nature of mortality via a Firth logit estimator, or used the CACE estimator. Coefficients ranged from a reduction in the rate of stillbirths from –0. 012 with Firth logit to –0. 025 with the CACE approach.

We also calculated estimates at the facility level, which allowed us to consider complication rates. Although facility-level results were generally consistent with the main results, the individual-level regressions were more comparable with the data from the primary outcome analyses. For robustness, eFigure 1 and eTable 5 in Supplement 2 show the results of constraining the secondary outcome regressions to the reduced sample of the primary outcome analyses, which were generally consistent with the previous findings.

---

### Ridge regression in prediction problems: automatic choice of the ridge parameter [^50a16a0e]. Genetic Epidemiology (2013). Low credibility.

Theoretical Justification

The method we propose is developed based on a popular choice of the ridge parameter that was proposed by [Hoerl et al.], which we denote k HKB after the authors who proposed it. Here, are the ordinary least squares (OLS) regression coefficients, equivalent to equation 2 with. Hoerl et al. proposed the following choice of ridge parameter:whereWhen, k HKB is not defined, because it is dependent on the ordinary least squares regression (OLSR) coefficientsthat are themselves not defined when the data have more predictors than observations. When, k HKB can equivalently be writtenIn a generalised RR, individual shrinkage parameters are assigned to each of the principal components in the linear model. Then, k HKB is motivated as the harmonic mean of the 'ideal' generalised ridge estimator in terms of minimising mean square error of the coefficient estimates. Hoerl et al. explain their choice of the harmonic mean as a way to preventing the small, which have little predicting power, leading to too large a a shrinkage parameter as would happen if the arithmetic mean were to be used. We observed thatin this estimator are the principal components regression coefficients defined in equation 3. In a simulation study with, we investigated the use ofprincipal components in computing. In Supplementary Appendix A and Supplementary Fig. S1 we demonstrate that when the signal-to-noise ratio is not too low, estimates ofwith smaller mean squared error are obtained usingwiththan when using k HKB.

---

### Depression, violence and socioeconomic outcomes among refugees in east Africa: evidence from a multicountry representative survey [^8947a052]. BMJ Mental Health (2023). High credibility.

Statistical analysis

The first part of the analysis explored the prevalence of depressive symptoms and functional impairment in refugee populations. We used simple t-tests to compare the prevalence in refugee subgroups and refugee and host populations. We report 95% CIs.

The second part of the analysis used regression analysis to explore the association between exposure to violence predisplacement and mental health and socioeconomic outcomes postdisplacement. We estimated regression equations of the following form:

whereis the dependent variable (either a measure of depressive symptoms, functional impairment or socioeconomic outcomes), andis the explanatory variable of interest (either a measure of violence exposure, depressive symptoms or functional impairment).is a vector of control variables, which are described in online supplemental tables A.2-A.4 in the supplement.andare enumeration areas and enumerator fixed effects, respectively. We included control variables and fixed effects to minimise the risk of omitted variable bias. Enumeration area fixed effects were included to control for unobserved variables that could influence the average answers obtained in the different locations. Enumerator fixed effects are useful to control for unobserved variables that could influence each enumerator's average answers.

We were primarily interested in the parameter, estimated using ordinary least squares (OLS) regression. Given the absence of random or quasi-random variation in violence exposure, depressive symptoms and functional impairment, omitted variable bias and reverse causality are possible. We were, therefore, cautious when interpreting regression results and avoided making strong causal claims.

We used sampling weights and clustered standard errors (SEs) in the analysis to account for the sampling design. Variables that are non-binary were standardised to facilitate the interpretation and comparison of regression coefficients.

This analysis adheres to the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) guideline. The STROBE checklist is shown in online supplemental file.

---

### Local opinion leaders: effects on professional practice and healthcare outcomes [^2cf77e6b]. The Cochrane Database of Systematic Reviews (2019). Medium credibility.

Background

Clinical practice is not always evidence-based and, therefore, may not optimise patient outcomes. Local opinion leaders (OLs) are individuals perceived as credible and trustworthy, who disseminate and implement best evidence, for instance through informal one-to-one teaching or community outreach education visits. The use of OLs is a promising strategy to bridge evidence-practice gaps. This is an update of a Cochrane review published in 2011.

Objectives

To assess the effectiveness of local opinion leaders to improve healthcare professionals' compliance with evidence-based practice and patient outcomes.

Search Methods

We searched CENTRAL, MEDLINE, Embase, three other databases and two trials registers on 3 July 2018, together with searching reference lists of included studies and contacting experts in the field.

Selection Criteria

We considered randomised studies comparing the effects of local opinion leaders, either alone or with a single or more intervention(s) to disseminate evidence-based practice, with no intervention, a single intervention, or the same single or more intervention(s). Eligible studies were those reporting objective measures of professional performance, for example, the percentage of patients being prescribed a specific drug or health outcomes, or both. We included all studies independently of the method used to identify OLs.

Data Collection and Analysis

We used standard Cochrane procedures in this review. The main comparison was (i) between any intervention involving OLs (OLs alone, OLs with a single or more intervention(s)) versus any comparison intervention (no intervention, a single intervention, or the same single or more intervention(s)). We also made four secondary comparisons: ii) OLs alone versus no intervention, iii) OLs alone versus a single intervention, iv) OLs, with a single or more intervention(s) versus the same single or more intervention(s), and v) OLs with a single or more intervention(s) versus no intervention.

Main Results

We included 24 studies, involving more than 337 hospitals, 350 primary care practices, 3005 healthcare professionals, and 29,167 patients (not all studies reported this information). A majority of studies were from North America, and all were conducted in high-income countries. Eighteen of these studies (21 comparisons, 71 compliance outcomes) contributed to the median adjusted risk difference (RD) for the main comparison. The median duration of follow-up was 12 months (range 2 to 30 months). The results suggested that the OL interventions probably improve healthcare professionals' compliance with evidence-based practice (10.8% absolute improvement in compliance, interquartile range (IQR): 3.5% to 14.6%; moderate-certainty evidence). Results for the secondary comparisons also suggested that OLs probably improve compliance with evidence-based practice (moderate-certainty evidence): i) OLs alone versus no intervention: RD (IQR): 9.15% (-0.3% to 15%); ii) OLs alone versus a single intervention: RD (range): 13.8% (12% to 15.5%); iii) OLs, with a single or more intervention(s) versus the same single or more intervention(s): RD (IQR): 7.1% (-1.4% to 19%); iv) OLs with a single or more intervention(s) versus no intervention: RD (IQR):10.25% (0.6% to 15.75%). It is uncertain if OLs alone, or in combination with other intervention(s), may lead to improved patient outcomes (3 studies; 5 dichotomous outcomes) since the certainty of evidence was very low. For two of the secondary comparisons, the IQR included the possibility of a small negative effect of the OL intervention. Possible explanations for the occasional negative effects are, for example, the possibility that the OLs may have prioritised some outcomes, at the expense of others, or that an unaccounted outcome difference at baseline, may have given a faulty impression of a negative effect of the intervention at follow-up. No study reported on costs or cost-effectiveness. We were unable to determine the comparative effectiveness of different approaches to identifying OLs, as most studies used the sociometric method. Nor could we determine which methods used by OLs to educate their peers were most effective, as the methods were poorly described in most studies. In addition, we could not determine whether OL teams were more effective than single OLs.

Authors' Conclusions

Local opinion leaders alone, or in combination with other interventions, can be effective in promoting evidence-based practice, but the effectiveness varies both within and between studies. The effect on patient outcomes is uncertain. The costs and the cost-effectiveness of the intervention(s) is unknown. These results are based on heterogeneous studies differing in types of intervention, setting, and outcomes. In most studies, the role and actions of the OL were not clearly described, and we cannot, therefore, comment on strategies to enhance their effectiveness. It is also not clear whether the methods used to identify OLs are important for their effectiveness, or whether the effect differs if education is delivered by single OLs or by multidisciplinary OL teams. Further research may help us to understand how these factors affect the effectiveness of OLs.

---

### Bias due to participant overlap in two-sample mendelian randomization [^3617dacb]. Genetic Epidemiology (2016). Low credibility.

2.3 Magnitude of bias in a one‐sample setting

The ordinary least squares (OLS, also known as standard least squares regression) estimate is obtained by regressing the outcome on the risk factor. This "observational" estimate is typically biased due to confounding. The relative bias of the 2SLS estimate — the bias of the 2SLS estimate divided by the bias of the OLS estimate — is approximately and asymptotically equal to(Staiger & Stock, 1997), whereis the "F parameter". An F parameter of 10 therefore corresponds to arelative bias of the 2SLS estimate compared to the OLS estimate. However, this calculation cannot be directly employed for bias correction in an applied setting, as the F statistic in a given dataset may differ substantially from the F parameter due to random variation (Burgess, Thompson, & CRP CHD Genetics Collaboration, 2011). As weak instrument bias occurs due to chance correlations with confounders, the reference OLS estimate should ideally be unadjusted for measured confounders, unless these confounders are also adjusted for in the IV estimate.

2.4 Expected bias of 2SLS estimator

The bias of the 2SLS estimator in a one‐sample setting has been considered theoretically (Nagar, 1959). One approximation to the bias is:where μ is the concentration parameter, K is the number of IVs, is the variance of the error in the first‐stage regression model, andis the covariance of the error terms in the first‐ and second‐stage regression models (Bun & Windmeijer, 2011). In a two‐sample setting, this formula may not be directly applicable, as the sample sizes for the first‐ and second‐stage regressions (and so the lengths of the error term vectors) may differ, in which case a covariance cannot be calculated. If the sample sizes are equal, then we can decompose the covariance into a term corresponding to individuals included in both regressions, and a term corresponding to unrelated individuals that will have expectation zero. If the sample sizes differ, dependence between these two error terms is still driven by individuals in common between these two regressions, and the presence of individuals in only one or other of the regressions will dilute this dependence. As covariance is a linear operator in both its arguments, we may therefore expect the bias of the 2SLS estimator to be approximately linear in the proportion of overlap between the samples.

---

### Improving genetic prediction by leveraging genetic correlations among human diseases and traits [^8e106b51]. Nature Communications (2018). Medium credibility.

Fig. 1
Schematic of the methods. a Data and programs used to create predictors. b Terminology to refer to different types of predictors. OLS, ordinary least squares. The most common GWAS methodology to estimate SNP effects is to estimate the effect sizes of one SNP at a time using linear regression. BLUP, best linear unbiased prediction. SNP effects are estimated simultaneously for all SNPs. The estimates depend on the other SNPs included in the analysis, since the contribution from correlated SNPs will be shared between them

Consider two genetically correlated traits for which we have individual-level genetic predictors with BLUP properties. For each individual, i, and focal trait of interest, f, we have a genetic predictionfor each trait, k, that we can combine together using the index weights, w i, k, for eacheffect to produce a weighted multi-trait BLUP genetic predictor:In the Methods section, we show that the optimal index weights can be calculated as:whereis the SNP heritability of trait k (proportion of phenotypic variance explained by genome-wide SNPs), r G is the genetic correlation between trait k and the focal trait andis the expected squared correlation between a phenotype and a BLUP predictor, calculated as:where M eff is the effective number of chromosome segments and N k is the sample size of trait k. These weights will ensure that the contribution of each added trait is approximately proportional to the square root of its sample size, its SNP heritability and its genetic correlation with the focal trait (trait 1), while accounting for different variances of single-trait BLUP predictors.

---

### Emergent constraints on carbon budgets as a function of global warming [^23f6b836]. Nature Communications (2024). High credibility.

We therefore derive an observational constraint on the specific carbon budget of 553 ± 82 PgC/°C.

The emergent constraints derived in this study use a very similar approach to a number of previous studies. applying an ordinary-least-squares (OLS) fit between the predictand and the predictor variable. More sophisticated Bayesian approaches have been proposed and applied in other studies –. However, these approaches have been found to yield very similar constraints to OLS when the emergent relationships are strong and linear, as they are in this study.

We make use of emergent relationships across the CMIP6 models between the specific carbon budget at a given level of global warming and the specific carbon budget up to the current day. The probability density of the y-axis variable, is given byWhere the probability of y given x, is derived from the best fit emergent relationship, and the probablity of x, is the observational constraint. The emergent constraint P (y) is therefore affected by both the quality of the emergent relationship P (y | x) and the uncertainty in the observational constraint P (x). We integrate this equation numerically to derive the constraint on the y variable, making use of the estimated uncertainty in the observational constraint and assuming, in this case, thatcan be represented by a Gaussian distribution. In this study, the emergent relationships are very well approximated by a linear regression, so thatwhereis the linear regression, calculated in this study using ordinary least squares, and the x-dependent prediction error of the regression is given byandis the number of points, andare the mean and variance of the x -axis variable, andis the standard error in the fit, given by the square root of

---

### How the internet increases modern contraception uptake: evidence from eight sub-saharan African countries [^5eb4a280]. BMJ Global Health (2020). High credibility.

Statistical analysis

The key exposure variable is individual access to the internet: for our purposes, internet 'exposure' and 'access' are synonyms. We included in our analysis the following: controls for age in years; educational level (no education/primary/secondary/higher education); whether the woman is working; whether her partner is living in the household; number of living children; place of residence (i.e. urban vs rural); household income (divided into quintiles of distribution for the country of residence). Our analysis proceeds in three steps. First, we estimate the association between internet access and the probability of using modern contraception. We do this with descriptive multivariate ordinary least square (OLS; linear probability) regression model. Second, we estimate the moderator effect of the respondent's educational attainment. Third, in order to ensure that internet exposure is, indeed, exogenous, we estimate a two-Stage Least Square (2SLS) regression model using two instrumental variables (IVs). For this, exposure to the internet is captured by (1) the question of whether the connection of the backbone network in country has been connected to, at least, one submarine cable; and (2) the distance between the main server and the largest city of the country; adjusting for covariates.

---

### Olsalazine sodium (Dipentum) [^8af96321]. FDA (2009). Low credibility.

Regarding the use of olsalazine PO (also known as Dipentum) in patients with eGFR 10–20 mL/min/1.73 m²:
- Avoid use as much as possible. Avoid high doses.
- Monitor serum concentrations.

---

### Refining penalized ridge regression: a novel method for optimizing the regularization parameter in genomic prediction [^27c9590f]. G3 (2024). Medium credibility.

Materials and methods

Datasets

A concise overview of the 14 datasets used in this study is provided in Table A1 (Appendix A).

Statistical model

In a general context, we have a covariate vector, and we want to use this information to predict or explain how this variable affects a real-value response. The linear multiple regression model assumes a relationship given by

whereis a random error vector with mean 0, and is independent of. This error is included in the model to capture measurement errors and the effects of other unregistered explanatory variables that can help explain the mean response. Then, the conditional mean of this model isand the conditional distribution ofgivenis only affected by the information of.

To estimate the parameters, we usually have a set of data, often known as training data, whereis a vector of features measurement andis the response measurement corresponding to the i th individual drawn. In the context of large p and small n, the most common method to estimateis the Ridge regression method, which consists of taking thevalue that minimizes the penalized residual sum of squares defined as

whereis the regularization parameter, which determines the level or degree to which the beta coefficients are shrunk toward 0. When, the ordinary least square (OLS) is the solution to the beta coefficients, but when λ is large, theis dominated by the penalization term, and the OLS solution must shrink toward 0. In general, when the number of parameters to be estimated is larger than the number of observations, the estimator resulting in the OLS is invalid. In this situation, the intuition of Ridge regression tries to alleviate this by constraining the sum of squares for the beta coefficients.

---

### Lost in translation: on the problem of data coding in penalized whole genome regression with interactions [^9071c5f7]. G3 (2019). Medium credibility.

Theory: Specification Of Regression Methods

If an expression includes an inverse of a matrix, we implicitly assume that the matrix is invertible for the respective statement, also if not mentioned explicitly. Analogously, some statements for OLS may implicitly assume that a unique estimate exists, which in particular restricts to cases in which the number of observations is at least the same as the number of parameters which have to be determined. Moreover, we will use "estimated" and "predicted" effects as synonym in this work since the quantities may be considered as being fixed or being random in several instances.

---

### Resource allocation for maximizing prediction accuracy and genetic gain of genomic selection in plant breeding: a simulation experiment [^ecccc54c]. G3 (2013). Low credibility.

Allocating resources between population size and replication affects both genetic gain through phenotypic selection and quantitative trait loci detection power and effect estimation accuracy for marker-assisted selection (MAS). It is well known that because alleles are replicated across individuals in quantitative trait loci mapping and MAS, more resources should be allocated to increasing population size compared with phenotypic selection. Genomic selection is a form of MAS using all marker information simultaneously to predict individual genetic values for complex traits and has widely been found superior to MAS. No studies have explicitly investigated how resource allocation decisions affect success of genomic selection. My objective was to study the effect of resource allocation on response to MAS and genomic selection in a single biparental population of doubled haploid lines by using computer simulation. Simulation results were compared with previously derived formulas for the calculation of prediction accuracy under different levels of heritability and population size. Response of prediction accuracy to resource allocation strategies differed between genomic selection models (ridge regression best linear unbiased prediction [RR-BLUP], BayesCπ) and multiple linear regression using ordinary least-squares estimation (OLS), leading to different optimal resource allocation choices between OLS and RR-BLUP. For OLS, it was always advantageous to maximize population size at the expense of replication, but a high degree of flexibility was observed for RR-BLUP. Prediction accuracy of doubled haploid lines included in the training set was much greater than of those excluded from the training set, so there was little benefit to phenotyping only a subset of the lines genotyped. Finally, observed prediction accuracies in the simulation compared well to calculated prediction accuracies, indicating these theoretical formulas are useful for making resource allocation decisions.

---

### Olsalazine sodium (Dipentum) [^c79c9341]. FDA (2009). Low credibility.

Regarding the use of olsalazine PO (also known as Dipentum) in patients with eGFR < 10 mL/min/1.73 m²:
- Avoid use as much as possible. Avoid high doses.
- Monitor serum concentrations.

---

### High-yield parallel fabrication of quantum-dot monolayer single-electron devices displaying coulomb staircase, contacted by graphene [^c30a27e1]. Nature Communications (2021). High credibility.

The presence of the QD SAM is confirmed by AFM combined with mechanical scraping (Fig. 6), a QCM and energy-dispersive X-ray (EDX) (Fig. 4).

Fig. 6
AFM imaging of device regions verifying the formation of a QD monolayer.

a – b Height profile across an Au electrode where the QD SAM is first assembled and subsequently scraped away mechanically using an AFM tip. Measured height difference ~ 5.2 nm. c – d Height profile across an Au electrode where the QD SAM is not assembled, due to photoresist protection, but with the area still scraped mechanically with the AFM tip. Measured height difference ~ 1.3 nm.

In both OL and EBL device fabrication the PMMA is removed from the SLG with acetone, followed by rinsing with IPA. For OL devices, optical resist is spun on SLG, and the entire area outside the central region is exposed and developed. This leaves a rectangle of resist over the central region covering just the tips of the Au electrodes. The positions of the tips are staggered across the likely positions of this rectangle's edges, caused by alignment error, to minimise device areas on each sample after the exposed SLG is etched by oxygen plasma in a reactive-ion etching (RIE) machine (20 s at 10 W and 75 mTorr). The remaining SLG only contacts the Au electrode tips, where the C6S2 SAM and QDs are assembled, and the grounding electrodes.

For EBL devices, four thicknesses (40, 50, 60, 100 nm) of 950,000 molecular-weight PMMA in anisole (1:1) are spun on the SLG. This is done to capture the minimum EBL resolution when patterning the SLG top electrodes as these define device sizes. Deep UV lithography is used to remove all but a PMMA rectangle over the samples' central regions much like on the OL samples, the difference being that these can be subsequently patterned with EBL. The PMMA development is in IPA:methyl isobutyl ketone:methyl ethyl ketone 15:5:1 for 5–10 s at 21 ° C. The remaining PMMA is then patterned with EBL and the SLG is etched with RIE to create the smallest device areas in the dataset.

---

### Validation and characterisation of a DNA methylation alcohol biomarker across the life course [^3ff96f5a]. Clinical Epigenetics (2019). Medium credibility.

DNA methylation measurements

In ARIES, cord blood and peripheral blood samples (whole blood, buffy coats or blood spots) were collected according to standard procedures. DNA extraction, wet laboratory preparation and DNA methylation measurement by Illumina Infinium HumanMethylation450K (HM450) BeadChip were performed as part of the ARIES project, as previously described. Briefly, samples from all ARIES time-points were distributed semi-randomly across HM450 slides to minimise the potential for confounding by technical batch. Data pre-processing was performed using the meffil package. Samples failing quality control (average probe detection p value ≥ 0.01, those with sex or genotype mismatches) were excluded from further analysis, and probes containing < 95% of signals detectable above background signal (detection p value < 0.01) were also removed. Functional normalisation was performed to minimise non-biological variation in probes.

In HN5000, blood samples were processed and frozen upon receipt and stored at − 80 °C. Genome-wide DNA methylation data was generated in participants using Infinium MethylationEPIC BeadChip (EPIC array) (Illumina, USA) at the Bristol Bioresource Laboratories. Following extraction, DNA was bisulphite-converted using the Zymo EZ DNA MethylationTM kit (Zymo, Irvine, CA, USA) and genome-wide methylation status of over 850,000 CpG sites was measured using the EPIC array according to the manufacturer's protocol using an Illumina iScan. All data pre-processing and normalisation was again performed using the meffil package, which excluded five of the total samples for not meeting the QC criteria.

Covariates

For the ARIES parental generation at midlife, offspring generation in both childhood and adolescence, and HN5000 participants, DNA methylation levels were adjusted for age, sex, body mass index (BMI) and Houseman estimate white blood cell (WBC) counts by residualizing on these factors by ordinary least squares (OLS) regression prior to calculation of DNAm-Alcs. Levels from pregnancy were not adjusted for sex, as only female participants had DNA methylation available, but were adjusted for age, WBC counts and pre-pregnancy BMI. The adjustment set for DNA methylation at birth included gestational age (weeks), child sex, birthweight (grammes) and WBC counts calculated using a cord blood reference set. Indicator variables for self-reported current smoking at midlife for the ARIES parents and for having ever/never smoked a cigarette in adolescence for the offspring were used in sensitivity analyses.

---

### High-yield parallel fabrication of quantum-dot monolayer single-electron devices displaying coulomb staircase, contacted by graphene [^17d78f8f]. Nature Communications (2021). High credibility.

We first consider the fabrication variables that best predict the occurrence of Coulomb staircase, then we fit ~ 1000 I – V steps to gather step parameters and quantify the step variation within and across devices. We also perform combined ultrasonic force microscopy and atomic force microscopy (AFM), scanning electron microscopy (SEM) and transmission electron microscopy (TEM) to gain further structural information. All of this is used to explain why we see a consistently high yield of SET characteristics for device areas ranging from < 800 nm 2 up to 16 μ m 2.

Devices are fabricated on a SiO 2 -coated Si substrate in a 160 μ m × 30 μ m rectangular region at the centre of each sample (Fig. 1 b, f). In this area, 39 devices are made simultaneously by patterning the SLG such that it only covers the tips of the 39 QD-coated Au electrodes (seen as vertical lines in Fig. 1 b). Each fabrication cycle (batch) produces 36 samples (~1400 devices) but this can be scaled up to much larger numbers by increasing the wafer size. The SLG also makes direct electrical contact with three horizontal electrodes, positioned in the centre of the devices, that are left bare. In all other areas, the SLG lies on the SiO 2.

By staggering the Au electrodes such that they span the possible positions of the etched SLG edge — produced by optical lithography (OL) misalignment (Fig. 1 g) — a range of device areas can be obtained for a given sample that, in some cases, gives smaller areas than could have been produced with a non-stochastic approach, the goal being to minimise these areas and observe the most interesting electronic behaviour. In these OL samples, device areas range from 0.18 ± 0.16 to 18.3 ± 0.2 μ m 2. In one batch, additional electron-beam lithography (EBL) reduces areas further by up to a factor of 2500, resulting in samples with areas from < 0.0025 to 2.15 μ m 2 (Fig. 1 h).

---

### Cross-validation without doing cross-validation in genome-enabled prediction [^e80d0cc6]. G3 (2016). Low credibility.

Cross-Validation with Ordinary Least-Squares

Setting

A linear model used for regressing phenotypes on additive codes at biallelic marker loci (−1, 0, 1 for aa, Aa and AA, respectively), such as in a genome-wide association study, isHere, is thevector of phenotypic measurements, is themarker matrix, andis the number of copies of a reference allele at locus j observed in individualis avector of fixed regressions on marker codes, known as allelic substitution effects. Phenotypes and markers are often centered; if an intercept is fitted, the model is expanded by addingas an effect common to all phenotypes. The residual vector is assumed to follow the distributionwhereis anidentity matrix, andis a variance parameter common to all residuals.

The basic principles set here carry to the other prediction methods discussed in this paper. In this section, we assumeso that ordinary least-squares (OLS) or maximum likelihood under the normality assumption above can be used. The OLS estimator ofis, and the fitted residual for datum i is, whereis therow ofAssuming the model holds, so the estimator is unbiased. A review of the pertinent principles is given in Appendix A, from which we extract results.

It is shown in Appendix A that the uncertainty of a prediction, as measured by variance, increases with p (model complexity), and decreases with the size of the testing set. Two crucial matters in genome-enabled prediction must be underlined. First, if the model is unnecessarily complex, prediction accuracy (in the MSE sense) degrades unless the increase in variance is compensated by a reduction in prediction bias. Second, if the training set is made large at the expense of the size of the testing set, prediction mean squared error will be larger than otherwise. The formulae ofsuggest that expected prediction accuracy, as measured by predictive correlation (not necessarily a good metric;), increases with n. However, the variability of the predictions would increase, as found byin an empirical study of Holstein progeny tests with alternative CV layouts. Should one aim at a higher expected predictive correlation or at a more stable set of predictions at the expense of the former? This question does not have a simple answer.

---

### 4-year results from the RAPID-PsA phase 3 randomised placebo-controlled trial of certolizumab pegol in psoriatic arthritis [^aab6671a]. RMD Open (2018). Low credibility.

In patients who do not respond adequately to their first biological DMARD, the GRAPPA and European League Against Rheumatism treatment guidelines for PsA both recommend switching to a second biological DMARD; including the option to switch between anti-TNFs. A head-to-head trial of CZP and the anti-TNF adalimumab in patients with rheumatoid arthritis recently demonstrated the efficacy and safety of switching to a second anti-TNF after primary failure to an initial anti-TNF. In this study of CZP in patients with PsA, although only around 1 in 5 had previously been treated with an anti-TNF, the efficacy of CZP was similar in patients both with and without prior anti-TNF exposure, indicating that CZP may be effective in patients who do not respond adequately to their first biological DMARD.

The limitations of the RAPID-PsA study include the lack of a placebo control beyond Week 24 and inherent bias in having dose-blind and OL periods, when the patient is aware that they are receiving active treatment, as is their physician. As is true for all clinical trials, patient withdrawal from the study also introduces a risk of bias in the data, and the impact of patient withdrawal is likely to be greater in a long-term study. Imputation of the missing data that results from patient withdrawal helps to conserve the validity of the analyses, but also requires assumptions to be made about the measurements that patients would have had if they had remained in the study. Here, we have reported both observed and imputed data to minimise the risk of bias. Another limitation of clinical trials is that while the long-term clinical efficacy and safety data are relevant to clinical practice, the study participants are not completely representative of all patients treated in the clinical practice. In conclusion, the 4-year data demonstrating the efficacy of CZP across most PsA disease domains in the RAPID-PsA study support CZP treatment for the long-term therapeutic management of PsA.

---

### Effect of alcohol label designs with different pictorial representations of alcohol content and health warnings on knowledge and understanding of low-risk drinking guidelines: a randomized controlled trial [^4c39235b]. Addiction (2021). Medium credibility.

Table 3
Understanding of the low‐risk drinking guidelines (LRDG): distance from the correct answer for questions concerning how many servings/containers could be consumed before reaching 14 units (each measure is an average of six answers: two beer, two wine and two spirits).

Table 4
Understanding of the low‐risk drinking guidelines (LRDG): ordinary least squares (OLS) regression with accuracy of estimate of how many servings/containers could be drunk and the drinker still remain under the 14‐unit per week LRDG.

The inaccuracy was driven by the estimates for wines, and especially spirits. Figure 7 shows the understanding estimates for servings, disaggregated into wine, beer and spirts. For beer, all intervention groups gave similar and accurate answers to questions concerning how many servings they could have. Within each label design the CIs of the understanding estimates for servings of beer, alcohol and spirits do not overlap, with participants being least accurate regarding servings of spirits. When the estimates are expressed in terms of units the numerical ordering is preserved, but some of the CIs overlap (see Fig. 7).

Figure 7
Understanding of the low‐risk drinking guidelines (LRDG) (servings): how many servings of alcohol can be consumed while remaining under the LRDG? Mean distance from the correct answer in (a) servings and (b) units, ordered from most to least accurate (in terms of aggregate average measure), showing 95% confidence intervals (CIs) from an ordinary least squares (OLS) regression controlling for demographics

---

### A method to estimate the contribution of rare coding variants to complex trait heritability [^583bcf21]. Nature Communications (2024). High credibility.

Statistical model to estimate RV heritability using RARity

We developed a method, RARity, to compute heritability estimates based on aggregating linear regression models over large genetic regions including up to thousands of variants. The method is based on a multivariate linear regression model:The RARity method entails computing the multiple linear regression solutions using an ordinary least square (OLS) for each of the non-overlapping genetic blocks in parallel under the condition thatis much larger than the number of genetic variants in theth block, while ensuring the between block correlation, due to linkage disequilibrium (LD) spillage between blocks, is minimized. In other words, RARity approximates the linear solution toby setting the observedto a block diagonal matrix, whereGiven the observed quantitative trait, the OLS estimate of the genetic effects vector for theth blockis:and the fitted value, denoted by, can be computed as:The estimated heritability associated with thematrix is simply the amount of variance explained by the fitted value:Sinceincreases as the number of predictors increase, the adjusted, denoted by, is used as our estimate for the proportion of variance explained. Total RV heritability of the trait is estimated by the sum ofover all K blocks:The 95% confidence interval (CI) ofcan be approximated for each block using the asymptotic properties described by Alginausing the Wald's method, where the variance ofis given by:The 95% CI for the adjustedof a single block can then be derived accordingly:whereTo estimate the 95% CI for, we approximated the asymptotic variance by the sum of the individual sampling variance, for each block, assuming each block is roughly uncorrelated of others after controlling for LD spillage:which then translates to a Wald's 95% CI for the:

---

### Asymmetric one-pot transformation of isoflavones to pterocarpans and its application in phytoalexin synthesis [^9cf208b2]. Nature Communications (2020). High credibility.

Fig. 3
Synthesis of isoflavanol 8.

Four-step approach to 8 via ATH of 2′-hydroxyisoflavanone 9 and optimised two-step synthesis of 8 via ATH of isoflavone 10.

The ATH led to the isolation of isoflavan-4-ol 8 in 89% yield and excellent enantiomeric excess after optimisation of our previously reported conditions. The 2′-hydroxyl-substituted substrate 8 proved to be even more reactive than 2′-unsubstituted ones and encouraged us to subject the isoflavone 10 to the established protocol, too. The substrate 10 was prepared by Suzuki coupling of iodochromone 15 with the boronic acid 19 (for preparation, see Supplementary Note 6). Quenching the cross-coupling reaction with concentrated hydrochloric acid provided isoflavone 10 in a single step in 78% yield after crystallisation. The ATH cascade from 10 to isoflavan-4-ol 8 proceeded with a high yield of 92% and excellent enantioselectivity (> 99% ee), even with only 1 mol% of chiral catalyst instead of 5 mol%. We envision, that a first hydride transfer generates a racemic isoflavanone. Initially, we thought that the intramolecular hydrogen bond between the 2′-hydroxyl group and the ketone causes a stronger polarisation of the enone and hereby facilitates the 1,4-reduction, as 2′-unsubstituted isoflavones were earlier shown to be unsuitable substrates under our ATH conditions. However, several experiments with 2′-unsubstituted isoflavones in the presence of externally added hydrogen bond donors did not support this theory. Possibly, the intramolecular hydrogen bond in 10 fixes the orientation of the aromatic B ring to minimise unfavourable steric interactions between substrate and catalyst. The R enantiomer of the intermediate isoflavanone is preferentially reduced in the crucial ATH step to give the isoflavan-4-ol 8 via the proposed transition state TS 1, while the S enantiomer racemises rapidly under the reaction conditions via keto–enol tautomerisation. The attractive CH–π interaction between the p- cymene ligand and the aromatic A ring of the substrate together with the avoidance of a destabilising steric interaction between the tosyl group and the aryl substituent at the heterocyclic C ring is supposed to be responsible for the high enantioselectivity and diastereoselectivity of this reduction.

---

### Patterns of social connection among older adults in england… [^459bbb11]. JAMA Network (2024). Excellent credibility.

The dashed horizontal line indicates a PS threshold of 0.
8. Number of people in the household Have a partner Have any child Have any relative Have any friend How close is your relationship with your spouse or partner. How many of your children would you say you have a close relationship with. How many of these family members would you say you have a close relationship with. eFigure 2. Total Within-Clusters Sum of Squares by the Number of Clusters Using the K-Prototypes Algorithm and Integrated Completed Likelihood Criterion Using Gaussian Mixture Model eFigure
3. Cluster Profiles Using the K-Prototypes Algorithm eFigure 4. Cluster Profiles Using Latent Class Model. This study used a model-based clustering algorithm, KAMILA, short for Kay-Means for Mixed Large Data. 21, 22 It clusters continuous variables like the K-means algorithm and categorical variables based on Gaussian-multinomial mixture models. We applied the KAMILA algorithm with different numbers of clusters.

The optimal number of clusters was chosen based on the prediction strength method. 23 We defined the optimal number of clusters as the largest number of clusters with a prediction strength greater than the threshold of 0.
8.
21. Sensitivity analyses were carried out using the k-prototypes algorithm using Gower distance via R package clustMixTy24 and Gaussian mixture model clustering method via R package VarSelLCM. 25 These algorithms were chosen because they have been shown to outperform other alternatives for mixed data of categorical and continuous variables.
26. We acknowledge that baseline adjustment is controversial, which may lead to downward bias in presence of residual autocorrelation, 27 while leaving it out puts us at risk of omitted variable bias. By presenting 2 sets of results, we hope to posit plausible bounds on the true association between the social connection cluster and outcome.

Clustering analysis was unweighted, but the regression analyses were weighted using self-completion weights from wave 4. Sensitivity analyses using the k-prototype method and Gaussian mixture model supported the 5-cluster solution. The k-prototype method gave largely consistent cluster partitions as KAMILA, but the Gaussian mixture model had a poor agreement with either KAMILA or k-prototype, which was likely because the multivariate normal assumption was violated.

---

### Enantiopure synthesis of [5] helicene based molecular lemniscates and their use in chiroptical materials [^a1e63a92]. Nature Communications (2025). High credibility.

Fig. 1
Synthetic route to lemniscate (P, P)−8.

Enantiomeric lemniscate (M, M)− 8 was synthesised in an identical synthetic sequence using (S)−4-phenylbutyn-2-ol in step 4 (see Supplementary Fig. 1).

Fig. 2
Solid-state structure of 6 and ECD spectra of 6 and 7.

A The molecular structure of [5]helicenoid 6. The thermal ellipsoids are drawn at 50% probability level and all H atoms are omitted for clarity; (B) ECD spectra (molar ellipticity) of compounds P (S, S)− 6 (red) and M (R, R)− 6 (black) and (C) P (S, S)− 7 (red) and M (R, R)− 7 (black) recorded in CHCl 3.

In line with previously reported literature, the stereochemical outcome of the cyclisation reaction to form 6 is founded upon the minimisation of 1,3-allylic-like strain between the methyl groups at the stereocentres and the distal phenyl groups. As such, good levels of diastereoselectivity were observed, with a diastereomeric ratio of ca. 9:1 determined by 1 H NMR analysis of the crude reaction mixture. No evidence of epimerisation of compound 6 is observed upon long-term storage at room temperature or upon heating to 140 °C for a period of 24 h. Furthermore, computational studies indicate an energy barrier to epimerisation from P (S, S)- to M (S, S)- 6 of 33.2 kcal mol -1 (see Supplementary Information), thus demonstrating the conformational stability imparted to the architecture by the dual sp 3 stereocentres contained within the two pyran rings of 6.

---

### Association between birth weight and refractive error in adulthood: a mendelian randomisation study [^24653d9c]. The British Journal of Ophthalmology (2020). Medium credibility.

Background

Pathological myopia is one of the leading causes of blindness globally. Lower birth weight (BW) within the normal range has been reported to increase the risk of myopia, although findings conflict. We sought to estimate the causal effect of BW on refractive error using Mendelian randomisation (MR), under the assumption of a linear relationship.

Methods

Genetic variants associated with BW were identified from meta-analysis of a genome-wide association study (GWAS) for self-reported BW in 162039 UK Biobank participants and a published Early Growth Genetics (EGG) consortium GWAS (n = 26836). We performed a one-sample MR analysis in 39658 unrelated, adult UK Biobank participants (independent of the GWAS sample) using an allele score for BW as instrumental variable. A two-sample MR sensitivity analysis and conventional ordinary least squares (OLS) regression analyses were also undertaken.

Results

In OLS analysis, BW showed a small, positive association with refractive error: +0.04 D per SD increase in BW (95%CI 0.02 to 0.07; p = 0.002). The one-sample MR-estimated causal effect of BW on refractive error was higher, at +0.28 D per SD increase in BW (95%CI 0.05 to 0.52, p = 0.02). A two-sample MR analysis provided similar causal effect estimates, with minimal evidence of directional pleiotropy.

Conclusions

Our study suggests lower BW within the normal range is causally associated with a more myopic refractive error. However, the impact of the causal effect was modest (range 1.00 D covering approximately 95% of the population).

---

### An occupational health intervention programme for workers at high risk for sickness absence. cost effectiveness analysis based on a randomised controlled trial [^a9235238]. Occupational and Environmental Medicine (2008). Low credibility.

DISCUSSION

Main findings

The intervention, a personal feedback of the health survey results and an invitation to a consultation at the local OHS, was cost-saving and more effective in reducing sickness absence than usual occupational health care (dominant in terms of health economics). The cost-effectiveness was not sensitive to any cost variables and the result did not change whether we used available cost data or data where missing total costs were imputed. The health survey outcome measures showed that the differences between the two groups were minimal concerning the subjects' self-rated health problems. In other words, the intervention produced the same (self-rated) health outcomes at a lower cost than usual care.

Strengths and weaknesses of the study

Our primary outcome was based on register data on sickness absence, which has several advantages: good coverage, accuracy and consistency. We were able to collect sickness absence data for all employees, whose employment still continued at the 12-month follow-up time point (n = 192 in both groups). The resource use data were collected by a questionnaire in a postal survey, and we received 134 responses in the intervention group and 138 responses in the usual care group. The overall response rate of about 70% in a postal survey is reasonably high. Comparison of the number of sickness absence days between the intervention and usual care (control) groups among employees with complete data and among employees with available cost data indicated however that the total cost data of employees were not missing completely at random (table 2). It appeared that the non-respondents in the usual care (control) group had significantly more sickness absence than the respondents, while such difference between the respondents and non-respondents in the intervention group was not found. This difference may be a side-effect of the intervention: participation in the intervention may have reduced the usual non-responding tendency among the most high-risk subjects. Therefore imputation of missing total cost data was deemed necessary to produce less biased cost-effectiveness results. A two-part approach to imputation was chosen due to the fact that typically different processes determine the probability of seeking care and the amounts of costs eventually incurred. Several regression techniques were explored in part two of the two-part approach. We chose the results based on OLS regression, because it performed best in the accuracy tests and produced conservative estimates in comparison with other methods. Therefore the imputed total costs are more likely underestimates rather than overestimates of the real total costs.

---

### FW: an R package for finlay-wilkinson regression that incorporates genomic / pedigree information and covariance structures between environments [^fc2a2f92]. G3 (2015). Low credibility.

The Finlay-Wilkinson regression (FW) is a popular method among plant breeders to describe genotype by environment interaction. The standard implementation is a two-step procedure that uses environment (sample) means as covariates in a within-line ordinary least squares (OLS) regression. This procedure can be suboptimal for at least four reasons: (1) in the first step environmental means are typically estimated without considering genetic-by-environment interactions, (2) in the second step uncertainty about the environmental means is ignored, (3) estimation is performed regarding lines and environment as fixed effects, and (4) the procedure does not incorporate genetic (either pedigree-derived or marker-derived) relationships. Su et al. proposed to address these problems using a Bayesian method that allows simultaneous estimation of environmental and genotype parameters, and allows incorporation of pedigree information. In this article we: (1) extend the model presented by Su et al. to allow integration of genomic information [e.g., single nucleotide polymorphism (SNP)] and covariance between environments, (2) present an R package (FW) that implements these methods, and (3) illustrate the use of the package using examples based on real data. The FW R package implements both the two-step OLS method and a full Bayesian approach for Finlay-Wilkinson regression with a very simple interface. Using a real wheat data set we demonstrate that the prediction accuracy of the Bayesian approach is consistently higher than the one achieved by the two-step OLS method.

---

### Structural equation models in occupational health: an application to exposure modelling [^b97eb744]. Occupational and Environmental Medicine (2012). Low credibility.

Objectives

Many occupational hygiene surveys are designed to collect pollutant monitoring data from multiple locations simultaneously to better reflect the reality of work-related exposure. The exposure model must account for the complexity inherent in this study design, as well as be flexible to extrapolating exposures across an occupational cohort for dose-response modelling and risk assessment. This paper explores the structural equation model (SEM) as a tool to analyse pollutant monitoring data from occupational studies with multiple concurrent sampling across exposure locations.

Methods

This study uses exposure data from a comprehensive assessment of diesel exhaust in the US trucking industry to test the strength of SEMs over more standard analytical approaches such as ordinary least squares (OLS). The exposure data consist of concurrent sampling of elemental carbon from multiple co-located monitors on individual workers, work area and background levels at 36 different trucking terminals across the USA.

Results

The SEM is compared with two separate OLS specifications-one that focuses only on predicting personal exposure and excludes data from the additional monitoring sites, and a second that estimates three separate OLS specifications. When compared with the OLS specifications, the SEM provided a better fit to these layered exposure data. The OLS specifications suffered from bias in the coefficients, including downward bias in the work area and background exposure levels and overstatement of the smoking effect. Additionally, many theoretically valid covariates were significant only in the SEM.

Conclusions

This study provides evidence in favour of more widespread use of SEMs in occupational health. SEMs represent a more robust and realistic framework for modelling multiple exposure pathways and have the potential to reduce exposure misclassification bias and strengthen the linkages between studies of exposure and disease outcomes.

---

### Built structures influence patterns of energy demand and COemissions across countries [^434be7cc]. Nature Communications (2023). High credibility.

Consider a linear specification, where variables have been previously standardized to account for differences in scales. Lasso finds estimates for model coefficient B keeping the model sparse by minimizing the following term:

The first part of the term (3) is the in-sample squared error minimized by a classical least-squares approach. Lasso also includes the absolute sum of coefficients in the objective function, which penalizes complexity driving some of the estimated coefficients to zero.

The value of λ is typically chosen so that the estimated model satisfies a predetermined condition. Several criteria can be employed, the most common of which is cross-validation. Cross-validation selects theto minimize the out-of-sample prediction error. First, sample observations are split into K random folds (validation sets). For each validation set, the model is fitted using data from the other folds, and the out-of-sample deviance for the observations in the validation set is computed (i.e. using data not employed for estimation). Finally, the overall out-of-sample performance of the model in all the validation sets is assessed by the mean-square prediction error (MSPE), a statistical parameter in squared (log) units required for model selection. Cross-validation selects theover a grid of possible values such that the corresponding model has the minimum MSPE. In Table 2, MSPE is transformed into r 2, i.e. the goodness of fit within the sample of countries, and oSr 2, i.e. the cross-validated out-of-sample goodness of fit for the optimal models. If no variable is added or removed at λ*, this is reported in the left columns of Table 2 as Unchanged. Note that beyond, more variables could be added but would not further improve the out-of-sample prediction.

---

### Accelerated estimation and permutation inference for ACE modeling [^6430bce2]. Human Brain Mapping (2019). Medium credibility.

2.2.1 Linear regression with squared differences

In the 1980s, a simple linear regression method for variance component estimation using squared differences (SqD's) of each subject pair was proposed by Grimes and Harvey (1980). For a sample of n subjects, there are (n 2 − n)/2 distinct SqD's. Note that the expectation of a SqD depends on the covariance, that is, for random variables A and B with. This allows SqD's to be related to variance parameters in a linear fashion, in particular construction of a linear regression where coefficients correspond to the variance components A, C, E (Grimes & Harvey, 1980; Lindquist, Spicer, Asllani, & Wager, 2012). Grimes and Harvey (1980) used ordinary least squares (OLS), which can produce negative variance component estimates that they simply neglected.

To deal with the non‐negativity problem, Lawson and Hanson (1987) proposed a now ubiquitous non‐negative least squares (NNLS) algorithm. The foundation of this algorithm is the Karush–Kuhn–Tucker (KKT) conditions (Karush, 1939; Kuhn & Tucker, 1951), which were first proposed for more complex nonlinear programming problems. In our case with the linearity assumption, the KKT conditions can be simplified to accelerate the computation. Although other methods had been proposed to solve this non‐negativity problem for large and sparse matrix settings, Luo and Duraiswami (2011) suggested that NNLS still maintained its superiority when small or moderate dense matrices were handled.

While Grimes and Harvey's method specifies a linear regression with the use of (n 2 − n)/2 different observations of SqD's, our modification of this method simplifies the computation such that onlyobservations are utilized in computing SqD's. Thus, the integration of the construction of the linear regression model with SqD's and estimating variance‐covariance parameters using NNLS with computational modification yields a novel and fast NNLS regression approach for unknown variance component estimation, entitled "Accelerated Permutation Inference for the ACE model (APACE)". The method of linear regression model construction with SqD's vary depending on whether subject‐specific covariates are included in the GLM model or not.

---

### An encompassing mendelian randomization study of the causes and consequences of major depressive disorder [^564d2d1b]. Nature: Mental Health (2025). High credibility.

OSMR

We conducted OSMR to test the effect of MDD on 48 outcomes for which no GWAS was available. Compared with TSMR, the statistical power of OSMR was much more limited (average 7–27% assuming effect sizes β = 0.1–0.3 or OR 1.1–1.3) because the instrument SNPs explained only minute amounts of variance in the MDD exposure (R 2 = 0.08%, F = 0.58). Nevertheless, the OSMR diagnostics indicated that the MDD instrument did not suffer from weak instrument bias (for the significant findings at P FDR < 0.05, average weak instrument test F = 39.9, average P = 3.5 × 10 −6).

Despite the overall limited power in the OSMR, we found evidence that MDD liability has an effect on a range of functional outcomes, increasing pain, problems with daily life, and hospitalizations, while reducing health satisfaction (Supplementary Table 6). Results are shown in Fig. 4 alongside the ordinary least squares (OLS) regression results relying on observational data only (MDD diagnosis predicting each outcome). The strongest OLS associations were found in the disease and functional outcomes category, with protective effects of MDD liability on disease outcomes. These protective effects are not in line with previous literature and findings from TSMR. They could be the effect of censoring in the hospital record data or, speculatively, be driven by a lower likelihood of an MDD being diagnosed in the presence of a medical disease that can be an alternative explanation for the observed symptoms. Regardless, the OSMR findings suggest that the protective effects of MDD on disease are not causal, while the negative impact on functional outcomes is. In addition, according to the OSMR results, genetic liability to MDD decreased the likelihood of being a fruit consumer and of having an accident and increased the chance of alcohol-related mortality, living in a socially deprived region, engaging in self-harm and experiencing partner violence.

---

### Optimisation of positive end-expiratory pressure by forced oscillation technique in a lavage model of acute lung injury [^de637dce]. Intensive Care Medicine (2011). Low credibility.

Purpose

We evaluated whether oscillatory compliance (C(X5)) measured by forced oscillation technique (FOT) at 5 Hz may be useful for positive end-expiratory pressure (PEEP) optimisation.

Methods

We studied seven pigs in which lung injury was induced by broncho-alveolar lavage. The animals were ventilated in volume control mode with a tidal volume of 6 ml/kg. Forced oscillations were superimposed on the ventilation waveform for the assessment of respiratory mechanics. PEEP was increased from 0 to 24 cmH(2)O in steps of 4 cmH(2)O and subsequently decreased from 24 to 0 in steps of 2 cmH(2)O. At each 8-min step, a CT scan was acquired during an end-expiratory hold, and blood gas analysis was performed. C(X5) was monitored continuously, and data relative to the expiratory hold were selected and averaged for comparison with CT and oxygenation.

Results

Open lung PEEP (PEEP(ol)) was defined as the level of PEEP corresponding to the maximum value of C(X5) on the decremental limb of the PEEP trial. PEEP(ol) was on average 13.4 (± 1.0) cmH(2)O. For higher levels of PEEP, there were no significant changes in the amount of non-aerated tissue (V(tissNA)%). In contrast, when PEEP was reduced below PEEP(ol), V(tissNA)% dramatically increased. PEEP(ol) was able to prevent a 5% drop in V(tissNA)% with 100% sensitivity and 92% specificity. At PEEP(ol) V(tissNA)% was significantly lower than at the corresponding PEEP level on the incremental limb.

Conclusions

The assessment of C(X5) allowed the definition of PEEP(ol) to be in agreement with CT data. Thus, FOT measurements of C(X5) may provide a non-invasive bedside tool for PEEP titration.

---

### Mendelian randomization analysis with multiple genetic variants using summarized data [^ad4a8f67]. Genetic Epidemiology (2013). Low credibility.

Implementation

Estimates of the causal effect using all the genetic variants are calculated using individual-level data with the two-stage least squares (2SLS) method [Baum et al.], and using summarized data with the IVW (equations 1 and 2) and likelihood-based (equation 3) methods. The first-stage model in the 2SLS was taken as additive in the variants throughout, and as such the genetic model was misspecified when there were gene–gene interactions. Summarized associations were obtained by ordinary least squares (OLS) linear regression of the risk factor and outcome on each variant in separate regression models. The likelihood-based analyses were performed in R using the optim command to directly maximize the likelihood.

An estimate of the correlation between the genetic associations with risk factor and outcome ofwas used based on the approximate observational correlation between the risk factor and outcome. Estimates were not especially sensitive to moderate (± 0.2) changes in this correlation. (A sensitivity analysis for this parameter is shown later for an applied example.)

In each scenario, results from 10,000 simulated datasets for the comparison of the individual-level and summarized data methods are given. We present the mean and median estimates across simulations, the standard deviation (SD) of estimates, the mean standard error (SE), the coverage of the 95% confidence interval for the causal effect (the proportion of simulated datasets for which the 95% confidence interval included the true value of), and the empirical power at a 5% significance level (the proportion of simulated datasets for which the 95% confidence interval excluded the null value of). The Monte Carlo standard error (representing the variation in estimates due to the finite number of simulations) was approximately 0.001 for the mean estimate (0.004 for the final scenario with gene–gene interactions) and 0.2% for the coverage. In each set of simulations, the mean value of the F statistic in the regression of the risk factor on the IVs is given.

---

### Oligodendrocyte fate after spinal cord injury [^18b2d80c]. Neurotherapeutics (2011). Low credibility.

Oligodendrocytes (OLs) are particularly susceptible to the toxicity of the acute lesion environment after spinal cord injury (SCI). They undergo both necrosis and apoptosis acutely, with apoptosis continuing at chronic time points. Loss of OLs causes demyelination and impairs axon function and survival. In parallel, a rapid and protracted OL progenitor cell proliferative response occurs, especially at the lesion borders. Proliferating and migrating OL progenitor cells differentiate into myelinating OLs, which remyelinate demyelinated axons starting at 2 weeks post-injury. The progression of OL lineage cells into mature OLs in the adult after injury recapitulates development to some degree, owing to the plethora of factors within the injury milieu. Although robust, this endogenous oligogenic response is insufficient against OL loss and demyelination. First, in this review we analyze the major spatial-temporal mechanisms of OL loss, replacement, and myelination, with the purpose of highlighting potential areas of intervention after SCI. We then discuss studies on OL protection and replacement. Growth factors have been used both to boost the endogenous progenitor response, and in conjunction with progenitor transplantation to facilitate survival and OL fate. Considerable progress has been made with embryonic stem cell-derived cells and adult neural progenitor cells. For therapies targeting oligogenesis to be successful, endogenous responses and the effects of the acute and chronic lesion environment on OL lineage cells must be understood in detail, and in relation, the optimal therapeutic window for such strategies must also be determined.

---

### Best (but oft-forgotten) practices: checking assumptions concerning regression residuals [^f2ebb771]. The American Journal of Clinical Nutrition (2015). Low credibility.

The residuals of a least squares regression model are defined as the observations minus the modeled values. For least squares regression to produce valid CIs and P values, the residuals must be independent, be normally distributed, and have a constant variance. If these assumptions are not satisfied, estimates can be biased and power can be reduced. However, there are ways to assess these assumptions and steps one can take if the assumptions are violated. Here, we discuss both assessment and appropriate responses to violation of assumptions.

---

### Estradiol (Estradiol vaginal inserts) [^b4022de9]. FDA (2025). Medium credibility.

INSTRUCTIONS FOR USE

Estradiol (es″ tra dye′ ol) Vaginal Inserts, USP

Read this Instructions for Use before you start using estradiol vaginal inserts and each time you get a refill. There may be new information. This information does not take the place of talking to your healthcare provider about your menopausal symptoms or your treatment.

 How should I use estradiol vaginal inserts?

Estradiol vaginal insert is an insert for use only in the vagina. Do not take by mouth.
Wash and dry your hands well before handling estradiol vaginal inserts.

Step 1: Tear off 1 applicator.

Step 2: Pull apart the plastic wrap and remove the applicator (see Figure A).

If after opening the package you see that the estradiol vaginal insert has come out of the applicator but has not fallen out of the package, carefully put the insert back into the applicator for insertion.

Step 3: Hold the applicator between your thumb and middle finger. Leave your index (pointer) finger free to press the applicator plunger (see Figure B).

Step 4: Select the best position for vaginal insertion of estradiol vaginal inserts that is most comfortable for you. For insertion in the lying down position, see Figure C. For insertion in the standing position, see Figure D.

---

### Pan-cancer multi-omic model of LINE-1 activity reveals locus heterogeneity of retrotransposition efficiency [^71cc7954]. Nature Communications (2025). High credibility.

Adjusting RNA and RT estimates based on sequencing metrics

Intronic rate of RNA-seq, which has previously been shown to be a key confound for L1 expression, was calculated using RNA-SeQC v2. A linear regression between the L1 RNA estimates and the intronic rate was then performed in Python v3.7.12 using statsmodels v0.13.0 OLS to perform an ordinary least squares regression. The residuals from this model were then used as the adjusted L1 RNA estimates (Supplementary Fig. 20a). Tumor and normal RNA-seq were fitted in the same model.

Similarly, quality metrics for the WGS samples were calculated as described above. An ordinary least squares model was fitted to the tumor-specific retrotransposition counts as a function of the average read length, depth of coverage, average base quality, chimeric read fraction, and clipped base fraction in both the tumor sample and the paired normal sample. The residuals from this model were then used as the adjusted L1 RT estimates (Supplementary Fig. 20b).

---

### Quantile regression in the field of liver transplantation: a case study-based tutorial [^9c9501de]. Liver Transplantation (2025). Medium credibility.

We present a tutorial on quantile regression, an underutilized yet valuable class of multivariable linear regression models that allows researchers to understand more fully the conditional distribution of response as compared to models based on conditional means. Quantile regression models are flexible, have attractive interpretations, and are implemented in most statistical software packages. Our focus is on an intuitive understanding of quantile regression models, particularly as compared with more familiar regression methods such as conditional mean models as estimated using ordinary least squares (OLS). We frame our tutorial through 2 clinical case studies in the field of liver transplantation: one in the context of estimating the recipient's financial burden after transplantation and another in estimating intraoperative blood transfusion needs. Our real-world cases demonstrate how quantile regression models give researchers a richer understanding of relationships in the data and provide a more nuanced clinical understanding compared to more commonly used linear regression models. We encourage researchers to explore quantile regression as a tool to answer relevant clinical research questions and support their more widespread adoption.

---

### A multicentre, prospective, randomised, double-blind study to measure the treatment effectiveness of abobotulinum A (aboBTXA) among women with refractory interstitial cystitis / bladder pain syndrome [^480de1b9]. International Urogynecology Journal (2014). Low credibility.

Introduction and Hypothesis

To determine if abobotulinumtoxin A (AboBTXA) is an effective treatment for interstitial cystitis/bladder pain syndrome (IC/BPS).

Methods

We performed a double-blind study of 54 women with severe, refractory IC from three referral centres whom we randomly allocated to treatment with hydrodistension + injection of normal saline or to hydrodistension + injection with AboBTXA. The O'Leary-Sant questionnaire consists of problem (OLS-PI) and symptom (OLS-PI) index scores, and bladder diary data were compared between AboBTXA and control patients at baseline and at 3 months of follow-up. Measurements were made beyond 3 months, but no further randomised comparison was possible due to the ability of nonresponsive patients in either group to have AboBTXA treatment.

Results

Complete data were available in 50 patients, and in both groups, OLS questionnaires showed improvement at 3 months. Only the OLS-PI was improved in the AboBTXA group (p = 0.04). At 3 months, no difference was found in either OLS-SI or total OLS score. Twelve patients had urinary tract infection (UTI) treated during the follow-up period, which confounded results. In the 38 patients without UTI, there was improvement in total OLS score (p = 0.02), OLS-PI (0.08), and OLS-SI (p = 0.008) for the AboBTXA group at 3 months. Only five AboBTXA compared with two control patients had a 50% reduction in OLS score.

Conclusions

For chronic refractory IC/BPS patients, AboBTXA was associated with no overall improvement in total OLS score, although significant benefit was noted in a small number of patients. The absence of posttreatment UTI was associated with a better response to AboBTXA.

---

### Uncovering oligodendrocyte enhancers that control cnp expression [^1185fae1]. Human Molecular Genetics (2023). Medium credibility.

Oligodendrocytes (OLs) produce myelin sheaths around axons in the central nervous system (CNS). Myelin accelerates the propagation of action potentials along axons and supports the integrity of axons. Impaired myelination has been linked to neurological and neuropsychiatric disorders. As a major component of CNS myelin, 2',3'-cyclic nucleotide 3'-phosphodiesterase (CNP) plays an indispensable role in the axon-supportive function of myelin. Notably, this function requires a high-level expression of CNP in OLs, as evidenced by downregulated expression of CNP in mental disorders and animal models. Little is known about how CNP expression is regulated in OLs. Especially, OL enhancers that govern CNP remain elusive. We have recently developed a powerful method that links OL enhancers to target genes in a principled manner. Here, we applied it to Cnp, uncovering two OL enhancers for it (termed Cnp-E1 and Cnp-E2). Epigenome editing analysis revealed that Cnp-E1 and Cnp-E2 are dedicated to Cnp. ATAC-seq and ChIP-seq data show that Cnp-E1 and Cnp-E2 are conserved OL-specific enhancers. Single cell multi-omics data that jointly profile gene expression and chromatin accessibility suggest that Cnp-E2 plays an important role in Cnp expression in the early stage of OL differentiation while Cnp-E1 sustains it in mature OLs.

---

### Genetic taste blindness to bitter and body composition in childhood: a mendelian randomization design [^0c11206d]. International Journal of Obesity (2014). Low credibility.

Background

The ability to taste 6-n-propylthiouracil (PROP) may be associated with body composition, but previous findings from observational studies are conflicting and cannot be interpreted causally. The aim of this study was to estimate the causal association between PROP taster status and body composition in a population-based cohort study.

Methods

The study was embedded in a population-based prospective birth cohort study. The TAS2R38 genotype (rs713598) was used as an instrumental variable (IV) to obtain unbiased effect estimates of the relation between PROP taster status and body weight (n = 3778). Adiposity measures included body mass index (BMI) and fat mass measured by dual- energy X-ray absorptiometry scan at the child's age of 6 years. Associations were investigated using both ordinary linear regression (OLS) and two-stage least squares regression (2SLS).

Results

Non-taster girls had higher BMI standard deviation scores (SDS) and higher body fat as compared with taster girls (results from linear regression BMI SDS: -0.09, P = 0.023, body fat mass (%): -0.49, P = 0.028). The TAS2R38 genotype predicted PROP phenotype (F = 240), indicating a strong IV. The 2SLS effect estimates were imprecise but similar to the observational estimates (-0.08 for BMI SDS and -0.46 for body fat mass %) and were not significantly different from the OLS results (Hausman test: P > 0.10). For boys there were no differences observed between tasters and non-tasters.

Conclusions

Our findings suggest a causal relation between PROP taster status and body weight among 6-year-old girls; Mendelian randomization was consistent with conventional estimates. In contrast, body weight among boys appeared to be independent of the PROP taster status. Further research should focus on possible underlying pathways, such as dietary behavior.

---

### Are local public expenditure reductions associated with increases in inequality in emergency hospitalisation? Time-series analysis of english local authorities from 2010 to 2017 [^eba5993f]. Emergency Medicine Journal (2024). Medium credibility.

Analysis

We estimated the association between mean avoidable and all-cause emergency admissions (ie, between-area inequalities) and need-adjusted expenditure reductions between 2010 and 2017. To examine inequalities between neighbourhoods within a given local authority (ie, within-area inequalities by level of deprivation), we constructed equity indicators from 2010 to 2017 at the LAD level using the same methods as NHS England, except using ONS population data.

The equity indicator for inequalities between neighbourhoods used by NHS England is the AGI. This is calculated using an ordinary least square (OLS) regression model of the relationship between neighbourhood-level deprivation and rates of avoidable and all-cause emergency admissions for each LAD for the years 2010–2017. The AGI represents the modelled gap (ie, the slope of the OLS regression) in emergency admissions between the most and least deprived neighbourhoods in England, if the local authority patterns were replicated nationwide. The mean (min-max) AGI for avoidable admissions in 2017 was 2288.7 (105.7–6221), while for all-cause emergency admissions, the AGI was 6909.3 (377.7–17 864.2).

We present descriptive data for 2010 and 2017, representing the first year where expenditure reductions were observed, and the last year included in the analysis. We chose the period between 2010 and 2017 for two reasons: (1) it was plausible that reductions in local government expenditure would have an effect on emergency admissions that could start appearing in 2010 and be detectable up to 2017; and (2) a 7-year period provided sufficient time to identify a trend in the data.

We used fixed-effects regressions to determine the association between the size of total expenditure reductions and between-area and within-area inequality trends in emergency admissions. The advantage of fixed-effects models is that they control for between-individuals time-invariant differences, so the coefficients cannot be biased due to omitted time-invariant characteristics. Because the distribution of deprivation within county districts is not homogeneous, we tested the robustness of our findings by running the analysis with and without these LADs. All analyses were conducted using Stata version/SE V.16.

Patient and public involvement

It was not feasible to involve patients or the public in the design or conduct of this specific research. Members of the public are involved actively in the wider UNFAIR research programme and dissemination plans for all the research outputs.

---

### Prevalence of drug-drug interactions in children with cardiac disorders receiving off-label drugs in a single centre in Pakistan: a cross-sectional study [^3ea1976a]. BMJ Paediatrics Open (2025). High credibility.

Patient selection

Patients with a stay of 24 hours in the paediatric cardiology ward were included in the study. Patients' drug profiles lacking relevant information required for the study were excluded. The patients who undergo any surgical procedure were also excluded from the study. Standard electrolyte solutions, oxygen therapy and topical medicines were also excluded. Simple random sampling was employed to collect patient data from the cohort. A predesigned proforma was used to collect patient demographics and clinical profiles which included details about diagnosis, stay, prescribed drugs, dose, frequency and duration of regimen. All the data were collected manually from clinical drug profiles of patients. Patient data were evaluated using Thomson healthcare Micromedex DrugDex and DrugReax (Watson health, IBM Corporation).

Information bias was addressed by excluding the patients with incomplete medical records. Observational bias was addressed by the extraction of data by two independent raters and their agreement strengthened the reliability of data. Drug-drug interactions were identified and classified by the MICROMEDEX drug interaction database, a validated tool and widely used in clinical decision support. The use of this standardised database enhances the reliability of DDI assessment.

Patient and public involvement

Patients and/or the public were not involved in the design, conduct, reporting or dissemination plan of this research as this study was an anonymised prospective cross-sectional study and the data were collected from patients medical and clinical records.

Definition of variables

Paediatrics age was categorised according to WHO classification as infants (age 0–2 years), children (2–12 years) and adolescents (12 to 18 years).OL drug use was defined as the use of a drug outside information labelled on the product licence. Categories for OL drug use were (1) the drug not approved for specific age of paediatric, (2) use of a drug for a specific indication not approved, (3) dose administered not mentioned in labelled information and (4) dosage form used other than approved ones.DDIs were screened using Micromedex Drug Reax which classifies DDIs based on severity, documentation and onset DDIs with a major severity were considered to be CSDDIs and included in the regression analyses. Severe drug-drug interactions were defined as those which have the potential to cause life-threatening outcomes to patients' health and require intervention to prevent or minimise the adverse effects.

---

### Linear regression in medical research [^90ff7dca]. Anesthesia and Analgesia (2021). Medium credibility.

Variable selection is a much-debated topic, and the details are beyond the scope of this Statistical Minute. Basically, variable selection depends on whether the purpose of the model is to understand the relationship between variables or to make predictions. This is also predicated on whether there is informed a priori theory to guide variable selection and on whether the model needs to control for variables that are not of primary interest but are confounders that could distort the relationship between other variables.

Omitting important variables or interactions can lead to biased estimates and a model that poorly describes the true underlying relationships, whereas including too many variables leads to modeling the noise (sampling error) in the data and reduces the precision of the estimates. Various statistics and plots, including adjusted R 2, Mallows C p, and residual plots are available to assess the goodness of fit of the chosen linear regression model.

---

### Is there a causal role for homocysteine concentration in blood pressure? A mendelian randomization study [^adb0d68d]. The American Journal of Clinical Nutrition (2016). Low credibility.

1982 Pelotas Birth Cohort

Multinomial regression models were used to verify if MTHFR C677T genotype distribution was associated with the covariates (sex, skin color, years of education, family income, regular alcohol consumption, leisure-time physical activity, smoking, and BMI). Homocysteine was log transformed, due to its positively skewed distribution, and standardized (SD units). Crude and adjusted (for sociodemographic and lifestyle variables) associations of standardized log homocysteine concentration with SBP and DBP were evaluated by using conventional ordinary least-squares (OLS) linear regression (Figure 1).

FIGURE 1
Analysis plan. Individual data from the 1982 Pelotas Birth Cohort were used to estimate the association of homocysteine concentration with SBP and DBP [unadjusted "crude" model and adjusted for potential confounders ("adjusted" model)] and to investigate the association of genetically increased homocysteine concentration with SBP and DBP [MR analysis; unadjusted "crude" model and adjusted for genomic ancestry ("adjusted" model)]. Summary data from the ICBP and homocysteine GWASs were combined to further investigate the association of genetically increased homocysteine concentration with SBP and DBP (MR analysis) by using as an IV the SNP MTHFR C677T (single SNP approach) or 18 SNPs associated with homocysteine concentration (multiple SNP approach). DBP, diastolic blood pressure; GWAS, genomewide association study; Hcy, homocysteine; ICBP, International Consortium for Blood Pressure; IV, instrumental variable; IVW, inverse variance weighted; MR, Mendelian randomization; MTHFR, methylenetetrahydrofolate reductase; OLS, ordinary least-squares linear regression; SBP, systolic blood pressure; SNP, single nucleotide polymorphism; 2SLS, 2-stage least-squares regression.

MR analysis of the association of standardized log homocysteine concentration with SBP and DBP was performed by using 2-stage least-squares (2SLS) regression, which is an IV estimation technique. In the first stage, homocysteine concentration is regressed against the IV. The second stage consists of regressing the values of SBP and DBP against the predicted values of the first model. The MTHFR C677T variant was coded in the additive genetic model according to the number of copies of the T allele. Results from OLS and 2SLS regression were compared by using the Durbin-Wu-Hausman (DWH) test (Figure 1).

To control for population stratification, analyses were adjusted for the top 10 ancestry-informative principal components (calculated by using a linkage disequilibrium–pruned subset of 655,046 autosomal SNPs).

---

### Does higher education protect against obesity? Evidence using mendelian randomization [^6ebc8719]. Preventive Medicine (2017). Low credibility.

Objectives

The aim of this explorative study was to examine the effect of education on obesity using Mendelian randomization.

Methods

Participants (N = 2011) were from the on-going nationally representative Young Finns Study (YFS) that began in 1980 when six cohorts (aged 30, 33, 36, 39, 42 and 45 in 2007) were recruited. The average value of BMI (kg/m 2) measurements in 2007 and 2011 and genetic information were linked to comprehensive register-based information on the years of education in 2007. We first used a linear regression (Ordinary Least Squares, OLS) to estimate the relationship between education and BMI. To identify a causal relationship, we exploited Mendelian randomization and used a genetic score as an instrument for education. The genetic score was based on 74 genetic variants that genome-wide association studies (GWASs) have found to be associated with the years of education. Because the genotypes are randomly assigned at conception, the instrument causes exogenous variation in the years of education and thus enables identification of causal effects.

Results

The years of education in 2007 were associated with lower BMI in 2007/2011 (regression coefficient (b) = -0.22; 95% Confidence Intervals [CI] = -0.29, -0.14) according to the linear regression results. The results based on Mendelian randomization suggests that there may be a negative causal effect of education on BMI (b = -0.84; 95% CI = -1.77, 0.09).

Conclusion

The findings indicate that education could be a protective factor against obesity in advanced countries.

---

### Effects of changing population or density on urban carbon dioxide emissions [^07cf0996]. Nature Communications (2019). High credibility.

We summarize all these properties calculated for Cobb–Douglas (Eq. (3)) and translog (Eq. (5)) models in Supplementary Table 2.

Fitting models with the ridge regression approach

As we have discussed in the main text, multicollinearity is present in the models of Eqs. (3) and (5). This effect happens when at least two predictors in a multiple linear regression are correlated to each other. Under this situation and depending on the degree of correlation among the predictors, ordinary-least-squares estimates of the parameters can be unstable against minor changes in the input data and also display large standard errors. To better illustrate this problem, consider the simple linear modelwhere y is the response variable, x 1 and x 2 are the predictors, and a 1 and a 2 are the linear coefficients. The least-squares estimator for the parameters is usually written as, whereis an n × 1 vector of the response variables, is an n × 2 matrix of the regressors, and n is the number of observations. If the values of predictors are strongly correlated, the inversion of the matrix X T X can become unstable, and consequently lead to unstable estimates for the linear coefficients.

---

### Estimating the "impact" of out-of-home placement on child well-being: approaching the problem of selection bias [^edd25a0c]. Child Development (2009). Low credibility.

This study used data on 2,453 children aged 4–17 from the National Survey of Child and Adolescent Well-Being and 5 analytic methods that adjust for selection factors to estimate the impact of out-of-home placement on children's cognitive skills and behavior problems. Methods included ordinary least squares (OLS) regressions and residualized change, simple change, difference-in-difference, and fixed effects models. Models were estimated using the full sample and a matched sample generated by propensity scoring. Although results from the unmatched OLS and residualized change models suggested that out-of-home placement is associated with increased child behavior problems, estimates from models that more rigorously adjust for selection bias indicated that placement has little effect on children's cognitive skills or behavior problems.

---

### Glial cell deficits are a key feature of schizophrenia: implications for neuronal circuit maintenance and histological differentiation from classical neurodegeneration [^89dfd6ae]. Molecular Psychiatry (2025). Medium credibility.

Necroptosis, another pathological process, is a type of regulated cell death triggered by death receptors and a pathological hallmark in multiple sclerosis. Whether or not necroptosis is relevant for OLs losses in SCZ remains to be established, although cell death of mature OLs is different from that of differentiating OLs. Importantly, not all OLs may be affected by the aforementioned pathological processes. Instead, dysfunctional OLs, some of which undergo degeneration, atrophy or necroptosis, can coexist with unaffected ones.

Recent findings show that cuprizone treatment (a standard approach to study mechanisms of OL death) initiated a caspase-3–dependent form of rapid cell death only in differentiating OLs, while mature OLs did not activate this pathway and exhibited delayed cell death. It is also known that during normal brain development, MCs digest OL progenitor cells, raising the possibility that activated MCs might also phagocytose mature OLs in SCZ. However, Uranova et al. found no evidence for increased OL dystrophy in association with MC activation.

Theoretically, OL deficits may be a consequence of medication, since clozapine and haloperidol treatments have been shown to cause multiple molecular alterations in human cultured OLs. Moreover, antipsychotic treatment has been shown to enhance mitochondrial autophagy in OLs. However, OL numbers were not found to be significantly reduced in macaque monkey brains after chronic exposure to antipsychotics. Moreover, quetiapine was shown to enhance OL regeneration and myelin repair in the cuprizone-induced demyelination mouse model of multiple sclerosis and SCZ. Thus, medication is unlikely to initiate OL death.

With regard to pathophysiological consequences of OL losses, demise of a single OL can lead to loss of myelin sheath for several internodes of 20–60 axons, amplifying the loss to multiple neurons. This will disrupt axonal conductance and metabolic supply of the affected fibres. Thus, massive OL losses will leave high numbers of neurites either partially or completely unmyelinated, contributing to the well-documented, disturbed white matter integrity and network disconnectivity in SCZ. This network disconnectivity might have effects on multiple brain functions, including higher order brain processes. Based on the results of their stereological study, Falkai et al. proposed that the decreased number of OLs in the hippocampus may contribute to cognitive deficits in SCZ by impairing the connectivity of this brain structure. Another stereological study identified reduced OL numbers in the prefrontal cortex. This could also lead to negative effects on glutamate and dopamine functions.

---

### Comparison of direct and indirect methods of estimating health state utilities for resource allocation: review and empirical analysis [^9548be3c]. BMJ (2009). Excellent credibility.

Average relations between direct and indirect utilities across the independent groups were fitted using least squares regression lines, with the constraint that all methods assign the value 1 to perfect health. In each case the scores from the direct method were regressed on the scores from the indirect method, to test the hypothesis that direct utilities could be predicted by applying a linear correction to the indirect utilities. The predictive value of the fitted lines was assessed using an approximate method. Residuals about the fitted line were calculated and standardised with respect to variation between subjects (in both utilities). The method used only those studies that contributed means and standard deviations to the data set. The latter were converted to standard errors. Where a group had been formed (as described above) by pooling values over different health states, average standard errors were used — guaranteed to be greater than the true standard errors in the presence of (unknown) correlations between states. For most studies it was not possible to estimate residual standard deviations accurately because the correlations between direct and indirect utilities were not available. Instead, a conservative approach was employed, leading to underestimates of the absolute magnitude of the standardised residuals. For a fitted line y = a+bx the standardised residual for the point (x ′, y ′) with standard errors (s x, s y) was estimated as (y ′− a − bx ′)÷(s y +| b | s x). The denominator of this expression is guaranteed to be greater than the true residual standard deviation. We applied χ 2 tests to the sums of squares of the estimated standardised residuals. The approximations described here mean that these tests are conservative — they understate the discrepancy between the reported utility values and the fitted lines. Small P values indicate that such discrepancies cannot reasonably be attributed to variation between the respondents contributing to the same study.

---

### Olmesartan medoxomil (Benicar) [^929a8c00]. FDA (2023). Medium credibility.

Regarding the use of olmesartan medoxomil PO (also known as Benicar) in patients with crCl < 40 mL/min:

- No initial adjustment required.
- Monitor renal function. Monitor for hyperkalemia.

---

### Quality initiative in rectal cancer strategy: a qualitative study of participating surgeons [^ef343623]. Journal of the American College of Surgeons (2006). Low credibility.

Background

The Quality Initiative in Rectal Cancer (QIRC) Strategy randomized 16 hospitals across Ontario to the QIRC strategy versus minimal intervention. The strategy included a workshop, recruitment of a local opinion leader (OL), operative demonstrations, postoperative checklists, audit, and feedback. Surgeons at each intervention hospital used a standardized approach to select a local OL from their ranks. We assessed the experiences of OL and non-OL surgeons in the QIRC strategy.

Study Design

Semi-structured qualitative telephone interviews were completed with 8 OLs and 8 non-OL surgeons. Interviews were guided by Grounded Theory. Initial interviews were assessed to ensure that domains of interest were fully explored. Two investigators (FW, MF) independently reviewed all final transcripts and identified themes. Consensus among all investigators was achieved for final themes.

Results

All approached surgeons participated in interviews. Seven themes were identified: surgical OLs with subspecialist expertise were supported; surgical OL requires technical expertise; limited role for local OL on changing physician practice in rectal cancer operations; limited effect of identifying local OL on local interactions; operative demonstrations supported; characteristics of operative demonstrator were important; and perceived positive effect of the QIRC strategy on practice.

Conclusions

The experience of local OLs in this trial appears to be mixed. Although some of the themes support the concept of a local OL, other themes suggest the local OL had a limited role and effect. The overall QIRC strategy, and in particular the operative demonstration, was viewed positively and was perceived to have a positive longterm effect on participants' practice.

---

### Why are we regressing? [^fd8ada5d]. The Journal of Foot and Ankle Surgery (2012). Low credibility.

In this first of a series of statistical methodology commentaries for the clinician, we discuss the use of multivariate linear regression.

---

### When can group level clustering be ignored? Multilevel models versus single-level models with sparse data [^a2891d87]. Journal of Epidemiology and Community Health (2008). Low credibility.

Objective

The use of multilevel modelling with data from population-based surveys is often limited by the small number of cases per level-2 unit, prompting many researchers to use single-level techniques such as ordinary least squares regression.

Design

Monte Carlo simulations are used to investigate the effects of data sparseness on the validity of parameter estimates in two-level versus single-level models.

Setting

Both linear and non-linear hierarchical models are simulated in order to examine potential differences in the effects of small group size across continuous and discrete outcomes. Results are then compared with those obtained using disaggregated techniques (ordinary least squares and logistic regression).

Main Results

At the extremes of data sparseness (two observations per group), the group level variance components are overestimated in the two-level models. But with an average of only five observations per group, valid and reliable estimates of all parameters can be obtained when using a two-level model with either a continuous or a discrete outcome. In contrast, researchers run the risk of Type I error (standard errors biased downwards) when using single-level models even when there are as few as two observations per group on average. Bias is magnified when modelling discrete outcomes.

Conclusions

Multilevel models can be reliably estimated with an average of only five observations per group. Disaggregated techniques carry an increased risk of Type I error, even in situations where there is only limited clustering in the data.

---

### Improved prediction of rates of visual field loss in glaucoma using empirical bayes estimates of slopes of change [^644fd815]. Journal of Glaucoma (2012). Low credibility.

Purpose

To describe and test a new methodology for estimation of rates of progressive visual field loss in glaucoma.

Methods

This observational cohort study enrolled 643 eyes of 368 patients recruited from the Diagnostic Innovations in Glaucoma Study, followed for an average of 6.5 ± 2.0 years. The visual field index was used to evaluate degree of visual field loss in standard automated perimetry. Growth mixture models were used to evaluate visual field index changes over time. Empirical Bayes estimates of best linear unbiased predictions (BLUPs) were used to obtain slopes of change based on the first 5 visual fields for each eye. These slopes were then used to predict future observations. The same procedure was done for ordinary least squares (OLS) estimates. The mean square error of the predictions was used to compare the predictive performance of the different methods.

Results

The growth mixture model successfully identified subpopulations of nonprogressors, slow, moderate, and fast progressors. The mean square error was significantly higher for OLS compared with the BLUP method (32.3 vs 13.9, respectively; P < 0.001), indicating a better performance of the BLUP method to predict future observations. The benefit of BLUP predictions was especially evident in eyes with moderate and fast rates of change.

Conclusions

Empirical Bayes estimates of rates of change performed significantly better than the commonly used technique of OLS regression in predicting future observations. Use of BLUP estimates should be considered when evaluating rates of functional change in glaucoma and predicting future impairment from the disease.

---

### Return on investment of enhanced behavioral health services… [^15775fba]. JAMA Network (2025). Excellent credibility.

Hawrilenko M, Smolka C, Ward E, et al. Return on Investment of Enhanced Behavioral Health Services. JAMA Netw Open. 2025; 8: e2457834. doi:
10. 1001/jamanetworkopen.
2024. 57834 eMethods eResults. A and B, Pre to post changes in total cost of care are presented by medical risk and high-cost condition. The gray markers at the bottom of panel A represent the distribution of risk scores. The distance between regression lines represents the difference-in-differences at a given risk score. C, High-cost condition savings estimates are plotted at the average risk level for members with that condition. Behavioral health diagnoses were obtained via medical claims data and the program electronic medical record system, and they were defined as International Statistical Classification of Diseases, Tenth Revision codes between F01 and F99 among the first 3 diagnosis codes. The last diagnosis in the index month was used as the index diagnosis.

Nearest neighbor matching was used to match users to nonusers at up to a 1: 2 ratio using the following criteria: employer, behavioral health diagnosis category, log-transformed medical risk score, age, sex, and date of diagnosis. A caliper of standardized mean difference of 0. 1 was applied to medical risk scores to prioritize high-quality matches. Weights were used to adjust for participants who only received 1 match. An ROI multiple of 1. 0 represents full cost offset, with values greater than

1. 0 indicating net-positive ROI. Service categories were analyzed by fitting separate models to the spending accrued for each category, further stratified by whether spending was associated with a behavioral health diagnosis. Two-tailed P <. 05 was considered statistically significant.

Data were analyzed using R, version 4. 4, and the R software package survey.
37. Assessment of the parallel trends assumption found that match groups had nearly identical medical spending trends prior to their index date, implying suitability of the data for difference-in-differences modeling.

---

### Statistical methods in epidemiology. VI. correlation and regression: the same or different? [^0a3b90e5]. Disability and Rehabilitation (2000). Low credibility.

Purpose

The statistical terms 'correlation' and 'regression' are frequently mistaken for each other in the scientific literature. Why this is so is unclear. This paper discusses their differences/ similarities arguing that in most circumstances regression is the most appropriate technique to use, since regression incorporates a notion of dependency of one variable on another.

Method

Pearson's correlation coefficient (r) is introduced as a method for estimating the degree of linear association between two normally distributed variables. The problem of least squares' regression (when y depends on x) is introduced by considering the best-fitting straight line between points on a scatter plot.

Results

Correlation, regression analysis and residual estimation are discussed by taking examples from the author's own teaching experiences.

Conclusions

Correlation and regression share some similarities. However, regression is the better technique to use because with it comes a notion of dependency of one variable upon another. Regression model checking includes residual examination. The importance of plotting and examination of residuals cannot be overemphasized. Residual examination should become as much a part of a regression analysis as the estimation of the regression coefficients themselves.

---

### Regression: understanding what covariates and confounds Do in adjusted analyses [^204cc71f]. The Journal of Clinical Psychiatry (2024). Medium credibility.

The use of regression analysis is common in research. This article presents an introductory section that explains basic terms and concepts such as independent and dependent variables (IVs and DVs), covariates and confounds, zero-order correlations and multiple correlations, variance explained by variables and shared variance, bivariate and multivariable linear regression, line of least squares and residuals, unadjusted and adjusted analyses, unstandardized (b) and standardized (β) coefficients, adjusted R 2, interaction terms, and others. Next, this article presents a more advanced section with the help of 3 examples; the raw data files for these examples are included in supplementary materials, and readers are encouraged to download the data files and run the regressions on their own in order to better follow what is explained in the text (this, however, is not mandatory, and readers who do not do so can also follow the discussions in the text). The 3 examples illustrate many points. When important covariates are not included in regressions, the included IVs explain a smaller proportion of the variance in the DV, and the relationships between the included IVs and the DV may not be correctly understood. Including interaction terms between IVs can improve the explanatory value of the model whether the IVs are intercorrelated or not. When IVs are intercorrelated (such as when one is a confound), although their net effect in multivariable regression may explain a greater proportion of the variance in the DV, their individual b and β coefficients decrease in proportion to the shared variance that is removed. Thus, variables that were found statistically significant in unadjusted analyses may lose statistical significance in fully adjusted analyses. Readers may find it useful to keep these points in mind when running regressions on their data or when reading studies that present their results through regressions.

---

### Quantification of neighborhood-level social determinants of health in the continental United States [^b6de4643]. JAMA Network Open (2020). High credibility.

Regression Analysis

We estimated associations between premature mortality rates in Chicago using the 4 indices derived from the dominant principal components while controlling for the violent crime rate. The indices were used as input to retain the greatest information rather than as k-means clusters because transforming the continuous principal components to discrete clusters invariably results in the loss of information. First, we estimated a linear regression model using ordinary least squares (OLS) estimation. A spatial weight matrix was constructed for the census tract data set using second-order queen contiguity, assigning bordering neighbors (up to 2 census tracts away) for each tract. We implemented a spatial autoregressive (SAR) model, incorporating spatially lagged mortality and 2-stage least squares estimation.

---

### Advanced statistics: linear regression, part I: simple linear regression [^18239641]. Academic Emergency Medicine (2004). Low credibility.

Simple linear regression is a mathematical technique used to model the relationship between a single independent predictor variable and a single dependent outcome variable. In this, the first of a two-part series exploring concepts in linear regression analysis, the four fundamental assumptions and the mechanics of simple linear regression are reviewed. The most common technique used to derive the regression line, the method of least squares, is described. The reader will be acquainted with other important concepts in simple linear regression, including: variable transformations, dummy variables, relationship to inference testing, and leverage. Simplified clinical examples with small datasets and graphic models are used to illustrate the points. This will provide a foundation for the second article in this series: a discussion of multiple linear regression, in which there are multiple predictor variables.

---

### Oligodendroglial excitability mediated by glutamatergic inputs and nav1.2 activation [^523641fc]. Nature Communications (2017). Medium credibility.

Fig. 3
Morphology and physiological properties of excitable vs. non-excitable pre-OLs and mature OLs. a – c Confocal images of excitable pre-OLs a, non-excitable pre-OLs b, and mature OLs c, which were filled with Alexa 568 during whole-cell recordings. Scale bar, 10 μm. d – f Representative traces of Na v -mediated currents generated by voltage steps (from –100 to 40 mV for d and e, from –110 to 30 mV for f) in excitable pre-OLs, non-excitable pre-OLs and mature OLs. Gray arrows indicate both peak outward currents (I peak) and steady-state outward currents (I peak), and the red arrow indicates inward currents. Inset, expanded time scale of inward currents from excitable pre-OLs (scale; 2 ms and 400 pA, d). g – i Current–voltage (I – V) relationship for I peak (black), I steady (gray), and I inward (red) from excitable pre-OLs g. I-V relationship for I peak (black) and I steady (gray) from non-excitable pre-OLs h and mature OLs i. Data represent the mean ± s.e.m. j Excitable pre-OLs fired APs in response to current injections (> 50 pA, 300 ms) in current-clamp mode. k, l Recordings of membrane potential from a non-excitable pre-OL k and a mature OL l in response to current injections (300 ms, from –80 to 200 pA for k, and –50 to 400 pA for l). Dashed lines indicate the resting membrane potential

---

### Limitations of ordinary least squares models in analyzing repeated measures data [^303d6265]. Medicine and Science in Sports and Exercise (2004). Low credibility.

Purpose

To a) introduce and present the advantages of linear mixed models using generalized least squares (GLS) when analyzing repeated measures data; and b) show how model misspecification and an inappropriate analysis using repeated measures ANOVA with ordinary least squares (OLS) methodology can negatively impact the probability of occurrence of Type I error.

Methods

The effects of three strength-training groups were simulated. Strength gains had two slope conditions: null (no gain), and moderate (moderate gain). Ten subjects were hypothetically measured at five time points, and the correlation between measurements within a subject was modeled as compound symmetric (CS), autoregressive lag 1 (AR(1)), and random coefficients (RC). A thousand data sets were generated for each correlation structure. Then, each was analyzed four times — once using OLS, and three times using GLS, assuming the following variance/covariance structures: CS, AR(1), and RC.

Results

OLS produced substantially inflated probabilities of Type I errors when the variance/covariance structure of the data set was not CS. The RC model was less affected by the actual variance/covariance structure of the data set, and gave good estimates across all conditions.

Conclusions

Using OLS to analyze repeated measures data is inappropriate when the covariance structure is not known to be CS. Random coefficients growth curve models may be useful when the variance/covariance structure of the data set is unknown.

---

### Repeated measures designs and analysis of longitudinal data: If at first you Do not succeed-try, try again [^51e44956]. Anesthesia and Analgesia (2018). Low credibility.

Marginal Models: GEEs

A GEE can be used to estimate the regression parameters for the expected (mean) response of an outcome given a set of explanatory variables while accounting for repeated measurements on same subjects. To account for nonindependence, the analyst needs to specify a working correlation structure, which represents the assumed correlation of the repeated measurements. Figure 3 shows a schematic representation of a selection of different working correlation structures.

Figure 3.
Schematic representation of 4 working correlation structures commonly used in GEE estimation (A–D). The numbers 1–5 represent repetitive measurements, and the shade of the box represents the correlation between the 2 measurements, with a darker shade representing a stronger correlation. For example, the box on the cut-point between first row and third column (or vice versa) represents the correlation between the first and third measurements. While the correlation of a value with itself is always 1 (represented by the black boxes on the diagonal line), the off-diagonal correlations differ between the correlation structures. A, The independent correlation structure assumes uncorrelated measurements. B, Compound symmetry assumes all off-diagonal correlations to be equal. C, The autoregressive structure assumes decreasing correlations as the time interval increases. D, Unstructured correlation makes no assumptions and allows all correlations to differ. GEE indicates generalized estimating equation.

The exchangeable structure (also termed "compound symmetry") assumes all correlations to be equal. The autoregressive structure assumes correlations to decrease as the time interval between the measurements increases. An unstructured correlation makes no assumptions about the structure and allows each correlation to be different. The GEE procedure, using robust standard errors, has the desirable property that its estimates are rather robust against misspecifications of the working correlation structure, and it will often still produce valid results, especially when the sample size is reasonably large.

As the marginal approach models the mean response, the interpretation refers to population-average effects of the predictor variables. The regression parameters thus allow inferences on how the mean outcome, averaged over the whole population, is expected to change relative to changes in the independent variable(s).

---

### Postpandemic recovery of case mix index and risk-adjusted mortality in US hospitals [^98561a17]. JAMA Network Open (2025). High credibility.

Importance

The COVID-19 pandemic disrupted long-standing trends in hospital quality and patient safety, prompting questions about whether risk-adjusted outcomes have resumed their prepandemic trajectories.

Objective

To determine whether trends in risk-adjusted mortality and case mix index (CMI) among hospitalized patients in hospitals have returned to prepandemic trajectories.

Design, Setting, and Participants

This retrospective cohort study was a multicenter analysis that used the Vizient Clinical Data Base, which contains encounter-level administrative and financial data from more than 1300 hospitals in the US. The study included continuously reporting hospitals and examined inpatient discharges between October 2019 and March 2024. Data were analyzed between January and May 2025.

Main Outcomes and Measures

Quarterly estimates of CMI and standardized mortality ratio (SMR) (observed-to-expected ratio). Ordinary least squares (OLS) regression was used to evaluate overall linear trends, and joinpoint regression was used to identify inflection points. Statistical significance was defined as P < .05, with slope estimates reported alongside 95% CIs.

Results

Among 715 hospitals and 7 802 606 million inpatient encounters, the mean CMI increased from 1.70 in the fourth quarter (Q4) of 2019 to 1.79 in the first quarter (Q1) of 2024 (difference, 0.09; 95% CI, 0.01 to 0.17; P = 0.02). In OLS regression, CMI showed no significant overall linear trend (R2 = 0.006; P = 0.77). The mean SMR decreased from 1.00 in Q4-2019 to 0.80 in Q1-2024 (difference, -0.20; 95% CI, -0.32 to -0.08; P = 0.001), with a significant linear decline across the study period (R2 = 0.735; P < .001). Joinpoint regression identified a CMI inflection point in Q4-2020 (slope, 1.85; 95% CI, 0.73 to 4.14; P < .001 before; slope, -0.30; 95% CI, -0.62 to -0.09; P = 0.006 after) and an SMR inflection point in Q3-2021, after which SMR declined significantly by -3.17% per quarter (P < .05).

Conclusions and Relevance

In this cohort study of 715 US hospitals from 2019 to 2024, risk-adjusted in-hospital mortality declined significantly following the COVID-19 pandemic, resuming its prepandemic trajectory of improvement, while patient acuity as measured by CMI remained elevated. These findings suggest a new postpandemic baseline for patient acuity, whereas hospital mortality outcomes have returned to prior improvement trends.

---

### Educational attainment and mental health outcomes: a within-sibship mendelian randomization study [^9b2585ae]. Psychological Medicine (2025). Medium credibility.

Figure 1.
Educational attainment and symptoms of anxiety. Standard deviation (SD) changes in the anxiety score and its 95% confidence interval per SD increase in years of education are shown. Estimated associations are displayed for ordinary least squares regression (OLS) and Mendelian randomization models. Note: SD, 'standard deviation unit'; OLS EA, 'ordinary least squares regression model with educational attainment as exposure'; OLS PGS-edu, 'ordinary least squares regression model with the educational attainment polygenic score as exposure'; 1SMR, 'one-sample Mendelian randomization'.

Figure 2.
Educational attainment and symptoms of depression. Standard deviation (SD) changes in the depression score and its 95% confidence interval per SD increase in years of education are shown. Estimated associations are displayed for ordinary least squares regression (OLS) and Mendelian randomization models. Note: SD, 'standard deviation unit'; OLS EA, 'ordinary least squares regression model with educational attainment as exposure'; OLS PGS-edu, 'ordinary least squares regression model with the educational attainment polygenic score as exposure'; 1SMR, 'one-sample Mendelian randomization'; 2SMR, 'two-sample Mendelian randomization'.

Figure 3.
Educational attainment and neuroticism. Standard deviation (SD) changes in the neuroticism score and its 95% confidence interval per SD increase in years of education are shown. Estimated associations are displayed for ordinary least squares regression (OLS) and Mendelian randomization models. Note: SD, 'standard deviation unit'; OLS EA, 'ordinary least squares regression model with educational attainment as exposure'; OLS PGS-edu, 'ordinary least squares regression model with the educational attainment polygenic score as exposure'; 1SMR, 'one-sample Mendelian randomization'; 2SMR, 'two-sample Mendelian randomization'.

Figure 4.
Educational attainment and use of psychotropic medication. Log odds changes in psychotropic medication use and its 95% confidence interval per SD increase in years of education are shown. Estimated associations are displayed for logistic regression (LOG) and Mendelian randomization models. Note: SD, 'standard deviation unit'; LOG EA, 'logistic regression model with educational attainment as exposure'; LOG PGS-edu, 'logistic regression model with the educational attainment polygenic score as exposure'; 1SMR, 'one-sample Mendelian randomization'.

---

### The burden of proof studies: assessing the evidence of risk [^33867457]. Nature Medicine (2022). Excellent credibility.

Monotonicity

We imposed monotonicity constraints using several linear inequality constraints based on exemplar exposures. Given an exemplar exposure x i, the requirement that the slope of the spline at exposure x i, be non-negative can be formulated asfor a computed vector X i. Linear inequality constraints were strictly enforced by the optimization solver used to fit the model, see Zheng et al.

Robust trimming strategy

To make the estimation of the overall relationship insensitive to potential outlying studies or observations within studies, we applied a robust, likelihood-based statistical approach — least trimmed squares (LTS) — to our mixed-effects models. The goal of robust statistical methods is to ensure that estimates are robust to outlying observations. Trimming approaches form a subclass of robust statistical methods, and LTS was originally developed in the context of linear regression. LTS works by classifying observations into a majority of inliers and minority of outliers while simultaneously fitting the model with respect to which the inlier/outlier classification is made. Compared with other robust approaches, such as M-estimators, trimming methods are more effective in limiting influence than outliers, and have a high breakdown point, that is, the proportion of the data that can be arbitrarily corrupted before the estimator becomes invalid.

Trimming estimators have been applied to a broad range of problems, from linear regressionto high-dimensional sparse regression and general machine learning problems. In the context of mixed-effects models, trimming methods are far and away the most effective robust tools currently available for meta-analysis. In practice, the approach requires only a specified inlier proportion, which was set to 90% across all examples, that is, we fit the 90% most self-coherent data points.

Using this approach, we trimmed 10% of the observations as part of the model fitting process, simultaneously discovering and fitting the most self-coherent 90% of the observations. Numerical studies in data-rich cases have shown that quality of estimation is unaffected by trimming, even when there are no outliers in the data. In the meta-analytic regime, the 90% level is a heuristic that balances the sparsity of available data with the need to improve estimates in the presence of outliers. This step also substantially decreased the number of risk–outcome pairs with evidence of residual publication or reporting bias.

---

### Dicer1 and miR-219 are required for normal oligodendrocyte differentiation and myelination [^61eaeaf2]. Neuron (2010). Low credibility.

To investigate the role of microRNAs in regulating oligodendrocyte (OL) differentiation and myelination, we utilized transgenic mice in which microRNA processing was disrupted in OL precursor cells (OPCs) and OLs by targeted deletion of Dicer1. We found that inhibition of OPC-OL miRNA processing disrupts normal CNS myelination and that OPCs lacking mature miRNAs fail to differentiate normally in vitro. We identified three miRNAs (miR-219, miR-138, and miR-338) that are induced 10-100x during OL differentiation; the most strongly induced of these, miR-219, is necessary and sufficient to promote OL differentiation, and partially rescues OL differentiation defects caused by total miRNA loss. miR-219 directly represses the expression of PDGFRalpha, Sox6, FoxJ3, and ZFP238 proteins, all of which normally help to promote OPC proliferation. Together, these findings show that miR-219 plays a critical role in coupling differentiation to proliferation arrest in the OL lineage, enabling the rapid transition from proliferating OPCs to myelinating OLs.

---

### Dissecting the effect of workplace exposures on workers' rating of psychological health and safety [^efb7f36a]. American Journal of Industrial Medicine (2019). Medium credibility.

Table 4
Standardized ordinary least‐squared linear regression estimates for dimensions of the COPSOQ and perceived psychological health and safety in the workplace, stratified by sex

Table 5
Standardized ordinary least‐squared linear regression estimates for dimensions of the COPSOQ and perceived psychological health and safety in the workplace, stratified by categories of gendered labor market roles

Table 6
Standardized ordinary least‐squared linear regression estimates for dimensions of the COPSOQ and perceived psychological health and safety in the workplace, stratified by age groups

---

### Clinical management update of oral leukoplakia: a review from the American head and neck society cancer prevention service [^02191e7c]. Head & Neck (2025). Medium credibility.

4 Clinical Management: Definitive Treatment

The first step in definitive management should involve counseling and treatment for cessation of alcohol, tobacco, betel quid, marijuana, vaping, and any other potential etiologies of OL. This can be completed as part of the initial consultation using simple cessation techniques and methods, such as nicotine replacement for tobacco smokers. Further consultations can be made for medical management of cessation, treatment of comorbid psychiatric conditions or referral to detoxification or rehab centers depending upon the need of the patient. There is a significant effort being made to bring cessation counseling to the forefront of head and neck cancer treatment, at the time of initial consultation. The same opportunity exists at the time of consultation for OL, with the potential for prevention being even greater at this earlier stage of recognition.

Treatment options for OL include observation, surgical or laser excision, laser ablation, and chemoprevention. Often, treatment depends upon the size and characteristics of the lesion. For example, a small, well‐defined, localized lesion may be amenable to excision (either surgical or laser removal) with low morbidity, whereas larger, diffuse lesions may require consideration for alternative methods such as topical or systemic chemoprevention.

In 2023, Zhou et al. completed a review of studies that examined excision of oral precancerous lesions with attention to rate of recurrence and MT. They found a pooled recurrence rate from 13 studies comprising 907 patients showed a 29.5% recurrence after scalpel excision and a 32.2% recurrence after laser excision. For patients with OL, the pooled rate of MT was 8.9% for scalpel excision, 6% for laser, and 10.2% for clinical observation, without statistically significant difference (Table 1). Thus, neither surgical nor laser excision is superior in regard to recurrence rates of OL or preventing MT. Another recent review with meta‐analysis examining laser compared to standard treatment shows no statistical difference in MT rates between scalpel and laser excision. This demonstrates the need for close follow‐up regardless of treatment provided and the need for additional prospective trials to validate diagnostic adjuncts and treatment of OL to intervene in high‐risk patients.

---

### Healthcare expenditures associated with depression among individuals with osteoarthritis: post-regression linear decomposition approach [^02d93582]. Journal of General Internal Medicine (2015). Low credibility.

Background

Depression is common among individuals with osteoarthritis and leads to increased healthcare burden. The objective of this study was to examine excess total healthcare expenditures associated with depression among individuals with osteoarthritis in the US.

Design

Adults with self-reported osteoarthritis (n = 1881) were identified using data from the 2010 Medical Expenditure Panel Survey (MEPS). Among those with osteoarthritis, chi-square tests and ordinary least square regressions (OLS) were used to examine differences in healthcare expenditures between those with and without depression. Post-regression linear decomposition technique was used to estimate the relative contribution of different constructs of the Anderson's behavioral model, i.e., predisposing, enabling, need, personal healthcare practices, and external environment factors, to the excess expenditures associated with depression among individuals with osteoarthritis. All analysis accounted for the complex survey design of MEPS.

Key Results

Depression coexisted among 20.6% of adults with osteoarthritis. The average total healthcare expenditures were $13,684 among adults with depression compared to $9284 among those without depression. Multivariable OLS regression revealed that adults with depression had 38.8% higher healthcare expenditures (p < 0.001) compared to those without depression. Post-regression linear decomposition analysis indicated that 50% of differences in expenditures among adults with and without depression can be explained by differences in need factors.

Conclusions

Among individuals with coexisting osteoarthritis and depression, excess healthcare expenditures associated with depression were mainly due to comorbid anxiety, chronic conditions and poor health status. These expenditures may potentially be reduced by providing timely intervention for need factors or by providing care under a collaborative care model.

---

### Counterfactual reasoning underlies the learning of priors in decision making [^0689aebd]. Neuron (2018). Low credibility.

A similar logistic regression model was fit to confidence (Figure 4 F):whereis the probability of a high-confidence report, h is the choice (left or right) to account for potential differences in confidence due to chosen side, and a is the accuracy of the response (0 or 1 for incorrect and correct decisions respectively). Figure 4 F (bottom) shows thecoefficients. The extra terms are included as potential confounders.

The same regressions were used for both data and model in Figures 4 C and 4F. For the model, we conducted the logistic regressions independently for 200 simulations the model and then averaged the regression coefficients. The standard errors (gray shading) are the standard deviation of the coefficients from the 200 simulations. The model was evaluated on the same sequence of trials as the participants.

To test the influence of motion strength onBelief (Figure S5), we fit the following linear regression model:whereBelief is the difference between the belief reported in the current trial and the belief reported in the previous trial (or the difference from ½ for the first trial of the block). To simplify the regression model, Belief was multiplied by −1 when the subject chose the leftward direction of motion. Therefore a positiveBelief indicates a change in the direction of the choice. Accordingly, is the belief in the current trial (see Figure 6) relative to the actual choice (i.e.is equal to the reported belief for rightward choices, and to one minus the reported belief for leftward choices). As in Figure S5, only correct trials were used for the regression model.

We used the following logistic regression model to test the influence of the block's base rate on the choices for 0% coherence trials:whereis the probability that the choice is made in the direction considered most likely by the subject, that is, consistent with the belief reported on the previous trial. In the regression analysis we only included trials of 0% motion strength and those in which the belief in the previous trial was either lower than 0.05 or higher than 0.95.

In the analysis of Figure 8, we used the MSE between the reported belief and the model prediction to compare the goodness-of-fit of the models with and without lag. We evaluated the significance of the difference in the MSE by simulating each model 200 times, and defining the p value as the proportion of times in which the model with lag had a lower MSE than the Bayesian model.

---

### The need for data harmonization – a response to boden and ozonoff [^68de19d2]. American Journal of Industrial Medicine (2010). Low credibility.

Boden and Ozonoff's undercount estimates in their recent Commentary rely on three assumptions for which no quantitative literature references are provided. Alternatively, we show that findings in both studies and published data indicate lower upper-bound estimates for the undercount range. Am. J. Ind. Med. 53:854–855, 2010. (c) 2010 Wiley-Liss, Inc.

---

### Comparison of direct and indirect methods of estimating health state utilities for resource allocation: review and empirical analysis [^aad75437]. BMJ (2009). Excellent credibility.

Table 7
Pairwise comparisons between and within direct and indirect methods

NA = not applicable. Second column shows numbers of states contributing to mean and SD of the difference. Sign tests and regression analyses are based on aggregate health states obtained from averaging data within independent groups of participants. Regression slopes refer to least squares lines for predicting direct utility from indirect utility, constrained to pass through the point (1,1). Predictive P-values assess the goodness-of-fit of the lines, taking variation within studies into account.

The discrepancy between individual direct and indirect measures is reflected in figure 3. These plots are constructed using information taken directly from the studies, without aggregation into independent groups. If direct and indirect methods gave the same results, then the points would be distributed equally above and below the 45° line in each panel. The great majority of points in all panels, however, fell above this line. In each panel, the broken line represents the predicted direct utility score from a regression on the indirect score, as computed from the "current patient" comparisons. Table 7 shows the slopes for these lines and those based on hypothetical comparisons. The lines represent average relations only, with statistically significant (P < 0.05) departures from the line in all but one instance, which was based on very low sample numbers. This finding suggests that the variation between participants within studies was not sufficient to account for the discrepancies between the plotted points and the fitted lines. At best, these lines characterise "average" relations between direct and indirect methods across a collection of different health states; it cannot be assumed that they will produce accurate conversions from one type of utility to another.

Fig 3 Direct utilities against indirect utilities. Plotted points are means (if available) or medians from health-states within 28 studies. Vertical and horizontal lines represent standard errors cited (or deduced) within the studies. Broken lines are regressions of direct on indirect utilities from current patient comparisons. In top left panel, one (hypothetical) point lies off the scale, with EQ-5D = −0.52, time trade off = −0.17.

---

### Primer on binary logistic regression [^4e5ef025]. Family Medicine and Community Health (2021). Medium credibility.

The twovalues are below two and so are not problematic. For this model, the no perfect multicollinearity assumption is met.

The linearity assumption requires that continuous independent variables, or predictors, have a linear relationship with the log-odds of the predicted probabilities for the outcome. Linear relationships are relationships that seem to follow a relatively straight line. One way to check this relationship is to create a scatterplot with the continuous predictor on the x-axis and the log-odds of the predicted probabilities on the y-axis. Add a loess curve and a line representing a linear relationship between the two variables to the scatterplot. The loess curve shows the relationship between the predictor and the transformed outcome in a more nuanced way, while the fitted line shows what the relationship between the two would be if it were linear. If the loess curve and the fitted line are approximately the same, the linearity assumption is met. If the loess curve deviates from the line, the linearity assumption fails.

The loess curve is very close to the linear relationship so the linearity assumption appears to be met (figure 2). Assuming that these data were collected using an acceptable sampling frame without related observations (independence of observations assumption), the data meet the assumptions to report the model as unbiased.

Figure 2
Checking the linearity assumption graphically.

Step 3: estimate the binary logistic regression model

The dependent variable for binary logistic regression is a categorical variable with two categories (denoted as y in equation 1). In the statistical model it is transformed using the logit transformation into a probability ranging from 0 to 1 (equation 1).

Equation 1. A statistical form of the binary logistic regression model.

In equation 1, the p(y) stands for the probability of one category (often the presence of a behaviour or condition) of the dependent variable, theare coefficients of the independent variables or predictors, and theare the independent variables. Those who are familiar with linear regression might notice that the statistical form of the linear regression model is inside the parentheses of the exponent ofin the denominator of the right-hand side of the equation.

---

### Calcium, magnesium, potassium, and sodium oxybates (Xywav) [^76ce2712]. FDA (2025). Medium credibility.

Patients entering the study were taking a stable dosage of 1) Xyrem only, 2) Xyrem + another anticataplectic, 3) a non-Xyrem anticataplectic, or 4) were cataplexy‑treatment naïve. Patients taking Xyrem at study entry were switched (at a gram for gram dose) from Xyrem to XYWAV for a minimum of 2 weeks and titrated, if needed, to a stable, tolerable, and effective dosage over 8 weeks. Most patients who switched from Xyrem to XYWAV (41/59; 69%) had no change in dosage from study entry to the stable dose period; 27% (16/59) had an increase in dosage, and 3% (2/59) had a decrease in dosage. Among patients whose dosage was changed, most changes were within one titration step (≤ 1.5 g). Patients not taking Xyrem at study entry were initiated at 4.5 g/night of XYWAV and titrated at a rate of 1 or 1.5 g/night/week to a tolerable dose of XYWAV. Patients taking an anticataplectic other than Xyrem were tapered off the non-Xyrem anticataplectic over 2 to 8 weeks. All patients continued to receive XYWAV only, for the treatment of cataplexy during the last 2 weeks of the OL OTTP.

---

### US Cystic Fibrosis Foundation and European Cystic Fibrosis Society consensus recommendations for the management of non-tuberculous mycobacteria in individuals with cystic fibrosis [^2952d7d7]. Thorax (2016). Medium credibility.

Cystic Fibrosis Foundation and European Cystic Fibrosis Society risk factors and infection control — minimise potential cross-infection of NTM (particularly Mycobacterium abscessus complex [MABSC]) between individuals with CF by following national infection control guidelines; CF-related lung disease is a clear risk factor for NTM-PD; rates of heterozygosity for CFTR mutations within the non-CF population with pulmonary NTM disease are high (30–50%); there have been conflicting reports on the relationship between spirometry and NTM-positive samples, and the prevalence of NTM-positive sputum samples in patients referred for lung transplantation has been reported to be as high as 19.7%.

---

### Compared with what? Estimating the effects of injury prevention policies using the synthetic control method [^e89a466f]. Injury Prevention (2018). Low credibility.

Introduction

This paper discusses the application of the synthetic control method to injury-related interventions using aggregate data from public information systems. The method selects and determines the optimal control unit in the data by minimising the difference between the pre-intervention outcomes in one treated unit (eg, a state) and a weighted combination of potential control units.

Method

I demonstrate the synthetic control method by an application to Florida's post-2010 policy and law enforcement initiatives aimed at bringing down opioid overdose deaths. Using opioid-related mortality data for a panel of 46 states observed from 1999 to 2015, the analysis suggests that a weighted combination of Maine (46.1%), Pennsylvania (34.4%), Nevada (5.4%), Washington (5.3%), West Virginia (4.3%) and Oklahoma (3.4%) best predicts the preintervention trajectory of opioid-related deaths in Florida between 1999 and 2009. Model specification and placebo tests, as well as an iterative leave- k -out sensitivity analysis are used as falsification tests.

Results

The results indicate that the policies have decreased the incidence of opioid-related deaths in Florida by roughly 40% (or -6.19 deaths per 100.000 person-years) by 2015 compared with the evolution projected by the synthetic control unit. Sensitivity analyses yield an average estimate of -4.55 deaths per 100.000 person-years (2.5th percentile: -1.24, 97.5th percentile: -7.92). The estimated cumulative effect in terms of deaths prevented in the postperiod is 3705 (2.5th percentile: 1302, 97.5th percentile: 6412).

Discussion

Recommendations for practice, future research and potential pitfalls, especially concerning low-count data, are discussed. Replication codes for Stata are provided.

---

### Low measles seropositivity in vaccinated children-JAMA network… [^98fd58c3]. JAMA Network (2025). Excellent credibility.

Data Sharing Statement A and C, The horizontal red dashed line and the vertical red dashed line represent the positivity threshold for measles-specific neutralizing antibodies. B and C, The horizontal red line indicates the positivity threshold for measles-specific IgG. D, The vertical red dashed line represents the positivity threshold for measles-specific immunoglobulin M. C, The horizontal red dashed line represents the positivity threshold for measle-specific neutralizing antibodies. D, The horizontal red line represents the positivity threshold for measles-specific immunoglobulin G. It has a specificity of 100% and a sensitivity of 97. 0%. The IgM ELISA kit has an average intra-assay CV of 4. 29%, an average interassay CV of
6. 94%, with a specificity of 100% and a sensitivity of 100%.

The plates were incubated for 42 hours at 37 °C with 5% CO2. Fluorescent plaques were imaged and quantified using the ImageXpress Nano platform and the MetaXpress software. The 50% neutralizing dose was calculated using the Karber formula and converted to mIU/mL based on the 3rd International Standard Anti-Measles Serum. 8 A neutralizing antibody titer of 120 mIU/mL or higher was considered protective. 7 The assay had a CV of 5. 7% and a detection limit of 15 mIU/mL in our laboratory. Continuous variables are presented as median or mean, as appropriate. Differences in antibody titers between sexes were assessed using the Wilcoxon rank-sum test, while the Kruskal-Wallis test compared titers across vaccine dose groups. Associations between age and antibody titers were evaluated using Spearman correlation. A P <. 05 was considered statistically significant. All analyses were conducted and figures were generated using RStudio version 2024.
09.

0 + 375.

---

### Multinational Association of Supportive Care in Cancer (MASCC) clinical practice guidance for the prevention of breast cancer-related arm lymphoedema (BCRAL): international Delphi consensus-based recommendations [^e4c2ab8b]. EClinicalMedicine (2024). High credibility.

Breast cancer-related arm lymphoedema (BCRAL) prophylactic compression sleeves — The panel stated that prophylactic compression sleeves should be offered as an option for prevention, and clinicians should counsel that benefit beyond one year is uncertain; this is especially relevant for patients receiving axillary lymph node dissection (ALND) plus regional node irradiation where the peak to development is 18–24 months. Sleeves are relatively low cost, minimal risk, and readily available, and because some patients develop BCRAL within the first 6 months after surgery, prophylactic sleeves are a reasonable option for those wishing to minimise early risk.

---

### Oligodendrocyte dynamics in the healthy adult CNS: evidence for myelin remodeling [^8f57b968]. Neuron (2013). Low credibility.

Oligodendrocyte precursors (OPs) continue to proliferate and generate myelinating oligodendrocytes (OLs) well into adulthood. It is not known whether adult-born OLs ensheath previously unmyelinated axons or remodel existing myelin. We quantified OP division and OL production in different regions of the adult mouse CNS including the 4-month-old optic nerve, in which practically all axons are already myelinated. Even there, all OPs were dividing and generating new OLs and myelin at a rate higher than can be explained by first-time myelination of naked axons. We conclude that adult-born OLs in the optic nerve are engaged in myelin remodeling, either replacing OLs that die in service or intercalating among existing myelin sheaths. The latter would predict that average internode length should decrease with age. Consistent with that, we found that adult-born OLs elaborated much shorter but many more internodes than OLs generated during early postnatal life.

---

### Biased expectations about future choice options predict sequential economic decisions [^3a665b76]. Communications Psychology (2024). Medium credibility.

Table 2
Key features of fitted theoretical models

We now turn to descriptions of the three theoretical models that survived parameter recovery and graduated to model comparison. The objective and subjective values versions of the Cut Off heuristic derive from the mathematically optimal solution to the "Secretary problem", an optimal stopping problem with a mathematical solution that is relatively simple, as it is constrained by numerous required assumptions that need not hold for full-information problems. Namely, the secretary problem solution assumes the agent uses no prior knowledge of the generating distribution, considers only relative ranks of option values and feels rewarded only when choosing the top-ranked option. Although the Cut Off heuristic derives from the optimal solution to the secretary problem, which makes different assumptions than the optimality solution of the full information problem we consider here, Todd and Millerpropose that the Cut Off heuristic might nevertheless be robust to violations of the secretary problem assumptions and, being a heuristic, would be relatively simple for humans to compute on the fly in realistic settings. More specifically, Todd & Miller propose that such a Cut Off heuristic explains undersampling bias because the heuristic can perform nearly-optimally (on secretary problems) while incurring fewer samples, which "satisfices" under conditions where the problem involves a ground truth cost for new samples (note that the Cut Off heuristic has no formal cost to sample parameter). This heuristic has previously been fitted to human behaviour on full information optimal stopping problems, although little evidence was found favouring it in that study. The Cut Off heuristic chooses to sample again for every option until it reaches a cut-off sequence position, which is fitted as the key theoretical free parameter. Then, the model continues to sample until it reaches the next option with the highest relative rank so far. Here, we used the optimal cut-off value (37% of the sequence length, rounded to the nearest integer) as the starting value during model fitting and the parameter search was bounded between 2 and the sequence length minus 1 (as the learning period defined by the cut-off must contain at least one sample and be followed by at least one sample available for choice). Cut-off values below the optimal value lead to undersampling and cut-off values above the optimal value lead to oversampling.

---

### Morphological and functional convergence of visual projection neurons from diverse neurogenic origins in drosophila [^f4ed3e67]. Nature Communications (2025). High credibility.

Genetics and immunohistochemistry

Male and female flies were dissected at different developmental stages: late larval stage (L3), 24 h after puparium formation (APF), 48 h APF, 72 h APF, 96 h APF and 3–5 days after eclosion (adult stage). Flies were maintained at 18 °C–25 °C, while crosses were maintained at 25 °C. For FLEXAMP experiments, crosses were maintained at 18 °C, moved to 29 °C for heat shock (12 h–24 h), and then maintained at 18 °C until eclosion. All genotypes used in this study are detailed in Supplementary Table 2. All immunohistochemistry experiments were performed in at least 3 different animals for each genotype. In particular for Fig. 3 A, n = 3 optic lobes (Ol); for Fig. 3 B–D, n = 15 Ol; for Fig. 3E–H, n = 7,9,3,3 Ol respectively; for Fig. 4A–C, n = 5,4,6 Ol respectively; for Fig. 5A, B, n = 6,6 Ol respectively; For Fig. 6A–H, n = 4,6,4,5,5,19,4,7 Ol respectively; for Fig. 7A–D, n = 15,10,10,3 Ol respectively; for Fig. 7F, G, n = 3,4 Ol respectively; for Supplementary Fig. 2B–E, n = 5,3,7,4 Ol respectively; for Supplementary Fig. 3B–D, n = 5,3,7 Ol respectively; for Supplementary Fig. 4B–D, n = 5,4,5 Ol respectively; for Supplementary Fig. 5B–D, n = 7,5,3 Ol respectively; for Supplementary Fig. 6B–D, n = 7,3,6 Ol respectively; for Supplementary Fig. 7B–D, n = 5,3,3 Ol respectively; for Supplementary Fig. 8B–D, n = 5,5,3 Ol respectively; for Supplementary Fig. 9B–D, n = 5,4,4 Ol respectively; for Supplementary Fig. 10 B–D, n = 8,7,5 Ol respectively; for Supplementary Fig. 11B–D, n = 4,4,5 Ol respectively; for Supplementary Fig. 12B–D, n = 4,6,4 Ol respectively; for Supplementary Fig. 13B–D, n = 6,4,3 Ol respectively; and for Supplementary Fig. 14B–D, n = 6,3,6 Ol respectively.

---

### Biased expectations about future choice options predict sequential economic decisions [^819b4ae6]. Communications Psychology (2024). Medium credibility.

Fig. 6
Model comparison for Study 2.

Points in the first and second rows show sampling rates for n = 151 participants. Human participant sampling is reproduced from Fig. 2. In the first row, horizontal solid lines link samples data for humans (black points) and Ideal Observer (grey points) when BF 01 > 3 (at least moderate evidence for equal means) while dotted lines indicate when BF 10 > 3 (at least moderate evidence for different means). Statistical details for these pairwise tests can be found in Supplementary Table 1. Study 2 confirms undersampling is inconsistent at best in the full condition. The second row shows BIC values, where lower values indicate better model fit. Black horizontal lines indicate when BF 01 > 3. When BF 10 > 3, the horizontal line is coloured the same as the point spread of the better model. Statistical details for these pairwise tests can be found in Table 6. Biased Prior (blue) dominates other models. The third row corroborates this conclusion, as Biased Prior model also best fitted the most participants. Model point spread data colours (See also legend in lower right panel): Cost to Sample (green), Cut Off (orange), Biased Prior (blue). Boxplots reflect first, second (median) and third quartiles, while whiskers reflect 1.5 interquartile range. Point spreads reflect individual participant mean values. Abbreviations: Subj = Models that make choices about subjective values; Obj = Models that makes choices about objective values.

---

### Age-related anabolic resistance of myofibrillar protein synthesis is exacerbated in obese inactive individuals [^b1eb8d1a]. The Journal of Clinical Endocrinology and Metabolism (2017). Low credibility.

Correlations

Absolute postprandial MyoPS rates showed a tendency to correlate negatively with leg fat mass [r 2 = 0.20; P = 0.07; Fig. 3(a)] and correlated positively with average daily step count in OL and OO combined [r 2 = 0.33; P = 0.015; Fig. 3(b)]. The net postprandial MyoPS response (i.e. delta change from postabsorptive values) correlated negatively with leg fat mass [r 2 = 0.4; P = 0.006; Fig. 3(c)] and positively with average daily step count for OL and OO combined [r 2 = 0.26; P = 0.036; Fig. 3(d)]. HOMA-IR correlated positively with type I fiber lipid droplet number (r 2 = 0.41; P = 0.018), type I fiber lipid droplet area (r 2 = 0.47; P = 0.009), leg fat mass (r 2 = 0.4; P = 0.007), and average daily step count (r 2 = 0.26; P = 0.036) for OL and OO combined. Although not significant, there was a trend for a negative correlation between the net postprandial MyoPS response and serum CRP in older individuals (r 2 = 0.23; P = 0.050).

Figure 3.
Correlations between (a) absolute postprandial myofibrillar fractional synthesis rate (FSR) and leg fat mass and (b) average daily step count in OL and OO combined. Correlations between (c) the delta change in postprandial myofibrillar FSR from postabsorptive values and leg fat mass and (d) average daily step count in OL and OO combined.

---

### International committee on mental health in cystic fibrosis: Cystic Fibrosis Foundation and European Cystic Fibrosis Society consensus statements for screening and treating depression and anxiety [^52b6db1c]. Thorax (2016). Medium credibility.

Cystic fibrosis — pharmacologic management of depression and anxiety prioritizes selective serotonin reuptake inhibitors (SSRIs), which are recommended by virtually all published guidelines as first-line medications for both depression and anxiety; among options, citalopram, escitalopram, sertraline and fluoxetine are described as more likely to be available inexpensively, covered by health plans, have regulatory approvals in a variety of age groups and minimise the potential for medication interactions and side effects. Because the pharmacokinetics of medications may be altered in cystic fibrosis (CF), optimal dose adjustment requires close monitoring of therapeutic benefits, adverse effects and medical status; dose reduction may be required in individuals with renal or hepatic impairment, treatment-emergent adverse effects or drug–drug interactions, whereas dose increases may be required for those with impaired absorption or enhanced hepatic metabolism, partial response to treatment or drug–drug interactions, and therapeutic drug monitoring of blood levels, when available, may supplement clinical monitoring. Clinicians should address the medical and psychiatric history and ensure that patients are informed of medications used for CF; when used with lumacaftor, the doses of citalopram, escitalopram and sertraline may need to be increased. Linezolid is not recommended for use with serotonergic antidepressants when alternatives are readily available; when both are clinically necessary, the lowest effective doses should be used, with informed consent and monitoring for serotonin syndrome. QTc prolongation is more likely with citalopram than other SSRIs, and electrocardiogram (EKG) and electrolyte monitoring can be considered when simultaneous use of multiple medications known to prolong the QTc is clinically necessary.

---

### Primer on binary logistic regression [^8c5f1975]. Family Medicine and Community Health (2021). Medium credibility.

Family medicine has traditionally prioritised patient care over research. However, recent recommendations to strengthen family medicine include calls to focus more on research including improving research methods used in the field. Binary logistic regression is one method frequently used in family medicine research to classify, explain or predict the values of some characteristic, behaviour or outcome. The binary logistic regression model relies on assumptions including independent observations, no perfect multicollinearity and linearity. The model produces ORs, which suggest increased, decreased or no change in odds of being in one category of the outcome with an increase in the value of the predictor. Model significance quantifies whether the model is better than the baseline value (ie, the percentage of people with the outcome) at explaining or predicting whether the observed cases in the data set have the outcome. One model fit measure is the count- [Formula: see text], which is the percentage of observations where the model correctly predicted the outcome variable value. Related to the count- [Formula: see text] are model sensitivity-the percentage of those with the outcome who were correctly predicted to have the outcome-and specificity-the percentage of those without the outcome who were correctly predicted to not have the outcome. Complete model reporting for binary logistic regression includes descriptive statistics, a statement on whether assumptions were checked and met, ORs and CIs for each predictor, overall model significance and overall model fit.

---

### Biased expectations about future choice options predict sequential economic decisions [^49921c9c]. Communications Psychology (2024). Medium credibility.

Here, we set the prior values of μ and σ 2 in two possible ways: objective value and subjective values versions. In some previous studies of optimal stopping for price decisions, the mean and variance of the generating distribution has been fixed in advance by the mean and variance of the distribution of objective prices. We implemented an objective values version of the Ideal Observer in this way for all the study conditions reported herein. This objective values procedure for the Ideal Observer assumes that the raw prices can be treated as a proxy for participants' subjective value of the prices, so an Ideal Observer that optimises only the raw prices when making decisions would therefore be an appropriate basis for comparison with participants. However, we also had direct access to participants' subjective values of options in some conditions (Pilot full, Study 1 full condition, Study 1 ratings condition, Study 2 and both sequence length conditions of Study 3), due to the presence of the initial rating phase, and so we could also build a subjective values version of the Ideal Observer. This second way of computing the Ideal Observer assumes that participants' subjective valuation of prices may not necessarily exactly equal the raw price values, especially in their scaling, which may be relevant to full information problems. We used each participants' individualised ratings (subjective valuations) of the prices as option values input to the subjective values version of the Ideal Observer, and we used the mean and variance of individual participants' ratings distributions when initialising the prior of the generating distribution of the Ideal Observer.

Because conditions with an initial rating phase had objective and subjective values versions of the Ideal Observer, with each version providing separate optimality estimates, we were able to test the hypotheses that the use of objective or subjective values when modelling (a) affects the strategy taken by the optimality model and (b) changes the assessment of participant bias. We ensured for both objective values and subjective values versions of the models that better options were always more positively-valued such that the models were always solving a maximisation problem. We further ensured that estimated parameters for both objective values and subjective values versions of the models would be on the same scales by reflecting the objective prices around their mean. Then we rescaled those values to span 1 (the highest/worst price) to 100 (the best price). These reflected and rescaled objective values were then used in objective values models when computing the prior generating distribution, and when inputting price values to the model as option values. Subjective values were already rated by participants on this same 1 to 100 scale.

---

### Evidence-based guideline: premature ovarian insufficiency [^55e28cca]. Fertility and Sterility (2025). High credibility.

Premature ovarian insufficiency — options and prescribing principles for HT: The guideline group recommends shared decision making when prescribing each component of HT with consideration of patient preference, contraceptive needs, and presence of co-morbidities. Different estrogens/progestogens have variable metabolic and other effects which should be taken into consideration when personalising care in POI. The guideline group recommends that HCPs and women should be aware that compounded "bio-identical" preparations of estrogen and progesterone are not recommended due to lack of data regarding efficacy and safety. Women with POI should be advised that adherence to HT is important to minimise long term health risks and therefore long term follow up is needed.

---

### Using multilevel models and generalized estimating equation models to account for clustering in neurology clinical research [^be0a6ac7]. Neurology (2024). Medium credibility.

Method 1: GEE Methods

Generalized linear models (GLMs) are a family of regression models that are often used in clinical and epidemiologic research. Examples include linear regression models for continuous outcomes, logistic regression models for binary outcomes, and Poisson regression models for count outcomes. The regression coefficients and their associated standard errors are most often estimated using ordinary least squares (for linear regression models) or maximum likelihood estimation (for all other GLMs). A key assumption of these approaches is that the subjects are independent. In the context of clustered data where the assumption of independence may be violated, GEE methods can be used to estimate the regression coefficients of GLMs along with their standard errors. It is insufficient to simply say that a GEE model was fit. Instead, one needs to specify the type of regression model (e.g. a logistic regression model) along with how it was estimated (e.g. GEE estimation). For example, a particular study's methods section may state "… we used logistic regression estimated using generalized estimating equation methods… " to indicate they accounted for clustering. Regression coefficients estimated using GEE methods can be interpreted in the same way as the equivalent model for nonclustered data. Thus, for a logistic regression model, the exponentiated regression coefficients can be interpreted as odds ratios, comparing the relative change in the odds of the outcome for 2 individuals who differ on the given variable by 1 unit and whose values of all the other covariates are the same.

---

### Biased expectations about future choice options predict sequential economic decisions [^597e5e95]. Communications Psychology (2024). Medium credibility.

Fig. 5
Model comparison for Study 1 conditions with a first phase.

Results from the ratings condition (n = 51 participants) are shown in the left column and from the full condition (n = 50) on the right. Human participant sampling rates in the first row are reproduced from Fig. 2. In the first row, horizontal solid lines link samples data for humans (black points) and Ideal Observer (grey points) when BF 01 > 3 (at least moderate evidence for equal means) while dotted lines indicate when BF 10 > 3 (at least moderate evidence for different means). Human and Ideal Observer sampling never showed BF 01 > 3 (at least moderate evidence for equal means). Statistical details for these pairwise tests can be found in Supplementary Table 1. There is clearer evidence for participant undersampling in the ratings than in the full condition. The second row shows BIC values where lower values indicate better model fit. Horizontal lines are shown in the colour corresponding to the point spread of the better-fitting model when BF 10 > 3 or in black when BF 01 > 3. Statistical details for these pairwise tests can be found in Table 5. The third row shows number of participants that each model best fitted. In both conditions, some version of the Biased Prior model (blue) fits better than any other model, though the ratings condition is more ambiguous. Model point spread data colours (See also legend in lower right panel): Cost to Sample (green), Cut Off (orange), Biased Prior (blue). Boxplots reflect first, second (median) and third quartiles, while whiskers reflect 1.5 interquartile range. Point spreads reflect individual participant mean values. Abbreviations: Subj = Models that make choices about subjective values; Obj = Models that makes choices about objective values.

---

### The fly connectome reveals a path to the effectome [^8a83b308]. Nature (2024). Excellent credibility.

Fig. 2
Inferring the effectome using standard and Bayesian approaches on simulated data.

a, We used the connectome to set the effectome weights for a whole-brain simulation using all 121,327 connected neurons (neurons with no incoming or outgoing connections, above a threshold of > 5 synapses, were not included). b, Synaptic weights were set proportional to synapse count, with positive (negative) sign for excitatory (inhibitory) synapses. c, IV estimates of postsynaptic weights of a single example neuron. Most of the error falls along the vertical line where true weight equals 0 (which is the majority of the weights, owing to the sparsity of the fly connectome). d, Mean ± 2 s.d. of an independent Gaussian connectome prior on each weight in the effectome. We set the prior mean to be proportional to the signed synapse count of the connectome and variance equal to the absolute value of the mean plus a small constant, so that the prior width is non-zero between neurons with no known synapses. e, An IV–Bayes estimator shows smaller error than the raw IV estimator in b. f, The error of estimated weights (residual sum of squares, RSS) decreases with the number of samples for both estimators, but IV–Bayes gives several orders of magnitude faster convergence (orange below blue line; mean ± s.d.; n = 10 simulations). Mean squared error will decrease indefinitely for both estimators because they are consistent (that is, they converge to ground truth as the number of samples goes to infinity). Horizontal lines show error level where the R 2 of the recovered weights is zero (long dash) and 0.9 (short dash), respectively.

---

### Characterizing oligodendrocyte-lineage cells and myelination in the basolateral amygdala: insights from a novel methodology in postmortem human brain [^5592ea39]. Psychiatry Research (2025). Medium credibility.

The basolateral amygdala (BLA) plays a key role in the pathophysiology of depressive disorders and trauma, yet oligodendrocyte (OL)-lineage cells and myelin in this region remain understudied in humans. This may be due in part to the lack of a cost-effective, antibody-based method to isolate OL and OL precursor cells (OPC) from postmortem brain tissue. This study aimed to 1) create and validate a method for isolating OPC and OL nuclei from postmortem grey matter; 2) compare OPC and OL gene expression in the BLA between individuals with depression who died by suicide (with or without a history of childhood abuse) and matched controls; and 3) provide histological characterizations of OPCs, OLs, and myelin in the BLA. Frozen left-hemisphere BLA samples were obtained from brain donors with well-characterized phenotypic information. Immunolabeled nuclei were sorted into OPC (SOX10+/CRYAB-) and OL (SOX10+/CRYAB+) populations, and RNA was measured using a custom Nanostring codeset. OPC (PDGFRα+) and OL (MYRF+) densities were determined using RNAScope, and axons (NF-H) and myelin (MBP) were labeled by immunofluorescence to assess myelin area fraction. This method successfully isolated OPC and OL nuclei with correct transcriptomic profiles. In the OL fraction, MOBP expression was significantly decreased in depressed individuals with a history of childhood abuse compared to controls. No other genes showed group differences in either fraction, though significant age-related expression patterns were observed. Furthermore, no group differences were seen in cell densities or myelin coverage. This study validates a novel sorting method and provides a comprehensive characterization of OL-lineage gene expression, cell densities, and myelin in the human BLA.

---

### Statistical predictions with glmnet [^c66b29db]. Clinical Epigenetics (2019). Medium credibility.

It may be difficult to obtain a clear understanding of the limitations and possibilities offered by shrinkage methods for prediction of n < < p models due to the many implicit assumptions hidden in such methods. Bias increases with the penalty parameter λ, as can be seen from the equation above. Given equal MSE, it is often desirable to choose the most parsimonious model (Occam's rule), as parsimonious models are often more interpretable. There could of course be reasons not to choose the most parsimonious model (e.g. Lasso's handling of correlated predictors) but then this should be justified. Nevertheless, the only way to properly validate the final selected predictor model is to assess its performance on an independent test set. We give an example in Additional file 1 of how variable selection can be performed on data from the Illumina Human Methylation 450k platform where the aim is to train a simple model for age prediction. The number of folds used for training and prediction can be adjusted according to the number of samples in the dataset. It should be noted that cross validation is performed by random selection of the k -folds. If the obtained results are to be duplicated at a later stage, it is recommended that a seed is specified. It is also possible to fix the penalty parameter λ. The smaller the penalty parameter λ is, the closer the elastic net coefficient estimate is to the least squares estimate, as the influence of the penalty term in the elastic net equation above will diminish. It is, however, impossible to carry out least squares estimation when the number of explanatory variables in the model exceeds the number of samples.

Standard errors

Statistical testing is not directly possible using the elastic net, as no standard errors for the estimated parameters (i.e. slope coefficients) are computed directly. There is some discussion concerning the most appropriate methods to estimate variances and perform hypothesis testing for Lasso, but there seems to be no general agreement as of yet, not least due to Lasso's unpredictable variable selection. For instance, bootstrapping is one method that can be applied for performing statistical inference on the estimated coefficients, but may be very time consuming on large datasets, depending on both the number of samples as well as the number of predictors.

---

### Methods for obtaining unpublished data [^903e12f2]. The Cochrane Database of Systematic Reviews (2011). Low credibility.

Background

In order to minimise publication bias, authors of systematic reviews often spend considerable time trying to obtain unpublished data. These include data from studies conducted but not published (unpublished data), as either an abstract or full-text paper, as well as missing data (data available to original researchers but not reported) in published abstracts or full-text publications. The effectiveness of different methods used to obtain unpublished or missing data has not been systematically evaluated.

Objectives

To assess the effects of different methods for obtaining unpublished studies (data) and missing data from studies to be included in systematic reviews.

Search Methods

We identified primary studies comparing different methods of obtaining unpublished studies (data) or missing data by searching the Cochrane Methodology Register (Issue 1, 2010), MEDLINE and EMBASE (1980 to 28 April 2010). We also checked references in relevant reports and contacted researchers who were known or who were thought likely to have carried out relevant studies. We used the Science Citation Index and PubMed 'related articles' feature to identify any additional studies identified by other sources (19 June 2009).

Selection Criteria

Primary studies comparing different methods of obtaining unpublished studies (data) or missing data in the healthcare setting.

Data Collection and Analysis

The primary outcome measure was the proportion of unpublished studies (data) or missing data obtained, as defined and reported by the authors of the included studies. Two authors independently assessed the search results, extracted data and assessed risk of bias using a standardised data extraction form. We resolved any disagreements by discussion.

Main Results

Six studies met the inclusion criteria; two were randomised studies and four were observational comparative studies evaluating different methods for obtaining missing data. Methods to obtain missing dataFive studies, two randomised studies and three observational comparative studies, assessed methods for obtaining missing data (i.e. data available to the original researchers but not reported in the published study). Two studies found that correspondence with study authors by e-mail resulted in the greatest response rate with the fewest attempts and shortest time to respond. The difference between the effect of a single request for missing information (by e-mail or surface mail) versus a multistage approach (pre-notification, request for missing information and active follow-up) was not significant for response rate and completeness of information retrieved (one study). Requests for clarification of methods (one study) resulted in a greater response than requests for missing data. A well-known signatory had no significant effect on the likelihood of authors responding to a request for unpublished information (one study). One study assessed the number of attempts made to obtain missing data and found that the number of items requested did not influence the probability of response. In addition, multiple attempts using the same methods did not increase the likelihood of response. METHODS TO OBTAIN UNPUBLISHED STUDIES: One observational comparative study assessed methods to obtain unpublished studies (i.e. data for studies that have never been published). Identifying unpublished studies ahead of time and then asking the drug industry to provide further specific detail proved to be more fruitful than sending of a non-specific request.

Authors' Conclusions

Those carrying out systematic reviews should continue to contact authors for missing data, recognising that this might not always be successful, particularly for older studies. Contacting authors by e-mail results in the greatest response rate with the fewest number of attempts and the shortest time to respond.

---

### Performance of linear mixed models in estimating structural rates of glaucoma progression using varied random effect distributions [^dab23bbe]. Ophthalmology Science (2023). Medium credibility.

Purpose

To compare how linear mixed models (LMMs) using Gaussian, Student t, and log-gamma (LG) random effect distributions estimate rates of structural loss in a glaucomatous population using OCT and to compare model performance to ordinary least squares (OLS) regression.

Design

Retrospective cohort study.

Subjects

Patients in the Bascom Palmer Glaucoma Repository (BPGR).

Methods

Eyes with ≥ 5 reliable peripapillary retinal nerve fiber layer (RNFL) OCT tests over ≥ 2 years were identified from the BPGR. Retinal nerve fiber layer thickness values from each reliable test (signal strength ≥ 7/10) and associated time points were collected. Data were modeled using OLS regression as well as LMMs using different random effect distributions. Predictive modeling involved constructing LMMs with (n - 1) tests to predict the RNFL thickness of subsequent tests. A total of 1200 simulated eyes of different baseline RNFL thickness values and progression rates were developed to evaluate the likelihood of declared progression and predicted rates.

Main Outcome Measures

Model fit assessed by Watanabe-Akaike information criterion (WAIC) and mean absolute error (MAE) when predicting future RNFL thickness values; log-rank test and median time to progression with simulated eyes.

Results

A total of 35 862 OCT scans from 5766 eyes of 3491 subjects were included. The mean follow-up period was 7.0 ± 2.3 years, with an average of 6.2 ± 1.4 tests per eye. The Student t model produced the lowest WAIC. In predictive models, all LMMs demonstrated a significant reduction in MAE when estimating future RNFL thickness values compared with OLS (P < 0.001). Gaussian and Student t models were similar and significantly better than the LG model in estimating future RNFL thickness values (P < 0.001). Simulated eyes confirmed LMM performance in declaring progression sooner than OLS regression among moderate and fast progressors (P < 0.01).

Conclusions

LMMs outperformed conventional approaches for estimating rates of OCT RNFL thickness loss in a glaucomatous population. The Student t model provides the best model fit for estimating rates of change in RNFL thickness, although the use of the Gaussian or Student t distribution in models led to similar improvements in accurately estimating RNFL loss.

Financial Disclosures

Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.

---

### Adaptation and initial results of the Polish version of the GA (2) LEN chronic urticaria quality of life questionnaire (CU-Q (2) oL) [^863f715a]. Journal of Dermatological Science (2011). Low credibility.

Background

Strong negative influence upon the quality of life in chronic urticaria is well proved. Before the GA(2)LEN Chronic Urticaria Quality of Life Questionnaire (CU-Q(2)oL) was introduced, the quality of life in chronic urticaria had been measured with general or dermatology specific questionnaires. CU-Q(2)oL was initially developed in Italy and consisted of 23 items divided into 6 quality of life dimensions.

Objective

The aim of our study was to adapt the Polish version of CU-Q(2)oL and to provide initial results from the Polish sample.

Methods

To prepare the Polish version forward and back translation was prepared. After cognitive debriefing, we collected a group of 126 chronic urticaria patients who completed Polish CU-Q(2)oL, Dermatology Life Quality Index (DLQI) and Skindex-29 questionnaire. Disease severity was assessed with Urticaria Activity Score (UAS). We performed the factorial analysis to identify CU-Q(2)oL subscales in our study, internal consistency and convergent validity assessment as well as factors driving the results. Moreover, we analysed tool's reproducibility and responsiveness.

Results

The factor analysis resulted in six subscales of Polish CU-Q(2)oL version with satisfying face validity: Itching, Swelling/Mental status, Functioning, Sleep, Eating/Limits, Embarrassment. All subscales presented recommended internal consistency and convergent validity. Disease severity was the only factor predicting results of all the subscales. Polish CU-Q(2)oL version was reproducible and sensitive to change. We noticed the highest quality of life impairment in Itching and Embarrassment subscales whereas Eating/Limits was the least affected.

Conclusions

Our study supports reliability, responsiveness and validity of the Polish version of CU-Q(2)oL - easy in use, non time-consuming instrument to be used in research, clinical management and treatment outcome assessment and is one more step to confirm quality of life impairment in chronic urticaria.

---

### Representation of exposures in regression analysis and interpretation of regression coefficients: basic concepts and pitfalls [^860a26d1]. Nephrology, Dialysis, Transplantation (2014). Low credibility.

Regression models are being used to quantify the effect of an exposure on an outcome, while adjusting for potential confounders. While the type of regression model to be used is determined by the nature of the outcome variable, e.g. linear regression has to be applied for continuous outcome variables, all regression models can handle any kind of exposure variables. However, some fundamentals of representation of the exposure in a regression model and also some potential pitfalls have to be kept in mind in order to obtain meaningful interpretation of results. The objective of this educational paper was to illustrate these fundamentals and pitfalls, using various multiple regression models applied to data from a hypothetical cohort of 3000 patients with chronic kidney disease. In particular, we illustrate how to represent different types of exposure variables (binary, categorical with two or more categories and continuous), and how to interpret the regression coefficients in linear, logistic and Cox models. We also discuss the linearity assumption in these models, and show how wrongly assuming linearity may produce biased results and how flexible modelling using spline functions may provide better estimates.