# Medical Question & Answer

**Sample ID**: d2baf20c-66e9-efb0-7518-254e82f69907
**Dataset Index**: 215957

---

## Question

[Coordinate method on the plane]

[Properties and characteristics of the tangent]

Form the equation of the line passing through the point A(0; 7) and tangent to the circle (x − 15)² + (y − 2)² = 25.

---

## Answer

> Let's see… What do we have here? The user is asking how to find the equation(s) of the line(s) passing through the point A(0, 7) and tangent to the circle (x − 15)² + (y − 2)² = 25. Let's break this down step-by-step. First, I need to think about the circle's center and radius. Then, I should verify the geometric condition for tangency and translate it into an algebraic distance condition. Next, I will set up the equation of a line through A with slope m and impose the tangency condition to solve for m. After that, I should check whether vertical lines are possible and handle that case separately. Finally, I will write the two tangent equations and confirm the results with a quick sanity check.

> Let me first confirm the circle's parameters. The given equation is (x − 15)² + (y − 2)² = 25, so the center C is at (15, 2) and the radius r is √25 = 5. I should double-check that these are correct before proceeding, and yes, they are.

> Now, I need to ensure I understand the tangency condition. A line is tangent to a circle if and only if the distance from the center of the circle to the line equals the radius. So, for any candidate line through A(0, 7), I must have distance(C, line) = 5. Hold on, let's not jump to conclusions; I should also consider whether a vertical line through A could be tangent, since vertical lines have undefined slope and require a separate check.

> Next, I will write the general equation of a non-vertical line through A(0, 7) with slope m. That is y − 7 = m(x − 0), or equivalently mx − y + 7 = 0. I should confirm the standard form is correct, and yes, that's the right linear form to use for distance calculations.

> I will now apply the point-to-line distance formula from the center C(15, 2) to the line mx − y + 7 = 0, and set it equal to the radius 5. The distance formula gives |m·15 − 1·2 + 7| / √(m² + (−1)²) = 5, which simplifies to |15m + 5| / √(m² + 1) = 5. Wait, let me verify the numerator: 15m − 2 + 7 is indeed 15m + 5, so that's correct.

> Squaring both sides to eliminate the absolute value and the square root, I get (15m + 5)² = 25(m² + 1). Expanding the left side gives 225m² + 150m + 25 = 25m² + 25. Subtracting 25 from both sides and collecting terms yields 200m² + 150m = 0, which factors to 50m(4m + 3) = 0. So the solutions are m = 0 or m = −3/4. I should double-check the algebra, and yes, that factorization is correct.

> For m = 0, the line is y = 7. For m = −3/4, substituting back into y − 7 = m(x − 0) gives y = −(3/4)x + 7, which I can rewrite as 3x + 4y − 28 = 0. Hold on, I should verify the arithmetic: 4y = −3x + 28 implies 3x + 4y − 28 = 0, which is correct.

> But wait, what if the tangent is vertical? A vertical line through A(0, 7) has equation x = 0. I need to check the distance from C(15, 2) to x = 0, which is simply |15 − 0| = 15. Since 15 ≠ 5, a vertical line is not tangent, so I can exclude that case. I should confirm there are no other special cases, and indeed, the two slopes I found are the only solutions.

> Therefore, the two tangent lines are y = 7 and 3x + 4y − 28 = 0. Let me reconsider whether both satisfy the distance condition. For y = 7, the distance from (15, 2) to y = 7 is |2 − 7| = 5, which matches the radius. For 3x + 4y − 28 = 0, the distance is |3·15 + 4·2 − 28| / √(3² + 4²) = |45 + 8 − 28| / 5 = |25| / 5 = 5, which also matches. So both lines are indeed tangent.

---

The equations of the lines through (A(0, 7)) tangent to the circle ((x − 15)² + (y − 2)² = 25) are:

- **Horizontal tangent**: (y = 7)
- **Sloped tangent**: (y = −[3/4]x + 7)

---

## Geometric setup

- **Circle**: Center (C(15, 2)), radius (r = 5)
- **Point**: (A(0, 7))
- **Goal**: Find lines through (A) tangent to the circle

---

## Method 1: algebraic approach

### General line equation

A line through (A(0, 7)) has the form:

y = mx + 7

or in standard form:

mx − y + 7 = 0

---

### Tangency condition

The distance from the center (C(15, 2)) to the line must equal the radius (r = 5):

|m·15 − 1·2 + 7|/√(m² + (−1)²) = 5

Simplify the numerator:

|15m + 5|/√(m² + 1) = 5

Square both sides:

(15m + 5)² = 25(m² + 1)

Expand and simplify:

225m² + 150m + 25 = 25m² + 25

200m² + 150m = 0

50m(4m + 3) = 0

Solutions:

m = 0 or m = −[3/4]

---

### Tangent lines

- **For (m = 0)**: (y = 7)
- **For (m = −[3/4])**: (y = −[3/4]x + 7)

---

## Method 2: geometric approach

### Distance from point to center

Compute the distance from (A(0, 7)) to the center (C(15, 2)):

AC = √[(15 − 0)² + (2 − 7)²] = √(225 + 25) = √250 = 5√10

Since (AC > r), two tangents exist.

---

### Right triangle setup

Each tangent forms a right triangle with hypotenuse (AC) and leg (r). The other leg is the tangent length (AT):

AT = √(AC² − r²) = √(250 − 25) = √225 = 15

---

### Slopes from angles

Let (\\theta) be the angle between (AC) and the tangent. Then:

sin θ = [r/AC] = [5/(5√10)] = [1/√10]

The slope of (AC) is:

m_AC = [(2 − 7)/(15 − 0)] = −[1/3]

Using the angle-addition formula for slopes, the tangent slopes are:

m = [m_AC ± tan θ]/[1 ∓ m_AC tan θ]

Compute (\\tan \\theta = \\frac{\\sin \\theta}{\\cos \\theta} = \\frac{1/\\sqrt{10}}{3/\\sqrt{10}} = \\frac{1}{3}), then:

m = [(−[1/3] ± [1/3])/(1 ∓ (−[1/3])([1/3]))] = [(−[1/3] ± [1/3])/(1 ± [1/9])]

This yields (m = 0) and (m = −[3/4]), matching the algebraic result.

---

## Verification

Both methods yield the same two tangent lines:

- **Horizontal tangent**: (y = 7)
- **Sloped tangent**: (y = −[3/4]x + 7)

---

The equations of the tangent lines through (A(0, 7)) to the circle are (y = 7) and (y = −[3/4]x + 7).

---

## References

### Using both qualitative and quantitative data in parameter identification for systems biology models [^fc71653e]. Nature Communications (2018). Medium credibility.

Results

An illustration of the potential value of qualitative data

To demonstrate the potential value of qualitative data, we consider a simple case of solving for the coefficients of polynomial functions.

We consider two polynomial functions: y 1 = ax 2 − bx + c and y 2 = dx + e. Suppose we want to solve for the coefficients a, b, c, d, and e, which we will take to be positive. As the ground truth coefficients to be determined, we choose (a, b, c, d, e) = (0.5, 3, 5, 1, 1.5).

Suppose that a limited amount of quantitative information is available. Namely, it is known that the parabola y 1 contains the points (2, 1) and (8, 13), and the line y 2 contains the point (3.5,5). This is not enough information to solve for any of the coefficients because three points are required to specify a parabola, and two points are required to specify a line (Fig. 1a).

Fig. 1
A simple illustration using polynomial functions. We use qualitative and quantitative information to determine the unknown coefficients. a Visualization of the problem. We seek to find the coefficients of equations for a parabola and a line, with the ground truth shown (blue solid curves). Two points on the parabola and one point on the line are known (black dots). These three points are consistent with infinitely many possible solutions (e.g. orange dashed curves). Qualitative information (colored circles, x -axis) specifies whether the parabola is above (+) or below (−) the line. This information limits the possible values of intersection points x 1 and x 2 to the green shaded segments of the x -axis. b Bounds on coefficient values as a function of the number of qualitative points known. Shaded areas indicate the range of possible values of each coefficient

---

### Reconstitution reveals how myosin-VI self-organises to generate a dynamic mechanism of membrane sculpting [^1b8da43b]. Nature Communications (2019). High credibility.

Geometrically, this condition means that we demand that the point at s = 0 moves along the normal to the curve for all times.

Now consider the arc lengthin terms of an arbitrary curve parametrisation σ, whereis the metric. Recalling that, and, the time derivative of the arc length can be rewritten as

Hence, the time evolution of the total length L (perimeter) of the curve can be written in the form

where for the last equality in Eq. (13) we used the periodicity of T along the curve Γ. We now choose a parametrisation of the curve relative to the full arc length, ρ = s / L that is time invariant: ∂ t (s / L) = 0; as the curve expands (L changes), the internal distance (ρ) between the points along the curve remains the same. In other words, the points on Γ (t) will be evenly distributed as the interface grows. With Eqs. (12) and (13), this condition translates into

Since the choice, Eq. (11), amounts to T (t, 0) = 0, we have

The evolution equation for the Cartesian coordinates x and y then follow from Eqs. (10) and (15) as

To proceed, we derive an equation of motion for the angle θ between the tangent to the curve and the positive x axis, defined as

To this end, we will need the following identitywhere in the first line we used that, which follows from Eq. (12) together with the definition. Using Eq. (15) for, we arrive at Eq. (20). Furthermore, note that by definition. Applying Eq. (20) toand using the fact that the curvature κ can be written in the form, we find:

---

### Multiple tipping points and optimal repairing in interacting networks [^ad1069fa]. Nature Communications (2016). Medium credibility.

Additional phase diagrams

Figure 8a shows the collection of stable solutions (solid blue lines) and unstable solutions (dashed red lines) for the activity z A = 1− a A of network A, with parameter values as used in Fig. 1a, but for a range of different values of. The solid black line indicates, the value ofused in Fig. 1a. Green circles in this figure correspond to the stable states found in Fig. 1a and red crosses correspond to the unstable solutions for z A form Fig. 1a. Figure 8b shows an analogous phase diagram for the parameters with values as in Fig. 8a, again for a range of.

Forbidden transitions

Transition lines for 12→21 and 21→12 do not appear in our phase diagram and it is quite easy to understand why. Let us assume that the transition line for 12→21 does exist. To obtain that transition, the idea would be to simultaneously increaseand decrease(that is, increase the damage in one part of the system and decrease in another part). Suppose we are in phase 12 and infinitesimally close to the supposed transition line. Considering the local geometry of this line, we may be able to observe its angle with respect to theaxis. If a transition occurs when increasingand decreasing, the tangent on the supposed line would have an angle of. From here, it follows that by increasingonly, while keepingconstant, we would also make a transition (cross the transition line). The only other possibility would be that we were moving along the transition line, but this is easy to disprove because it would imply that the transition does not depend on. If increasingonly causes a transition, the transition must end in state 22 and not in 21. This is because if we only increase, we increase damage to both network A (directly) and network B (indirectly, through the interdependent links).

---

### Shifting the optimal stiffness for cell migration [^8ce326d8]. Nature Communications (2017). Medium credibility.

Simulation analysis

The random motility coefficient (μ) for simulated two-dimensional cell migration was defined similarly to a diffusion coefficient as in equation (12).

In this equation, 〈 r 2 〉 is the mean squared displacement of the cell centre in a given time interval, t. From this relation, μ can be calculated from the slope of 〈 r 2 〉 versus t. This plot was generated for each simulated cell according to the overlap method of mean squared displacement calculation. In this method, all displacements at all possible time intervals are used to generate the plot. To correspond to our experimental cell migration experiments, simulation data at 15 min intervals was used to calculate mean squared displacements, and the first hour of each simulation were excluded from analysis to allow the system to reach steady state (Supplementary Fig. 5). In addition, large displacements in the simulated cell centre of 1 μm s −1 were removed. A linear trend line intersecting the origin and inversely weighted by the uncertainty in each data point was fit to the first half of the 〈 r 2 〉 versus t data for each simulated cell. The random motility coefficient was calculated from the slope of the trend line and averaged across all simulated cells at a given condition to obtain the mean random motility coefficient for that condition.

Simulated cell morphology was determined by creating a geometric shape based on the position outputs of the simulation. First, a 10 μm radius circle was centred at the cell body position. Then, 10 μm was added to the length of each module to account for the module starting at the edge of the cell body rather than the central point. Tangent lines to the cell circle were then drawn to connect the module tips to the central circle. The resulting shape was then analysed for aspect ratio using MATLAB 'regionprops' function. Simulation movies depicting cell shape and migration are provided for 0.1, 10 and 1,000 pN nm −1 substrates (Supplementary Movie 1).

Finally, the F-actin flow rate was calculated by taking the mean of the F-actin flow rates for each module, and the traction force was calculated by summing the magnitudes of the force on each module as well as the cell body.

---

### Multiple tipping points and optimal repairing in interacting networks [^d95be1ee]. Nature Communications (2016). Medium credibility.

Despite the seeming complexity of equations (1) and (2), it is noteworthy that there are only two unknown variables, a A and a B, and that all other parameters are fixed. These two equations define two curves in the (a A, a B) plane.

Figure 1a shows a graphical representation of the curves for a random regularnetwork (in which all the nodes have the same degree) with degree of k = 16 and threshold m = 8, for the symmetric parameter values, r A = r B = 0.60 and r d = 0.15. The size of each network is N = 2 × 10 4. The blue curve is a graphical representation of equation (1) and the brown curve is defined by equation (2). The curves, similar to two 'ropes', create a 'knot' that can have up to nine intersections, representing mathematical solutions of the system of equations. However, not all of these solutions represent observable and stable physical states. To see that, observe one of the curves in Fig. 1a, for example, the blue curve described by equation (1). If we increase damage done to network B (that is, we increase a B) and keep everything else constant, some damage will undoubtedly spread to network A. Thus, we expect that when a B is increased, a A must also increase (it would be very unusual if one network improves its activity as a result of damaging the other network). We conclude that the parts of the blue and brown curve that produce physical solutions are only those where a A and a B increase together or decrease together along the curve. This elimination leaves only four states in Fig. 1a that are stable (green circles), whereas the other five states are unstable (red crosses), for this particular choice of parameters. In simulated finite networks, when the network system evolves according to the rules of the model, at t = 0 we have a freedom to set initial conditions for the activities. Systems initially prepared to have a pair of values (a A, a B) corresponding to an unstable solution of equations (1) and (2) will be disturbed by a small fluctuation of a A or a B, owing to the system dynamics, and the values of a A or a B will rapidly change until one of the stable states is reached. Systems that are initially prepared to have values of a A or a B corresponding to a stable solution will fluctuate around these values, until perhaps a large finite fluctuation occurs and the system 'jumps' to another stable state. In general, for any choice of parameters, we have between one and four stable (physical) states. Figure 1b shows the scenario for the same network system when, r A = r B = 0.60 and r d = 0.15. In this case we have two stable states and one unstable state.

---

### Experimental observation of flow fields around active Janus spheres [^63e6492a]. Nature Communications (2019). High credibility.

Fig. 4
Two components of the velocity field. x -component of the velocity measured at y = 0 and as a function of the coordinate x for the two situations where the swimmer is stuck (a) and freely moving (b). y -component of the velocity measured at x = 0 and as a function of the coordinate y for the two situations where the swimmer is stuck (c) and freely moving (b). For all plots, the blue symbols and error bars are obtained experimentally after averaging the fields measured in a stripe of width 2 μm around y = 0 (a, b) and x = 0 (c, d). The red line is a fit of the experimental data using the expressions of the velocity given in the Methods section (Eqs. (15) and (17)), with K = v 0 / U as a free parameter. The expansions in Legendre polynomials are truncated at order N = 25. The values of the fit parameters are K stuck = 11.6 ± 0.7 and K moving = 15.2 ± 0.7

---

### To infinity and some glimpses of beyond [^d42883f3]. Nature Communications (2017). Medium credibility.

Methods

Complexification of ordinary differential equations

The complexified version(z = x + iy) leads to the two-dimensional dynamical system:

The real axis is an invariant subspace, retrieving our real results; yet complexification endows the dynamics with an intriguing capability: as Fig. 4a, b illustrates through the (x, y) phase plane, collapse is avoided in the presence of a minuscule imaginary part. Large elliptical-looking trajectories are traced on the phase plane, eventually returning to the neighborhood of the sole fixed point of (0, 0) — which in the real case one would characterize as semi-stable. The system of Eq. (19) can be tackled in closed form since the ODEyields 1/ z = − t + 1/ z (0). For z = x + iy (z (0) = x 0 + iy 0) we obtain the explicit orbit formulaEliminating time by dividing the two ODEs within Eq. (19) directly yields an ODE for y = y (x) (rather than the parametric forms of Eqs. (20), (21)). From this ODE, one can obtain that the quantityis an invariant of the phase plane dynamics, and thus the latter can be written as x 2 + (y − R) 2 = R 2, where. That is, the trajectory evolves along circles of radius R in the upper (resp. lower) half plane if y 0 > 0 (resp. y 0 < 0.) Approaching the axis with y 0 → 0, the curvature of these circles tends to 0 and their radius to ∞ (retrieving the real dynamics as a special case). Figure 4 through its planar projections illustrates not only the radial projection of the dynamics in the x − y plane, but the x − t and y − t dependencies.

---

### Exact, time-dependent analytical equations for spiral trajectories and matching gradient and density-correction waveforms [^e97e4fee]. Magnetic Resonance in Medicine (2026). Medium credibility.

1 INTRODUCTION

The use of spiral k‐space trajectories for data acquisition in MRI, is well established, with the benefits of high SNR and temporal efficiency, short minimum TEs, as well as reduced and incoherent artifacts from some types of motion. These trajectories traditionally follow an Archimedean spiral under some constraints for gradients (e.g. maximum gradient amplitude or slew rate). Two approaches to deriving optimal gradient waveforms that sample along this Archimedean spiral include approximately optimal analytical solutions, and numerical methods. These references reflect only a small portion of the methods published to date; however, to the authors' knowledge, there have been no exact analytical solutions, particularly none that allow gradient frequency limitations or include analytical solutions for both gradient waveforms and k‐space trajectories.

A variant of the spiral trajectory, which follows the involute of a circle, was previously introduced with the acronym WHIRL (Winding Hybrid Interleaved Radial Lines). This trajectory is similar to an Archimedean spiral, with two exceptions: (1) it forces the sampling normal to the trajectory (e.g. arm‐to‐arm spacing) to stay exactly uniform; and (2) it is not defined within a prescribed central circle. The first property makes it slightly more optimal than an Archimedean spiral purely in terms of path length. In contrast, the second property requires that one finds a bridging trajectory between the center of the measurement plane (k‐space origin) and the edge of the circle where the trajectory becomes defined. Notably, the slight difference in the math describing this trajectory allows it to be analytically defined under various gradient optimization constraints such as frequency, slew, and gradient magnitude. The inclusion of frequency is particularly relevant because the fidelity of gradient waveforms is known to depend on their frequency content. The proposed trajectory is completed by adding a quarter‐circle arc at the beginning of the trajectory to span the inner circle to the k‐space origin and a quarter‐circle arc at the end to bend the trajectory into a completely angular direction. The first arc is necessary, and the second arc makes the trajectory highly modular, as will be shown.

---

### PLANET: an ellipse fitting approach for simultaneous tand tmapping using phase-cycled balanced steady-state free precession [^be6b9570]. Magnetic Resonance in Medicine (2018). Low credibility.

Figure 2
a: Schematic representation of the ellipse at t = 0 + (red dashed line) and t = TE > 0 (blue solid line), which is rotated around the origin by φ. (x c, 0) = the geometrical center of the ellipse; A, B = semi‐axes of the ellipse. b: Geometrical determination of the angleusing the locations of the data points (x n, y n) on the vertical ellipse.

Step 3. Analytical solution for parameters.

Parametersof the parametric form of the ellipse in Equation [4] are related to the geometric characteristicsfrom the Cartesian form of ellipse in Equation [8] through a system of nonlinear equations (23):

We have solved this system for parametersanalytically. The results are presented in the Appendix. The T 1 and T 2 estimates can be found from parameters a and b using the following equations:

Additional Step 4. Estimation of the local off‐resonance.

The rotation angle in Equation [7] includes the local off‐resonanceand RF phase offset, which cannot be separated from Equation [5]. For simplicity, the chemical shift is ignored and the additional phase errors due to eddy current effects and B 0 drift are assumed to be negligible:

The off‐resonance, however, can be estimated from the locations of the data points with different RF phase increment settingson the vertical ellipse: the precession angleduring each TR depends only on the RF phase incrementand the local off‐resonance, and not on the RF phase offset:

Using a Cartesian parametric equation of the ellipse:and after substitution of x and y from Equation [13] by the real and imaginary components of the signal in Equation [4], the relationship between parameters t andcan be found as:

---

### Advanced statistics: linear regression, part I: simple linear regression [^18239641]. Academic Emergency Medicine (2004). Low credibility.

Simple linear regression is a mathematical technique used to model the relationship between a single independent predictor variable and a single dependent outcome variable. In this, the first of a two-part series exploring concepts in linear regression analysis, the four fundamental assumptions and the mechanics of simple linear regression are reviewed. The most common technique used to derive the regression line, the method of least squares, is described. The reader will be acquainted with other important concepts in simple linear regression, including: variable transformations, dummy variables, relationship to inference testing, and leverage. Simplified clinical examples with small datasets and graphic models are used to illustrate the points. This will provide a foundation for the second article in this series: a discussion of multiple linear regression, in which there are multiple predictor variables.

---

### Primer on binary logistic regression [^8adbb90e]. Family Medicine and Community Health (2021). Medium credibility.

Visualising the logistic function can help to clarify why this statistical form is useful for examining a binary outcome. Figure 3 shows the logistic function as the curve connecting the data points. Each data point is plotted with a value of the outcome along the y-axis. Because the outcome is binary with the two values of 0 and 1, the points are plotted at y = 0 and y = 1. The predictor variable is shown along the x-axis and appears to be continuous. Each data point takes a value of x which seems to range from about 10 to about 35. It is clear that the data points in the y = 0 category of the outcome generally have lower values of x than the data points in the y = 1 category. This pattern suggests that, as x increases, the probability of a person having the outcome value of y = 1 also increases.

Figure 3
The logistic function with example data.

The grey logistic function line is the logistic regression model for these data. The line identifies the predicted probability of y = 1 for each value of x. For example, if x = 17, the predicted probability of y would be.18. This might be translated into into a percentage with a statement like, there is an 18% probability that someone with an x value of 17 would have a y value of 1. A more concrete example might be to think of the x value as years a person has smoked cigarettes daily and y as their probability for being diagnosed with lung cancer. So, a person who has smoked daily for 17 years has an 18% probability of being diagnosed with lung cancer. Please note that these data are not actual lung cancer data; this is just an example to assist in developing intuition around the logistic function meaning. If these data were years of smoking predicting lung cancer diagnosis, equation 1 might be rewritten as equation 2:

Equation 2. Applying the statistical form of the binary logistic regression model.

---

### Standardization of spirometry 2019 update. An official American Thoracic Society and European Respiratory Society technical statement [^df365e99]. American Journal of Respiratory and Critical Care Medicine (2019). High credibility.

Back-extrapolated volume (BEV) on the volume–time curve — Time 0 is found by drawing a line with a slope equal to peak flow through the point of peak flow on the volume–time curve and setting Time 0 to the point where this line intersects the time axis. The BEV is equal to the volume of gas exhaled before Time 0, which, in these two examples from the same patient, is 0.136 L for the left panel (acceptable) and 0.248 L for the right panel (unacceptable). For this patient, the BEV limit is 5% FVC = 0.225 L.

---

### Identification of signal bias in the variable flip angle method by linear display of the algebraic ernst equation [^de617655]. Magnetic Resonance in Medicine (2011). Low credibility.

A novel linear parameterization for the variable flip angle method for longitudinal relaxation time T(1) quantification from spoiled steady state MRI is derived from the half angle tangent transform, τ, of the flip angle. Plotting the signal S at coordinates x = Sτ and y = S/τ, respectively, establishes a line that renders signal amplitude and relaxation term separately as y-intercept and slope. This representation allows for estimation of the respective parameter from the experimental data. A comprehensive analysis of noise propagation is performed. Numerical results for efficient optimization of longitudinal relaxation time and proton density mapping experiments are derived. Appropriate scaling allows for a linear presentation of data that are acquired at different short pulse repetition times, TR < < T1 thus increasing flexibility in the data acquisition by removing the limitation of a single pulse repetition time. Signal bias, like due to slice-selective excitation or imperfect spoiling, can be readily identified by systematic deviations from the linear plot. The method is illustrated and validated by 3T experiments on phantoms and human brain.

---

### A mathematical approach to human pterygium shape [^a8e2767f]. Clinical Ophthalmology (2016). Low credibility.

Results

We examined the pictures of each pterygium taken at the initial ophthalmological examination using a camera. On the contour plane curves which were seen, we measured the coordinates of five points (Table 1). For some patients, a few points were too close to enable us to estimate curve's type. Hence, we used the software to determine four more points on the contour curve.

We applied the spline approximations through those nine points which successfully reconstructed the curve. Reconstructed graphs of contour curve by spline approximation are shown in Figure 2. Since the original curves were very similar to conics, we took five points: the first is the point which is the nearest to the origin of supposed conic; a further two points distinguished from one side and two from the other side. The most simple class of curves which pass through five plane points is the class of conic sections which satisfies the equation of the form (Figure 3):

The previous equation given by the determinant can be written in the form Ax 2 + 2 Bxy + Cy 2 + 2 Dx + 2 Ey + F = 0.

Denote

According to the analytical geometry, this equation determines:
Ellipse if δ > 0 ∧ s Δ < 0
Hyperbola if δ < 0 ∧ Δ≠0
Parabola if δ = 0 ∧ Δ≠0

By plotting original curve, spline, and conics, we obtained very close graphs for every patient (Table 2). So, we can conclude that the shape of pterygia is of conic form.

Equations of conics for five patients were calculated (Table 3). These equations show that the conics are slightly rotated around X-axis; therefore, the graphs are not symmetrically located by X-axis (Figure 4).

---

### Logistic regression in medical research [^cbe948a6]. Anesthesia and Analgesia (2021). Medium credibility.

Figure.
Relationship between a continuous independent variable X and a binary outcome that can take values 0 (eg, "no") or 1 (eg, "yes"). As shown, the probability that the value of the outcome is 1 seems to increase with increasing values of X. A, Using a straight line to model the relationship of the independent variable with the probability provides a poor fit; results in estimated probabilities < 0 and > 1; and grossly violates the assumptions of linear regression. Logistic regression models a linear relationship of the independent variable with the natural logarithm (ln) of the odds of the outcome variable. B, This translates to a sigmoid relationship between the independent variable and the probability of the outcome being 1, with predicted probabilities appropriately constrained between 0 and 1.

Logistic regression is actually an extension of linear regression. Rather than modeling a linear relationship between the independent variable (X) and the probability of the outcome (Figure A), which is unnatural since it would allow predicted probabilities outside the range of 0–1, it assumes a linear (straight line) relationship with the logit (the natural logarithm of the odds) of the outcome. The regression coefficients represent the intercept (b 0) and slope (b 1) of this line

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^070d751c]. Magnetic Resonance in Medicine (2021). Medium credibility.

Force and torque constraints can be added using the known main B 0 field distribution, integrating over the current distribution for each basis function and entering the results into matrix H or C. One row is added for each direction of force or torque, to obtain an overall magnitude constraint. Eddy currents are computed in a similar manner; the step response for time‐dependent eddy currents on the surface of a conducting cylinder — typically the thermal shield in the magnet — is computed at multiple points in space and time. Each point in space and time is entered as a separate inequality constraint equation. It is usually sufficient to constrain eddy currents at time = 0 following a step change in gradient current, reducing the size of the problem.

Finally, and of primary significance to the present work, E‐field constraints can be handled in a similar manner to those for force and torque. At gradient frequencies of interest, the time evolution of E‐fields in human tissues is short, and therefore proportional to instantaneous slew rate and not the detailed waveform shape in time. Thus, given a body model, the E‐field is computed from each gradient coil basis function for unit slew rate at a series of points over the body surface, such as using the methods we have described recently. 17 Calculation at points on the interior of the model is not required, as the maximum magnitude always occurs on the surface of a uniform body model (see Supporting Information). A magnitude constraint is created on the surface by placing a series of rotated inequality constraints on the vector E‐field tangent to the surface. For example, we choose 32 directions at each point spaced over 360º, which constrains the magnitude to within 0.5% of the desired value.

---

### Scaling behaviour for the water transport in nanoconfined geometries [^5a6a5408]. Nature Communications (2014). Medium credibility.

along the n direction, orthogonally to the SAS and passing through the centre of the atom i (Fig. 2b). For the 12–6 Lennard–Jones potential, it follows that, with ε k, σ k and r k denoting the depth of the potential well, the distance at with such potential becomes zero and the Euclidean distance between the generic line point with coordinate n and the centre of k th nearest neighbour, respectively. For the Coulomb interactions, the average potential energy at a fixed temperature T between the N n atoms and the water dipoles is, where E, μ w, k B and Γ denote the electrical field strength, water dipole moment (7.50 × 10 −30 C m for the SPC/E model), the Boltzmann constant and the Langevin function Γ (x) = coth(x)−1/ x. The strength of the electrical field E can be readily computed following the law of electrostatics (see Methods). Knowing the effective potential U eff (n) for the atom i, a corresponding characteristic length δ i can be estimated within which the water molecules have reduced mobility. This length δ i is given by δ i = n i,2 − n i,1 where n i,2 and n i,1 are the two zeros of the equation U eff (n)+ k B T /4 = 0 (Fig. 2c). Therefore, based on the definition of δ i, all the water molecules located within such a distance are significantly affected by the van der Walls and Coulomb interactions, whereas all the water molecules beyond the characteristic length δ i can escape the potential well generated by the solid wall. Here k B T /4 is half the kinetic energy per independent degree of freedom according to the equipartition of energy (see Methods). By proper averaging over the surface, the mean characteristic length δ of the overall solid surface (Fig. 2d) can be derived as

---

### Cam morphology but neither acetabular dysplasia nor pincer morphology is associated with osteophytosis throughout the hip: findings from a cross-sectional study in UK biobank [^457dbc9c]. Osteoarthritis and Cartilage (2021). Medium credibility.

Fig. 1
Top left image: Sample DXA scan from UKB showing rHOA. Top right image: Outline points are shown around the femoral head and acetabulum on the same DXA scan. Points 22, 31, 78 & 84 are labelled and blue, they mark the point boundaries between which mJSW is calculated. Bottom left image: Outline points are shown along with osteophyte mark-ups where green denotes acetabular osteophytes and red superior femoral osteophytes. Bottom right image: Circle of best fit is shown in orange with purple lines depicting how LCEA is calculated and yellow lines depicting how AA is calculated.

Alpha angle

To automatically derive alpha angle (AA), a custom Python script was developed that fits a circle of best fit using the outline points 15–28 around the femoral head. The script calculates the angle between a line passing through the centre of the femoral head and neck, and a line passing through the centre of the femoral head and the point at which the femoral head–neck junction leaves the circle of best fit (Fig. 1). An in-depth description of these methods including validation experiments has previously been published. Cam morphology was defined as AA ≥ 60°. For repeatability, 100 images were reassessed more than 2 months after initial reading with the same methods. The AA from each assessment was compared giving a concordance correlation coefficient 0.84, and cam morphology comparison gave a kappa 0.81 (97% agreement).

Lateral centre-edge angle

To automatically derive the lateral centre-edge angle (LCEA), a custom Python script was developed that calculates the angle between a line passing through the lateral edge of the acetabulum (defined by outline point 78) and the centre of the femoral head (defined by the circle of best fit as described above), and a line which passes perpendicular to the image x -axis through the centre of the femoral head (Fig. 1). Pincer morphology was defined as a LCEA of ≥ 45° and AD as a LCEA < 25°. 100 images were reassessed for repeatability more than 2 months after initial reading. The LCEA from each assessment was compared giving a concordance correlation coefficient 0.98, pincer morphology comparison gave a kappa 0.94 (99% agreement), and AD gave a kappa 1 (100% agreement).

---

### How ice grows from premelting films and water droplets [^d8e36798]. Nature Communications (2021). High credibility.

This allows us to determine the kinetic phase diagram, identifying the regions in (p, T) space where the different outcomes of the interfacial wetting dynamics is to be expected (Fig. 3). In particular, we identify three significant kinetic phase lines:
The line of kinetic coexistence (dotted-red line in Fig. 3) occurs when Δ p k = 0. The location of this line can be obtained from Eq. (7), for the choice Π (h) = 0. States above this line are effectively oversaturated and have stationary film thicknesses consistent with Π (h) < 0 and are effectively oversaturated. Accordingly, the Laplace condition for droplet formation is met for the first time, and droplets can be stabilized transiently. However, this occurs well above the liquid–vapor coexistence line, and explains why droplets reported in experiment are formed only above the condensation line. Fig. 3 Kinetic phase diagram for ice crystal growth. Panel a shows the equilibrium phase diagram and kinetic phase lines. The red solid line is the sublimation line, whereas the dashed lines are metastable prolongations of the vaporization (blue) and melting (black) lines. The filled triangle (▴) indicates the triple point where these lines meet. The remaining features describe the outcome of the dynamics. The shaded area designates the region of activated growth. The dotted lines are kinetic phase lines corresponding to kinetic coexistence (red dotted), kinetic α → β transition (blue dotted) and kinetic spinodal (green dotted) lines as explained in the text. Panel b shows sketches with the dynamics observed in different points of the phase diagram, as indicated with the corresponding symbols. The colored lines describe the ice/liquid (red) and the liquid/vapor (blue) surfaces enclosing the premelting film. The black arrows show the direction of preferential growth. At the point marked by an asterisk, in the region of activated dynamics, growth proceeds by horizontal translation of nucleated terraces. At points such as that marked by a circle, above the region of activated dynamics, growth can occur continuously without activation in a steady state of constant film thickness. At points such as that marked by the open triangle (△), above the kinetic coexistence line, droplets can condense and are stabilized transiently with a crater growing inside. At points such as that marked by a square (□), beyond the α → β line, films in the β -thick state can be stabilized transiently and form at the rim of the droplet. At higher pressures, past the kinetic spinodal line (green dotted), such as the point marked with a lozenge (♢), the crystal growth rate can no longer match the condensation rate, and the film thickness diverges. The detailed dynamics corresponding to symbols in the phase diagram is illustrated in Figs. 4 and 5.
The line of α → β kinetic transition (dotted-blue line in Fig. 3). At sufficiently high saturation, the linear term in ω k (h) stabilizes the β state transiently, and it is possible to observe the coexistence between α and β states that has been reported in experiments. The line where the condition is met is obtained by solving a double tangent construct as in usual wetting phase diagrams (Supplementary Note 5).
The kinetic spinodal line (dotted-green line in Fig. 3), which occurs when Δ p k = − Π spin, with Π spin the value at which the interface potential g (h) predicts that the liquid/vapor interface L lv becomes linearly unstable, i.e. has a spinodal. This condition leads to a line p spin (T) that can be obtained from Eq. (7), for the choice Π = Π spin. Crossing this line signals the region of the p - T plane where ice crystal growth cannot match the rate of vapor condensation, and the premelting film thickness diverges.

---

### Global increases of salt intrusion in estuaries under future environmental conditions [^786e446d]. Nature Communications (2025). High credibility.

We further computed changes in the return periods and levels of extreme salt intrusion events. We first calculated return periods and levels using the 35-year annual maximum timeseriesfor the present and future periods (the triangle and circle markers in Fig. 4 a). Next, Generalized Extreme Value (GEV) distribution functions were fitted to the return period curves for each period (gray dashed and orange solid lines for present and future). Here, 100-year events were considered as typical extreme events (blue vertical line). The extreme return levels were defined as extrapolatedthat corresponds to the 100-year return periods based on the fitted GEV distribution functions (i.e.where gray dashed and orange solid curves intersect with the vertical blue line). The extreme return levels for the present and future are denoted asand, respectively (red horizontal dashed and solid lines, respectively). Pangani was taken as an example to visualize the changes in return period curves where we observed the largest relative increases in the future 100-year return level (Fig. 4 a). The same plots for all the remaining estuaries are presented in Supplementary Fig. S9. The relative changes of the 100-year return levels are defined as. The following results focus only on the future simulations in which all the changes in forcings are considered, including the river discharge and RSLR (δ Q & δ H R case). We find − 0.28 ≤ Δ X y r 100* ≤ 0.25 (median 0.095) for all the studied estuaries and 0.032 ≤ Δ X y r 100* ≤ 0.25 (median 0.10) for the 83% of the estuaries (15 out of 18) showing increasing future 100-year return levels. The changed future return periods for the extreme events were computed by finding points whereintersect with future return curves (i.e. the red horizontal dashed lines meet with the orange solid lines in Fig. 4 a). It is found that such future return periods are projected to decrease to 3.2 years for 6 estuaries on average (a, b, d, n, p, r in Supplementary Fig. S9). For 9 estuaries (c, g–k, m, o, q in Supplementary Fig. S9), the salt intrusion length belonging to a future 2-year return level is larger than ones corresponding to the extreme event under present-day conditions, as is seen from the orange circles always being above the red horizontal dashed lines. For 3 estuaries (e, f, l in Supplementary Fig. S9), return levels in future are projected to be reduced because of increasing magnitude of low discharge. Our results show that events that are considered as extreme in the present-day would occur much more frequent under changes in river discharge and increasing water depth in the future climate.

---

### Non-markovian recovery makes complex networks more resilient against large-scale failures [^5a2a638c]. Nature Communications (2020). High credibility.

Fig. 3
Evolutionary properties of MR dynamics.

The dynamical process can be represented as a flow diagram with the lines showing how the fractions of [X], [Y], and [A] evolve in time. The solid circles are the fixed points that the system will finally evolve into. a Theoretical calculations based on the mean-field theory. The open circles trace out a separatrix, with systems on different sides evolving into different fixed points. b Simulation results. The system parameters are β 1 = 0.004, β 2 = 2.0, μ 1 = 0.01, and μ 2 = 1.

Pairwise approximation theory for the MR model: It is possible to formulate a theory that takes into account of two-node spatial correlation based on the pairwise approximation (PA). The basic idea is to follow the evolution of different types of links, i.e. links that connect different pairs of neighboring nodes. The PA method has been used widely in studying epidemic and information spreading –, and in coevolving voter models and adaptive games with two or more strategies –. In "Effect of nodal correlation: pairwise approximation for the MR model" of "Methods" section, we develop a PA based theory for the MR model.

Fig. 4
Comparison of simulation results with predictions from PA analysis and mean-field theory for the MR model.

a Time evolution of the fraction of inactive nodes. The initial conditions are [X] 0 = [Y] 0 = 0. The parameter values are β 1 = 0.009, β 2 = 2.0, μ 1 = 0.01, and μ 2 = 1.0. Several time instants are marked to facilitate visualization of the time evolution in different stages: t O = 0, t A = 60, t B = 120.7, and t C = 480. b Phase diagram on the (β 2 − β 1) parameter plane. Other parameters are μ 1 = 0.01, and μ 2 = 1.0. c Dependence of β c on the initial value of [X] 0, with [Y] 0 = 0. The solid (dashed) curve is calculated by the PA (mean-field) theory, and the symbols are for simulation results obtained by averaging over 100 realizations.

---

### Primer on logistic regression for emergency care researchers [^12c58eb1]. The Journal of Emergency Medicine (2022). Medium credibility.

Background

Logistic regression plays a fundamental role in the production of decision rules, risk assessment, and in establishing cause and effect relationships. This primer is aimed at novice researchers with minimal statistical expertise.

Objective

Introduce the logit equation and provide a hands-on example to facilitate understanding of its benefits and limitations.

Discussion

This primer reviews the mathematical basis of a logit equation by comparing and contrasting it with the simple straight-line (linear) equation. After gaining an understanding of the meaning of beta coefficients, readers are encouraged to download a free statistical program and database to produce a logistic regression analysis. Using this example, the narrative then discusses commonly used methods to describe model fitness, including the C-statistic, chi square, Akaike and Bayesian Information Criteria, McFadden's pseudo R 2, and the Hosmer-Lemeshow test. The authors provide a how-to discussion for variable selection and estimate of sample size. However, logistic regression alone can seldom establish causal inference without further steps to explore the often complex relationship amongst variables and outcomes, such as with the use of a directed acyclic graphs. We present key elements that generally should be considered when appraising an article that uses logistic regression. This primer provides a basic understanding of the theory, hands-on construction, model analysis, and limitations of logistic regression in emergency care research.

Conclusions

Logistic regression can provide information about the association of independent variables with important clinical outcomes, which can be the first step to show predictiveness or causation of variables on the outcomes of interest. © 2022 Elsevier Inc.

---

### Nonlinear delay differential equations and their application to modeling biological network motifs [^8c888ca3]. Nature Communications (2021). High credibility.

Motif II: autoregulation

Autoregulation, one of the most common biological motifs, describes a single biological species that regulates its own production (Figs. 4 a–c).

Fig. 4
The complete phase diagram for the autoregulation network motif has analytically derivable parameter regions for bistability, monostablility, monostablility with damped oscillations, and oscillations.

a The autoregulation network motif, with a dotted arrow indicating either (b) self-activation or (c) self-repression. The two cases are given by n < 0 (activation) and n > 0 (repression). d Stable (black circles) and unstable (white circles) fixed points for activator and repressor cases are given by the intersection of the regulation (solid) and degradation+leakage (dashed) lines. Note that activators can have 1, 2, or 3 fixed points, whereas repressors always just have one. e Parameter space showing all possible behaviors for autoregulation with delay. Shading shows simulation results (with an interval of 0.1 for both γ and η axes) and curves show the analytically derived bifurcation boundaries. See Supplementary Fig. 3 a for cases −3 ≤ n ≤ 3 and Supplementary Fig. 3 b for boundaries in η vs. n parameter space. f Representative simulation curves for the four qualitatively different behaviors, with different colors representing different initial conditions (see "Methods"). ϵ = 0.

The complete phase space for autoregulation demonstrates the quantitative and qualitative importance of delays

Based on Eq. (5), the governing equation for such a system with delayed regulation is given by setting Y = X (output equals input) in Eq. (7):This equation has four parameters (η, γ, ϵ, and n).

Since leakage must be small relative to regulation (i.e. ϵ / η ≪ 1) for regulation to be strongly effective ("activated" rate much greater than "non-activated" rate), we will focus here on the case with no leakage (ϵ = 0). We treat non-negligible leakage in the supplements (Supplementary Note 3). Note that in general Eq. (11) has no closed-form solution.

---

### Approaches to nonlinear curve fitting in laboratory medicine [^1824a689]. Laboratory Medicine (2024). Medium credibility.

Nonlinear curve fitting is an important process in laboratory medicine, particularly with the increased use of highly sensitive antibody-based assays. Although the process is often automated in commercially available software, it is important that clinical scientists and physicians recognize the limitations of the various approaches used and are able to select the most appropriate model. This article summarizes the key nonlinear functions and demonstrates their application to common laboratory data. Following this, a basic overview of the statistical comparison of models is presented and then a discussion of important algorithms used in nonlinear curve fitting. An accompanying Microsoft Excel workbook is available that can be used to explore the content of this article.

---

### How dieting might make some fatter: modeling weight cycling toward obesity from a perspective of body composition autoregulation [^32b99e3d]. International Journal of Obesity (2020). Medium credibility.

Two exponential fits are shown: a generalized linear model (GLM) with 95% confidence intervals (solid line), and a linear model (LM), with R 2 values (dotted line). The four figures correspond to the four methods presented in the main text for computing the value FAT END at the final time END at which the subjects would have completely recovered their initial FFM. The two red squares correspond to the US Army Ranger data points presented in the section on 'Applications of the Model'.

Their exact values depend on the method used for computing the values FAT END when the FFM has been completely recovered and on the type of statistical regression used. As explained previously, we consider four methods for computing FAT END. In Fig. 4, we show the fits obtained from a generalized linear model (GLM) with 95% confidence intervals (solid line) and from a linear model (LM), with R 2 values (dotted line). Following the performance of diagnostics tests to analyze the residuals, it is found that the GLM satisfies the major assumptions of regression analysis better than the LM, especially concerning the normality assumption of the error terms. Nevertheless, as shown in Fig. 4, both models give curves that are close to each other. In simple terms, the main difference between the above LM and GLM approaches to estimate the best parameter values for the constants a and b is the way the error term is handled. In the LM method, we write y = a × e bx × ε, where ε is a random error variable that follows a log-normal distribution with parameters μ = 0 and σ 2. Taking the logarithm on both sides of the equality gives, which corresponds to the linear model, where, x ′ = x, β 1 = b andis a random error variable that follows a normal distribution with mean μ = 0 and variance σ 2. Note that in the LM method, the error term ε is multiplied with the exponential function y = a × e bx. In the GLM method, the error term is instead added to the exponential function. Formally, we write y = a ×e bx + ε, where ε is a random error variable that follows a normal distribution with mean 0 and variance σ 2. As a consequence, the GLM admits the possibility of the value y = 0 (which is excluded in LM) and assumes that the variance V (y) is constant, while the LM method assumes that V (y) varies with x. Finally, note that the LM method admits exact analytical solutions for the model parameters a and b, while the GLM method requires numerical optimization algorithms to find the best values (the maximum likelihood estimates) for a and b.

---

### Minimum electric-field gradient coil design: theoretical limits and practical guidelines [^075005b9]. Magnetic Resonance in Medicine (2021). Medium credibility.

Regions A and B are geometrically symmetric about the z = 0 plane, with minimum energy solutions (assuming no E‐field constraint) yielding z‐symmetric field solutions and zero B 0 concomitant fields. Hence, the open diamond starting point (representing the minimum energy solution with no E‐field constraints) for the solid and dashed curves (in both black and green cases) coincide. The symmetry is broken by the addition of a patient model with an E‐field constraint.

The knee in the curves marks the point where magnetic energy, current density, and winding complexity increase rapidly as E max is driven to lower values. These complexities render unrealizable or impractical any gradient designs on the vertical portions of the curves to the left of the knee. Examination of winding patterns indicates that solutions that exhibit energy increases > 25% (or even less depending on coil type) above the global minimum energy become unrealizable (eg, demonstrating two or more "eyes" per half coil [four or more total eyes for an x or y coil] in the fingerprint wire patterns).

The red and purple dotted curves in Figure 2 represent two practical cases in which the primary coil currents are restricted to a single inner surface near the patient and the shield coil currents to an outer cylinder, while at the same time adding torque and eddy current constraints. Line segments acd of Figure 1 represent a primary winding surface consisting of a cone and a cylinder, whereas line segment ab represents its cylindrical shield winding; this yields designs similar to those proposed by previous literature 8, 22 and results in the red dotted curves in Figure 2. A second case is defined by restricting primary currents to the cylinder represented by line segment cd and shield currents to the cylinder ab; this yields designs similar to those proposed by previous literature 28 and produces the purple dotted curves in Figure 2. For both configurations, the eddy current surface is a 1‐m‐long, 620‐mm‐diameter cylinder, centered about the gradient isocenter and placed outside the shield winding of the gradient coil. The time = 0 eddy current error is constrained to a peak deviation less than 0.1% of the ideal gradient field on the surface of a 20‐cm‐diameter volume, corresponding to 100 µT for a 1 T/m step change in gradient strength. The torque constraint is set to zero for a uniform z‐directed B 0 main magnetic field. There is no net force for a perfectly uniform main B 0 field in all calculations.

---

### New particle formation from isoprene under upper-tropospheric conditions [^aa4be822]. Nature (2024). Excellent credibility.

Fig. 2
Particle-nucleation rates from IP-OOM at −30 °C and −50 °C, with variable NO x.

a – d, Nucleation rates at 1.7 nm, J 1.7, versus IP 0N without NO x present (a), IP 0N with NO x (b), HIO x + H 2 SO 4 with and without NO x (c) and the product (HIO x + H 2 SO 4) × IP 0N with and without NO x (d). Measurements without NO x are indicated by diamonds (without acids) and circles (with acids). Measurements with NO x are indicated by triangles (without acids) and squares (with acids). Hollow symbols indicate −30 °C and solid symbols indicate −50 °C. In c, nucleation rates measured at contaminant acid concentrations are assigned the acid limit of detection (around 2 × 10 4 cm −3). The solid lines in c show the nucleation rates expected for H 2 SO 4 with 4 pptv NH 3 at −30 °C (red) and −50 °C (blue), both at 60% RH. The dashed and solid lines in d represent fits to the equation 10 a ×log10(x)+ b, in which, for the dashed line, a = 1.241 and b = −15.065, and for the solid line, a = 1.505 and b = −19.948. Panels a – c show that both IP 0N and total acid (HIO x + H 2 SO 4) contribute to the nucleation rate. Panel d indicates that it is the product of IP 0N and total acid (that is, the dimer formation rate) that best describes the nucleation rate, J 1.7, as the data points cluster into two groups primarily characterized by temperature alone. IP 1-2N also contribute to particle nucleation but they are less effective than IP 0N (Extended Data Fig. 5). The experimental conditions are: isoprene = 0.04–1.50 ppbv (0.1–4.2 × 10 10 cm −3), O 3 = 1–590 ppbv (3.7 × 10 10 to 1.8 × 10 13 cm −3), I² = 0–7.5 × 10 7 cm −3, SO 2 = 0–4.6 × 10 9 cm −3, OH = 0.11–6.90 × 10 7 cm −3, HO 2 = 0.6–17.0 × 10 8 cm −3, HO 2 /OH ratio = 11–118, NO = 0–0.22 ppbv, NO 2 = 0–0.77 ppbv, RH = 29–70% and temperature = −30 °C and −50 °C. The error bars represent the standard deviation of the measurement at steady state. All measurements are made under galactic cosmic ray conditions (natural ionization amounts).

---

### Mathematical method to build an empirical model for inhaled anesthetic agent wash-in [^38a7677f]. BMC Anesthesiology (2011). Low credibility.

Part II. Prospective testing

Solving the above derived equation for F D yields the following equation:

where Time = desired time lag after turning on the vaporizer to reach F At (any value between 1 and 5 min); and Ht = patient height in cm. After entering F At, Time, Ht, and chosen FGF, the corresponding F D to reach F At within the desired time lag can be calculated. Because any FGF can be chosen, this will result in a virtually infinite number of FGF - F D combinations. Patient demographics for each subgroup are presented in Table 1. Performance parameters PE, MDPE, APE and MDAPE for the three subgroups are presented in Figure 4, that also includes the linear regression line and a third order polynomial fit to examine whether PE and APE systematically increased or decreased with increasing FGF. MDPE and MDAPE were -2.9 and 7.0% in the 3.5% after 3.5 min group, -3.4 and 11.4% in the 5% after 5 min group, and -16.2 and 16.2% in the 6% after 4.5 min groups, respectively. There was a very weak (linear) correlation between F A and age, but not with height (effect incorporate in model) and weight (Figure 5).

Figure 4
Model performance. Performance Error (PE, %, closed circles, group 3.5% after 3.5 min = A; group 5% after 5 min = C, and group 6% after 4 min = E) and Absolute Performance Error (APE, %, open circles, group 3.5% after 3.5 min = B, group 5% after 5 min = D, and group 6% after 4 min = F), with their respective linear regression line (hatched), polynomial fit (grey line), and median performance error (MDPE, continuous black line, A, C, and E) and median absolute performance error (MDAPE, continuous black line, B, D, and F).

Figure 5
Prospective testing. Linear regression between covariates (age, height, and weight) and residual error (predicted minus measured end expired desflurane concentration) in the 3.5% after 3.5 min group (A, B, and C), the 5% after 5 min group (D, E, and F), and the 6% after 4.5 min group (G, H, and I).

---

### Repeatability and reproducibility of a new method for centration analysis via optical zone tangent points after corneal refractive surgery [^c2a71e18]. BMC Ophthalmology (2024). Medium credibility.

Fig. 1
The left panel is a composite picture using the square method to measure the COZ on the Pentacam tangential difference map. A rectangle is formed by hypothetical tangents (red dashed lines) in four directions: superior, inferior, nasal, and temporal to the optical zone. Point O is the geometric center of the rectangle, i.e. the center of the optical zone. In the right panel, the point of the farthest edges of OZ at the temple is located on the Pentacam tangential difference map. The diopter of this point is 0.0D and the coordinates of this point (-2.53 mm, -0.57 mm) are directly shown on the map. Examiners could judge the location of the tangent point by moving the mouse and observing the changes in the values of the coordinates and diopters during the measurement process

Located the tangent points on the farthest edges of the OZ at the temple, nasal, superior, and inferiorregions (Fig. 2)). The coordinates of the COZin the tangential difference maps were calculated using the following formulas,

Fig. 2
On the tangential difference maps, the tangent point is depicted with a black cross, which also indicates the position of the mouse cursor during the measurement. The left aspect of the image represents the temporal side. The coordinates of the tangent point are displayed directly in the lower left corner of each panel. For the right eye, the positive x values indicated nasal decentration and negative x values indicated temporal decentration

The centration analysis on the pachymetry difference maps was conducted similarly. The OZs in the pachymetry difference maps resemble the shape of concentric circles. The coordinates of the four tangent points were located on the smallest circle encompassing the maximum pachymetrical difference (Fig. 3). The coordinates of the COZin pachymetry difference maps were calculated by the following formula

---

### Modeling the electrical resistivity of polymer composites with segregated structures [^efc4bc6b]. Nature Communications (2019). High credibility.

Computational modeling

To represent a random configuration of silica particles on a cubic domain, spheres are scattered by choosing the center coordinates of each individual sphere uniformly at random. Spheres are placed one-by-one so that the distances from the designated center position to the center positions of pre-existing spheres are apart from each other farther than the diameter. The diameter of the sphere is set to the average size of the silica filler, and the number of spheres per unit volume is determined according to the weight ratio of silica particles in the composite samples used in the experiments.

Upon the completion of the random placement of circular fillers, a CNT network is created on the domain by placing multiple random instances of a flexible wire. According to morphological characteristics as observed in the SEM and TEM images, a random instance of the wire is placed so that a CNT wire is distributed uniformly in the simulation domain and can proceed forwardly to pass through a gap between silica particles but cannot penetrate the particles. The flexibility of a CNT wire is reflected by modeling them as a series of small line segments connected with joints that can bend freely within a certain degree (up to 120°). To create a single wire on the domain, constituting line segments are placed in sequence from one side to the other. The first line segment is placed at random in the volume that spheres do not occupy. Subsequent line segments are placed in a straight line unless they touch spheres. If the line segment touches a sphere, the direction of the line segment is changed toward a tangential direction of the sphere in contact so that the wire smoothly circumvents the sphere. The width and length of a single wire are set to the average diameter and length of CNTs used in the experiment, respectively. The length of a line segment is set the same as the width of the wire, and thus the line segment can be thought as of a small spherical cylinder of the identical height and width, i.e. with a square side view. This facilitates the test for the connectivity of two wires since the contact suffices to check whether, at each endpoint of a line segment, there exists any other endpoint of a line segment from a different wire within a ball of radius equal to the length of the line segment centered at the endpoint. A graphical description of the procedure is illustrated in Supplementary Fig. 1. A sample cubic domain of 10 μm × 10 μm × 10 μm is taken from the composite model to obtain the CNT network. The connectivity of the domain is checked by examining the contacts between flexible wires. For a pair of two wires, all possible pairwise distances between two line segments from respective wires are calculated. If at least one value of the distances is less than 2 nm, which is based on a tunneling mechanism (see Supplementary Note 1) –, the two wires are considered to be in contact at the position of the corresponding line segments. A graphical representation of the procedure is presented in Supplementary Fig. 2. A clustering analysis identifies percolating clusters of wires that span across the domain. Starting from the leftmost wires touching the left end, each cluster is expanded gradually toward the right end by including wires in contact. If a cluster contains one of the rightmost wires touching the right end, this cluster is declared to be a conducting path. For all conducting paths, KCL is applied at all junctions of wires to construct a system of linear equations about voltage drops across the junctions due to the contact resistivity (ρ c). In the simulation, ρ c is considered as a tunneling resistivity arising from the thin insulating layer (i.e. epoxy resin) between crossing CNTs –. Since 1 V voltage is assumed to apply across the domain, the inverse of the solution of the system of linear equations corresponds to the overall resistance of the network. This process is repeated to obtain 500 independent random instances, and an ensemble average of the resistance is calculated based on the set of tested samples between 30th percentile and 70th percentile. The simulation is conducted over different configurations of silica content, silica size, CNT content, and CNT dimension. For massive simulation, the source code is implemented in MATLAB parallel computing tool box.

---

### Quantitative imaging metrics for the assessment of pulmonary pathophysiology: an official American Thoracic Society and Fleischner society joint workshop report [^6517cbfd]. Annals of the American Thoracic Society (2023). High credibility.

Basic stereological measurements — first-order parameters and probes identify that "First-order parameters are volume (three-dimensional [3D]), surface (two-dimensional [2D]), length (one-dimensional [1D]), and number (zero-dimensional [0D])". Measurements "are performed using geometric test probes, such as points (0D), lines (1D), planes (2D), or volumes (3D)". These probes create countable events in the image, and "Raw counts provide ratios… that are multiplied by the reference space volume to obtain absolute measures for the lung or subcompartment".

---

### Non-linear relationships in clinical research [^668fb19a]. Nephrology, Dialysis, Transplantation (2025). Medium credibility.

Polynomial functions

In Fig. 4, we provide an example of a simple power transformation using the square function, which raises a variable to the power of 2 (x 2), providing a U-shaped curve. Higher powers of x can be also used to determine the shape of the function, such as the cubic function (x 3) which has a distinctive S-shape. These power terms form the core elements of so-called polynomial functions, which along with the coefficients included in the function, offer a flexible way to model various curves. By adjusting the coefficients and power functions, polynomials offer a wide variety of shapes. "Fractional" polynomial functions allow the power terms to be fractions instead of just whole numbers (i.e. x 1/2) [21]. A (fractional) polynomial function often provides sufficient flexibility to follow relatively simple non-linear curves, providing a simpler solution than the more advanced techniques we describe below. However, higher degree polynomials can be sensitive to "noise" in the data, and are not suited for fitting some of the more complex curves (e.g. sudden shifts, discontinuities, or logarithmic curves). They may also suffer from Runge's phenomenon, becoming unstable and oscillating at the edges of the data, and extrapolate poorly beyond the original range of the independent variable.

Regression splines

A powerful approach to dealing with non-linearity is provided by the family of spline functions. Instead of a single function defining the whole curve, such as polynomials or other transformations, splines are constructed by using a series of functions, each defining a different segment of the curve. As splines are constructed segment by segment — or piece by piece — they are often referred to as "piecewise" functions. Segments are connected to each other using so-called "knots", and the spline is restricted to join at these knots so there are no gaps in the curve. The simplest spline function is the linear spline function. This function assumes linearity within each segment, but the overall curve formed by the connected segments can be non-linear. For a small number of segments, linear spline models can be as easy to interpret as linear regression, as each segment can be represented by a single slope. Figure 3 provides an example of a simple linear spline with two knots (in green). These two knots divide the range of the independent variable into three segments, each with its own slope.

---

### Dispersion-engineered metasurfaces reaching broadband 90% relative diffraction efficiency [^cade3067]. Nature Communications (2023). High credibility.

Design

We first created a 'library' of nanostructures through parameter sweep of mirror symmetric nanostructures. Finite-difference time-domain (FDTD) simulations (Lumerical, Ansys) were performed to obtain far-field phase spectra for wavelengths 400–800 nm (in 10 nm per step) under circularly polarized incidence. Period boundary condition was used. The rotation angle of each element was kept constant during simulation as the rotation-induced phase delay can be predicted by Pancharatnam-Berry phase. After simulating each nanostructure, we obtained the polarization converted and conserved phases over the entire bandwidth from 400–800 nm (and) and fitted them by a quadratic polynomial (, where ω is angular frequency and a 1 to a 3 are fitting coefficients) from wavelength 450 nm to 700 nm to get group delay and group delay dispersion. After the fitting, each nanostructure gets a number of goodness of fit. Subsequently, we removed those nanostructures whose goodness of fit is lower than 0.98 in order to exclude the nanostructures with strong resonances within the design bandwidth. Figure S2 shows the nanostructures, as blue circles located by their polarization converted and conserved phases at design wavelengths as x - and y -axis before and after applying the filter condition. The total amount of nanostructures reduced from about 20,000 to 7900. The black line in Fig. S2b indicates the target linear phases of grating (equally sampled 8 times from 0 to 2 π). The next goal is to make sure each target black circle can find a corresponding blue one. Note that, because phase is relative, the blue circles are allowed to shift together horizontally and vertically until a figure of merit is maximized or minimized. To implement such process, we used Matlab to write a two-variable (phase shifts along x - and y -directions) particle swarm code by using the 1 st -order grating diffraction efficiency or wavefront aberration function as figure of merit. For the former figure of merit, the 1 st -order diffraction efficiency was calculated by Fourier transform and scalar diffraction theory, then the data was sent back to the Matlab particle swarm algorithm as feedback for the code to find the best shifts. In the latter, we used nanostructure phases from the library and calculated the wavefront aberration function with respect to the target linear one. It is worth mentioning that the above process does not guarantee the global best solution because of approximations. We therefore repeated the above-mentioned process and generated ~30 different metagrating designs. The best one was reported in the main text while a few of the rest are shown in Fig. S13.

---

### Comparison of airway opening pressure measurements: low-constant-flow vs. constant low-slope pressure ramp methods [^4415fc00]. BMC Anesthesiology (2025). Medium credibility.

Fig. 2
Bland-Altman plots and Passing-Bablok regression analysis between AOP flow and AOP pres (a) and (d) represent all patients, (b) and (e) represent patients with AOP flow ≥ 5 cm H 2 O, and (c) and (f) represent patients with AOP flow < 5cmH 2 O. The Bland–Altman plots showed that the mean difference (bias) and the limits of agreement (precision) between AOP flow and AOP pres were (a) 2.5 cmH 2 O (95% confidence interval [CI]: 1.9–3.1) and limits of agreement (precision) were − 1.1 cmH 2 O and 6.1 cmH 2 O, respectively, in all patients, (b) 3.7 cmH 2 O (95% CI: 2.9–4.6) and limits of agreement (precision) were 0.15 cmH 2 O and 7.3 cmH 2 O, respectively, in patients with AOP flow ≥ 5cmH 2 O, and (c) 1.4 cmH 2 O (95% CI: 1.0–1.7) and limits of agreement (precision) were − 0.21 cmH 2 O and 3.0 cmH 2 O, respectively, in patients with AOP flow < 5cmH 2 O. The solid blue line represents the bias, whereas the solid red lines represent the upper and lower limits of agreement. Gray circles represent individual data Passing-Bablok regression analysis showed that the regression equation was (d) y = 1.39x + 0.90 (95% CI for slope b: 1.20 to 1.65, 95% CI for intercept a: 0.48–1.64) in all patients The equation was (e) y = 0.82x + 4.51 (95% CI for slope b: 0.50 to 1.17, 95% CI for intercept a: 2.57–6.72) in patients with AOP flow ≥ 5cmH 2 O, and (f) y = 0.2 + 2 × (95% CI for slope b: 1.00–5.50, 95% CI for intercept a: −2.78–1.15) in patients with AOP flow < 5cmH 2 O. The solid red line represents the regression equation. The dotted blue lines represent the equation of y = x. Gray circles represent individual data AOP, airway opening pressure

---

### Primer on binary logistic regression [^4e5ef025]. Family Medicine and Community Health (2021). Medium credibility.

The twovalues are below two and so are not problematic. For this model, the no perfect multicollinearity assumption is met.

The linearity assumption requires that continuous independent variables, or predictors, have a linear relationship with the log-odds of the predicted probabilities for the outcome. Linear relationships are relationships that seem to follow a relatively straight line. One way to check this relationship is to create a scatterplot with the continuous predictor on the x-axis and the log-odds of the predicted probabilities on the y-axis. Add a loess curve and a line representing a linear relationship between the two variables to the scatterplot. The loess curve shows the relationship between the predictor and the transformed outcome in a more nuanced way, while the fitted line shows what the relationship between the two would be if it were linear. If the loess curve and the fitted line are approximately the same, the linearity assumption is met. If the loess curve deviates from the line, the linearity assumption fails.

The loess curve is very close to the linear relationship so the linearity assumption appears to be met (figure 2). Assuming that these data were collected using an acceptable sampling frame without related observations (independence of observations assumption), the data meet the assumptions to report the model as unbiased.

Figure 2
Checking the linearity assumption graphically.

Step 3: estimate the binary logistic regression model

The dependent variable for binary logistic regression is a categorical variable with two categories (denoted as y in equation 1). In the statistical model it is transformed using the logit transformation into a probability ranging from 0 to 1 (equation 1).

Equation 1. A statistical form of the binary logistic regression model.

In equation 1, the p(y) stands for the probability of one category (often the presence of a behaviour or condition) of the dependent variable, theare coefficients of the independent variables or predictors, and theare the independent variables. Those who are familiar with linear regression might notice that the statistical form of the linear regression model is inside the parentheses of the exponent ofin the denominator of the right-hand side of the equation.

---

### Indocyanine green [^def168cb]. FDA (2015). Low credibility.

Photometric Method

Determination Using Percentage Retention of Dye:

A typical curve obtained by plotting dye concentration versus optical density is shown opposite. Percent retention can be read from this plot.

If more accurate results are desired, a curve using the patient's blood and the vial of Indocyanine Green being used in the determination can be constructed as follows:

Take 6 mL of non-dye-containing venous blood from the patients arm. Place in a test tube and allow the blood to clot. The serum is separated by centrifugation.
Pipette 1 ml. of the serum into a microcuvette.
Add 1 lambda (λ) of the 5-mg/mL aqueous Indocyanine Green solution to the serum, giving a dilution of 5 mg/liter, the standard for 50% retention. (The addition of 2 lambda (λ) of the 5-mg/mL Indocyanine Green solution would give 100% retention; however, this concentration cannot be read on the spectrophotometer.)
The optical density of this solution is read at 805 nm, using normal serum as the blank.
Plot the 50% figure obtained in Step 4, and draw a line connecting this point with the zero coordinates.

Percentage Retention:

A single 20-minute sample (withdrawn from a vein in the opposite arm that injected) is allowed to clot, centrifuged, and its optical density is determined at 805 nm using the patients normal serum as the blank. Dye concentration is read from the curve above. A single 20-minute sample of serum in healthy subjects should contain no more than 4% of the initial concentration of the dye. The use of percentage retention is less accurate than percentage disappearance rate but provides reproducible results. Hemolysis does not interfere with a reading.

Determination Using Disappearance Rate of Dye:

To calculate the percentage disappearance rate, obtain samples at 5, 10, 15 and 20 minutes after injecting the dye. Prepare the sample as in the previous section and measure the opticaI densities at 805 nm, using the patient's normal serum as the blank. The Indocyanine Green concentration in each timed specimen can be determined by using the concentration curve illustrated. Plot values on semilogarithmic paper.

Specimens containing Indocyanine Green should be read at the same temperature since its optical density is influenced by temperature variations.

Normal Values: Percentage disappearance rate in healthy subjects is 18–24% per minute. Normal biological half-time is 2.5–3.0 minutes.

---

### Revealing the predictability of intrinsic structure in complex networks [^e364bb88]. Nature Communications (2020). High credibility.

Fig. 5
Effect of regular structures in networks.

a A schematic depiction of combining a circle model network (regular) into a real network. In the circle model network, each node has k c links with its closest nodes. b We decrease the regular links by using value of k c from 20 to 2 in the circular model network. Points with the same shape and color correspond to a real network. The arrow presents the flow of the value pair as k c decreases. It is clear that our theoretical prediction works better with less regular structural features.

In conclusion, for the first time we established a theoretical framework to quantify the intrinsic structure predictability in real and artificial random networks solely based on network structure, and independent from any prediction algorithms. With theoretical intuition on proper normalization, we uncover a universal linear relationship between the shortest compression length of the network structure and its structure predictability for a wide range of real networks such as biological networks, social networks and infrastructure networks, and analytically derived the mathematical origin of this linear relationship in artificial networks. In principle, such relationship can serve as a benchmark to quantify the performance of any practical prediction algorithm in non-regular networks. Leveraging upon this linear relationship, we can obtain the structure predictability that is intrinsic to the structure of complex networks and provide the accuracy bounds for any link prediction algorithm. In practice, our method can also be used to estimate the commercial value of a network dataset through its compressed length without using any link prediction algorithm. Our finding is demonstrated upon data structure in the form of networks. However, if the structural entropy and prediction limit are linked through the underlying dynamical process for data structures other than networks, it is likely that the predictability in some other machine learning problems for different types of systems can also be inferred through similar approaches of optimal compression.

---

### Towards fully integrated photonic displacement sensors [^20926c4e]. Nature Communications (2020). High credibility.

For each waveguide we fit a set of two linear equations to the experimental data (see Methods section), which are indicated as red (D 0), green (D 60), and blue (D 120) semi-transparent planes. The good overlap between the experimental data and the fitted planar equations validates the calibration process and the assumption of linearity. Especially the gradients of the three calibration planes can be used to assess the quality of our displacement sensor. For this reason we plot the gradients of each plane as red, green, and blue arrows in the upper right inset. The vectors basically follow the orientations of the waveguides (dotted black lines), with the biggest angular mismatch of ≈20 ∘ between the blue arrow and its corresponding waveguide, which can be attributed to aberrations of the incoming beam and the imperfections of the sample. The amplitudes of the gradient vectors represent an important measure of the sensitivity S of our device, which is defined as change in directivity per nanometer displacement. Here we achieve sensitivities of S 0 ≈ 0.33% nm −1, S 60 ≈ 0.37% nm −1, and S 120 ≈ 0.37% nm −1 that are up to one order of magnitude lower than recently reported comparable experimental results, which were achieved in the visible regime and without integration on a photonic chip. However, depending on the actual detector system, signals on the order of 1% and below are measurable, implying that displacements in the nanometer regime are observable.

Finally, in order to experimentally estimate the resolution of our integrated displacement sensing prototype, we perform a line scan along the x -direction — 11 positions with a step size of 25 nm each — where we measure 61 images for each position set by the piezo stage. Calculating the directivity parameter D 0 (the most sensitive parameter for shifts along the x -axis) for all camera frames results in the step function shown in Fig. 5 b, where each color-coded step corresponds to a different position. While the individual 25-nm steps can be observed with ease, we also see fluctuations of D 0 within each step, which are caused by real jittering of the sample relative to the beam and the noise of the camera. The measured standard deviations of D 0 of each step are indicated as horizontal, dotted black lines, while the median is indicated as solid line. The average standard deviation is ≈1.7%, corresponding to a positioning accuracy of ≈ ± 6 nm.

---

### Modeling presynaptic inhibition by the amyloid precursor protein demonstrates one potential mechanism for preventing runaway synaptic modification in Alzheimer's disease [^00165c4d]. Alzheimer's & Dementia (2025). Medium credibility.

Equations 1 and 2 are the standard equations for associative memory in numerous models. However, the network described by these equations is unstable and sensitive to interference between memories. Most associative memory models avoid this instability and interference by ignoring synaptic transmission during Hebbian synaptic modification, but here we focus on instability as an important property. The instability can be seen by combining the equations by replacing r in Equation 1 with r from Equation 2; this results in the following equation:

The instability of this equation is shown in Figure 2K–O. The figure shows that retrieval of a previous associative memory can influence the synaptic modification process during the encoding of a new overlapping associative memory. In this example, Figure 2K shows the case of a new episode that involves a single point of overlap in the presynaptic input with a previously encoded memory (the place). For example, you meet a second colleague at the same place where you met the first colleague. The overlap results in spread across previously strengthened synapses (thick blues lines, with the specific synapse involved in retrieval marked by the red line in Figure 2K). Thus, the same place can cause retrieval of the face from Memory 1 (orange circle in Figure 2K). This causes strengthening of additional incorrect synapses from the face in Memory 2 to the face in Memory 1, as shown by the orange line in Figure 2L. This problem becomes compounded further when learning another episode in succession in which there is one or more overlapping events with any previously encoded memories, as shown in Figure 2P–T. This eventually results in a weight matrix W that cannot discern any previously encoded memories from one another, with this problem resulting in unnecessary and undesired strengthening of many additional synapses.

---

### Light-driven continuous rotating Möbius strip actuators [^110f46f1]. Nature Communications (2021). High credibility.

Second, any specific point on the Möbius strip executed a nearly in situ flip motion in the vertical direction. The inner and outer surfaces of the C-Möbius[+1] ribbon were marked with a blue line and a red line normal to the long axis of the strip, respectively, and one point, mark C, was located at the junction of the blue line and red line. Figure 7c shows that in the first circle rotation, the inner and outer lines changed to red and blue lines, and mark C rotated 180° During the second circle rotation, the outer blue line rotated to the inner surface, and mark C returned to the original position after completing a 360° rotation. To dissect the rotation statistically, the position coordinates of mark C relative to midpoint O of the width of the Möbius strip were analysed and are plotted in Fig. 7d. We set the midpoint O of the width as the origin (0, 0) in the vertical x ′′- z ′′ plane and recorded the relative position coordinates of mark C during the rotation, which confirmed that the point on the ring edge was capable of moving along a roughly circular trajectory in the x ′′- z ′′ plane (Fig. 7e and Supplementary Movie 11). Furthermore, when mark C completed a 360° rotation, the locus of twist would have undergone two 360° rotation circuits. The flip circle trace was obtained by using Eq. (2) based on the least-squares method, and the trace radius R" was calculated as 1.5 mm.

---

### Comparison of parameter optimization methods for quantitative susceptibility mapping [^26a0417b]. Magnetic Resonance in Medicine (2021). Medium credibility.

Purpose

Quantitative Susceptibility Mapping (QSM) is usually performed by minimizing a functional with data fidelity and regularization terms. A weighting parameter controls the balance between these terms. There is a need for techniques to find the proper balance that avoids artifact propagation and loss of details. Finding the point of maximum curvature in the L-curve is a popular choice, although it is slow, often unreliable when using variational penalties, and has a tendency to yield overregularized results.

Methods

We propose 2 alternative approaches to control the balance between the data fidelity and regularization terms: 1) searching for an inflection point in the log-log domain of the L-curve, and 2) comparing frequency components of QSM reconstructions. We compare these methods against the conventional L-curve and U-curve approaches.

Results

Our methods achieve predicted parameters that are better correlated with RMS error, high-frequency error norm, and structural similarity metric-based parameter optimizations than those obtained with traditional methods. The inflection point yields less overregularization and lower errors than traditional alternatives. The frequency analysis yields more visually appealing results, although with larger RMS error.

Conclusion

Our methods provide a robust parameter optimization framework for variational penalties in QSM reconstruction. The L-curve-based zero-curvature search produced almost optimal results for typical QSM acquisition settings. The frequency analysis method may use a 1.5 to 2.0 correction factor to apply it as a stand-alone method for a wider range of signal-to-noise-ratio settings. This approach may also benefit from fast search algorithms such as the binary search to speed up the process.

---

### Modelling the temporal trajectories of human milk components [^a7f977f9]. BMC Pregnancy and Childbirth (2024). Medium credibility.

Fig. 9
Examples for our generic, two-phase saturation model. Broken line: initial phase (colostrum). Continuous line: second (saturation) phase. The alternative of the λ = 0 case (when the parameter a becomes per se insignificant) is λ = 6, with either a < 0, a = 0, or a > 0.000000000000000e+00 Similarly, significance test may show that r can be taken as zero, implying y 0 + aλ = y End

F-test decided whether the full two-phase model with four parameters (y 0, a, r, y End) were needed to describe a dataset, or any of the parameters could be a fixed value, to decrease the dimension of the model. Note that value set of λ was considered binary: it is either 6 (default) or 0. In the latter case, the first phase is embedded in the saturation model, and the result is a single-phase, pure saturation model, with three-parameters. Again, F-test decided if the single-phase pure saturation model was sufficient to fit a particular dataset or the λ = 6 case was significant with a slope a.

Similarly, F-test was used to decide whether one or two of the parameters can be considered identical, for a pair of datasets (e.g. a pair of trajectories, showing the effects of delivery mode; – see Fig. 4).

The secondary model could be used to quantify the effect of various factors, mother history and other characteristics on the fitted parameters (e.g. y End) of the primary model. The non-linear regression algorithm was built in a bespoke Microsoft Excel Add-In, written in Visual Basic, implementing the standard Levenberg–Marquardt method. The Data Analysis Add-In of Excel was used to carry out linear regression and ANOVA procedures, with 5% significance level.

---

### J-shapedness: an often missed, often miscalculated relation: the example of weight and mortality [^9e991138]. Journal of Epidemiology and Community Health (2014). Low credibility.

We present three considerations in analysing the association between weight and mortality, as well as other relations that might be non-linear in nature. First, authors must graphically plot their independent and dependent variables in a continuous manner. Second, authors should assess the shape of that relation, and note its shape. If it is non-linear, and specifically, J-shaped or U-shaped, careful consideration should be given to using the 'best' statistical model, of which multivariate fractional polynomial regression is a reasonable choice. Authors should also refrain from truncating their data to avoid dealing with non-linear relations.

---

### Systematic dimensional analysis of the scaling relationship for gradient and shim coil design parameters [^a1e900ab]. Magnetic Resonance in Medicine (2022). Medium credibility.

Purpose

To demonstrate systematic, linear algebra-based, dimensional analysis to derive a scaling relationship among the design parameters of MRI gradient and harmonic shim coils.

Theory and Methods

The dimensions of five physical quantities relevant for gradient coil design (inductance, gradient amplitude, inner diameter [d], current, and the permeability of free space) were decomposed into fundamental units, and their exponents were arranged into a dimensional matrix. The resulting set of homogenous equations was solved using standard linear algebraic methods. Inclusion of the number of turns as an additional unit yielded a 5×5 dimensional matrix with a unique, nontrivial solution. The analysis was extended to harmonic shim coils. The gradient coil scaling relationship was compared with data from 24 published gradient coil sets.

Results

Only when the unit of turns was included did the linear algebra-based analysis uniquely produce the known scaling relationship that gradient inductance is proportional to gradient efficiency squared times d⁵. By applying the same methodology to an lth order shim coil, a novel result is obtained: Shim inductance is proportional to its efficiency squared times d^(2l + 3). The predicted power-law relationship between inductance-normalized gradient efficiency and the diameter accounted for > 92% of the efficiency variation of the surveyed gradient coils. A dimensionless parameter is proposed as an intrinsic figure-of-merit of gradient coil efficiency.

Conclusion

Systematic application of linear algebra-based dimensional analysis can provide new insight in gradient and shim coil design by revealing fundamental scaling relations and helping to guide the design and comparison of coils with different diameters.

---

### Curvature in metabolic scaling [^f5c66bb0]. Nature (2010). Excellent credibility.

For more than three-quarters of a century it has been assumed that basal metabolic rate increases as body mass raised to some power p. However, there is no broad consensus regarding the value of p: whereas many studies have asserted that p is 3/4 (refs 1–4; 'Kleiber's law'), some have argued that it is 2/3 (refs 5–7), and others have found that it varies depending on factors like environment and taxonomy. Here we show that the relationship between mass and metabolic rate has convex curvature on a logarithmic scale, and is therefore not a pure power law, even after accounting for body temperature. This finding has several consequences. First, it provides an explanation for the puzzling variability in estimates of p, settling a long-standing debate. Second, it constitutes a stringent test for theories of metabolic scaling. A widely debated model based on vascular system architecture fails this test, and we suggest modifications that could bring it into compliance with the observed curvature. Third, it raises the intriguing question of whether the scaling relation limits body size.

---

### Singular sublimation of ice and snow crystals [^b1b6a9e0]. Nature Communications (2018). Medium credibility.

Fig. 5
Global ice drop evaporation. a Evolution of the volume V of the drop shown in Fig. 2; the inset shows the instantaneous volume flux d V /d t as a function of the drop radius. b radius R (red circles) and height H (blue circles) for the same drop. The dashed and solid lines denote the numerical simulation and analytical results, respectively (see Supplementary Note 2). c Experimental and numerical profiles taken every 15 min for the same drop

Simulations of evaporating snowflakes

The study of pointy ice drops provides us the ingredients to understand the evaporation of snowflakes. However, their geometry is more complex with several sharp regions next to each other. It was shown for arrays of evaporating drops that to first order, they do not influence each other if they are more than their characteristic size apart. This is not the case for the branches of the snowflakes, which are very close and interact with each other. Thus, the problem cannot be solved analytically, but we can nonetheless solve Eqs. (1) and (2) numerically using finite element simulations, which include these interactions (see Methods). We extract the initial projected snowflake shape by image processing and assume a uniform thickness as a first approximation. Then assuming typical experimental parameters, we compute the snowflake shapes at later times (Fig. 1b and Supplementary Movie 1). Because the shape evolution is governed by the geometry, this is sufficient to perfectly reproduce the snowflake shapes at various times, confirming that the very specific time evolution comes solely from the singular nature of the diffusion equation close to sharp points. Therefore, even more complex objects such as snow aggregates could be simulated, provided the full three-dimensional (3D) initial shape is known.

Application to dissolving solids

Our findings are relevant for studies of the ageing of snow or de-icing, but the methodology presented here is general to all free-boundary diffusive processes and can also be applied to the dissolution of solids, for instance to control the smoothness of surfaces during synthesis or to optimise crystalline shapes for drug dissolution (see Supplementary Note 2 and Supplementary Figure 8).

---

### Neurons exploit stochastic growth to rapidly and economically build dense dendritic arbors [^65c721f6]. Nature Communications (2025). High credibility.

Fig. 6
The mean-field model reveals that arbor expansion is driven by length fluctuations.

a Measured arbor diameters are plotted from 24–120 h AEL along the anterior-posterior (AP) and left-right (LR) axes. Growth initiates at 16 h AEL from a soma of size 10 µm (black hollow circle). Cubic regressions used to fit the front speed are shown in solid lines. b Dendrite length density along the LR axis is normalized by its central density. Solid lines show the mean front profiles at 24 (red), 48 (purple), and 96 (yellow) hours AEL, averaged from individual neuron front profiles shown in faded lines aligned at 10% of their central length density. The lower 25% of the densities are fitted with exponential functions (dashed lines) to estimate the decay length. c Allowed values of the front speedand decay lengthby Eq. (16). The marginally stable solution coincides with the global minimum of the front speed confined on the-curve (solid circles). The average measured front speed and decay length along the LR axis are visualized by solid triangles. d Numerical solutions of the dendrite density at 1600 min from an initial isotropic sigmoid front of radius ~10 µm. The computation uses parameters at 48 h AEL. e, f Front speed and front decay length from measurements along AP and LR axes, theoretical predictions, and numerical solutions at 24, 48, and 96 h AEL. All errors are standard deviations. Those for the theory are estimated by bootstrapping (Methods: Statistical Analysis).

To predict the front speed and decay length, we solved Eqs. (1)-(3) in a co-moving frame. To facilitate solution, we made three well-justified assumptions in the distal front: we omitted the internal dendrite density (because terminal branches are in the majority), we dropped the collision term (because it is second order in density, which is small), we set the radial transport termto zero (because it decays as). Using an exponential trial solution, we obtained a constraint Eq. (16) on the allowed values ofversusas shown in Fig. 6c. The marginally stable solutionmust satisfy. This condition pinpoints the emerging front speedas the minimal speed along the-curve, which corresponds to a singular solution for the decay length.

---

### KDIGO 2024 clinical practice guideline for the evaluation and management of chronic kidney disease [^34c1b44c]. Kidney International (2024). High credibility.

Early-stage chronic kidney disease risk prediction applicability and progression example — Practice Point 2.2.4 notes that risk prediction equations developed for use in people with CKD G3–G5, may not be valid for use in those with CKD G1–G2. The Work Group recognizes that in earlier stages (G1–G3), large declines in eGFR can occur in 2- to 5-year time frames without reaching kidney failure. Figure 16 illustrates this with a CKD G1–G2 profile in which kidney failure risk is 0.07% over 2 years and 0.32% over 5 years versus CKD progression risk of 10.4% over 3 years, for a 50-year-old male with diabetes with eGFR 80 ml/min per 1.73 m 2 and urine ACR 1 g/g.

---

### Translating the A1c assay into estimated average glucose values [^6c8643a2]. Diabetes Care (2008). Low credibility.

For measuring the steady-state correlation between AG and A1C, the study was designed to include subjects with relatively stable glycemia. A1C values were generally stable, with 96% of the subjects maintaining A1C within 1 percentage point of their baseline value over the course of the study.

The relationship between the A1C level at the end of the 3-month study period and the calculated AG during the preceding 3 months, expressed as the simple linear regression AG mg/dl = 28.7 × A1C – 46.7 (AG mmol/l = 1.59 × A1C − 2.59), R 2 = 0.84, P < 0.0001, is shown in Fig. 1. The correlation has an SD of prediction error of 15.7 mg/dl (0.87 mmol/l). Based on the model described in the statistical analysis section, the estimated values are as follows: α = −41.4, 95% CI −48.8 to −33.5; β = 27.9, 26.7–29.0; β1 = 4.81, 2.18–15.33; β2 = 2.03, 1.42–2.59. This leads to an estimated error SD of 13.4, 15.7, and 18.0 mg/dl when A1C is 6, 7, and 8%, respectively. The Bayesian model–suggested regression line differs < 2 mg/dl from a simple linear regression line in the A1C range of 4–10%, which includes 98.5% of our samples; the prediction intervals widen (P < 0.05) as A1C values increase to 12%, but the difference between the Bayesian and simple linear regression is still < 5 mg/dl. A Bland-Altman type of analysis examining the difference between the estimated glucose and observed glucose over the range of glucose values is shown in online appendix 2. The 90% prediction limits for the AG, based on the varying SD model, were very close to the preset limits of ± 15% of the predicted mean over the full range of A1C; 89.95% of the samples fell within 15% of the calculated AG.

---

### Graphs [^c6c6d5a7]. Chest (2006). Low credibility.

Two rules of good graphs are presented and explicated.

---

### Principled approach to the selection of the embedding dimension of networks [^0e29bd7c]. Nature Communications (2021). High credibility.

There could be several ways of finding the solution of Eq. (1). Here, given the smoothness of the empirically observed loss functions, we opted for a parametric approach. Specifically, we found thatwhere s and α are fitting parameters, represents well the data in various combinations of embedding methods and embedded networks. Equation (2) is meant to describe the mathematical behavior of the loss function only in the range d ∈ [1, d r). In particular in the definition of Eq. (2), L ∞ appears as the value of the normalized loss function in the limit of infinitely large embedding dimensions. However, such a limit has no physical meaning and is used only to facilitate the mathematical description of the empirical loss function in the regime d ≪ d r. Best fits, obtained by minimizing the mean-squared error, of the function of Eq. (2) are shown in Figs. 1 a, b and 2 a. We performed a systematic analysis on a corpus of 135 real-world networks. We found that best estimatesof the asymptotic value L ∞ for the normalized embedding loss function are generally close to zero (Supplementary Table 1). Best estimatesof the factor s, regulating the rate of the power-law decay toward L ∞, seem very similar to each other, irrespective of the network that is actually embedded. Measured values ofindicate only a mild dependence on the underlying network (see Fig. 3). For uncorrelated clouds of points in d dimension, the central limit theorem allows us to predict that L (d) ~ 1/ d 1/2. Our best estimatesof the decay exponent α are generally greater than those expected for uncorrelated clouds of data points, indicating that the embedding algorithm correctly retains network structural information even in high-dimensional space. In systematic analyses performed on random networks constructed using either the ER and the BA models, we find that the size of the network is not an important factor in determining the plateau value L ∞. The decay exponent α and the rate s are positively correlated with density of the embedded network, but their values become constant in the limit of large network sizes (see Fig. 4).

---

### Non-linear relationships in clinical research [^e9886c50]. Nephrology, Dialysis, Transplantation (2025). Medium credibility.

Figure 1:
A linear regression model fits a straight line (in blue) as close as possible to every data point (in black) on the scatterplot. The difference between each data point and the line produced by the model is called the "residual", represented here by the red lines.

Figure 2:
Scatterplots with linear regression line, residual plots, normal probability plots and histograms of residuals for both an example of a linear relationship, and an example of a non-linear relationship in which linear regression clearly does not fit the data. In the linear example (A), the residuals are spread randomly around the regression line (A1–A3), following an approximate normal distribution (A4), indicating a constant variance of residuals (i.e. homoscedasticity). In the non-linear example (B), a pattern is visible in the distribution of residuals (B1–B3), and the residuals follow a skewed, non-normal, distribution (B4), indicating heteroscedasticity — an important departure from the linear regression assumption of constant variance of residuals.

It should be noted that linear regression is not the only model that relies on a linear relationship; this assumption is common across many statistical models. In the case of linear regression, the model coefficient is interpreted as the change in outcome for a one-unit increase in the independent variable, and that this effect is constant across the full range of the independent variable. Logistic regression, for instance, used to model binary outcomes, also relies on the assumption of a linear relationship between a continuous independent variable and the log-odds — or logit — of the outcome occurring. Similar to linear regression, the modeled coefficient is interpreted as the change in the log-odds of the outcome occurring for every unit increase in the continuous independent variable. A residual plot of the continuous independent variable on the X-axis and the residuals on the Y-axis may help reveal any non-linear patterns in logistic regression. As mentioned above, splines can also be used exploratively to visualize the relationship between the continuous independent variable on the X-axis and the log odds on the Y-axis.

---

### Transition from the topological to the chaotic in the nonlinear Su-schrieffer-heeger model [^d9597125]. Nature Communications (2025). High credibility.

To analyze the correspondence between the nonlinear winding number and the dimension of the stable manifold, we consider the extended nonlinear SSH model in Fig. 1. In this model, we add next-next-to-nearest-neighbor hoppings (α Ψ B (x − 2) to Eq. (4) and α Ψ A (x + 2) to Eq. (5)) to the nonlinear SSH model. Figure 4 a presents the phase diagram of the extended SSH model in the linear limit b = c = 0 –. One can confirm that the winding number becomes ν = 2 at α > d − a and α > a.

Fig. 4
Vector fields representing the deviation of state variables in the extended nonlinear SSH model.

a Phase diagram of the linear extended SSH model. a, d, and α are real parameters that determine the strength of intercell, nearest-neighbor intracell, and long-range hoppings, respectively. Each color represents the parameter regions with the same winding number, which is shown by the numbers in the regions. b – d Vector field and the stable manifold. The blue curved arrows represent the vector field at (Ψ(x), Ψ(x + 1)) corresponding to the values of eigenvectors at the sites x and x + 1. The red disks are stable fixed points, the red squares are saddle points, and the green circle is a fully unstable fixed point. The orange curves are eye-guides of the one-dimensional stable manifolds. b If the winding number is one under weak nonlinearity (the blue circle in a), the stable manifold is one-dimensional. The parameters used are a = 0.5, b = d = −1, and α = 0.25. c When the winding number is two under weak nonlinearity (the red filled square in a), the fixed point is stable and thus has a two-dimensional stable manifold. The parameters used are a = 1, b = d = −1, and α = 4. d When the nonlinearity-induced topological phase transition from zero to one occurs (the green arrow in a), nonzero fixed points appear and their stable manifold is one-dimensional. The parameters used are a = 1.75, b = d = −1, and α = 0.25.

---

### Optimal free descriptions of many-body theories [^f77fa88f]. Nature Communications (2017). Medium credibility.

Methods

Optimization

The optimization to find σ andin (3) is performed by a Monte Carlo basin-hopping strategyusing the Nelder–Mead simplex algorithm for local minimization within basins of the cost function. This global strategy was selected to counteract an observed tendency for local methods to get trapped in local minima. The initial guess for this search is found as follows. The normalization constant E 0 is the lowest entanglement energy of the input entanglement spectrum { E }. We iteratively construct an approximate set of single-particle entanglement energies starting from an empty set. First, we take the lowest remaining level in the spectrum and subtract E 0 to produce a new single-particle level k. Then we remove the many-body levels, which are closest to the new combinatorial levels generated according to (2) by the additional single-particle level. This process is repeated until the input spectrum is exhausted. We can also introduce a truncation of the entanglement spectrum cutting off high entanglement energies, making the construction of the initial guess terminate faster. The minimization of D (σ, σ f) to identify the optimal free model for the Ising Hamiltonian (5) is calculated using a local Nelder–Mead method.

Finite-size scaling

We perform the finite-size scaling according to an ansatz (4). The parameters of the collapse were estimated using the method of ref. From the scaling ansatz (4) and for a trial set of scaling parameters g c, ν and ζ, the scaled values x L = (g − g c) L 1/ ν andare calculated from each unscaled data point. From this collection of scaled data points (x L, y L) across all L, we implicitly define a so-called master curve that best represents them. This curve y (x) is defined around a point x as the linear regression calculated by taking the scaled data points immediately left and right of x for each system size L. We characterize the deviation of the scaled points (x L, y L) from the master curve y (x L) using the χ 2 statistic. This measure is used as the cost function for an optimization problem over the scaling parameters g c, ν, ζ and θ, which can be solved using the same techniques as the previous problems.

---

### The drug titration paradox: correlation of more drug with less effect in clinical data [^632831e6]. Clinical Pharmacology and Therapeutics (2021). Medium credibility.

Monte Carlo simulations

Figure 4 shows the results for the simulations. Figure 4a shows the resulting effect when a normally distributed random dose was administered to 5,000 simulated individuals (Simulation 1). Figure 4b shows the resulting effect when given a dose equal to the individual D 50 was administered to 5,000 simulated individuals (Simulation 2). Figure 4c and d show the progression of the titration from step 1 to step 5 for β 1 = 0.5 and β 2 = 0.0 (Simulation 3). After 5 steps, 99% of the simulated subjects had an effect between 0.45 and 0.53. The coefficient of variation of the effect for the population was 2.89%. Figure 4e and f show the progression of the titration from step 1 to step 5 for β 1 = 0.5 and β 2 = 0.1 (Simulation 4). After 5 steps, 99% of the simulated subjects had an effect between 0.41 and 0.56. The coefficient of variation of the effect for the population was 5.53%.

Figure 4
The results of the Monte Carlo simulations. (a) Simulation 1: Random dose. (b) Simulation 2: Individualized D 50 dose. (c & d) Simulation 3: steps 1 and 5 using β 1 = 0.5 and β 2 = 0.0. (e & f) Simulation 4: steps 1 and 5 using β 1 = 0.5 and β 2 = 0.1. The dotted line represents the Hill equation. The dashed line is a linear regression through the simulated dose–effect data. The shaded regions provide examples for d an acceptable effect range and f an acceptable dose range. The titration paradox will be greater for a wider acceptable effect range and a narrower acceptable dose range. D 50, the dose causing 50% effect.

---

### In vivo validation of patient-specific pressure gradient calculations for iliac artery stenosis severity assessment [^114153aa]. Journal of the American Heart Association (2017). Low credibility.

Quantitative Accuracy of the Calculated Translesional Pressure Gradient

For every lesion, the in vivo measured and calculated pressure gradients during peak hyperemia are shown in Figure 4. A good agreement by overlapping error bars of the measured and calculated pressure gradient was found in 21 of the 25 lesions. Interestingly, all lesions with nonoverlapping error bars (lesions 5, 8, 15, and 18) correspond to the 4 points outside the 1 SD estimate of the hyperemic flow relation (Figure 3). The mean absolute difference and associated SD between the in vivo and calculated translesional pressure gradient after administration of a vasodilator was −0.9 ± 12.7 mm Hg (mean ± 2 SDs), which can be seen in the Bland‐Altman plot shown in Figure 5. The R 2 between the calculated and in vivo measured hyperemic pressure gradient with respect to the line y = x was 0.81 (Figure 6). It can be observed that the number of patients with a pressure gradient > 40 mm Hg is limited. However, these lesions are of less interest because a large error on the pressure prediction will still likely indicate a hemodynamic significant stenosis (∆p ≥ 10 mm Hg).

Figure 4
Calculated (blue) and in vivo measured (green) maximal pressure gradients observed after administering a vasodilator. The black markers below the lesion numbers indicate stenoses evaluated in the same patient but from different legs. A green circle around the lesion indicates overlap between the calculated and measured translesional pressure gradient. The red square indicates a nonoverlapping SD of the calculated and measured pressure gradient. The black dashed line indicates the cutoff for hemodynamic significant stenoses (≥ 10 mm Hg). 3DRA indicates 3‐dimensional rotational angiography.

Figure 5
Bland‐Altman plot demonstrating the bias (−0.9 mm Hg) between the calculated and measured translesional pressure gradient at maximal hyperemia. The 2 outer lines indicate the 2lower and higher than the mean bias (± 12.7 mm Hg).

Figure 6
Correlation between in vivo measured and calculated pressure gradients. The black dashed lines indicate the cutoff for hemodynamic significant lesions (> 10 mm Hg). The R 2 with respect to the line y = x is 0.81.

---

### Global energy spectrum of the general oceanic circulation [^a034bbb3]. Nature Communications (2022). High credibility.

Regression analysis of phase shift

Figure 3 presents a clear phase shift in the seasonal cycle as a function of length-scale. In order to quantify the phase shift, we need to first extract a meaningful set of (k ℓ, time) points. To that end, we extract, for each k ℓ, the (i) times corresponding to the lowest 10% (dark blue in Fig. 3), (ii) two middle-most 10% for the two zero-crossings (white in Fig. 3), and (iii) highest 10% (dark red in Fig. 3) of the normalized deviations presented in Fig. 3. This is essentially extracting the (k ℓ, time)-coordinates for the line of darkest red, darkest blue, and the two white lines, resulting in a total of four regression sets. Periodic phase adjustment to the days of the year is applied to maintain monotonicity in time, and the k ℓ grid is truncated to focus on regimes with a clear linear trend. The extracted data points are shown as the dots/vertical bars in Fig. S3 in the SM, along with their corresponding regression fits.

Figure 7 presents the linear regression slope analysis for the data shown in Fig. S3. The different regression analyses generally agree well, with 12 of the 16 regression sets indicating a 35–45 day time-lag per octave of spatial scales. From this analysis, we conclude that length-scales that differ by a factor of two (i.e. ℓ 1 / ℓ 2 = 2) have seasonal cycles that are off-set by 41 ± 3 days. Scales that differ a decade (ℓ 1 / ℓ 2 = 10) would correspondingly have a phase shift of 136 ± 10days, or roughly 4.5 months.

Fig. 7
Regression analysis summary.

Regression slope estimates and confidence intervals for each of the datasets shown in Fig. S3. Vertical dashed lines separate the data sources, with the text along the top indicating the source data and hemisphere. Diamonds indicate the regression slope estimate, dark envelopes the 75% confidence interval, and light envelopes the 95% confidence interval. The r -value for each regression fit is printed alongside the corresponding slope distribution. The left-most illustration, separated by a thick black line, presents the mean (diamond) and confident intervals (envelopes) across the 16 regression analyses. In the legend, 'min' means the lowest 10% z-score, 'mid' the two middle-most 10% groups, and 'max' the highest 10%.

---

### Homomeric gluA2 (R) AMPA receptors can conduct when desensitized [^dd8c6928]. Nature Communications (2019). High credibility.

Fig. 1
Q/R editing affects the kinetics and variance of GluA2 currents. a Representative outside-out patch response (10 mM glutamate, 100 ms, –60 mV; gray bar) from a HEK293 cell transfected with GluA2(Q)/γ-2 (average current, black; five individual responses, grays). Inset: current–variance relationship (dotted line indicates background variance and red circle indicates expected origin). b As a, but for GluA2(R)/γ-2. Note that the data cannot be fitted with a parabolic relationship passing through the origin. c Pooled τ w, des data for GluA2 alone (n = 12 Q-form and 9 R-form), GluA2/γ-2 (n = 21 and 27), GluA2/γ-8 (n = 7 and 10), and GluA2/GSG1L (n = 6 and 13). Box-and-whisker plots indicate the median (black line), the 25–75th percentiles (box), and the 10–90th percentiles (whiskers); filled circles are data from individual patches and open circles indicate means. Two-way ANOVA revealed an effect of Q/R editing (F 1,97 = 111.34, P < 0.0001), an effect of auxiliary subunit type (F 3,97 = 32.3, P < 0.0001) and an interaction (F 3,97 = 2.84, P = 0.041). d Pooled data for I ss. Box-and-whisker plots and n numbers as in c. Two-way ANOVA indicated an effect of Q/R editing (F 1,97 = 129.98, P < 0.0001), an effect of auxiliary subunit type (F 3,97 = 58.30, P < 0.0001), and an interaction (F 3,97 = 58.67, P < 0.0001). e Doubly normalized and averaged current–variance relationships (desensitizing current phase only) from GluA2(Q) and GluA2(R) expressed alone (n = 12 and 9), with γ-2 (n = 19 and 23), with γ-8 (n = 7 and 10), or with GSG1L (n = 6 and 13). Error bars are s.e.m.s. All Q-forms can be fitted with parabolic relationships passing through the origin, while R-forms cannot. f Pooled NSFA conductance estimates for GluA2(Q) alone, GluA2(Q)/γ-2, GluA2(Q)/γ-8, and GluA2(Q)/GSG1L (n = 12, 18, 7, and 6, respectively). Box-and-whisker plots as in c. Indicated P values are from Wilcoxon rank sum tests. Source data are provided as a Source Data file

---

### On the convexity of ROC curves estimated from radiological test results [^e12ae042]. Academic Radiology (2010). Low credibility.

Rationale and Objectives

Although an ideal observer's receiver operating characteristic (ROC) curve must be convex-ie, its slope must decrease monotonically-published fits to empirical data often display "hooks". Such fits sometimes are accepted on the basis of an argument that experiments are done with real, rather than ideal, observers. However, the fact that ideal observers must produce convex curves does not imply that convex curves describe only ideal observers. This article aims to identify the practical implications of nonconvex ROC curves and the conditions that can lead to empirical or fitted ROC curves that are not convex.

Materials and Methods

This article views nonconvex ROC curves from historical, theoretical, and statistical perspectives, which we describe briefly. We then consider population ROC curves with various shapes and analyze the types of medical decisions that they imply. Finally, we describe how sampling variability and curve-fitting algorithms can produce ROC curve estimates that include hooks.

Results

We show that hooks in population ROC curves imply the use of an irrational decision strategy, even when the curve does not cross the chance line, and therefore usually are untenable in medical settings. Moreover, we sketch a simple approach to improve any nonconvex ROC curve by adding statistical variation to the decision process. Finally, we sketch how to test whether hooks present in ROC data are likely to have been caused by chance alone and how some hooked ROCs found in the literature can be easily explained as fitting artifacts or modeling issues.

Conclusion

In general, ROC curve fits that show hooks should be looked on with suspicion unless other arguments justify their presence.

---

### Scattering approach to diffusion quantifies axonal damage in brain injury [^7b18d7f3]. Nature Communications (2025). High credibility.

Having validated the functional form (1), we used it to estimate and validate D ∞, i and c D, i for individual axons. For that, we employed linear regression with respect tofor t between 10 and 500 ms. Figure 2e validates Eq. (2) for individual axons. Nearly no deviations occur from the identity line for both synthetic and SBEM-segmented axons, indicating the accuracy and robustness in predicting D ∞, given the axonal cross-section A (x).

To validate Eq. (3), we calculated the theoretical value of c D by estimating the plateau Γ 0 of the power-spectral density Γ η (q) for individual synthetic and SBEM-segmented axons, as shown in Fig. 2a, d, and Supplementary Fig. S1. We then confirmed the agreement between c D, i from MC-simulated D i (t) for individual axons and their theoretical prediction (3), Fig. 2f, where data points align with the identity line, indicating the absence of bias in the prediction. Random errors in these plots come from errors in estimating Γ 0, especially for short (SBEM-segmented) axons, as well as from estimating the slope c D in asymptotic dependence (1) due to MC noise. The numerical agreement with Eq. (3) is notably better for longer synthetic axons. Figure 2f also indicates that as the cross-sectional variation var [α (x)] increases, the deviations from the identity line become more pronounced, which could be attributed to corrections to FJ equation (4), when the "fast" transverse and "slow" longitudinal dynamics are not fully decoupled.

The validated theory opens up the way to massively speed up the predictions of dMRI measurements and their change in pathology based on 3d segmentations: what would normally require over a year of GPU-powered MC simulations in the realistic microstructure of Fig. 1 for tens of thousands of segmented axons is now predicted in mere seconds on a regular desktop computer by calculating the relevant dMRI parameters using Eqs. (2)–(3) based on axon cross-sections A (x).

---

### Non-linear relationships in clinical research [^4d28fd9a]. Nephrology, Dialysis, Transplantation (2025). Medium credibility.

Unlike linear relationships, which assume a constant effect of the independent variable, models containing splines or polynomials have effects that change over the range of the variable. In our non-linear example, we cannot summarize our findings with a single regression coefficient as the "effect" of time on serum albumin varies throughout the follow-up period, making interpretation less straightforward. Several methods exist to report results in this situation. The easiest is to simply present the curve visually in a plot, showing how the trajectory of serum albumin evolves over time. However, some form of quantitative assessment is often desired to complement the plots. One approach is to report the slope (i.e. regression coefficient) at multiple time points of interest. The slope can be calculated by determining the difference in serum albumin levels between specific time points. For example, estimating the change in serum albumin between –3 and –2 years would reveal the effect (i.e. slope) of time on serum albumin during that specific interval. In other words, the calculated slope — or regression coefficient — reflects the effect for a 1-unit increase in time on serum albumin, specifically within that time interval. The calculated slope for the interval between –1 and 0 years would likely show a stronger effect of time, as visualized by the steeper slope in that part of the curve. Changes in slope indicate periods of more rapid change (or stabilization) in serum albumin. Of note, this method provides the effect at the midpoint between the time values (i.e. the average slope over the time interval). Another more accurate approach to understand the fluctuating effect of time is to calculate the first derivative of the trajectory. This provides the instantaneous rate of change (i.e. slope) at any point on the curve, and in our example, reveals how quickly albumin levels are rising or falling at different points during follow-up. As an example, Fig. 6 provides the slope (i.e. first derivative) at –2.5 years preceding death for all methods except categorization (as the slope in the corresponding category is zero), demonstrating how different the results can be depending on the method used.

---

### Bicisate dihydrochloride (Neurolite) [^a376ead7]. FDA (2022). Medium credibility.

DETERMINATION OF RADIOCHEMICAL PURITY

The preparation and quality control of the agent should follow the procedure shown below.

Materials for TLC Procedure

Bakerflex silica gel IB-F, 2.5 x 7.5cm, Baker #4463–02

Solvent system: Ethyl Acetate, HPLC grade

Dose calibrator or gamma counter for measuring radioactivity

Small chromatographic developing tank

Syringe and shielded vials, as needed

TLC Procedure

Establish the radiochemical purity (RCP) of the final solution by the thin layer chromatography (TLC) using Baker-Flex silica gel IB-F plates and a solvent system of ethyl acetate. The RCP should be ≥ 90%.

Procedure – Using fresh ethyl acetate pour enough solvent into the developing tank to a depth of 3 to 4 mm. Seal the tank with Parafilm and allow 15 to 30 minutes for solvent equilibration. It is important to pre-equilibrate and preserve the integrity of the headspace in the chromatographic tank, otherwise unreproducible TLC results are obtained.

 Note: Ethyl acetate is a skin/mucous membrane irritant and should be handled in a hood whenever possible.

With a pencil, draw a faint line across the TLC plate at heights of two (2) cm, four and one half (4.5) cm and seven (7) cm from the bottom of the TLC plate. Place approximately 5 µL of the final solution at the center of the 2 cm mark. This can be accomplished by using a syringe fitted with a 25 or 27 gauge needle and allowing a drop to form while holding the syringe in a vertical position. The diameter of the spot should not be greater than 10mm. Allow the spot to dry for 5 to 10 minutes, no longer.

Place the plate in the pre-equilibrated TLC tank and develop to the 7.0 cm line (about 15 minutes). Remove the plate and dry in a ventilated area.

Quantification

Cut the TLC plate at the 4.5 cm mark with scissors. Count the activity on each plate using a dose calibrator or a gamma counter. The top portion contains the Technetium Tc99m Bicisate and the bottom portion contains all radioimpurities.

Calculate the radiochemical purity using the following equation:

% Technetium Tc99m Bicisate = A tx 100

At+ Ab

Where: At = activity of the top piece and Ab = activity of the bottom piece.

---

### Optimization on multifractal loss landscapes explains a diverse range of geometrical and dynamical properties of deep learning [^d5160640]. Nature Communications (2025). High credibility.

Fig. 6
Experimental validation of the fractional diffusion theory.

a Theoretical predictions of the time-averaged mean squared displacement (TAMSD) in equation (13) (gray dashed lines) are fit to TAMSD curves (T = 1000) for GD trajectories on the loss landscape L constructed from B H with constant H ∈ {0.4, 0.5, 0.6, 0.7}. TAMSD curves in the second regime, where equation (13) is applicable, are obtained for analysis. For visual clarity, we separate the curves by multiplying by arbitrary factors; note that this does not change the diffusion exponent at small lag times τ. b For each L constructed from B H with constant H ∈ {0.1, 0.2,…, 0.9}, we simulate 5 random initializations of GD. The diffusion exponent α is estimated from least-squares regression on the power law segment in the first decade of τ for TAMSD curves in the second regime. Dots and error bars represent mean and 95% confidence interval calculated from 10,000 bootstrap resamples, respectively. The dotted line corresponds to the theoretical prediction in equation (14). c TAMSD calculated from the numerical solution of equation (10) using a window of size T = 3000 and a systematic progression of waiting times t w. Eye-guides indicate approximate diffusion exponents α.

On the other hand, the tilted washboard component affects dynamics at small t while the optimizer approaches the limiting basin (i.e. the first regime of Fig. 5). Since no analytical solution is available for a general potential, we numerically solve equation (10) and then calculate the TAMSD (see "Methods" for details on the numerical scheme). Under choices of simulation parameters that approximate the black trajectory in Fig. 4 b (e.g. 10,000 iterations, learning rate is 1000, starting point is around 700 units away from the limiting basin, etc.; see "Methods" for all parameters), we obtain TAMSD curves (Fig. 6 c) that are remarkably similar to that of our model (Fig. 5). Notably, the curves include a transition from an initial transient super-diffusive regime to an ensuing sub-diffusive regime.

---

### Measurements of the size and correlations between ions using an electrolytic point contact [^378e967a]. Nature Communications (2019). High credibility.

Fig. 2
Electrolytic ion transport through sub-nanopores. a A juxtaposition of the current-voltage characteristics acquired from the same sub-nanopore with a 0.50 nm mean-diameter using different concentrations of NaCl electrolyte. The dotted lines reflect FESs. Inset: The conductance of a pore with a mean-diameter of 0.52 nm as a function of NaCl concentration, illustrating a minimum conductance for concentrations < 100 mM. The dotted-line represents a match to the data assuming a surface charge of −0.19 e nm -2. b Like a, but acquired from pores with 0.30 nm × 0.40 nm→)0.35 nm, (0.50 nm × 0.55 nm→)0.52 nm and (0.80 nm × 0.85 nm→)0.82 nm mean-diameters at the waist in 250 mM NaCl. Inset: Like b, but for a pore with a (0.95 nm × 1.00 nm→)0.97 nm mean-diameter. c The current–voltage characteristic of a sub-nanopore with a mean-diameter of (0.35 nm × 0.40 nm→)0.37 nm measured with 250 mM NaCl on both sides of the membrane (open circles), and then with a gradient across the membrane with only 1 mM NaCl on the trans -side (half-filled circles). The asymmetric conductance indicates that > 97% of the current was carried by Na +. Inset: Like c, but for a pore with a mean-diameter of (0.75 nm × 0.85 nm→)0.80 nm. Here, 90% of the current was carried by Na +. d The dependences of the diffusivity extracted from FES on the mean-diameter of sub-nanopores for Na + in 250 mM NaCl (open circles). The best-fit (black dotted) line extrapolates to zero diffusivity near a 0.22 nm-mean-diameter. For comparison, juxtaposed on the same plot is the diffusivity extracted from MD using model sub-nanopores with 0.30 nm and 0.50 nm diameters (gray circles). e Like a, but acquired from two sub-nanopores with (0.80 nm × 0.85 nm→) 0.82 nm (gray lasso) and 0.30 nm (black lasso) mean-diameters using different electrolytes at 500 mM. f The dependences of the conductance on the mean-diameter of sub-nanopores for four different electrolytes at 250 mM. The best-fit lines for the metal ions extrapolate to zero conductance at 0.21 ± 0.11 nm for Na +; 0.24 ± 0.11 nm for K +; 0.26 ± 0.11 nm for Li + and 0.23 ± 0.11 nm for Mg 2+, near to a 0.24 nm-diameter. For comparison, juxtaposed on the same plot are the conductances extracted from MD simulations performed using model sub-nanopores with 0.30 and 0.50 nm diameters in LiCl and NaCl. The error bars are typical of the standard deviation of the empirical data

---

### Large oscillatory thermal hall effect in kagome metals [^19c982a9]. Nature Communications (2024). High credibility.

Fig. 2
The quantum oscillations in λ x x and λ x y and the 180-degree phase flip in λ x y.

a The oscillatory componentsandwere extracted from λ x x and λ x y at selected temperatures, obtained after a fifth-order polynomial background subtraction from the raw data. A primary contribution from the delta orbit (~87 T) is marked by the grey dashed line. b Fourier transformation of the quantum oscillations at field ranged from 4 T to 13 T, showing four principal frequencies, F α = 11 T, F β = 25 T, F γ = 72 T, and F δ = 87 T. c Raw data of the quantum oscillation in thermal Hall signal at different T ranging from 3.25 K to 17.15 K. Each curve is shifted with a constant. d The oscillatory components were obtained after fifth-order polynomial background subtraction. The 75 T high-pass filter is applied to emphasize the oscillation from the delta orbit (~87 T). As the temperature goes from 3.25 K to 17.15 K at magnetic field, the oscillation amplitude passes through zero, accompanied by a phase reversal. e The relative phase ψ of the oscillation in the T vs. 1/ H phase diagram (see Supplementary Note 7 for the definition of ψ). At low T and strong H, ψ > 1, the region is colored with orange. At high T and weak H, ψ < 1, the phase becomes opposite, and the area is colored blue. The purple dashed line shows the fitted phase-shifting boundary with function. f In the T vs. H phase diagram, the zero amplitude locations of the oscillations are plotted as the red circles. The zeros match the ψ = 1 boundary in (e), and the error bar is estimated from the broadening of the boundary. The straight purple dashed line is linear fitting of the boundary using the same parameter as Fig. 3c. The slope of this straight line gives the value of, and the cyclotron mass was determined as 0.13 m e.

---

### Revealing the relationship between liquid fragility and medium-range order in silicate glasses [^404f70e2]. Nature Communications (2023). High credibility.

We now propose another fictitious, super-fragile, glass-forming liquid that has the highest limit of fragility for silicate-glass materials, hereafter denoted as Fictitious high. It is assumed that this hypothetical glass should contain only small-size rings, which are highly stressed, and therefore can deform the most at T g. Therefore, the Fictitious high glass should have an MRD value of 3.15 Å. Using the linear equation obtained from Fig. 5, the m value of the Fictitious high glass-forming liquid should therefore be 70. The Fictitious high glass estimated data-point is added to the linear correlation as the red open star in Fig. 5. It is noted that this upper bound fragility value of 70 is predicted only for silicate glasses with a ring structure; glasses with other structural types, such as molecular materials and polymers, may have much higher fragility values, with an upper limit predicted to be 180.

Structural origin of m - MRD correlation by in situ neutron

We emphasize that the m - MRD relationship revealed herein is unexpected and intriguing, since there is a priori no obvious reason for the MRD value (a purely static, structural parameter measured in the glassy state) to correlate with the fragility (a kinetic property measured in the supercooled liquid state). To search for the underlying structural origin of the inverse m - MRD relationship, we conducted in-situ high-temperature neutron total-scattering analyses with particular focus on the near- T g range. Three charge-balanced CAS glasses x CaO– x Al 2 O 3 –(1–2 x)SiO 2 (x = 0.15, 0.25, 0.3) (see Supplementary Table 7, where the nomenclature of the CAS glasses is given by the SiO 2 content, i.e. the glass with x = 0.15 is designated as CAS70) were measured at temperatures from RT to 1.1 T g, and one binary sodium silicate (NS) glass 20Na 2 O–80SiO 2 (NS20) from RT to 1.25 T g. The fragility-index parameters of three CAS glasses were determined by isothermal equilibrium viscosity measurements using a three-point beam-bending methodaround the glass transition range. Their fragility-index values are listed in Supplementary Table 7, with the detailed information presented in Supplementary Note 3. The fragility-index data of NS20 is from ref.

---

### Microfluidic multipoles theory and applications [^31dd0050]. Nature Communications (2019). High credibility.

Upon inspection, the problem can be transformed to streamline coordinates (Fig. 2a) using the function

In the streamline domain Φ, the problem is equivalent to a channel geometry with flows of concentration c = 1 and c = 0 separated by a no-flux boundary condition on the origin. At the stagnation point, the no-flux condition is dropped, and the flows are free to mix (Fig. 2a) (see Supplementary Table 2 for more details on the streamline problem). The separating streamline going from the stagnation point to the aspiration aperture corresponds to the semi-infinite segment of the horizontal axis where the fluids can mix. If the Péclet number is high enough (higher than about 10, which is always realized in microfluidics applications), this segment can be taken to have concentration c = 1/2 and the walls of the channel geometry can be safely ignored (Supplementary Note 1). The problem can thus be decomposed in two problems of advection-diffusion around semi-infinite obstacles of fixed concentration. The problem of advection-diffusion around such a semi-infinite obstacle has been extensively studied in theoretical fluid mechanics, notably in the theory of dendrite solidification, and in the study of out of plane flow in Burgers vortex sheets. It yields the solutionwhere Φ stag is the image of the stagnation point and erf(x) is the error function. The sign of ± is determined by whether we have an incoming flow of concentration c = 0 or c = 1. However, neither of these concentration profiles represent the full dipole footprint when transformed. This can be seen physically in the flow dipole, in which there is both incoming fluid at concentration 0 (aspirated from the system's surroundings), and incoming fluid at concentration 1 (injected by the aperture). To solve this issue, we separate the problem into an "interior" and an "exterior" domain at the streamline of concentration c = 1/2 (see checkerboard insets in Fig. 2). There remains a discontinuity in our solution due to the branch cut of the logarithm functions in Eq. (1), but the solution can be made continuous by placing the singularities on the real axis and using it as an axis of symmetry. The final step is then to obtain the entire solution as a piecewise function assembling the "interior" and "exterior" solutions, given by transforming Eq. (6) back to the dipole flow domain Z. The interior and exterior domains can be defined either by checking the sign of Φ in the streamline domain or by using the expression for the separating line in the Z domain in polar coordinates (see Supplementary Note 2).

---

### Insulin degludec [^2e18ccba]. FDA (2024). Medium credibility.

Step 4:

Push the capped needle straight onto the Pen and twist the needle on until it is tight (See Figure E).

Step 5:

Pull off the outer needle cap. Do not throw it away (See Figure F).

Step 6:

Pull off the inner needle cap and throw it away (See Figure G).

Priming your Insulin Degludec FlexTouch Pen:

Step 7:

Turn the dose selector to select 2 units (See Figure H).

Step 8:

Hold the Pen with the needle pointing up. Tap the top of the Pen gently a few times to let any air bubbles rise to the top (See Figure I).

Step 9:

Hold the Pen with the needle pointing up. Press and hold in the dose button until the dose counter shows "0". The "0" must line up with the dose pointer.
A drop of insulin should be seen at the needle tip (See Figure J).
If you do not see a drop of insulin, repeat steps 7 to 9, no more than 6 times.
If you still do not see a drop of insulin, change the needle and repeat steps 7 to 9.

---

### Non-linear relationships in clinical research [^ad643ba8]. Nephrology, Dialysis, Transplantation (2025). Medium credibility.

True linear relationships are rare in clinical data. Despite this, linearity is often assumed during analyses, leading to potentially biased estimates and inaccurate conclusions. In this introductory paper, we aim to first describe-in a non-mathematical manner-how to identify non-linear relationships. Various methods are then discussed that can be applied to deal with non-linearity, including transformations, polynomials, splines and generalized additive models, along with their strengths and weaknesses. Finally, we illustrate the use of these methods with a practical example from nephrology, providing guidance on how to report the results from non-linear relationships.

---

### Estimation in medical imaging without a gold standard [^82dda7fe]. Academic Radiology (2002). Low credibility.

Rationale and Objectives

In medical imaging, physicians often estimate a parameter of interest (eg, cardiac ejection fraction) for a patient to assist in establishing a diagnosis. Many different estimation methods may exist, but rarely can one be considered a gold standard. Therefore, evaluation and comparison of different estimation methods are difficult. The purpose of this study was to examine a method of evaluating different estimation methods without use of a gold standard.

Materials and Methods

This method is equivalent to fitting regression lines without the x axis. To use this method, multiple estimates of the clinical parameter of interest for each patient of a given population were needed. The authors assumed the statistical distribution for the true values of the clinical parameter of interest was a member of a given family of parameterized distributions. Furthermore, they assumed a statistical model relating the clinical parameter to the estimates of its value. Using these assumptions and observed data, they estimated the model parameters and the parameters characterizing the distribution of the clinical parameter.

Results

The authors applied the method to simulated cardiac ejection fraction data with varying numbers of patients, numbers of modalities, and levels of noise. They also tested the method on both linear and nonlinear models and characterized the performance of this method compared to that of conventional regression analysis by using x-axis information. Results indicate that the method follows trends similar to that of conventional regression analysis as patients and noise vary, although conventional regression analysis outperforms the method presented because it uses the gold standard which the authors assume is unavailable.

Conclusion

The method accurately estimates model parameters. These estimates can be used to rank the systems for a given estimation task.

---

### Universal scaling in real dimension [^d1d47cd6]. Nature Communications (2024). High credibility.

In order to extract the correlation length exponent from the scaling of 〈 R 2 (N)〉, one needs to identify a suitable region of N where one can reasonably apply the relation in Eq. (3). This universal region can be identified by observing the collapse of different curves 〈 R 2 (N)〉 for different system sizes L. This analysis is reported in Fig. 4, for both σ = 1.8 and σ = 1.1. In the upper panel the collapse in rather evident in a wider region of N, while in the lower panel the collapse region is harder to determine. The universal window is visually identified as the region where the three curves overlap and exhibit a linear behavior. For all σ ≳ 1.5 the universal window roughly corresponds to the region where the disagreement between the three curves remains below 5%. The same analysis has been repeated for all values of σ resulting in very extended and well-defined fitting regions for all σ ≳ 1.5, similarly to what is reported in the upper panel in Fig. 4. For 1.5 ≳ σ ≳ 1.1 the collapse region is less extended but still pronounced enough to obtain reliable ν estimates, at least up to d s ≃ 3.5, see the lower panel in Fig. 4. Finally, in the region σ ≤ 1 (corresponding to d s ≥ 4) it is not possible to identify a clear universal region and, accordingly, the ν estimates become less precise, see the Supplementary Note II. As a consequence, the agreement between our data and the theoretical line is poorer in this region, see Fig. 3.

Fig. 4
Logarithmic derivative of the average spatial extent of the random walk.

The plot displays the logarithmic derivative of the average spatial extent of the random walk as a function of the inverse logarithm of the number of steps N. Data shown for σ = 1.8 and σ = 1.1, corresponding to ρ = 3.8 (top) and ρ = 3.1 (bottom), for different lattice sizes: L × L = 64 × 64 (blue), 128 × 128 (yellow), 256 × 256 (green). The collapse region is well established for larger values of ρ and corresponds to a regime where scaling corrections and finite sizes effects are negligible, so that one can define a ' ', as bracketed by the vertical red dashed lines, and extrapolate from there the critical exponent.

---

### Network properties determine neural network performance [^47a4abec]. Nature Communications (2024). High credibility.

Machine learning influences numerous aspects of modern society, empowers new technologies, from Alphago to ChatGPT, and increasingly materializes in consumer products such as smartphones and self-driving cars. Despite the vital role and broad applications of artificial neural networks, we lack systematic approaches, such as network science, to understand their underlying mechanism. The difficulty is rooted in many possible model configurations, each with different hyper-parameters and weighted architectures determined by noisy data. We bridge the gap by developing a mathematical framework that maps the neural network's performance to the network characters of the line graph governed by the edge dynamics of stochastic gradient descent differential equations. This framework enables us to derive a neural capacitance metric to universally capture a model's generalization capability on a downstream task and predict model performance using only early training results. The numerical results on 17 pre-trained ImageNet models across five benchmark datasets and one NAS benchmark indicate that our neural capacitance metric is a powerful indicator for model selection based only on early training results and is more efficient than state-of-the-art methods.

---

### Norvir [^cd1699c3]. FDA (2020). Medium credibility.

0.25 0.8 mL (62.5 mg) 0.9 mL (75 mg) 1.1 mL (87.5 mg) 1.25 mL (100 mg)

0.50 1.6 mL (125 mg) 1.9 mL (150 mg) 2.2 mL (175 mg) 2.5 mL (200 mg)

0.75 2.3 mL (187.5 mg) 2.8 mL (225 mg) 3.3 mL (262.5 mg) 3.75 mL (300 mg)

1.00 3.1 mL (250 mg) 3.75 mL (300 mg) 4.4 mL (350 mg) 5 mL (400 mg)

1.25 3.9 mL (312.5 mg) 4.7 mL (375 mg) 5.5 mL (437.5 mg) 6.25 mL (500 mg)

1.50 4.7 mL (375 mg) 5.6 mL (450 mg) 6.6 mL (525 mg) 7.5 mL (600 mg)

Body surface area (BSA) can be calculated as follows1:

[norvir equation]

---

### Recommendations for cardiac chamber quantification by echocardiography in adults: an update from the American Society of Echocardiography and the European association of cardiovascular imaging [^194fdbe5]. Journal of the American Society of Echocardiography (2015). Medium credibility.

Left atrial (LA) volume quantification by echocardiography is described using two-dimensional echocardiography (2DE) and three-dimensional (3D) approaches, with 2D volumetric measurements based on tracings from apical four- and two-chamber views; at the mitral valve level the contour is closed by a straight line, endocardial tracing excludes the atrial appendage and pulmonary veins, LA length L is the shortest long axis from apical two- and four-chamber views, and the two lengths should not differ more than 5 mm; volumes can be computed by an area-length approximation or by a disk summation technique, and 3D data sets are usually acquired from the apical approach using a multibeat full-volume acquisition. For the 2DE area-length technique, advantages include accurate assessment of asymmetric remodeling of the left atrium and being a more robust predictor of cardiovascular events than linear or area measurements, whereas limitations include geometric assumptions about LA shape, few accumulated data on normal population, and that single plane volume calculations are inaccurate because they assume A1 = A2. For 3D data sets, advantages are no geometrical assumption about LA shape and greater accuracy compared with 2D measurements, while limitations include dependence on adequate image quality, lower temporal resolution, limited data on normal values, and that patient's cooperation is required.

---

### Engineering phase and polarization singularity sheets [^d73719c8]. Nature Communications (2021). High credibility.

Fig. 2
Comparison between phase gradient maximization and field minimization to obtain phase singularities.

Both methods can be used to obtain phase singularities, but they produce different field behavior in terms of its real (blue) and imaginary (red) zero-isosurfaces. Yellow dots label the positions at which the field and phase gradients are optimized. Inset surface plots are the logarithmically scaled field intensities at z = 0 μm over the same XY domain. The z = 0 μm plane is indicated with the gray plane in each isosurface plot. a When the phase gradient in a specified direction is maximized, the two zero-isosurfaces align approximately tangentially and in the direction normal to that specified gradient. This produces a flat low field intensity structure along these aligned zero-isosurfaces. b Minimizing the field amplitude at a point to produce a singularity merely enforces a crossing of the zero-isosurfaces without any alignment, producing a 1D line singularity. c Simultaneously optimizing two nearby points with directed phase gradients can extend the range of the singularity sheet. d Minimizing the field amplitude at two points simultaneously does not guarantee alignment of the zero-isosurfaces and can instead produce multiple crossing lines, each producing a 1D line singularity.

---

### Isentress [^58c6e69e]. FDA (2024). Medium credibility.

[Figure B]

Step 2. Fill the dosing syringe. Start with the plunger pushed all the way inside the barrel of the syringe. Insert the tip of the syringe into the water and pull back on the plunger to the 5 mL marking on the barrel of the syringe (see FIGURE C).

[Figure C]

Step 3. Pour out remaining water from mixing cup (see FIGURE D).

[Figure D]

Step 4. Add the 5 mL of water from the dosing syringe back into the mixing cup by pressing down on the plunger (see FIGURE E).

[Figure E]

Step 5. Open 1 foil packet. There is a notch that you can use to tear open the foil packet, or you may use scissors to cut along the dotted line. Pour entire contents into mixing cup (see FIGURE F).

[Figure F]

Step 6. Close the attached lid to seal the mixing cup (see FIGURE G). It will snap shut.

[Figure G]

Step 7. Swirl the mixing cup to mix using a gentle circular motion for 30–60 seconds (see FIGURE H). Do not turn the mixing cup upside down. The liquid will be cloudy.

---

### Deep brain stimulation of the subcallosal cingulate gyrus for depression: anatomical location of active contacts in clinical responders and a suggested guideline for targeting [^269c88c8]. Journal of Neurosurgery (2009). Low credibility.

Object

Deep brain stimulation (DBS) of the subcallosal cingulate gyrus (SCG), including Brodmann area 25, is currently being investigated for the treatment of major depressive disorder (MDD). As a potential emerging therapy, optimal target selection within the SCG has still to be determined. The authors compared the location of the electrode contacts in responders and nonresponders to DBS of the SCG and correlated the results with clinical outcome to help in identifying the optimal target within the region. Based on the location of the active contacts used for long-term stimulation in responders, the authors suggest a standardized method of targeting the SCG in patients with MDD.

Methods

Postoperative MR imaging studies of 20 patients with MDD treated with DBS of the SCG were analyzed. The authors assessed the location of the active contacts relative to the midcommissural point and in relation to anatomical landmarks within the medial aspect of the frontal lobe. For this, a grid with 2 main lines was designed, with 1 line in the anterior-posterior and 1 line in the dorsal-ventral axis. Each of these lines was divided into 100 units, and data were converted into percentages. The anterior-posterior line extended from the anterior commissure (AC) to the projection of the anterior aspect of the corpus callosum (CCa). The dorsal-ventral line extended from the inferior portion of the CC (CCi) to the most ventral aspect of the frontal lobe (abbreviated "Fr" for the formula).

Results

Because the surgical technique did not vary across patients, differences in stereotactic coordinates between responders and nonresponders did not exceed 1.5 mm in any axis (x, y, or z). In patients who responded to the procedure, contacts used for long-term stimulation were in close approximation within the SCG. In the anterior-posterior line, these contacts were located within a 73.2 ± 7.7 percentile distance from the AC (with the AC center being 0% and the line crossing the CCa being 100%). In the dorsal-ventral line, active contacts in responders were located within a 26.2 ± 13.8 percentile distance from the CCi (with the CCi edge being 0% and the Fr inferior limit being 100%). In the medial-lateral plane, most electrode tips were in the transition between the gray and white matter of SCG.

Conclusions

Active contacts in patients who responded to DBS were relatively clustered within the SCG. Because of the anatomical variability in the size and shape of the SCG, the authors developed a method to standardize the targeting of this region.

---

### Noninvasive cardiac output monitoring in a porcine model using the inspired sinewave technique: a proof-of-concept study [^486c5890]. British Journal of Anaesthesia (2019). Medium credibility.

Fig 3
Bland–Altman analysis of the agreement between paired measurements of (a) IST vs and (b) Δ IST vs Δfrom baseline. Colours represent each animal (1–8). Solid line, mean difference (bias); dotted lines, limits of agreement (LOA).

Trending ability was assessed by calculating thefrom the previous paired measurement values throughout the protocol, with < 15% meanexcluded. Linear regression shows a high correlation betweenandof 0.84 (P < 0.01). The concordance was 92.5% as assessed using four-quadrant analysis (Fig. 4), where data points located in either quadrant of agreement were considered concordant. Linear regression analysis of the four-quadrant plot shows an equation of. Half-circle polar plot analysis (Fig. 5) revealed an angular bias of 5.98° (–24.4°, 36.3°), and a concordance of 92.3% (% of data points within ± 30° limits). Half-circle polar plot analysis of the %(Supplementary Fig. S3) revealed an angular bias of 4.75° (26.8, 36.2) and a concordance of 90.5%. Trending ability assessed via the TIM demonstrated the following: 65.1% of paired measurements were uninterpretable, 13.2% interchangeable, 9.7% uncertain, and 12% non-interchangeable.

Fig 4
Four-quadrant plot analysis of Δ IST vs Δthroughout the protocol, with an exclusion zone of 15% mean(0.67 L min −1). Linear regression analysis reveals an equation of Δ IST = 0.65×Δ+0.01, where r = 0.84. Data points located in either quadrant of agreement were considered concordant (92.5%).

Fig 5
Half-circle polar-plot analysis of IST vs throughout the protocol, with an exclusion zone of 15% mean cardiac output (0.67 L min −1). Mean angular bias = 5.98° (radial limits, ± 30.2°). Data points located within ± 30° limits were considered concordant (92.3%). Data points distributed near the polar axis (0°) indicate good trending.

---

### High-dimensional one-shot optical field compressive sensing of structured light [^cb75b8fc]. Nature Communications (2025). High credibility.

Now we can calculate the 3D spatiospectral and spatiotemporal light field profiles. Fourier transformation along the spectral domain onyields the 3D spatiotemporal profileof the-polarized light field. For the-polarized light, the 3D spatiospectral phase profile is, and the amplitude one is. The complex amplitudes of- and-polarized light components unambiguously determine the 3D spatiospectral polarization state with a method different from previous approaches using metasurfaces. The 3D spatiotemporal field profileis obtained again through Fourier transformation on, and complete light field information is obtained using Eq. (1). The data reconstruction procedure of the 3D spatiotemporal vectorial optical field is systematically illustrated in Fig. 1e, including all key calculation steps mentioned above.

To prove the concept, we first generate less structured light fields with 3D homogeneous linear, circular, and elliptical polarization states, and test the capability of resolving 3D spatiotemporal amplitude, phase, polarization, and wavelength information. An-polarized, 800 nm, 40 fs laser pulse coming from a 1 kHz Ti:Sapphire laser amplifier transmits through a half-wave plate (WPZ2325-795 from Union Optics Inc.) whose optical axis is −15° to the-direction, so the output laser field is expected to be linearly polarized along -30° to the-direction. Figure 2a shows the actual field profile along the linear polarization direction with the carrier laser frequency reduced by 0.4 times for clear illustration. Meanwhile, the polarization directions of the laser field at selected time slices are labeled by white arrows around −30° to the-direction in Fig. 2b. The 3D intensity profile has a 38 fs temporal duration.

Fig. 2
High-dimensional one-shot optical sensing of homogeneously polarized light.

a The 3D spatiotemporal optical field profile of a femtosecond laser pulse with linear polarization −30° to the-direction. The carrier laser frequency is reduced by 0.4 times for clear illustration. b The 3D spatiotemporal polarization direction (white arrows) and intensity (color map) profiles of the linearly polarized femtosecond laser field for selected time slices. c The polarization parameterdescribing the spectral phase difference between- and-polarized components of the linearly polarized femtosecond laser pulse, the red line is for the experimental (2.17° standard deviation shown in pink area) and the blue line for the calculation results. d and e The same as b, but for right-rotating circular (d) and left-rotating elliptical (e) polarizations.

---

### Observational evidence of ring current in the magnetosphere of mercury [^6126831e]. Nature Communications (2022). High credibility.

A 3D view of the test particle trajectories is shown in Fig. 3a. A closed and bifurcated drift shell is demonstrated in the simulation results. As the test protons drift westward from the magnetotail, the mirror points move poleward, and the bounce path becomes longer. To keep the first adiabatic invariant constant, protons move off the equator to higher latitudes in Mercury's dayside magnetosphere and form a bifurcated Shabansky orbit. The bifurcation starts at the local time of ~10 h and stops at ~14 h. This local time span can be estimated by the equatorial magnetic field strength distribution: when the equatorial magnetic field strength is even larger than that at the particle mirror point, the particle no longer passes through the equator but moves to a higher latitude of a local magnetic field minimum. The simulation result agrees with the prediction from the magnetic field distribution in the equatorial plane (Supplementary Fig. 2). The bifurcated drift shell spans fromtoN in magnetic latitude and ~1.3to ~1.5in radial distance within ~10–14 h local time.

Fig. 3
Comparison of the test-particle simulation and MESSENGER observations of Mercury's off-equatorial ring current.

a 3D view of the trajectories of the 5 keV test protons shown by the red and blue curves with magnetic field lines shown by the white curves. The model parameters r Hel and DI are 0.387 AU and 50, respectively, corresponding to aof 1.41. b – d Energetic proton flux distributions based on MESSENGER observations in the day-night (Local Time: 11–13 h & 23–01 h), geomagnetic equatorial (| Z | < 0.2), and dawn-dusk planes (Local Time: 5–7 h & 17–19 h) under moderate solar wind. The dashed grey circles indicate the gridlines with radius of 2. See Supplementary Fig. 9 for the colour alternative version of this figure.

Our test-particle simulations suggest the existence of a complete and bifurcated proton ring current under moderate solar wind conditions. This test-particle trajectory is similar to that in previous simulations of 34 keV electrons in Mercuryand 20–300 keV protons in Earth. The simulation results are consistent with observations of the protons trapped in the high latitude regions in Case II. Another simulation under lowdemonstrates an earth-like equatorial ring current, corresponding to the observations in case I, as shown in Supplementary Fig. 3.

---

### Best (but oft-forgotten) practices: checking assumptions concerning regression residuals [^f2ebb771]. The American Journal of Clinical Nutrition (2015). Low credibility.

The residuals of a least squares regression model are defined as the observations minus the modeled values. For least squares regression to produce valid CIs and P values, the residuals must be independent, be normally distributed, and have a constant variance. If these assumptions are not satisfied, estimates can be biased and power can be reduced. However, there are ways to assess these assumptions and steps one can take if the assumptions are violated. Here, we discuss both assessment and appropriate responses to violation of assumptions.

---

### Insulin degludec [^8b23a229]. FDA (2024). Medium credibility.

Step 5:

Pull off the outer needle cap. Do not throw it away (See Figure F).

Step 6:

Pull off the inner needle cap and throw it away (See Figure G).

Priming your Insulin Degludec FlexTouch Pen:

Step 7:

Turn the dose selector to select 2 units (See Figure H).

Step 8:

Hold the Pen with the needle pointing up. Tap the top of the Pen gently a few times to let any air bubbles rise to the top (See Figure I).

Step 9:

Hold the Pen with the needle pointing up. Press and hold in the dose button until the dose counter shows "0". The "0" must line up with the dose pointer.
A drop of insulin should be seen at the needle tip (See Figure J).
If you do not see a drop of insulin, repeat steps 7 to 9, no more than 6 times.
If you still do not see a drop of insulin, change the needle and repeat steps 7 to 9.

Selecting your dose:

Step 10:

Insulin Degludec FlexTouch Pen 100 units/mL is made to deliver the number of insulin units that your healthcare provider prescribed. Do not perform any dose conversion.

---

### Relative position of sacral base in the pelvis and its correlation with spino-pelvic parameters [^74e17108]. European Spine Journal (2020). Medium credibility.

Purpose

To investigate the relationship between relative location of the sacral base and spinal alignment in standing healthy adult volunteers.

Methods

One hundred seventy-two volunteers (men = 83, mean age = 39.3 years [20–70], women = 89, mean age = 39.6 years [20–62]) with no history of spinal disease were imaged using a low-dose biplanar slot-scanning 3D X-ray imaging system. A circle was drawn around three points: cranial vertex of the iliac crest (A), caudal vertex of the ischium (B), and anterior vertex of the pubis. Pelvic height (PH) was defined as the diameter (A-B). A tangent line perpendicular to PH (C) was drawn by passing through (A). Sacral height (SH) was defined as the distance between (C) and the center of the sacral base parallel to PH. Relative SH (rSH) was calculated as SH/PH×100.

Results

Mean (SD) rSH was 18.3 ± 3.2 (men 20.0 ± 2.9, women 16.7 ± 2.6). rSH significantly positively correlated with thoracic kyphosis (r = 0.20, p < 0.05), lumbar lordosis (r = 0.28, p < 0.05), pelvic incidence (r = 0.28, p < 0.05), and sacral slope (r = 0.32, p < 0.0001), and significantly negatively correlated with pelvic thickness (r = -0.66, p < 0.0001). rSH did not correlate with pelvic tilt.

Conclusion

The center of the sacral base is normally located 3.8 ± 0.8 cm caudal to the cranial vertex of the iliac crest. The sacral base was located more caudally in men than in women, regardless of age. The more caudal the sacral base, the angle of the spino-pelvic parameters (TK, LL, PI, SS) progressively increases along with a decrease in the sacro-acetabular distance (Pth). Pelvic tilt did not correlate with the location of the sacrum.

---

### A robust curve-fitting procedure for the analysis of plasmid DNA strand break data from gel electrophoresis [^c954ab21]. Radiation Research (2011). Low credibility.

A robust method for fitting to the results of gel electrophoresis assays of damage to plasmid DNA caused by radiation is presented. This method makes use of nonlinear regression to fit analytically derived dose-response curves to observations of the supercoiled, open circular and linear plasmid forms simultaneously, allowing for more accurate results than fitting to individual forms. Comparisons with a commonly used analysis method show that while there is a relatively small benefit between the methods for data sets with small errors, the parameters generated by this method remain much more closely distributed around the true value in the face of increasing measurement uncertainties. This allows for parameters to be specified with greater confidence, reflected in a reduction of errors on fitted parameters. On test data sets, fitted uncertainties were reduced by 30%, similar to the improvement that would be offered by moving from triplicate to fivefold repeats (assuming standard errors). This method has been implemented in a popular spreadsheet package and made available online to improve its accessibility.

---

### Cortical state dynamics and selective attention define the spatial pattern of correlated variability in neocortex [^cd2a6c6f]. Nature Communications (2022). High credibility.

Fig. 4
Dependence of noise correlations on lateral distance.

a Laminar recordings generally exhibit slight horizontal displacements which manifest in a systematic shift of the RFs (circles) across channels (left panel). The shift of the RFs (lines, RF contours; dots, RF centers; dva, degrees of visual angle) for an example recording (right panel). b In two-phase recordings, noise correlations decrease with the RF-center distance in both superficial (crimson) and deep (green) layers (dots - data points, lines - linear regression, superficial layers n = 2544 MU pairs; deep layers n = 3064 MU pairs). Orange background highlights the range of short lateral distances within single or nearby columns. Purple background highlights longer lateral distances between distant columns, such as distances covered by a Utah array, which are outside the range of our laminar recordings. Error bars represent the standard error of the mean (SEM). c Same as b for one-phase recordings. Noise correlations do not decrease with the RF-center distance (superficial layers n = 920 MU pairs; deep layers n = 1448 MU pairs). d Our theory predicts that noise correlations decay with lateral distance exponentially, with the decay constant L called correlation length. Simulations of the full dynamical-system network (circles) agree with the analytical formula derived using the binary-unit network approximation (line). The model parameters α 1, α 2, r on, and r off are sampled from a distribution of parameters in HMMs fitted to the data. Source data are provided as a Source Data file.

---

### Standards of care in diabetes – 2025 [^ef149bc3]. Diabetes Care (2025). High credibility.

Regarding specific circumstances for diabetic nephropathy, more specifically with respect to pediatric patients, ADA 2025 guidelines recommend to determine the eGFR at the time of diagnosis and annually thereafter.

---

### Insulin degludec (Tresiba) [^d8594405]. FDA (2024). Medium credibility.

Step 5:

Pull off the outer needle cap. Do not throw it away (See Figure F).

Step 6:

Pull off the inner needle cap and throw it away (See Figure G).

Priming your TRESIBA FlexTouch Pen:

Step 7:

Turn the dose selector to select 2 units (See Figure H).

Step 8:

Hold the Pen with the needle pointing up. Tap the top of the Pen gently a few times to let any air bubbles rise to the top (See Figure I).

Step 9:

Hold the Pen with the needle pointing up. Press and hold in the dose button until the dose counter shows "0". The "0" must line up with the dose pointer.
A drop of insulin should be seen at the needle tip (See Figure J).
If you do not see a drop of insulin, repeat steps 7 to 9, no more than 6 times.
If you still do not see a drop of insulin, change the needle and repeat steps 7 to 9.

Selecting your dose:

Step 10:

TRESIBA FlexTouch Pen 200 units/mL is made to deliver the number of insulin units that your healthcare provider prescribed. Do not perform any dose conversion.

---

### Quantitative lung morphology: semi-automated measurement of mean linear intercept [^fce1ecb8]. BMC Pulmonary Medicine (2019). Medium credibility.

Optimization of number of chords to sample to accurately estimate MLI actual

Application of the method yielded a data set of 118,716 chords measured across the computer-generated images of uniform-radius circles. A repeated random subsampling algorithm was implemented on this dataset to estimate MLI measured using N randomly sampled chords from the pool of all chords measured per image (numbering N max); N was an integer on the interval [2, N max] and for each N, 5 random subsamples were used. The number of chords sampled per image was then analyzed via ROC curve to determine the ability of N chords to accurately estimate MLI actual as p ≥ 0.05 by one-sample t-test, Fig. 3 a. AUC ROC is a nearly monotonic function of r stratum, Fig. 3 b. This non-monotonicity is likely due to higher relative noise when measuring smaller radii circles. We then used Youden's Index to estimate the optimal number of chords to sample to accurately measure MLI actual, Table 1. The optimal number of chords per r stratum was used to calculate MLI measured, Fig. 4. Finally, a reliability analysis was performed on MLI measured, stratified by r, using a two-way mixed effects model to determine the reliability of the measurements. We demonstrated excellent reliability, with ICC = 0.9998 and p < 0.0001, Fig. 4.

Fig. 3
ROC Curves to Optimize the Number of Chords to Sample. a ROC curves were generated to test the sensitivity and specificity of number of chords in estimating MLI actual per radius stratum. b AUC ROC values and 95% confidence intervals as a classification performance measure

Table 1
Optimal number of chords to estimate MLI actual

Red shading — failure to estimate MLI actual (AUC ROC < 0.5)

Yellow shading — fair estimation (0.6 < AUC ROC < 0.8)

Green shading — good estimation (AUC ROC > 0.8)

Fig. 4
Dot Plot of MLI measured. Dot plot of intraclass correlation. We demonstrate high reliability with ICC = 0.9998. Vertical rule lines represent MLI actual. Represents significant deviation from MLI actual by one-sample t-test, p < 0.05. Data for MLI actual corresponding to radii of 5 or 10 pixels not shown due to poor AUC ROC as discussed in Table 1

---

### Reliability of dynamic causal modelling of resting-state magnetoencephalography [^29379285]. Human Brain Mapping (2024). Medium credibility.

2.4.2 Reliability of inferredparameters

To assess the reliability of parameters with random effects, we used a parametric empirical Bayesian approach to assess the contribution of random effects to conditionally dependent parameter estimates. Mathematically, let a column vector of model parameters at the first level DCM, over cohort, is(number of participants andis the number of parameters for each participant). Then, the generative model of the PEB is given by (Friston et al.):

The first line of Equation 9 is the generative model of each DCM with unknown parameters inferred from neuroimaging data at the first level. The second line models (macro‐level) empirical priors that constrain parameter estimates from the first‐level DCM. In the second line of Equation 9, is the design matrix withcovariant. The first column of X is equal to one and reflects the group mean; generally, the rest of the column can be defined based on empirical data. The symbolis the Kronecker product, andis theidentity matrix. The random effects have a Gaussian distribution and at the second line of equation (6A),(whereis the precision matrix or inverse of covariance). The precision matrix is parameterised with a single (hyper‐precision) parameter, γ, as follows (Friston et al.):

---

### Characteristics of non-ablative resurfacing of soft tissues by repetitive Er: YAG laser pulse irradiation [^009b4e6c]. Lasers in Surgery and Medicine (2021). Medium credibility.

Deep Tissue Response

Figure 7a shows the calculated long‐exposure coagulation depths (z c) as a function of the sequence duration t s, for three sub‐ablative sequence fluences, F s = 2.4, 4.8, and 7.2 J/cm 2, and three pulse separation times t sep = 25, 75, and 125 milliseconds. The tissue coagulation depth (z c) is defined as the tissue depth below which the cell injury Ω (z) is smaller than Ω = 0.5, in agreement with the finding that the value of damage integral of Ω ≈ 0.5 defines the threshold below which the skin damage can be tolerated without the occurrence of irreversible epidermal injury.

Figure 7
(a) Calculated coagulation depths (z c) for three non‐ablative sequence fluences F s = 2.4, 4.8, and 7.2 J/cm 2, as a function of the sequence duration t s, for t sep = 25 milliseconds (diamonds), 75 milliseconds (squares), and 125 milliseconds (circles). The lines are a visual guide for the eye; (b) Full lines represent calculated coagulation depths for different sequence durations at corresponding pain threshold fluences for without (F p) and with topical anesthesia (F p‐EMLA), for t sep of 25 milliseconds (diamonds), 75 milliseconds (squares), and 125 milliseconds (circles). Dashed lines represent calculated coagulation depths for ablation threshold fluences for t sep = 100 and 50 milliseconds. Published measured coagulation depths are represented by the gray squares and the gray triangle.

As can be concluded from Figure 7, the coagulation depth depends predominantly on cumulative fluence F s and t s while the internal pulse sequence structure characterized by N and t sep, is relatively unimportant. This is demonstrated by showing both, the symbol and trend line, where the same trend line applies for different pulse separations t sep (represented by different symbols), and consequently also for different N.

It is important to note that heat diffusion does not last only for the duration of the sequence (t s) but continues also after the sequence has ended. Therefore the total "duration" of heat diffusion is the same for all sequence durations. In Figure 7a, the observation that longer sequence durations give lower coagulation depths is a consequence of lower surface temperatures (T s) for longer t s (see Equation 8), resulting also in smaller damage integrals (see Equation 1).

---

### Insulin aspart (Novolog) [^08393d01]. FDA (2023). Medium credibility.

(Figure C)

Step 3:

Select a new needle.
Pull off the paper tab from the outer needle cap (See Figure D).

(Figure D)

Step 4:

Push the capped needle straight onto the Pen and twist the needle on until it is tight (See Figure E).

(Figure E)

Step 5:

Pull off the outer needle cap. Do not throw it away (See Figure F).

(Figure F)

Step 6:

Pull off the inner needle cap and throw it away (See Figure G).

(Figure G)

Priming your NovoLog FlexTouch Pen:

Step 7:

Turn the dose selector to select 2 units (See Figure H).

(Figure H)

Step 8:

Hold the Pen with the needle pointing up. Tap the top of the Pen gently a few times to let any air bubbles rise to the top (See Figure I).

(Figure I)

Step 9:

Hold the Pen with the needle pointing up. Press and hold in the dose button until the dose counter shows "0". The "0" must line up with the dose pointer.
A drop of insulin should be seen at the needle tip (See Figure J).
If you do not see a drop of insulin, repeat steps 7 to 9, no more than 6 times.
If you still do not see a drop of insulin, change the needle and repeat steps 7 to 9.

---

### Factor VIIa (recombinant) [^411df77d]. FDA. Low credibility.

The dosage of factor VIIa (recombinant) IV for treatment of bleeding episodes in adults with acquired hemophilia is 70–90 mcg/kg IV q2-3h until hemostasis is achieved

---

### Archimedes' law explains penetration of solids into granular media [^e81c74a7]. Nature Communications (2018). Medium credibility.

Understanding the response of granular matter to intrusion of solid objects is key to modelling many aspects of behaviour of granular matter, including plastic flow. Here we report a general model for such a quasistatic process. Using a range of experiments, we first show that the relation between the penetration depth and the force resisting it, transiently nonlinear and then linear, is scalable to a universal form. We show that the gradient of the steady-state part, K ϕ, depends only on the medium's internal friction angle, ϕ, and that it is nonlinear in μ = tan ϕ, in contrast to an existing conjecture. We further show that the intrusion of any convex solid shape satisfies a modified Archimedes' law and use this to: relate the zero-depth intercept of the linear part to K ϕ and the intruder's cross-section; explain the curve's nonlinear part in terms of the stagnant zone's development.

---

### Orientational diffusion reflects fiber structure within a voxel [^06c16629]. Magnetic Resonance in Medicine (2002). Low credibility.

Several new MR techniques have been introduced to infer direction through diffusion in multiple nerve fiber bundles within a voxel. To date, however, there has been no physical model reported to evaluate these methodologies and their ability to determine fiber orientation. In this article a model of diffusion analogous to nerve fibers is presented. Diffusion measurements at multiple closely spaced angles of 15 degrees in samples with different fiber orientations are compared with theoretical calculations for restricted diffusion in cylindrical geometry. Orientational diffusion measurements are shown to reflect fiber geometry and theoretical predictions to within 10%. Simulations of fiber crossings within a voxel suggest fiber orientation does not correspond to the direction of the largest measured diffusion coefficient, but theoretical knowledge of signal decay curves can predict the shape of these diffusion coefficient contours for given fiber orientation probabilities.

---

### Comparison of AI-integrated pathways with human-AI interaction in population mammographic screening for breast cancer [^c3ee0a28]. Nature Communications (2024). High credibility.

Fig. 3
Comparison of AI-integrated scenarios.

A Human reader consensus performance compared with AI standalone, AI reader-replacement, AI band-pass and AI triage on the retrospective cohort (n = 149,105 screening episodes) without interaction effects. Representative points are shown for AI standalone (96.0% specificity, 75.0% sensitivity), AI single reader (95.6% specificity, 67.3% sensitivity), AI reader-replacement (96.3% specificity, 82.3% sensitivity), AI band-pass (96.6%, 81.7%) and AI triage (95.7% specificity, 78.0% sensitivity). Other potential operating points are shown as a continuous line. Both AI reader-replacement and AI band-pass improved performance over the human reader consensus (96.1% specificity, 79.8% sensitivity). B AI-integrated scenarios when reader performance is varied with an interaction effect when the human reader disagrees with the AI reader. From 0% to 50% of discordant decisions are reversed when the AI reader was correct (triangle, positive effect), uniformly (circle, neutral effect) and incorrect (diamond, negative effect). For AI triage to match human reader consensus performance, a 15% positive interaction effect of the AI reader on human readers is required. Source data are provided as a Source Data file.