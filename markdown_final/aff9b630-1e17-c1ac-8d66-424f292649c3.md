# Medical Question & Answer

**Sample ID**: aff9b630-1e17-c1ac-8d66-424f292649c3
**Dataset Index**: 295157

---

## Question

How should you interpret the treatment difference of −29.6% (95% CI −50.5 to −8.8) in Trep-AB with respect to efficacy and noninferiority?

---

## Answer

> Let's see… What do we have here? The user is asking how to interpret the treatment difference of -29.6% (95% CI -50.5% to -8.8%) in the Trep-AB noninferiority trial comparing oral linezolid to benzathine penicillin G for early syphilis, and what this means for efficacy and noninferiority. Let's break this down step-by-step. First, I need to think about the trial design and whether noninferiority was appropriately framed. Then, I should verify the primary endpoint and how the margin was prespecified. Next, I will examine the observed treatment difference and its confidence interval against the margin. After that, I need to interpret the clinical magnitude of the inferiority signal. Finally, I should consider assay sensitivity, constancy, and the broader implications for practice and guidelines, including whether any ancillary benefits salvage the result.

> Let me first confirm the trial context and design. Trep-AB was a multicenter, open-label, randomized controlled noninferiority trial in adults with early syphilis, comparing 5 days of oral linezolid 600 mg/day versus a single intramuscular dose of benzathine penicillin G 2.4 million IU, with a primary outcome of treatment response at 48 weeks and a prespecified noninferiority margin, which I should confirm from the publication and registry details.

> Wait, let me verify the primary outcome and the margin. The primary endpoint was the difference in treatment response at 48 weeks, with a noninferiority margin that I initially thought was 10% based on common practice, but hold on, I should verify the exact prespecified margin in the protocol and publication. I need to check whether the margin was explicitly stated as 10% or a different value, because the conclusion hinges on where the 95% CI sits relative to that margin, and I should not assume without confirming the protocol-specified delta.

> I will now examine the observed result. The point estimate for the absolute risk difference is -29.6% favoring penicillin, with a 95% confidence interval of -50.5% to -8.8%, meaning linezolid performed substantially worse than penicillin, and the entire confidence interval lies below zero, indicating statistically significant inferiority in a conventional superiority framing. Importantly, the lower bound of the CI is far below any reasonable noninferiority margin, so noninferiority is not supported regardless of the exact delta chosen, and the authors correctly concluded that linezolid was not noninferior to penicillin [^d3bca7b0].

> Hold on, let's not jump to conclusions about clinical relevance without translating the magnitude. A 29.6% absolute reduction in response corresponds to a number needed to treat of about 3.4 in favor of penicillin, which is a large clinically meaningful difference in infectious disease outcomes. This magnitude is incompatible with any claim that linezolid could be considered an acceptable alternative on efficacy grounds alone, and it reinforces that the failure of noninferiority is not a trivial statistical artifact but a clinically important inferiority signal [^d3bca7b0].

> Next, I should review assay sensitivity and constancy assumptions. Noninferiority trials rely on the premise that the active control would have beaten placebo or no treatment in this setting, and that the current trial conditions preserve that advantage. Given that penicillin remains the standard of care with robust historical effectiveness, and the observed inferiority of linezolid is large and consistent, the assay sensitivity concern is less about whether penicillin works and more about whether linezolid retains any meaningful efficacy here, which the data do not support [^ad71a21b] [^d3bca7b0].

> I need to ensure we consider ancillary benefits that might justify a noninferiority design despite worse efficacy. The authors report no significant difference in drug-related adverse events, but that alone does not offset a 30% absolute deficit in treatment response; moreover, noninferiority designs are ethically justified when there are clear advantages like improved safety, convenience, or cost, and here those advantages are not compelling enough to outweigh the large efficacy loss, so the noninferiority framework fails on both statistical and clinical grounds [^d3bca7b0] [^ad71a21b].

> But wait, what if the margin had been wider? Could a permissive margin have rescued this result? Even with a generously wide margin, the lower bound of the CI at -8.8% still crosses into clinically unacceptable territory, and regulatory and methodological guidance cautions against using overly permissive margins that could approve meaningfully inferior therapies. Thus, even under different margin assumptions, this result would remain a failure of noninferiority and a demonstration of clinically important inferiority [^d115e303] [^d3bca7b0].

> I should double-check the practical implications. Clinically, this result argues strongly against substituting oral linezolid for benzathine penicillin G in early syphilis, and it aligns with guideline positions that prioritize penicillin as first-line therapy. The trial also underscores the importance of prespecifying and justifying noninferiority margins transparently, which was variably reported across the literature and remains a recurring weakness in noninferiority trials, though recent reporting quality has been improving [^d3bca7b0] [^a1481b22] [^52535678].

> In summary, I should confirm the bottom line clearly. The -29.6% treatment difference with a 95% CI entirely below zero demonstrates that linezolid is statistically and clinically inferior to benzathine penicillin G for early syphilis treatment response, and therefore the noninferiority hypothesis is rejected. There is no credible noninferiority claim here, and linezolid should not be considered an evidence-based alternative to penicillin for this indication based on these data [^d3bca7b0].

---

The Trep-AB trial shows that **linezolid is inferior to benzathine penicillin G** for early syphilis, with a 29.6% lower response rate (95% CI -50.5% to -8.8%) [^d3bca7b0]. This is a **clinically significant difference** that exceeds any reasonable noninferiority margin, so linezolid cannot be considered noninferior. The confidence interval does not include zero, confirming a true inferiority signal, and there is no evidence of offsetting safety or convenience benefits to justify use. Therefore, **benzathine penicillin G remains the standard of care** and linezolid should not be used as an alternative therapy for early syphilis.

---

## Clinical interpretation of the treatment difference

- **Point estimate**: -29.6% indicates linezolid's response rate is about 30% lower than benzathine penicillin G.
- **Confidence interval**: -50.5% to -8.8% means the true difference likely lies between 8.8% and 50.5% in favor of penicillin, with 95% confidence.
- **Statistical significance**: The CI excludes zero, confirming a statistically significant inferiority of linezolid.

---

## Implications for noninferiority assessment

Noninferiority requires that the **lower bound of the 95% CI be above a prespecified margin** (often ~10% for binary outcomes). Here, the lower bound (-8.8%) is below zero, so noninferiority is not supported regardless of the margin chosen. Thus, linezolid is **statistically and clinically inferior** to benzathine penicillin G [^d3bca7b0].

---

## Clinical significance and practical implications

A 29.6% absolute reduction is a **large, clinically meaningful loss of efficacy**. There were no reported safety or convenience advantages to offset this deficit, so linezolid should not replace penicillin. Guidelines and practice should continue to **favor benzathine penicillin G** as first-line therapy for early syphilis.

---

## Limitations and considerations

The trial was **open-label and small (n = 59)**, which could bias results toward the null; however, the observed inferiority is large and consistent, making a false-negative unlikely. Generalizability is limited by the small sample and single-country setting, but the magnitude of inferiority and biological plausibility support external validity.

---

## Conclusion and recommendations

Linezolid is **significantly inferior to benzathine penicillin G** for early syphilis, with a 29.6% lower response rate and a 95% CI that excludes noninferiority. There is no justification to use linezolid as an alternative, and benzathine penicillin G remains the standard of care.

---

## References

### Interpreting the results of noninferiority trials-a review [^b3816811]. British Journal of Cancer (2022). Medium credibility.

Here, we focus on the specific issue of understanding the limitations and meaning of noninferiority results. In particular, we explore situations where a 'noninferior treatment' based on a specific choice of a noninferiority boundary can be traditionally inconclusive, traditionally superior, or, indeed, traditionally inferior to the conventional treatment (Fig. 1). We also discuss the need for additional complementary analyses, based on assessing the efficacy of the new treatment compared with no treatment. We recommend that two margins be set — one for clinical noninferiority against the standard treatment and another for efficacy relative to no treatment and that both must be satisfied before accepting a new treatment.

Fig. 1
Treatment effect and 95% confidence interval.

Point estimate and 95% confidence interval for different outcomes using conventional and noninferiority methods.

---

### Interpreting the results of noninferiority trials-a review [^2c978551]. British Journal of Cancer (2022). Medium credibility.

Introduction

Noninferiority outcomes were developed to determine if a new treatment might be at most marginally less efficacious than the standard treatment. This is particularly relevant in assessing bioequivalence of a new formulation to an established drug. When other aspects of the treatment are also important in determining its use, a treatment that is, say, 90% (or even 50%) as effective as the standard treatment might be considered of value in certain circumstances. An example is when the new treatment may provide safety advantages compared with the standard treatment, so that slightly lower efficacy may be acceptable especially so if the disease is rarely fatal, and the new treatment is less toxic or cheaper. In these cases, a noninferiority analysis can complement the traditional approach — where a new treatment is considered superior to the conventional treatment only if the 95% confidence interval for the difference is completely in the positive effect size region, inferior if it is completely in the negative region, and inconclusive if it straddles the no effect point.

---

### Kevin M. krudys, PhD… [^5b682b9e]. FDA (2025). Medium credibility.

changing from -18% to -22% on CDR-SB – Study 301 was negative with treatment difference favoring placebo changing from 15% to 2% on CDR-SB www. fda. gov Analysis of Final Dataset ⊗Treatment effect for the high dose changed over time. 3
- Both Phase 3 Trials futility stopped – Increased placebo worsening later entangled with a possible effect of late mid-study dose increase in APOE carriers – Positive 302 has Consistently smaller effects in non-carriers who had higher exposure from study start. 6
- Conditional power < 20% futility decision used interim treatment effect from pooled studies
- study 302 high dose CP was only 58. 63% at the interim for 302 interim effect: High dose interim effect size: -. 28, p = 0.
139. **At interim N = 782**: Placebo LS Mean = 1.
53. **• In remaining N = 798 ITT patients Placebo LS Mean**:

1.

77 Low effect: -. 57 p = . 094 High effect: -. 50 p = .
126. numerically worse than low dose – Robust regression: legitimate, more resistant to outlier analysis of 301, still shows no effect of high dose compared to placebo and numerically worse than low dose – Trimmed mean analysis removing these shows no significant high dose effect: -. 15
- May actually be a systemic lack of efficacy www. fda. gov "Rapid Progressors" in Early Alzheimer's Study 301. – Non-carriers comprise 1/3 of study population
- more 10mg/kg doses = less intermediate dosing
- also less ARIA adverse events for APOE-, so less dose reductions
- However, results show less effect in this randomization stratified subgroup – Even pooling studies, no effect in high non-carriers, consistent across studies.

---

### Interpreting the results of noninferiority trials-a review [^e70f521c]. British Journal of Cancer (2022). Medium credibility.

Noninferiority trials are becoming increasing common, but are often poorly reported and misunderstood. A better understanding of the new components of a noninferiority trial and their interpretation is needed. Noninferiority trials are an extension of conventional superiority trials, which provide a basis for determining if a new treatment, which may have advantages other than efficacy, has sufficient efficacy to be useful in certain situations. A key feature is the need to specify a clinical noninferiority margin above which the lower boundary of the confidence interval for the difference between the new treatment and the conventional treatment must lie. In most cases a nontreated control arm is not included, and when the efficacy of the new treatment is less than that of the standard treatment, determining its efficacy versus no treatment can be a major challenge. Treatments meeting a clinical noninferiority requirement can be statistically significantly superior to standard treatment, of similar efficacy (i.e., no significant difference), or even significantly inferior in a conventional analysis. Noninferiority comparisons are an important addition to the reporting of clinical trials, but require prior consideration of several factors that conventional superiority analyses do not address.

---

### Interpreting the results of noninferiority trials-a review [^904874f2]. British Journal of Cancer (2022). Medium credibility.

Observations

Several new treatments have been appropriately accepted as useful based on noninferiority trials.

A full analysis of a noninferiority trial requires consideration of three outcomes – one each for an untreated population, the population receiving the standard treatment, and the population receiving the experimental treatment (Fig. 2). In contrast, a conventional analysis only requires a comparison of two event rates — the standard established treatment (or no treatment when no established standard treatment exists) against the new treatment. Noninferiority analyses focus on the difference between the conventional treatment and new treatment, but some (typically historical) evidence is needed to estimate the benefits of the new treatment versus no treatment in the population under study. Superiority to no treatment is not addressed directly by the noninferiority comparison, and this is especially relevant when the point estimate of efficacy for the new treatment is below that of the standard treatment.

Fig. 2
Percentages of patients with a recurrence (with confidence intervals) according to a treatment option.

Efficacy endpoints in noninferiority studies. Results for three groups need to be considered — a group receiving the conventional treatment, one receiving the experimental treatment and an untreated group. The experimental treatment needs to be evaluated against the conventional treatment, and if not better, also a no-treatment group. Within a standard two-arm noninferiority trial, only the difference between the conventional and experimental arms can be directly measured. The difference between the conventional treatment and no treatment needs to be inferred from historical data, and these two are then used to estimate the difference between the experimental treatment and no treatment.

The European Medicines Agency (EMA) and the U.S. Food and Drug Administration (FDA) guidelines both recommend that, generally, a 95% two-sided confidence interval be used for assessing noninferiority. Thus, not only must the point estimate of progression rate be above the noninferiority cut-off, but the entire confidence interval must lie within the noninferiority region. These documents and more recent papers provide a general discussion of issues related to noninferiority designs, including a review of major papers published in this area.

---

### Interpreting the results of noninferiority trials-a review [^088da075]. British Journal of Cancer (2022). Medium credibility.

Subgroup analysis

In a superiority trial that includes both good and poor prognosis patients, it is often assumed that a treatment shown to be superior overall will be superior for both good prognosis and poor prognosis patients (provided there is no evidence of an interaction). The same is less likely to be true for a noninferiority comparison. A treatment could be clinically noninferior for good prognosis patients but not for poor prognosis patients for whom the absolute benefit of a more effective treatment is likely to be larger and more easily established. For most treatments, the relative efficacy tends to be more homogenous across different prognostic groups than the absolute efficacy, and thus has the advantage that it is more often applicable to patients with different underlying risks of progression. However, to aid patients in weighing up the pros and cons of two different treatments, it is generally the absolute difference in risk that is most relevant. A comparison of treatments by relative risk can mask important differences in absolute risk for patients with different prognoses. Consider a new treatment that is overall less effective with relative risk of 1.25. For poor prognosis patients with a 20% chance of recurrence on conventional treatment that would translate into an additional 5% chance of recurrence. Whereas, for good prognosis patients with a 6% chance of recurrence on conventional treatment, this implies a 1.5% additional chance of recurrence. On this basis, the new treatment might be considered noninferior for good prognosis patients, but not for poor prognosis patients, in keeping with treating poor prognosis disease more aggressively. Thus, secondary comparisons of the new and conventional treatments in predefined good and poor prognosis patients (on both a relative and absolute scale) is highly desirable. It may be too much to ask to demonstrate noninferiority separately in each subgroup, but it may be appropriate to consider the overall treatment effect (and its confidence interval) applied to the outcome in controls in different subgroups.

Specifying the noninferiority margin for the absolute difference has the additional advantage that it can be more easily compared with other treatment effects. For determining how much loss of efficacy is acceptable when balanced against advantages such as reduced toxicity, convenience, or reduced costs, it is the absolute effect that will enter an overall health economic analysis.

---

### Interpreting the results of noninferiority trials-a review [^1af56f32]. British Journal of Cancer (2022). Medium credibility.

Noninferiority extends these possibilities by determining if the new treatment is "not substantially worse" than the standard treatment based on the confidence interval of this difference not including a predefined unfavourable difference in outcomes — the noninferiority margin. In the literature, noninferiority has sometimes been used when the difference between two treatments is inconclusive without reference to a noninferiority margin. Such use is inappropriate. An inconclusive outcome simply means that no statistically significant difference was seen between the two treatments. If the trial was underpowered the actual difference might still be substantial. It is important to recognise that a further requirement for inferiority is that the confidence interval excludes the predefined noninferiority margin. This guarantees that with high confidence (usually 95%) the new treatment is not substantially worse than the standard treatment (i.e. not worse by as much as the predefined amount). Thus for a noninferiority margin of 10%, a treatment that was 3% worse with a 95% confidence interval of 15% worse to 9% better cannot be said to be noninferior (because it could be as much as 15% worse). However, if the confidence interval was from 7% worse to 1% better, it would be considered noninferior for this noninferiority margin, even though it is statistically significantly worse (the 95% confidence interval excludes no difference). Thus, while an inconclusive finding does not directly provide any information on the performance of the two treatments, a noninferior finding implies that compared with the standard treatment, the new treatment is at most worse by no more than a predefined amount. If the new treatment has other benefits, such as fewer side effects, lower cost, or ease in delivery, this may be acceptable.

---

### Interpreting the results of noninferiority trials-a review [^e5d4a296]. British Journal of Cancer (2022). Medium credibility.

To illustrate this point, consider a conventional treatment that historically reduced 5-year recurrence from 30 to 20%, and suppose in the noninferiority trial, that the new treatment leads to 4% more recurrence than the conventional treatment. If, as before, the conventional treatment results in 20% recurrence, this 4% increase translates to a 20% relative (6% absolute) decrease in 5-year recurrence compared with no treatment (assuming recurrence with no treatment would still be 30%). However, if due to changes in other aspects of usual care or the study population, the conventional treatment leads to a 5-year recurrence of just 8% in the new trial and 12% on the new treatment, the question of what the recurrence rate would have been with no treatment becomes critical. If one assumes the benefit of conventional treatment is proportional to the risk of recurrence, then recurrence with no treatment would again be 50% greater, corresponding to 12% and indicating no effect of the new treatment. If, instead, one assumes the absolute benefit of conventional treatment is preserved, recurrence with no treatment would have been 18% (8% + (30–20%)), considerably more than 12% on the new treatment. For simplicity we have illustrated these issues in terms of the point estimates, but in practice it is essential to use the 95% confidence intervals for the treatment effects.

---

### Noninferiority Randomized controlled trials [^d3946aac]. The Journal of Investigative Dermatology (2022). Medium credibility.

From 2005 to 2015, the publication of noninferiority trials increased by six-fold. Noninferiority trials assess whether a new treatment's efficacy is comparable with that of the standard of care and have several appeals. Noninferiority trials can evaluate for both noninferiority and superiority of a new treatment. In addition, multiple treatment modalities exist, and new treatments may be advantageous for reasons beyond efficacy. Common elements of trial design such as the research question, outcomes, statistical analysis, and interpretation of results differ meaningfully between noninferiority trials and superiority trials. The noninferiority margin, constancy assumption, and assay sensitivity are unique aspects of noninferiority trials. As with all randomized controlled trials, patient engagement in and reporting of noninferiority trials are also important. In this review, we discuss the methodological considerations and limitations of noninferiority trials.

---

### The clinical interpretation of noninferiority trials [^34194115]. Inflammatory Bowel Diseases (2024). Medium credibility.

Noninferiority trials are designed to demonstrate that a new treatment is not unacceptably worse than a standard treatment, considering an allowable difference termed the noninferiority margin. We highlight that selection of noninferiority margins at the time of study design can be biased toward wider margins that favor noninferiority claims. We discuss a clinically oriented approach to interpretation of results with a focus on confidence intervals and recommend that readers base their judgments regarding noninferiority on margins reflecting patient values and preferences rather than those set by investigators. We provide examples from trials in inflammatory bowel diseases.

---

### Interpretation and inference in noninferiority randomized controlled trials in drug research [^c4589e57]. Clinical Pharmacology and Therapeutics (2010). Low credibility.

Noninferiority (NI) trials in drug research are used for the purpose of demonstrating that a new treatment is not worse than a proven active comparator, thereby indirectly showing that the treatment is effective. This article explains and addresses the complications in the interpretation of NI trials that arise from the indirect comparison. On the basis of our review of 232 trials, we conclude that the interpretation and inference of NI trials are complicated, partly because of the incompleteness of the information.

---

### Evaluating intermittent androgen-deprivation therapy phase III clinical trials: the devil is in the details… [^15b00be6]. ASCO (2016). Low credibility.

Not only did neither end point reach statistical significance for superiority of IAD over CAD, but the PFS HR estimate was in the opposite direction. The upper confidence limit for each end point suggests that we cannot rule out a 59% increase in the risk of progression or death or a 25% increase in the risk of death with IAD compared with CAD with 95% confidence. These are large relative margins that would be considered clinically inferior. NIMs: Relative and Absolute Three trials were survival-based noninferiority trials. However, the observed median OS in the CAD arm was 9. 2 years, so the NIM of

1. 25 translated into a difference in OS between arms of 1. 8 years, which would be considered noninferior. It is doubtful that either clinicians or patients would consider a survival difference of 1. 8 years as comparable. If PR. 7 used a NIM of 1.

2, the interim results would not have led to the early reporting of the study and the conclusion of noninferiority of IAD. In contrast, if the S9346 had chosen a 1. 25 NIM, the IAD OS results would have been reported as noninferior. The observed median OS for CAD in S9346 was 5. 8 years, so the more conservative NIM of

1. 20 translated into an absolute difference of roughly 1 year; this difference is too large to be considered clinically acceptable. As pointed out by Burotto et al, 16rarely are NIMs justified in the study design of a trial. A summary of NIMs, prespecified medians, and observed medians and their impact on absolute differences in survival is listed in Table 3. We therefore urge caution in interpreting the results of noninferiority trials, as previously reviewed 19; there is the distinct possibility that such adoption could have far-reaching consequences for the outcomes of treatment of metastatic PC.

In medicine, therapeutic value is a balance between risks and benefits; the lack of statistically significant inferiority of IAD does not equal clinically insignificant differences; a median OS difference of 8 and 10 months in favor of CAD in patients with metastatic disease in S9346 and TAP22, respectively, cannot be ignored. This, coupled with a modest effect of IAD on QOL, and the accumulating biologic d.

---

### Interpreting the results of noninferiority trials-a review [^da444b21]. British Journal of Cancer (2022). Medium credibility.

Noninferiority margin

Determination of the noninferiority margin is the main challenge in designing noninferiority analyses, and its choice is central for drawing meaningful conclusions. The margin should depend on the severity of the endpoint. For example, a smaller margin would be appropriate when mortality is the endpoint, as compared with, say, the need for additional salvage treatment. The margin should also take into account the magnitude of any other benefits of the new treatment. Often this margin is referred to as 'clinically noninferior'. For these reasons, the noninferiority margin should be determined in advance, ideally by a panel of patients, clinicians and researchers and specified in the protocol.

Crucial to this decision is reliable knowledge of 'disease progression' in the absence of treatment, and the benefit achieved with the conventional treatment. Progression can be measured in several ways, including mortality, recurrence, an increase in extent of disease (stage) or severity of symptoms. Consideration should be given as to how many additional cases of 'progression' one would accept for every 100 patients treated with the new versus the standard treatment. Whatever measure is used, it must be predefined and based on prior data, in which the 'other' benefits of the new treatment are quantified and used to determine how great any inferiority of the new treatment compared with the standard can be considered acceptable.

Noninferiority can be assessed either as a relative or absolute difference in efficacy between the standard treatment and the experimental treatment, and both have their advantages and disadvantages. The absolute difference is often most relevant in discussions with patients, as it reflects a change in the risk of progression without reference to the overall risk of progression or the reduction associated with standard treatment. The relative difference can be particularly helpful in understanding how the new treatment compares with the conventional treatment in terms of how much of the overall treatment effect compared with no treatment is retained or extended. This is most relevant when the new treatment is less efficacious than the standard, when its efficacy compared with no treatment becomes questionable.

---

### Interpreting the results of noninferiority trials-a review [^9c02748e]. British Journal of Cancer (2022). Medium credibility.

Conclusions and relevance

In summary, care needs to be taken in the use and interpretation of noninferiority trials. Ideally, two margins should be specified: one based on an absolute difference for determining clinical noninferiority compared with standard treatment; and a second based on a relative difference for inferring efficacy relative to no treatment. A comparison with no treatment is essential when the new treatment is noninferior but numerically less efficacious than the standard treatment. This is usually based on meta-analysis of historical comparisons of the conventional treatment with no treatment, focusing on patients with similar prognosis to the population in the current trial.

As with conventional superiority trials, one must specify the population being evaluated. Typically, intention-to-treat (ITT), per protocol or as treated are used. One point that needs to be considered with a noninferiority analysis is that the new treatment may be more acceptable to patients than conventional treatment, potentially due to greater ease of use or fewer side effects, leading to higher compliance. Usually, the ITT population is most appropriate, but as noted above, this can underestimate the actual difference between treatments, and it is important to report the compliance with treatment in both arms and discuss as necessary.

Noninferior treatments can be conventionally inferior, non-significantly different, or superior to the standard treatment, and a conventional analysis also needs to be provided to report this. When the new treatment is inferior, further analysis of the extent of the inferiority, and clear evidence of some other benefit is essential.

---

### Noninferiority trial design: opportunities and challenges [^5c83ca17]. The Journal of Hand Surgery (2022). Medium credibility.

Defining treatment effectiveness is the foundation of evidence-based practice. Most studies comparing the effectiveness of treatment options involve superiority designs in which a treatment is compared against a placebo, standard care, or an alternative treatment. However, in scenarios in which it is not ethical to consider these options, noninferiority designs can be considered. Noninferiority (NI) trials aim to demonstrate that a new treatment is not unacceptably worse than a standard treatment. Noninferiority is determined relative to a noninferiority margin, which is the difference between the test and active control treatment that is not unacceptably clinically inferior. However, there are important considerations with respect to the design, analysis, and interpretation of NI studies, which differ from superiority trials. This review will outline the key components of NI trials, how to interpret the findings, and understand their nuances and potential limitations.

---

### How to use a noninferiority trial: users' guides to the medical literature [^ad71a21b]. JAMA (2012). Excellent credibility.

Clinical investigators are increasingly testing treatments that have the primary benefit of decreased burden or harms relative to an existing standard. The goal of the resulting randomized trials — called noninferiority trials — is to establish that the novel treatment's effectiveness is not substantially less than the existing standard. Conclusions from these trials are, however, based on noninferiority thresholds specified by authors whose judgments may not coincide with those of patients and clinicians. This article highlights issues related to validity, interpretation, and applicability of results specific to noninferiority trials. Suboptimal administration of standard treatment or exclusive reliance on the analyze-as-randomized approach that is standard for conventional superiority trials may produce misleading results in noninferiority trials. Clinicians should judge whether the novel treatment's impact on effectiveness outcomes — the prime reason for wanting to prescribe it — is sufficiently close to that of standard treatment that they are comfortable substituting it for the existing standard. Trading off desirable and undesirable consequences is an individual decision: given the benefits of a novel treatment, some patients may perceive the uncertainty regarding a reduction in treatment effectiveness as acceptable while others may not.

---

### Empirical consequences of current recommendations for the design and interpretation of noninferiority trials [^e4d071a2]. Journal of General Internal Medicine (2018). Low credibility.

METHODS

We searched MEDLINE using the search terms "noninferiority", "noninferior", "non-inferiority", and "non-inferior" combined with the name of the journals as recognized by MEDLINE and published between June 1, 2011, and November 1, 2016. We limited our search to the five highest-impact general medical journals in order to focus on the most widely cited and possibly highest-quality articles. – We reviewed the resulting abstracts to identify articles that met our inclusion criteria: prospective, parallel-group randomized controlled trials where the primary outcome was tested using a noninferiority hypothesis. We then reviewed the full manuscripts and excluded trials that had a cluster-randomized design, trials where the data were incomplete or could not be summarized, those that used a Bayesian methodology, and those that did not use an AC (e.g. Food and Drug Administration [FDA]-mandated placebo-controlled post-approval safety studies). One author (SKA) abstracted the data from the trials into a standardized form and employed a system of redundant checks to ensure data accuracy. Another author (AMH) checked a sample of the data to ensure accuracy. We tabulated basic data about the trial including methodological and statistical design as reported. In trials where more than one analysis was reported (e.g. intention-to-treat [ITT], per-protocol [PP], as-treated [AT]), we determined whether the results differed depending on the analytical method.

We characterized trial results in terms of the point estimate and confidence intervals in accord with Figure 1 of the CONSORT statement, using a 95% two-sided confidence interval, calculated from the raw numbers provided in the manuscript, and coded the trial authors' conclusions regarding declarations of noninferiority, superiority, inferiority, or inconclusive results, and whether they differed from CONSORT. We used the first outcome mentioned in the manuscript as the primary outcome for our data set when multiple outcomes were reported. Some trials compared multiple interventions, e.g. multiple doses of a new drug against one AC group, and we considered these to represent separate comparisons. In determining whether justification for the selection of a delta value was presented, we coded trials as having "none" if no mention whatsoever was made as to how it was selected, "abstract" if some mention was made but it was vague or irreproducible, and "concrete" if an explicit reproducible justification was provided.

---

### Interpreting the results of noninferiority trials-a review [^ae0dbfe8]. British Journal of Cancer (2022). Medium credibility.

To infer some efficacy of the new treatment versus no treatment, its minimal effect (i.e. the upper limit of the 95% confidence interval for recurrence) versus conventional treatment should be less than the minimal effect of conventional treatment versus no treatment (termed M 1 by the FDA). As M 1 is based on historical comparisons, and only supports some efficacy of the new treatment vs no treatment, the FDA recommends taking some fraction of M 1, e.g. M 1 /2, for the 'efficacy' margin so that at least half the efficacy of the conventional treatment is retained. Note that specifying a smaller fraction is a more demanding requirement in that a greater proportion of the benefit of the conventional treatment must be retained, e.g. using M 1 /5 would require that at least 80% of the conventional treatment vs no treatment effect is retained. In many cases, the stipulation based on the noninferiority margin will be more demanding, especially when there is a large and well-established effect of the conventional treatment. When the population being studied has changed in an important way from the historical standard, the estimate of M 1 can be unreliable. In this situation, there may be a case for a three-arm trial, in which a no-treatment arm is added alongside the conventional treatment and the new treatment arms. This is only justified if there is uncertainty (equipoise) as to whether the conventional treatment is superior to no treatment in this new setting.

---

### Interpreting the results of noninferiority trials-a review [^a4ce1df3]. British Journal of Cancer (2022). Medium credibility.

Comparisons with a no-treatment arm

For a new treatment to be considered acceptable it is essential that it is shown to be superior to no treatment. In most noninferiority trials, this is a problem because there is no untreated (or placebo only) arm; the new treatment is only compared with the accepted conventional treatment. A key challenge is to estimate the counterfactual: what would have happened had the patients not been treated, and consider the potential benefits of the new treatment compared to no treatment. Even if not as efficacious as the standard treatment, it is essential that the new treatment provides some benefit — i.e. it should be superior to a placebo. Assessing this is necessarily based on comparisons with a historical series, and to do this a second 'efficacy' margin needs to be specified to indirectly infer superiority to no treatment. Even if guided by a meta-analysis of trials of standard treatment compared with no treatment, the magnitude of this effect will be less reliably determined, as it is necessarily based on an indirect comparison with a historical reference. Using the observed progression rate in an untreated population may provide a poor counterfactual for the population under study if improvements in supportive treatment have led to a better prognosis, or if simply the inclusion criteria of historical trials were quite different from those in the current trial.

---

### Empirical consequences of current recommendations for the design and interpretation of noninferiority trials [^82d6e28a]. Journal of General Internal Medicine (2018). Low credibility.

Figure 3
Plot of 151 comparisons of absolute risk differences as a function of the log of the total number of patients analyzed in the trial, color coded by the interpretation of the results as recommended by CONSORT. See text for details.

Figure 4
Plot of 151 comparisons with a calculable absolute risk difference as in Figure 3, but with statistically significant results in favor of active control (AC), coded as inconclusive or noninferior in Figure 3, denoted by red in Figure 4.

In five of the comparisons where the authors used an alpha threshold less stringent than a two-sided 0.05 equivalent, our use of a two-sided 95% confidence interval changed the conclusions. In each of these cases, the more stringent confidence interval made the result less favorable for the NT. In one trial, use of a two-sided 95% confidence interval changed the result from superior to noninferior. In three trials, the use of a two-sided 95% confidence interval caused a change in the classification of the result from scenario 6 (inconclusive) to scenario 7 (the NT is statistically significantly worse but the result is deemed inconclusive), and in one trialit changed a scenario 3 (noninferior) to scenario 7 (inconclusive). In all these instances, it was the change from a one-sided to a two-sided confidence interval that changed the categorization of the result, rather than increased stringency from the use of a smaller one-sided alpha value. In the most extreme case (antibiotics vs. appendectomy for acute appendicitis), the use of a one-sided confidence interval concealed a large and highly statistically significant result in favor of the AC (absolute difference = 27%; 95% CI 21.3–32.9%). Two other trials had statistically significant results favoring the AC by 7% or more that were concealed by the CONSORT interpretative framework.

---

### Is noninferior not inferior? [^ea9bc274]. NEJM Evidence (2022). Medium credibility.

Is Noninferior Not Inferior? What is a non-inferiority trial margin? To answer this, ask whether you have ever weighed a tradeoff between the best version of something and an acceptable alternative. Restated, in a choice between two decisions, is one option not inferior to the other? Watch an animated video that explores the basis for non-inferiority trials, the meaning of non-inferiority margins, and the interpretation of a non-inferiority trial's results.

---

### Assessment of noninferiority margins in cardiovascular medicine trials [^511441c7]. JACC: Advances (2024). Medium credibility.

Assessment of trial interpretation

All the 10 analyses that originally claimed noninferiority but did not meet noninferiority after recalculation did not include cautionary notes to account for the chance of a differing interpretation (Central Illustration). Compared to others, these trials displayed a larger median difference between anticipated and recalculated noninferiority margins (44.7% [IQR: 38.6%-56.7%] vs 15.3% [IQR: −1.5% to 28.9%]; P < 0.001).

---

### Active-control clinical trials to establish equivalence or noninferiority: methodological and statistical concepts linked to quality [^efc94460]. American Heart Journal (2003). Low credibility.

The randomized, double-blind, placebo-controlled trial is the optimum method for clinical evaluation of new treatments, as assessed by clinicians and statisticians. However, if a known standard of therapy exists, it may be difficult to prove that a new therapy is superior. Equivalence and noninferiority clinical trial designs are now frequently utilized in clinical medical research. This article reviews the statistical differences between superiority, equivalence, and noninferiority design schemes, which pose specific ethical questions and have important implications for interpretation and clinical application of trial results. A guideline is proposed as a standard approach for reporting to facilitate qualitative assessment of the methodology of these trials.

---

### Interpreting the results of noninferiority trials-a review [^03238b0c]. British Journal of Cancer (2022). Medium credibility.

Inferior 'noninferior' treatments

A treatment is either noninferior or 'not noninferior'. Curiously, when clinical noninferiority is established, the new 'noninferior' treatment can be inferior to the comparator treatment in the conventional sense of being statistically significantly worse (Fig. 1). This confusing language occurs because a noninferiority comparison allows a noninferiority margin, and if this is made large enough, a treatment which is significantly less efficacious than the standard treatment can still meet the noninferiority criterion. Thus, a full evaluation should also consider if the new treatment is statistically inferior to the conventional treatment. When this is the case, it is particularly important to ask, 'What is the evidence that the new treatment is more efficacious than no treatment?' Failure to address these points is a serious omission and can lead to an unbalanced evaluation of the value of the new treatment.

Such an outcome arose in the TARGIT-A trial of intraoperative radiotherapy (IORT) for localised breast cancer. Here, a 2.5% absolute difference in 5-year local recurrence was the pre-specified noninferiority margin. This noninferiority margin was met, but IORT led to more than twice the number of local recurrences when compared with conventional external beam radiotherapy (EBRT), and this difference is conventionally statistically significant (i.e. the null hypothesis of no difference in local recurrence rate would be rejected) for the predefined 5-year follow-up (24 vs 11 cases; 5 y Kaplan–Meier 2.33% vs 1.02%, difference 1.21% (95% CI (0.33–2.09%); binomial RR = 2.22, P = 0.024). Further, using all available follow-up (median 8.6 years), the absolute difference between treatments was substantially larger (60 vs 24 cases, 5.26% vs 2.07%, difference 3.19%) and this difference in proportions was highly significant (P = 0.00004) [, Table 3]. Thus, IORT was noninferior but conventionally inferior to EBRT in terms of 5-year local recurrence. However, in a secondary analysis, the authors report that when all-cause mortality is included for a composite endpoint of local recurrence-free survival, no significant differences were seen between treatment arms (, Fig. 3).

---

### An orwellian discourse on the meaning and measurement of noninferiority [^0fc15a5e]. The American Journal of Cardiology (2007). Low credibility.

The customary interpretation of active-controlled noninferiority trials is founded on a number of unverifiable assumptions. These assumptions can be circumvented, and the semantic and statistic interpretation of the trials placed on a more rational foundation, if treatment comparisons are analyzed from a Bayesian perspective. In conclusion, the resultant probabilistic measures thereby render the meaning of noninferiority more transparent and clinically relevant.

---

### Making sense of noninferiority: a clinical and statistical perspective on its application to cardiovascular clinical trials [^da260725]. Progress in Cardiovascular Diseases (2006). Low credibility.

Active control noninferiority trials are being used with increasing frequency in new drug or device development when standard placebo-controlled trials are considered unethical. Nevertheless, the design and analysis of these trials are founded on a number of assumptions and arbitrary criteria that are generally not well understood or justifiable. Trials designed to show noninferiority require an appropriate reference population, a proven active control and dose, an appropriate margin of noninferiority that is clinically relevant and statistically justifiable, a high level of adherence to treatment, and adequate statistical power to reliably conclude that a treatment is truly noninferior and therefore effective. Accordingly, if noninferiority trials are to be applied to clinical and regulatory decisions regarding the marketing and use of new treatments, the assumptions must be made explicit and their influence on the resultant conclusions must be assessed rigorously. When conservative criteria were applied to each of the key assumptions underlying 2 representative noninferiority trials, they materially undermined the conclusions regarding noninferiority failing to confirm reported conclusions regarding noninferiority despite enthusiastic dissemination and acceptance of the results. Because the clinical, regulatory, and economic impact of active control noninferiority trials is substantial, robust criteria should be used routinely in their design, analysis, and interpretation to reach their intended objectives and to keep them from becoming wasted efforts.

---

### Misleading reporting (spin) in noninferiority randomized clinical trials in oncology with statistically not significant results: a systematic review [^c9a0e9fc]. JAMA Network Open (2021). High credibility.

Key Points

Question

Is the interpretation and reporting of noninferiority trials with primary end point results that are not statistically significant correct, and what are the associated factors of misleading reporting?

Findings

This systematic review of 52 noninferiority randomized clinical trials of cancer treatments with results for primary end points that are not statistically significant, 75% included misleading reporting. Multivariable analysis found that the prevalence of misleading reporting was significantly lower in reports with funding from for-profit sources and higher in reports of novel experimental treatments.

Meaning

These findings suggest that authors should carefully consider noninferiority cancer clinical trial result interpretation and reporting, especially for primary outcome results that are not statistically significant.

---

### Assessment of noninferiority margins in cardiovascular medicine trials [^bde1d986]. JACC: Advances (2024). Medium credibility.

In evidence-based medicine, randomized controlled trials are critical for advancing science and informing clinical practice. However, several types of bias in trial design and conduction may affect their results and interpretation. Communicating the primary results of a trial at a large international medical conference with simultaneous or subsequent publication in a peer-reviewed medical Journal is another step where substantial bias may occur. For instance, the conclusions of a study may be intentionally or unintentionally interpreted and reported with positive connotations despite evidence of neutral or negative results.,

These issues can be even more challenging in the setting of a noninferiority design. Experts and regulatory authorities established some critical considerations in this scenario. The reporting and interpretation of noninferiority trials depend on rejecting or failing to reject a so-called "null hypothesis" (ie, arm A is inferior to arm B) and therefore accepting the corresponding "alternative hypothesis" (ie, arm A is inferior to arm B by less than a certain prespecified treatment effect, also known as noninferiority margin). In particular, the outcome of a noninferiority trial depends on where the CI of the effect size for a treatment or strategy lies around the noninferiority margin. Therefore, the choice of the margin represents a key issue for the validity and credibility of a noninferiority trial. To establish an accurate summary estimate of the treatment effect, regulators recommend that previous studies of the active control versus placebo are evaluated and, as appropriate, the effect size is obtained by pooling the available measures with meta-analytic methods, with the final aim to preserve more than a half of the putative effect of the active control versus placebo when selecting the noninferiority margin.

---

### Empirical consequences of current recommendations for the design and interpretation of noninferiority trials [^07642d49]. Journal of General Internal Medicine (2018). Low credibility.

In a superiority trial, a two-sided alpha threshold for statistical significance is conventionally set at < 0.05, whereas alpha thresholds in noninferiority trials are more variable. No investigations to date have evaluated whether the selection of an alpha threshold less stringent than a two-sided 0.05 equivalent influences the conclusions of noninferiority trials.

It is commonly noted that intention-to-treat analyses, recommended for superiority trials, are less conservative than per-protocol or as-treated analyses in noninferiority trials. – However, only one small studyhas investigated whether the conclusions of noninferiority trials vary by method of analysis, and whether per-protocol and as-treated analyses are more conservative.

Finally, a proposed ethical prerequisite for the use of a noninferiority design states that the NT must have known advantages such as reduced cost, greater convenience, or fewer side effects to justify the randomization of patients to a therapy with unknown efficacy. This requirement is not met in some noninferiority trials, but we are not aware of any empirical investigation of the frequency with which this occurs.

Our aim was to investigate how the aforementioned characteristics of noninferiority trials affect their results and the validity of their conclusions.

---

### Good enough: a primer on the analysis and interpretation of noninferiority trials [^ab6296d1]. Annals of Internal Medicine (2006). Low credibility.

Active-control noninferiority trials are being performed with increasing frequency when standard placebo-controlled trials are considered unethical. Three attributes are optimally required to establish noninferiority: 1) The treatment under consideration exhibits therapeutic noninferiority to the active control; 2) the treatment would exhibit therapeutic efficacy in a placebo-controlled trial if such a trial were to be performed; and 3) the treatment offers ancillary advantages in safety, tolerability, cost, or convenience. Trials designed to show noninferiority require an appropriate reference population, a proven active control and dose, a high level of adherence to treatment, and adequate statistical power. However, the formal analysis of such trials is founded on several assumptions that cannot be validated explicitly. These assumptions are evaluated in the context of 8 recently published noninferiority trials. The analyses in this paper confirm the establishment of noninferiority in only 4 of the 8 trials. The authors conclude that if noninferiority trials are to be applied to clinical and regulatory decisions about the marketing and use of new treatments, these assumptions must be made explicit and their influence on the resultant conclusions assessed rigorously.

---

### Empirical consequences of current recommendations for the design and interpretation of noninferiority trials [^b2b6a422]. Journal of General Internal Medicine (2018). Low credibility.

INTRODUCTION

Noninferiority trials are used to compare a new therapy (NT) to an active control (AC) when the use of a placebo control is not ethically feasible. The prevalence of noninferiority trials is increasing, despite concerns about their validity owing to several design and interpretation controversies. Compared to superiority trials, the interpretation of noninferiority trials is less straightforward, and there is greater flexibility and variability in their design parameters. Little empirical research has evaluated how these unique features may affect the validity of noninferiority trial results and conclusions.

In 2006, the CONSORT [Consolidated Standards of Reporting Trials] Group provided specific recommendations for the reporting of noninferiority and equivalence trials. Our Figure 1 is a simulacrum of the CONSORT schematic. As explained in the caption, asymmetry in interpretation using this schematic creates a potential bias in favor of the new or experimental therapy. The frequency with which biased interpretation results from this asymmetry is unknown.

Figure 1
Simulacrum of the CONSORT diagram for interpreting the results of noninferiority trials. According to CONSORT, noninferiority can be declared whenever the upper bound of the confidence interval of the difference between the two therapies does not include delta, as in scenarios 1–4. Whenever the upper bound of the confidence interval exceeds delta, as in scenarios 5–7, noninferiority cannot be declared, because the plausible values of the parameter include some values greater than delta. When both the upper and lower bounds of the confidence interval exceed delta, the NT is declared inferior to the AC, as in scenario 8. Scenario 1 represents all situations in which the upper bound of the confidence interval is less than zero — that is, any statistically significant result favoring the NT garners a declaration of superiority for the NT. By contrast, in scenarios 4 and 7, where there is a statistically significant difference favoring the AC, the NT is not declared inferior in this schematic, but rather noninferior (scenario 4) or inconclusive (scenario 7). NT, new treatment; AC, active control; Δ, delta (the pre-specified margin of noninferiority).

---

### Reporting of noninferiority margins on clinicalTrials.gov: a systematic review [^ca9268d7]. JAMA Network Open (2025). High credibility.

Introduction

Noninferiority trials aim to determine whether a new treatment is as effective as a reference treatment. The noninferiority margin is a central element in these trials, representing the loss of effectiveness in the primary end point compared with the reference treatment, which is acceptable given the benefits offered by the new treatment, such as improved safety, lower costs, or more convenient administration schemes. The importance of this margin and the methods for its definition have been described in guidelines from the US Food and Drug Administration, the European Medicines Agency, and the CONSORT (Consolidated Standards of Reporting Trials) 2010 statement extension for noninferiority trials. The margin must be justified on the basis of existing literature or clinical relevance and established during the trial planning stage for sample size calculation. The noninferiority margin is also crucial for interpreting results and drawing conclusions. To establish the noninferiority of the new treatment compared with the reference treatment, the CI of the new treatment effect must lie within the zone defined by the noninferiority margin.

Since 2005, the International Committee of Medical Journal Editors has mandated the registration of clinical trials in recognized public registries as a prerequisite for publication. One of the objectives of the prospective registration of clinical trials is to limit selective outcome reporting, a practice that involves modifying outcomes between the protocol and the publication, which has been shown to distort research findings toward overly favorable and misleading results. Given the crucial role of the noninferiority margin in the design and interpretation of noninferiority trials, its reporting at the time of registration as well as its consistency through the publication appears essential. However, concerns have been raised regarding the potential distortion of the noninferiority margin in protocols, trial registries, and publications. A study published in 2015 identified a discordance rate of 9% between the noninferiority margins reported in protocols submitted to ethics committees and those reported in corresponding publications. Few data exist on the reporting of the noninferiority margin in trial registries, but the most recent study found that a low proportion (only 2.6%) of the trials prespecified the noninferiority margin at initial registration. These findings were based on trials published between 2012 and 2014; thus, their registration on ClinicalTrials.gov occurred much earlier.

---

### The role of noninferiority studies in orthopaedic surgery: determining whether outcomes are the same, No worse, or simply not different [^0b81f895]. The Journal of Bone and Joint Surgery: American Volume (2025). Medium credibility.

➢ With any study, readers should be cautious and critical when the conclusion is that "these treatments are the same".➢ If only superiority testing was performed, failing to find a difference does not mean that the treatments are the same, even when the study was adequately powered.➢ Noninferiority analysis is the correct method to compare treatments that researchers and clinicians think may be "the same" for the primary outcome.➢ The most important aspect of a noninferiority analysis is the selection of the noninferiority margin, which is the minimum difference between groups that would be considered meaningful.➢ To perform noninferiority testing, the difference in an outcome measure of interest between experimental and control groups must be examined with respect to the noninferiority margin of the same outcome measure. Assuming that a greater value indicates improvement in an outcome measure, if the lower bound of a 95% confidence interval of a difference in means based on a 1-sided test is greater than the noninferiority margin, then the experimental treatment can be considered noninferior to the control.

---

### Empirical consequences of current recommendations for the design and interpretation of noninferiority trials [^1b3f31d0]. Journal of General Internal Medicine (2018). Low credibility.

RESULTS

Figure 2 shows the results of our search; 160 included manuscripts reported the results of 163 distinct trials and 182 noninferiority comparisons reported for those trials.

Figure 2
Flow diagram showing the results of our search.

Table 1 shows the characteristics of the trials. The majority of trials (78%) were published in the two highest-impact journals. Therapies pertaining to five specialties (infectious diseases, hematology/oncology, cardiology, pulmonary/critical care, and endocrinology) accounted for 91% of all trials in our cohort. Reporting was complete (100%), with no missing data for the primary outcome, delta, power, alpha sidedness, and planned sample size. Reporting of alpha was complete in 98.5% of trials, and the primary method of analysis was reported in 95.5%. Justification for delta, the pre-specified margin of noninferiority, was not reported in 58% of trials, and in only 25% was reported in a way that allowed replicability of its method of determination. Almost one-third of the trials (32%) used a two-sided alpha equivalent greater than the conventional standard for superiority trials (0.05), with four trials using the equivalent of a two-sided alpha of 0.20.

Table 1
Characteristics of the Trials in Our Cohort

NEJM, New England Journal of Medicine; Annals, Annals of Internal Medicine

For trials that used primary outcomes convertible to an absolute risk difference (n = 137), the mean pre-specified delta was 8.7%, with a range of 0.4% to 25%. For trials where mortality was the primary outcome or part thereof (n = 48), the mean pre-specified delta was 6.1%, with a range of 0.4% to 19.1%, and if mortality was not part of the outcome (n = 89), the mean pre-specified delta was 10.0%, with a range of 0.57% to 25%. The mean observed delta for the primary outcome in the 151 comparisons convertible to an absolute risk difference was +0.04% (range − 36.6% to +26.9%), with 61 point estimates favoring NT and 63 favoring AC. Of the total 182 comparisons, 95 point estimates favored the new treatment and 87 favored the alternative.

---

### Addendum: estimands and sensitivity analysis in clinical trials… [^ebc1c9d2]. FDA (2025). Medium credibility.

This addendum clarifies and extends ICH E9 in a number of respects. 43 44 Firstly, ICH E9 introduced the Intention-To-Treat principle in connection with the 45 effect of a treatment policy, i.e. the effect of treatment initially assigned at baseline. discontinuing treatment were lost to follow up. This addendum invites consideration of the 63 important distinction between non-adherence with, or withdrawal from, randomised treatment 64 and discontinuation from the trial; also between measurements that exist but have not been 65 collected, and measurements that do not, or cannot, exist. Having clarity in the estimand. 84 way that is less biased and more interpretable than naïve analysis of the per protocol set. 85 86. 167 reflect the lack of effect of the treatment when it is not taken. The set of intercurrent events 168 for consideration will depend on the specific therapeutic setting and trial objective.

Taking 169 use of rescue medication as an example, two different specifications include the combined 170 effect of treatment and any intercurrent event and the. 247 is given to subjects previously randomised to the control arm), but the treatment effect of 248 interest might concern the outcome if the subsequent active treatment had not been 249 administered. In these examples the non-availability of rescue medication and the absence of 250 the other active treatment reflect different hypothetical conditions. 290 adherence to treatment; it is of utmost importance to distinguish between treatment effects of 291 interest based on the hypothetical scenario of "if all subjects would adhere" from the 292 stratum of subjects who "would be able to adhere if administered the experimental treatment" 293.

344 events to reflect the scientific question of interest might be based on understanding the 345 treatment effect if the alternative treatment was not available, or in the stratum of subjects 346 who can adhere to treatment without needing an alternative. In some circumstances, answers 347 to these questions might be more relevant than e.g. the quantification of the effects of a 348 treatment policy that does not distinguish whether or not a patie.

---

### Reducing inferiority in the design, conduct, analysis, reporting, and interpretation of noninferiority trials [^5c4be059]. JACC: Advances (2024). Medium credibility.

The current approach to noninferiority may itself be inferior at present. As has been recommended in the past, composite endpoints with diverging responses in individual components to pharmacologic or device therapy are not appropriate (eg, combing bleeding and efficacy endpoints) as they drive the result to noninferiority while masking important differences in the safety and efficacy of the strategies. Just as clinicians and patients do in their decision-making, safety and efficacy data should be considered separately, and decisions should be based upon the totality of what are often divergent data. Rather than using noninferiority, superiority in safety (bleeding) of a new strategy could be established, and broader, more well powered patient centric endpoints such as death and hospitalization could be used to assess efficacy. Careful monitoring of event rates is warranted, and should they be lower than expected, sample sizes could be increased, or patient risk could be increased. Given the frequency with which noninferiority trials may be underpowered and no longer statistically significant when analysis is based upon actual event rates, regulators, journal editors, trialists and clinicians should require that both an absolute and a relative margin be assessed before a therapy is truly deemed to be noninferior to another. If there are concerns regarding the magnitude of missing data, tipping analyses should be performed to assess the robustness of the non-inferiority findings. These modifications may represent a superior approach to the current deficiencies in noninferiority trials.

---

### A case for using relative rather than absolute noninferiority margins in clinical trials [^356a4839]. JACC: Advances (2024). Medium credibility.

Debunking of 2 common arguments in favor of absolute noninferiority margins

# 1. Absolute risks are more interpretable: A common argument favoring the use of absolute noninferiority margins is that absolute risk differences are more clinically relevant and easier to interpret than relative risk differences. The common practice in clinical trials to derive the absolute margin as the expected event rate multiplied by the maximally acceptable relative risk directly contradicts this argument.

# 2. Absolute noninferiority margins have better statistical power: A common reason for ultimately using absolute rather than relative margins in noninferiority trials is the fact that for any given true event rate (ie, the population event rate or the event rate that would be observed if we enrolled an infinite number of patients from the intended study population), a trial that uses an absolute noninferiority margin will have better statistical power to show noninferiority than a trial that uses a relative noninferiority margin corresponding to the same difference. For example, if the true event rate in both the treatment arm and the control arm is 7.5% and patients are randomized 1:1 to treatment vs control, then a trial with an absolute margin of 3% will require 3,300 patients to achieve 90% power, whereas a trial with a relative margin of 1.4 will require 4,640 patients to achieve 90% power.

This apparent benefit of an absolute noninferiority margin is, however, an illusion related to the fact that if we were to conduct a large number of trials in which both treatment and control groups are sampled independently from populations with 7.5% event rates, then the relative difference would exceed 1.4 more often than the absolute difference would exceed 3%. Consider, for example, a trial in which the observed event rates are 6% in the control arm and 9% in the treatment arm. In this trial, the absolute difference is 3% and the relative risk is 1.5, but the observed risk difference corresponds to a 50% increased risk irrespectively. Rather than reverting to using an absolute noninferiority margin because the estimated sample size would be lower than if a corresponding relative margin was used, a more permissive relative margin should be allowed.

---

### Empirical consequences of current recommendations for the design and interpretation of noninferiority trials [^d27d08bd]. Journal of General Internal Medicine (2018). Low credibility.

Background

Noninferiority trials are increasingly common, though they have less standardized designs and their interpretation is less familiar to clinicians than superiority trials.

Objective

To empirically evaluate a cohort of noninferiority trials to determine 1) their interpretation as recommended by CONSORT, 2) choice of alpha threshold and its sidedness, and 3) differences between methods of analysis such as intention-to-treat and per-protocol.

Design

We searched MEDLINE for parallel-group randomized controlled noninferiority trials published in the five highest-impact general medical journals between 2011 and 2016.

Main Measures

Data abstracted included trial design parameters, results, and interpretation of results based on CONSORT recommendations.

Key Results

One hundred sixty-three trials and 182 noninferiority comparisons were included in our analysis. Based on CONSORT-recommended interpretation, 79% of experimental therapies met criteria for noninferiority, 13% met criteria for superiority, 20% were declared inconclusive, and 2% met criteria for inferiority. However, for 12% of trials, the experimental therapy was statistically significantly worse than the active control, but CONSORT recommended an interpretation of inconclusive or noninferior. A two-sided alpha equivalent of greater than 0.05 was used in 34% of the trials, and in five of these trials, the use of a standard two-sided alpha of 0.05 led to changes in the interpretation of results that disfavored the experimental therapy. In four of the five comparisons where different methods of analysis (e.g., intention-to-treat and per-protocol) yielded different results, the intention-to-treat analysis was the more conservative. In 11% of trials, a secondary advantage of the new therapy was neither reported nor could it be inferred by reviewers.

Conclusions

In this cohort, the design and interpretation of noninferiority trials led to significant and systematic bias in favor of the experimental therapy. Clinicians should exercise caution when interpreting these trials. Future trials may be more reliable if design parameters are standardized.

---

### Empirical consequences of current recommendations for the design and interpretation of noninferiority trials [^1af57f08]. Journal of General Internal Medicine (2018). Low credibility.

We found that point estimates from trials in our cohort were nearly symmetrically distributed around a difference of zero, similar to two prior investigations. A large analysis of superiority trials found a similar symmetrical distribution in new versus established treatments. While the stochastic nature of these results is of epistemological interest and open to speculative interpretation, we reason that this pattern provides support for the idea that new treatments, on average, are not substantially better than existing treatments. On this basis alone, the allowance of preferential treatment for NT is unjustified, especially given our finding that for many NTs, a specific secondary advantage of the NT was not stated and could not be inferred.

Our results have significant implications for the design and analysis of future noninferiority trials. The use of the CONSORT diagram (Fig. 1) for the classification of results should be reevaluated given its obfuscation of results disfavoring NT by a statistically significant margin in 12% of trials in our cohort. This view is bolstered by the fact that the authors of these reports had various ways of drawing conclusions in these CONSORT 4 and 7 scenarios, and that their conclusions often differed from the recommendations. An alternative approach would be to conclude superiority of any treatment with a statistically significant difference favoring it regardless of direction or size. This would remedy much of the directional bias resulting from asymmetry seen in Figure 5. Alternatively, the noninferiority design could be abandoned in favor of equivalence trials with symmetrical delta margins on both sides of unity.

---

### Misleading reporting (spin) in noninferiority randomized clinical trials in oncology with statistically not significant results: a systematic review [^15500ed9]. JAMA Network Open (2021). High credibility.

Importance

Spin, the inaccurate reporting of randomized clinical trials (RCTs) with results that are not statistically significant for the primary end point, distorts interpretation of results and leads to misinterpretation. However, the prevalence of spin and related factors in noninferiority cancer RCTs remains unclear.

Objective

To examine misleading reporting, or spin, and the associated factors in noninferiority cancer RCTs through a systematic review.

Data Sources

A systematic search of the PubMed database was performed for articles published between January 1, 2010, and December 31, 2019, using the Cochrane Highly Sensitive Search Strategy.

Study Selection

Two investigators independently selected studies using the inclusion criteria of noninferiority parallel-group RCTs aiming to confirm effects to cancer treatments published between January 1, 2010, and December 31, 2019, reporting results that were not statistically significant for the primary end points.

Data Extraction and Synthesis

Standardized data abstraction was used to extract information concerning the trial characteristics and spin based on a prespecified definition. The main investigator extracted the trial characteristics while both readers independently evaluated the spin. The Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) reporting guideline was followed.

Main Outcomes and Measures

The main outcome was spin prevalence in any section of the report. Spin was defined as use of specific reporting strategies, from whatever motive, to highlight that the experimental treatment is beneficial, despite no statistically significant difference for the primary outcome, or to distract the reader from results that are not statistically significant. The associations (prevalence difference and odds ratios [ORs]) between spin and trial characteristics were also evaluated.

Results

The analysis included 52 of 2752 reports identified in the PubMed search. Spin was identified in 39 reports (75.0%; 95% CI, 61.6%-84.9%), including the abstract (34 reports [65.4%; 95% CI, 51.1%-76.9%]) and the main text (38 reports [73.1%; 95% CI, 59.7%-83.3%]). Univariate analysis found that the spin prevalence was higher in reports with data managers (prevalence difference, 27%; 95% CI, 1.1%-50.3%), reports without funding from for-profit sources (prevalence difference, 31.2%; 95% CI, 4.8%-53.8%), and reports of novel experimental treatments (prevalence difference, 37.5%; 95% CI, 5.8%-64.7%). Multivariable analysis found that novel experimental treatment (OR, 4.64; 95% CI, 0.98–22.02) and funding only from nonprofit sources only (OR, 5.20; 95% CI, 1.21–22.29) were associated with spin.

Conclusions and Relevance

In this systematic review, most noninferiority RCTs reporting results that were not statistically significant for the primary end points showed distorted interpretation and inaccurate reporting. The novelty of an experimental treatment and funding only from nonprofit sources were associated with spin.

---

### Hypothesis testing in superiority, noninferiority, and equivalence clinical trials: implications in physical medicine and rehabilitation [^7a4a656b]. American Journal of Physical Medicine & Rehabilitation (2019). Medium credibility.

In medical research, it is important to be able to examine whether there is a significant difference between two samples. With this, establishing an appropriate hypothesis is a critical, basic step for correct interpretation of results in inferential statistical data analysis. It is important to note that the aim of hypothesis testing is not to "accept" or "reject" the null hypothesis but to gauge the likelihood that the observed difference is genuine if the null hypothesis is true. Traditionally, the null hypothesis assumes that there is no statistically significant difference between the two groups. It has become more difficult to develop new treatments that are better than the standard of care. This review article summarizes and explains the methodology of the different types of clinical trials regarding the relevant basic statistical concepts and hypothesis testing.

---

### Empirical consequences of current recommendations for the design and interpretation of noninferiority trials [^e8c6c9c2]. Journal of General Internal Medicine (2018). Low credibility.

In determining whether the NT had advantages that justified its evaluation using a noninferiority design, we coded trials as having "none" if no advantages were mentioned nor could they be inferred, "inferred" if none were reported but they could be inferred, and "explicit" if the purported advantages of the NT were explicitly stated in the manuscript. Because we were interested in the numerical statistical design features of the trials, we did not perform a subjective quality analysis as is done in a traditional meta-analysis. Likewise, because of highly variable reporting of sponsor and funding sources, and the investigators' independence from them or lack thereof, we did not abstract these data.

Summary statistics are presented for abstracted values. Chi-square and Student's t tests were used for exploratory analyses. Stata version 14 software (StataCorp LP, College Station, TX, USA) was used for all analyses, including recalculation of two-sided 95% confidence intervals.

---

### Understanding equivalence and noninferiority testing [^8251b4ac]. Journal of General Internal Medicine (2011). Low credibility.

Increasingly, the goal of many studies is to determine if new therapies have equivalent or noninferior efficacies to the ones currently in use. These studies are called equivalence/noninferiority studies, and the statistical methods for their analysis require only simple modifications to the traditional hypotheses testing framework. Nevertheless, important and subtle issues arise with the application of such methods. This article describes the concepts and statistical methods involved in testing equivalence/noninferiority. The aim is to enable the clinician to understand and critically assess the growing number of articles utilizing such methods.

---

### Quality of reporting of noninferiority and equivalence randomized trials [^8f0a675a]. JAMA (2006). Excellent credibility.

Context

Noninferiority and equivalence trials aim to show that the experimental treatment is not clinically worse than (noninferior) or clinically similar to (equivalent) a control active treatment. These study objectives imply particular planning and analysis.

Objective

To assess the methodologic quality of reports of randomized controlled trials of noninferiority and equivalence.

Design

We searched MEDLINE and the Cochrane Central Register of Controlled Trials for reports of randomized controlled trials of noninferiority and equivalence hypotheses published between January 1, 2003, and December 31, 2004.

Main Outcome Measures

Data extracted by use of a standardized form involved assessment of choice of noninferiority or equivalence margins, sample size calculation, sets of patients analyzed, method of statistical testing and reporting results, and conclusions.

Results

A total of 162 reports were included in the analysis (116 reports of noninferiority and 46 of equivalence). The margin defining noninferiority or equivalence was described in most reports (156 [96.3%]), with justification of the margin in only 33 (20.4%). Almost one quarter of the reports (35 [21.6%]) did not describe a sample size calculation, and an additional 11 (6.8%) did not take into account a prespecified noninferiority or equivalence margin. Less than half of the reports (69 [42.6%]) described both an intent-to-treat (ITT; all randomized patients are included in the analysis) or modified ITT (patients who never received treatment are excluded) and per-protocol (patients who did not complete the treatment are excluded) analysis, and only about half of those (39 [56.5%]) described both types of results. Results were displayed with confidence intervals in 136 reports (84.0%). Only 33 articles (20.3%) fulfilled reporting requirements specific to noninferiority and equivalence trials, 4 of them (12.1%) with misleading conclusions.

Conclusions

Reporting of noninferiority and equivalence trials has important deficiencies: absence of noninferiority or equivalence margin, only an ITT (or a per-protocol) analysis performed, and results not adequately reported. Moreover, even for articles fulfilling these requirements, conclusions are sometimes misleading.

---

### Reporting of noninferiority trials… [^2ae8c420]. JAMA Network (2015). Excellent credibility.

To better understand reporting of noninferiority trials, we examined registration records and results posted on ClinicalTrials. gov, as well as their corresponding publications, for information about the noninferiority margin and statistical analyses, and determined their association with trial and journal characteristics. We identified and characterized 344 unique trials registered on ClinicalTrials. gov, published in 338 articles that reported primary results of noninferiority trials. Consistent with our search strategy, all publications described noninferiority designs and nearly all provided noninferiority margins. However, any justification for choosing margins was provided for only 95. The most commonly cited reasons were previous research and reliance on expert opinion or clinical judgment. In contrast, on ClinicalTrials.

gov, approximately one-quarter described noninferiority designs, among which 15 specified noninferiority margins, 9 of which were prespecified at initial registration. The ClinicalTrials. gov and published margin values were concordant for all 15. On ClinicalTrials. gov, industry-sponsored trials were less likely to register noninferiority designs compared with nonindustry-sponsored trials, but were more likely to provide results with appropriate details of noninferiority analyses. Location, intervention, masking, and enrollment also were associated with providing results with appropriate details.

This cross-sectional analysis of noninferiority trials published between 2012 and 2014 demonstrated near-complete reporting of noninferiority designs and margins within our sample of publications, but not justification for choosing margins. However, voluntary reporting of noninferiority designs and margins in corresponding ClinicalTrials. gov records was suboptimal, consistent with prior research. 6 Moreover, among trials with results reported on ClinicalTrials. gov, more than one-third provided insufficient information to interpret noninferiority analyses.

---

### Rethinking noninferiority [^156feb8c]. JACC: Advances (2025). Medium credibility.

A Bayesian approach provides a natural statistical foundation for this process by enabling the sequential updating of treatment effect estimates as new data emerge. Instead of treating each RCT as an independent entity, the posterior distribution from one study would inform the prior for subsequent analyses, allowing for a more continuous and evidence-driven reassessment of NI.

As an alternative to using a permissive NI margin for initial approval and a more stringent NI margin for definitive approval, a single stringent NI margin could be used from the outset while varying the probability criterion at the different approval stages. Under this approach, initial approval could require a more permissive probability threshold, such as a 75% probability that the true treatment effect does not exceed the NI margin, whereas the final approval could require a 95% probability (Figure 1, right panel). While this approach deviates more from current regulatory practice, it is arguably more scientifically sound, as it ensures that the NI margin is clinically meaningful throughout the approval process.

---

### Assessment of noninferiority margins in cardiovascular medicine trials [^fa33a1a6]. JACC: Advances (2024). Medium credibility.

Discussion

The main findings of this study can be summarized as follows: 1) 3 noninferiority trials out of 4 used an ARD margin; 2) in the analyses using an ARD, almost 1 out of 4 had different results after recalculating the noninferiority margin; and 3) notes of cautionary interpretation were lacking in the conclusions of all the analyses that originally claimed noninferiority but did not meet noninferiority after recalculation.

Noninferiority trials have been increasingly performed over the last decades, and a rigorous methodology is of utmost importance to avoid the inappropriate adoption of a treatment that may threat the outcomes of patients. For instance, "biocreep" is a detrimental process that can lead to the acceptance of an inadequate treatment as a result of a stepwise sequence of noninferiority proofs entailing a gradual loss of treatment effect. To standardize and improve the architecture of noninferiority trials, several pillars have been identified by experts and regulatory authorities: 1) determination of the noninferiority margin based on the results of previous placebo-controlled trials of the active control; 2) choice of a noninferiority margin scale (ie, absolute or relative); 3) selection of appropriate endpoints (eg, clinical relevance, availability of historical data); 4) assay sensitivity over placebo (ie, superiority of the active control to placebo); 5) trial conduct (eg, adequateness of treatment administration, endpoint adjudication); and 6) selection of data analysis (eg, intention-to-treat, per-protocol, as treated).

---

### Reporting of noninferiority margins on clinicalTrials.gov: a systematic review [^7eac3b2c]. JAMA Network Open (2025). High credibility.

Conclusions

In this systematic review, we identified a concerning issue regarding the poor reporting of noninferiority margins at registration on ClinicalTrials.gov. This lack of transparency may allow for untraceable changes to the noninferiority margins, potentially distorting conclusions toward more favorable results. Implementing mandatory reporting of the design and the noninferiority margin (for noninferiority trials and the equivalence margin for equivalence trials) at registration could enhance the transparency and favor more reliable results.

---

### Assessment of noninferiority margins in cardiovascular medicine trials [^6dfcf967]. JACC: Advances (2024). Medium credibility.

Table 1
Study Characteristics According to the Chosen Type of Noninferiority Margin

Central Illustration
Assessment of Noninferiority Margins in Cardiovascular Medicine Trials

Distribution of noninferiority randomized controlled trials with relative or absolute margin over the eligible population of studies. Number of included analyses who have met noninferiority before (eg, according to authors) and after the recalculation of noninferiority margin; Number prevalence of analyses not including cautionary notes of interpretation among studies with divergent results after the noninferiority margin recalculation. ∗Indicates 1 single trial that did not claim noninferiority in the original analysis, but met noninferiority criteria after recalculation, therefore being excluded from the assessment of study conclusions. ARD = absolute risk difference; NI = noninferiority; RRR = relative risk ratio.

---

### Assessment of noninferiority margins in cardiovascular medicine trials [^74c52d7d]. JACC: Advances (2024). Medium credibility.

Among trials with divergent results after margin recalculation in our series, one showed an inverse discordance due to a higher-than-anticipated event rate. This case represents an example of why the recalculation of the ARD noninferiority margin can be important also in case of higher-than-anticipated event rates. Indeed, underestimation of event rates may lead a treatment that is actually noninferior to the control to be erroneously declared inferior, not published, and eventually excluded from further clinical development.

The absence of statements of cautionary interpretation of the study results, unduly highlighting the experimental treatment as beneficial despite fragile statistically significance in the primary outcome, can present with a variety of forms, including an excess focus on statistically significant results with selective or incomplete reporting, empowerment of secondary or subgroup analyses, interpretation of statistically nonsignificant results as a proof of equivalence, or emphasis on beneficial effects despite a lack of statistical significance. Importantly, the absence of cautionary interpretation should not be necessarily considered as a fraudulent conduct since it can also arise from unconscious bias toward or against a treatment, or insufficient methodological knowledge. Consequently, our study underscores that the noninferiority setting involves multiple considerations beyond the noninferiority margin, and it emphasizes that a rigorous interpretation of these studies requires a comprehensive analysis of all evidence, especially in cases of significant deviations between expected and observed event rates. A large investigation on the interpretation of study results has been conducted among negative or neutral oncology noninferiority trials, where it affected 3 studies out of four. In our study, a lack of phrasing suggesting the need for cautionary interpretation was identified in all the analyses showing divergent results after the margin recalculation. Interestingly, the high median percentage difference between the prespecified and the recalculated margins in analyses with divergent results seemed to be rooted in the variance between anticipated and observed event rates found in these studies. This highlights a growing challenge in designing randomized trials, especially in rapidly advancing fields where interventions improve quickly, thus affecting performance and reducing adverse events, which are key trial endpoints. In fact inaccuracies in study design predispose to the change of study results when the noninferiority margin is recalculated, therefore substantially increasing the likelihood of claiming noninferiority based on inappropriate assumptions.

---

### Randomized clinical trial design for assessing noninferiority when superiority is expected [^683d98f9]. Journal of Clinical Oncology (2007). Low credibility.

The randomized clinical trial (RCT) is the gold standard for definitive evaluation of new therapies. RCTs designed to show that the therapeutic efficacy of a new therapy is not unacceptably inferior to that of standard therapy are called noninferiority trials. Traditionally, noninferiority trials have required very large sample sizes. Sometimes, a new treatment regimen with a favorable toxicity and/or tolerability profile is also expected to have some modest improvement in efficacy. In such specialized settings we describe a hybrid trial-design approach that requires a dramatically smaller sample size than that of a standard noninferiority design. This hybrid design can naturally incorporate a formal test of superiority as well as noninferiority.

---

### Ensuring superior reporting of radiation therapy noninferiority trials: a systematic review [^69ba6959]. Advances in Radiation Oncology (2023). Medium credibility.

Introduction

Noninferiority trials aim to demonstrate that an experimental treatment is not worse than the standard treatment by a prespecified threshold called the noninferiority margin. These studies are often conducted when the experimental treatment is more convenient for patients, less toxic, more readily available, less costly, and/or when it is unethical to perform a placebo-controlled trial.

In a superiority trial, the null hypothesis asserts that 2 arms are the same. If the lower bound of the 95% confidence interval (CI) of the treatment difference is above zero, one can reject the null hypothesis (Fig 1 A). In contrast, the null hypothesis in a noninferiority trial states that the experimental arm is worse than the control arm by a specified margin (δ). There are 6 possible outcomes from a noninferiority trial as shown in Fig 1 B. If the lower bound of the 95% CI of the treatment difference is above the noninferiority margin, one can conclude noninferiority. Depending on if the 95% CI lies wholly above or below 0, one can also conclude statistical superiority or inferiority, respectively.

Figure 1
Conclusions from the 95% confidence intervals of treatment differences in superiority trials (A) and noninferiority trials (B).

As with other types of trials, the methodological quality of noninferiority trials should be appraised before drawing conclusions. A 2006 review of noninferiority trials published between 2003 and 2004 showed that only 20.3% of studies fulfilled reporting requirements to adequately allow readers to make conclusions. To improve the quality of reporting, the Consolidated Standards of Reporting Trials (CONSORT) group published a statement regarding reporting standards for noninferiority and equivalence clinical trials. A summary of the recommendations from this report are listed in Table 1.

Table 1
Summary of methodological and statistical reporting recommendations from the CONSORT 2010 extension for noninferiority and equivalence trials

Previous reviews of noninferiority trials in cancer have mainly focused on pharmacologic trials. To our knowledge, none have examined those involving radiation therapy. Noninferiority trials are important in radiation oncology as many trials test different schedules to make treatments more convenient or less toxic. This review aims to evaluate the reporting quality of noninferiority clinical trials involving radiation therapy by analyzing the reported data and to describe the characteristics of these studies.

---

### Comparative efficacy and safety profile of amlodipine 5 mg / losartan 50 mg fixed-dose combination and amlodipine 10 mg monotherapy in hypertensive patients who respond poorly to amlodipine 5 mg monotherapy: an 8-week, multicenter, randomized, double-blind phase III noninferiority study [^516849f4]. Clinical Therapeutics (2011). Low credibility.

Background

The number of hypertensive patients achieving treatment targets is not ideal with therapies that engage a single mechanism of action, and combination therapies using different mechanisms of action can increase drug efficacy in a synergistic way.

Objective

This noninferiority study compared the clinical efficacy and safety profile of fixed-dose combination of amlodipine/losartan 5/50 mg and amlodipine 10 mg monotherapy in essential hypertensive patients who respond poorly to amlodipine 5 mg monotherapy.

Methods

This was a double-blind, multicenter, randomized trial of hypertensive patients (N = 185) aged ≥ 18 years taking amlodipine 5 mg during the run-in treatment period but failed to achieve sitting diastolic blood pressure (DBP) < 90 mm Hg. After randomization into the amlodipine/losartan 5/50 mg fixed-dose combination group (n = 92) and the amlodipine 10 mg monotherapy group (n = 93), treatment was maintained without dose escalation for 8 weeks. The noninferiority margin was prespecified as 4 mm Hg after 8 weeks of treatment for the difference of the average change in DBP between treatments. The primary efficacy evaluation of noninferiority was tested using a confidence interval approach with a 97.5% 1-sided lower confidence limit using the average difference in DBP measured at baseline and 8 weeks.

Results

After 8 weeks, the DBP of both groups decreased from baseline by 8.9 (6.1) and 9.4 (7.5) mm Hg, respectively (difference = -0.5 [6.9] mm Hg, 95% CI: -2.5 to 1.5). Secondary end points of reductions in DBP after 4 weeks (-8.1 [6.7] vs -9.9 [7.3] mm Hg, difference = -1.8 mm Hg, 95% CI: -3.9 to 0.2) and sitting systolic blood pressure after 4 (-10.2 [11.8] vs -12.8 [10.2] mm Hg, difference = -2.6 mm Hg, 95% CI: -5.9 to 0.6) and 8 weeks (-12.2 [11.0] vs -13.4 [11.3] mm Hg, difference = -1.2 mmHg, 95% CI: -4.4 to 2.1) were comparable between the 2 treatment groups. There were 38 adverse events in 20 patients (21.7%) in the amlodipine/losartan 5/50 mg fixed-dose combination group and 31 in 24 patients (26.1%) in the amlodipine 10 mg monotherapy group; most were mild. There were 7 adverse events in 6 patients (6.5%) related to treatment in the fixed-dose combination group and 13 in 10 patients (10.9%) in the monotherapy group (P = 0.30).

Conclusions

Fixed-dose combination amlodipine/losartan 5/50 mg was not inferior in terms of reductions in DBP after 8 weeks of treatment and had comparable safety profile to amlodipine 10 mg in patients who did not respond to amlodipine 5 mg monotherapy. ClinicalTrials.gov identifier: NCT00940667.

---

### Rethinking noninferiority [^ae5d4d4a]. JACC: Advances (2025). Medium credibility.

The practical and ethical rationale for continued randomization

One could argue that the efficacy of a new therapy should be fully established before it is introduced into clinical practice. However, achieving this preapproval would require RCTs that are prohibitively large and costly, making it unfeasible for many companies. As demonstrated by our analysis of stent RCTs, the NI margins currently in use are much wider than what would be ideal, highlighting the need for continued evaluation after approval.

Unlike in superiority trials, where further randomization may become ethically questionable once a new treatment is proven to be more effective than its comparator, equipoise persists in NI trials because the new therapy has only been shown to be no worse than the standard within a predefined margin. This persistent equipoise allows for continued randomization, which is particularly relevant for therapies that do not offer substantial clinical advantages (such as better safety profile) over existing treatments.

By adopting a stepwise approval process for NI, regulatory agencies would foster a more rigorous approach to NI assessment, maintaining the feasibility of premarket clinical trials while ensuring patient safety by requiring further evidence before granting definitive approval to therapies with uncertain efficacy.

---

### Empirical consequences of current recommendations for the design and interpretation of noninferiority trials [^58e3e26d]. Journal of General Internal Medicine (2018). Low credibility.

Numerous previous reports have examined the adequacy of reporting of noninferiority trials, and have focused consistently on the methodology for the selection of the delta margin. Le Henanff et al.(2006) reported significant deficiencies in the reporting of statistical design parameters, justification for the delta margin selected (only 20% of reports in their cohort), and reporting of analysis method, with only 43% reporting more than one method (e.g. ITT and PP). Wangge et al.(2010) found that justification for the delta margin had increased to 46%, but the percentage reporting both types of analysis had not changed. In 2016, Rehal et al.found that justification for the delta margin remained stubbornly anchored at 46%, with multiple methods of analysis reported in 54%. These reports also described the trial authors' selections regarding alpha and its sidedness; however, our report is the first to describe and quantify the empirical consequences of these selections. Other investigators have noted the potential advantages of preferential use of ITT analyses in noninferiority trials, but the only other empirical analysis of the ITT/PP difference included just 20 trials and found results that comport with ours, with the ITT analysis being more conservative.

---

### A case for using relative rather than absolute noninferiority margins in clinical trials [^6e4d4b5a]. JACC: Advances (2024). Medium credibility.

Noninferiority trials are conducted to demonstrate that one therapy is not associated with an unacceptably high risk compared to another therapy. The maximum acceptable excess risk is defined in noninferiority trials by a "noninferiority margin", and if the difference in risk between the therapy of interest and the comparator therapy does not exceed the noninferiority margin, then the new therapy is considered safe, or "as good as" the comparator therapy.

The noninferiority margin can be expressed as an absolute or relative risk difference. Absolute rather than relative noninferiority margins are frequently used in cardiovascular trials. Unfortunately, absolute noninferiority margins are scientifically less robust than relative noninferiority margins and can lead to inaccurate conclusions regarding the safety of new therapies. This paper will attempt to describe why the issues associated with absolute margins should preclude them from being used, after first attempting to debunk 2 common arguments used in favor of absolute vs relative noninferiority margins in clinical trials.

---

### Use of mortality as an endpoint in noninferiority trials may lead to ethically problematic conclusions [^9e47b517]. Journal of General Internal Medicine (2019). Medium credibility.

Background

Noninferiority trials are becoming more common. Their design often requires investigators to "trade" a secondary benefit for efficacy. Use of mortality as an outcome of interest leads to important ethical conflicts whereby researchers must establish a minimal clinically important difference for mortality, a process which has the potential to result in problematic conclusions.

Objective

We sought to investigate the frequency of the use of mortality as an outcome in noninferiority trials, as well as to determine the average pre-specified noninferiority ("delta") values.

Design

We searched MEDLINE for reports of parallel-group randomized controlled noninferiority trials published in five high-impact general medical journals.

Main Outcome Measures

Data abstracted from articles including trial design parameters, results, and interpretation of results based on CONSORT recommendations.

Results

One hundred seventy-three manuscripts reporting 196 noninferiority comparisons were included in our analysis. Of these, over a third (67 trials) used mortality either as their sole endpoint (11 trials) or as part of a composite endpoint (56 trials). Nine trials were consort A, 21 trials consort B, 19 trials consort C, 12 were consort F, 4 consort G, and 2 were consort H. Four analyses showed statistically significant more deaths in the new treatment arm, while meeting consort criteria as "inconclusive" (consort G), (Behringer et al. in Lancet. 385(9976):1418–1427, 2015; Kaul et al. in N Engl J Med. 373(18):1709–1719, 2015; Bwakura-Dangarembizi et al. in N Engl J Med. 370(1):41–53, 2014) and thirteen trials utilizing mortality as an endpoint and had an absolute increase of > 3%, and six had an absolute increase of > 5%.

Conclusions

The use of mortality as an outcome in noninferiority trials is not rare and scenarios where the new treatment is statistically worse, but a conclusion of noninferiority or inconclusive do occur. We highlight these issues and propose simple steps to reduce the risk of ethically dubious conclusions.

---

### Ensuring superior reporting of radiation therapy noninferiority trials: a systematic review [^2a3926ec]. Advances in Radiation Oncology (2023). Medium credibility.

Discussion

In this systematic review of radiation noninferiority clinical trials, we found that the reporting of key methodological components was inconsistent. Noninferiority margins, CIs, and P values were not always reported, making it impossible to interpret results of these trials. Despite lacking the statistical rationale, a conclusion of noninferiority was claimed on the basis of inappropriate metrics in 3 studies. In light of these findings, we stress the importance of trialists reviewing CONSORT guidelines before the design of a noninferiority trial and reporting their data.

Selection of the noninferiority margin is the most important aspect in the design of a noninferiority trial as it is used to confirm or reject the hypothesis. A previous systematic review of noninferiority clinical trials of oncologic drugs showed that the median noninferiority margin was large at 12.5%. This is similar to the median noninferiority margin in our study of 9%. A larger noninferiority margin makes it easier to conclude noninferiority and can therefore be problematic if not appropriate. In contrast, a smaller margin would require a larger sample size to conclude noninferiority. Although reporting guidelines recommend that authors report the method to set the margin, only a minority of studies (10%) in our review reported statistical justification for the noninferiority margin. The European Medicines Agency and Food and Drug Administration provide guidance on deciding the margin for trials involving drugs. The margin is statistically defined as the lower bound 95% CI of the standard treatment effect compared with placebo based on historic clinical trials. A more conservative margin can also be considered to account for differences between historic trial conditions and the current trial; the Food and Drug Administration suggests the noninferiority margin to be 50% of the lower bound 95% CI of the historic standard treatment effect. These guidelines are difficult to apply to trials involving treatments that are historically not compared with placebo, such as in radiation oncology. Without statistical justification for the noninferiority margin, many authors relied on expert opinion and stakeholder analyses alone to derive their margins. This was in keeping with trials of medical devices which rely on expert opinion to select a noninferiority margin.

---

### Justification of noninferiority margin: methodology considerations in an exposure-response analysis [^babfdfb6]. Clinical Pharmacology and Therapeutics (2015). Low credibility.

The pivotal clinical trial to support the indication of liver transplantation for everolimus was based on a noninferiority trial design. The unique trial design made it impossible to estimate the noninferiority margin at the design stage. Even though the trial was conducted based on a noninferiority margin of 12% for the primary efficacy endpoint, the lack of consensus on this margin made the efficacy results difficult to interpret. A novel pharmacometric approach was applied to derive a new margin. Even though it was smaller than 12%, the new margin was large enough so that the observed efficacy results became interpretable. This novel analysis was an important contributor to the "totality of evidence" approach that led to the approval of everolimus for the new indication. This approval represents the approval of a new drug in more than 10 years for the indication of liver transplantation.

---

### Assessment of noninferiority margins in cardiovascular medicine trials [^1e8ec77c]. JACC: Advances (2024). Medium credibility.

Assessment of noninferiority margin

The relative frequency of using an ARD or a RRR as noninferiority margin was analyzed. Noninferiority trials using an ARD were further assessed if none of the following cases occurred: 1) the study used an ARD margin, but the results were reported using the upper confidence boundary of a RRR; and 2) the primary endpoint was reported as a continuous variable or event-free rate. To evaluate the impact of using an absolute noninferiority margin we recalculated the ARD margin based on the event rate observed at the end of the trial in the control group (ie, as opposed to the event rate anticipated by the investigators) (Supplemental Figure 1). In brief, for each ARD margin, the corresponding RRR margin was calculated as the ratio between the acceptable rate of events in the control arm (ie, anticipated event rate plus ARD margin of noninferiority) and the anticipated event rate in the control arm. A new acceptable event rate was then calculated as the product of the corresponding RRR margin of noninferiority and the event rate that was actually observed in the control arm. Finally, a revised ARD margin of noninferiority was calculated as the difference between the new acceptable event rate and the observed event rate in the control arm (Supplemental Figure 1, Supplemental Methods 2). The results were considered "divergent" (primary outcome) from the primary analysis if the upper boundary of the CI for the trial summary estimate (at the level of significance prespecified by the investigators) crossed the recalculated absolute noninferiority margin but did not cross the prespecified absolute noninferiority margin, or vice versa.

Assessment of trial interpretation

We scrutinized the conclusion sections of trials with diverging results for the presence of cautionary notes, ie, highlighting the risk associated with using an absolute noninferiority margin in the context of a lower-than-anticipated event rate (secondary outcome). Each article was read at the full-text level and analyzed by at least 3 independent investigators and then discussed in a consensus meeting.

---

### Rethinking noninferiority [^df0e181f]. JACC: Advances (2025). Medium credibility.

A stepwise approach to noninferiority assessment

A more adaptive and iterative regulatory framework would better balance the needs for innovation and timely introduction of new therapies with the requirement for robust clinical evidence. Instead of making a definitive decision based on a single NI RCT, the assessment of a new therapy's efficacy could follow a stepwise process, in which the treatment effect estimate is continuously refined through ongoing RCTs that continue after initial approval.

In this framework, an initial pivotal NI RCT would use a relatively permissive NI margin (as is currently the case), allowing the therapy to enter clinical practice while acknowledging residual uncertainty regarding its efficacy relative to the standard of care. However, approval at this stage would not be taken to indicate that the treatment's comparative effectiveness is fully established. Instead, subsequent RCT data would be required to incrementally improve certainty, progressively narrowing the NI margin as more evidence accumulates (Figure 1, left panel). These data could be acquired by continuing to randomize patients beyond the initial cohort intended as the analysis cohort for initial approval within the same RCT framework, or by conducting additional RCTs in parallel with the introduction of the therapy in clinical practice. Regulatory authorities could impose a time limit for when additional data would be required, and the more stringent NI margin should be met. This approach ensures that residual uncertainty is addressed while allowing promising therapies to be adopted sooner.

Figure 1
Proposed Stepwise Approach to Definitive Approval of New Therapies Introduced Via Noninferiority Trials

(Left) In the initial study cohort, a preliminary noninferiority assessment is conducted using a permissive NI margin (A), for example, requiring at least 95% probability that the true effect falls within this margin. Meeting this threshold grants conditional approval, with continued trials assessing a stricter NI margin (B) within a set time frame. Since the therapy is already on the market, the financial burden is lower than requiring a stringent margin upfront. If it fails step B, it is withdrawn; if successful, it must ultimately meet a clinically insignificant NI margin for full approval. (Right) Alternatively, a strict NI margin could be set from the start, with lower probability requirements for initial versus definitive approval. The right panel shows more probability mass extending beyond the NI margin at the initial stage (A) than at the definitive stage (C). NI = noninferiority; PDF = probability density function; TE = treatment effect.

---

### Non-inferiority trials: a systematic review on methodological quality and reporting standards [^52535678]. Journal of General Internal Medicine (2024). Medium credibility.

METHODS

Study Design

We conducted a systematic review of non-inferiority randomized controlled trials using PRISMA methods.

Study Eligibility

We included noninferiority, randomized controlled trials that were published in full-text in English in 2014 and 2019 without restriction to journal type or medical specialty. We excluded articles that only had an abstract or were equivalence or bioequivalence studies, design papers, meta-analyses, review articles, editorials, diagnostic trials, non-human trials, and duplicates.

Search Strategy

We electronically searched PubMed and Cochrane Library databases to identify randomized controlled trials published in 2014 and 2019. We searched PubMed using these key words: (noninferiority, non-inferiority, noninferior, non-inferior, noninferior*, non-inferior*) AND random*, and applied filters for human studies and English language studies. We searched Cochrane Library using the advanced search strategy using these key words: (noninferiority* non-inferiority* noninferior* non-inferior*) AND random*, and applied search limits for content type (trials), Cochrane Library publication date (all dates) and CENTRAL Trials only original publication year (2014 or 2019) and identified EMBASE as our preferred source to limit our search.

Article Selection

One of three investigators individually screened all titles and abstracts to identify potentially relevant studies. One of three investigators reviewed the remaining articles in full-text to make the final decision for article selection. Any uncertainties were reviewed by a fourth investigator and resolved by consensus.

---

### Assessment of noninferiority margins in cardiovascular medicine trials [^9f0ed6da]. JACC: Advances (2024). Medium credibility.

Background

Noninferiority trials are increasingly common in cardiovascular medicine, but their reporting and interpretation are challenging, particularly when an absolute risk difference is used as noninferiority margin.

Objectives

This study aimed to investigate the effect of using absolute rather than relative noninferiority margins in cardiovascular trials.

Methods

We reviewed noninferiority trials presented at major cardiovascular conferences from 2015 to 2022 and published within the same period. Based on the actual versus anticipated event rates in the control group, we recalculated the absolute noninferiority margin and re-assessed the trial results. The primary outcome of interest was the proportion of trials with a different interpretation after recalculation. Additionally, we analyzed the conclusion statements of these trials to determine if cautionary notes for the interpretation of study results were included.

Results

We analyzed a total of 768 trials, of which 88 had a noninferiority design and 66 used an absolute noninferiority margin. Of 48 comparisons from 45 trials qualifying for the analysis, 11 (22.9%) had divergent results after recalculation of the absolute noninferiority margin based on the observed rather than anticipated event rate. Ten trials originally claiming noninferiority, did not meet it after the margin recalculation. All of them did not include statements suggesting cautionary interpretation of the study results in the conclusion section. Compared with the other trials, these displayed a larger median difference between anticipated and recalculated noninferiority margins (44.7% [IQR: 38.6%-56.7%] vs 15.3% [IQR: -1.5% to 28.9%]; P < 0.001).

Conclusions

Recalculating noninferiority margins based on actual event rates, rather than anticipated ones, led to different outcomes in approximately 1 out of 4 cardiovascular trials, with most divergent trials lacking cautionary interpretation. These findings emphasize the importance of using or supplementing the relative noninferiority margin, particularly in studies with significant deviations between observed and expected event rates. This underscores the critical need for enhanced methodological and reporting standards in noninferiority trials, especially those employing absolute margins.

---

### Comparative effectiveness clinical trials in psychiatry: superiority, noninferiority, and the role of active comparators [^aa38194d]. The Journal of Clinical Psychiatry (2011). Low credibility.

Unlabelled

The Agency for Healthcare Research and Quality, part of the US Department of Health and Human Services, has issued several Requests for Applications to conduct comparative effectiveness research (CER). Many of the applications will involve randomized controlled clinical trials that include an active comparator. The inclusion of an active comparator has implications for clinical trial design. Despite a common misperception, a clinical trial result of no significant difference between active treatment groups does not imply equivalence or noninferiority. A noninferiority trial, on the other hand, can directly test whether one active treatment group is noninferior to the other. For example, noninferiority of an inexpensive generic could be tested in comparison with a novel, more costly intervention. Although seldom used in psychiatry, noninferiority clinical trials could play a fundamental role in CER. Features of noninferiority and the nearly ubiquitous superiority designs are contrasted. The noninferiority margin is defined and its application and interpretation are discussed.

Conclusions

Evidence of noninferiority can only come from well-designed and conducted noninferiority CER. Sample sizes needed in noninferiority trials and in superiority trials that include an active comparator are substantially larger than those needed in trials that can utilize a placebo control in their scientific design. As a result, trials with active comparators are more costly, require longer recruitment duration, and expose more participants to the risks of an experiment than do trials in which the only comparator is placebo.

---

### Assessing the justification, funding, success, and survival outcomes of randomized noninferiority trials of cancer drugs: a systematic review and pooled analysis [^135381b9]. JAMA Network Open (2019). High credibility.

Data Extraction

Data were independently extracted from published reports by 2 of us (F. A.T. and E.H.J) and verified by a third author (B.G.), with discrepancies resolved through consensus of all authors. We collected year of publication, treatment setting, primary end point, sample size, blinding (ie, double blind or open label), funding (ie, public, industry, or mixed public and industry), and the authors' listed criteria for using a noninferiority design.

We judged whether the noninferiority design was justified for each trial. Noninferiority was considered justified if the intervention being tested provided at least 1 of the following benefits to patients: (1) less cost; (2) decreased frequency of administration; (3) increased ease of administration, such as noninjectable (eg, oral) vs injectable formulation; or (4) improved quality of life.

We also extracted information on the outcome of the trial in terms of whether noninferiority was achieved. A trial was considered successful if it achieved noninferiority based on its own criteria. For trials that achieved noninferiority, we checked if the intervention also proved superiority based on 95% CIs and whether the publication concluded superiority. For quality-of-life outcomes, we considered quality of life to be improved if the summary was statistically better; we did not examine each domain of the assessment tool separately. Finally, information on the hazard ratio (HR) and 95% CI for OS were extracted from the published reports for pooled analysis. If a CI different from a 95% CI was reported, we recalculated the CI to a 95% CI.

Statistical Analysis

The associations of the justification for using the noninferiority design and success in achieving noninferiority with the funding source were assessed using Fisher exact tests. The overall association of the trial drugs on OS was assessed by pooling the HRs across the trials using a random-effects meta-analysis to account for heterogeneity. Heterogeneity among studies was assessed using the Cochrane Q statistic (assumption of homogeneity was considered invalid for values of P < .10) and quantified using an I 2 test. Subgroup analyses were prespecified and included funding, blinding, and success. All statistical analyses were conducted using Stata version 15 (StataCorp), and a 2-sided P < .05 was considered statistically significant.

---

### Assessment of noninferiority margins in cardiovascular medicine trials [^66ff2b83]. JACC: Advances (2024). Medium credibility.

Conclusions

Randomized clinical trials are one of the most acknowledged and trusted sources of knowledge in current evidence-based medicine. A number of issues can impair the proper reporting of a trial, including endpoint selection, assay sensitivity over placebo, adequateness of trial conduct, and selection of a proper data analysis plan. An additional peculiar challenge when dealing with noninferiority trials is represented by the determination of the type and magnitude of the noninferiority margin. Recalculating noninferiority margins based on actual event rates led to different outcomes in 1 out of 4 cardiovascular trials, and most differing trials lacked cautionary interpretation. To minimize these risks, recommendations from regulatory authorities should be highly regarded when conceiving, designing, conducting, reporting, and interpreting a noninferiority trial.

Perspectives

COMPETENCY IN MEDICAL KNOWLEDGE Noninferiority trials are becoming more common in cardiovascular medicine, but their reporting and interpretation can be difficult, particularly when using an absolute risk difference as the noninferiority margin. In cardiovascular medicine, absolute metrics are frequently preferred; however, using an absolute margin may carry some risk of regression towards noninferiority if the trial terminates with a lower-than-anticipated event rate. The adoption of both absolute and relative noninferiority margins might be the safest solution to address this issue.

TRANSLATIONAL OUTLOOK: Among noninferiority trials in cardiovascular medicine, the majority adopted an ARD margin and almost 1 out of 4 presented divergent results after recalculating the noninferiority margin. Most trials did not include notes of cautionary interpretation in the conclusions section. Our findings imply that Authors, Reviewers and Editors should be aware of the risks related to the choice of the noninferiority margin when dealing with designing, reporting, interpreting, and commenting on noninferiority trials, particularly if absolute metrics are used and in case of large discrepancy between observed and anticipated event rates in the control arm.

---

### Noninferiority designed cardiovascular trials in highest-impact journals [^89dc6be1]. Circulation (2019). Medium credibility.

Background

Noninferiority trials are increasingly being performed. However, little is known about their methodological quality. We sought to characterize noninferiority cardiovascular trials published in the highest-impact journals, features that may bias results toward noninferiority, features related to reporting of noninferiority trials, and the time trends.

Methods

We identified cardiovascular noninferiority trials published in JAMA, Lancet, or New England Journal of Medicine from 1990 to 2016. Two independent reviewers extracted the data. Data elements included the noninferiority margin and the success of studies in achieving noninferiority. The proportion of trials showing major or minor features that may have affected the noninferiority inference was determined. Major factors included the lack of presenting the results in both intention-to-treat and per-protocol/as-treated cohorts, α > 0.05, the new intervention not being compared with the best alternative, not justifying the noninferiority margin, and exclusion or loss of ≥ 10% of the cohort. Minor factors included suboptimal blinding, allocation concealment, and others.

Results

From 2544 screened studies, we identified 111 noninferiority cardiovascular trials. Noninferiority margins varied widely: risk differences of 0.4% to 25%, hazard ratios of 1.05 to 2.85, odds ratios of 1.1 to 2.0, and relative risks of 1.1 to 1.8. Eighty-six trials claimed noninferiority, of which 20 showed superiority, whereas 23 (21.1%) did not show noninferiority, of which 8 also demonstrated inferiority. Only 7 (6.3%) trials were considered low risk for all the major and minor biasing factors. Among common major factors for bias, 41 (37%) did not confirm the findings in both intention-to-treat and per-protocol/as-treated cohorts and 4 (3.6%) reported discrepant results between intention-to-treat and per-protocol analyses. Forty-three (38.7%) did not justify the noninferiority margin. Overall, 27 (24.3%) underenrolled or had > 10% exclusions. Sixty trials (54.0%) were open label. Allocation concealment was not maintained or unclear in 11 (9.9%). Publication of noninferiority trials increased over time (P < 0.001). Fifty-two (46.8%) were published after 2010 and had a lower risk of methodological or reporting limitations for major (P = 0.03) and minor factors (P = 0.002).

Conclusions

Noninferiority trials in highest-impact journals commonly conclude noninferiority of the tested intervention, but vary markedly in the selected noninferiority margin, and frequently have limitations that may impact the inference related to noninferiority.

---

### The clinical significance of statistical significance [^1fbf2f07]. The Oncologist (2008). Low credibility.

Modern clinical trials provide the evidence for most therapeutic advances, and that evidence, expressed in a statistical format, is used to draw inferences about a population from the study's results. Clinician judgment translates these inferences for best individual patient care, but many clinicians struggle with the statistical interpretation of trial results. This review provides a clinical and non-Bayesian perspective on some key elements in the statistical design, analysis, and interpretation of randomized, comparative, phase III clinical trials intended to demonstrate a better outcome (superiority) than with a control treatment.

---

### Reporting of noninferiority margins on clinicalTrials.gov: a systematic review [^2e88ef45]. JAMA Network Open (2025). High credibility.

Importance

The noninferiority margin is a key methodological parameter in noninferiority trials that affects both sample size calculation and interpretation of results.

Objective

To assess (1) the reporting of the noninferiority margin on ClinicalTrials.gov, including when it was reported; (2) the consistency of the noninferiority margin between registration and publication; and (3) the reporting of the noninferiority margin at registration in a sample of recent trials.

Evidence Review

This systematic review was conducted in 2 stages. Stage 1 involved identifying all noninferiority trials registered on ClinicalTrials.gov with a primary completion date of January 1, 2010, to January 1, 2015, and searching for corresponding publications. Stage 2 included all noninferiority trials registered between January 1, 2022, and June 30, 2023. Two reviewers independently and manually extracted methodological characteristics related to the noninferiority design for each trial at registration and, when available, in results posted on ClinicalTrials.gov and in publications. The time points for reporting the noninferiority margin were at registration, during the patient enrollment phase (between start date and primary completion date), after the primary completion date, or in results posted.

Findings

Among the 266 trials completed between 2010 and 2015, only 8 (3.0%) reported the noninferiority margin at registration. The noninferiority margin was reported after registration for 31 of 266 trials (11.7%), with 11 (4.1%) reporting it during the patient enrollment phase and 20 (7.5%) reporting it after the primary completion date. Of the 132 trials with results posted on ClinicalTrials.gov, 79 (59.8%) reported the noninferiority margin. A corresponding publication was found for 208 trials, with 196 (94.2%) reporting the noninferiority margin. For 5 trials reporting the margin at both registration and in publication, the noninferiority margin was consistent in both sources. Among the 327 noninferiority trials first posted between 2022 and 2023, 30 (9.2%) reported the noninferiority margin at registration.

Conclusions and Relevance

In this systematic review, the reporting of the noninferiority margin on ClinicalTrials.gov was low. Mandatory reporting of the design and the noninferiority margin at registration could enhance the transparency and favor more reliable results.

---

### Assessment of noninferiority margins in cardiovascular medicine trials [^a0e5242a]. JACC: Advances (2024). Medium credibility.

The noninferiority margin is typically prespecified by the investigators either as an absolute risk difference (ARD) or as a relative risk ratio (RRR) of the treatment effect. An absolute margin is preferrable to assess infrequent events or to communicate the risk to an individual patient, while relative metrics are helpful at the population level. In cardiovascular medicine, absolute metrics are frequently preferred; however, using an ARD margin carries some risk of regression towards noninferiority if the trial terminates with a lower-than-anticipated event rate.

The reporting and interpretation of noninferiority trials have been the objectives of previous investigation in different medical fields. In cardiovascular medicine, where noninferiority designs are common for introducing new treatments, a study by Simonato et al. found that about a third of noninferiority trials in interventional cardiology reached different conclusions when using ARD margins compared to RRR margins. However, their focus on coronary stent trials limits broader applicability, and they did not examine how these trials were reported.

Our hypothesis is that noninferiority trials in this field frequently exhibit discordant outcomes based on prespecified vs recalculated ARD margins, and that many of these trials lack adequate cautionary interpretation in their conclusions when the study results are not certain due to lower-than-expected event rates. To fill this gap, we aimed at characterizing the reporting and interpretation of noninferiority trials across the broad field of cardiovascular medicine by addressing the prevalence of different types of noninferiority margin, and by evaluating the impact of using absolute rather than relative noninferiority margins in the context of lower-than-anticipated event rates.

---

### A case for using relative rather than absolute noninferiority margins in clinical trials [^beb656c1]. JACC: Advances (2024). Medium credibility.

Lower than anticipated event rates in a clinical trial result in less robust estimates of treatment effects and reduce the chance of a 'positive' result in superiority trials and noninferiority trials with relative margins, but increase the chance of a 'positive' result in noninferiority trials with absolute margins

Because an absolute noninferiority margin is fixed irrespective of what the observed event rates in the trial are, it corresponds to a relatively larger difference when event rates are low and is therefore easier to 'meet' when event rates are low. In other words, the statistical power of a noninferiority trial with an absolute noninferiority margin is greater the lower the observed event rates. This is counterintuitive since the certainty of the effect estimate is proportional to the event rate (ie, increases with increasing event rates) and contrasts sharply with the traditional superiority trial designed to demonstrate that one therapy is better than another (Table 1).

Table 1
Consequences of Lower and Higher Than Anticipated Event Rates in Superiority and Noninferiority Trials

In superiority trials and noninferiority trials with relative noninferiority margins, a higher event rate leads to a more precise estimate of the treatment effect and increases power to meet the trial's primary endpoint. Put differently, the more precisely the treatment difference can be estimated, the greater the likelihood of a 'positive' trial. In these types of trials, overestimation of event rates at the design stage will result in an overestimation of statistical power and is therefore undesirable.

Conversely, a noninferiority trial using an absolute margin will be more likely to be 'positive' if the event rate is lower, despite the fact that the treatment effect will be less precisely estimated with lower event rates. This introduces an incentive for the trialists to overestimate the event rate in such trials.

---

### Interpreting adverse signals in diabetes drug development programs [^0a83b0da]. Diabetes Care (2013). Low credibility.

The rosiglitazone experience prompted the FDA to issue new guidance about CV risk (44). This requires a meta-analysis of important CV events in phase 2/3 to achieve an upper 95% CI of < 1.3 to qualify for approval without requiring a postmarketing CV trial, provided that overall benefit and risk support approval (Fig. 2). If the upper 95% CI is > 1.8, additional phase 3 safety studies are required before resubmission for marketing authorization. If the upper CI lies between 1.3 and 1.8 and approval is otherwise appropriate, then a postmarketing CV events study generally will be necessary and required to show an upper 95% CI of < 1.3. In practice, each sponsor of recently approved drugs has elected to undertake such a study (or have been encouraged to do so by the FDA), even if the phase 2/3 CV events conform to an upper 95% CI < 1.3. Indeed, such postmarketing studies appear to be almost obligatory because no sponsor company would wish for its product to be disadvantaged in years to come if its competitors can claim hard end point CV data from large purpose-designed trials. These studies, which are currently ongoing, are summarized in Table 4. Although they are mostly event driven, differences in estimated event rates and duration, selection of major CV events, power calculations, types of statistics (superiority vs. noninferiority), and use of placebo, an active comparator, or both make direct comparisons between studies difficult.

---

### Reporting of noninferiority margins on clinicalTrials.gov: a systematic review [^6444ab4d]. JAMA Network Open (2025). High credibility.

Discussion

To our knowledge, this systematic review was the first to address the reporting of the noninferiority margin from initial registration to publication. In the 2010 to 2015 sample of trials, a detailed longitudinal analysis from registration to publication found that the noninferiority margin was reported at registration on ClinicalTrials.gov in only 3.0% and after registration in 11.7% of studies. In addition, the noninferiority margin was underreported in results posted on ClinicalTrials.gov (59.8%), making the interpretation of results challenging. In contrast, the noninferiority margin was better reported in publications (94.2%). In the 2022 to 2023 sample, current reporting practices were assessed by examining a set of recently registered noninferiority trials. A slight but insufficient improvement was observed, with only 9.2% of trials reporting the noninferiority margin at registration.

The validity of these findings is reinforced by the methodological rigor we used: 2 authors independently selected trials, extracted data, and searched for corresponding publications, with discrepancies resolved by consensus with a third author. We explored the history of changes to identify the stage at which the margin was reported, which allowed us to explain how authors use ClinicalTrials.gov to declare the noninferiority margin and report results. The use of 2 distinct samples — 1 allowing an assessment of the reporting of the margin until publication and 1 considering recently registered trials — allowed us to provide evidence of any improvement over time.

Previous studies have addressed the issue of the reporting of the noninferiority margin in trial registries. Dekkers et alanalyzed registry records of noninferiority trials published between 2005 and 2009 and found that only 2.0% reported the noninferiority margin in trial registries. Gopal et al, in a cross-sectional analysis of noninferiority trials published between 2012 and 2014 and search for corresponding ClinicalTrials.gov records, found a consistent rate of noninferiority margin reporting of 2.6% at registration. The present study shows a slight improvement (albeit insufficient), with only 9.2% of studies reporting the noninferiority margin at registration in the 2022 to 2023 sample, and adds important information about the time at which the margin is reported.

---

### Canagliflozin compared with sitagliptin for patients with type 2 diabetes who do not have adequate glycemic control with metformin plus sulfonylurea: a 52-week randomized trial [^2ab0ae38]. Diabetes Care (2013). Low credibility.

Statistical analyses

The primary hypothesis for this study was that canagliflozin 300 mg was noninferior to sitagliptin 100 mg in reducing A1C from baseline to week 52. The primary analysis was based on the modified intent-to-treat population (all randomized subjects who received one or more doses of study drug) with a last observation carried forward approach to impute missing data at the end point. Assuming no difference between canagliflozin and sitagliptin in A1C-lowering efficacy and a common SD of 1.0% with respect to change in A1C, it was estimated that 234 subjects per treatment group would provide ∼90% power to demonstrate the noninferiority of canagliflozin compared with sitagliptin. In addition, per-protocol analysis (subjects completing the 52-week study and without protocol deviations that could impact efficacy assessment) was conducted to further support the noninferiority assessment. To provide 90% power for the per-protocol analysis, assuming a discontinuation rate of 35% over 52 weeks, the sample size was increased to 360 subjects per treatment group.

Safety analyses and the primary efficacy analysis were conducted using the modified intent-to-treat population. The last observation carried forward approach was used for the primary analysis of efficacy data. All statistical tests were interpreted at a two-sided significance level of 5%, and all CIs were interpreted at a two-sided confidence level of 95%. Primary and continuous secondary end points were assessed using an ANCOVA model, including treatment and stratification factors as fixed effects and the corresponding baseline value as a covariate. The least squares (LS) mean differences and two-sided 95% CIs were estimated for the comparisons of canagliflozin versus sitagliptin. Noninferiority of canagliflozin to sitagliptin was assessed based on a prespecified margin of 0.3% for the upper limit of the two-sided 95% CI for the comparison in the primary last observation carried forward analysis. If noninferiority was demonstrated, then superiority was assessed, as determined by an upper bound of the 95% CI around the between-group difference (canagliflozin minus sitagliptin) of < 0.0%. A prespecified hierarchical testing sequence was implemented to strongly control overall type I error attributable to multiplicity; P values are reported for prespecified comparisons only.

---

### The need for combined assessment of multiple outcomes in noninferiority trials in oncology [^6263fac6]. JAMA Oncology (2020). High credibility.

Noninferiority trials in oncology assess novel therapies with the potential for slightly worse recurrence or death outcomes (ie, the margin of noninferiority) than standard therapies. This poses a dilemma because, in the absence of potential health outcome advantages, these trials may not provide the treatment equipoise required for an ethical study. Any new treatment with the potential for slightly worse recurrence or death outcomes should have countervailing health outcome advantages, but these are rarely taken into account in the design of noninferiority trials. This article presents the argument that not only the potentially worse health outcomes but also the potential benefits of the novel therapy should be considered when designing, analyzing, and reporting noninferiority trials. Some approaches to study design and analysis that consider both primary and secondary end points are discussed, and reporting the joint distributions of end points for the novel and standard treatments is recommended.

---

### Reducing inferiority in the design, conduct, analysis, reporting, and interpretation of noninferiority trials [^742c2411]. JACC: Advances (2024). Medium credibility.

While the stroke/SE endpoint fulfills the constancy assumption, this original endpoint has limitations. In trials evaluating antithrombins and devices to reduce bleeding, a reasonable expectation is that ischemic and hemorrhagic endpoints will go in opposite directions, driving the results to noninferiority and set the field up for "biocreep" or noninferiority creep. Indeed, recent guidance in the New England Journal of Medicine states that a noninferiority trial should not be based on divergent endpoints. Additional limitations of a stroke/SE endpoint include the fact that efficacy (ischemic stroke) endpoints use intent to treat analyses, while safety endpoints (hemorrhagic strokes) typically use per protocol or as treated analyses, but despite differing analytic approaches these 2 endpoints are grouped together. The endpoint does not include morbid/mortal outcomes such as subdural and epidural intracranial hemorrhage. This endpoint gives ischemic and hemorrhagic stroke the same weight but hemorrhagic stroke is more often fatal and disabling (30%-55% mortality). This endpoint does not account for gastrointestinal bleeding, critical organ, or fatal bleeding. Note also that the acceptable margin for efficacy and safety may be different; when safety and efficacy endpoints are combined, this nuance is masked. Despite the use of the stroke/SE endpoint in the ENGAGE trial, the Food and Drug Administration considered safety and efficacy separately to select the more effective but less safe dosing strategy of 60 mg vs 30 mg of Edoxaban, raising questions as to the utility of this composite endpoint. Note also that the risk of patients may change, and the standard of care may change in subsequent trials which may violate the "constancy assumption", again raising questions about its utility. Finally, more input from patients (such as utility scores) as to how they value different endpoints, would be informative in constructing noninferiority margins. How many ischemic strokes would patients tolerate to yield fewer bleeding outcomes?

---

### Oral linezolid compared with benzathine penicillin G for treatment of early syphilis in adults (trep-AB study) in Spain: a prospective, open-label, non-inferiority, randomised controlled trial [^d3bca7b0]. The Lancet: Infectious Diseases (2024). High credibility.

The study Trep-AB was published by Maria Ubals and colleagues in 2024 in the journal Lancet Infect Dis. This study is related to the following diseases: Syphilis. In the Trep-AB study, the trial question was: is oral linezolid noninferior to benzathine penicillin G in patients with early syphilis? In the Trep-AB study, the study design was: multi-center, open label, RCT. In the Trep-AB study, the population was: 59 male patients. The inclusion criteria were adult patients with serological or molecular confirmation of syphilis. The key exclusion criteria were known allergy to investigational drugs; symptomatic neurosyphilis; concurrent use of drugs with potential interactions; previous treatment for early syphilis within the past 6 months; antibiotic treatment potentially active against Treponema pallidum in the past week; pregnancy; concomitant symptomatic STI. In the Trep-AB study, the interventions were: n = 29 linezolid (at an oral dose of 600 mg/day for 5 days) n = 30 benzathine penicillin G (single dose of 2.4 million IU IM). In the Trep-AB study, the primary outcome was: difference exceeding non-inferiority margin in the rate of treatment response after 48 weeks of follow-up (70% vs. 100%; ARD -29.6, 95% CI -50.5 to -8.8). In the Trep-AB study, the safety outcomes were: no significant difference in drug-related adverse events. In the Trep-AB study, the conclusion was: in adult patients with serological or molecular confirmation of syphilis, linezolid was not noninferior to benzathine penicillin G with respect to the rate of treatment response after 48 weeks of follow-up.

---

### Rethinking noninferiority [^aed0e760]. JACC: Advances (2025). Medium credibility.

The concept of noninferiority (NI) is used when evaluating new therapeutic alternatives that are expected to provide comparable efficacy to existing treatments while potentially offering additional benefits, such as improved safety, enhanced convenience, or reduced costs. However, NI randomized controlled trials (RCTs) are also commonly used to support regulatory approval for therapies that do not offer clear clinical advantages, such as new iterations of coronary stent platforms or other devices, where any advantages may be largely theoretical.

To establish NI, a NI margin is defined, representing the maximum allowable loss of efficacy that is considered clinically acceptable. The selection of this margin is inherently subjective and contentious, requiring a delicate balance between statistical efficiency and clinical judgment. A margin that is too wide risks approving a therapy that is meaningfully less effective, potentially compromising patient outcomes. Conversely, a margin that is too narrow may unnecessarily hinder the adoption of therapies with meaningful ancillary benefits by necessitating prohibitively large trial sample sizes, which may be too costly and impractical before approval.

Currently, new therapies typically undergo an all-or-nothing approval process based on a single NI RCT, meaning that if a therapy meets the predefined NI margin, it receives full approval without further evaluation. This approach assumes that a single NI trial is sufficient to establish the long-term acceptability of a new therapy, despite residual uncertainty regarding its true comparative efficacy. For example, in our analysis of 58 stent RCTs, the median NI margin corresponded to a relative risk of 1.62, representing a clinically significant excess risk. There is no inherent reason why a definitive decision regarding NI should be based on one study alone.

---

### Reducing inferiority in the design, conduct, analysis, reporting, and interpretation of noninferiority trials [^eca5c341]. JACC: Advances (2024). Medium credibility.

Another current and particularly vexing issue complicating the design of noninferiority trials is the use of composite endpoints in which efficacy and safety endpoints may go in opposite directions fully or partially cancelling each other out and potentially biasing the results toward noninferiority and masking important differences in the separate endpoints of efficacy and safety. Examples include the composite endpoints of net clinical adverse events (NACE) and ischemic/hemorrhagic stroke plus systemic embolization (SE) which merge ischemic and bleeding endpoints in noninferiority trials. Based upon the "constancy assumption", the FDA has recommended that subsequent noninferiority trials preserve the design and methods of the original trial upon which the magnitude of benefit of the original therapy over placebo was measured. Because original trials of pharmacotherapy in atrial fibrillation used stroke/SE as the endpoint, subsequent trials have used the same endpoint to preserve the constancy of the endpoints and the margin of benefit of an original active treatment over "placebo".

---

### Misleading reporting (spin) in noninferiority randomized clinical trials in oncology with statistically not significant results: a systematic review [^ea1d2a56]. JAMA Network Open (2021). High credibility.

Introduction

Randomized clinical trials (RCTs) are the criterion standard in research for hypothesis-based treatment efficacy and safety evaluation. RCTs must be performed according to predefined study protocols and statistical analysis plans.RCT results are typically interpreted based on the statistical significance of the primary end point analysis results. Trials with statistically significant results for the primary end point are known as positive trials, while those with results that are not significant results are negative trials. Both results are equally important for scientific progress if quality RCTs are planned, conducted, analyzed, and reported.

However, problems can arise when reports mislead readers by distorting result interpretation and suggesting that positive results have been obtained, even if statistically significant differences have not been determined for the primary end point. This problem of misleading reporting is called spin. Boutron et alobserved that RCT reports with spin were more likely to emphasize the benefit of the experimental treatment by focusing on statistically significant results, including those of secondary end points and subgroup analyses, which should be interpreted as exploratory results. Systematic reviews have previously classified spin in the field of oncology. Studies on the impact of spin have concluded that it might lead readers to overestimate result positivity.

Spin in RCTs have mainly been discussed in superiority trials, with few reports assessing spin in noninferiority trials. Compared with superiority RCTs, noninferiority RCTs may have more factors that complicate interpretation, including noninferiority margin, assay sensitivity, and choice of analysis population. However, no systematic review has investigated spin prevalence in noninferiority RCTs in oncology. Given the complexities of interpretation inherent to noninferiority RCTs, we consider it is important to clarify how much spin exists and the factors associated with the spin when it is present.

Therefore, we performed a systematic review of the spin prevalence in negative noninferiority cancer RCTs published since 2010, when the US Food and Drug Administration guidelines for noninferiority trials were published. This systematic review of noninferiority RCTs investigated spin prevalence and its associated factors in oncology.

---

### Non-inferiority trials in cardiology: what clinicians need to know [^72dc1cb7]. Heart (2020). Medium credibility.

Clinical trials traditionally aim to show a new treatment is superior to placebo or standard treatment, that is, superiority trials. There is an increasing number of trials demonstrating a new treatment is non-inferior to standard treatment. The hypotheses, design and interpretation of non-inferiority trials are different to superiority trials. Non-inferiority trials are designed with the notion that the new treatment offers advantages over standard treatment in certain important aspects. The non-inferior margin is a predetermined margin of difference between the new and standard treatment that is considered acceptable or tolerable for the new treatment to be considered 'similar' or 'not worse'. Both relative difference and absolute difference methods can be used to define the non-inferior margin. Sequential testing for non-inferiority and superiority is often performed. Non-inferiority trials may be necessary in situations where it is no longer ethical to test any new treatment against placebo. There are inherent assumptions in non-inferiority trials which may not be correct and which are not being tested. Successive non-inferiority trials may introduce less and less effective treatments even though these treatments may have been shown to be non-inferior. Furthermore, poor quality trials favour non-inferior results. Intention-to-treat analysis, the preferred way to analyse randomised trials, may favour non-inferiority. Both intention-to-treat and per-protocol analyses should be recommended in non-inferiority trials. Clinicians should be aware of the pitfalls of non-inferiority trials and not accept non-inferiority on face value. The focus should not be on the p values but on the effect size and confidence limits.

---

### Non-inferiority trials: a systematic review on methodological quality and reporting standards [^a1481b22]. Journal of General Internal Medicine (2024). Medium credibility.

Description of Non-inferiority Margin in Trials

The NI margin was specified in nearly all trials for both years (94.3% vs 95.1%), with an increase in the number of trials determining the NI margin pre-randomization (88.3% vs 94.5%, p = 0.001). Reporting of the rationale for how the size of the margin was determined increased over time (36.7% vs 56.8%, p < 0.001). While clinical judgement remained the most common source (29.8% vs 22.5%), there was an increase in the number of articles incorporating patient values as justification for the NI margin (0.3% vs 20.7%, p < 0.001). The source of the expected active control event rate was described in about half of the trials for both years (55.1% vs 47.3%, p < 0.001), and was mostly based on single or multiple trials. (Table 2) Notably, there was an increase in articles presenting primary outcomes as absolute (41.8% vs 47.9%; p < 0.001) rather than relative values, with a mean NI margin of 11 vs 10 (p = 0.308) for absolute values and a mean ratio difference of 1.36 vs 1.13 (p = 0.350) for relative values over time. Overall, there was a slight but significant change in the main conclusions for NI trials published in 2014 and 2019, respectively: 77.5%/79.1% (non-inferiority), 2.8%/3.8% (inferiority), 7.0%/2.8% (superiority), and 12.7%/14.4% (inconclusive, including not non-inferior, not inferior and not superior) (p = 0.032).

Table 2
Quality of Reporting Methodology for Noninferiority Margin

* SR = systematic review, SD = standard deviation, HR = hazard ratio, OR = odds ratio, RR = relative risk

---

### Non-inferiority trials in cardiology: what clinicians need to know [^0477d237]. Heart (2020). Medium credibility.

Non-inferiority trials: what the clinician needs to know

The interpretation of non-inferiority trials is more complex than that of superiority trials. Correct interpretation involves carefully examining the design, the execution as well as the analysis and results of the trials. Is the non-inferiority trial design appropriate? What is the primary non-inferior hypothesis? What is the non-inferior margin and how is it chosen? These must be stated in all non-inferiority trials. The non-inferior margin must be specified with the rationale clearly specified. Is the study population representative of the condition being studied? An important aspect is to look at the event rate of the standard treatment, which should be comparable to historical results in previous superiority trials of the standard treatment over placebo. This will allow the reader to judge if suitably at-risk patients are recruited in the non-inferiority trial. It is also important to examine the quality of the execution of the trial. Poor quality trials favour non-inferior results. Non-inferiority trials should be analysed according to both intention-to-treat and per-protocol approaches and the results of both analyses should be in concordance. The point estimate and the CIs of the non-inferior trial should be noted as well, not just the p values showing non-inferiority. This will allow the clinician to assess how close the results of the study are to the non-inferior margin.

The use of non-inferiority trials is likely to increase. Clinicians should not accept the term 'non-inferior' at face value. It is important to be aware that 'non-inferior' does not mean 'equivalent' or 'similar' or 'as good as'. Non-inferiority means the new treatment is not unacceptably worse than standard treatment.

---

### New concepts of clinical trials in rheumatoid arthritis: a boom of noninferiority trials [^97cf7b71]. Current Opinion in Rheumatology (2016). Low credibility.

Purpose Of Review

The purpose is to describe the most recent randomized controlled trials (RCT) in patients with rheumatoid arthritis that had a noninferiority design, and to focus on methodological aspects of noninferiority.

Recent Findings

In 2014 and 2015 10 different RCTs with a noninferiority-design could be identified, in comparison to only a few in the decade before. Most RCTs had a rather small sample size, and had ill-defined noninferiority-margins, or noninferiority-margins without comprehensible clinical meaning. Six of the 10 trials indeed arrived at a conclusion of 'noninferiority'; four did not. Interestingly, many of the RCTs were pragmatic studies comparing strategies, and the investigators were neither blind to the treatment nor to the outcome. In addition, the treatments were often adaptive (e.g. treat-to-target approach). These characteristics are considered built-in incentives for noninferiority.

Summary

In the competitive pharmaceutical landscape of rheumatoid arthritis, with many effective drugs and strategies, it is no surprise that the number of noninferiority-trial (sharply) rises. But noninferiority trials are difficult to design, conduct, and interpret, and many principles of noninferiority-trial designs are currently ignored, which may jeopardise their conclusions to some extent.

---

### A phase 3, randomized, double-blind study comparing tedizolid phosphate and linezolid for treatment of ventilated Gram-Positive hospital-acquired or ventilator-associated bacterial pneumonia [^d8f998fb]. Clinical Infectious Diseases (2021). Medium credibility.

Efficacy

The tedizolid day 28 ACM rate was 28.1% vs 26.4% with linezolid (treatment difference, –1.8 (95% CI: –8.2 to 4.7). Tedizolid was noninferior to linezolid based on day 28 ACM in the ITT population, as the lower bound of the 95% CI for the overall treatment difference (linezolid–tedizolid) was above the predefined noninferiority margin of 10% (Table 2). Time to death was similar among the tedizolid and linezolid groups (Supplementary Figure 2). In the mITT population, tedizolid day 28 ACM rates were 23.0% in patients with gram-positive–only infections (monomicrobial and polymicrobial) and 28.6% in patients with gram-positive/gram-negative infections vs 19.2% and 29.6%, respectively, in patients treated with linezolid.

Table 2.
Primary and Secondary Efficacy Outcomes in Various Patient Populations

Noninferiority was not demonstrated for tedizolid compared with linezolid based on the investigator-assessed clinical cure rate at TOC in the ITT population; the investigator-assessed clinical cure rate was 56.3% with tedizolid vs 63.9% with linezolid, for a treatment difference of –7.6 (97.5% CI: –15.7 to 0.5). Time to investigator-assessed clinical failure in the ITT population is summarized in Supplementary Figure 3. In the ITT population, the 25% quartile time to investigator-assessed clinical failure was 2.0 (95% CI: 2.0 to 3.0) days in the tedizolid group and 3.0 (95% CI: 2.0 to 11.0) days in the linezolid group. Investigator-assessed clinical response rates at the TOC visit were lower for tedizolid compared with linezolid across most patient subgroups (Supplementary Figure 4).

---

### Current issues in conduct and reporting of noninferiority randomized controlled trials in surgical management of cancer patients [^cf324990]. Annals of Surgical Oncology (2021). Medium credibility.

Background

Serious concerns regarding quality of conduct and reporting of noninferiority trials (NITs) have been raised. Systematic analysis of the quality of the surgical NITs is lacking. Assessing the quality of conduct, reporting, and interpretation of surgical NITs in cancer patients is critical given their potential clinical impact. We aim to assess the quality of conduct, reporting, and interpretation of NITs that investigate the effects of surgical management in cancer patients.

Methods

A cross-sectional analysis of papers identified through a comprehensive literature database search was performed. Forty papers employing a phase III noninferiority (NI) randomized trial design to study effects of surgical methodology or sequencing of surgery in patients with solid cancers were included. Papers were assessed for type of analysis, justification of the noninferiority margin (NIM), consistency of type I error with confidence intervals (CIs), ability to achieve the predefined sample size, and interpretations regarding NI.

Results

Only half of the papers used both intention-to-treat and per protocol analyses; 62.5% provided no or poor justification for the NIM; 42.5% showed inconsistency of the type I error rate with CIs; 52.5% were deemed poor or fair quality, and 60.0% did not achieve the predefined sample size. One-fifth of the papers provided interpretation of the NI hypothesis that was not in concordance with the CONSORT guidelines.

Conclusions

The quality of conduct, reporting, and interpretation of surgical NITs is suboptimal, requiring further improvements through adherence to guidelines and rigorous assessment at the stages of the study approval, funding, and the peer-review process.

---

### Design of HIV noninferiority trials: where are we going? [^ab730bd7]. AIDS (2013). Low credibility.

Since the introduction of zidovudine, a nucleoside analogue reverse transcriptase inhibitor, there has been continuous improvement in the efficacy of antiretroviral treatments. Briefly, antiretroviral therapy moved from the era of zidovudine monotherapy to a combination of two analogues of the reverse transcriptase and then to triple-drug therapy with the introduction of protease inhibitors in 1996. The efficacy of triple-drug combinations was further consolidated with the introduction of the non-nucleoside analogue reverse transcriptase inhibitor. Beyond 1996, the impressive improvement in efficacy has implied that death and clinical endpoints could not be reasonably used as primary efficacy endpoints. Recent studies used plasma viral load as surrogate endpoints to evaluate efficacy of antiretroviral combinations. Progress in antiretroviral efficacy has also led to a move from superiority to noninferiority design. Methodological issues in noninferiority design have been already criticized, but recent trials provide a good opportunity for discussing some key features of that design. Recent studies are used to illustrate some inconsistencies in the choice of response rates, power and noninferiority margin. It appears that HIV noninferiority trials are overpowered by assuming lower success rates than those observed, enrolling a large number of patients and choosing a large margin. Consequently, failure to demonstrate noninferiority is uncommon. Novel designs or endpoints should be introduced emphasizing the expected benefits in terms of toxicity, adherence, resistance or costs.

---

### Exploring different objectives in non-inferiority trials [^d115e303]. BMJ (2024). Excellent credibility.

Different objectives: design considerations

Choosing non-inferiority margin

Conventionally, a non-inferiority trial aims to show that a new treatment is unlikely to be worse than the control arm by a defined margin based on a predefined effect measure (eg, absolute difference, relative risk, or hazard ratio). The difference in efficacy for the experimental relative to the control arm is calculated, and a maximum allowed value for the upper limit (assuming a negative outcome, such as death) or lower limit (assuming a positive outcome, such as disease remission) of the confidence interval is agreed at the design stage of the trial (non-inferiority margin; figure 1).

Fig 1
Illustration of non-inferiority based on difference in treatment effect on the risk ratio scale comparing a new intervention with an active control. Point estimates are shown with 95% confidence intervals (CI)

The non-inferiority margin should be derived differently depending on the trial objective. For alternative option trials, the margin is conventionally based on efficacy (with a safety analysis considered separately) and defined as the smallest clinically important difference. This approach is typical in licensing trials. The value of the margin might be based on expert opinion and, especially in licensing trials, on maintenance of the effect based on evidence synthesis from previous trials that compared the current treatment with placebo.

For a replacement trial, the non-inferiority margin would be based mainly on the expected magnitude of other benefits that the new treatment offers because the margin reflects the loss in effectiveness that balances the benefits (fig 2). Two approaches are possible to represent the expected other benefits on the scale of the primary outcome. A formal decision analysis approach could be undertaken to quantify the expected other benefits and potential harms relative to the primary outcome. Alternatively, a panel of clinicians or patients, or both, could make a judgment (by reaching a consensus or by obtaining individuals' opinions and synthesising these statistically). Ideally, guideline or policy bodies would be engaged in the selection of the margin, because ultimately their opinion is most relevant. Clearly, however, quantifying or judging the expected other benefits relative to the primary outcome will often be challenging, and might not be feasible. Also, formal decision analysis is likely to need expert support.

---

### Efficacy and safety of risankizumab vs. secukinumab in patients with moderate-to-severe plaque psoriasis (IMMerge): results from a phase III, randomized, open-label, efficacy-assessor-blinded clinical trial [^807b0401]. The British Journal of Dermatology (2021). Medium credibility.

Primary efficacy endpoints

The results of the two primary efficacy analyses showed that 73.8% (n = 121) of patients randomized to risankizumab achieved PASI 90 at week 16 compared with 65.6% (n = 107) of patients randomized to secukinumab. The difference in proportions of PASI 90 responders between groups (adjusted for stratification factors) was 8.2% [96.25% confidence interval (CI) −2.2 to 18.6], which fell within the 12% noninferiority margin; thus, the primary endpoint of noninferiority of risankizumab to secukinumab at week 16 was met (Figure 3). At week 52, 86.6% (n = 142) of patients randomized to risankizumab achieved PASI 90 compared with 57.1% (n = 93) of patients randomized to secukinumab. The adjusted difference was 29.8% (95% CI 20.8–38.8, P < 0.001) (Figure 3); thus, the primary endpoint of superiority of risankizumab to secukinumab at week 52 was met.

Figure 3
Primary efficacy results. Proportions of patients with ≥ 90% reduction in Psoriasis Area and Severity Index (PASI 90) at week 16 and week 52. Risankizumab was noninferior to secukinumab at week 16 based on a noninferiority margin of 12%, and superior to secukinumab at week 52 (P < 0.001). Data were assessed for the intent‐to‐treat population. The adjusted‐difference confidence interval (CI) values were 96.25% CI at week 16 and 95% CI at week 52. P ‐values were calculated from the Cochran–Mantel–Haenszel test, stratified by weight (≤ 100 kg vs. > 100 kg) and prior systemic biologic use for psoriasis. Nonresponder imputation was used for missing data.

---

### Rationale for and methods of superiority, noninferiority, or equivalence designs in orthopaedic, controlled trials [^90a73790]. Clinical Orthopaedics and Related Research (2011). Low credibility.

Background

To provide value-based healthcare in orthopaedics, controlled trials are needed to assess the comparative effectiveness of treatments. Typically comparative trials are based on superiority testing using statistical tests that produce a p value. However, as orthopaedic treatments continue to improve, superiority becomes more difficult to show and, perhaps, less important as margins of improvement shrink to clinically irrelevant levels. Alternative methods to compare groups in controlled trials are noninferiority and equivalence. It is important to equip the reader of the orthopaedic literature with the knowledge to understand and critically evaluate the methods and findings of trials attempting to establish superiority, noninferiority, and equivalence.

Questions/Purposes

I will discuss supplemental and alternative methods to superiority for assessment of the outcome of controlled trials in the context of diminishing returns on new therapies over old ones.

Methods

The three methods-superiority, noninferiority, and equivalence-are presented and compared, with a discussion of implied pitfalls and problems.

Results

Noninferiority and equivalence offer alternatives to superiority testing and allow one to judge whether a new treatment is no worse (within a margin) or substantively the same as an active control. Noninferiority testing also allows for inclusion of superiority testing in the same study without the need for adjustment of the statistical methods.

Conclusions

Noninferiority and equivalence testing might prove most valuable in orthopaedic, controlled trials as they allow for comparative assessment of treatments with similar primary end points but potentially important differences in secondary outcomes, safety profiles, and cost-effectiveness.

---

### Efficacy and safety of risankizumab vs. secukinumab in patients with moderate-to-severe plaque psoriasis (IMMerge): results from a phase III, randomized, open-label, efficacy-assessor-blinded clinical trial [^3840d064]. The British Journal of Dermatology (2021). Medium credibility.

Summary

Background

Patients with plaque psoriasis treated with biologic therapies need more efficacious, safe and convenient treatments to improve quality of life. Risankizumab and secukinumab inhibit interleukin‐23 and interleukin‐17A, respectively, and are effective in adult patients with moderate‐to‐severe plaque psoriasis but have different dosing regimens.

Objectives

To compare directly the efficacy and safety of risankizumab vs. secukinumab over 52 weeks.

Methods

IMMerge was an international, phase III, multicentre, open‐label, efficacy–assessor‐blinded, active‐comparator study, in which adult patients with chronic, moderate‐to‐severe plaque psoriasis were randomized in a 1: 1 ratio to treatment with risankizumab 150 mg or secukinumab 300 mg. Primary efficacy endpoints were the proportions of patients achieving ≥ 90% improvement from baseline in Psoriasis Area and Severity Index (PASI 90) at week 16 (noninferiority comparison with margin of 12%) and week 52 (superiority comparison).

Results

In total 327 patients from nine countries were treated with risankizumab (n = 164) or secukinumab (n = 163). Risankizumab was noninferior to secukinumab in the proportion of patients achieving PASI 90 at week 16 [73.8% vs. 65.6%; difference of 8.2%, 96.25% confidence interval (CI)−2.2 to 18.6; within the 12% noninferiority margin] and superior to secukinumab at week 52 (86.6% vs. 57.1%; difference of 29.8%, 95% CI 20.8–38.8; P < 0.001), thus meeting both primary endpoints. All secondary endpoints (PASI 100, static Physician's Global Assessment 0 or 1, and PASI 75) at week 52 demonstrated superiority for risankizumab vs. secukinumab (P < 0.001). No new safety concerns were identified.

Conclusions

At week 52, risankizumab demonstrated superior efficacy and similar safety with less frequent dosing compared with secukinumab.

---

### Photodynamic therapy vs. topical imiquimod for treatment of superficial basal cell carcinoma: a subgroup analysis within a noninferiority randomized controlled trial [^9733580f]. The British Journal of Dermatology (2015). Low credibility.

Background

A recent noninferiority randomized controlled trial (RCT) indicated that imiquimod can be considered as superior to methylaminolevulinate photodynamic therapy (MAL-PDT) in the treatment of superficial basal cell carcinoma (sBCC). Knowledge of treatment effectiveness in subgroups of patients is of great value in clinical practice to select the most effective treatment for an individual patient with sBCC.

Objectives

To explore whether the relative treatment effect of MAL-PDT and imiquimod is consistent across subgroups defined by patient and tumour characteristics.

Methods

Data were derived from a single-blinded, noninferiority, multicentre RCT comparing MAL-PDT, topical imiquimod and fluorouracil (ISRCTN79701845). Treatment success was defined as free of tumour recurrence at 12-month follow-up. Subgroup analyses were performed for subgroups defined by sex, age, tumour location and tumour size.

Results

Two hundred and two patients received MAL-PDT and 198 received imiquimod. The superiority of imiquimod vs. MAL-PDT was observed in subgroups of females, sBCC on the trunk and large tumours with risk differences in favour of imiquimod of 18.4% [95% confidence interval (CI) 7.8–29.0%], 21.0% (95% CI 10.9–31.1%) and 18.9% (95% CI 7.1–30.7%), respectively. Higher probability of treatment success for imiquimod vs. MAL-PDT was consistently found in all other subgroups with the exception of sBCC localized on the lower extremities in older patients. In the latter subgroup, the risk difference at the expense of imiquimod was -57.3% (95% CI -81.7% to -32.9%).

Conclusions

Imiquimod remains the first-choice treatment for sBCC in terms of effectiveness. In older patients with sBCC on the lower extremities MAL-PDT might be preferred. Results should be interpreted carefully as subgroup analyses were exploratory and not driven by prior hypotheses.

---

### Non-inferiority trials: a systematic review on methodological quality and reporting standards [^c92f954c]. Journal of General Internal Medicine (2024). Medium credibility.

CONCLUSION

The findings of our systematic review demonstrate that although the methods and quality of reporting of NI trials are improving, there continues to be deficiencies in the design and conduct of NI trials, specifically related to justification of the NI margin, blinding, and method of analysis. Clear justification of the NI margin is essential for accurate interpretation of NI trial results, and minimizes the potential for an unacceptable loss of efficacy with subsequent introduction of inferior therapies into clinical practice. These deficiencies may be attributed to unique aspects of NI trials compared with superiority trials, creating unfamiliarity of the investigators, authors, reviewers and editors of journals. Thus, it remains imperative that researchers, institutional review boards, editors and peer reviewers develop greater awareness of and strive for improved compliance with available guidelines that serve to improve the quality of reporting and reliability of results and conclusions of NI studies. Improved descriptions of the methods used and justification for the design and analysis of such trials is warranted to ensure accurate and consistent delivery of information that could hold vital implications in clinical decision-making.

---

### Efficacy and safety of risankizumab vs. secukinumab in patients with moderate-to-severe plaque psoriasis (IMMerge): results from a phase III, randomized, open-label, efficacy-assessor-blinded clinical trial [^9d287aee]. The British Journal of Dermatology (2021). Medium credibility.

Background

Patients with plaque psoriasis treated with biologic therapies need more efficacious, safe and convenient treatments to improve quality of life. Risankizumab and secukinumab inhibit interleukin-23 and interleukin-17A, respectively, and are effective in adult patients with moderate-to-severe plaque psoriasis but have different dosing regimens.

Objectives

To compare directly the efficacy and safety of risankizumab vs. secukinumab over 52 weeks.

Methods

IMMerge was an international, phase III, multicentre, open-label, efficacy-assessor-blinded, active-comparator study, in which adult patients with chronic, moderate-to-severe plaque psoriasis were randomized in a 1: 1 ratio to treatment with risankizumab 150 mg or secukinumab 300 mg. Primary efficacy endpoints were the proportions of patients achieving ≥ 90% improvement from baseline in Psoriasis Area and Severity Index (PASI 90) at week 16 (noninferiority comparison with margin of 12%) and week 52 (superiority comparison).

Results

In total 327 patients from nine countries were treated with risankizumab (n = 164) or secukinumab (n = 163). Risankizumab was noninferior to secukinumab in the proportion of patients achieving PASI 90 at week 16 [73.8% vs. 65.6%; difference of 8.2%, 96.25% confidence interval (CI)-2.2 to 18.6; within the 12% noninferiority margin] and superior to secukinumab at week 52 (86.6% vs. 57.1%; difference of 29.8%, 95% CI 20.8–38.8; P < 0.001), thus meeting both primary endpoints. All secondary endpoints (PASI 100, static Physician's Global Assessment 0 or 1, and PASI 75) at week 52 demonstrated superiority for risankizumab vs. secukinumab (P < 0.001). No new safety concerns were identified.

Conclusions

At week 52, risankizumab demonstrated superior efficacy and similar safety with less frequent dosing compared with secukinumab.

---

### Reporting of noninferiority margins on clinicalTrials.gov: a systematic review [^576427b0]. JAMA Network Open (2025). High credibility.

This study highlights a persistent low rate of noninferiority margin reporting at registration on ClinicalTrials.gov. This absence of transparent and traceable reporting creates the possibility of modifications to the noninferiority margin after the trial has begun. Such changes are particularly concerning because they could skew results toward more favorable conclusions. The conclusion of a noninferiority trial — whether the results fall within or beyond the noninferiority margin — depends on the predefined margin value. Modifying this noninferiority margin post hoc, whether intentionally or not, allows treatments that initially failed to meet the noninferiority criteria to be later considered noninferior with an expanded margin. Altering the noninferiority margin during a trial, particularly after seeing the results, may be similar to selective outcome reporting. We did not search for the noninferiority margin in study protocols, which might have shown a higher reporting rate, but study protocols are not always available. ClinicalTrials.gov remains a more accessible source of trial information.

Consequently, we recommend making the reporting of the noninferiority margin mandatory on registration; otherwise, the margin will likely not be reported. To this end, we suggest that ClinicalTrials.gov and other registries introduce mandatory fields for the design of interventional trials, prompting authors to classify them as superiority, noninferiority, or equivalence trials. For noninferiority trials, mandatory fields related to the noninferiority margin may be implemented to facilitate the tracking of any changes to the noninferiority margin over time. Such a requirement would enhance not only the integrity of clinical research but also the trust in noninferiority trial results. This suggestion extends to equivalence trials.

---

### Non-inferiority clinical trials to establish effectiveness… [^eca4c36a]. FDA (2025). Medium credibility.

CI for C-T is 1, well below M1; NI is demonstrated.
2. Point estimate of C-T favors C; the upper bound of the 95% CI for C-T is > 2, above M1; NI is not demonstrated.
3. Point estimate of C-T is zero, which suggests an equal effect; but the upper bound of the. 95% CI for C-T is > 2, so that NI is not demonstrated.
4. Point estimate favors T; NI is demonstrated, but superiority is not demonstrated.
5. Point estimate favors T; superiority and NI are demonstrated.
6. Point estimate of C-T is 1, favoring the control. The upper bound of the 95% CI for C-T. is < M1, demonstrating NI but at the same time the 95% CI for C-T is above zero, indicating that T is actually inferior to C, even while meeting the NI standard. The determination of M1 is a critical step in designing an NI trial and is often difficult; this.
4.

C-T point estimate favors C and upper bound of 95% CI > M1, indicating the study does not provide evidence of effectiveness for test drug. D. Assay Sensitivity Assay sensitivity is an essential property of an NI clinical trial. Assay sensitivity is the ability of the trial to have detected a difference between treatments of a specified size. Stated in another way, assay sensitivity means that had the study included a placebo, a control drug-placebo difference of at least M1 would have been present. study, inadequate measurement techniques, errors in delivering assigned treatments, high attrition, or poor follow-up may reduce the difference C-T observed in the study, potentially leading to a false conclusion of non-inferiority. It should also be appreciated that intent-to-treat approaches, which preserve the principle that all patients are analyzed according to the treatment. absolute 1. 05% increase in mortality rate in the reteplase-treated patients compared to those treated with streptokinase. The NI analysis for this study was to show that the 95% confidence interval of the difference in mortality rates.

---

### Noninferiority margins in trials of thrombectomy devices for acute ischemic stroke: is the bar being set too low? [^9cc55429]. Stroke (2019). Medium credibility.

Background and Purpose- Novel endovascular thrombectomy (EVT) devices for acute ischemic stroke are often cleared by regulatory agencies on the basis of noninferiority trials. The relation between the noninferiority margins used in trials and the minimal clinically important differences (MCIDs) determined by experts have not been systematically investigated. Methods- Systematic searches were performed to identify (1) all noninferiority design or noninferiority-presented stroke-EVT trials for acute ischemic stroke, (2) all studies determining the MCIDs for the same outcomes, and (3) all noninferiority coronary revascularization trials. Stroke-EVT trial results were reanalyzed using the broad noninferiority margins originally used and narrower noninferiority margins derived from formal MCID studies. Results- We identified 7 noninferiority-designed or noninferiority-interpreted stroke-EVT controlled trials, enrolling 1766 patients, variously comparing coil retrievers, first- and second-generation stent retrievers, and aspiration devices. In 6 trials, the primary outcome was achievement of reperfusion, using noninferiority margins of 15% (3 trials), 10% (2 trials), and 8% (1 trial). In contrast, a stroke expert survey identified the MCID for reperfusion as 3.1% to 5%, and cardiac trials used noninferiority margins of 3.5% to 4.4%. In one stroke-EVT trial, the primary outcome was functional independence, using a noninferiority margin of 15%. However, 2 stroke expert survey studies identified MCIDs for functional independence as having lower values, 5% and 1% to 1.5%. For both reperfusion and functional independence outcomes, all 7 trials demonstrated noninferiority with the broadest noninferiority margin, but only 4 and 3 trials demonstrated noninferiority with actual expert-derived margins for reperfusion and functional independence, respectively. Conclusions- Noninferiority margins used in EVT device trials have regularly exceeded the MCIDs determined by stroke experts, as well as margins used for cardiac devices. New approaches, such as the use of reasonably adequate performance margins, rather than noninferiority margins, are needed to optimize stroke-EVT trial design integrity and trial performance feasibility.